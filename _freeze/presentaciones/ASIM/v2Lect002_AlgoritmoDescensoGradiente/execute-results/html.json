{
  "hash": "defd1089d8d136efa73696950043b792",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Descenso de Gradiente en Ciencias Biomédicas\"\nsubtitle: \"Regresión lineal múltiple y regresión logística\"\nauthor: \"PhD. Pablo Eduardo Caicedo Rodríguez\"\ndate: last-modified\nlang: es\nformat:\n  revealjs:\n    code-tools: true\n    code-overflow: wrap\n    code-line-numbers: true\n    code-copy: true\n    fig-align: center\n    self-contained: true\n    theme:\n      - simple\n      - ../../recursos/estilos/metropolis.scss\n    slide-number: true\n    preview-links: auto\n    logo: ../../recursos/imagenes/generales/Escuela_Rosario_logo.png\n    css: ../../recursos/estilos/styles_pres.scss\n    footer: <https://pablocaicedor.github.io/>\n    transition: fade\n    progress: true\n    scrollable: true\n    hash: true\n  beamer:\n    slide-level: 2\n    incremental: false\n    aspectratio: 32\n    navigation: horizontal\n    theme: CambridgeUS\n    header-includes:\n      \\makeatletter\n      \\expandafter\\let\\csname figure*\\endcsname\\figure\n      \\expandafter\\let\\csname endfigure*\\endcsname\\endfigure\n      \\expandafter\\let\\csname table*\\endcsname\\table\n      \\expandafter\\let\\csname endtable*\\endcsname\\endtable\nexecute:\n  echo: false\n  warning: false\n  freeze: auto\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n<!-- TODO: Cambiar chunks por tabset quarto. Un tab mostrando resultado y otro tab mostrando el código -->\n\n## Objetivos de la sesión\n\n- Entender el **principio del descenso de gradiente (GD)** como método de optimización.\n- Aplicar GD a **regresión lineal múltiple** (objetivo continuo) y **regresión logística** (clasificación 0/1).\n- Analizar decisiones de ingeniería: **tasa de aprendizaje**, **escalado/normalización**, **batch vs. mini-batch vs. SGD**.\n- Interpretar resultados en **contextos biomédicos** (diagnóstico, pronóstico y evaluación de riesgo).\n\n::: notes\nEstructura sugerida: 4 bloques de ~45+45+45+30 min. Actividades cortas para mantener la atención.\n:::\n\n---\n\n## Agenda\n\n1. Fundamentos de GD y funciones de costo\n2. Caso 1: **Regresión lineal múltiple** con GD\n3. Caso 2: **Regresión logística** con GD\n4. Buenas prácticas, diagnósticos y discusión aplicada\n\n---\n\n# 1. Fundamentos de descenso de gradiente\n\n## Motivación biomédica\n\n- Ajustar parámetros de un **modelo fisiológico** o un **predictor clínico** con datos reales.\n- Ejemplos típicos:\n  - Estimar **gasto energético** a partir de IMC, edad y FC.\n  - Estimar **edad vascular** con variables de laboratorio.\n  - **Clasificar** presencia/ausencia de una condición (0/1) con biomarcadores.\n\n::: notes\nEnfatizar que el GD es base de la mayoría de métodos de AA actuales, incluidas redes neuronales.\n:::\n\n---\n\n## Regresión Lineal\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](v2Lect002_AlgoritmoDescensoGradiente_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n## Regresión Lineal\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](v2Lect002_AlgoritmoDescensoGradiente_files/figure-revealjs/unnamed-chunk-3-3.png){width=960}\n:::\n:::\n\n\n\n## Función de costo (error)\n\n:::columns\n:::{.column width=\"45%\"}\n**Regresión (continuo):**\n$$\nJ(\\mathbf{w}) \\;=\\; \\frac{1}{2m}\\sum_{i=1}^{m}\\left(y_j - \\hat{y}_j\\right)^2\n$$\ndonde $\\hat{y}_j = \\mathbf{w}^\\top \\mathbf{x}_j$.\n:::\n:::{.column .smaller width=\"45%\"}\n**Clasificación binaria:**\n**Entropía cruzada** (log-loss):\n$$\nJ(\\mathbf{w}) \\;=\\; -\\frac{1}{m}\\sum_{i=1}^{m}\\left[\\,y_i\\log\\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i)\\,\\right]\n$$\ndonde $\\hat{p}_i=\\sigma(\\mathbf{w}^\\top \\mathbf{x}_i)=\\frac{1}{1+e^{-\\mathbf{w}^\\top\\mathbf{x}_i}}$.\n:::\n:::\n\n::: notes\nConectar con la interpretación probabilística en logística y con el MSE en lineal.\n:::\n\n---\n\n## Función de costo (error)\n::: {.callout-important title=\"... Para el caso de ejemplo (un modelo tipo lineal)\"}\n\n\n$$\n\\mathbf{w_{j}}^\\top \\;=\\; \\left[w_{j,1}, w_{j,0}\\right]\n$$\n\n$$\nsalary_i = x_i\n$$\n\n$$\n\\hat{y}_j  \\;=\\; w_{j,1}*x_j + w_{j,0}\n$$\n\n$$\nJ(\\mathbf{w}) \\;=\\; \\frac{1}{2m}\\sum_{i=1}^{m}\\left(y_j - w_{j,1}*x_i - w_{j,0}\\right)^2\n$$\n\n:::\n\n---\n\n## Idea central del GD\n\n- Partimos de $\\mathbf{w}_{(0)}$ (p. ej., aleatorio).\n- Iteramos:\n$$\n\\mathbf{w}_{(t+1)} \\;=\\; \\mathbf{w}_{(t)} \\;-\\; \\alpha\\, \\nabla_{\\mathbf{w}} J(\\mathbf{w}_{(t)})\n$$\n- $\\alpha$ = **tasa de aprendizaje**: grande → rápido pero inestable; pequeña → estable pero lento.\n- Convergencia: buscamos $\\nabla J \\approx \\mathbf{0}$.\n\n**Visualización conceptual:** “valle” del error y trayectoria en zig-zag hacia el mínimo.\n\n---\n\n## Algoritmo de Descenso de Gradiente\n\n:::{.small_font}\n\n::: {.callout-note title=\"Para la estimación de $w_{j,0}$\" collapsible=\"false\"}\n\n$$\nw_{j+1,0} = w_{j,0} - \\alpha \\frac{\\partial J}{\\partial w_{j,0}}\n$$\n\n$$\n\\frac{\\partial J}{\\partial w_{j,0}} =\n\\frac{\\partial}{\\partial w_{j,0}}\n\\left(\n\\frac{1}{2m} \\sum_{i=1}^{m}\n\\left( y_i - w_{j,1} x_i - w_{j,0} \\right)^2\n\\right)\n$$\n\n$$\n\\frac{\\partial}{\\partial w_{j,0}}\n\\left(\n\\frac{1}{2m}\n\\sum_{i=1}^{m}\n\\left(\ny_i - w_{j,1}x_i - w_{j,0}\n\\right)^2\n\\right)\n=\n\\frac{1}{m}\n\\sum_{i=1}^{m}\n\\left(\nw_{j,1}x_i + w_{j,0} - y_i\n\\right)\n$$\n:::\n\n::: {.callout-note title=\"Para la estimación de $w_{j,1}$\" collapsible=\"false\"}\n\n$$\nw_{j+1,1} = w_{j,1} - \\alpha \\frac{\\partial J}{\\partial w_{j,1}}\n$$\n\n$$\n\\frac{\\partial J}{\\partial w_{j,1}} =\n\\frac{\\partial}{\\partial w_{j,1}}\n\\left(\n\\frac{1}{2m} \\sum_{i=1}^{m}\n\\left( y_i - w_{j,1} x_i - w_{j,0} \\right)^2\n\\right)\n$$\n\n$$\n\\frac{\\partial J}{\\partial w_{j,1}}\n=\n\\frac{1}{m}\n\\sum_{i=1}^{m}\n\\left(\nw_{j,1}x_i + w_{j,0} - y_i\n\\right)x_i\n$$\n\n:::\n\n:::\n\n\n---\n\n## Variantes: batch, mini-batch, SGD\n\n- **Batch GD:** usa todo el conjunto en cada actualización (costo alto por iteración).\n- **Mini-batch GD:** usa lotes pequeños (compromiso eficiencia/ruido).\n- **SGD (estocástico):** actualiza con una sola muestra por paso (barato, ruidoso, puede escapar de óptimos pobres).\n\n**Práctica recomendada:** mini-batch (p. ej., 32–256).\n\n---\n\n## Preprocesamiento y escalado\n\n- **Estandarizar** o **normalizar** las $x_j$ acelera y estabiliza GD.\n- Centrar: $x_j \\leftarrow (x_j - \\mu_j)/\\sigma_j$.\n- Manejo de outliers y transformaciones (log, Box–Cox) cuando aplique.\n\n::: notes\nConectar con mediciones biomédicas heterogéneas y escalas físicas.\n:::\n\n---\n\n## 1.5 EDA\n\n### Empezar a usar jupyter.\n\n---\n\n# 2. Caso 1 · Regresión lineal múltiple con GD\n\n## Planteamiento\n\n**Objetivo biomédico (ejemplo):** predecir **gasto energético** (kcal) a partir de **edad**, **IMC** y **FC**.\n\nModelo lineal:\n$$\n\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} = w_0 + w_1 x_1 + \\cdots + w_p x_p\n$$\n\nCosto (MSE):\n$$\nJ(\\mathbf{w}) = \\frac{1}{2m}\\sum_{i=1}^{m}(y_i - \\hat{y}_i)^2\n$$\n\nGradiente:\n$$\n\\frac{\\partial J}{\\partial w_j} = -\\frac{1}{m}\\sum_{i=1}^{m}(y_i - \\hat{y}_i)\\,x_{ij}\n$$\n\nActualización:\n$$\nw_j \\leftarrow w_j - \\alpha\\,\\frac{\\partial J}{\\partial w_j}\n$$\n\n---\n\n## Pseudocódigo (mini-batch)\n\n```pseudo\nin: X (m×p), y (m), α, batch_size, epochs\npreprocess: X ← standardize(X)\n\ninitialize w ← zeros(p+1)  # incluye sesgo w0 si se usa X̃ con columna 1\n\nfor epoch in 1..epochs:\n    for B in iterate_minibatches(X, y, batch_size, shuffle=True):\n        Xb, yb ← B\n        yhat ← Xb · w\n        grad ← (1/|B|) · (Xbᵀ · (yhat - yb))\n        w ← w - α · grad\n\nreturn w\n```\n\n::: notes\nDiscutir convergencia, criterio de parada (máx. iteraciones o ΔJ pequeño).\n:::\n\n---\n\n## Diagnóstico y validación\n\n- Curva $J$ vs. iteraciones (entrenamiento y validación).\n- Errores residuales: homocedasticidad, estructura vs. predicción.\n- Interpretación clínica de coeficientes $w_j$ y unidades.\n- Comparar con **ecuaciones normales** (solución cerrada) y discutir condicionamiento numérico.\n\n---\n\n# 3. Caso 2 · Regresión logística con GD (clasificación 0/1)\n\n## Planteamiento\n\n**Objetivo biomédico (ejemplo):** clasificar **riesgo de enfermedad** (0/1) con panel de biomarcadores.\n\nModelo:\n$$\n\\hat{p} = \\sigma(\\mathbf{w}^\\top\\mathbf{x}),\\quad \\sigma(z)=\\frac{1}{1+e^{-z}}\n$$\n\nCosto (entropía cruzada):\n$$\nJ(\\mathbf{w}) = -\\frac{1}{m}\\sum_{i=1}^{m}\\Big[y_i\\log \\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i)\\Big]\n$$\n\nGradiente:\n$$\n\\frac{\\partial J}{\\partial w_j} = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{p}_i - y_i)\\,x_{ij}\n$$\n\nActualización:\n$$\nw_j \\leftarrow w_j - \\alpha\\,\\frac{\\partial J}{\\partial w_j}\n$$\n\n---\n\n## Pseudocódigo (mini-batch)\n\n```pseudo\nin: X (m×p), y∈{0,1}^m, α, batch_size, epochs\npreprocess: X ← standardize(X)\n\ninitialize w ← zeros(p+1)\n\nfor epoch in 1..epochs:\n    for B in iterate_minibatches(X, y, batch_size, shuffle=True):\n        Xb, yb ← B\n        z ← Xb · w\n        p ← sigmoid(z)\n        grad ← (1/|B|) · (Xbᵀ · (p - yb))\n        w ← w - α · grad\n\nreturn w\n```\n\n**Inferencia:** clasificar con umbral $\\hat{p} \\ge \\tau$ (clínico/operativo).\n\n---\n\n## Métricas y curvas\n\n- **AUC-ROC**, **AUPRC**, **sensibilidad**, **especificidad**, **F1**.\n- Elección del **umbral $\\tau$** por criterio clínico (p. ej., maximizar sensibilidad bajo límite de FPs).\n- Calibración: curvas de confiabilidad.\n\n::: notes\nRelaciones costo-beneficio y prevalencia en biomédica.\n:::\n\n---\n\n## Visualización de la frontera de decisión\n\n- Con dos características ($x_1, x_2$), la frontera es una **línea** (hiperplano en general).\n- Durante GD, la frontera rota/traslada hasta estabilizarse.\n- Añadir **términos polinomiales** o **bases** para fronteras no lineales; GD sigue aplicando.\n\n---\n\n# 4. Buenas prácticas y discusión aplicada\n\n## Hiperparámetros y trucos prácticos\n\n- **Tasa de aprendizaje ($\\alpha$)**: búsqueda en rejilla o **programación de tasa** (decay).\n- **Inicialización**: pequeña aleatoria (cero puede estancar con ciertas variantes).\n- **Barajado** por época y **mini-batches** estratificados si la clase es rara.\n- **Regularización** (L2/L1) para estabilidad e interpretabilidad:\n  $$\n  J_{\\lambda} = J + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|_2^2 \\quad \\text{(Ridge)}\n  $$\n- **Detección de fuga de datos** y validación por **sujeto** en estudios clínicos.\n\n---\n\n## Checklist de la sesión (rápido)\n\n- [ ] Estandarizaste variables de entrada.\n- [ ] Definiste costo adecuado (MSE vs. CE).\n- [ ] Elegiste mini-batch y $\\alpha$ razonables.\n- [ ] Verificaste convergencia con curva de $J$.\n- [ ] Evaluaste con métricas adecuadas al objetivo clínico.\n- [ ] Documentaste supuestos y limitaciones.\n\n---\n\n## Objetivos de aprendizaje\n\n- **Comprender** los fundamentos de la **Regresión Lineal**, **Regresión Logística** y **Perceptrón Multicapa (MLP)**.\n- **Aplicar** estos modelos al contexto de **salud fetal** con datos de **cardiotocografía (CTG)**.\n- **Evaluar** el desempeño con métricas adecuadas (MSE, AUC/Log-Loss, matriz de confusión, F1).\n\n::: {.columns}\n::: {.column width=\"45%\"}\n\n1. Regresión Lineal\n2. Regresión Logística\n3. Perceptrón Multicapa\n4. Cierre y discusión\n\n:::\n::: {.column width=\"45%\"}\n**Dataset**: `fetal_health.csv` (UCI CTG).\n**Contexto clínico**: interpretación de CTG (*normal*, *sospechoso*, *patológico*).\n:::\n:::\n\n---\n\n## Contexto clínico (CTG)\n\n::: {.callout-important title=\"Defición\"}\n Prueba médica que monitoriza simultáneamente la frecuencia cardíaca del feto y la actividad contráctil del útero. Se realiza generalmente durante el tercer trimestre del embarazo y el parto, colocando dos transductores externos (uno para la frecuencia cardíaca fetal y otro para las contracciones) sobre el abdomen de la madre\n:::\n\n![Generada con Gemini](../../recursos/imagenes/Presentaciones/ASIM/cardiotocografia.png)\n\n## Contexto clínico (CTG)\n\n|Característica (Variable en CSV)                      |Cálculo o Descripción                                                                                                                                                                                                                                                                                       |\n|------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n|Parámetros Basales                                    |                                                                                                                                                                                                                                                                                                            |\n|baseline value                                        |Es la frecuencia cardíaca fetal (FCF) media aproximada en un segmento de 10 minutos, excluyendo aceleraciones, deceleraciones y períodos de variabilidad marcada (>25 lpm). Se redondea a incrementos de 5 latidos por minuto (lpm).[4, 5, 6, 7, 8] El rango normal se considera entre 110 y 160 lpm.[9, 10]|\n|fetal_movement                                        |Número de movimientos fetales detectados por segundo.[1, 11, 12]                                                                                                                                                                                                                                            |\n|uterine_contractions                                  |Número de contracciones uterinas por segundo. Se considera normal tener 5 o menos contracciones en 10 minutos.[1, 4, 11, 12]                                                                                                                                                                                |\n|Eventos Transitorios (Aceleraciones y Deceleraciones) |                                                                                                                                                                                                                                                                                                            |\n|accelerations                                         |Número de aceleraciones por segundo. Una aceleración es un aumento abrupto de la FCF por encima de la línea de base de al menos 15 lpm, que dura 15 segundos o más, pero menos de 2 minutos.[5, 9, 10]                                                                                                      |\n|light_decelerations                                   |Número de deceleraciones leves por segundo. Una deceleración es una caída de la FCF de más de 15 lpm que dura más de 15 segundos.[5] La categoría \"leve\" se refiere a su duración, típicamente menor a 120 segundos.[3]                                                                                     |\n|severe_decelerations                                  |Número de deceleraciones severas por segundo. Se refiere a deceleraciones de larga duración, a menudo definidas como aquellas que superan los 300 segundos.[3]                                                                                                                                              |\n|prolongued_decelerations                              |Número de deceleraciones prolongadas por segundo. Son caídas de la FCF que duran más de 2 o 3 minutos pero menos de 10 minutos.[3, 6, 13]                                                                                                                                                                   |\n|Variabilidad de la FCF                                |                                                                                                                                                                                                                                                                                                            |\n|abnormal_short_term_variability                       |Porcentaje de tiempo en que la variabilidad a corto plazo (latido a latido) es anormal. La variabilidad se considera anormal si es mínima (≤5 lpm) o marcada (>25 lpm).[6, 8]                                                                                                                               |\n|mean_value_of_short_term_variability                  |Valor medio de la variabilidad a corto plazo (STV), que describe las fluctuaciones de la FCF latido a latido.[3, 6]                                                                                                                                                                                         |\n|percentage_of_time_with_abnormal_long_term_variability|Porcentaje de tiempo en que la variabilidad a largo plazo es anormal. Se calcula sobre las fluctuaciones de la FCF en un período de un minuto.[5]                                                                                                                                                           |\n|mean_value_of_long_term_variability                   |Valor medio de la variabilidad a largo plazo (LTV), que mide la amplitud (diferencia entre el pico y el valle) de las fluctuaciones de la FCF en un minuto.[3, 5]                                                                                                                                           |\n|Características del Histograma de FCF                 |Estas son propiedades estadísticas calculadas a partir de la distribución de todos los valores de FCF registrados durante el período de monitorización.[1, 11, 12]                                                                                                                                          |\n|histogram_width                                       |El ancho del histograma, calculado como la diferencia entre el valor máximo (histogram_max) y el mínimo (histogram_min) de la FCF.                                                                                                                                                                          |\n|histogram_min                                         |El valor mínimo de la FCF registrado en el histograma.                                                                                                                                                                                                                                                      |\n|histogram_max                                         |El valor máximo de la FCF registrado en el histograma.                                                                                                                                                                                                                                                      |\n|histogram_number_of_peaks                             |El número de picos en la distribución del histograma.                                                                                                                                                                                                                                                       |\n|histogram_number_of_zeroes                            |El número de \"ceros\" o bins con frecuencia cero en el histograma.                                                                                                                                                                                                                                           |\n|histogram_mode                                        |El valor de FCF que aparece con mayor frecuencia (la moda estadística).                                                                                                                                                                                                                                     |\n|histogram_mean                                        |El valor medio de la FCF en el histograma (la media estadística).                                                                                                                                                                                                                                           |\n|histogram_median                                      |El valor central de la FCF en el histograma (la mediana estadística).                                                                                                                                                                                                                                       |\n|histogram_variance                                    |La varianza de los valores de FCF, que mide su dispersión alrededor de la media.                                                                                                                                                                                                                            |\n|histogram_tendency                                    |Indica la simetría o sesgo del histograma. Puede interpretarse como: 1 para tendencia a la derecha (positiva), -1 para tendencia a la izquierda (negativa) y 0 para una distribución simétrica.                                                                                                             |\n\n\n## Contexto clínico (CTG)\n\n- CTG registra **FCF** y **contracciones uterinas**.\n- Clasificación clínica (FIGO): **normal / sospechoso / patológico**.\n- Variabilidad, aceleraciones y desaceleraciones son claves.\n\n\n\n---\n\n## Regresión Lineal\n\n### Idea clave\nAproxima una relación **lineal** $\\hat{y} = \\beta_0 + \\sum_j \\beta_j x_j$minimizando **MSE**.\n\n### Ejemplo didáctico (CTG)\nUsamos una **variable continua** de CTG como respuesta (p. ej., *histogram_width*) para ilustrar ajuste y residuales.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](v2Lect002_AlgoritmoDescensoGradiente_files/figure-revealjs/unnamed-chunk-4-5.png){width=960}\n:::\n:::\n\n\n**Discusión:** supuestos (linealidad, homocedasticidad, independencia), diagnóstico con residuales.\n\n---\n\n## Regresión Logística\n\n### Idea clave\nModela $P(Y=1 \\mid \\mathbf{x}) = \\sigma(\\beta_0 + \\mathbf{x}^\\top \\beta)$ con **sigmoide** $\\sigma(z)=1/(1+e^{-z})$.\n\n## 1. Definición de Regresión Logística\n\nLa **Regresión Logística** es un algoritmo de aprendizaje automático supervisado utilizado fundamentalmente para problemas de **clasificación binaria**.\n\nA pesar de su nombre, su objetivo no es predecir un valor continuo, sino modelar la **probabilidad** ($P$) de que una observación pertenezca a una clase específica (usualmente denotada como $Y=1$).\n\nEl modelo toma variables de entrada (features) $x_1, \\dots, x_n$ y estima $P(Y=1 | \\mathbf{x})$.\n\n---\n\n## 2. El Mecanismo Central del Modelo\n\nEl modelo logístico opera en dos pasos cruciales:\n\n### 2.1. El Componente Lineal (Logit)\n\nPrimero, el modelo calcula una suma ponderada de las entradas, exactamente igual que en una regresión lineal. A este resultado ($z$) se le conoce como **logit** o, más formalmente, **log-odds**.\n\n$$\nz = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n$$\n\n* $\\beta_0$ es el intercepto (sesgo).\n* $\\beta_{1 \\dots n}$ son los coeficientes (pesos) que el modelo aprende.\n* El rango de salida de $z$ es el de todos los números reales: $(-\\infty, +\\infty)$.\n\n### 2.2. La Función Sigmoide (Logística)\n\nDado que una probabilidad debe estar en el rango $[0, 1]$, $z$ no puede ser el resultado final. La regresión logística aplica la **función sigmoide** ($\\sigma$) a $z$ para \"aplastar\" (squash) la salida lineal al rango de probabilidad.\n\n$$\nP = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n$$\n\n* Si $z \\to +\\infty$, $e^{-z} \\to 0$, y $P \\to 1$.\n* Si $z \\to -\\infty$, $e^{-z} \\to +\\infty$, y $P \\to 0$.\n* Si $z = 0$, $e^{-0} = 1$, y $P = 0.5$.\n\n---\n\n## 3. La Relación Clave: Probabilidad y Log-Odds\n\nEl concepto central que conecta el modelo lineal con la probabilidad es el **log-odds**. Esta transformación es necesaria para mapear un espacio acotado $[0, 1]$ a un espacio no acotado $[-\\infty, +\\infty]$.\n\n### 3.1. De Probabilidad a Log-Odds\n\nLa transformación se realiza en dos pasos:\n\n1.  **Probabilidad ($P$)**: La probabilidad del evento.\n    * Rango: $[0, 1]$\n\n2.  **Odds (Momios)**: La razón entre la probabilidad de que ocurra ($P$) y la de que no ocurra ($1-P$).\n    $$\n    Odds = \\frac{P}{1-P}\n    $$\n    * Rango: $[0, +\\infty]$\n\n3.  **Log-Odds (Logit)**: El logaritmo natural de los *odds*.\n    $$\n    Logit(P) = \\ln(Odds) = \\ln\\left(\\frac{P}{1-P}\\right)\n    $$\n    * Rango: $[-\\infty, +\\infty]$\n\nEl modelo de regresión logística es, por tanto, un modelo lineal que predice el *log-odds*:\n\n$$\nz = \\ln\\left(\\frac{P}{1-P}\\right) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n\n$$\n\n### 3.2. De Log-Odds a Probabilidad (La Inversa)\n\nPara obtener la probabilidad $P$ a partir del log-odds $z$, simplemente revertimos la transformación `Logit`. Este proceso de despejar $P$ de la ecuación del logit **da origen a la función sigmoide**:\n\n1.  Ecuación base:\n    $$\n    z = \\ln\\left(\\frac{P}{1-P}\\right)\n    $$\n\n2.  Aplicar exponencial (inversa del logaritmo):\n    $$\n    e^z = \\frac{P}{1-P}\n    $$\n\n3.  Despejar $P$:\n    $$\n    e^z (1-P) = P\n    $$\n    $$\n    e^z - e^z P = P\n    $$\n    $$\n    e^z = P + e^z P\n    $$\n    $$\n    e^z = P (1 + e^z)\n    $$\n\n4.  Probabilidad $P$ en función de $z$:\n    $$\n    P = \\frac{e^z}{1 + e^z}\n    $$\n\n5.  *Forma sigmoide alternativa (dividiendo numerador y denominador por $e^z$)*:\n    $$\n    P = \\frac{e^z/e^z}{(1 + e^z)/e^z} = \\frac{1}{e^{-z} + 1} = \\frac{1}{1 + e^{-z}}\n    $$\n\n---\n\n## 4. Interpretación de Coeficientes\n\nDebido a esta relación, los coeficientes ($\\beta_i$) del modelo tienen una interpretación específica:\n\n* **Coeficiente $\\beta_i$**: Un incremento de una unidad en la variable $x_i$ (manteniendo las demás constantes) genera un cambio de $\\beta_i$ en el **log-odds** de la predicción.\n* **Odds Ratio (OR)**: Para una interpretación más intuitiva, se utiliza $e^{\\beta_i}$. Un incremento de una unidad en $x_i$ **multiplica** los *odds* por un factor de $e^{\\beta_i}$.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](v2Lect002_AlgoritmoDescensoGradiente_files/figure-revealjs/unnamed-chunk-5-7.png){width=960}\n:::\n:::\n\n\n### Clasificación binaria (Normal vs No‑Normal)\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n              precision    recall  f1-score   support\n\n           0      0.778     0.745     0.761        94\n           1      0.929     0.940     0.934       332\n\n    accuracy                          0.897       426\n   macro avg      0.853     0.842     0.848       426\nweighted avg      0.895     0.897     0.896       426\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](v2Lect002_AlgoritmoDescensoGradiente_files/figure-revealjs/unnamed-chunk-6-9.png){width=960}\n:::\n:::\n\n\n---\n",
    "supporting": [
      "v2Lect002_AlgoritmoDescensoGradiente_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}