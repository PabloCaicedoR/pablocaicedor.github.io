{
  "hash": "aa95792fd1b9520ded474640cacfe987",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Redes Neuronales Convolucionales & Redes Recurrentes \"\nsubtitle: \"Regresión lineal múltiple, regresión logística y Redes Neuronales\"\nauthor: \"PhD. Pablo Eduardo Caicedo Rodríguez\"\ndate: last-modified\nlang: es\nformat:\n  revealjs:\n    code-tools: true\n    code-overflow: wrap\n    code-line-numbers: true\n    code-copy: true\n    fig-align: center\n    self-contained: true\n    theme:\n      - simple\n      - ../../recursos/estilos/metropolis.scss\n    slide-number: true\n    preview-links: auto\n    logo: ../../recursos/imagenes/generales/Escuela_Rosario_logo.png\n    css: ../../recursos/estilos/styles_pres.scss\n    footer: <https://pablocaicedor.github.io/>\n    transition: fade\n    progress: true\n    scrollable: true\n    hash: true\n\nexecute:\n  echo: false\n  warning: false\n  freeze: auto\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n## Introduction\n\n::: {.callout-important title=\"Motivation\"}\n\nStandard Feedforward Networks (MLPs) fail to scale for high-dimensional data like images due to:\n\n1.  **Full Connectivity**: Exploding parameter count.\n2.  **Spatial Invariance**: Ignorance of local spatial topology.\n\n:::\n\n**Convolutional Neural Networks (CNNs)** introduce:\n\n* **Local Connectivity**: Neurons connect only to a local receptive field.\n* **Parameter Sharing**: Same weights (filters) applied across the input.\n* **Equivariance**: Translation of input results in translation of output.\n\n\n## The Convolution Operation\n\n:::{.columns}\n\n:::{.column width=\"45%\"}\n\nIn the context of CNNs, the operation is technically a **cross-correlation**, but conventionally termed convolution.\n\nGiven an input image $I$ and a kernel (filter) $K$, the feature map $S$ is defined as:\n\n\n\n:::\n\n:::{.column width=\"45%\"}\n\n![](../../recursos/imagenes/GIFs/heatmap_moving_mask.gif)\n\n:::\n\n:::\n\n$$S(i, j) = (I * K)(i, j) = \\sum_{m} \\sum_{n} I(i+m, j+n) K(m, n)$$\n\nWhere:\n* $(i, j)$ are the pixel coordinates.\n* $(m, n)$ are the kernel offsets.\n\n\n\n## Hyperparameters\n\nThe spatial dimensions of the output feature map depend on:\n\n1.  **Filter Size ($F$)**: Receptive field dimensions (e.g., $3 \\times 3$).\n2.  **Stride ($S$)**: Step size of the filter convolution.\n3.  **Padding ($P$)**: Zero-padding around the border to preserve dimensions.\n\n**Output Dimension Formula:**\nGiven input size $W_{in} \\times H_{in}$:\n\n$$W_{out} = \\frac{W_{in} - F + 2P}{S} + 1$$\n\n\n\n## Pooling Layers\n\nPooling provides **invariance to small translations** and reduces dimensionality (downsampling).\n\n### Max Pooling\nSelects the maximum activation in the receptive field:\n$$y_{i,j,k} = \\max_{(p,q) \\in \\mathcal{R}_{i,j}} x_{p,q,k}$$\n\n### Average Pooling\nCalculates the arithmetic mean. Generally, Max Pooling performs better for identifying dominant features (edges, textures).\n\n\n\n## Activation Functions\n\nLinear convolution is insufficient for approximating non-linear functions.\n\n**ReLU (Rectified Linear Unit):**\n$$f(x) = \\max(0, x)$$\n\n* **Sparsity**: Activations $< 0$ are zeroed out.\n* **Gradient Propagation**: Mitigates vanishing gradient problem compared to Sigmoid/Tanh.\n\nVariants: *Leaky ReLU*, *ELU*, *GELU* (Gaussian Error Linear Unit).\n\n\n\n## Architecture Overview\n\nA typical CNN architecture follows a hierarchical pattern:\n\n1.  **Feature Extraction Block**:\n    * [Conv $\\rightarrow$ ReLU $\\rightarrow$ Pooling] $\\times N$\n2.  **Classification Head**:\n    * Flattening\n    * Fully Connected Layers (Dense)\n    * Softmax (for multi-class classification)\n\n$$P(y=j | \\mathbf{x}) = \\frac{e^{\\mathbf{w}_j^T \\mathbf{h} + b_j}}{\\sum_{k=1}^K e^{\\mathbf{w}_k^T \\mathbf{h} + b_k}}$$\n\n\n## Backpropagation in CNNs\n\nTraining requires computing gradients w.r.t weights $W$ using the Chain Rule.\n\nFor a convolution layer $l$:\n$$\\frac{\\partial L}{\\partial W^{(l)}} = \\frac{\\partial L}{\\partial \\text{out}^{(l)}} * \\text{in}^{(l)}$$\n\nWhere the gradient is computed via convolution between the incoming error signal and the input activations from the previous layer.\n\n\n\n## Implementation: PyTorch Snippet\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport torch\nimport torch.nn as nn\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        # Feature Extraction\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)\n        )\n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 7 * 7, 128), # Assuming 28x28 input\n            nn.ReLU(),\n            nn.Linear(128, 10)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n```\n:::\n\n# Recurrent Neuronal Network\n\n\n## ¿Por qué RNNs?\n\nLas redes neuronales tradicionales (MLP, CNN) asumen que **las entradas y salidas son independientes**.\n\n::: {.fragment}\n**El problema:**\n¿Cómo procesamos datos donde el *orden* importa?\n:::\n\n::: {.incremental}\n*   Traducción de idiomas (La gramática depende del contexto previo).\n*   Audio y Voz (La onda sonora es continua).\n*   Series de Tiempo (El valor de hoy depende de ayer).\n*   Genómica (Secuencias de ADN).\n:::\n\n## La Celda Recurrente (RNN Cell)\n\nLa diferencia fundamental es la **memoria**. La RNN procesa la entrada actual ($x_t$) considerando el estado anterior ($a_{t-1}$).\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](v2Lect004_CNN_LSTM_files/figure-revealjs/fig-rnn-single-cell-1.svg){#fig-rnn-single-cell fig-align='center' width=960}\n:::\n:::\n\n\n## Formulación Matemática\n\nAnalicemos las ecuaciones clave utilizando el código de color:\n\n$$\n\\textcolor{#D35400}{a_t} = g_1(\\textcolor{#C0392B}{W_{aa}}\\textcolor{#D35400}{a_{t-1}} + \\textcolor{#C0392B}{W_{ax}}\\textcolor{#00796B}{x_t} + \\textcolor{#C0392B}{b_a})\n$$\n\n$$\n\\textcolor{#00796B}{\\hat{y}_t} = g_2(\\textcolor{#C0392B}{W_{ya}}\\textcolor{#D35400}{a_t} + \\textcolor{#C0392B}{b_y})\n$$\n\n::: {.callout-note}\n*   $\\textcolor{#D35400}{a_t}$: **Estado oculto** (Hidden State). Es la \"memoria\" del paso $t$.\n*   $\\textcolor{#C0392B}{W_{ax}, W_{aa}, W_{ya}}$: **Pesos compartidos**. Son los mismos para *cada* paso de tiempo.\n*   $g_1$: Usualmente **tanh** o ReLU.\n*   $g_2$: Usualmente **Softmax** (clasificación) o Lineal (regresión).\n:::\n\n## Desenrollando en el Tiempo (Unrolling)\n\nUna RNN es simplemente la misma celda ejecutada múltiples veces. $a_t$ pasa información de un paso al siguiente.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](v2Lect004_CNN_LSTM_files/figure-revealjs/fig-rnn-unrolled-fixed-1.svg){#fig-rnn-unrolled-fixed fig-align='center' width=1344}\n:::\n:::\n\n\n## Arquitecturas Flexibles\n\nLas RNN permiten procesar secuencias de longitudes variables en diferentes configuraciones.\n\n::: {layout-ncol=2}\n**Tipos:**\n\n1.  **Many-to-Many ($T_x = T_y$):** Clasificación de entidades nombradas (NER), Generación de texto.\n2.  **Many-to-One:** Análisis de sentimiento, Clasificación de actividad.\n3.  **One-to-Many:** Generación de música, Captioning de imágenes (Input = Imagen CNN).\n4.  **Many-to-Many ($T_x \\neq T_y$):** Traducción automática (Encoder-Decoder).\n:::\n\n## Retropropagación en el Tiempo (BPTT)\n\nPara entrenar, calculamos el gradiente de la pérdida $L$ respecto a los parámetros $W$.\n\n$$ \\frac{\\partial L}{\\partial W} = \\sum_{t} \\frac{\\partial L_t}{\\partial W} $$\n\n::: {.callout-warning title=\"El Reto del Gradiente\"}\nAl multiplicar gradientes muchas veces (por la regla de la cadena a través del tiempo), estos pueden:\n\n1.  **Desvanecerse (Vanishing):** La red olvida el pasado lejano. (Solución: **LSTM/GRU**).\n2.  **Explotar (Exploding):** El entrenamiento diverge. (Solución: **Gradient Clipping**).\n:::\n\n## Resumen Visual\n\n<br>\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](v2Lect004_CNN_LSTM_files/figure-revealjs/fig-rnn-summary-final-1.svg){#fig-rnn-summary-final fig-align='center' width=1152}\n:::\n:::\n\n\n**Conclusión:** Las RNNs unifican el aprendizaje sobre datos secuenciales aprendiendo parámetros ($W$) que se comparten a través del tiempo.\n\n\n\n## Basic Concepts\n\n<br/>\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](v2Lect004_CNN_LSTM_files/figure-revealjs/fig-rnn-diplosaurio-fixed-1.svg){#fig-rnn-diplosaurio-fixed fig-align='center' width=960}\n:::\n:::\n\n\n## Basic Concepts\n\n::: {.callout-note title=\"General Schema\"}\n\nLet's make a general structure of the problem\n\n:::\n\n<br/>\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](v2Lect004_CNN_LSTM_files/figure-revealjs/fig-rnn-sequence-fixed-1.svg){#fig-rnn-sequence-fixed fig-align='center' width=1344}\n:::\n:::\n\n\n## Basic Concepts\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](v2Lect004_CNN_LSTM_files/figure-revealjs/fig-rnn-cell-v3-1.svg){#fig-rnn-cell-v3 fig-align='center' width=960}\n:::\n:::\n\n\n\n",
    "supporting": [
      "v2Lect004_CNN_LSTM_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}