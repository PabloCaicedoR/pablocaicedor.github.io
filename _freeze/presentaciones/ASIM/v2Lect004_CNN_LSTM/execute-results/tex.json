{
  "hash": "3ead506f9de54d437627bc4fe2ab7a18",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Redes Neuronales Convolucionales & Redes Recurrentes \"\nsubtitle: \"Regresión lineal múltiple, regresión logística y Redes Neuronales\"\nauthor: \"PhD. Pablo Eduardo Caicedo Rodríguez\"\ndate: last-modified\nlang: es\nformat:\n  revealjs:\n    code-tools: true\n    code-overflow: wrap\n    code-line-numbers: true\n    code-copy: true\n    fig-align: center\n    self-contained: true\n    theme:\n      - simple\n      - ../../recursos/estilos/metropolis.scss\n    slide-number: true\n    preview-links: auto\n    logo: ../../recursos/imagenes/generales/Escuela_Rosario_logo.png\n    css: ../../recursos/estilos/styles_pres.scss\n    footer: <https://pablocaicedor.github.io/>\n    transition: fade\n    progress: true\n    scrollable: true\n    hash: true\n  beamer:\n    slide-level: 2\n    incremental: false\n    aspectratio: 32\n    navigation: horizontal\n    theme: CambridgeUS\n    header-includes:\n      \\makeatletter\n      \\expandafter\\let\\csname figure*\\endcsname\\figure\n      \\expandafter\\let\\csname endfigure*\\endcsname\\endfigure\n      \\expandafter\\let\\csname table*\\endcsname\\table\n      \\expandafter\\let\\csname endtable*\\endcsname\\endtable\nexecute:\n  echo: false\n  warning: false\n  freeze: auto\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n## Introduction\n\n::: {.callout-important title=\"Motivation\"}\n\nStandard Feedforward Networks (MLPs) fail to scale for high-dimensional data like images due to:\n\n1.  **Full Connectivity**: Exploding parameter count.\n2.  **Spatial Invariance**: Ignorance of local spatial topology.\n\n:::\n\n**Convolutional Neural Networks (CNNs)** introduce:\n\n* **Local Connectivity**: Neurons connect only to a local receptive field.\n* **Parameter Sharing**: Same weights (filters) applied across the input.\n* **Equivariance**: Translation of input results in translation of output.\n\n\n## The Convolution Operation\n\n:::{.columns}\n\n:::{.column width=\"45%\"}\n\nIn the context of CNNs, the operation is technically a **cross-correlation**, but conventionally termed convolution.\n\nGiven an input image $I$ and a kernel (filter) $K$, the feature map $S$ is defined as:\n\n\n\n:::\n\n:::{.column width=\"45%\"}\n\n![](../../recursos/imagenes/GIFs/heatmap_moving_mask.gif)\n\n:::\n\n:::\n\n$$S(i, j) = (I * K)(i, j) = \\sum_{m} \\sum_{n} I(i+m, j+n) K(m, n)$$\n\nWhere:\n* $(i, j)$ are the pixel coordinates.\n* $(m, n)$ are the kernel offsets.\n\n\n\n## Hyperparameters\n\nThe spatial dimensions of the output feature map depend on:\n\n1.  **Filter Size ($F$)**: Receptive field dimensions (e.g., $3 \\times 3$).\n2.  **Stride ($S$)**: Step size of the filter convolution.\n3.  **Padding ($P$)**: Zero-padding around the border to preserve dimensions.\n\n**Output Dimension Formula:**\nGiven input size $W_{in} \\times H_{in}$:\n\n$$W_{out} = \\frac{W_{in} - F + 2P}{S} + 1$$\n\n\n\n## Pooling Layers\n\nPooling provides **invariance to small translations** and reduces dimensionality (downsampling).\n\n### Max Pooling\nSelects the maximum activation in the receptive field:\n$$y_{i,j,k} = \\max_{(p,q) \\in \\mathcal{R}_{i,j}} x_{p,q,k}$$\n\n### Average Pooling\nCalculates the arithmetic mean. Generally, Max Pooling performs better for identifying dominant features (edges, textures).\n\n\n\n## Activation Functions\n\nLinear convolution is insufficient for approximating non-linear functions.\n\n**ReLU (Rectified Linear Unit):**\n$$f(x) = \\max(0, x)$$\n\n* **Sparsity**: Activations $< 0$ are zeroed out.\n* **Gradient Propagation**: Mitigates vanishing gradient problem compared to Sigmoid/Tanh.\n\nVariants: *Leaky ReLU*, *ELU*, *GELU* (Gaussian Error Linear Unit).\n\n\n\n## Architecture Overview\n\nA typical CNN architecture follows a hierarchical pattern:\n\n1.  **Feature Extraction Block**:\n    * [Conv $\\rightarrow$ ReLU $\\rightarrow$ Pooling] $\\times N$\n2.  **Classification Head**:\n    * Flattening\n    * Fully Connected Layers (Dense)\n    * Softmax (for multi-class classification)\n\n$$P(y=j | \\mathbf{x}) = \\frac{e^{\\mathbf{w}_j^T \\mathbf{h} + b_j}}{\\sum_{k=1}^K e^{\\mathbf{w}_k^T \\mathbf{h} + b_k}}$$\n\n\n## Backpropagation in CNNs\n\nTraining requires computing gradients w.r.t weights $W$ using the Chain Rule.\n\nFor a convolution layer $l$:\n$$\\frac{\\partial L}{\\partial W^{(l)}} = \\frac{\\partial L}{\\partial \\text{out}^{(l)}} * \\text{in}^{(l)}$$\n\nWhere the gradient is computed via convolution between the incoming error signal and the input activations from the previous layer.\n\n\n\n## Implementation: PyTorch Snippet\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport torch\nimport torch.nn as nn\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        # Feature Extraction\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)\n        )\n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 7 * 7, 128), # Assuming 28x28 input\n            nn.ReLU(),\n            nn.Linear(128, 10)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n```\n:::\n\n# Recurrent Neuronal Network\n",
    "supporting": [
      "v2Lect004_CNN_LSTM_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{longtable}\n\\usepackage{array}\n\\usepackage{multirow}\n\\usepackage{wrapfig}\n\\usepackage{float}\n\\usepackage{colortbl}\n\\usepackage{pdflscape}\n\\usepackage{tabu}\n\\usepackage{threeparttable}\n\\usepackage{threeparttablex}\n\\usepackage[normalem]{ulem}\n\\usepackage{makecell}\n\\usepackage{xcolor}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}