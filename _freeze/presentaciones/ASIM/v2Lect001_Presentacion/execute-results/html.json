{
  "hash": "2ff8a536eb01659c17dd563a4d11fe05",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"ML para Señales e Imágenes Médicas\"\nsubtitle: \"Flujo completo, buenas prácticas y demos con datos sintéticos\"\nlang: es\nformat:\n  revealjs:\n    code-tools: true\n    code-overflow: wrap\n    code-line-numbers: true\n    code-copy: true\n    fig-align: center\n    self-contained: true\n    theme:\n      - simple\n      - ../../recursos/estilos/metropolis.scss\n    slide-number: true\n    preview-links: auto\n    logo: ../../recursos/imagenes/generales/Escuela_Rosario_logo.png\n    css: ../../recursos/estilos/styles_pres.scss\n    footer: <https://pablocaicedor.github.io/>\n    transition: fade\n    progress: true\n    scrollable: true\n    hash: true\nexecute:\n  echo: true\n  warning: false\n  freeze: auto\n---\n\n## Propósito y alcance (visión general)\n- Flujo de trabajo: datos→representación→modelo→validación→reporte.\n- Ética: consentimiento, PHI, licencias, sesgo y desbalance.\n- Preparación: filtrado, normalización, segmentación, *leakage*.\n- Representaciones: STFT/EEG/EMG, texturas; *deep* (CNN/UNet).\n- Validación: **CV estratificada**, *early stopping*, semillas.\n- Métricas: ROC-AUC, F1; Dice/IoU; MAE/RMSE.\n- Interpretabilidad/robustez y reporte reproducible.\n\n## Ética y cumplimiento (1/2)\n- Consentimiento informado y minimización de datos.\n- PHI: remover identificadores; anonimización/pseudonimización.\n- Licencias: usar CC; atribuir autor, año, URL y licencia.\n- NC/ND: no usos comerciales / no obras derivadas (respetar).\n- Ejemplo: ECG sintético para QRS (docencia) sin PHI.\n\n## Ética y riesgo de sesgo (2/2)\n:::: {.columns style=\"gap: 1.2rem;\"}\n::: {.column width=\"45%\"}\n- Desbalance por clase/población.\n- *Sampling* estratificado y *cost-sensitive*.\n- Auditoría de *drift* y *fairness*.\n:::\n::: {.column width=\"45%\"}\n- Ejemplo clínico: TC nódulos pulmonares.\n  Dataset real: LUNA16 (verificar licencia).\n  Docencia: nódulos sintéticos controlados (sin PHI).\n:::\n::::\n\n## Preparación de datos (1/2)\n- Filtrado: ECG/EMG (pasa-banda), EEG (notch 50/60 Hz).\n- Normalización/estandarización según modelo.\n- Segmentación: latidos, *epochs* EEG, ROIs.\n- **Evitar *data leakage***: normalizar con estadísticas del **train**.\n- Particiones: train/valid/test estratificadas.\n\n## Preparación de datos (2/2)\n:::: {.columns style=\"gap: 1.2rem;\"}\n::: {.column width=\"45%\"}\n- *Leakage* comunes:\n  - Normalizar con todo el dataset.\n  - Selección de *features* global.\n  - *Tuning* sobre test.\n:::\n::: {.column width=\"45%\"}\n- Ejemplo: EMG picos.\n  Ventanas 200 ms; normalizar por canal\n  con media/DE de *train* únicamente.\n:::\n::::\n\n## Representaciones en señales (1/2)\n- STFT/espectrograma (tiempo-frecuencia).\n- EEG bandas: δ, θ, α, β, γ (potencia relativa).\n- EMG: RMS, ARV; envolvente (rectificación+suavizado).\n- ECG: energía por ventana, R-R, derivadas simples.\n- Ejemplo: QRS — energía en 5–15 Hz (sintético).\n\n## Demo: espectrograma de señal estilo EEG\n\n::: {#cell-fig-spectrogram .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np, matplotlib.pyplot as plt\nnp.random.seed(42)\nfs=128; t=np.arange(0,10,1/fs)\nsig=np.sin(2*np.pi*10*t)*(t<5)+np.sin(2*np.pi*6*t)*(t>=5)+0.4*np.random.randn(len(t))\nNw=256; H=64; w=np.hanning(Nw)\nframes=[sig[i:i+Nw]*w for i in range(0,len(sig)-Nw,H)]\nS=np.array([np.abs(np.fft.rfft(f)) for f in frames]).T\nf=np.fft.rfftfreq(Nw,1/fs); tt=np.arange(S.shape[1])*H/fs\nplt.figure(figsize=(7,3))\nplt.imshow(20*np.log10(S+1e-6), aspect='auto', origin='lower',\n           extent=[tt[0],tt[-1],f[0],f[-1]])\nplt.xlabel(\"Tiempo [s]\"); plt.ylabel(\"Frecuencia [Hz]\")\nplt.title(\"Espectrograma sintético EEG (10→6 Hz)\"); plt.colorbar(label=\"dB\")\nplt.tight_layout(); plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Espectrograma (STFT) de señal sintética estilo EEG.](v2Lect001_Presentacion_files/figure-revealjs/fig-spectrogram-output-1.png){#fig-spectrogram}\n:::\n:::\n\n\n## Representaciones en imágenes (2/2)\n:::: {.columns style=\"gap: 1.2rem;\"}\n::: {.column width=\"45%\"}\n- Intensidad/gradientes, texturas (Haralick/GLCM).\n- Histogramas locales; evitar paletas *rainbow*.\n- *Deep*: CNN (clasif.), UNet (segmentación).\n:::\n::: {.column width=\"45%\"}\n- Ejemplo: RM rodilla — cartílago.\n  Máscaras sintéticas para medir Dice/IoU.\n:::\n::::\n\n## Modelos (visión general)\n- Clásicos: regresión, SVM, árboles/ensembles.\n- Profundos: CNN, UNet; RNN/transformers (secuencias).\n- Selección por objetivo/datos/recursos.\n- Regularización: L2, *dropout*, *early stopping*.\n- Semillas fijas para reproducibilidad.\n- Ejemplo: QRS (regresión logística simple).\n\n## Entrenamiento y validación\n:::: {.columns style=\"gap: 1.2rem;\"}\n::: {.column width=\"45%\"}\n- **CV k-fold estratificada** por clase.\n- Conjunto de validación para *tuning*.\n- *Early stopping* con paciencia.\n:::\n::: {.column width=\"45%\"}\n- Semillas: `np.random.seed(42)`.\n- Registrar versiones HW/SW.\n- Ejemplo: EEG sueño — CV por sujeto (si aplica).\n:::\n::::\n\n## Métricas por tarea\n- Clasificación: ROC-AUC, sensibilidad, especificidad, F1.\n- Segmentación: Dice, IoU (Jaccard).\n- Regresión: MAE, RMSE.\n- Reportar incertidumbre (IC/bootstrapping).\n- **Evitar** métricas sesgadas por desbalance (solo accuracy).\n\n## Demo: ROC/F1 vs umbral (clasificación binaria)\n\n::: {#cell-fig-roc .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np, matplotlib.pyplot as plt\nnp.random.seed(42)\nn=800; y=(np.random.rand(n)<0.35).astype(int)\nscores=0.6*y+0.3*np.random.rand(n)\nthr=np.linspace(0,1,101)\ntpr=[]; fpr=[]; f1=[]\nfor th in thr:\n    yhat=(scores>=th).astype(int)\n    tp=np.sum((yhat==1)&(y==1)); fp=np.sum((yhat==1)&(y==0))\n    fn=np.sum((yhat==0)&(y==1)); tn=np.sum((yhat==0)&(y==0))\n    tpr.append(tp/max(tp+fn,1)); fpr.append(fp/max(fp+tn,1))\n    prec=tp/max(tp+fp,1); rec=tpr[-1]; f1.append(2*prec*rec/max(prec+rec,1e-9))\nauc=np.trapz(sorted(tpr), x=sorted(fpr))\nplt.figure(figsize=(7,3))\nplt.subplot(1,2,1); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],'--')\nplt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC (AUC≈{auc:.2f})\")\nplt.subplot(1,2,2); plt.plot(thr,f1); plt.xlabel(\"Umbral\"); plt.ylabel(\"F1\")\nplt.title(\"F1 vs umbral\"); plt.tight_layout(); plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Curva ROC y F1 vs umbral con datos sintéticos.](v2Lect001_Presentacion_files/figure-revealjs/fig-roc-output-1.png){#fig-roc}\n:::\n:::\n\n\n## Demo: Dice/IoU en segmentación (máscara sintética)\n\n::: {#cell-fig-dice .cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np, matplotlib.pyplot as plt\nnp.random.seed(42)\nH,W=128,128\ngt=np.zeros((H,W),int); gt[40:90,30:80]=1\npred=gt.copy(); pred[45:95,35:85]=1; pred=np.roll(pred,2,axis=1)\ninter=(gt&pred).sum(); union=(gt|pred).sum()\ndice=2*inter/(gt.sum()+pred.sum()); iou=inter/union\nplt.figure(figsize=(7,3))\nplt.subplot(1,3,1); plt.imshow(gt,cmap='gray'); plt.axis('off'); plt.title(\"GT\")\nplt.subplot(1,3,2); plt.imshow(pred,cmap='gray'); plt.axis('off'); plt.title(\"Pred\")\nplt.subplot(1,3,3); plt.imshow(gt+2*pred,cmap='gray'); plt.axis('off')\nplt.title(f\"Dice={dice:.2f}, IoU={iou:.2f}\")\nplt.tight_layout(); plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Máscaras binarias y métricas Dice/IoU en cartílago sintético.](v2Lect001_Presentacion_files/figure-revealjs/fig-dice-output-1.png){#fig-dice}\n:::\n:::\n\n\n## Interpretabilidad y robustez\n- Saliency/Grad-CAM para CNN (visión global).\n- Perturbaciones: ruido, desenfoque, *contrast shift*.\n- Validación externa: otro hospital/población.\n- Ejemplo: Grad-CAM en UNet (referencia, sin PHI).\n- Advertencia: saliency no implica causalidad clínica.\n\n## Demo: sensibilidad a perturbaciones (imagen)\n\n::: {#cell-fig-perturb .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np, matplotlib.pyplot as plt\nnp.random.seed(42)\nimg=np.zeros((128,128)); img[40:88,50:78]=1.0\nnoise=img+0.25*np.random.randn(*img.shape)\nblur=np.copy(img)\nfor _ in range(6): blur=(blur+np.roll(blur,1,0)+np.roll(blur,-1,0)+np.roll(blur,1,1)+np.roll(blur,-1,1))/5\nplt.figure(figsize=(7,3))\nplt.subplot(1,3,1); plt.imshow(img,cmap='gray'); plt.axis('off'); plt.title(\"Original\")\nplt.subplot(1,3,2); plt.imshow(noise,cmap='gray'); plt.axis('off'); plt.title(\"Ruido\")\nplt.subplot(1,3,3); plt.imshow(blur,cmap='gray'); plt.axis('off'); plt.title(\"Desenfoque\")\nplt.tight_layout(); plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Impacto de ruido/desenfoque en una ROI sintética.](v2Lect001_Presentacion_files/figure-revealjs/fig-perturb-output-1.png){#fig-perturb}\n:::\n:::\n\n\n## Reporte reproducible\n- Fijar semillas (`np.random.seed(42)`).\n- Versiones: Python/NumPy/Matplotlib; HW (GPU/CPU).\n- Guardar *config*, preprocesamiento y splits.\n- Licencias de datos/modelos/código.\n- Documentar criterios de exclusión y fallos.\n\n## Referencias clave (selección)\n- U. Ronneberger *et al.*, MICCAI 2015, UNet, DOI: https://doi.org/10.1007/978-3-319-24574-4_28\n- K. He *et al.*, CVPR 2016, ResNet, DOI: https://doi.org/10.1109/CVPR.2016.90\n- R. R. Selvaraju *et al.*, ICCV 2017, Grad-CAM, DOI: https://doi.org/10.1109/ICCV.2017.74\n- J. A. Hanley, B. J. McNeil, Radiology 1982, ROC-AUC, DOI: https://doi.org/10.1148/radiology.143.1.7063747\n- A. A. Taha, A. Hanbury, ISBI 2015, métricas segm., DOI: https://doi.org/10.1109/ISBI.2015.7164114\n\n",
    "supporting": [
      "v2Lect001_Presentacion_files"
    ],
    "filters": [],
    "includes": {}
  }
}