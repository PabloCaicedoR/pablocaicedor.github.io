[
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Preparar una Presentación | 5 PASOS para una CONFERENCIA EXITOSA por Sebastián Lora.\n¿Cómo estructurar una presentación? por Espacio Ñ de la Universidad del Norte\n\n\n\n\n\nCómo Hacer una Buena Presentación de Diapositivas (Tips) por Javier Muñiz.\nConsejos para una buena presentación en POWER POINT por NiboKids en el cole!.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentación\nNo se siguen ninguno de los consejos de los videos adjuntos para la creación de la presentación\nSe siguen algunos de los consejos de los videos adjuntos para la creación  de la presentación\nSe siguen todos los consejos de los videos adjuntos para la creación  de la presentación\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificación de los ejemplos\nNo se describe el código utilizado para los ejemplos\nSe describe parcialmente el código de los ejemplos\nSe describe a cabalidad el código de los ejemplos\n\n\nCalidad del código\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl código utilizado es completamente desarrollado por los estudiantes a excepción del manejo de datos (NUMPY array y las funciones matemáticas elementales) y la graficación (MATPLOTLIB)"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generación-de-presentaciones",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generación-de-presentaciones",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Preparar una Presentación | 5 PASOS para una CONFERENCIA EXITOSA por Sebastián Lora.\n¿Cómo estructurar una presentación? por Espacio Ñ de la Universidad del Norte"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generación-de-dipostivas",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generación-de-dipostivas",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Hacer una Buena Presentación de Diapositivas (Tips) por Javier Muñiz.\nConsejos para una buena presentación en POWER POINT por NiboKids en el cole!."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#rúbrica-de-evaluación",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#rúbrica-de-evaluación",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Indicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentación\nNo se siguen ninguno de los consejos de los videos adjuntos para la creación de la presentación\nSe siguen algunos de los consejos de los videos adjuntos para la creación  de la presentación\nSe siguen todos los consejos de los videos adjuntos para la creación  de la presentación\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificación de los ejemplos\nNo se describe el código utilizado para los ejemplos\nSe describe parcialmente el código de los ejemplos\nSe describe a cabalidad el código de los ejemplos\n\n\nCalidad del código\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl código utilizado es completamente desarrollado por los estudiantes a excepción del manejo de datos (NUMPY array y las funciones matemáticas elementales) y la graficación (MATPLOTLIB)"
  },
  {
    "objectID": "rubricas/Rubrica_Regression.html",
    "href": "rubricas/Rubrica_Regression.html",
    "title": "Rúbrica: Modelos de regresión",
    "section": "",
    "text": "Equipo 1Equipo 2\n\n\nIntegrantes\n\nLaura Bazante\nNicolás Panesso\nNicoll Arcos\n\nDataset: concreto\n\n\nIntegrantes\n\nKatherin Diaz\nHeidy Fernández\nJuan Muñoz\n\nDataset: Rendimiento\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsuficiente0%\nAceptable50%\nSuperior100%\n\n\n\n\nObjetivo análisis exploratorio de datos\nNo hay un objetivo aparente\nExiste un objetivo de análisis exploratorio de datos planteado pero este no se encuentra alineado con el modelo\nEl objetivo del análisis exploratorio de datos planteado se alinea con la construcción del modelo se encuentra bien descrito\n\n\nContexto del Dataset\nNo es posible establecer el ámbito al cual pertenecen los datos utilizados para desarrollar el trabajo\nSe hace una descripción muy básica de las características del dataset\nSe hace una descripción detallada de las características y las variables que componen el dataset\n\n\nJustificación\nNo existe una justificación aparente\nExiste justificación pero esta se encuentra mal planteda\nLa justificación se encuentra bien planteada\n\n\nPreprocesamiento\nNo se realizó preprocesamiento de los datos.  O no se argumenta de manera clara la razón de los procedimientos realizados\nAl dataset se le aplicaron solo algunas operaciones de preprocesamiento y los datos no tienen la calidad requerida\nAl dataset se le aplicaron las operaciones de preprocesamiento necesarias para mejorar su calidad y poder construir los modelos de clasificación\n\n\nConexión entre el EDA y el modelo final\nMás de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nMenos de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nTodas las decisiones para el modelo inicial fueron tomadas a partir del EDA\n\n\nDuración de la presentación\nLa presentación dura menos de 8 minutos o más de 13 minutos\nLa presentación dura menos de 9 minutos o más de 11 minutos\nLa presentación dura 10 minutos\n\n\nMaterial de clase\nNo usa la plantilla RMARKDOWN\n\nUsa la plantilla  RMARKDOWN\n\n\nUso de gráficos\nNo se usa ESTADÍSTICA para explicar todas las decisiones\n\nSe usa ESTADÍSTICA para explicar todas las decisiones\n\n\nJustificación de las decisiones del modelo final\nMás de dos decisiones del modelo final no están justificadas\nMenos de dos decisiones del modelo final no están justificadas\nLas decisiones del modelo final son justificadas.\n\n\nEvaluación del modelo\nNo hace evaluación del modelo\nUsa el índice de determinación para evaluar el modelo\nUsa el índice de determinación para evaluar el modelo y además hace análisis de residuos sobre la salida del modelo\n\n\nModelo de regresión\nNo se construyó el modelo o el grupo no puede explicar de manera clara la razón de los procedimientos realizados\nSolo construyó un modelo o no hay claridad sobre las características del modelo elegido\nIdentificó el modelo de mayor precisión después de realizar varias pruebas, se exponen las características del modelo elegido.  El modelo se presenta de forma gráfica"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit",
    "href": "tutoriales/tut002_IA.html#que-es-microbit",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#componentes",
    "href": "tutoriales/tut002_IA.html#componentes",
    "title": "Microbit – El minicomputador",
    "section": "Componentes",
    "text": "Componentes"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#como-la-puedo-programar",
    "href": "tutoriales/tut002_IA.html#como-la-puedo-programar",
    "title": "Microbit – El minicomputador",
    "section": "Como la puedo programar?",
    "text": "Como la puedo programar?"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#distribución-e-impacto",
    "href": "tutoriales/tut002_IA.html#distribución-e-impacto",
    "title": "Microbit – El minicomputador",
    "section": "Distribución e impacto",
    "text": "Distribución e impacto\n\nDistribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#problema",
    "href": "tutoriales/tut002_IA.html#problema",
    "title": "Microbit – El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable en 0.\nMostrar el número en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "href": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "title": "Microbit – El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#lets-code",
    "href": "tutoriales/tut002_IA.html#lets-code",
    "title": "Microbit – El minicomputador",
    "section": "Let’s Code",
    "text": "Let’s Code\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#editor",
    "href": "tutoriales/tut002_IA.html#editor",
    "title": "Microbit – El minicomputador",
    "section": "Editor",
    "text": "Editor\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "href": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "title": "Microbit – El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable con el número a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#componentes",
    "href": "tutoriales/tut001_microbit.html#componentes",
    "title": "Microbit – El minicomputador",
    "section": "Componentes",
    "text": "Componentes"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "href": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "title": "Microbit – El minicomputador",
    "section": "Como la puedo programar?",
    "text": "Como la puedo programar?"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "href": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "title": "Microbit – El minicomputador",
    "section": "Distribución e impacto",
    "text": "Distribución e impacto\n\nDistribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#problema",
    "href": "tutoriales/tut001_microbit.html#problema",
    "title": "Microbit – El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable en 0.\nMostrar el número en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "href": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "title": "Microbit – El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#lets-code",
    "href": "tutoriales/tut001_microbit.html#lets-code",
    "title": "Microbit – El minicomputador",
    "section": "Let’s Code",
    "text": "Let’s Code\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#editor",
    "href": "tutoriales/tut001_microbit.html#editor",
    "title": "Microbit – El minicomputador",
    "section": "Editor",
    "text": "Editor\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "href": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "title": "Microbit – El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable con el número a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "tutoriales/ExpansionTaylor.html",
    "href": "tutoriales/ExpansionTaylor.html",
    "title": "Computación de seno y coseno usando expansión de Taylor",
    "section": "",
    "text": "Las ecuaciones de las expansiones de Taylor (centradas en cero) fueron extraídas de la recopilación que hizo Wikipedia\n\\[cos\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{x^{2n}}{2n!}\\left(-1\\right)^{n}}\\]\n\\[sin\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{\\left(-1\\right)^{n}}{\\left(2n+1\\right)!}x^{2n+1}}\\]\n\ndef factorial(x):\n    output = 1\n    for k in range(1,x+1):\n        output = output*k\n    return output\n\n\ndef sin_taylor_expansion(x,n):\n    pi = 3.141592653589793238462643383279502884197169399375105820974944\n    x = pi*x/180\n    output = 0\n    for k in range(0, n):\n        term = (((-1)**k)/factorial(2*k + 1))*(x**(2*k+1))\n        output = output+term\n    return output\n\n\nv_est = sin_taylor_expansion(30,5)\n\nprint(v_est)\n\nprint(\"Error Relativo:\", abs(0.5-v_est)/0.5)\n\n0.5000000000202799\nError Relativo: 4.0559777758630844e-11"
  },
  {
    "objectID": "clases/Class_PSIM.html",
    "href": "clases/Class_PSIM.html",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "“Un área de rápido crecimiento y variedad de aplicaciones en la ingeniería biomédica a nivel nacional y global es el procesamiento digital de señales e imágenes médicas. Es por eso, que a través de este curso se desea dar las herramientas necesarias para los graduados del programa puedan tener competencias básicas en las técnicas clásicas y algunas técnicas modernas de procesamiento de señales e imágenes. La primera parte del curso se encuentra enfocada al desarrollo de técnicas de procesamiento para señales biomédicas unidimensionales, exponiendo primero su origen fisiológico y siguiendo con la presentación de las principales técnicas para su análisis y procesamiento. La segunda parte del curso hace énfasis en el estudio de imágenes médicas, partiendo de una explicación de los principales métodos computacionales utilizados para procesamiento digital de imágenes y luego exponiendo brevemente el proceso de su formación. A través de prácticas de laboratorio con señales e imágenes médicas (reales o simuladas), el estudiante podrá aplicar y reforzar los conocimientos aprendidos en el curso” fragmento tomado del microcurriculo de la asignatura.\nEl curso está dividido en 4 partes:\n1. Introducción al procesado de señales e imágenes biomédicas.\n2. Fundamentos procesado de señales e imágenes biomédicas\n3. Extracción de características de señales biomédicas.\n4. Extracción de características de imágenes biomédicas."
  },
  {
    "objectID": "clases/Class_PSIM.html#presentaciones",
    "href": "clases/Class_PSIM.html#presentaciones",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción\nIntroducción al procesamiento de imagenes\nLa imagen digital. Procesamiento de Imágenes"
  },
  {
    "objectID": "clases/Class_PSIM.html#datos",
    "href": "clases/Class_PSIM.html#datos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_PSIM.html#códigos",
    "href": "clases/Class_PSIM.html#códigos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_PSIM.html#laboratorios",
    "href": "clases/Class_PSIM.html#laboratorios",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio 01\nLaboratorio 02"
  },
  {
    "objectID": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "href": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nPrimer Parcial 2024-I\nPrimer Parcial 2024-II. Examen01\nPrimer Parcial 2024-II. Examen02\nPrimer Parcial 2024-II. Examen03"
  },
  {
    "objectID": "clases/Class_PSIM.html#clases",
    "href": "clases/Class_PSIM.html#clases",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Clases",
    "text": "Clases\nLunes 2:30pm-4:00pm F-105. Martes 2:30pm-4:00pm D-201."
  },
  {
    "objectID": "clases/Class_PSIM.html#laboratorio",
    "href": "clases/Class_PSIM.html#laboratorio",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Laboratorio",
    "text": "Laboratorio\nJUEVES 2:30pm-4:00pm. I1-304"
  },
  {
    "objectID": "clases/Class_PSIM.html#atención-a-estudiantes",
    "href": "clases/Class_PSIM.html#atención-a-estudiantes",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes"
  },
  {
    "objectID": "clases/Class_ML.html",
    "href": "clases/Class_ML.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Que es ?\nEl aprendizaje automático (machine learning) es una rama de la inteligencia artificial que permite a los sistemas aprender y mejorar de la experiencia sin ser explícitamente programados. Esto significa que los sistemas de aprendizaje automático pueden identificar patrones en los datos y usar esos patrones para hacer predicciones o tomar decisiones.\nHay muchos tipos diferentes de algoritmos de aprendizaje automático, pero todos ellos funcionan de manera similar. Primero, el algoritmo se “entrena” con un conjunto de datos. Este conjunto de datos contiene ejemplos de los tipos de problemas que el algoritmo debe resolver. Por ejemplo, si el algoritmo está diseñado para clasificar imágenes, el conjunto de datos podría contener imágenes de gatos y perros.\nUna vez que el algoritmo está entrenado, puede usar los patrones que ha aprendido para hacer predicciones sobre nuevos datos. Por ejemplo, si se le muestra una nueva imagen de un animal, el algoritmo podría predecir si es un gato o un perro.\nEl aprendizaje automático es una tecnología muy poderosa que se puede aplicar a una amplia gama de problemas. Algunos ejemplos de aplicaciones de aprendizaje automático incluyen:\n\nClasificación de imágenes\nReconocimiento de voz\nDetección de fraudes\nRecomendación de productos\nOptimización de rutas\n\nEl aprendizaje automático es una tecnología en constante evolución, y se espera que se use cada vez más en los próximos años.\n\n\nMaterial del curso\nPresentación\n\n\nReferencias\n\nB. Boehmke y B. M. Greenwell, Hands-on machine learning with R. Boca Raton: CRC Press, 2019.\nG. Bonaccorso, Mastering machine learning algorithms: expert techniques to implement popular machine learning algorithms and fine-tune your models. 2018.\nM. Fenner, Machine learning in python for everyone. Boston, MA: Addison-Wesley, 2019.\nK. Kolodiazhnyi, Hands-On Machine Learning with C++ Build, Train, and Deploy End-To-end Machine Learning and Deep Learning Pipelines. Birmingham: Packt Publishing, Limited, 2020. Accedido: 28 de septiembre de 2021.\nM. Kubat, An Introduction to Machine Learning. Cham: Springer International Publishing, 2017. doi: 10.1007/978-3-319-63913-0.\nS. Raschka y V. Mirjalili, Python machine learning: machine learning and deep learning with Python, scikit-learn, and TensorFlow, Second edition, Fourth release,[fully revised and Updated]. Birmingham Mumbai: Packt Publishing, 04.\nS. Skansi, Introduction to Deep Learning: From Logical Calculus to Artificial Intelligence. Cham: Springer International Publishing, 2018. doi: 10.1007/978-3-319-73004-2."
  },
  {
    "objectID": "clases/Class_Statistics.html",
    "href": "clases/Class_Statistics.html",
    "title": "Probabilidad Computacional & Estadística",
    "section": "",
    "text": "Introducción\nLa Estadística es una disciplina que se ocupa de la recopilación, organización, análisis, interpretación y presentación de datos. En la aplicación de estadísticas a un problema científico, industrial o social, es convencional comenzar con una población estadística o un modelo estadístico a ser estudiado.\nLas poblaciones pueden ser grupos diversos de personas u objetos como “todas las personas que viven en un país” o “cada átomo que compone un cristal”. La estadística se ocupa de todos los aspectos de los datos, incluyendo la planificación de la recopilación de datos en términos del diseño de encuestas y experimentos.\nCuando no se pueden recopilar datos del censo, los estadísticos recopilan datos desarrollando diseños experimentales específicos y muestras de encuestas. La muestra representativa asegura que las inferencias y conclusiones pueden extenderse razonablemente de la muestra a la población en general.\nUn estudio experimental implica tomar medidas del sistema bajo estudio, manipular el sistema y luego tomar medidas adicionales utilizando el mismo procedimiento para determinar si la manipulación ha modificado los valores de las medidas. En contraste, un estudio observacional no implica manipulación experimental.\nLos dos métodos estadísticos principales utilizados en el análisis de datos son:\n- Estadísticas descriptivas, que resumen los datos de una muestra utilizando índices como la media o la desviación estándar.\n- Estadísticas inferenciales, que extraen conclusiones a partir de datos que están sujetos a variación aleatoria (por ejemplo, errores observacionales, variación de muestreo).\nLas inferencias en estadísticas matemáticas se hacen bajo el marco de la teoría de probabilidad, que se ocupa del análisis de fenómenos aleatorios. Un procedimiento estadístico estándar implica la recopilación de datos que conducen a una prueba de la relación entre dos conjuntos de datos estadísticos, o un conjunto de datos y datos sintéticos extraídos de un modelo idealizado.\n\n\nObjetivo de la clase\nLa Estadística Descriptiva es una rama de la estadística que se ocupa de resumir, organizar y presentar los datos de manera significativa y concisa. Se centra en describir y analizar las características principales de un conjunto de datos sin hacer generalizaciones o inferencias a una población más grande.\nLas estadísticas descriptivas suelen incluir medidas como la tendencia central (por ejemplo, media, mediana, moda), la dispersión (por ejemplo, rango, varianza, desviación estándar) y la forma de la distribución (por ejemplo, asimetría, curtosis).\nAdemás, las estadísticas descriptivas implican una representación gráfica de los datos a través de gráficos, gráficas y tablas, que pueden ayudar aún más en la visualización e interpretación de la información.\n\n\nAplicaciones de la Estadística Descriptiva\nLa Estadística Descriptiva se utiliza en diversas aplicaciones:\n\nInformes de Tráfico y Compromiso: Un ejemplo de análisis descriptivo es la generación de informes.\nAnálisis de Estados Financieros: Otro ejemplo familiar de análisis descriptivo es el análisis de estados financieros.\nTendencias de Demanda: Las estadísticas descriptivas pueden ayudar a identificar y analizar las tendencias de demanda.\nResultados Agregados de Encuestas: Los resultados agregados de las encuestas pueden ser resumidos y presentados utilizando estadísticas descriptivas.\nProgreso hacia Metas: Las estadísticas descriptivas pueden ser útiles para rastrear y presentar el progreso hacia las metas establecidas.\n\nEn resumen, las estadísticas descriptivas proporcionan un resumen claro y conciso de los datos, permitiendo a los investigadores o analistas obtener información y comprender patrones, tendencias y distribuciones dentro del conjunto de datos. Esto facilita una mejor comprensión de los datos y proporciona una base para un análisis estadístico más profundo o procesos de toma de decisiones.\n\n\nMaterial del curso\nPresentacion"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab04_sol_ImagProc02.html",
    "href": "laboratorios/PSIM/Previous/lab04_sol_ImagProc02.html",
    "title": "Algoritmos básicos de procesamiento de imágenes",
    "section": "",
    "text": "Usando la imagen fresas.png la cual fue tomada de la página Geeks for geeks resuelva las siguientes cuestiones.\n\nAplique las siguientes transformaciones y describa el efecto de cada transformación:\n\nTransformación n-potencial con \\(1&lt;n&lt;2\\)\nTransformación n-potencial con \\(0.5&lt;n&lt;1\\)\nTransformación LOG (Logaritmo Natural)\nTransformación exponencial\nDescriba en un diagrama de bloques el algoritmo necesario para realizar este tipo de transformaciones.\nInvestigue y desarrolle el algoritmo de la transformación \\(\\Gamma\\). La información básica la puede encontrar aqui\n\n\nRecuerde: Si una imagen queda completamente blanca o completamente negra, es probable que sea por mal manejo de rangos de intensidad\n\nimport pydicom as pyimag1\nimport cv2 as pyimag2\nimport matplotlib.pyplot as pyimag3\nimport numpy as pyimag4\n\nruta = \"../../data/imagen_dicom.dcm\"\n\n\ndata_imagen = pyimag1.dcmread(ruta)\nimage = data_imagen.pixel_array\npyimag3.imshow(image, cmap=\"gray\")\npyimag3.axis(\"off\")\n\npatient_name= data_imagen.PatientID\nprint(f\"Nombre del paciente: {patient_name}\")\n\nNombre del paciente: 239\n\n\n\n\n\n\n\n\n\n\nSea los siguientes kernels de convolución:\n\n\\(\\begin{bmatrix}\n1 & 1 & 1 \\\\\n1 & -8 & 1 \\\\\n1 & 1 & 1\n\\end{bmatrix}\\)\n\\(\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n-1 & 8 & -1 \\\\\n-1 & -1 & -1\n\\end{bmatrix}\\)\n\n\nExplique las siguientes cuestiones:\n\nInvestigue las formas de realizar la convolución con opencv.\nAplique cada uno de los kernels de convolución y compare los resultados.\nExplique cuales son las respectivas resoluciónes de pixel de las imagenes resultantes así como su máximo y su mínimo.\n\n\nkernel1 = (1 / 9) * pyimag4.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\nkernel2 = pyimag4.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\nconv1 = pyimag2.filter2D(image, ddepth=-1, kernel=kernel1)\nconv1_normalized = pyimag2.normalize(conv1, None, 0, 255, pyimag2.NORM_MINMAX)\nconv2 = pyimag2.filter2D(image, ddepth=-1, kernel=kernel2)\nconv2_normalized = pyimag2.normalize(conv2, None, 0, 255, pyimag2.NORM_MINMAX)\npyimag3.imshow(pyimag4.concatenate(\n    (conv1_normalized, conv2_normalized), \n    axis=1), \n    cmap=\"gray\")\npyimag3.axis(\"off\")\n\n\n\n\n\n\n\n\n\nrows, cols = image.shape\nangle = 45\nM = pyimag2.getRotationMatrix2D((cols//2, rows//2), angle, 1)\ntransformed_image = pyimag2.warpAffine(image, M, (cols, rows))\npyimag3.imshow(transformed_image, cmap=\"gray\")\npyimag3.axis(\"off\")\n\n\n\n\n\n\n\n\n\nUtilizando la imagen radiografía, aplique cada tipo de matriz afine presente en las diapositivas de clase\nDeterminar proyecto final para PSIM.\n\nDeterminar el problema a resolver.\nDeterminar el objetivo a alcanzar\nDeterminar el dataset\n\n\nRecuerde, en su proyecto final, NO podrá hacer uso de algoritmos de machine learning."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach\n\ndef f_hat(x):\n    return 4*(x**3) - 8*x\n\ndef shift(xs, n):\n    if n &gt;= 0:\n        return np.concatenate((np.full(n, xs[0]), xs[:-n]))\n    else:\n        return np.concatenate((xs[-n:], np.full(-n, xs[-1])))\n\ndef f_hat_num(x,t):\n    delta = shift(t, -1) - t\n    salida = (shift(x, -1) - x) / np.mean(delta[:-1])\n    return np.concatenate((salida[:-1], [salida[-2]]))\n\n\ntemp = np.array([0,1,2,3,4,5,6])\nnp.concatenate([temp, [temp[-1]]])\n\narray([0, 1, 2, 3, 4, 5, 6, 6])\n\n\n\nplt.plot(t, f_hat(t))\nplt.plot(t, f_hat_num(f(t), t))"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach\n\nimport sympy as sp\n\n# Define the variable and the expression\nx1 = sp.symbols(\"x1\")\nexpr = x1**4 - 4 * x1**2 + 4\n\nresult = sp.integrate(expr, (x1, -10, 10)).evalf()\n\n# Print the LaTeX representation\nprint(sp.latex(expr))\nprint(result)\n\nx_{1}^{4} - 4 x_{1}^{2} + 4\n37413.3333333333\n\n\n\n# Define the limits of integration\na = -10\nb = 10\n\n# Define the number of subintervals\nn = 100\n\n# Calculate the width of each subinterval\nh = (b - a) / n\n\n# Initialize the sum\nsum = 0.5 * (f(a) + f(b))\n\n# Apply the Trapezoid Rule\nfor i in range(1, n):\n    sum += f(a + i * h)\n\n# Calculate the integral\nintegral = h * sum\n\nprint(\"Approximate integral:\", integral)\n\nApproximate integral: 37439.465599999996"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)\n\n# Define the derivative function\ndef f1(x, y):\n    return 2 * x - 3 * y\n\n\n# Initial condition\nx0 = 0\ny0 = 1\n\n# Step size\nh = 0.1\n\n# Total steps\nn = int(10 / h)\n\n# Create arrays to store x and y values\nx = [0] * (n + 1)\ny = [0] * (n + 1)\n\n# Initialize x and y arrays\nx[0] = x0\ny[0] = y0\n\n# Euler's Method\nfor i in range(n):\n    x[i + 1] = x[i] + h\n    y[i + 1] = y[i] + h * f1(x[i], y[i])"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent.\n\nt1= np.linspace(-2,2,1000)\nplt.plot(t1, f(t1))\n\n\n\n\n\n\n\n\n\n# Initial guess\nx0 = 10 * (np.random.rand() - 0.5)\n\n# Learning rate\nalpha = 0.01\n\n# Number of iterations\nn_iter = 1000\n\n# Gradient Descent\nxg = x0\nfor i in range(n_iter):\n    xg = xg - alpha * f_hat(xg)\n\n# Print the minimum\nprint(\"Time of the minimum:\", xg)\nprint(\"Function value at minimum:\", f(xg))\n\nTime of the minimum: -1.4142135623730956\nFunction value at minimum: 8.881784197001252e-16"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab03_ImagProc.html",
    "href": "laboratorios/PSIM/Previous/lab03_ImagProc.html",
    "title": "Laboratorio 3: Carga de datos e Histograma",
    "section": "",
    "text": "Cargar el archivo imagen_dicom.dcm y almacenarlo en la variable var01.\nCargar el archivo imagen_nii.nii y almacenarlo en la variable var02.\nCargar el archivo covid-4.png y almacenarlo en la variable var03.\nMostrar las variables: var01, var02, var03.\nDescribir las dimensiones de cada una de las imagenes.\nTomar la var03 y si tiene más de una dimensión, convertirla a imagen en escala de grises, con profundidad de intensidad de pixel de 8bits.\nContar cuantos pixeles hay para cada valor de intensidad posible en la conversión en escala de grises de la variable var03. Mostrar estos valores en una gráfica de barras.\nPara el punto 7 solo puede utilizar la librería numpy.\nPara el punto 8 solo puede utilizar la librería matplotlib."
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "El electrocardiograma (ECG o EKG) es una grabación de la actividad eléctrica cardíaca en la superficie de la piel, durante un período de tiempo determinado. En cada ciclo cardíaco, un corazón sano presenta una secuencia de señales eléctricas que se generan en el nodo sinoauricular y se distribuyen en el corazón hasta alcanzar los ventrículos. Estas señales tienen una forma característica que se muestra en la figura 1.\n\n\n\nFigura 1. ECG durante un ciclo cardíaco normal\n\n\nA través de un ECG, un profesional de la salud entrenado es capaz de obtener información relevante sobre el funcionamiento del corazón; por ejemplo, se puede determinar la frecuencia cardíaca, la presencia de daño en el músculo cardíaco, los efectos de medicamentos y la función de marcapasos implantados.\n\n\nLos estudiantes conocerán las principales teorías concernientes a la generación del electrocardiograma y su relación con el funcionamiento del corazón.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#objetivo-de-aprendizaje",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes conocerán las principales teorías concernientes a la generación del electrocardiograma y su relación con el funcionamiento del corazón."
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#duración",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#materiales",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-1-revisión-al-electrocardiograms",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-1-revisión-al-electrocardiograms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 1: Revisión al electrocardiograms",
    "text": "Actividad 1: Revisión al electrocardiograms\n\n¿Qué es un electrocardiograma (ECG) y cuál es su importancia en el diagnóstico clínico?\n¿Qué información electrofisiológica proporciona un ECG y cómo se relaciona con la actividad del corazón?\n¿Qué es una derivación (lead) en el contexto de un ECG y cuál es su función?\n¿Cuántas derivaciones existen en un ECG estándar y cómo se clasifican?\nObserve la Figura 1 proporcionada y determine a qué derivación corresponde el diagrama mostrado. Justifique su respuesta.\n¿Qué es una arritmia y qué tipos existen? Describa las características de cada tipo de arritmia."
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-2-análisis-del-articulo",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-2-análisis-del-articulo",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 2: Análisis del articulo",
    "text": "Actividad 2: Análisis del articulo\n\n¿Cuáles son las principales clases de arritmias que el artículo estudia y cómo se agrupan?\n¿Qué impacto tienen las arritmias en la salud pública según el artículo? Mencione datos estadísticos relevantes.\n¿Por qué es importante mejorar la precisión en la clasificación automática de arritmias?\n¿Cuáles son las principales fuentes de ruido en una señal de ECG y qué técnicas se utilizaron en el artículo para reducirlas?\n¿Por qué se aplicó normalización a las señales ECG? ¿Qué impacto tuvo en la clasificación? Explique el método de normalización.\n¿Cuáles son las principales características extraídas de la señal ECG en este estudio?\n¿Por qué es importante la selección de características para el entrenamiento de un algoritmo de clasificación?"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-3-análisis-de-la-base-de-datos",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-3-análisis-de-la-base-de-datos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 3: Análisis de la base de datos",
    "text": "Actividad 3: Análisis de la base de datos\n\n¿Cuáles fueron los criterios de selección de los pacientes?\n¿Cuántos registros de ECG se recopilaron en total y qué duración tienen las señales analizadas?\n¿Cómo se realizó la toma de datos del ECG? Especifique el número de derivaciones, la duración del registro y la frecuencia de muestreo.\n¿Cuáles fueron las características demográficas de la población estudiada? Describa la distribución por edad y género.\n¿Cuál fue la prevalencia de cada tipo de arritmia en la base de datos? ¿Qué arritmias fueron las más frecuentes y cuáles fueron las menos comunes?"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#criterios-de-evaluación",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Criterios de Evaluación",
    "text": "Criterios de Evaluación\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nNivel Excelente (5.0 - 4.5)\nNivel Satisfactorio (4.4 - 3.5)\nNivel Aceptable (3.4 - 2.5)\nNivel Deficiente (&lt;2.5)\nPeso (%)\n\n\n\n\nComprensión teórica del ECG y su relevancia clínica\nExplica de manera clara y detallada la importancia del ECG, su función diagnóstica y la información electrofisiológica que proporciona. Responde con precisión todas las preguntas teóricas.\nResponde la mayoría de las preguntas con claridad, pero algunas respuestas pueden carecer de profundidad o detalles.\nResponde las preguntas de manera parcial o con imprecisiones conceptuales. Falta claridad en algunos conceptos.\nRespuestas incompletas o con errores fundamentales en la comprensión del ECG y su relevancia.\n20%\n\n\nAnálisis del artículo de Zheng et al.\nIdentifica y sintetiza correctamente las clases de arritmias, impacto en salud pública, técnicas de reducción de ruido y normalización. Argumenta con evidencia del artículo.\nPresenta un buen análisis, aunque algunas respuestas carecen de profundidad o precisión. Uso adecuado pero limitado de la evidencia.\nMuestra dificultad en identificar o explicar correctamente algunos conceptos clave del artículo.\nAnálisis deficiente, respuestas vagas o incorrectas, falta de relación con el artículo.\n20%\n\n\nAnálisis de la base de datos de ECG\nDescribe con precisión los criterios de selección, número de registros, condiciones de adquisición y características demográficas. Utiliza correctamente los datos del artículo.\nExplica la mayoría de los aspectos, aunque con algunas omisiones o falta de precisión en los datos.\nResponde parcialmente, con confusión en algunos aspectos metodológicos o demográficos.\nNo logra describir correctamente los criterios de la base de datos o presenta errores graves en su interpretación.\n20%\n\n\nJustificación y análisis de derivaciones\nIdentifica correctamente la derivación del ECG mostrado en la Figura 1, justificando con base en conocimientos teóricos.\nIdentifica la derivación con una justificación aceptable, aunque podría ser más clara.\nPresenta una identificación incorrecta o incompleta con una justificación débil.\nNo justifica o identifica erróneamente la derivación.\n15%\n\n\nPresentación y redacción del informe\nInforme bien estructurado, sin errores gramaticales o de formato. Uso adecuado de referencias. Argumentación clara y precisa.\nInforme organizado, aunque con algunos errores menores de gramática o formato. Argumentación adecuada.\nPresentación con errores de redacción y formato. Explicaciones poco estructuradas.\nInforme desorganizado, con errores graves de gramática y sin referencias adecuadas.\n15%\n\n\nParticipación y trabajo en equipo\nDemuestra alto compromiso y participación en la sesión de laboratorio. Contribuye activamente al desarrollo del informe.\nParticipa en la mayoría de las actividades, aunque con algunas intervenciones limitadas.\nParticipa de forma esporádica o depende en exceso del grupo para completar las actividades.\nNo participa o su aporte al equipo es mínimo.\n10%\n\n\n\nTotal: 100% puntos."
  },
  {
    "objectID": "laboratorios/APSB/lab01_IniciandoJetsonNano.html",
    "href": "laboratorios/APSB/lab01_IniciandoJetsonNano.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Download the Jetson Nano 2GB Developer Kit SD Card Image and note where it was saved on the computer.\nDownload, install, and launchSD Memory Card Formatter for Windows\nDownload, install, and launch Etcher."
  },
  {
    "objectID": "laboratorios/APSB/lab01_IniciandoJetsonNano.html#requiered-downloads",
    "href": "laboratorios/APSB/lab01_IniciandoJetsonNano.html#requiered-downloads",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Download the Jetson Nano 2GB Developer Kit SD Card Image and note where it was saved on the computer.\nDownload, install, and launchSD Memory Card Formatter for Windows\nDownload, install, and launch Etcher."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html",
    "href": "laboratorios/ASIM/lab001_OOP.html",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "href": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "href": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Encapsulation",
    "text": "Encapsulation\n\nEncapsulation is the concept of bundling data and methods that operate on that data within a single unit (class).\nIt helps to hide the implementation details and expose only the necessary information to the outside world."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "href": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Inheritance",
    "text": "Inheritance\n\nInheritance is the mechanism by which one class can inherit the attributes and methods of another class.\nIt promotes code reuse and facilitates the creation of a hierarchy of classes."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "href": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Polymorphism",
    "text": "Polymorphism\n\nPolymorphism is the ability of an object to take on multiple forms.\nIt can be achieved through method overriding (where a subclass provides a different implementation of a method) or method overloading (where multiple methods with the same name can be defined with different parameters)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "href": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Abstraction",
    "text": "Abstraction\n\nAbstraction is the concept of showing only the necessary information to the outside world while hiding the implementation details.\nIt helps to reduce complexity and improve code readability.\n\n\nclass BankAccount:\n    def __init__(self, account_number, account_name, balance):\n        self.account_number = account_number\n        self.account_name = account_name\n        self.balance = balance\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance:\n            print(\"Insufficient funds\")\n        else:\n            self.balance -= amount\n\n    def display_details(self):\n        print(f\"Account Number: {self.account_number}\")\n        print(f\"Account Name: {self.account_name}\")\n        print(f\"Balance: {self.balance}\")\n\n\nThe BankAccount class encapsulates the account_number, account_name, and balance attributes, as well as the deposit, withdraw, and display_details methods.\nThe __init__ method is a special method that is called when an object is created, and it initializes the attributes.\nThe deposit and withdraw methods modify the balance attribute, demonstrating encapsulation.\nThe display_details method provides a way to access the attributes without exposing them directly, demonstrating abstraction.\n\n\nclass SavingsAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, interest_rate):\n        super().__init__(account_number, account_name, balance)\n        self.interest_rate = interest_rate\n\n    def add_interest(self):\n        interest = self.balance * self.interest_rate\n        self.deposit(interest)\n\n\nThe SavingsAccount class inherits the attributes and methods of BankAccount using the super() function.\nIt adds an additional attribute interest_rate and a method add_interest that calculates and deposits interest.\n\n\nclass CurrentAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, overdraft_limit):\n        super().__init__(account_number, account_name, balance)\n        self.overdraft_limit = overdraft_limit\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance + self.overdraft_limit:\n            print(\"Transaction declined\")\n        else:\n            super().withdraw(amount)\n\n\n\n\nimage.png\n\n\n\n“Designing a Comprehensive Hospital Management System in Python”\n\nIntroduction\nIn this task, we aim to develop a straightforward hospital management system that efficiently manages patients, doctors, and appointments. Leveraging Python’s object-oriented programming capabilities, we will create a robust framework to streamline hospital operations.\n\n\nSystem Components\nThe hospital management system comprises four primary classes: Person, Patient, Doctor, Appointment, and Hospital.\n\n\nPerson Class\nThe Person class serves as the foundation for both Patient and Doctor classes, encapsulating essential attributes:\n\nname\nage\ngender\n\n\n\nPatient Class\nInheriting from Person, the Patient class introduces additional attributes:\n\npatient_id\nillness\n\n\n\nDoctor Class\nSimilarly, the Doctor class inherits from Person and includes:\n\ndoctor_id\nspecialization\n\n\n\nAppointment Class\nThe Appointment class encompasses:\n\nappointment_id\npatient (a Patient object)\ndoctor (a Doctor object)\ndate\ntime\n\n\n\nHospital Class\nThe Hospital class is the central hub, managing:\n\npatients (a list of Patient objects)\ndoctors (a list of Doctor objects)\nappointments (a list of Appointment objects)\nHospital Class Methods: The Hospital class features the following methods:\n\nadd_patient(name, age, gender, patient_id, illness): Adds a new patient to the hospital.\nadd_doctor(name, age, gender, doctor_id, specialization): Adds a new doctor to the hospital.\nschedule_appointment(appointment_id, patient_id, doctor_id, date, time): Schedules a new appointment.\nlist_appointments(): Lists all appointments.\n\n\n\n\nImplementation\nBy utilizing these classes and methods, the hospital management system provides a structured approach to managing patients, doctors, and appointments, ensuring efficient and organized hospital operations."
  },
  {
    "objectID": "laboratorios/ASIM/lab002_CNN_cap.html",
    "href": "laboratorios/ASIM/lab002_CNN_cap.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torchvision\n\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader\n\nimport torch.nn as nn\n\nfrom torch import utils\nfrom torch import optim\nfrom torch import device\nfrom torch import inference_mode\n\nimport tqdm\n\nfrom timeit import default_timer as timer\nfrom tqdm.auto import tqdm\n\nfrom torchmetrics import ConfusionMatrix\nimport mlxtend\nfrom mlxtend.plotting import plot_confusion_matrix\nimport numpy\nfrom torchvision.transforms.v2 import (\n    ConvertImageDtype,\n    Normalize,\n    Resize,\n    CenterCrop,\n    ToTensor,\n    ToImage,\n    Compose\n)\n\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0\n\n\n\ntransformacion = Compose([\n    ToTensor(), \n    Normalize(mean=[0.5], std=[0.5])\n    ])\n\n/home/pablo/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n\n\n\ndata_flag = \"pathmnist\"\ninfo = INFO[data_flag]\nDataClass = getattr(medmnist, info[\"python_class\"])\n\n# Load the training and testing datasets\ntrain_data = DataClass(split=\"train\", transform=transformacion, download=True)\nval_data = DataClass(split=\"val\", transform=transformacion, download=True)\ntest_data = DataClass(split=\"test\", transform=transformacion, download=True)\n\nDownloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /home/pablo/.medmnist/pathmnist.npz\n\n\n100%|██████████| 205615438/205615438 [00:20&lt;00:00, 10059790.46it/s]\n\n\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\n\n\n\n# check data properties\nimg = train_data[0][0]\nlabel = train_data[0][1]\n\nprint(f\"Image:\\n {img}\")\nprint(f\"Label:\\n {label}\")\n\nprint(f\"Image shape: {img.shape}\")\nprint(f\"Label: {label}\")\n\nImage:\n tensor([[[0.7255, 0.7176, 0.7255,  ..., 0.7255, 0.7176, 0.7333],\n         [0.7098, 0.7255, 0.7176,  ..., 0.5451, 0.5059, 0.4902],\n         [0.7255, 0.7255, 0.7176,  ..., 0.6314, 0.6235, 0.6392],\n         ...,\n         [0.7098, 0.7020, 0.7333,  ..., 0.7333, 0.7255, 0.7333],\n         [0.6706, 0.7020, 0.7333,  ..., 0.7333, 0.7333, 0.7333],\n         [0.6863, 0.7255, 0.7333,  ..., 0.7255, 0.7333, 0.7412]],\n\n        [[0.6314, 0.6235, 0.6235,  ..., 0.6314, 0.6235, 0.6314],\n         [0.6157, 0.6235, 0.6157,  ..., 0.3882, 0.3490, 0.3176],\n         [0.6314, 0.6235, 0.6078,  ..., 0.4980, 0.5059, 0.5216],\n         ...,\n         [0.6078, 0.5765, 0.6314,  ..., 0.6314, 0.6314, 0.6392],\n         [0.5059, 0.5686, 0.6314,  ..., 0.6314, 0.6392, 0.6314],\n         [0.5294, 0.6235, 0.6314,  ..., 0.6314, 0.6314, 0.6392]],\n\n        [[0.7804, 0.7804, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7725, 0.7725, 0.7725,  ..., 0.5843, 0.5451, 0.5294],\n         [0.7725, 0.7725, 0.7647,  ..., 0.6706, 0.6706, 0.6941],\n         ...,\n         [0.7647, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7098, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7255, 0.7725, 0.7804,  ..., 0.7804, 0.7804, 0.7882]]])\nLabel:\n [0]\nImage shape: torch.Size([3, 28, 28])\nLabel: [0]\n\n\n\n# Number of image channels\nn_channels = info[\"n_channels\"]\nprint(f\"number of channels: {n_channels}\")\n\n# Number of classes\nn_classes = len(info[\"label\"])\nprint(f\"number of classes: {n_classes}\")\n\n# Get the class names from the dataset\nclass_names = info[\"label\"]\nprint(f\"class names: {class_names}\")\n\nnumber of channels: 3\nnumber of classes: 9\nclass names: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n\n\n\nfor i in range(3):\n    img = train_data[i][0]\n    label = train_data[i][1]\n    plt.figure(figsize=(3, 3))\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(label)\n    plt.axis(False)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.6313726..0.84313726].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.372549..0.85882354].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# change data into dataloader form\nBATCH_SIZE = 128\ntrain_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n\n\n# check dataloader\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")\n\nDataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53cd0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53490&gt;)\nLength of train dataloader: 704 batches of 128\nLength of test dataloader: 57 batches of 128\nLength of val dataloader: 79 batches of 128"
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#importance-of-frequency-response-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#importance-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Importance of Frequency-Response Filters",
    "text": "Importance of Frequency-Response Filters\n\nFrequency-response filters are critical for enhancing specific features or reducing noise in images.\nWidely used in MRI, CT, and ultrasound imaging."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#what-is-a-frequency-response-filter",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#what-is-a-frequency-response-filter",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is a Frequency-Response Filter?",
    "text": "What is a Frequency-Response Filter?\n\nA frequency-response filter modifies the frequency components of a signal.\nApplied in image processing to control which frequencies (details) pass or are suppressed."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#types-of-frequency-response-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#types-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Types of Frequency-Response Filters",
    "text": "Types of Frequency-Response Filters\n\nLow-pass filters: Allow low frequencies, suppress high frequencies (smoothes image).\nHigh-pass filters: Allow high frequencies, suppress low frequencies (sharpens image).\nBand-pass filters: Allow frequencies in a certain range."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#spatial-vs.-frequency-domain",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#spatial-vs.-frequency-domain",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Spatial vs. Frequency Domain",
    "text": "Spatial vs. Frequency Domain\n\nSpatial domain: Operations on pixel values directly.\nFrequency domain: Operations on the image’s frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#fourier-transform",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#fourier-transform",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Fourier Transform",
    "text": "Fourier Transform\n\nConverts an image from the spatial domain to the frequency domain.\nFormula: \\[F\\left(u,v\\right) = \\sum\\sum f\\left(x,y\\right) e^{-j2\\pi(\\frac{ux}{M} + \\frac{vy}{N})}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#low-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#low-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low-Pass Filters",
    "text": "Low-Pass Filters\n\nRemoves high-frequency components (e.g., noise, sharp edges).\nExample: Gaussian filter, Butterworth filter."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#high-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#high-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "High-Pass Filters",
    "text": "High-Pass Filters\n\nEnhances edges and high-frequency details.\nExample: Laplacian filter."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#band-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#band-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Band-Pass Filters",
    "text": "Band-Pass Filters\n\nAllows frequencies within a specific range.\nUseful for isolating specific image features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#noise-reduction-in-mri",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#noise-reduction-in-mri",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Noise Reduction in MRI",
    "text": "Noise Reduction in MRI\n\nLow-pass filters reduce noise and artifacts in MRI scans.\nSmoothes the image without losing crucial details."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#edge-enhancement-in-ultrasound-images",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#edge-enhancement-in-ultrasound-images",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge Enhancement in Ultrasound Images",
    "text": "Edge Enhancement in Ultrasound Images\n\nHigh-pass filters help in detecting tissue boundaries by enhancing edges.\nImproves clarity of anatomical structures."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#feature-extraction-in-ct-scans",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#feature-extraction-in-ct-scans",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Feature Extraction in CT Scans",
    "text": "Feature Extraction in CT Scans\n\nFilters can help in extracting features like tumors or vessels.\nBand-pass filters isolate structures of interest at specific frequency ranges."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process",
    "text": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process\n\nLoad MRI image.\nApply Fourier Transform to move the image into the frequency domain.\nDesign and apply a low-pass filter.\nPerform Inverse Fourier Transform to return to the spatial domain.\nVisualize the result."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#summary",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#summary",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Summary",
    "text": "Summary\n\nFrequency-response filters play a crucial role in biomedical image processing.\nHelp enhance key features and suppress unwanted noise."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#future-trends",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#future-trends",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Future Trends",
    "text": "Future Trends\n\nDeep learning integration with traditional filters.\nDevelopment of adaptive filters for real-time processing."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#what-is-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#what-is-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is Thresholding?",
    "text": "What is Thresholding?\n\nDefinition: A technique to separate objects from the background in images.\nConcept: Converting a grayscale image into a binary image.\nImportance: Simplification for further analysis (e.g., edge detection, segmentation)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#global-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#global-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Global Thresholding",
    "text": "Global Thresholding\n\nExplanation of Global Thresholding.\nExample of a fixed threshold ( T ):\n\nIf ( I(x, y) &gt; T ), the pixel becomes white (1), otherwise black (0).\n\nLimitations: Sensitivity to uneven lighting."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#adaptive-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#adaptive-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Adaptive Thresholding",
    "text": "Adaptive Thresholding\n\nDefinition of Adaptive Thresholding.\nInstead of a global threshold, the threshold is calculated for different regions of the image.\nAdvantages: Effective in images with varying illumination.\nAlgorithm: Example of an adaptive method based on the local mean of neighboring pixels."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#otsus-algorithm",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#otsus-algorithm",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Otsu’s Algorithm",
    "text": "Otsu’s Algorithm\n\nExplanation of Otsu’s Algorithm.\n\nAutomatic global thresholding that minimizes the within-class variance.\n\nSteps of the algorithm:\n\nCompute image histograms.\nEvaluate the between-class variance function for every possible threshold.\nSelect the threshold that minimizes the within-class variance.\n\nAdvantages: Automatic and effective in bimodal images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#justification-for-using-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#justification-for-using-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Justification for Using Thresholding",
    "text": "Justification for Using Thresholding\n\nWhen thresholding is useful:\n\nImages with a clear contrast between the object and the background.\nSituations requiring quick segmentation.\n\nExample applications:\n\nText detection, object recognition, medical images (e.g., X-rays).\n\nLimitations: Less effective in noisy or low-quality images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#comparison-of-thresholding-algorithms",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#comparison-of-thresholding-algorithms",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Comparison of Thresholding Algorithms",
    "text": "Comparison of Thresholding Algorithms\n\n\n\n\n\n\n\n\n\n\nMethod\nPrecision\nProcessing Speed\nEase of Implementation\nTypical Applications\n\n\n\n\nGlobal Threshold\nMedium\nFast\nSimple\nHigh-contrast images\n\n\nAdaptive Threshold\nHigh\nModerate\nModerate\nUnevenly lit images\n\n\nOtsu’s Algorithm\nHigh\nModerate\nModerate\nBimodal distributions"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nShow examples of original images and the result after applying:\n\nGlobal Thresholding.\nAdaptive Thresholding.\nOtsu’s Algorithm.\n\nVisualizations highlighting the differences."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples-1",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nResultsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.imshow(image_circle, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nplt.imshow(image_gradient, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nplt.imshow(noisy_circle, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh1 = cv2.threshold(image_circle, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh1, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh2 = cv2.threshold(image_gradient, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh3 = cv2.threshold(noisy_circle, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh1 = cv2.adaptiveThreshold(image_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh1, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh2 = cv2.adaptiveThreshold(image_gradient, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh3 = cv2.adaptiveThreshold(noisy_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, otsu_thresh1 = cv2.threshold(image_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh1, cmap=\"gray\")\nplt.axis(\"off\");\nplt.show()\n\n_, otsu_thresh2 = cv2.threshold(image_gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, otsu_thresh3 = cv2.threshold(noisy_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#conclusion-and-questions",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#conclusion-and-questions",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Conclusion and Questions",
    "text": "Conclusion and Questions\n\nSummary of key points:\n\nThresholding as a simple yet powerful technique.\nImportance of choosing the right algorithm depending on the context.\nOtsu’s algorithm as an effective solution for bimodal images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-morphological-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction to Morphological Operations",
    "text": "Introduction to Morphological Operations\n\nDefinition: Morphological operations apply a structuring element to an image to alter its structure.\nFocus: Primarily used for binary images.\nKey applications: Noise removal, object extraction, shape analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#structuring-element",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#structuring-element",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Structuring Element",
    "text": "Structuring Element\n\nA small matrix used to probe and interact with a given image.\nCommon shapes: Rectangular, circular, elliptical.\nExample: A 3x3 square structuring element.\n\n\\[\\begin{bmatrix}\n  1 & 1 & 1 \\\\\n  1 & 1 & 1 \\\\\n  1 & 1 & 1 \\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#common-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#common-morphological-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Common Morphological Operations",
    "text": "Common Morphological Operations\n\nErosion:\n\nRemoves pixels on object boundaries.\nShrinks the size of objects in the image.\nUsed to eliminate small noise or detach connected objects.\n\nDilation:\n\nAdds pixels to object boundaries.\nEnlarges the object in an image.\nHelps fill small holes and gaps within objects.\n\nOpening:\n\nErosion followed by dilation.\nUsed to remove small objects (noise) while maintaining the shape of larger objects.\n\nClosing:\n\nDilation followed by erosion.\nFills small holes and gaps in an object’s boundaries.\n\nTop-Hat Transformation:\n\nThe difference between the original image and its opening.\nUsed to highlight bright regions on a dark background.\nDetecting small, bright objects or details in an unevenly illuminated image.\n\nBlack-Hat Transformation:\n\nThe difference between the closing of an image and the original image.\nUsed to highlight dark regions on a bright background.\nEmphasizing dark objects or shadows in an image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#example-of-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#example-of-morphological-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Example of Morphological Operations",
    "text": "Example of Morphological Operations"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-frequency-response",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-frequency-response",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction to Frequency Response",
    "text": "Introduction to Frequency Response\n\nWhat is Frequency Response?\n\nThe frequency response of an image shows how spatial details in the image are distributed across different frequencies.\nIn image processing, this is typically analyzed using the Fourier Transform.\n\nWhy Frequency Analysis?\n\nUseful for identifying patterns, noise, and image structures not easily observed in the spatial domain."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-fourier-transform",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-fourier-transform",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The Fourier Transform",
    "text": "The Fourier Transform\n\nFourier Transform (FT):\n\nConverts an image from the spatial domain (pixels) to the frequency domain (sinusoids).\nEach point in the frequency domain represents a specific frequency in the image.\n\nMathematical Basis:\n\n( F(u,v) = _x _y f(x,y) e^{-j 2 (ux/M + vy/N)} )\nWhere ( F(u,v) ) is the frequency representation of the image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-and-high-frequencies",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-and-high-frequencies",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low and High Frequencies",
    "text": "Low and High Frequencies\n\nLow Frequencies:\n\nRepresent slow variations or large structures in the image (e.g., background or smooth gradients).\n\nHigh Frequencies:\n\nRepresent rapid variations or fine details (e.g., edges, noise).\n\nKey Insight: Most of the important structural information in an image is captured in the low-frequency range."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-domain-representation",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-domain-representation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Frequency Domain Representation",
    "text": "Frequency Domain Representation\n\nThe Fourier Transform of an image produces a frequency spectrum.\nDC Component (center of the spectrum): Represents the average intensity of the image.\nHigher frequencies: Spread out from the center and capture finer details.\nLogarithmic scale: Often used to visualize the frequency spectrum due to the wide range of values."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-2d-discrete-fourier-transform-dft",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-2d-discrete-fourier-transform-dft",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The 2D Discrete Fourier Transform (DFT)",
    "text": "The 2D Discrete Fourier Transform (DFT)\n\nThe 2D DFT is used to convert a 2D image into its frequency components:\n\nInput: A 2D grayscale image.\nOutput: A complex matrix representing amplitude and phase for each frequency.\n\nInverse DFT: Converts the frequency representation back to the spatial domain."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-pass-and-high-pass-filtering",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-pass-and-high-pass-filtering",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low-Pass and High-Pass Filtering",
    "text": "Low-Pass and High-Pass Filtering\n\nLow-Pass Filter (LPF):\n\nAllows low frequencies to pass, attenuates high frequencies.\nUsed to blur images, removing high-frequency details like noise and edges.\n\nHigh-Pass Filter (HPF):\n\nAllows high frequencies to pass, attenuates low frequencies.\nUsed to sharpen images by enhancing edges and fine details."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#band-pass-filtering",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#band-pass-filtering",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Band-Pass Filtering",
    "text": "Band-Pass Filtering\n\nBand-Pass Filter:\n\nAllows frequencies within a certain range (band) to pass.\nUseful for selectively enhancing specific frequency components while filtering others.\n\nApplications: Used in image enhancement and texture analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-response-visualization",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-response-visualization",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Frequency Response Visualization",
    "text": "Frequency Response Visualization\n\nMagnitude Spectrum:\n\nRepresents the amplitude of each frequency component.\nTypically visualized using the logarithmic scale to manage the large range of values.\n\nPhase Spectrum:\n\nRepresents the phase of each frequency component.\nLess important for human perception but crucial for reconstructing the image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#applications-of-frequency-domain-processing",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#applications-of-frequency-domain-processing",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Applications of Frequency Domain Processing",
    "text": "Applications of Frequency Domain Processing\n\nNoise Removal: Low-pass filters can smooth out high-frequency noise.\nEdge Detection: High-pass filters enhance edges and sharp transitions.\nImage Compression: Frequency domain analysis helps identify redundant information.\nPattern Recognition: Useful for detecting repetitive patterns like textures."
  },
  {
    "objectID": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "href": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sources of data",
    "text": "Sources of data\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---element-wise-operation",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---element-wise-operation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Element-Wise Operation",
    "text": "Basic Mathematic - Element-Wise Operation\n\n\n\n\n\n\n\nDefinition\n\n\nOperation involving one or more images is carried out on a pixel-bypixel basis\n\n\n\n\n\\[\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}  \n\\end{bmatrix} \\oplus \\begin{bmatrix} b_{11} & b_{12} \\\\  b_{21} & b_{22}\\end{bmatrix} = \\begin{bmatrix} a_{11}+b_{11} & a_{12}+b_{12} \\\\  a_{21}+b_{21} & a_{22}+b_{22}\\end{bmatrix} \\]\n\\[\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}  \n\\end{bmatrix} \\odot \\begin{bmatrix} b_{11} & b_{12} \\\\  b_{21} & b_{22}\\end{bmatrix} = \\begin{bmatrix} a_{11}.b_{11} & a_{12}.b_{12} \\\\  a_{21}.b_{21} & a_{22}.b_{22}\\end{bmatrix} \\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---linear-operations",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---linear-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Linear Operations",
    "text": "Basic Mathematic - Linear Operations\n\n\n\n\n\n\n\nDefinition\n\n\nGiven two arbitrary constants, \\(\\alpha_1\\) and \\(\\alpha_2\\), and two arbitrary images \\(f_1\\left(x,y\\right)\\) and \\(f_2\\left(x,y\\right)\\), \\(\\varkappa\\) is said to be a linear operator if:\n\\[ \\begin{equation}\\begin{split} \\varkappa\\left[\\alpha_1 f_1\\left(x,y\\right) + \\alpha_2 f_2\\left(x,y\\right)\\right] & =  \\alpha_1 \\varkappa\\left[ f_1\\left(x,y\\right)\\right] + \\alpha_2 \\varkappa\\left[f_2\\left(x,y\\right)\\right] \\\\ & = \\alpha_1 g_1\\left(x,y\\right) + \\alpha_2 g_2\\left(x,y\\right) \\end{split}\\end{equation} \\]\n\n\n\n\nSupose \\(\\alpha_1 = 5\\), \\(\\alpha_2 = 2\\), \\(\\varkappa = max\\) and consider:\n\\[f_1 = \\begin{bmatrix}0 & -1 \\\\2 & 4\\end{bmatrix}\\], \\[f_2 = \\begin{bmatrix}30 & 4 \\\\-2 & -3\\end{bmatrix}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Adding",
    "text": "Basic Mathematic - Adding"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Adding",
    "text": "Basic Mathematic - Adding\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_ray_chest = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/female-chest-x-ray.jpg\")\nplt.imshow(x_ray_chest, cmap=\"gray\")\nplt.show()\nimage_synt1 = 100*np.abs(np.random.normal(0, 1, x_ray_chest.shape))\nplt.imshow(image_synt1)\nplt.show()\nfinal_image = np.uint8(x_ray_chest+image_synt1)\nplt.imshow(final_image)\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---multiplying",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---multiplying",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Multiplying",
    "text": "Basic Mathematic - Multiplying\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_ray_chest = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/female-chest-x-ray.jpg\")\nmask = np.uint8(np.zeros(x_ray_chest.shape))\nmask[400:700, 250:600, :]=1\nplt.imshow(x_ray_chest)\nplt.show()\nplt.imshow(255*mask)\nplt.show()\nplt.imshow(np.multiply(x_ray_chest,mask))\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\nOriginal\n\n\n\n\n\n\n\nExp=1.1\n\n\n\n\n\n\n\nExp=1.2\n\n\n\n\n\n\n\n\n\nExp=0.2\n\n\n\n\n\n\n\nExp=0.30\n\n\n\n\n\n\n\nExp=0.5\n\n\n\n\n\n\n\n\nx_ray_chest_gray = cv2.cvtColor(x_ray_chest, cv2.COLOR_BGR2GRAY)\nplt.imshow(x_ray_chest_gray, cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,1.1), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,1.2), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.2), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.3), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.5), cmap=\"gray\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood Operations",
    "text": "Neighborhood Operations\n\nFor example, suppose that the specified operation is to compute the average value of the pixels in a rectangular neighborhood of size mn × centered on \\(\\left(x,y\\right)\\). The coordinates of pixels in this region are the elements of set \\(S_{xy}\\).\n\n\nImagescode\n\n\n\n\n\n\n\n\n\nElderly woman image\n\n\n\n\n\n\n\n\n\n\nGray-scale image\n\n\n\n\n\n\n\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nplt.imshow(elderly)\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nOriginalAveragingCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN = 10\nkernel = np.ones((N,N),np.float32)/(N*N)\ndst = cv2.filter2D(elderly_gray,-1,kernel)\nplt.imshow(dst, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-3",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nOriginalMedianCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN=11\n\ndst1 = cv2.medianBlur(elderly_gray, N)\nplt.imshow(dst1, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-4",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-4",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nMeanMedian"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-5",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-5",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-6",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-6",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: http://datagenetics.com/blog/august32013/index.html"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge dection",
    "text": "Edge dection"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge dection",
    "text": "Edge dection"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge dection",
    "text": "Edge dection\n\nImages Grad YImages Grad XImages Grad Trunc YImages Trunc Grad XCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndst = cv2.Sobel(elderly_gray, cv2.CV_16S, 1, 0,  ksize=3, scale=1, delta=0, borderType= cv2.BORDER_DEFAULT)\ndst1 = np.uint8(255*dst/np.max(dst))\nplt.imshow(dst1, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram",
    "text": "Histogram\n\nHistogramCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram",
    "text": "Histogram\n\nFirst thing to doImageCodeRecommended Reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n3\n2\n2\n1\n1\n0\n3\n0\n1\n\n\n2\n2\n2\n3\n2\n2\n0\n2\n2\n1\n\n\n0\n3\n2\n0\n1\n1\n3\n1\n1\n1\n\n\n3\n0\n2\n0\n2\n3\n1\n0\n2\n1\n\n\n2\n2\n0\n0\n3\n1\n3\n1\n3\n1\n\n\n3\n3\n2\n0\n3\n0\n3\n2\n0\n3\n\n\n3\n3\n1\n1\n2\n3\n0\n3\n1\n3\n\n\n3\n1\n3\n3\n2\n0\n3\n0\n2\n1\n\n\n2\n1\n1\n3\n3\n1\n3\n2\n2\n1\n\n\n0\n3\n2\n2\n1\n1\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\n\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"red\")\nplt.show()\n\n\n\ncv2.calcHist(images, channels, mask, histSize, ranges)\nHelp Docs Opencv"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-3",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram",
    "text": "Histogram\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef adjust_gamma(image, gamma=1.0):\n   invGamma = 1.0 / gamma\n   table = np.array([((i / 255.0) ** invGamma) * 255\n      for i in np.arange(0, 256)]).astype(\"uint8\")\n\n   return cv2.LUT(image, table)\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"red\")\nplt.show()\nelderly_gray_light = adjust_gamma(image=elderly_gray, gamma=2)\nplt.imshow(elderly_gray_light, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_light = cv2.calcHist(elderly_gray_light, [0], None, [256], [0,256])\nplt.plot(elderly_hist_light, color=\"red\")\nplt.show()\nelderly_gray_dark = adjust_gamma(image=elderly_gray, gamma=0.3)\nplt.imshow(elderly_gray_dark, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_dark = cv2.calcHist(elderly_gray_dark, [0], None, [256], [0,256])\nplt.plot(elderly_hist_dark, color=\"red\")\nplt.show()\nelderly_gray_lowcontrast=np.uint8(0.1*elderly_gray)+172\nplt.imshow(elderly_gray_lowcontrast, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_lowcontrast = cv2.calcHist(elderly_gray_lowcontrast, [0], None, [256], [0,256])\nplt.plot(elderly_hist_lowcontrast, color=\"red\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram Equalization",
    "text": "Histogram Equalization\n\n\n\n\n\n\n\nAlgorithm\n\n\n\nCalculate Histogram: Calculate the histogram of the original image, showing the frequency distribution of each intensity level.\nCalculate Cumulative Distribution Function (CDF): Calculate the cumulative distribution function (CDF) of the histogram. The CDF represents the cumulative sum of frequencies for each intensity level.\nEqualization: For each pixel in the original image, calculate the new intensity value using the formula: \\[New_value = (CDF(old value) * (L-1))\\] where L is the number of intensity levels (e.g., 256 for an 8-bit image).\nAssign New Values: Assign the new intensity values calculated in step 3 to the equalized image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram Equalization",
    "text": "Histogram Equalization\n\nImagesCodeRecommended Reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.imshow(elderly_gray_lowcontrast, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\nplt.plot(elderly_hist_lowcontrast, color=\"red\")\nplt.show()\n\nelderly_hist_equ = cv2.equalizeHist(elderly_gray_lowcontrast)\nplt.imshow(elderly_hist_equ, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\nelderly_hist_equ = cv2.calcHist(elderly_hist_equ, [0], None, [256], [0,256])\nplt.plot(elderly_hist_equ, color=\"red\")\nplt.show()\n\n\n\nHistogram Equalization OPENCV tutorial"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-matching",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-matching",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram Matching",
    "text": "Histogram Matching\n\nExplainAlgorithmResultCode\n\n\n\n\n\nTaken from PyImageSearch\n\n\n\n\nStep 1: Calculate Histograms Compute the histograms of the source image (Hs) and target image (Ht) for intensity values (r).\nStep 2: Calculate CDFs Compute the cumulative distribution functions (CDFs) for the source image (CDFs) and target image (CDFt).\nStep 3: Establish Correspondence Find the corresponding intensity values between the source and target images using the inverse CDF of the target image.\nStep 4: Apply Transformation Apply the intensity transformation to the source image using the established correspondence.\nStep 5: Verify Similarity Calculate the mean absolute difference between the transformed source image and the target image to verify their similarity.\n\n\n\n\n\n\n\n\n\n\n\n(-0.5, 1199.5, 799.5, -0.5)\n\n\n\n\n\n\n\n\n\nDiferencia media absoluta: 4.501011458333333\n\n\n\n\n\n# Cargar la imagen fuente y objetivo\nimg_s = cv2.imread('imagen_fuente.jpg')\nimg_t = cv2.imread('imagen_objetivo.jpg')\n\n# Calcula los histogramas\nhist_s = cv2.calcHist([img_s], [0], None, [256], [0, 256])\nhist_t = cv2.calcHist([img_t], [0], None, [256], [0, 256])\n\n# Calcula las CDF\ncdf_s = np.cumsum(hist_s)\ncdf_t = np.cumsum(hist_t)\n\n# Establece la correspondencia\nr_t = np.interp(cdf_s, cdf_t, np.arange(256))\n\n# Aplica la transformación\nimg_t_match = cv2.LUT(img_s, r_t)\n\n# Verifica la similitud\ndiff = np.mean(np.abs(img_t_match - img_t))\n\nprint(f'Diferencia media absoluta: {diff}')"
  },
  {
    "objectID": "presentaciones/PSIM/Lect009_Wavelet_001.html",
    "href": "presentaciones/PSIM/Lect009_Wavelet_001.html",
    "title": "Prueba Quarto",
    "section": "",
    "text": "Encabezado de Prueba\nEsto es un texto de prueba para verificar el funcionamiento básico."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification",
    "text": "Signal Classification"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-bounded",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-bounded",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification – Bounded",
    "text": "Signal Classification – Bounded"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-compact-support",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-compact-support",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification – Compact Support",
    "text": "Signal Classification – Compact Support"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-causal",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-causal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification – Causal",
    "text": "Signal Classification – Causal"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---evenodd",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---evenodd",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification - Even/Odd",
    "text": "Signal Classification - Even/Odd\n\n\n\n\n\n\n\n\n\nEven\n\n\n\\[f\\left(t\\right) = f\\left(-t\\right)\\] \\[f\\left[t\\right] = f\\left[-t\\right]\\]\n\n\n\n\n\n\n\n\n\n\n\nOdd\n\n\n\\[f\\left(t\\right) = -f\\left(-t\\right)\\] \\[f\\left[t\\right] = -f\\left[-t\\right]\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-1",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification",
    "text": "Signal Classification\n\n\n\n\n\n\n\nDecomposition\n\n\nAll signal can be decomposed in two signals: one even, one odd.\n\\[x(t) = x_{even}(t) + x_{odd}(t)\\]\n\n\n\n\nWhere:\n\\[x_{even}(t) = \\frac{x(t)+x(-t)}{2} \\] \\[x_{odd}(t) = \\frac{x(t)-x(-t)}{2} \\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\n\n\n\n\n\n\n\nExample\n\n\nDecompose the signal \\(x(t)=e^{t}\\) into its even and odd parts"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-1",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\n\\[x_{\\text{even}}(t) = \\frac{x(t) + x(-t)}{2}\\]\n\\[x_{\\text{odd}}(t) = \\frac{x(t) - x(-t)}{2}\\]\n\\[x(-t) = e^{-t}\\]\n\\[x_{\\text{even}}(t) = \\frac{e^t + e^{-t}}{2} = \\cosh(t)\\]\n\\[x_{\\text{odd}}(t) = \\frac{e^t - e^{-t}}{2} = \\sinh(t)\\]\n\\[x(t) = x_{\\text{even}}(t) + x_{\\text{odd}}(t)\\]\n\\[e^t = \\cosh(t) + \\sinh(t)\\] ​"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-2",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Transformations",
    "text": "Signal Transformations\nTypes of Transformations\nSignals can undergo two types of transformations:\n\nIndependent variable transformations (affect the time or input axis).\nDependent variable transformations (affect the amplitude or output axis)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#independent-variable-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#independent-variable-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Independent Variable Transformations",
    "text": "Independent Variable Transformations\nTime Scaling\n\nDefinition: Changes the time scale of the signal. [ x(at), a &gt; 1 , &lt; a &lt; 1 ]\nExample: If ( x(t) = (t) ), then ( x(2t) ) is compressed.\n\nTime Shifting\n\nDefinition: Shifts the signal in time. [ x(t - t_0) ]\nExample: ( x(t - 2) ) shifts the signal 2 units to the right.\n\nTime Reversal\n\nDefinition: Flips the signal across the vertical axis. [ x(-t) ]\nExample: If ( x(t) = t^2 ), then ( x(-t) = t^2 ) (even signal)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#dependent-variable-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#dependent-variable-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Dependent Variable Transformations",
    "text": "Dependent Variable Transformations\nAmplitude Scaling\n\nDefinition: Multiplies the amplitude by a scalar factor. [ a x(t), a &gt; 1 , &lt; a &lt; 1 ]\nExample: If ( x(t) = (t) ), then ( 2x(t) ) doubles the amplitude.\n\nAmplitude Shifting\n\nDefinition: Adds a constant value to the amplitude. [ x(t) + c ]\nExample: If ( x(t) = (t) ), then ( x(t) + 2 ) shifts the signal up by 2 units."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#combined-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#combined-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Combined Transformations",
    "text": "Combined Transformations\nExample\nConsider: [ y(t) = 2 x(3t - 1) + 1 ] 1. Time compression: ( x(3t) ) compresses the signal. 2. Time shift: ( x(3t - 1) ) shifts it to the right by 1 unit. 3. Amplitude scaling: ( 2 x(3t - 1) ) amplifies the signal. 4. Amplitude shift: ( +1 ) shifts it upward."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#visualization-example-in-python",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#visualization-example-in-python",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Visualization Example in Python",
    "text": "Visualization Example in Python"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "It is a mathematical algorithm or system that processes digital signals.\nThey enhance, suppress, or modify specific frequency components.\nThese filters are essential for removing noise, extracting relevant information, and improving signal quality."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-1",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Importante\n\n\n\nThe digital filter separates the noise and the information of a discrete signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-2",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Digital Filter – Introduction",
    "text": "Digital Filter – Introduction"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-3",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Suppose a discrete time system\n\\[ y[n] = \\sum_{k=1}^{K} a_k y[n - k] + \\sum_{m=0}^{M} b_m x[n - m]\\]\n\nK y M are the order of the filter.\nWe must know the initial condition."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#examples-of-digital-filters",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#examples-of-digital-filters",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Gain\n\n\n\n\\[y[n] = G x[n]\\]\n\n\n\n\n\n\n\n\nDelay of \\(n_0\\) samples\n\n\n\n\\[y[n] = x[n - n_0]\\]\n\n\n\n\n\n\n\n\nTwo points moving average\n\n\n\n\\[y[n] = \\frac{1}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\nEuler approximation of the derivative\n\n\n\n\\[y[n] = \\frac{x[n] - x[n - 1]}{T_s}\\]\n\n\n\n\n\n\n\n\n\nAveraging over N consecutive epochs of duration L\n\n\n\n\\[y[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} x[n - kL]\\]\n\n\n\n\n\n\n\n\nTrapezoidal integration formula\n\n\n\n\\[y[n] = y[n - 1] + \\frac{T_s}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\nDigital “leaky integrator” (First-order lowpass filter)\n\n\n\n\\[y[n] = a y[n - 1] + x[n], \\quad 0 &lt; a &lt; 1\\]\n\n\n\n\n\n\n\n\nDigital resonator (Second-order system)\n\n\n\n\\[y[n] = a_1 y[n - 1] + a_2 y[n - 2] + b x[n], \\quad a_1^2 + 4a_2 &lt; 0\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#the-impulse-response",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#the-impulse-response",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "The impulse response, denoted as \\(ℎ[n]\\), is the output of a digital filter when the input is a unit impulse function \\(\\delta[n]\\)\nThe impulse response fully describes the system. Given \\(h[n]\\), we can determine the output for any input using convolution.\nDifferent types of filters (low-pass, high-pass, band-pass, etc.) have characteristic impulse responses."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#conditions",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#conditions",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "For a system’s response to be fully described by its impulse response, the system must satisfy the following key conditions.\n\n\n\n\n\n\nLinearity\n\n\n\nIf the system responds to \\(x_1[n]\\) with \\(y_1[n]\\) and to \\(x_2[n]\\) with \\(y_2[n]\\), then:\n\\[y[n] = y_1[n] + y_2[n]\\]\n\n\n\n\n\n\n\n\nHomogeneity\n\n\n\nIf the input is scaled by a constant \\(c\\), the output is also scaled:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } cx[n] \\rightarrow cy[n]\\]\n\n\n\n\n\n\n\n\nTime Invariance\n\n\n\nA system must be time-invariant, meaning a time shift in the input causes the same shift in the output:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } x[n - n_0] \\rightarrow y[n - n_0]\\]\n\n\n\n\n\n\n\n\nCausality\n\n\n\nA causal system is one where the output at time \\(n\\) depends only on present and past inputs:\n\\[h[n] = 0 \\quad \\forall n &lt; 0\\]\n\n\n\n\n\n\n\n\nStability\n\n\n\nIf the impulse response does not satisfy this condition, the system may produce unbounded outputs.\n\\[\\sum_{n=-\\infty}^{\\infty} |h[n]| &lt; \\infty\\]\n\n\n\n\n\n\n\n\nConvolution Representation\n\n\n\nIf all condition met then\n\\[y[n] = x[n] * h[n] = \\sum_{m=-\\infty}^{\\infty} x[m] h[n - m]\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\n\nBio - That came from a biological being\nSignal - A signal is a function that conveys information about a physical phenomenon.\nBiosignals - The search for information from living systems to know its health state"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-1",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\nThe codification of biosignals into variations: * Electrical * Mechanical * Chemical * Thermal"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-2",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-3",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1791: Luigi Galvani discovers electrical signals in living tissues (frog legs)\n1830s: Carlo Matteucci studies electrical signals in the heart\n1887: Willem Einthoven invents the first electrocardiograph (ECG)\n1900s: James Mackenzie develops the first clinical ECG machine"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-1",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1920s: Electroencephalography (EEG) is developed by Hans Berger\n1930s: Electromyography (EMG) is developed by John Humphrey and others\n1940s: Development of the first commercial ECG machines\n1950s: Signal processing techniques are applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-2",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1960s: Digital signal processing and computer analysis of biomedical signals emerge\n1970s: Biomedical signal processing becomes a recognized field\n1980s: Development of Holter monitoring (24-hour ECG)\n1990s: Advances in signal processing and machine learning applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-3",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n2000s: Development of wearable devices and mobile health (mHealth) technologies\n2010s: Emergence of big data analytics and cloud computing in biomedical signal processing\n2020s: Integration of artificial intelligence (AI) and machine learning (ML) in biomedical signal processing"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-4",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-4",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1895: Wilhelm Roentgen discovers X-rays, leading to medical imaging\n1900s: X-ray technology improves with development of modern X-ray tubes\n1913: Albert Salomon develops mammography\n1920s: Ultrasound technology is developed by Karl Dussik and others"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-5",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1930s: Nuclear medicine emerges with development of radioactive tracers\n1950s: Computed Tomography (CT) scans are developed by Godfrey Hounsfield and Allan McLeod Cormack\n1960s: Development of medical ultrasound imaging\n1970s: Magnetic Resonance Imaging (MRI) is developed by Richard Ernst and others"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-6",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-6",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1980s: Digital image processing and analysis techniques are applied to biomedical images\n1990s: Advances in MRI and CT scan technology, including 3D imaging\n2000s: Development of functional MRI (fMRI), diffusion tensor imaging (DTI), and other advanced MRI techniques\n2010s: Emergence of artificial intelligence (AI) and machine learning in medical imaging"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-7",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-7",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nAdditional Milestones:\n\n1950s: Development of medical electronics and instrumentation\n1960s: First medical imaging computers are developed\n1970s: Development of digital image processing and analysis software\n1980s: Emergence of medical imaging informatics and PACS (Picture Archiving and Communication Systems)\n1990s: Development of telemedicine and teleradiology\n2000s: Emergence of electronic health records (EHRs) and health information exchanges (HIEs)\n2010s: Development of personalized medicine and precision health initiatives"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#periodic-functions",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#periodic-functions",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Periodic functions",
    "text": "Periodic functions\n\n\n\n\n\n\n\n\nDefinition\n\n\nAny signal that meets any of this conditions \\[x\\left(t\\right)=x\\left(t + kT\\right)\\] \\[x\\left[n\\right]=x\\left[t + kT\\right]\\]\n\n\n\n\nWhere \\(k\\in\\mathbb{z}\\) and \\(T\\in\\mathbb{R}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#sum-of-two-periodic-signals",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#sum-of-two-periodic-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sum of Two Periodic Signals",
    "text": "Sum of Two Periodic Signals\nIf \\(\\( x_1(t) \\)\\) and \\(\\( x_2(t) \\)\\) are periodic with periods \\(\\( T_1 \\)\\) and \\(\\( T_2 \\)\\):\n\\[\nx_1(t + T_1) = x_1(t), \\quad x_2(t + T_2) = x_2(t)\n\\]\nThe sum of both signals is:\n\\[\nx(t) = x_1(t) + x_2(t)\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#condition-for-the-periodicity-of-the-sum",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#condition-for-the-periodicity-of-the-sum",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Condition for the Periodicity of the Sum",
    "text": "Condition for the Periodicity of the Sum\nFor \\(\\( x(t) \\)\\) to be periodic, there must exist a common period \\(\\( T \\)\\) such that:\n\\[\nT = k_1 T_1 = k_2 T_2\n\\]\nwhere ( k_1, k_2 ) are positive integers."
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#common-period-and-least-common-multiple",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#common-period-and-least-common-multiple",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Common Period and Least Common Multiple",
    "text": "Common Period and Least Common Multiple\nThe smallest common period is the least common multiple (lcm) of \\(\\( T_1 \\)\\) and \\(\\( T_2 \\)\\):\n\\[\nT = \\operatorname{lcm}(T_1, T_2)\n\\]\nIf the ratio of the periods is a rational number:\n\\[\n\\frac{T_1}{T_2} \\in \\mathbb{Q}\n\\]\nThen, the sum \\(\\( x_1(t) + x_2(t) \\)\\) will be periodic.\nIf the ratio is irrational, the resulting signal will not be periodic."
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#example",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "href": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Methodology for designing an edge ai device",
    "text": "Methodology for designing an edge ai device\n\nProblem Definition & Use Case Analysis\nData Collection & Preprocessing\nModel Selection & Optimization\nHardware Selection\nDeployment & Model Inference\nTesting, Validation, and Continuous Improvement\nFinal Deployment & Scaling"
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Problem Definition & Use Case Analysis",
    "text": "Problem Definition & Use Case Analysis\n\nIdentify the specific AI task (e.g., real-time ECG analysis, fall detection, predictive maintenance in IoT).\nDetermine operational constraints, including:\n\nPower consumption (battery-operated vs. wired).\nLatency requirements (real-time processing vs. periodic updates).\nCommunication needs (Wi-Fi, Bluetooth, LoRa, standalone processing)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Collection & Preprocessing",
    "text": "Data Collection & Preprocessing\n\nSensor Selection: Choose sensors relevant to the application (e.g., accelerometers for motion tracking, biosensors for health monitoring).\nEdge-Compatible Data Acquisition: Optimize data formats to reduce memory and computational load.\nPreprocessing on Edge:\n\nSignal filtering (e.g., noise reduction in biomedical signals).\nFeature extraction (e.g., time-series features for motion classification)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Model Selection & Optimization",
    "text": "Model Selection & Optimization\n\nModel Selection:\n\nLightweight CNNs (for image processing).\nRecurrent Neural Networks (RNNs) / LSTMs (for time-series data like ECG).\nTinyML models optimized for microcontrollers (e.g., TensorFlow Lite, PyTorch Mobile).\n\nModel Optimization for Edge Deployment:\n\nQuantization: Convert floating-point models to int8 or int16 to reduce size and computation load.\nPruning: Remove unnecessary neurons or layers while preserving accuracy.\nDistillation: Train a smaller model using knowledge from a larger one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Hardware Selection",
    "text": "Hardware Selection\n\nProcessing Unit:\n\nMicrocontrollers (MCUs) (e.g., ARM Cortex-M, ESP32) → Low-power, simple AI tasks.\nEdge AI Accelerators (e.g., Google Edge TPU, NVIDIA Jetson Nano) → More complex AI processing.\nFPGAs (Field-Programmable Gate Arrays) → Custom AI workloads for high-speed processing.\n\nMemory & Storage:\n\nRAM Optimization: Choose embedded SRAM or external DRAM depending on model size.\nFlash Storage: Store inference models efficiently.\n\nConnectivity:\n\nOffline processing for low-latency applications.\nEdge-to-cloud integration for periodic updates."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Deployment & Model Inference",
    "text": "Deployment & Model Inference\n\nConvert trained AI models into optimized edge-compatible formats (e.g., TensorFlow Lite, ONNX).\nImplement real-time inference using hardware-accelerated libraries (e.g., TensorRT, OpenVINO).\nOptimize firmware for energy efficiency using duty-cycling techniques (process only when necessary)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Testing, Validation, and Continuous Improvement",
    "text": "Testing, Validation, and Continuous Improvement\n\nEdge Benchmarking:\n\nMeasure inference speed and power consumption.\nValidate model accuracy on real-world edge-generated data.\n\nSecurity & Reliability:\n\nImplement secure boot & firmware updates to prevent cyber threats.\nEnsure robust error handling for sensor malfunctions.\n\nFeedback & Model Updating:\n\nIf connected to a cloud system, update models periodically using federated learning.\nOptimize AI pipelines with incremental learning on-device where feasible."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Final Deployment & Scaling",
    "text": "Final Deployment & Scaling\n\nDeploy at scale, ensuring the Edge AI model adapts to different environments.\nImplement remote monitoring & diagnostics for predictive maintenance.\nEnable over-the-air (OTA) updates to improve AI models post-deployment."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "href": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Abstract",
    "text": "Abstract\nThe hardware-software co-design approach is the most widely used methodology for Edge AI device development. It ensures:\n\nReal-time performance with optimized AI models.\nEnergy-efficient processing for battery-operated or low-power devices.\nScalability and security in edge environments.\n\nThis methodology is industry-standard and used by leading companies in healthcare, automotive, and industrial IoT, ensuring robust and reliable Edge AI solutions."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "href": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Example of application",
    "text": "Example of application\n\n\n\n\n\n\n\nUse case\n\n\nA wearable ECG monitoring device designed for continuous heart health tracking and arrhythmia detection. This Edge AI-based solution analyzes ECG signals in real-time on a low-power microcontroller, providing instant alerts for cardiac irregularities without relying on cloud computing."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 1: Problem Definition & Use Case Analysis",
    "text": "Step 1: Problem Definition & Use Case Analysis\n\n\n\n\n\n\n\nObjective\n\n\nDetect abnormal heart rhythms (arrhythmias) in real-time using a wearable ECG device.\n\n\n\n\nOperational Constraints:\n\nMust be energy-efficient (battery-operated, low power consumption).\nNeeds real-time inference for immediate alerts.\nShould operate offline, but sync with mobile apps for periodic review.\n\nKey Challenges:\n\nProcessing ECG data on a low-power Edge device.\nMinimizing false positives/negatives in arrhythmia detection.\nEnsuring high reliability and accuracy."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 2: Data Collection & Preprocessing",
    "text": "Step 2: Data Collection & Preprocessing\nSensor Selection:\n\nECG sensor (e.g., AD8232) captures raw heart signals.\nAccelerometer (optional) for motion artifacts reduction.\n\nEdge-Compatible Data Acquisition:\n\nSample rate: 250 Hz (sufficient for arrhythmia detection).\nUse on-device filtering (low-pass filters) to remove noise.\n\nPreprocessing on Edge:\n\nApply Butterworth filters for noise reduction.\nR-peak detection using Pan-Tompkins algorithm for heart rate calculation.\nExtract features like RR intervals, QRS width, and HR variability."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 3: Model Selection & Optimization",
    "text": "Step 3: Model Selection & Optimization\nAI Model:\n\nUse 1D CNN + LSTM hybrid model (efficient for ECG signal processing).\nTrain the model using MIT-BIH Arrhythmia Database.\n\nModel Optimization for Edge AI:\n\nQuantization: Convert model to int8 precision using TensorFlow Lite.\nPruning: Remove redundant neurons to reduce computation load.\nKnowledge Distillation: Train a smaller model from a high-performing one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 4: Hardware Selection",
    "text": "Step 4: Hardware Selection\nMicrocontroller (MCU):\n\nNordic nRF52840 (low-power ARM Cortex-M4 + BLE connectivity).\nAlternative: ESP32 (for low-cost AI inference).\n\nMemory & Storage:\n\nRAM: 512KB (optimized for Edge AI processing).\nFlash storage: 4MB (stores ECG data logs for later analysis).\n\nConnectivity:\n\nBluetooth Low Energy (BLE) for periodic sync with mobile apps.\nCan function offline with real-time alerts."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 5: Deployment & Model Inference",
    "text": "Step 5: Deployment & Model Inference\n\nConvert trained TensorFlow model → TensorFlow Lite for Edge AI inference.\nDeploy on the Nordic nRF52840 MCU using TensorFlow Lite for Microcontrollers.\nUse hardware-accelerated inference for efficient processing.\nImplement event-driven processing (AI runs only on abnormal detections to save power)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 6: Testing, Validation, and Continuous Improvement",
    "text": "Step 6: Testing, Validation, and Continuous Improvement\nEdge Benchmarking:\n\nReal-time inference latency: &lt;10 ms per ECG segment.\nPower consumption: 5mW (optimized for long battery life).\n\nSecurity & Reliability:\n\nSecure Boot & Firmware Updates to prevent hacking.\nAdaptive AI Models: Learns individual patient heart patterns to reduce false alarms.\n\nFeedback & Model Updating:\n\nSync detected arrhythmia events with a cloud server for validation.\nUse federated learning to improve AI models without sharing raw patient data."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 7: Final Deployment & Scaling",
    "text": "Step 7: Final Deployment & Scaling\n\nMass production of the device for hospitals, clinics, and home use.\nIntegration with mobile apps for patient-doctor communication.\nRegulatory Approval: Submit for FDA/CE certification for medical device compliance.\nOver-the-Air (OTA) Updates: Allow model updates based on new ECG patterns."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Linux",
    "text": "What is Linux\n\nDefinition: Linux is a free, open-source operating system (OS) based on Unix, created by Linus Torvalds in 1991.\nKey Features:\n\nOpen-source: Anyone can view, modify, and distribute the source code.\nFree to use: No licensing fees.\nMulti-user and multitasking.\n\nStructure: Comprises a kernel (core of the OS) and various utilities."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\nControls the hardware.\nTypes of linux kernel\n\nMonolithic kernel: All the concurrent processes are executed simultaneously in the kernel itself. All the processes share same memory recourses.\nMicro kernel: user services and kernel services are executed in separate address spaces. User services are kept in user address space and kernel services are kept in kernel address space.\nHybrid kernel: this kernel has the monolithic speed and the stability of the micro.\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nShell\n\n\nThe shell serves as an interface to the kernel, acting as a bridge between the user and the system’s core operations. It hides the internal workings of the kernel, allowing users to perform tasks without needing to understand the underlying processes. Users simply enter a command, and the shell leverages the kernel’s functions to execute the specified task.\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "href": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Why is Linux Popular?",
    "text": "Why is Linux Popular?\n\nFlexibility: Runs on a wide range of devices (PCs, servers, smartphones, embedded systems).\nSecurity: Highly secure and less vulnerable to malware.\nCommunity Support: Strong open-source community for development and troubleshooting.\nCustomization: Highly configurable; users can tailor it to specific needs.\nPerformance: Efficient resource utilization, ideal for servers and low-end devices."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Linux vs Other Operating Systems",
    "text": "Linux vs Other Operating Systems\n\n\n\n\n\n\n\n\n\nFeature\nLinux\nWindows\nmacOS\n\n\n\n\nCost\nFree\nPaid\nPaid\n\n\nSource Code\nOpen-source\nProprietary\nProprietary\n\n\nSecurity\nHighly secure\nVulnerable to malware\nSecure\n\n\nCustomization\nHigh\nLow\nLow\n\n\nUsage\nServers, DevOps, IoT\nDesktop, Gaming\nCreative industries"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Linux Distributions",
    "text": "Linux Distributions\n\nWhat are Distributions (Distros)?\nVariants of Linux tailored for specific purposes.\nPopular Distros:\n\nUbuntu: User-friendly, great for beginners.\nDebian: Stable and widely supported.\nFedora: Cutting-edge technologies.\nCentOS/Red Hat: Enterprise-level stability.\nKali Linux: Security and penetration testing."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Applications of Linux",
    "text": "Applications of Linux\n\nEveryday Use: Desktops and laptops (e.g., Ubuntu, Mint).\nServers: Powers most web servers, databases, and cloud infrastructure.\nEmbedded Systems: Used in IoT devices, routers, and automotive systems.\nSupercomputers: Runs on 100% of the top 500 supercomputers.\nProgramming & Development: Preferred OS for software developers."
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Linear Regression",
    "text": "Linear Regression"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Linear Regression",
    "text": "Linear Regression\nIn the example, in previous slide, data was modelled as a linear function. The difference (error) between the modelled data \\(\\left( \\hat{y}_n \\right)\\) and actual data \\(\\left( y_n \\right)\\) can be written as\n\n\n\n\n\n\n\nCost function\n\n\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Some other examples of cost function",
    "text": "Some other examples of cost function\n\\[E = \\sqrt{\\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}}\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left| \\hat{y}_n - y_n \\right| }\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nLooking the cost surface, we notices that this surface has a global minimum. If we could have an algorithm which automatically finds it.\n\nCost Surface"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nIndeed, there are multiples algorithms for minima searching. The most famous is the one named as least squares but in this course we will use the gradient descent algorithm.\nAssuming that the data model is a function \\(f\\left(\\theta_i, x_n, y_n\\right)\\), where \\(\\theta\\) is known as model parameter.\n\n\n\n\n\n\n\nThe gradient descent algorithm\n\n\n\\[\\boldsymbol{\\theta}_{i,j+1} =  \\boldsymbol{\\theta}_{i,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{i}}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\nAssumptions\n\n\n\nLinear model for the Regression\nMean square error as cost function\n\\(\\eta = 1\\)\n\n\n\n\n\n\\[\\boldsymbol{\\theta}_i = \\left[ \\theta_1, \\theta_0 \\right]^T\\]\n\\[\\hat{y}_n  = \\theta_1 x_n + \\theta_0\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_1\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{1,j+1} = \\boldsymbol{\\theta}_{1,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right) x_n}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_0\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{0,j+1} = \\boldsymbol{\\theta}_{0,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  E & = & \\frac{1}{N} \\sqrt{u}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{1}{2 N \\sqrt{u}} \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}}\\\\\n  \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}} &=& 2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{2 N \\sqrt{u}}\n\\end{eqnarray}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} &=& \\frac{\\sum_{n=1}^{N}{x_n \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{2}} &=& \\frac{\\sum_{n=1}^{N}{x_n^2 \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\n\\end{eqnarray}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nSuposse…\n\n\nA dataset of M tuples \\((\\mathbf{x}_i, \\mathbf{y}_i)\\) with i = 1, …, M.\n\n\\(\\mathbf{x}_i\\): Inputs\n\\(\\mathbf{y}_i\\): Outputs\n\n\n\n\n\n\n\n\n\n\n\n\nWhat it is a neural network\n\n\nIs a mathematical function (sometimes called a network function) that takes some kind of input (typically multi-dimensional) called x iand generate some output."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nNetwork function\n\n\n\nThe output generated by the network function is called \\(\\hat{y}_i\\)\nThe network function normally depends on a certain number N of parameters, which we will indicate with \\(\\mathbf{\\theta}_k\\) \\[ \\mathbf{\\hat{y}}_i = f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), where, k=0,1,2,\\ldots,N \\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nImportante\n\n\nA neural network is nothing more than a mathematical function that depends on a set of parameters that are tuned, hopefully in some smart way, to make the network output as close as possible to some expected output.\n\n\n\n\n\n\n\n\\(\\mathbf{x}_i \\in \\mathbb{R}^n\\)\n\\(\\mathbf{y}_i \\in \\mathbb{R}^k\\)\n\\(i = 0,1,2,\\ldots,M\\)\n\\(\\mathbf{\\theta}_k \\in \\mathbb{R}^N\\)\n\\(k = 0,1,2,\\ldots,N\\)\n\n\n\nLoss function \\(L \\left( \\mathbf{\\hat{y}}_i, \\mathbf{y}_i \\right) = L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\)\nLoss function measures how close are \\(\\mathbf{\\hat{y}}_i\\) and \\(\\mathbf{y}_i\\)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nLearning\n\n\n\n$ _{_k ^N} L ( f ( _k, _i ), _i ) $\n\\(\\min_{\\mathbf{\\theta}_k \\in \\mathbb{R}^N} L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\) subject to \\(c_q, q=1,2,3,\\ldots,Q\\) with \\(Q \\in \\mathbb{N}\\)\nThe learning process is the search of a minima. However, most of the algorithms can search only a “local” minima.\nIn principle, we want to find the global minimum or, in other words, the point for which the function value is the smallest between all possible points.\n\n\n\n\n\n\nIdentifying if the minimum is a local or a global minimum is impossible, due to the network function complexity.\nThis is one (albeit not the only one) of the reasons that training large neural networks is such a challenging numerical problem."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "A single neuron",
    "text": "A single neuron"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Neural Network",
    "text": "Neural Network"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Neural Network",
    "text": "Neural Network\n\nTaken from GeeksforGeeks"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\nNeural Networks have a great number of internal parameters for learning; which varying in a vast range of values.\nThis number of parameters is fundamental for neural network knowledge representation\n\n\n\n\n\n\n\nProblem\n\n\nBut if this number increases too much the neural network is prone to overfitting"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\n\n\n\n\n\n\nDefinition\n\n\nRegularization techniques reduce the possibility of a neural network overfitting by constraining the range of values that the weight values within the network hold.\n\n\n\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\nRegularization works on assumption that smaller weights generate simpler model and thus helps avoid overfitting.\nThe simpler model is less prone to overfitting.\nAdding the regularization term to the sum of squared differences between the actual value and predicted value."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k\n\\end{eqnarray}\\]\n\n\n\n\n\n\n\nNota\n\n\n\\(\\lambda\\) is the penalty term or regularization parameter which determines how much to penalizes the weights."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Types of Regularization",
    "text": "Types of Regularization\n\n\nL1 Regularization or Lasso or L1 norm\n\nL1 penalizes sum of absolute value of weights.\nL1 has a sparse solution.\nL1 has multiple solutions.\nL1 has built in feature selection.\nL1 is robust to outliers.\nL1 generates model that are simple and interpretable but cannot learn complex patterns.\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\lvert \\theta_k \\rvert\n\\end{eqnarray}\\]\n\nL2 Regularization or Ridge Regularization\n\nL2 regularization penalizes sum of square weights.\nL2 has a non sparse solution\nL2 has one solution\nL2 has no feature selection\nL2 is not robust to outliers\nL2 gives better prediction when output variable is a function of all input features\nL2 regularization is able to learn complex data patterns\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation",
    "text": "Evaluation\n\n\n\n\n\n\n\nRegression\n\n\n\n\\(R^2\\)\nResidual graph\nAutocorrelation analysis\n\n\n\n\n\n\n\n\n\n\n\n\nClassification\n\n\n\nConfusion Matrix(Matriz de Confusión)\nPrecision(Precisión)\nRecall(Exhaustividad)\nF1-score(Valor-F)\nAccuracy(Exactitud)\nTrue Positive(Positivos Verdaderos)\nTrue Negative(Negativos Verdaderos)\nFalse Positive(Positivos Falsos)\nFalse Negative(Negativos Falsos)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nConfusion Matrix\n\n\n“Also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one.”"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nTrue Negative\n\n\nValues that being negative have been classified as negative\n\n\n\n\n\n\n\n\n\n\n\nTrue Positive\n\n\nValues that being positive have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Positive\n\n\nValues that being negative have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Negative\n\n\nValues that being negative have been classified as positive"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nSensitivity\n\n\nHow good is my classifier at detecting positive cases? \\[ \\frac{TP}{TP+FN} \\]\n\n\n\n\n\n\n\n\n\n\n\nSpecificity\n\n\nHow good is my classifier at avoiding negative cases? \\[ \\frac{TN}{TN+FP} \\]\n\n\n\n\n\n\n\n\n\n\n\n\nPrecision\n\n\nHow credible is my classifier when it detects a positive case? \\[\\frac{TP}{TP+FP}\\]\n\n\n\n\n\n\n\n\n\n\n\nAccuracy and Balance Accuracy\n\n\nHow many cases the classifier correctly identifies? \\[Accuracy = \\frac{TP+TN}{TP+FP+FN+TN}\\] \\[BalancedAccuracy = \\frac{Specificity+Sensitivity}{2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nPrevalence\n\n\nHow often does the positive condition actually occur in our sample? \\[\\frac{TP+FN}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nDetection Rate\n\n\nPercentage of true positives \\[\\frac{TP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nDetection Prevalence\n\n\nPercentage of positives \\[\\frac{TP+FP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nHarmonic mean of recall and precision.\n\n\n\\[2\\frac{\\left( Precision \\right) \\left( Sensitivity \\right)}{Precision+Sensitivity}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 1"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 2"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\n\n\nFor Class 3"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Sistemas y Señales Biomédicoss en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n17 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n22 ene 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura análisis numérico.\n\n\n\n1 jul 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso de Probabilidad computacional y estadística.\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#clases",
    "href": "index.html#clases",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Sistemas y Señales Biomédicoss en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n17 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n22 ene 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura análisis numérico.\n\n\n\n1 jul 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso de Probabilidad computacional y estadística.\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#tutoriales",
    "href": "index.html#tutoriales",
    "title": "PECR Knowledge Hub",
    "section": "Tutoriales",
    "text": "Tutoriales\n\n\n\n\n\n\n\n\n\n\nPython programming\n\n\nA small tutorial in python in slides\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMicrobit – El minicomputador\n\n\nTutorial: Electrónica Básica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMicrobit – El minicomputador\n\n\nTutorial: Electrónica Básica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial de Python\n\n\nBreve Tutorial de Python\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputación de seno y coseno usando expansión de Taylor\n\n\nUn ejemplo de clase del cálculo de una serie de Taylor sin uso de librerías especiales de Python – En construcción –\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#proyectos",
    "href": "index.html#proyectos",
    "title": "PECR Knowledge Hub",
    "section": "Proyectos",
    "text": "Proyectos\n\n\n\n\n\n\n\n\n\n\nPredictive modeling for seizure detection in pharmacoresistant epilepsy: a machine learning approach\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html",
    "title": "Estudio de arritmia cardíaca",
    "section": "",
    "text": "#from google.colab import drive\n#drive.mount('/content/drive')"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librerías",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librerías",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de librerías",
    "text": "Carga de librerías\n\nnumpy: Para manipulación numérica y funciones estadísticas básicas\nmatplotlib.pyplot: Para generación de gráficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.signal as sig"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#configuración-de-carpetas",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#configuración-de-carpetas",
    "title": "Estudio de arritmia cardíaca",
    "section": "Configuración de carpetas",
    "text": "Configuración de carpetas\n\n# data_path = \"/content/drive/MyDrive/ECG_Dataset/\"#Datapath de colab\ndata_path = \"../../data/\""
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\n\n\n\n\n\n\n\n\n\nfs =  500\n\nfc1 = 0.5\nfc2 = 50\norder_fir = 51\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import freqz, windows\n\n\n# Definir el vector de frecuencias\nf_vect = np.linspace(-fs//2, fs//2, order_fir)\n\n# Definir la respuesta en frecuencia deseada\nH1 = np.zeros(len(f_vect))\nH1[(((f_vect &gt;= 0.5) & (f_vect &lt;= 50)) | ((f_vect &lt;= -0.5) & (f_vect &gt;= -50)))] =  1  # Banda de paso entre 0.5 y 50 Hz\n\nplt.figure(figsize=(10,6))\nplt.plot(f_vect, H1)\n\n# Normalizar las frecuencias con respecto a Nyquist (fs/2)\nnormalized_frequencies = f_vect / (fs / 2)\n\n# Interpolación de la respuesta deseada\nH_interp = np.interp(np.linspace(0, 1, order_fir), normalized_frequencies, H1)\n\n# Transformada Inversa de Fourier para obtener la respuesta al impulso\nh = np.fft.ifft(H_interp, order_fir).real  # Solo tomamos la parte real\n\n# Aplicar ventana de Hamming\nwindow = windows.hamming(order_fir)\nh_windowed = h * window\n\n# Normalizar la energía del filtro\nh_windowed /= np.sum(h_windowed)\n\n# Calcular la respuesta en frecuencia\nw, H_fir = freqz(h_windowed, worN=2048, fs=fs)\n\n# Graficar la respuesta al impulso\nplt.figure(figsize=(12, 5))\nplt.stem(h_windowed, basefmt=\"C0\")\nplt.title(\"Respuesta al Impulso del Filtro FIR con Especificación en Frecuencia\")\nplt.xlabel(\"n (muestras)\")\nplt.ylabel(\"h[n]\")\nplt.grid()\nplt.show()\n\n# Graficar la respuesta en frecuencia\nplt.figure(figsize=(12, 6))\nplt.subplot(2, 1, 1)\nplt.plot(w, 20 * np.log10(abs(H_fir)), \"b\")\nplt.title(\"Respuesta en Frecuencia - Magnitud\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Magnitud [dB]\")\nplt.grid()\n\nplt.subplot(2, 1, 2)\nplt.plot(w, np.angle(H_fir), \"g\")\nplt.title(\"Respuesta en Frecuencia - Fase\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Fase [radianes]\")\nplt.grid()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import firls, freqz\n\n# Parámetros del filtro\nfs = 500  # Frecuencia de muestreo en Hz\nN = 51  # Número de coeficientes del filtro (impar para centrar en cero)\n\n# Definir las bandas y la respuesta deseada\nbands = [0, 0.5, 50, fs / 2]  # Frecuencias en Hz\ndesired = [0, 10, 10, 0]  # Pasa-banda de 0.5 Hz a 50 Hz\n\n# Diseñar el filtro FIR con firls\nh_firls = firls(N, bands, desired, fs=fs)\n\n# Calcular la respuesta en frecuencia\nw, H_fir = freqz(h_firls, worN=2048, fs=fs)\n\n# Graficar la respuesta al impulso\nplt.figure(figsize=(12, 5))\nplt.stem(h_firls, basefmt=\"C0\")\nplt.title(\"Respuesta al Impulso del Filtro FIR con firls\")\nplt.xlabel(\"n (muestras)\")\nplt.ylabel(\"h[n]\")\nplt.grid()\nplt.show()\n\n# Graficar la respuesta en frecuencia\nplt.figure(figsize=(12, 6))\nplt.subplot(2, 1, 1)\nplt.plot(w, 20 * np.log10(abs(H_fir)), \"b\")\nplt.title(\"Respuesta en Frecuencia - Magnitud\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Magnitud [dB]\")\nplt.grid()\n\nplt.subplot(2, 1, 2)\nplt.plot(w, np.angle(H_fir), \"g\")\nplt.title(\"Respuesta en Frecuencia - Fase\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Fase [radianes]\")\nplt.grid()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html",
    "href": "codigo/PSIM/cod001_signal_conditioning.html",
    "title": "Paginas importantes",
    "section": "",
    "text": "https://www.nature.com/articles/s41597-020-0386-x\nhttps://physionet.org/content/ecg-arrhythmia/1.0.0/"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librerías",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librerías",
    "title": "Paginas importantes",
    "section": "Carga de librerías",
    "text": "Carga de librerías\n\nnumpy: Para manipulación numérica y funciones estadísticas básicas\nmatplotlib.pyplot: Para generación de gráficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\nscipy.signal: Para análisis de señales de la librería SCIPY\nscipy.optimize: Para realizar el ajuste de curva\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.signal as signal\nfrom scipy.signal import freqz, butter, cheby1, firwin\nfrom scipy.optimize import curve_fit"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#configuración-de-carpetas",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#configuración-de-carpetas",
    "title": "Paginas importantes",
    "section": "Configuración de carpetas",
    "text": "Configuración de carpetas\n\ndata_path = \"/content/drive/MyDrive/ECG_Dataset/\""
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "title": "Paginas importantes",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\nplt.plot(f_vect1, mag_ecg_fft1**2)\nplt.grid()\n\n\n\n\n\n\n\n\n\nfs = 500\nfcut = 50\norder = 4\n\nf_corte = fcut/(fs/2)\n\nb, a = signal.butter(order, f_corte, \"lowpass\")\n\n\ndef plot_filter_response(b, a=1, fs=1.0):\n    \"\"\"Grafica la respuesta en frecuencia de un filtro dado.\"\"\"\n    w, h = freqz(b, a, worN=2048, fs=fs)  # Calcula la respuesta en frecuencia\n\n    # Magnitud de la respuesta en frecuencia\n    plt.figure(figsize=(10, 6))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(w, 20 * np.log10(abs(h)), \"b\")\n    plt.title(\"Respuesta en Frecuencia del Filtro\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Magnitud [dB]\")\n    plt.grid()\n\n    # Fase de la respuesta en frecuencia\n    plt.subplot(2, 1, 2)\n    plt.plot(w, np.angle(h), \"g\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Fase [radianes]\")\n    plt.grid()\n\n    plt.tight_layout()\n    plt.show()\n\n\n# Parámetros del filtro\nfs = 1000  # Frecuencia de muestreo en Hz\ncutoff = 200  # Frecuencia de corte en Hz\norder = 4  # Orden del filtro\n\n# Filtro IIR Butterworth\nb_iir, a_iir = butter(order, cutoff, fs=fs, btype=\"low\", analog=False)\nprint(\"Filtro IIR Butterworth\")\nplot_filter_response(b_iir, a_iir, fs=fs)\n\n# Filtro FIR (ventana de Hamming)\nnumtaps = 50  # Número de coeficientes del FIR\nb_fir = firwin(numtaps, cutoff, fs=fs, window=\"hamming\")\nprint(\"Filtro FIR (Ventana de Hamming)\")\nplot_filter_response(b_fir, fs=fs)\n\n\necg_filt_1 = signal.lfilter(b, a, lead_10)\necg_filt_2 = signal.filtfilt(b, a, lead_10) # No causal.\n\n\nplt.plot(t, ecg_filt_1)\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nmag_ecg_filt = np.abs(np.fft.fft(ecg_filt_2))[:np.uint(N/2)]\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.plot(f_vect1, mag_ecg_filt)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\ndef modelo_artefacto(time, p0, p1, p2, p3, p4):\n  return p0+p1*np.sin(p2*time)+p3*np.cos(p4*time)\n\n\npopt, pcov = curve_fit(modelo_artefacto, t, ecg_filt_2)\n\n\npopt[1]\n\n152.2437794044702\n\n\n\nplt.plot(t, modelo_artefacto(t, *popt))\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2-modelo_artefacto(t, *popt))"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "",
    "text": "La leucemia linfoblástica aguda (LLA) es un tipo de cáncer hematológico caracterizado por la proliferación descontrolada de linfoblastos inmaduros en la médula ósea, la sangre y otros órganos. Este trastorno impide la producción adecuada de células sanguíneas normales, lo que provoca síntomas como anemia, infecciones recurrentes y sangrados anormales. [1]\nEl cáncer es una de las principales causas de mortalidad entre niños y adolescentes en todo el mundo; cada año se diagnostica cáncer a aproximadamente 274.000 niños de entre 0 y 19 años. [2]\nEn América Latina y el Caribe, se estima que alrededor de 30.000 niñas, niños y adolescentes menores de 19 años resultarán afectados por el cáncer anualmente. De ellos, casi 10.000 fallecerán a causa de esta enfermedad.\nEn los países de ingresos altos, más del 80% de los niños afectados de cáncer se curan, pero en muchos países de ingresos medianos y bajos la tasa de curación es de aproximadamente el 20%.[3]\nLas defunciones evitables debidas a los cánceres infantiles en los países de ingresos medianos y bajos se producen a consecuencia de la falta de diagnóstico, los diagnósticos incorrectos o tardíos, las dificultades para acceder a la atención sanitaria, el abandono del tratamiento, la muerte por toxicidad y las mayores tasas de recidivas. [3]"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#significado-en-el-contexto-del-modelo",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#significado-en-el-contexto-del-modelo",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Significado en el Contexto del Modelo",
    "text": "Significado en el Contexto del Modelo\n\nCombinación Lineal\n\nCada característica \\(x_i\\) se pondera por su importancia relativa \\(\\theta_i\\)\nEl término independiente \\(\\theta_0\\) añade un sesgo base\n\nInterpretación de los Coeficientes\n\n\\(\\theta_i &gt; 0\\): La característica aumenta la probabilidad de leucemia\n\\(\\theta_i &lt; 0\\): La característica disminuye la probabilidad de leucemia\n\\(|\\theta_i|\\): Magnitud del impacto de la característica\n\nFlujo del Modelo\n\\[\nX\\theta \\xrightarrow{\\text{producto punto}} z \\xrightarrow{\\text{sigmoide}} h_\\theta(x) = \\frac{1}{1 + e^{-z}}\n\\]\nResultado\n\n\\(z\\): Puntuación lineal (puede ser cualquier número real)\n\\(h_\\theta(x)\\): Probabilidad entre 0 y 1 después de aplicar la sigmoide\n\n\nLa regularización L1 (también conocida como LASSO - Least Absolute Shrinkage and Selection Operator) es una técnica para prevenir el sobreajuste (overfitting).\n\n¿Qué es la regularización L1?\nEs un término que se añade a la función de costo:\n\\[\n\\frac{\\lambda}{m} \\sum_{j=1}^{n} |\\theta_j|\n\\]\nDonde:\n- λ (lambda) es el parámetro que controla la fuerza de la regularización\n- m es el número de muestras\n- θj son los parámetros del modelo\n- |θj| es el valor absoluto de cada parámetro\n\n\n¿Por qué se implementa?\n\nPrevención de sobreajuste:\n\nPenaliza coeficientes muy grandes que podrían hacer que el modelo se ajuste demasiado a los datos de entrenamiento\nAyuda al modelo a generalizar mejor con nuevos datos\n\nSelección de características:\n\nLa regularización L1 tiende a producir coeficientes exactamente iguales a cero\nEsto efectivamente selecciona las características más importantes y descarta las menos relevantes\n\n\n\n\nEfectos prácticos:\n\nCon lambda_reg = 0:\n\nNo hay regularización\nEl modelo puede sobreajustarse\n\nCon lambda_reg pequeño (ej: 0.1):\n\nRegularización suave\nBalance entre ajuste y generalización\n\nCon lambda_reg grande (ej: 10):\n\nRegularización fuerte\nMás coeficientes se vuelven cero\nModelo más simple pero puede subajustarse (underfitting)\n\n\n\n\nVentajas:\n\nSelección automática de características más relevantes para detectar leucemia\nReducción del ruido en las mediciones de células\nModelo más robusto y generalizable a nuevas muestras\nInterpretabilidad mejorada al identificar las características más importantes"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#área-del-contorno",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#área-del-contorno",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "1. Área del Contorno",
    "text": "1. Área del Contorno\nEl área de un contorno cerrado se calcula utilizando la fórmula del área de un polígono mediante coordenadas:\n\\[\n\\text{Área} = \\frac{1}{2} \\sum_{i=1}^{n} (x_i y_{i+1} - y_i x_{i+1})\n\\]\nDonde:\n- \\(n\\) : Número total de puntos en el contorno\n- \\((x_i, y_i)\\) : Coordenadas del punto \\(i\\) del contorno\n- \\((x_{i+1}, y_{i+1})\\) : Coordenadas del siguiente punto en el contorno\n- El punto \\(n+1\\) se considera igual al punto 1, cerrando el polígono\nEsta fórmula:\n- Utiliza el método de triangulación para calcular el área\n- Funciona para cualquier polígono cerrado, sea cóncavo o convexo\n- El resultado es positivo si los puntos están ordenados en sentido antihorario\n- El valor absoluto del resultado da el área real"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#perímetro-del-contorno",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#perímetro-del-contorno",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "2. Perímetro del Contorno",
    "text": "2. Perímetro del Contorno\nEl perímetro se calcula sumando las distancias entre todos los puntos consecutivos del contorno:\n\\[\n\\text{Perímetro} = \\sum_{i=1}^{n} \\sqrt{(x_{i+1} - x_i)^2 + (y_{i+1} - y_i)^2}\n\\]\nDonde:\n- \\(n\\) : Número total de puntos en el contorno\n- \\((x_i, y_i)\\) : Coordenadas del punto actual\n- \\((x_{i+1}, y_{i+1})\\) : Coordenadas del siguiente punto\n- El último punto se conecta con el primero para cerrar el contorno\nEsta fórmula:\n- Utiliza la distancia euclidiana entre puntos consecutivos\n- La suma total representa la longitud del contorno completo\n- Es independiente de la orientación del contorno"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#circularidad",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#circularidad",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "3. Circularidad",
    "text": "3. Circularidad\nLa circularidad es una medida adimensional que cuantifica qué tan similar es una forma a un círculo perfecto:\n\\[\n\\text{Circularidad} = \\frac{4\\pi \\times \\text{Área}}{\\text{Perímetro}^2}\n\\]\nDonde:\n- \\(\\text{Área}\\) : Área del contorno calculada con la primera fórmula\n- \\(\\text{Perímetro}\\) : Perímetro del contorno calculado con la segunda fórmula\n- \\(\\pi\\) : Constante matemática pi (≈ 3.14159)\nInterpretación de los valores:\n- \\(\\text{Circularidad} = 1\\) : Círculo perfecto\n- \\(0 &lt; \\text{Circularidad} &lt; 1\\) : Formas no circulares\n- Valores cercanos a 1: Formas casi circulares\n- Valores cercanos a 0: Formas muy alargadas o irregulares\nPropiedades importantes:\n1. Es invariante a la escala (el tamaño no afecta el resultado)\n2. Es adimensional (no tiene unidades)\n3. Siempre es menor o igual a 1 (la igualdad solo se da en círculos perfectos)\n4. Es sensible a irregularidades en el contorno\nEjemplo de interpretación:\n- Circularidad = 0.95: Forma muy circular\n- Circularidad = 0.7: Forma moderadamente circular\n- Circularidad = 0.3: Forma muy irregular o alargadas"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-logística",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-logística",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Función Logística",
    "text": "Función Logística\nLa función logística, o función sigmoide, se define como:\n\\[\nP(y = 1|x) = \\frac{1}{1 + e^{-(w^T x + b)}}\n\\]\nDonde:\n- ( P(y = 1|x) ) es la probabilidad de que la clase sea 1 dado un vector de características ( x ).\n- ( w ) es el vector de pesos del modelo.\n- ( b ) es el sesgo o término independiente.\n- ( x ) es el vector de características de entrada.\nLa función sigmoide convierte la salida lineal ( w^T x + b ) en un valor entre 0 y 1, que puede interpretarse como una probabilidad."
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-de-costo",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-de-costo",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Función de Costo",
    "text": "Función de Costo\nPara entrenar el modelo, se utiliza la función de costo de entropía cruzada:\n\\[\nJ(w, b) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(P(y^{(i)}|x^{(i)})) + (1 - y^{(i)}) \\log(1 - P(y^{(i)}|x^{(i)})) \\right]\n\\]\nDonde:\n- ( m ) es el número total de ejemplos en el conjunto de datos.\n- ( y^{(i)} ) es la etiqueta verdadera para el i-ésimo ejemplo.\n- ( P(y{(i)}|x{(i)}) ) es la probabilidad predicha para el i-ésimo ejemplo."
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#gradientes-y-actualización",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#gradientes-y-actualización",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Gradientes y Actualización",
    "text": "Gradientes y Actualización\nLos gradientes de la función de costo con respecto a los parámetros ( w ) y ( b ) se utilizan para actualizar los pesos y el sesgo mediante descenso por gradiente:\n\nGradiente del peso ( w ):\n\n\\[\n\\frac{\\partial J(w, b)}{\\partial w} = \\frac{1}{m} \\sum_{i=1}^{m} (P(y^{(i)}|x^{(i)}) - y^{(i)}) x^{(i)}\n\\]\n\nGradiente del sesgo ( b ):\n\n\\[\n\\frac{\\partial J(w, b)}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (P(y^{(i)}|x^{(i)}) - y^{(i)})\n\\]\nLos parámetros se actualizan de la siguiente manera:\n\nActualización del peso ( w ):\n\n\\[\nw := w - \\alpha \\frac{\\partial J(w, b)}{\\partial w}\n\\]\n\nActualización del sesgo ( b ):\n\n\\[\nb := b - \\alpha \\frac{\\partial J(w, b)}{\\partial b}\n\\]\nDonde ( ) es la tasa de aprendizaje.\nLa precisión del modelo se evalúa comparando las predicciones con las etiquetas verdaderas en el conjunto de prueba, utilizando métricas como la precisión (accuracy), precisión (precision), sensibilidad (recall), y especificidad."
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‘Machine Learning with R’ by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book’s specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book’s examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution\n\ndata_path = \"../../data/\""
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load\n\ndata = pd.read_csv(data_path+\"insurance_2.csv\")\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\nNumber of GPUs available: 1\nGPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   salary    1338 non-null   float64\n 6   region    1338 non-null   object \n 7   charges   1338 non-null   float64\ndtypes: float64(3), int64(2), object(3)\nmemory usage: 83.8+ KB\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\ncount\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n\n\nmean\n39.207025\n30.663397\n1.094918\n159064.411451\n13270.422265\n\n\nstd\n14.049960\n6.098187\n1.205493\n41741.994963\n12110.011237\n\n\nmin\n18.000000\n15.960000\n0.000000\n104622.922023\n1121.873900\n\n\n25%\n27.000000\n26.296250\n0.000000\n130087.161933\n4740.287150\n\n\n50%\n39.000000\n30.400000\n1.000000\n146740.897257\n9382.033000\n\n\n75%\n51.000000\n34.693750\n2.000000\n171897.191284\n16639.912515\n\n\nmax\n64.000000\n53.130000\n5.000000\n338460.517246\n63770.428010\n\n\n\n\n\n\n\n\ndata.select_dtypes(\"object\")\n\n\n\n\n\n\n\n\nsex\nsmoker\nregion\n\n\n\n\n0\nfemale\nyes\nsouthwest\n\n\n1\nmale\nno\nsoutheast\n\n\n2\nmale\nno\nsoutheast\n\n\n3\nmale\nno\nnorthwest\n\n\n4\nmale\nno\nnorthwest\n\n\n...\n...\n...\n...\n\n\n1333\nmale\nno\nnorthwest\n\n\n1334\nfemale\nno\nnortheast\n\n\n1335\nfemale\nno\nsoutheast\n\n\n1336\nfemale\nno\nsouthwest\n\n\n1337\nfemale\nyes\nnorthwest\n\n\n\n\n1338 rows × 3 columns\n\n\n\n\ndata[\"sex\"] = data[\"sex\"].astype(\"category\")\ndata[\"smoker\"] = data[\"smoker\"].astype(\"category\")\ndata[\"region\"] = data[\"region\"].astype(\"category\")\n\n\ndata.select_dtypes(\"number\")\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\n0\n19\n27.900\n0\n159272.812482\n16884.92400\n\n\n1\n18\n33.770\n1\n117088.625944\n1725.55230\n\n\n2\n28\n33.000\n3\n129043.852213\n4449.46200\n\n\n3\n33\n22.705\n0\n194635.486180\n21984.47061\n\n\n4\n32\n28.880\n0\n113585.904592\n3866.85520\n\n\n...\n...\n...\n...\n...\n...\n\n\n1333\n50\n30.970\n3\n145933.927725\n10600.54830\n\n\n1334\n18\n31.920\n0\n117665.917758\n2205.98080\n\n\n1335\n18\n36.850\n0\n133402.353115\n1629.83350\n\n\n1336\n21\n25.800\n0\n133975.682996\n2007.94500\n\n\n1337\n61\n29.070\n0\n216658.755628\n29141.36030\n\n\n\n\n1338 rows × 5 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   age       1338 non-null   int64   \n 1   sex       1338 non-null   category\n 2   bmi       1338 non-null   float64 \n 3   children  1338 non-null   int64   \n 4   smoker    1338 non-null   category\n 5   salary    1338 non-null   float64 \n 6   region    1338 non-null   category\n 7   charges   1338 non-null   float64 \ndtypes: category(3), float64(3), int64(2)\nmemory usage: 56.8 KB\n\n\n\n\n2. Visualizing distributions\n\nsns.histplot(data[\"bmi\"], stat=\"probability\")\n\n\n\n\n\n\n\n\n\n\n3. Exploring relationships between variables\n\nsns.scatterplot(data=data, x=\"bmi\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\n\n4. Analyzing categorical variables\n\nsns.countplot(data=data, x=\"smoker\", stat=\"probability\")\n\n\n\n\n\n\n\n\n\nsns.boxplot(data=data, y=\"charges\", x=\"smoker\")\n\n\n\n\n\n\n\n\n\nsns.pointplot(data=data, x=\"sex\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\ng001 = sns.FacetGrid(data=data, col=\"smoker\", row=\"sex\")\ng001.map(plt.scatter, \"bmi\", \"charges\")\n\n\n\n\n\n\n\n\n\nsns.regplot(data=data, x=\"salary\", y=\"charges\",\n            scatter_kws={\"color\": \"blue\"},  # Color de los puntos\n            line_kws={\"color\": \"red\"})"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "title": "Health Care Cost Predictor",
    "section": "5. Checking availability of GPU",
    "text": "5. Checking availability of GPU\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\ndevice1\n\nUsing device: cuda:0\n\n\ndevice(type='cuda', index=0)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "title": "Health Care Cost Predictor",
    "section": "6. Splitting data",
    "text": "6. Splitting data\n\nentrada = data[\"salary\"].to_numpy().reshape(-1, 1)\nsalida = data[\"charges\"].to_numpy().reshape(-1, 1)\n\n\nstandarScaler_features = StandardScaler().fit(entrada)\nstandarScaler_output = StandardScaler().fit(salida)\n\n\nsalary_train, salary_test, charges_train, charges_test = train_test_split(\n    standarScaler_features.transform(entrada),\n    standarScaler_output.transform(salida),\n    train_size=0.7,\n    shuffle=True,\n)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "title": "Health Care Cost Predictor",
    "section": "7. Converting Data To Tensor",
    "text": "7. Converting Data To Tensor\n\nt_salary_train = torch.tensor(salary_train, dtype=torch.float32, device=device1)\nt_salary_test = torch.tensor(salary_test, dtype=torch.float32, device=device1)\nt_charges_train = torch.tensor(charges_train, dtype=torch.float32, device=device1)\nt_charges_test = torch.tensor(charges_test, dtype=torch.float32, device=device1)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "8. Model Implementation",
    "text": "8. Model Implementation\n\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\nmodel = LinearRegression().to(device1)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "10. Train Model",
    "text": "10. Train Model\n\nnum_epochs = 1000\nfor epoch in range(num_epochs):\n\n     # Fordward Pass and loss\n\n     charges_predicted = model(t_salary_train)\n     loss = criterion(charges_predicted, t_charges_train)\n\n     # Backward pass\n     loss.backward()\n\n     #wweights update\n     optimizer.step()\n     optimizer.zero_grad()\n\n     # Progress tracking\n\n     if (epoch+1)%10 ==0:\n          print(f\"Epoch: {epoch+1}, loss={loss.item():.4f}\")\n\nEpoch: 10, loss=1.2763\nEpoch: 20, loss=0.8460\nEpoch: 30, loss=0.5655\nEpoch: 40, loss=0.3828\nEpoch: 50, loss=0.2637\nEpoch: 60, loss=0.1861\nEpoch: 70, loss=0.1355\nEpoch: 80, loss=0.1026\nEpoch: 90, loss=0.0811\nEpoch: 100, loss=0.0671\nEpoch: 110, loss=0.0579\nEpoch: 120, loss=0.0520\nEpoch: 130, loss=0.0481\nEpoch: 140, loss=0.0456\nEpoch: 150, loss=0.0439\nEpoch: 160, loss=0.0428\nEpoch: 170, loss=0.0421\nEpoch: 180, loss=0.0417\nEpoch: 190, loss=0.0414\nEpoch: 200, loss=0.0412\nEpoch: 210, loss=0.0411\nEpoch: 220, loss=0.0410\nEpoch: 230, loss=0.0409\nEpoch: 240, loss=0.0409\nEpoch: 250, loss=0.0409\nEpoch: 260, loss=0.0408\nEpoch: 270, loss=0.0408\nEpoch: 280, loss=0.0408\nEpoch: 290, loss=0.0408\nEpoch: 300, loss=0.0408\nEpoch: 310, loss=0.0408\nEpoch: 320, loss=0.0408\nEpoch: 330, loss=0.0408\nEpoch: 340, loss=0.0408\nEpoch: 350, loss=0.0408\nEpoch: 360, loss=0.0408\nEpoch: 370, loss=0.0408\nEpoch: 380, loss=0.0408\nEpoch: 390, loss=0.0408\nEpoch: 400, loss=0.0408\nEpoch: 410, loss=0.0408\nEpoch: 420, loss=0.0408\nEpoch: 430, loss=0.0408\nEpoch: 440, loss=0.0408\nEpoch: 450, loss=0.0408\nEpoch: 460, loss=0.0408\nEpoch: 470, loss=0.0408\nEpoch: 480, loss=0.0408\nEpoch: 490, loss=0.0408\nEpoch: 500, loss=0.0408\nEpoch: 510, loss=0.0408\nEpoch: 520, loss=0.0408\nEpoch: 530, loss=0.0408\nEpoch: 540, loss=0.0408\nEpoch: 550, loss=0.0408\nEpoch: 560, loss=0.0408\nEpoch: 570, loss=0.0408\nEpoch: 580, loss=0.0408\nEpoch: 590, loss=0.0408\nEpoch: 600, loss=0.0408\nEpoch: 610, loss=0.0408\nEpoch: 620, loss=0.0408\nEpoch: 630, loss=0.0408\nEpoch: 640, loss=0.0408\nEpoch: 650, loss=0.0408\nEpoch: 660, loss=0.0408\nEpoch: 670, loss=0.0408\nEpoch: 680, loss=0.0408\nEpoch: 690, loss=0.0408\nEpoch: 700, loss=0.0408\nEpoch: 710, loss=0.0408\nEpoch: 720, loss=0.0408\nEpoch: 730, loss=0.0408\nEpoch: 740, loss=0.0408\nEpoch: 750, loss=0.0408\nEpoch: 760, loss=0.0408\nEpoch: 770, loss=0.0408\nEpoch: 780, loss=0.0408\nEpoch: 790, loss=0.0408\nEpoch: 800, loss=0.0408\nEpoch: 810, loss=0.0408\nEpoch: 820, loss=0.0408\nEpoch: 830, loss=0.0408\nEpoch: 840, loss=0.0408\nEpoch: 850, loss=0.0408\nEpoch: 860, loss=0.0408\nEpoch: 870, loss=0.0408\nEpoch: 880, loss=0.0408\nEpoch: 890, loss=0.0408\nEpoch: 900, loss=0.0408\nEpoch: 910, loss=0.0408\nEpoch: 920, loss=0.0408\nEpoch: 930, loss=0.0408\nEpoch: 940, loss=0.0408\nEpoch: 950, loss=0.0408\nEpoch: 960, loss=0.0408\nEpoch: 970, loss=0.0408\nEpoch: 980, loss=0.0408\nEpoch: 990, loss=0.0408\nEpoch: 1000, loss=0.0408\n\n\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )\n\n\n\n\n\n\n\n\n\ns_predicha = standarScaler_output.inverse_transform(prediction.cpu().numpy())\ns_real = standarScaler_output.inverse_transform(charges_test)\n\nresiduos = s_real- s_predicha\n\nsm.graphics.tsa.plot_acf(residuos, lags=100)"
  },
  {
    "objectID": "codigo/ASIM/cod002_LinearRegression.html",
    "href": "codigo/ASIM/cod002_LinearRegression.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport numpy as np\n\n# Generate some random data\nnp.random.seed(0)\nX = np.random.rand(100,1)\ny = 3 + 2 * X + np.random.randn(100,1) / 1.5\nX\n\narray([[0.5488135 ],\n       [0.71518937],\n       [0.60276338],\n       [0.54488318],\n       [0.4236548 ],\n       [0.64589411],\n       [0.43758721],\n       [0.891773  ],\n       [0.96366276],\n       [0.38344152],\n       [0.79172504],\n       [0.52889492],\n       [0.56804456],\n       [0.92559664],\n       [0.07103606],\n       [0.0871293 ],\n       [0.0202184 ],\n       [0.83261985],\n       [0.77815675],\n       [0.87001215],\n       [0.97861834],\n       [0.79915856],\n       [0.46147936],\n       [0.78052918],\n       [0.11827443],\n       [0.63992102],\n       [0.14335329],\n       [0.94466892],\n       [0.52184832],\n       [0.41466194],\n       [0.26455561],\n       [0.77423369],\n       [0.45615033],\n       [0.56843395],\n       [0.0187898 ],\n       [0.6176355 ],\n       [0.61209572],\n       [0.616934  ],\n       [0.94374808],\n       [0.6818203 ],\n       [0.3595079 ],\n       [0.43703195],\n       [0.6976312 ],\n       [0.06022547],\n       [0.66676672],\n       [0.67063787],\n       [0.21038256],\n       [0.1289263 ],\n       [0.31542835],\n       [0.36371077],\n       [0.57019677],\n       [0.43860151],\n       [0.98837384],\n       [0.10204481],\n       [0.20887676],\n       [0.16130952],\n       [0.65310833],\n       [0.2532916 ],\n       [0.46631077],\n       [0.24442559],\n       [0.15896958],\n       [0.11037514],\n       [0.65632959],\n       [0.13818295],\n       [0.19658236],\n       [0.36872517],\n       [0.82099323],\n       [0.09710128],\n       [0.83794491],\n       [0.09609841],\n       [0.97645947],\n       [0.4686512 ],\n       [0.97676109],\n       [0.60484552],\n       [0.73926358],\n       [0.03918779],\n       [0.28280696],\n       [0.12019656],\n       [0.2961402 ],\n       [0.11872772],\n       [0.31798318],\n       [0.41426299],\n       [0.0641475 ],\n       [0.69247212],\n       [0.56660145],\n       [0.26538949],\n       [0.52324805],\n       [0.09394051],\n       [0.5759465 ],\n       [0.9292962 ],\n       [0.31856895],\n       [0.66741038],\n       [0.13179786],\n       [0.7163272 ],\n       [0.28940609],\n       [0.18319136],\n       [0.58651293],\n       [0.02010755],\n       [0.82894003],\n       [0.00469548]])\n\n\n\n\n# Convert data to PyTorch tensors\nX_tensor = torch.from_numpy(X.astype(np.float32))\ny_tensor = torch.from_numpy(y.astype(np.float32))\n\n\n# Define the linear regression model\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Initialize the model, loss function, and optimizer\nmodel = LinearRegression()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# Train the model\nfor epoch in range(1000):\n    optimizer.zero_grad()\n    outputs = model(X_tensor)\n    loss = criterion(outputs, y_tensor)\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 100 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n# Print the learned parameters\n\nm = model.linear.weight.item()\nb = model.linear.bias.item()\n\nprint(\"Learned parameters:\")\nprint(\"Weight:\", m)\nprint(\"Bias:\", b )\n\nEpoch 1, Loss: 17.11027717590332\nEpoch 101, Loss: 0.5529825687408447\nEpoch 201, Loss: 0.4432789981365204\nEpoch 301, Loss: 0.44221213459968567\nEpoch 401, Loss: 0.4419429302215576\nEpoch 501, Loss: 0.4417407214641571\nEpoch 601, Loss: 0.44158604741096497\nEpoch 701, Loss: 0.44146785140037537\nEpoch 801, Loss: 0.4413774013519287\nEpoch 901, Loss: 0.4413083791732788\nLearned parameters:\nWeight: 1.91282320022583\nBias: 3.170973062515259\n\n\n\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0 , 1, 200)\nfig001 = plt.figure()\nplt.plot(t, m*t+b)\nplt.plot(X, y, 'r*')"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\ndata = pd.read_csv(\"../../data/diabetes.csv\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network data",
    "text": "Create neural network data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‘Machine Learning with R’ by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book’s specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book’s examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\n\n2. Visualizing distributions\n\n\n3. Exploring relationships between variables\n\n\n4. Analyzing categorical variables"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "Model Implementation",
    "text": "Model Implementation"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "Train Model",
    "text": "Train Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\n#data = pd.read_csv(\"drive/MyDrive/ASIM/diabetes.csv\")\ndata = pd.read_csv(\"../../data/diabetes.csv\")\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\ncount\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n\n\nmean\n3.845052\n120.894531\n69.105469\n20.536458\n79.799479\n31.992578\n0.471876\n33.240885\n0.348958\n\n\nstd\n3.369578\n31.972618\n19.355807\n15.952218\n115.244002\n7.884160\n0.331329\n11.760232\n0.476951\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.078000\n21.000000\n0.000000\n\n\n25%\n1.000000\n99.000000\n62.000000\n0.000000\n0.000000\n27.300000\n0.243750\n24.000000\n0.000000\n\n\n50%\n3.000000\n117.000000\n72.000000\n23.000000\n30.500000\n32.000000\n0.372500\n29.000000\n0.000000\n\n\n75%\n6.000000\n140.250000\n80.000000\n32.000000\n127.250000\n36.600000\n0.626250\n41.000000\n1.000000\n\n\nmax\n17.000000\n199.000000\n122.000000\n99.000000\n846.000000\n67.100000\n2.420000\n81.000000\n1.000000"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values\n\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship\n\nsns.histplot(data=data, x=\"BloodPressure\", kde=True)\n\n\n\n\n\n\n\n\n\nsns.countplot(data=data, x=\"Outcome\")\n\n\n\n\n\n\n\n\n\ndata.drop(data[data[\"BloodPressure\"]==0].index, inplace=True)\n\n\nsns.countplot(data=data, x=\"Outcome\")\n\n\n\n\n\n\n\n\n\nfeatures = [\n    \"Pregnancies\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"BMI\",\n    \"DiabetesPedigreeFunction\",\n    \"Age\"\n]\n\noutput = [\n    \"Outcome\"\n]"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data\n\nstandardScaler_features = StandardScaler().fit(data[features])\nstandardScaler_output = StandardScaler().fit(data[output])\n\nstandard_features = standardScaler_features.transform(data[features])\nstandard_output = data[output].values.reshape(-1,1)\n\n\nclass ConjuntoDatosTabulares(Dataset):\n  def __init__(self, ent, sal):\n    self.inputs = torch.tensor(ent, dtype=torch.float32)\n    self.outputs = torch.tensor(sal, dtype=torch.float32)\n\n  def __len__(self):\n    return len(self.inputs)\n\n  def __getitem__(self, idx):\n    return self.inputs[idx], self.outputs[idx]\n\n\n\nbs = 32  # Tamaño del lote\n\n\ntotal_data = ConjuntoDatosTabulares(ent=standard_features, sal=standard_output)\ntotal_data_dataloader = DataLoader(total_data, batch_size = 32, shuffle=True)\n\n\ntrain_ds, val_ds, test_ds = random_split(total_data, [0.56, 0.14, 0.3])\n\ntrain_loader = DataLoader(train_ds, batch_size = bs, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size = bs, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size = bs, shuffle=True)\n\n\na = next(iter(total_data_dataloader))\nx, y = a"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#create-neural-network",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#create-neural-network",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network",
    "text": "Create neural network\n\nclass RedNeuronal(nn.Module):\n  def __init__(self, num_caract, num_salidas):\n    super(RedNeuronal, self).__init__()\n    self.num_inputs = num_caract\n    self.num_outputs = num_salidas\n    self.hidden1 = nn.Linear(self.num_inputs, 10)\n    self.fact1 = nn.ReLU()\n    self.hidden2 = nn.Linear(10, 12)\n    self.fact2 = nn.ReLU()\n    self.hidden3 = nn.Linear(12, 13)\n    self.fact3 = nn.ReLU()\n    self.hidden4 = nn.Linear(13, self.num_outputs)\n    self.fact4 = nn.Sigmoid()\n\n  def forward(self, x):\n    x = self.fact1(self.hidden1(x))\n    x = self.fact2(self.hidden2(x))\n    x = self.fact3(self.hidden3(x))\n    x = self.fact4(self.hidden4(x))\n    return x"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model\n\nepocas = 1000  # Número de épocas de entrenamiento\n\n\nred = RedNeuronal(8, 1)\nred = red.to(device=device1)\n\n\nprint(red.parameters())\n\n&lt;generator object Module.parameters at 0x7fcf6518c190&gt;\n\n\n\ncriterio = nn.BCELoss()\noptimizador = optim.Adam(red.parameters(), lr=0.001)\n\n\n# Entrenar la red neuronal\nfor epoca in range(epocas):\n    perdida_entrenamiento = 0\n    for X_batch, y_batch in train_loader:\n        # Pasar los datos por la red neuronal\n        salida = red(X_batch.to(device=device1))\n\n        # Calcular la pérdida\n        perdida = criterio(salida, y_batch.to(device=device1))\n\n        # Actualizar los pesos\n        optimizador.zero_grad()\n        perdida.backward()\n        optimizador.step()\n        perdida_entrenamiento += perdida.item()\n\n    # Imprimir la pérdida en cada época\n    # print(f\"Época {epoca+1}, pérdida: {perdida.item():.8f}\")\n    perdida_validacion = 0\n    con_exactitud = 0\n    total = 0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            # Pasar los datos por la red neuronal\n            salida = red(X_batch.to(device=device1))\n\n            # Calcular la pérdida\n            perdida = criterio(salida, y_batch.to(device=device1))\n\n            perdida_validacion += perdida.item()\n\n    # Imprimir los resultados\n    print(f\"Época {epoca+1}\")\n    print(f\"Perdida entrenamiento: {perdida_entrenamiento/len(train_loader)}\")\n    print(f\"Perdida validación: {perdida_validacion/len(val_loader)}\")\n\nÉpoca 1\nPerdida entrenamiento: 0.7267978053826553\nPerdida validación: 0.7159790992736816\nÉpoca 2\nPerdida entrenamiento: 0.7182281980147729\nPerdida validación: 0.7118411660194397\nÉpoca 3\nPerdida entrenamiento: 0.7104145655265222\nPerdida validación: 0.7019551694393158\nÉpoca 4\nPerdida entrenamiento: 0.7015121854268588\nPerdida validación: 0.6946617513895035\nÉpoca 5\nPerdida entrenamiento: 0.6905638575553894\nPerdida validación: 0.6804916262626648\nÉpoca 6\nPerdida entrenamiento: 0.6800636832530682\nPerdida validación: 0.6584434807300568\nÉpoca 7\nPerdida entrenamiento: 0.6666435966124902\nPerdida validación: 0.6408872753381729\nÉpoca 8\nPerdida entrenamiento: 0.6524532116376437\nPerdida validación: 0.6386194676160812\nÉpoca 9\nPerdida entrenamiento: 0.6351055273642907\nPerdida validación: 0.602764829993248\nÉpoca 10\nPerdida entrenamiento: 0.6161944040885339\nPerdida validación: 0.5701538622379303\nÉpoca 11\nPerdida entrenamiento: 0.5947254254267766\nPerdida validación: 0.5622555166482925\nÉpoca 12\nPerdida entrenamiento: 0.5704072484603295\nPerdida validación: 0.5211050510406494\nÉpoca 13\nPerdida entrenamiento: 0.548466084095148\nPerdida validación: 0.480282261967659\nÉpoca 14\nPerdida entrenamiento: 0.5316605155284588\nPerdida validación: 0.4288185238838196\nÉpoca 15\nPerdida entrenamiento: 0.5179111269804147\nPerdida validación: 0.4584948718547821\nÉpoca 16\nPerdida entrenamiento: 0.5062230687875015\nPerdida validación: 0.4407348707318306\nÉpoca 17\nPerdida entrenamiento: 0.49960110966975874\nPerdida validación: 0.4830065444111824\nÉpoca 18\nPerdida entrenamiento: 0.49942563359554\nPerdida validación: 0.3943897932767868\nÉpoca 19\nPerdida entrenamiento: 0.48894316875017607\nPerdida validación: 0.4019322246313095\nÉpoca 20\nPerdida entrenamiento: 0.4884497339908893\nPerdida validación: 0.37546899914741516\nÉpoca 21\nPerdida entrenamiento: 0.4813868930706611\nPerdida validación: 0.39141348749399185\nÉpoca 22\nPerdida entrenamiento: 0.4776655458486997\nPerdida validación: 0.3661811575293541\nÉpoca 23\nPerdida entrenamiento: 0.47272541660528916\nPerdida validación: 0.45798082649707794\nÉpoca 24\nPerdida entrenamiento: 0.4703685755913074\nPerdida validación: 0.44551635533571243\nÉpoca 25\nPerdida entrenamiento: 0.46607735523810756\nPerdida validación: 0.4059871584177017\nÉpoca 26\nPerdida entrenamiento: 0.4660418469172258\nPerdida validación: 0.38415608555078506\nÉpoca 27\nPerdida entrenamiento: 0.4620107962534978\nPerdida validación: 0.4321253150701523\nÉpoca 28\nPerdida entrenamiento: 0.45929738879203796\nPerdida validación: 0.3779127597808838\nÉpoca 29\nPerdida entrenamiento: 0.4604421624770531\nPerdida validación: 0.39340754598379135\nÉpoca 30\nPerdida entrenamiento: 0.45797420465029204\nPerdida validación: 0.41168972104787827\nÉpoca 31\nPerdida entrenamiento: 0.453733898126162\nPerdida validación: 0.3659657798707485\nÉpoca 32\nPerdida entrenamiento: 0.4509870432890378\nPerdida validación: 0.35692010819911957\nÉpoca 33\nPerdida entrenamiento: 0.4491236439118019\nPerdida validación: 0.39127306640148163\nÉpoca 34\nPerdida entrenamiento: 0.44821084233430714\nPerdida validación: 0.4903676062822342\nÉpoca 35\nPerdida entrenamiento: 0.4483366654469417\nPerdida validación: 0.41949494183063507\nÉpoca 36\nPerdida entrenamiento: 0.4433157375225654\nPerdida validación: 0.3596146032214165\nÉpoca 37\nPerdida entrenamiento: 0.44532549610504735\nPerdida validación: 0.4067723825573921\nÉpoca 38\nPerdida entrenamiento: 0.441569637793761\nPerdida validación: 0.3658885098993778\nÉpoca 39\nPerdida entrenamiento: 0.4414483675589928\nPerdida validación: 0.36617711186408997\nÉpoca 40\nPerdida entrenamiento: 0.442814643566425\nPerdida validación: 0.43410953134298325\nÉpoca 41\nPerdida entrenamiento: 0.44105668709828305\nPerdida validación: 0.41927940398454666\nÉpoca 42\nPerdida entrenamiento: 0.4365276006551889\nPerdida validación: 0.4514813870191574\nÉpoca 43\nPerdida entrenamiento: 0.4371137320995331\nPerdida validación: 0.40512615442276\nÉpoca 44\nPerdida entrenamiento: 0.4338447176493131\nPerdida validación: 0.3971825987100601\nÉpoca 45\nPerdida entrenamiento: 0.4321022881911351\nPerdida validación: 0.4355890303850174\nÉpoca 46\nPerdida entrenamiento: 0.43205584012545073\nPerdida validación: 0.41393060982227325\nÉpoca 47\nPerdida entrenamiento: 0.4316117866681172\nPerdida validación: 0.3700167201459408\nÉpoca 48\nPerdida entrenamiento: 0.4322385054368239\nPerdida validación: 0.5200365260243416\nÉpoca 49\nPerdida entrenamiento: 0.4290507435798645\nPerdida validación: 0.4920997768640518\nÉpoca 50\nPerdida entrenamiento: 0.4292399768645947\nPerdida validación: 0.36969228461384773\nÉpoca 51\nPerdida entrenamiento: 0.42718150180119735\nPerdida validación: 0.4156232178211212\nÉpoca 52\nPerdida entrenamiento: 0.424829540344385\nPerdida validación: 0.4026588648557663\nÉpoca 53\nPerdida entrenamiento: 0.42635376636798566\nPerdida validación: 0.5363039597868919\nÉpoca 54\nPerdida entrenamiento: 0.42566425525225127\nPerdida validación: 0.3764454163610935\nÉpoca 55\nPerdida entrenamiento: 0.4237565237742204\nPerdida validación: 0.3808739259839058\nÉpoca 56\nPerdida entrenamiento: 0.4219471537149869\nPerdida validación: 0.4832487851381302\nÉpoca 57\nPerdida entrenamiento: 0.4212725300055284\nPerdida validación: 0.41617023199796677\nÉpoca 58\nPerdida entrenamiento: 0.4186098369268271\nPerdida validación: 0.3641137257218361\nÉpoca 59\nPerdida entrenamiento: 0.42065096359986526\nPerdida validación: 0.4038226157426834\nÉpoca 60\nPerdida entrenamiento: 0.41977634911353773\nPerdida validación: 0.38351573422551155\nÉpoca 61\nPerdida entrenamiento: 0.42114768578455997\nPerdida validación: 0.4520387575030327\nÉpoca 62\nPerdida entrenamiento: 0.4161078998675713\nPerdida validación: 0.393571600317955\nÉpoca 63\nPerdida entrenamiento: 0.4192577485854809\nPerdida validación: 0.41231170296669006\nÉpoca 64\nPerdida entrenamiento: 0.4160077480169443\nPerdida validación: 0.3934858366847038\nÉpoca 65\nPerdida entrenamiento: 0.41279572592331815\nPerdida validación: 0.3768220767378807\nÉpoca 66\nPerdida entrenamiento: 0.41775457904889035\nPerdida validación: 0.4513847976922989\nÉpoca 67\nPerdida entrenamiento: 0.4163452753653893\nPerdida validación: 0.4106815755367279\nÉpoca 68\nPerdida entrenamiento: 0.41231613205029416\nPerdida validación: 0.47492188960313797\nÉpoca 69\nPerdida entrenamiento: 0.41317373743424046\nPerdida validación: 0.3622148148715496\nÉpoca 70\nPerdida entrenamiento: 0.41339464027148026\nPerdida validación: 0.39243172109127045\nÉpoca 71\nPerdida entrenamiento: 0.41166099447470444\nPerdida validación: 0.4348529800772667\nÉpoca 72\nPerdida entrenamiento: 0.41057429634607756\nPerdida validación: 0.45380373299121857\nÉpoca 73\nPerdida entrenamiento: 0.40971608803822446\nPerdida validación: 0.43138349056243896\nÉpoca 74\nPerdida entrenamiento: 0.4103902509579292\nPerdida validación: 0.3543439395725727\nÉpoca 75\nPerdida entrenamiento: 0.41078854409547955\nPerdida validación: 0.4501536637544632\nÉpoca 76\nPerdida entrenamiento: 0.40908563137054443\nPerdida validación: 0.4332057163119316\nÉpoca 77\nPerdida entrenamiento: 0.40671666998129624\nPerdida validación: 0.47097714990377426\nÉpoca 78\nPerdida entrenamiento: 0.4092497917322012\nPerdida validación: 0.3809227794408798\nÉpoca 79\nPerdida entrenamiento: 0.40779951214790344\nPerdida validación: 0.39128022640943527\nÉpoca 80\nPerdida entrenamiento: 0.40222956010928523\nPerdida validación: 0.38470108062028885\nÉpoca 81\nPerdida entrenamiento: 0.40348539444116444\nPerdida validación: 0.3810441344976425\nÉpoca 82\nPerdida entrenamiento: 0.402382846062\nPerdida validación: 0.42453859001398087\nÉpoca 83\nPerdida entrenamiento: 0.4035201118542598\nPerdida validación: 0.42277510464191437\nÉpoca 84\nPerdida entrenamiento: 0.40302718602694\nPerdida validación: 0.4245646893978119\nÉpoca 85\nPerdida entrenamiento: 0.40186390509972203\nPerdida validación: 0.4499344155192375\nÉpoca 86\nPerdida entrenamiento: 0.40172262031298417\nPerdida validación: 0.49974845349788666\nÉpoca 87\nPerdida entrenamiento: 0.400823359306042\nPerdida validación: 0.425841860473156\nÉpoca 88\nPerdida entrenamiento: 0.39879807142110973\nPerdida validación: 0.3989344537258148\nÉpoca 89\nPerdida entrenamiento: 0.3981326176570012\nPerdida validación: 0.4065830484032631\nÉpoca 90\nPerdida entrenamiento: 0.3998530392463391\nPerdida validación: 0.39869045466184616\nÉpoca 91\nPerdida entrenamiento: 0.39560900972439694\nPerdida validación: 0.37907231599092484\nÉpoca 92\nPerdida entrenamiento: 0.3956319529276628\nPerdida validación: 0.3895183838903904\nÉpoca 93\nPerdida entrenamiento: 0.3948855010362772\nPerdida validación: 0.40453095734119415\nÉpoca 94\nPerdida entrenamiento: 0.3942739229935866\nPerdida validación: 0.42533183097839355\nÉpoca 95\nPerdida entrenamiento: 0.39367732405662537\nPerdida validación: 0.49657849967479706\nÉpoca 96\nPerdida entrenamiento: 0.39477550295683056\nPerdida validación: 0.42017025500535965\nÉpoca 97\nPerdida entrenamiento: 0.39310317773085374\nPerdida validación: 0.38999152556061745\nÉpoca 98\nPerdida entrenamiento: 0.3917583009371391\nPerdida validación: 0.43369147926568985\nÉpoca 99\nPerdida entrenamiento: 0.38949758960650516\nPerdida validación: 0.4349787309765816\nÉpoca 100\nPerdida entrenamiento: 0.39008616025631243\nPerdida validación: 0.395715843886137\nÉpoca 101\nPerdida entrenamiento: 0.38877419783518863\nPerdida validación: 0.36947037652134895\nÉpoca 102\nPerdida entrenamiento: 0.39078972202080947\nPerdida validación: 0.4100741744041443\nÉpoca 103\nPerdida entrenamiento: 0.39032559669934785\nPerdida validación: 0.42708979547023773\nÉpoca 104\nPerdida entrenamiento: 0.3895266938668031\nPerdida validación: 0.4977172240614891\nÉpoca 105\nPerdida entrenamiento: 0.3862973955961374\nPerdida validación: 0.4343803748488426\nÉpoca 106\nPerdida entrenamiento: 0.38772000716282773\nPerdida validación: 0.4120924770832062\nÉpoca 107\nPerdida entrenamiento: 0.387257273380573\nPerdida validación: 0.46935633569955826\nÉpoca 108\nPerdida entrenamiento: 0.3854876779592954\nPerdida validación: 0.4736231788992882\nÉpoca 109\nPerdida entrenamiento: 0.3852063004787152\nPerdida validación: 0.4230464696884155\nÉpoca 110\nPerdida entrenamiento: 0.3828760408438169\nPerdida validación: 0.5397054925560951\nÉpoca 111\nPerdida entrenamiento: 0.3831189355024925\nPerdida validación: 0.43693213164806366\nÉpoca 112\nPerdida entrenamiento: 0.3818291677878453\nPerdida validación: 0.39886316657066345\nÉpoca 113\nPerdida entrenamiento: 0.38133204671052784\nPerdida validación: 0.4186994433403015\nÉpoca 114\nPerdida entrenamiento: 0.38088562855353725\nPerdida validación: 0.39437006786465645\nÉpoca 115\nPerdida entrenamiento: 0.38014946763332075\nPerdida validación: 0.42200181633234024\nÉpoca 116\nPerdida entrenamiento: 0.3776790407987741\nPerdida validación: 0.3852379620075226\nÉpoca 117\nPerdida entrenamiento: 0.37825816640487087\nPerdida validación: 0.4611133188009262\nÉpoca 118\nPerdida entrenamiento: 0.3772958150276771\nPerdida validación: 0.38224026188254356\nÉpoca 119\nPerdida entrenamiento: 0.3778039331619556\nPerdida validación: 0.4286082088947296\nÉpoca 120\nPerdida entrenamiento: 0.3743162567798908\nPerdida validación: 0.39137063175439835\nÉpoca 121\nPerdida entrenamiento: 0.3749724511916821\nPerdida validación: 0.4739982336759567\nÉpoca 122\nPerdida entrenamiento: 0.37313790504749006\nPerdida validación: 0.39009249955415726\nÉpoca 123\nPerdida entrenamiento: 0.3736418072993939\nPerdida validación: 0.48800554871559143\nÉpoca 124\nPerdida entrenamiento: 0.3741052127801455\nPerdida validación: 0.4744153171777725\nÉpoca 125\nPerdida entrenamiento: 0.37422877779373753\nPerdida validación: 0.43327439576387405\nÉpoca 126\nPerdida entrenamiento: 0.371814754146796\nPerdida validación: 0.4883398041129112\nÉpoca 127\nPerdida entrenamiento: 0.3707105219364166\nPerdida validación: 0.4257439374923706\nÉpoca 128\nPerdida entrenamiento: 0.3705435876662915\nPerdida validación: 0.4996122717857361\nÉpoca 129\nPerdida entrenamiento: 0.36863908630151015\nPerdida validación: 0.44596949219703674\nÉpoca 130\nPerdida entrenamiento: 0.36837688088417053\nPerdida validación: 0.5108792632818222\nÉpoca 131\nPerdida entrenamiento: 0.3644952911597032\nPerdida validación: 0.4148697182536125\nÉpoca 132\nPerdida entrenamiento: 0.3676655269586123\nPerdida validación: 0.4180637337267399\nÉpoca 133\nPerdida entrenamiento: 0.36441197762122524\nPerdida validación: 0.4463004618883133\nÉpoca 134\nPerdida entrenamiento: 0.364000148498095\nPerdida validación: 0.45392312854528427\nÉpoca 135\nPerdida entrenamiento: 0.3633742378308223\nPerdida validación: 0.5120198130607605\nÉpoca 136\nPerdida entrenamiento: 0.36356962414888233\nPerdida validación: 0.5091618970036507\nÉpoca 137\nPerdida entrenamiento: 0.3639798118517949\nPerdida validación: 0.4719684571027756\nÉpoca 138\nPerdida entrenamiento: 0.3627295471154727\nPerdida validación: 0.44826727360486984\nÉpoca 139\nPerdida entrenamiento: 0.3609895293529217\nPerdida validación: 0.4631754010915756\nÉpoca 140\nPerdida entrenamiento: 0.3619653765971844\nPerdida validación: 0.5464806333184242\nÉpoca 141\nPerdida entrenamiento: 0.3585687061915031\nPerdida validación: 0.5189626067876816\nÉpoca 142\nPerdida entrenamiento: 0.3566366388247563\nPerdida validación: 0.46764953434467316\nÉpoca 143\nPerdida entrenamiento: 0.36353538128045887\nPerdida validación: 0.46592652797698975\nÉpoca 144\nPerdida entrenamiento: 0.35643438536387223\nPerdida validación: 0.43039967119693756\nÉpoca 145\nPerdida entrenamiento: 0.35604520256702715\nPerdida validación: 0.5149550661444664\nÉpoca 146\nPerdida entrenamiento: 0.35637769676171815\nPerdida validación: 0.4144183583557606\nÉpoca 147\nPerdida entrenamiento: 0.355108747115502\nPerdida validación: 0.4768465459346771\nÉpoca 148\nPerdida entrenamiento: 0.35542476864961475\nPerdida validación: 0.4844294711947441\nÉpoca 149\nPerdida entrenamiento: 0.3519860024635608\nPerdida validación: 0.4547104239463806\nÉpoca 150\nPerdida entrenamiento: 0.3521421987276811\nPerdida validación: 0.466669999063015\nÉpoca 151\nPerdida entrenamiento: 0.3548166167277556\nPerdida validación: 0.5513210147619247\nÉpoca 152\nPerdida entrenamiento: 0.35027686334573305\nPerdida validación: 0.5020348504185677\nÉpoca 153\nPerdida entrenamiento: 0.34959811774583965\nPerdida validación: 0.5455379039049149\nÉpoca 154\nPerdida entrenamiento: 0.3523002461745189\nPerdida validación: 0.47232835739851\nÉpoca 155\nPerdida entrenamiento: 0.35344558495741624\nPerdida validación: 0.5145654082298279\nÉpoca 156\nPerdida entrenamiento: 0.3485158762106529\nPerdida validación: 0.486834391951561\nÉpoca 157\nPerdida entrenamiento: 0.34897099549953753\nPerdida validación: 0.5043940991163254\nÉpoca 158\nPerdida entrenamiento: 0.34723360263384306\nPerdida validación: 0.5066465809941292\nÉpoca 159\nPerdida entrenamiento: 0.34640762439140904\nPerdida validación: 0.5473715737462044\nÉpoca 160\nPerdida entrenamiento: 0.34859538536805373\nPerdida validación: 0.4481390565633774\nÉpoca 161\nPerdida entrenamiento: 0.3447049787411323\nPerdida validación: 0.424229035153985\nÉpoca 162\nPerdida entrenamiento: 0.34568210060779864\nPerdida validación: 0.4851425141096115\nÉpoca 163\nPerdida entrenamiento: 0.3433854981110646\nPerdida validación: 0.48836609721183777\nÉpoca 164\nPerdida entrenamiento: 0.3420627174469141\nPerdida validación: 0.509034663438797\nÉpoca 165\nPerdida entrenamiento: 0.34017568826675415\nPerdida validación: 0.6002066135406494\nÉpoca 166\nPerdida entrenamiento: 0.34276773035526276\nPerdida validación: 0.52107934653759\nÉpoca 167\nPerdida entrenamiento: 0.34077843106709993\nPerdida validación: 0.48411911725997925\nÉpoca 168\nPerdida entrenamiento: 0.3387271555570456\nPerdida validación: 0.446561835706234\nÉpoca 169\nPerdida entrenamiento: 0.34064857547099775\nPerdida validación: 0.4455733299255371\nÉpoca 170\nPerdida entrenamiento: 0.3393576191021846\nPerdida validación: 0.4353795200586319\nÉpoca 171\nPerdida entrenamiento: 0.34231315094691056\nPerdida validación: 0.4627293348312378\nÉpoca 172\nPerdida entrenamiento: 0.3361229976782432\nPerdida validación: 0.5688041225075722\nÉpoca 173\nPerdida entrenamiento: 0.33672307087824893\nPerdida validación: 0.45936134085059166\nÉpoca 174\nPerdida entrenamiento: 0.33723970445302814\nPerdida validación: 0.5437187701463699\nÉpoca 175\nPerdida entrenamiento: 0.3378218343624702\nPerdida validación: 0.6265709698200226\nÉpoca 176\nPerdida entrenamiento: 0.3348902968259958\nPerdida validación: 0.4678940027952194\nÉpoca 177\nPerdida entrenamiento: 0.33359681299099553\nPerdida validación: 0.49202893674373627\nÉpoca 178\nPerdida entrenamiento: 0.3337265390616197\nPerdida validación: 0.46057265624403954\nÉpoca 179\nPerdida entrenamiento: 0.33145728134191954\nPerdida validación: 0.5372823402285576\nÉpoca 180\nPerdida entrenamiento: 0.33341708091589123\nPerdida validación: 0.4422183372080326\nÉpoca 181\nPerdida entrenamiento: 0.3310887057047624\nPerdida validación: 0.7397722750902176\nÉpoca 182\nPerdida entrenamiento: 0.32945447243176973\nPerdida validación: 0.4633013419806957\nÉpoca 183\nPerdida entrenamiento: 0.32728753983974457\nPerdida validación: 0.4701136499643326\nÉpoca 184\nPerdida entrenamiento: 0.3269531589287978\nPerdida validación: 0.5811994299292564\nÉpoca 185\nPerdida entrenamiento: 0.3289144921761293\nPerdida validación: 0.6501174867153168\nÉpoca 186\nPerdida entrenamiento: 0.3250019389849443\nPerdida validación: 0.48658087104558945\nÉpoca 187\nPerdida entrenamiento: 0.3252809208173018\nPerdida validación: 0.5948077514767647\nÉpoca 188\nPerdida entrenamiento: 0.32456459448887753\nPerdida validación: 0.5170600488781929\nÉpoca 189\nPerdida entrenamiento: 0.3248377591371536\nPerdida validación: 0.5801271125674248\nÉpoca 190\nPerdida entrenamiento: 0.3258056640625\nPerdida validación: 0.5002523139119148\nÉpoca 191\nPerdida entrenamiento: 0.3205260726121756\nPerdida validación: 0.7138897553086281\nÉpoca 192\nPerdida entrenamiento: 0.3199167068188007\nPerdida validación: 0.5612407624721527\nÉpoca 193\nPerdida entrenamiento: 0.31928349229005665\nPerdida validación: 0.6081007793545723\nÉpoca 194\nPerdida entrenamiento: 0.3201474203513219\nPerdida validación: 0.5727706551551819\nÉpoca 195\nPerdida entrenamiento: 0.3193618678129636\nPerdida validación: 0.47843847796320915\nÉpoca 196\nPerdida entrenamiento: 0.3186295720247122\nPerdida validación: 0.5062254294753075\nÉpoca 197\nPerdida entrenamiento: 0.3170779118171105\nPerdida validación: 0.6240173578262329\nÉpoca 198\nPerdida entrenamiento: 0.31651219954857457\nPerdida validación: 0.733600378036499\nÉpoca 199\nPerdida entrenamiento: 0.31591541492022\nPerdida validación: 0.5893783569335938\nÉpoca 200\nPerdida entrenamiento: 0.31407135954269993\nPerdida validación: 0.672258049249649\nÉpoca 201\nPerdida entrenamiento: 0.3167167156934738\nPerdida validación: 0.5906193181872368\nÉpoca 202\nPerdida entrenamiento: 0.31775486125395846\nPerdida validación: 0.6703383028507233\nÉpoca 203\nPerdida entrenamiento: 0.3142982469155238\nPerdida validación: 0.493832191452384\nÉpoca 204\nPerdida entrenamiento: 0.3143202100808804\nPerdida validación: 0.6293051838874817\nÉpoca 205\nPerdida entrenamiento: 0.3154367025081928\nPerdida validación: 0.5778104141354561\nÉpoca 206\nPerdida entrenamiento: 0.312066729252155\nPerdida validación: 0.5893872007727623\nÉpoca 207\nPerdida entrenamiento: 0.3136929445541822\nPerdida validación: 0.516918983310461\nÉpoca 208\nPerdida entrenamiento: 0.30938355510051435\nPerdida validación: 0.582847073674202\nÉpoca 209\nPerdida entrenamiento: 0.3098432135123473\nPerdida validación: 0.5286299884319305\nÉpoca 210\nPerdida entrenamiento: 0.3081144358103092\nPerdida validación: 0.5873531252145767\nÉpoca 211\nPerdida entrenamiento: 0.3083389034638038\nPerdida validación: 0.602348081767559\nÉpoca 212\nPerdida entrenamiento: 0.3055564474601012\nPerdida validación: 0.6705131381750107\nÉpoca 213\nPerdida entrenamiento: 0.30720986884373885\nPerdida validación: 0.6529285907745361\nÉpoca 214\nPerdida entrenamiento: 0.3054585216137079\nPerdida validación: 0.6688360720872879\nÉpoca 215\nPerdida entrenamiento: 0.30763639509677887\nPerdida validación: 0.5135140027850866\nÉpoca 216\nPerdida entrenamiento: 0.303421927186159\nPerdida validación: 0.5739713087677956\nÉpoca 217\nPerdida entrenamiento: 0.3031972520626508\nPerdida validación: 0.5670073255896568\nÉpoca 218\nPerdida entrenamiento: 0.30217409363159764\nPerdida validación: 0.592064693570137\nÉpoca 219\nPerdida entrenamiento: 0.30135699533499205\nPerdida validación: 0.636160098016262\nÉpoca 220\nPerdida entrenamiento: 0.3016016884491994\nPerdida validación: 0.5606770887970924\nÉpoca 221\nPerdida entrenamiento: 0.3024453268601344\nPerdida validación: 0.5745292976498604\nÉpoca 222\nPerdida entrenamiento: 0.3018904064710324\nPerdida validación: 0.7433184385299683\nÉpoca 223\nPerdida entrenamiento: 0.2971323464925473\nPerdida validación: 0.740757018327713\nÉpoca 224\nPerdida entrenamiento: 0.2984556464048532\nPerdida validación: 0.5652462765574455\nÉpoca 225\nPerdida entrenamiento: 0.29587332101968616\nPerdida validación: 0.5960354954004288\nÉpoca 226\nPerdida entrenamiento: 0.298045168702419\nPerdida validación: 0.6095506846904755\nÉpoca 227\nPerdida entrenamiento: 0.2962602503024615\nPerdida validación: 0.8097492754459381\nÉpoca 228\nPerdida entrenamiento: 0.29590065891926104\nPerdida validación: 0.642509862780571\nÉpoca 229\nPerdida entrenamiento: 0.29353805115589726\nPerdida validación: 0.6805313527584076\nÉpoca 230\nPerdida entrenamiento: 0.2950842518072862\nPerdida validación: 0.5805027037858963\nÉpoca 231\nPerdida entrenamiento: 0.2943579313846735\nPerdida validación: 0.5456069093197584\nÉpoca 232\nPerdida entrenamiento: 0.293004646897316\nPerdida validación: 0.5370007765013725\nÉpoca 233\nPerdida entrenamiento: 0.2904043530042355\nPerdida validación: 0.627612516283989\nÉpoca 234\nPerdida entrenamiento: 0.2912729737850336\nPerdida validación: 0.7116727158427238\nÉpoca 235\nPerdida entrenamiento: 0.28903550253464627\nPerdida validación: 0.660587415099144\nÉpoca 236\nPerdida entrenamiento: 0.28757661695663744\nPerdida validación: 0.5772789008915424\nÉpoca 237\nPerdida entrenamiento: 0.28811851946207195\nPerdida validación: 0.7320586889982224\nÉpoca 238\nPerdida entrenamiento: 0.28815625779903853\nPerdida validación: 0.7152724415063858\nÉpoca 239\nPerdida entrenamiento: 0.28606483340263367\nPerdida validación: 0.6598239541053772\nÉpoca 240\nPerdida entrenamiento: 0.285346840436642\nPerdida validación: 0.6209026128053665\nÉpoca 241\nPerdida entrenamiento: 0.2845807350598849\nPerdida validación: 0.7468656450510025\nÉpoca 242\nPerdida entrenamiento: 0.2821243279255353\nPerdida validación: 0.7041357904672623\nÉpoca 243\nPerdida entrenamiento: 0.28611129178450656\nPerdida validación: 0.6743378043174744\nÉpoca 244\nPerdida entrenamiento: 0.284884695823376\nPerdida validación: 0.6707199811935425\nÉpoca 245\nPerdida entrenamiento: 0.2815088893358524\nPerdida validación: 0.5728727634996176\nÉpoca 246\nPerdida entrenamiento: 0.28080847744758314\nPerdida validación: 0.6702363193035126\nÉpoca 247\nPerdida entrenamiento: 0.2867404520511627\nPerdida validación: 0.5843783281743526\nÉpoca 248\nPerdida entrenamiento: 0.2806525001159081\nPerdida validación: 0.7861420884728432\nÉpoca 249\nPerdida entrenamiento: 0.27863137194743526\nPerdida validación: 0.6410687640309334\nÉpoca 250\nPerdida entrenamiento: 0.2770683398613563\nPerdida validación: 0.5936639066785574\nÉpoca 251\nPerdida entrenamiento: 0.2768169263234505\nPerdida validación: 0.6833072006702423\nÉpoca 252\nPerdida entrenamiento: 0.2748305465166385\nPerdida validación: 0.6042004376649857\nÉpoca 253\nPerdida entrenamiento: 0.2757860215810629\nPerdida validación: 0.7947159111499786\nÉpoca 254\nPerdida entrenamiento: 0.2751406201949486\nPerdida validación: 0.6367254927754402\nÉpoca 255\nPerdida entrenamiento: 0.2708621449195422\nPerdida validación: 0.7180898785591125\nÉpoca 256\nPerdida entrenamiento: 0.275149221603687\nPerdida validación: 0.7423695474863052\nÉpoca 257\nPerdida entrenamiento: 0.2727271203811352\nPerdida validación: 0.9060819447040558\nÉpoca 258\nPerdida entrenamiento: 0.2681584942799348\nPerdida validación: 0.5963035766035318\nÉpoca 259\nPerdida entrenamiento: 0.27062331025417036\nPerdida validación: 0.873478040099144\nÉpoca 260\nPerdida entrenamiento: 0.2674179868056224\nPerdida validación: 0.8986184149980545\nÉpoca 261\nPerdida entrenamiento: 0.2690170338520637\nPerdida validación: 0.6592900529503822\nÉpoca 262\nPerdida entrenamiento: 0.26846447587013245\nPerdida validación: 0.9479366093873978\nÉpoca 263\nPerdida entrenamiento: 0.26402759552001953\nPerdida validación: 0.9008272737264633\nÉpoca 264\nPerdida entrenamiento: 0.2652583489051232\nPerdida validación: 0.6301005408167839\nÉpoca 265\nPerdida entrenamiento: 0.2668720644253951\nPerdida validación: 0.6739533171057701\nÉpoca 266\nPerdida entrenamiento: 0.261234122973222\nPerdida validación: 0.8646781742572784\nÉpoca 267\nPerdida entrenamiento: 0.26453658250662\nPerdida validación: 0.6588940024375916\nÉpoca 268\nPerdida entrenamiento: 0.2624517106092893\nPerdida validación: 0.6618993282318115\nÉpoca 269\nPerdida entrenamiento: 0.26085009712439317\nPerdida validación: 0.8263240605592728\nÉpoca 270\nPerdida entrenamiento: 0.2599637359380722\nPerdida validación: 0.6784602850675583\nÉpoca 271\nPerdida entrenamiento: 0.257305567081158\nPerdida validación: 0.6983089298009872\nÉpoca 272\nPerdida entrenamiento: 0.25707618319071257\nPerdida validación: 0.7596462219953537\nÉpoca 273\nPerdida entrenamiento: 0.25479228565326106\nPerdida validación: 0.8516096025705338\nÉpoca 274\nPerdida entrenamiento: 0.2555289314343379\nPerdida validación: 0.6697004027664661\nÉpoca 275\nPerdida entrenamiento: 0.25535631752931154\nPerdida validación: 0.7662394493818283\nÉpoca 276\nPerdida entrenamiento: 0.25399595499038696\nPerdida validación: 0.6714568100869656\nÉpoca 277\nPerdida entrenamiento: 0.2534373849630356\nPerdida validación: 0.8177104741334915\nÉpoca 278\nPerdida entrenamiento: 0.2528454798918504\nPerdida validación: 0.6949421167373657\nÉpoca 279\nPerdida entrenamiento: 0.2524537363877663\nPerdida validación: 0.6863048002123833\nÉpoca 280\nPerdida entrenamiento: 0.2513547700185042\nPerdida validación: 0.9646367728710175\nÉpoca 281\nPerdida entrenamiento: 0.25098807078141433\nPerdida validación: 0.8969951719045639\nÉpoca 282\nPerdida entrenamiento: 0.2472042705004032\nPerdida validación: 0.8082799464464188\nÉpoca 283\nPerdida entrenamiento: 0.24754732789901587\nPerdida validación: 0.7941425144672394\nÉpoca 284\nPerdida entrenamiento: 0.24609676003456116\nPerdida validación: 0.684365876019001\nÉpoca 285\nPerdida entrenamiento: 0.2511652432955228\nPerdida validación: 0.8623279631137848\nÉpoca 286\nPerdida entrenamiento: 0.24547406687186316\nPerdida validación: 0.6912081725895405\nÉpoca 287\nPerdida entrenamiento: 0.2429599383702645\nPerdida validación: 0.9732776954770088\nÉpoca 288\nPerdida entrenamiento: 0.2432185262441635\nPerdida validación: 1.0060452669858932\nÉpoca 289\nPerdida entrenamiento: 0.24023229227616236\nPerdida validación: 0.8277311474084854\nÉpoca 290\nPerdida entrenamiento: 0.23955060427005476\nPerdida validación: 0.786811426281929\nÉpoca 291\nPerdida entrenamiento: 0.23958009022932786\nPerdida validación: 0.7557588405907154\nÉpoca 292\nPerdida entrenamiento: 0.23640594402184853\nPerdida validación: 0.8277218341827393\nÉpoca 293\nPerdida entrenamiento: 0.242647141791307\nPerdida validación: 0.7543492093682289\nÉpoca 294\nPerdida entrenamiento: 0.23744144004124862\nPerdida validación: 0.9005269259214401\nÉpoca 295\nPerdida entrenamiento: 0.23505891057161185\nPerdida validación: 1.0138403475284576\nÉpoca 296\nPerdida entrenamiento: 0.23421819106890604\nPerdida validación: 0.8683191686868668\nÉpoca 297\nPerdida entrenamiento: 0.2318978040264203\nPerdida validación: 0.8101358413696289\nÉpoca 298\nPerdida entrenamiento: 0.23346705046983865\nPerdida validación: 0.7712786123156548\nÉpoca 299\nPerdida entrenamiento: 0.23196385686214155\nPerdida validación: 0.7931528687477112\nÉpoca 300\nPerdida entrenamiento: 0.23038125955141509\nPerdida validación: 0.9017031192779541\nÉpoca 301\nPerdida entrenamiento: 0.2300905608213865\nPerdida validación: 0.8927458971738815\nÉpoca 302\nPerdida entrenamiento: 0.22902650099534255\nPerdida validación: 0.7802269160747528\nÉpoca 303\nPerdida entrenamiento: 0.22824548184871674\nPerdida validación: 0.7526897303760052\nÉpoca 304\nPerdida entrenamiento: 0.22763773340445298\nPerdida validación: 0.8381522595882416\nÉpoca 305\nPerdida entrenamiento: 0.22718356033930412\nPerdida validación: 0.8254359364509583\nÉpoca 306\nPerdida entrenamiento: 0.22468459835419288\nPerdida validación: 1.0651862174272537\nÉpoca 307\nPerdida entrenamiento: 0.2252236008644104\nPerdida validación: 0.7800127901136875\nÉpoca 308\nPerdida entrenamiento: 0.22522478034863105\nPerdida validación: 0.7735980823636055\nÉpoca 309\nPerdida entrenamiento: 0.22313766926527023\nPerdida validación: 0.9621244966983795\nÉpoca 310\nPerdida entrenamiento: 0.22204241729699647\nPerdida validación: 1.0749974250793457\nÉpoca 311\nPerdida entrenamiento: 0.22262436610001785\nPerdida validación: 1.3250411748886108\nÉpoca 312\nPerdida entrenamiento: 0.21946634925328767\nPerdida validación: 1.220914050936699\nÉpoca 313\nPerdida entrenamiento: 0.2192572527206861\nPerdida validación: 1.041431501507759\nÉpoca 314\nPerdida entrenamiento: 0.22139415374168983\nPerdida validación: 0.8025665357708931\nÉpoca 315\nPerdida entrenamiento: 0.21974669626125923\nPerdida validación: 0.8422096148133278\nÉpoca 316\nPerdida entrenamiento: 0.21913381665945053\nPerdida validación: 0.8897643834352493\nÉpoca 317\nPerdida entrenamiento: 0.21626591223936814\nPerdida validación: 1.055869460105896\nÉpoca 318\nPerdida entrenamiento: 0.21514099263227904\nPerdida validación: 1.1917777508497238\nÉpoca 319\nPerdida entrenamiento: 0.21370321741470924\nPerdida validación: 1.0201979875564575\nÉpoca 320\nPerdida entrenamiento: 0.21699885450876677\nPerdida validación: 0.8245937786996365\nÉpoca 321\nPerdida entrenamiento: 0.21201098309113428\nPerdida validación: 1.1265588402748108\nÉpoca 322\nPerdida entrenamiento: 0.21394624962256506\nPerdida validación: 0.962070643901825\nÉpoca 323\nPerdida entrenamiento: 0.20957350157774413\nPerdida validación: 0.9868338853120804\nÉpoca 324\nPerdida entrenamiento: 0.21265120231188261\nPerdida validación: 0.8874924257397652\nÉpoca 325\nPerdida entrenamiento: 0.2091066837310791\nPerdida validación: 1.0081952214241028\nÉpoca 326\nPerdida entrenamiento: 0.21077775267454293\nPerdida validación: 0.8385808542370796\nÉpoca 327\nPerdida entrenamiento: 0.20795948058366776\nPerdida validación: 0.8538511730730534\nÉpoca 328\nPerdida entrenamiento: 0.20780498018631569\nPerdida validación: 0.9103939160704613\nÉpoca 329\nPerdida entrenamiento: 0.20708075280372912\nPerdida validación: 1.1897397637367249\nÉpoca 330\nPerdida entrenamiento: 0.20662683363144213\nPerdida validación: 0.885913148522377\nÉpoca 331\nPerdida entrenamiento: 0.20712659450677726\nPerdida validación: 1.0818254053592682\nÉpoca 332\nPerdida entrenamiento: 0.20439559909013602\nPerdida validación: 1.0768046230077744\nÉpoca 333\nPerdida entrenamiento: 0.20461885745708758\nPerdida validación: 0.9814814329147339\nÉpoca 334\nPerdida entrenamiento: 0.20301808130282623\nPerdida validación: 1.1490432769060135\nÉpoca 335\nPerdida entrenamiento: 0.2035538857946029\nPerdida validación: 1.178459957242012\nÉpoca 336\nPerdida entrenamiento: 0.20196825036635765\nPerdida validación: 1.0208635181188583\nÉpoca 337\nPerdida entrenamiento: 0.20007529854774475\nPerdida validación: 0.8982732370495796\nÉpoca 338\nPerdida entrenamiento: 0.20441429087748894\nPerdida validación: 1.2766572535037994\nÉpoca 339\nPerdida entrenamiento: 0.19922098345481432\nPerdida validación: 1.2669693678617477\nÉpoca 340\nPerdida entrenamiento: 0.20049226914460844\nPerdida validación: 1.1927863359451294\nÉpoca 341\nPerdida entrenamiento: 0.19930510165599677\nPerdida validación: 1.1106315851211548\nÉpoca 342\nPerdida entrenamiento: 0.1986603576403398\nPerdida validación: 0.9161171913146973\nÉpoca 343\nPerdida entrenamiento: 0.1980497338450872\nPerdida validación: 0.8788779089227319\nÉpoca 344\nPerdida entrenamiento: 0.19675294711039618\nPerdida validación: 0.926335796713829\nÉpoca 345\nPerdida entrenamiento: 0.1941346635039036\nPerdida validación: 1.0945035070180893\nÉpoca 346\nPerdida entrenamiento: 0.1936252420911422\nPerdida validación: 1.0377127081155777\nÉpoca 347\nPerdida entrenamiento: 0.19242666776363665\nPerdida validación: 1.2945685386657715\nÉpoca 348\nPerdida entrenamiento: 0.19187256120718443\nPerdida validación: 1.0255257040262222\nÉpoca 349\nPerdida entrenamiento: 0.19146961661485526\nPerdida validación: 1.3043287247419357\nÉpoca 350\nPerdida entrenamiento: 0.19094201062734312\nPerdida validación: 0.9868040531873703\nÉpoca 351\nPerdida entrenamiento: 0.1926536777844796\nPerdida validación: 0.9217413030564785\nÉpoca 352\nPerdida entrenamiento: 0.1905878747885044\nPerdida validación: 0.9125046692788601\nÉpoca 353\nPerdida entrenamiento: 0.187868713759459\nPerdida validación: 0.9345213063061237\nÉpoca 354\nPerdida entrenamiento: 0.18901339631814223\nPerdida validación: 0.9942605942487717\nÉpoca 355\nPerdida entrenamiento: 0.18814368947194174\nPerdida validación: 0.9075269959867001\nÉpoca 356\nPerdida entrenamiento: 0.18838231953290793\nPerdida validación: 1.0101798176765442\nÉpoca 357\nPerdida entrenamiento: 0.1871264118414659\nPerdida validación: 1.3163970857858658\nÉpoca 358\nPerdida entrenamiento: 0.18556923533861452\nPerdida validación: 1.1430521309375763\nÉpoca 359\nPerdida entrenamiento: 0.18438442624532259\nPerdida validación: 1.0945535898208618\nÉpoca 360\nPerdida entrenamiento: 0.18359505041287497\nPerdida validación: 1.1046949326992035\nÉpoca 361\nPerdida entrenamiento: 0.18347960653213355\nPerdida validación: 1.0777917206287384\nÉpoca 362\nPerdida entrenamiento: 0.18606625038843888\nPerdida validación: 1.039321780204773\nÉpoca 363\nPerdida entrenamiento: 0.1835288187632194\nPerdida validación: 1.8219835758209229\nÉpoca 364\nPerdida entrenamiento: 0.1832315560716849\nPerdida validación: 0.9855913817882538\nÉpoca 365\nPerdida entrenamiento: 0.18345200499662986\nPerdida validación: 1.3815755248069763\nÉpoca 366\nPerdida entrenamiento: 0.18204493877979425\nPerdida validación: 1.3143933415412903\nÉpoca 367\nPerdida entrenamiento: 0.18039714430387205\nPerdida validación: 1.1001662760972977\nÉpoca 368\nPerdida entrenamiento: 0.1790039367400683\nPerdida validación: 1.1200962960720062\nÉpoca 369\nPerdida entrenamiento: 0.17842322817215553\nPerdida validación: 1.248393177986145\nÉpoca 370\nPerdida entrenamiento: 0.17733524567805803\nPerdida validación: 1.1019806116819382\nÉpoca 371\nPerdida entrenamiento: 0.18092230707406998\nPerdida validación: 1.0071088895201683\nÉpoca 372\nPerdida entrenamiento: 0.1787138833449437\nPerdida validación: 0.9970914125442505\nÉpoca 373\nPerdida entrenamiento: 0.17536774850808656\nPerdida validación: 1.2062337547540665\nÉpoca 374\nPerdida entrenamiento: 0.1755595069665175\nPerdida validación: 1.2552458047866821\nÉpoca 375\nPerdida entrenamiento: 0.17521371291233942\nPerdida validación: 1.3755380511283875\nÉpoca 376\nPerdida entrenamiento: 0.17484821493809038\nPerdida validación: 0.9694990161806345\nÉpoca 377\nPerdida entrenamiento: 0.16993199575405854\nPerdida validación: 1.2601993381977081\nÉpoca 378\nPerdida entrenamiento: 0.17217573007711998\nPerdida validación: 1.0045286491513252\nÉpoca 379\nPerdida entrenamiento: 0.16950746167164582\nPerdida validación: 1.0718081295490265\nÉpoca 380\nPerdida entrenamiento: 0.17159914741149315\nPerdida validación: 1.4655284881591797\nÉpoca 381\nPerdida entrenamiento: 0.16838658973574638\nPerdida validación: 1.1533843874931335\nÉpoca 382\nPerdida entrenamiento: 0.17031876341654703\nPerdida validación: 0.9962851293385029\nÉpoca 383\nPerdida entrenamiento: 0.16913885737840945\nPerdida validación: 1.7159227132797241\nÉpoca 384\nPerdida entrenamiento: 0.16765954746649817\nPerdida validación: 1.159842073917389\nÉpoca 385\nPerdida entrenamiento: 0.1671962749499541\nPerdida validación: 1.4913894534111023\nÉpoca 386\nPerdida entrenamiento: 0.1681254764015858\nPerdida validación: 1.122810274362564\nÉpoca 387\nPerdida entrenamiento: 0.165319480575048\nPerdida validación: 1.54014253616333\nÉpoca 388\nPerdida entrenamiento: 0.16413759382871482\nPerdida validación: 1.1817348301410675\nÉpoca 389\nPerdida entrenamiento: 0.1640704136628371\nPerdida validación: 1.2460854202508926\nÉpoca 390\nPerdida entrenamiento: 0.16306643531872675\nPerdida validación: 1.609892874956131\nÉpoca 391\nPerdida entrenamiento: 0.16301732109143183\nPerdida validación: 1.4515731483697891\nÉpoca 392\nPerdida entrenamiento: 0.16136908989686233\nPerdida validación: 1.096735492348671\nÉpoca 393\nPerdida entrenamiento: 0.16398021177603647\nPerdida validación: 1.068606436252594\nÉpoca 394\nPerdida entrenamiento: 0.15940716748054212\nPerdida validación: 1.2023451328277588\nÉpoca 395\nPerdida entrenamiento: 0.16102972282813147\nPerdida validación: 1.3458791375160217\nÉpoca 396\nPerdida entrenamiento: 0.15895120684917158\nPerdida validación: 1.1531001776456833\nÉpoca 397\nPerdida entrenamiento: 0.16065807869801155\nPerdida validación: 1.4515523314476013\nÉpoca 398\nPerdida entrenamiento: 0.16089507135061118\nPerdida validación: 1.0475106053054333\nÉpoca 399\nPerdida entrenamiento: 0.1607217674071972\nPerdida validación: 1.0925526916980743\nÉpoca 400\nPerdida entrenamiento: 0.15985893744688767\nPerdida validación: 1.1263118088245392\nÉpoca 401\nPerdida entrenamiento: 0.15693163986389452\nPerdida validación: 1.5815104246139526\nÉpoca 402\nPerdida entrenamiento: 0.15736779341330895\nPerdida validación: 1.3613525032997131\nÉpoca 403\nPerdida entrenamiento: 0.15994859314881837\nPerdida validación: 1.3299525380134583\nÉpoca 404\nPerdida entrenamiento: 0.15524562992728674\nPerdida validación: 1.129160463809967\nÉpoca 405\nPerdida entrenamiento: 0.15532630681991577\nPerdida validación: 1.2196290791034698\nÉpoca 406\nPerdida entrenamiento: 0.15297087396566683\nPerdida validación: 2.013798788189888\nÉpoca 407\nPerdida entrenamiento: 0.15678289418037122\nPerdida validación: 1.579893410205841\nÉpoca 408\nPerdida entrenamiento: 0.15148546947882727\nPerdida validación: 1.1102407947182655\nÉpoca 409\nPerdida entrenamiento: 0.15315252427871412\nPerdida validación: 1.093673411756754\nÉpoca 410\nPerdida entrenamiento: 0.15141890599177435\nPerdida validación: 1.3287800699472427\nÉpoca 411\nPerdida entrenamiento: 0.15180933131621435\nPerdida validación: 1.3786164820194244\nÉpoca 412\nPerdida entrenamiento: 0.1497001200914383\nPerdida validación: 1.5654205977916718\nÉpoca 413\nPerdida entrenamiento: 0.1539385886146472\nPerdida validación: 1.0817826110869646\nÉpoca 414\nPerdida entrenamiento: 0.1514056955392544\nPerdida validación: 1.9382396638393402\nÉpoca 415\nPerdida entrenamiento: 0.15173272100778726\nPerdida validación: 1.3418876677751541\nÉpoca 416\nPerdida entrenamiento: 0.14910465880082205\nPerdida validación: 1.8640508651733398\nÉpoca 417\nPerdida entrenamiento: 0.14727372017044288\nPerdida validación: 1.1653900444507599\nÉpoca 418\nPerdida entrenamiento: 0.1486102778177995\nPerdida validación: 1.4865805208683014\nÉpoca 419\nPerdida entrenamiento: 0.1470818628485386\nPerdida validación: 1.8298079371452332\nÉpoca 420\nPerdida entrenamiento: 0.14542641719946495\nPerdida validación: 1.8267624229192734\nÉpoca 421\nPerdida entrenamiento: 0.1465584973876293\nPerdida validación: 1.7401020023971796\nÉpoca 422\nPerdida entrenamiento: 0.1459429063476049\nPerdida validación: 1.8647668659687042\nÉpoca 423\nPerdida entrenamiento: 0.14751056438455215\nPerdida validación: 1.853477194905281\nÉpoca 424\nPerdida entrenamiento: 0.14484965801239014\nPerdida validación: 1.9142803102731705\nÉpoca 425\nPerdida entrenamiento: 0.14378211962488982\nPerdida validación: 1.9636558592319489\nÉpoca 426\nPerdida entrenamiento: 0.14685687107535508\nPerdida validación: 2.342496156692505\nÉpoca 427\nPerdida entrenamiento: 0.1424619727409803\nPerdida validación: 4.561129406094551\nÉpoca 428\nPerdida entrenamiento: 0.14290866886193937\nPerdida validación: 4.768705457448959\nÉpoca 429\nPerdida entrenamiento: 0.1421340394478578\nPerdida validación: 2.390932723879814\nÉpoca 430\nPerdida entrenamiento: 0.14333476355442634\nPerdida validación: 1.9665760695934296\nÉpoca 431\nPerdida entrenamiento: 0.14370077475905418\nPerdida validación: 4.5777967274188995\nÉpoca 432\nPerdida entrenamiento: 0.1428644536779477\nPerdida validación: 1.915467545390129\nÉpoca 433\nPerdida entrenamiento: 0.1437031918993363\nPerdida validación: 1.8353270888328552\nÉpoca 434\nPerdida entrenamiento: 0.1391112907574727\nPerdida validación: 1.8254324793815613\nÉpoca 435\nPerdida entrenamiento: 0.14128816758210844\nPerdida validación: 2.2376081943511963\nÉpoca 436\nPerdida entrenamiento: 0.13954832634100547\nPerdida validación: 4.6626335978508\nÉpoca 437\nPerdida entrenamiento: 0.138767588023956\nPerdida validación: 1.7955627366900444\nÉpoca 438\nPerdida entrenamiento: 0.140621029986785\nPerdida validación: 1.9822211861610413\nÉpoca 439\nPerdida entrenamiento: 0.13871822305596793\nPerdida validación: 1.8298685476183891\nÉpoca 440\nPerdida entrenamiento: 0.13960186392068863\nPerdida validación: 2.2689503729343414\nÉpoca 441\nPerdida entrenamiento: 0.1384184412085093\nPerdida validación: 1.978897362947464\nÉpoca 442\nPerdida entrenamiento: 0.1393213366659788\nPerdida validación: 1.796176865696907\nÉpoca 443\nPerdida entrenamiento: 0.1366216018795967\nPerdida validación: 1.8592241257429123\nÉpoca 444\nPerdida entrenamiento: 0.13682998573550811\nPerdida validación: 1.7595698600634933\nÉpoca 445\nPerdida entrenamiento: 0.13522964973862356\nPerdida validación: 1.9084278345108032\nÉpoca 446\nPerdida entrenamiento: 0.13606802832621795\nPerdida validación: 2.1424740850925446\nÉpoca 447\nPerdida entrenamiento: 0.13595753048474973\nPerdida validación: 1.9501730501651764\nÉpoca 448\nPerdida entrenamiento: 0.13536394158234963\nPerdida validación: 1.7681202897801995\nÉpoca 449\nPerdida entrenamiento: 0.13383748439642099\nPerdida validación: 1.776937936898321\nÉpoca 450\nPerdida entrenamiento: 0.134520024061203\nPerdida validación: 2.3689710795879364\nÉpoca 451\nPerdida entrenamiento: 0.13803439873915452\nPerdida validación: 2.100162461400032\nÉpoca 452\nPerdida entrenamiento: 0.1336829622204487\nPerdida validación: 2.2752034962177277\nÉpoca 453\nPerdida entrenamiento: 0.13292249807944664\nPerdida validación: 1.995318591594696\nÉpoca 454\nPerdida entrenamiento: 0.13514817792635697\nPerdida validación: 1.9861263036727905\nÉpoca 455\nPerdida entrenamiento: 0.1320819346090922\nPerdida validación: 1.9134028553962708\nÉpoca 456\nPerdida entrenamiento: 0.13178949975050414\nPerdida validación: 2.345687836408615\nÉpoca 457\nPerdida entrenamiento: 0.13060673899375475\nPerdida validación: 1.7884992298204452\nÉpoca 458\nPerdida entrenamiento: 0.13102037072754824\nPerdida validación: 2.0062188506126404\nÉpoca 459\nPerdida entrenamiento: 0.13201026274607733\nPerdida validación: 2.2236380875110626\nÉpoca 460\nPerdida entrenamiento: 0.13188833112900072\nPerdida validación: 1.913369283080101\nÉpoca 461\nPerdida entrenamiento: 0.13061570146909127\nPerdida validación: 2.1135205924510956\nÉpoca 462\nPerdida entrenamiento: 0.12994415083756813\nPerdida validación: 2.502940058708191\nÉpoca 463\nPerdida entrenamiento: 0.13231988767018685\nPerdida validación: 2.2688323259353638\nÉpoca 464\nPerdida entrenamiento: 0.132278629220449\nPerdida validación: 1.9339222609996796\nÉpoca 465\nPerdida entrenamiento: 0.1299718085389871\nPerdida validación: 1.854475636035204\nÉpoca 466\nPerdida entrenamiento: 0.13145282578009826\nPerdida validación: 2.1876435577869415\nÉpoca 467\nPerdida entrenamiento: 0.1313119169611197\nPerdida validación: 2.0629679560661316\nÉpoca 468\nPerdida entrenamiento: 0.12963297819862\nPerdida validación: 1.8632949441671371\nÉpoca 469\nPerdida entrenamiento: 0.13173786350167715\nPerdida validación: 2.3062230050563812\nÉpoca 470\nPerdida entrenamiento: 0.12814507748071963\nPerdida validación: 1.8778863623738289\nÉpoca 471\nPerdida entrenamiento: 0.1295533965413387\nPerdida validación: 2.0298818349838257\nÉpoca 472\nPerdida entrenamiento: 0.12830456117024788\nPerdida validación: 1.8326761359348893\nÉpoca 473\nPerdida entrenamiento: 0.13108183042361185\nPerdida validación: 1.8978855609893799\nÉpoca 474\nPerdida entrenamiento: 0.12631277166880095\nPerdida validación: 1.8579567857086658\nÉpoca 475\nPerdida entrenamiento: 0.1265657704610091\nPerdida validación: 1.8173991988878697\nÉpoca 476\nPerdida entrenamiento: 0.1263832891216645\nPerdida validación: 2.03189879655838\nÉpoca 477\nPerdida entrenamiento: 0.1271198460688958\nPerdida validación: 2.035249412059784\nÉpoca 478\nPerdida entrenamiento: 0.12515214171547157\nPerdida validación: 2.3506749868392944\nÉpoca 479\nPerdida entrenamiento: 0.1258234651042865\nPerdida validación: 2.0357569456100464\nÉpoca 480\nPerdida entrenamiento: 0.12334210511583549\nPerdida validación: 2.3931768983602524\nÉpoca 481\nPerdida entrenamiento: 0.12442116553966816\nPerdida validación: 1.8402148545719683\nÉpoca 482\nPerdida entrenamiento: 0.12398571349107303\nPerdida validación: 1.8500240058638155\nÉpoca 483\nPerdida entrenamiento: 0.12187421866334401\nPerdida validación: 2.4725755900144577\nÉpoca 484\nPerdida entrenamiento: 0.12302208233338136\nPerdida validación: 2.2796106934547424\nÉpoca 485\nPerdida entrenamiento: 0.12683135729569656\nPerdida validación: 1.8626185692846775\nÉpoca 486\nPerdida entrenamiento: 0.12531459446136767\nPerdida validación: 2.2455354630947113\nÉpoca 487\nPerdida entrenamiento: 0.12518665194511414\nPerdida validación: 2.294196218252182\nÉpoca 488\nPerdida entrenamiento: 0.12416661272828396\nPerdida validación: 5.504393815994263\nÉpoca 489\nPerdida entrenamiento: 0.12151235857835183\nPerdida validación: 4.765833288431168\nÉpoca 490\nPerdida entrenamiento: 0.12303080123204452\nPerdida validación: 2.5530178621411324\nÉpoca 491\nPerdida entrenamiento: 0.1221739208469024\nPerdida validación: 2.623643547296524\nÉpoca 492\nPerdida entrenamiento: 0.12077710233055629\nPerdida validación: 2.641333118081093\nÉpoca 493\nPerdida entrenamiento: 0.12215936126617286\nPerdida validación: 2.523965746164322\nÉpoca 494\nPerdida entrenamiento: 0.12131250764314945\nPerdida validación: 2.86473748087883\nÉpoca 495\nPerdida entrenamiento: 0.11971759996735133\nPerdida validación: 2.8849087059497833\nÉpoca 496\nPerdida entrenamiento: 0.11921405147474545\nPerdida validación: 3.088648520410061\nÉpoca 497\nPerdida entrenamiento: 0.11881179362535477\nPerdida validación: 2.7041009813547134\nÉpoca 498\nPerdida entrenamiento: 0.12069269728202087\nPerdida validación: 2.701828509569168\nÉpoca 499\nPerdida entrenamiento: 0.11688872054219246\nPerdida validación: 2.6526040136814117\nÉpoca 500\nPerdida entrenamiento: 0.12055957403320533\nPerdida validación: 2.768251270055771\nÉpoca 501\nPerdida entrenamiento: 0.1185041986978971\nPerdida validación: 2.610110007226467\nÉpoca 502\nPerdida entrenamiento: 0.11842981869211563\nPerdida validación: 2.783321276307106\nÉpoca 503\nPerdida entrenamiento: 0.11740847648336337\nPerdida validación: 5.701580911874771\nÉpoca 504\nPerdida entrenamiento: 0.11811252511464633\nPerdida validación: 5.549773216247559\nÉpoca 505\nPerdida entrenamiento: 0.11450959799381402\nPerdida validación: 2.8138828575611115\nÉpoca 506\nPerdida entrenamiento: 0.1174502051793612\nPerdida validación: 2.615239202976227\nÉpoca 507\nPerdida entrenamiento: 0.11577433175765552\nPerdida validación: 2.584429509937763\nÉpoca 508\nPerdida entrenamiento: 0.11714056907938077\nPerdida validación: 2.5579630389111117\nÉpoca 509\nPerdida entrenamiento: 0.11275060732777302\nPerdida validación: 2.8419259935617447\nÉpoca 510\nPerdida entrenamiento: 0.11713154499347393\nPerdida validación: 3.056575983762741\nÉpoca 511\nPerdida entrenamiento: 0.11541045027283522\nPerdida validación: 2.8400514125823975\nÉpoca 512\nPerdida entrenamiento: 0.11325491334383304\nPerdida validación: 2.6306902319192886\nÉpoca 513\nPerdida entrenamiento: 0.11358885925549728\nPerdida validación: 2.571716500679031\nÉpoca 514\nPerdida entrenamiento: 0.11338759013093434\nPerdida validación: 2.9470843076705933\nÉpoca 515\nPerdida entrenamiento: 0.11455664554467568\nPerdida validación: 2.9394672214984894\nÉpoca 516\nPerdida entrenamiento: 0.11280371965124057\nPerdida validación: 5.647374600172043\nÉpoca 517\nPerdida entrenamiento: 0.11306084377261308\nPerdida validación: 2.619787771254778\nÉpoca 518\nPerdida entrenamiento: 0.1135869212448597\nPerdida validación: 2.853236883878708\nÉpoca 519\nPerdida entrenamiento: 0.11409064611563316\nPerdida validación: 5.546691715717316\nÉpoca 520\nPerdida entrenamiento: 0.1118229848261063\nPerdida validación: 2.745006173849106\nÉpoca 521\nPerdida entrenamiento: 0.11278153583407402\nPerdida validación: 3.1580388844013214\nÉpoca 522\nPerdida entrenamiento: 0.11320935247036126\nPerdida validación: 2.7071564495563507\nÉpoca 523\nPerdida entrenamiento: 0.11237332626030995\nPerdida validación: 2.6988750621676445\nÉpoca 524\nPerdida entrenamiento: 0.10959484084294392\nPerdida validación: 3.124171957373619\nÉpoca 525\nPerdida entrenamiento: 0.11166479524511558\nPerdida validación: 5.45481139421463\nÉpoca 526\nPerdida entrenamiento: 0.11054900173957531\nPerdida validación: 3.007249414920807\nÉpoca 527\nPerdida entrenamiento: 0.11383987246797635\nPerdida validación: 2.8005631417036057\nÉpoca 528\nPerdida entrenamiento: 0.10905527896606006\nPerdida validación: 3.0521177500486374\nÉpoca 529\nPerdida entrenamiento: 0.11215656551604088\nPerdida validación: 2.909767299890518\nÉpoca 530\nPerdida entrenamiento: 0.11102713014070804\nPerdida validación: 2.6694091595709324\nÉpoca 531\nPerdida entrenamiento: 0.10923272371292114\nPerdida validación: 2.6914474070072174\nÉpoca 532\nPerdida entrenamiento: 0.10927552013443066\nPerdida validación: 2.8471918255090714\nÉpoca 533\nPerdida entrenamiento: 0.11039042931336623\nPerdida validación: 5.58680272102356\nÉpoca 534\nPerdida entrenamiento: 0.11040670768572734\nPerdida validación: 5.831094592809677\nÉpoca 535\nPerdida entrenamiento: 0.10797414355553113\nPerdida validación: 2.8358536660671234\nÉpoca 536\nPerdida entrenamiento: 0.10849945705670577\nPerdida validación: 2.847647100687027\nÉpoca 537\nPerdida entrenamiento: 0.10771226997558887\nPerdida validación: 2.6895657889544964\nÉpoca 538\nPerdida entrenamiento: 0.10608476199782811\nPerdida validación: 2.9265541434288025\nÉpoca 539\nPerdida entrenamiento: 0.10907147738796014\nPerdida validación: 3.472039520740509\nÉpoca 540\nPerdida entrenamiento: 0.10541577493915191\nPerdida validación: 2.654316759100766\nÉpoca 541\nPerdida entrenamiento: 0.10745507736618702\nPerdida validación: 5.496880441904068\nÉpoca 542\nPerdida entrenamiento: 0.10491894815976803\nPerdida validación: 2.7173368334770203\nÉpoca 543\nPerdida entrenamiento: 0.1082516282510299\nPerdida validación: 5.47006168961525\nÉpoca 544\nPerdida entrenamiento: 0.10422761451739532\nPerdida validación: 2.749433569610119\nÉpoca 545\nPerdida entrenamiento: 0.1062567073565263\nPerdida validación: 2.848259523510933\nÉpoca 546\nPerdida entrenamiento: 0.10411920971595325\nPerdida validación: 3.7098141610622406\nÉpoca 547\nPerdida entrenamiento: 0.10428597262272468\nPerdida validación: 2.771275945007801\nÉpoca 548\nPerdida entrenamiento: 0.10482547260247745\nPerdida validación: 2.740638144314289\nÉpoca 549\nPerdida entrenamiento: 0.10570188955618785\nPerdida validación: 3.0091414153575897\nÉpoca 550\nPerdida entrenamiento: 0.10292766644404484\nPerdida validación: 3.15601310133934\nÉpoca 551\nPerdida entrenamiento: 0.10313611305676974\nPerdida validación: 3.4876405000686646\nÉpoca 552\nPerdida entrenamiento: 0.102155673962373\nPerdida validación: 2.9055378437042236\nÉpoca 553\nPerdida entrenamiento: 0.10382852617364663\nPerdida validación: 2.723412472754717\nÉpoca 554\nPerdida entrenamiento: 0.10259475057514814\nPerdida validación: 5.492315292358398\nÉpoca 555\nPerdida entrenamiento: 0.10145168722822116\nPerdida validación: 2.754060558974743\nÉpoca 556\nPerdida entrenamiento: 0.10143737294352971\nPerdida validación: 3.07767117023468\nÉpoca 557\nPerdida entrenamiento: 0.1056364316206712\nPerdida validación: 2.9746521413326263\nÉpoca 558\nPerdida entrenamiento: 0.10130224491541202\nPerdida validación: 3.025153934955597\nÉpoca 559\nPerdida entrenamiento: 0.10119306353422311\nPerdida validación: 3.1392782032489777\nÉpoca 560\nPerdida entrenamiento: 0.10136075776356918\nPerdida validación: 3.2021331638097763\nÉpoca 561\nPerdida entrenamiento: 0.10253067285968707\nPerdida validación: 3.076074779033661\nÉpoca 562\nPerdida entrenamiento: 0.10206653034457794\nPerdida validación: 5.530216574668884\nÉpoca 563\nPerdida entrenamiento: 0.10454103207358947\nPerdida validación: 3.2058138102293015\nÉpoca 564\nPerdida entrenamiento: 0.10343335053095451\nPerdida validación: 3.1237970888614655\nÉpoca 565\nPerdida entrenamiento: 0.09964850559257545\nPerdida validación: 3.4429604411125183\nÉpoca 566\nPerdida entrenamiento: 0.10099474125756668\nPerdida validación: 3.31308913230896\nÉpoca 567\nPerdida entrenamiento: 0.09864685397881728\nPerdida validación: 2.990403264760971\nÉpoca 568\nPerdida entrenamiento: 0.10084413794370797\nPerdida validación: 3.0305745601654053\nÉpoca 569\nPerdida entrenamiento: 0.09896215968407117\nPerdida validación: 2.773144192993641\nÉpoca 570\nPerdida entrenamiento: 0.09875178738282277\nPerdida validación: 3.2597747147083282\nÉpoca 571\nPerdida entrenamiento: 0.09714520020553699\nPerdida validación: 2.7881274856626987\nÉpoca 572\nPerdida entrenamiento: 0.09834642221148197\nPerdida validación: 2.897169277071953\nÉpoca 573\nPerdida entrenamiento: 0.09885117368629345\nPerdida validación: 3.086055040359497\nÉpoca 574\nPerdida entrenamiento: 0.09760436788201332\nPerdida validación: 2.9079464077949524\nÉpoca 575\nPerdida entrenamiento: 0.09912287873717454\nPerdida validación: 3.261339485645294\nÉpoca 576\nPerdida entrenamiento: 0.09698486127532445\nPerdida validación: 2.9379115402698517\nÉpoca 577\nPerdida entrenamiento: 0.0979744757597263\nPerdida validación: 3.2120234966278076\nÉpoca 578\nPerdida entrenamiento: 0.0980399100539776\nPerdida validación: 2.905558556318283\nÉpoca 579\nPerdida entrenamiento: 0.09601865737484051\nPerdida validación: 3.2893512845039368\nÉpoca 580\nPerdida entrenamiento: 0.09636882950480168\nPerdida validación: 5.822457730770111\nÉpoca 581\nPerdida entrenamiento: 0.09623523285755745\nPerdida validación: 2.9834419786930084\nÉpoca 582\nPerdida entrenamiento: 0.09567874211531419\nPerdida validación: 2.834209755063057\nÉpoca 583\nPerdida entrenamiento: 0.09520710431612454\nPerdida validación: 3.457405775785446\nÉpoca 584\nPerdida entrenamiento: 0.09503164486243175\nPerdida validación: 2.783683327026665\nÉpoca 585\nPerdida entrenamiento: 0.09478533927064675\nPerdida validación: 3.208044409751892\nÉpoca 586\nPerdida entrenamiento: 0.09366065492996803\nPerdida validación: 2.8148815520107746\nÉpoca 587\nPerdida entrenamiento: 0.09470219050462429\nPerdida validación: 3.1014271676540375\nÉpoca 588\nPerdida entrenamiento: 0.09309046171032466\nPerdida validación: 3.2367973625659943\nÉpoca 589\nPerdida entrenamiento: 0.09493592811318544\nPerdida validación: 3.512310117483139\nÉpoca 590\nPerdida entrenamiento: 0.09326716999594982\nPerdida validación: 3.0231358408927917\nÉpoca 591\nPerdida entrenamiento: 0.09341454792481202\nPerdida validación: 3.043340712785721\nÉpoca 592\nPerdida entrenamiento: 0.09278626940571345\nPerdida validación: 5.691175103187561\nÉpoca 593\nPerdida entrenamiento: 0.09466937327614197\nPerdida validación: 3.352739989757538\nÉpoca 594\nPerdida entrenamiento: 0.09303238815986194\nPerdida validación: 3.332100570201874\nÉpoca 595\nPerdida entrenamiento: 0.0932160415328466\nPerdida validación: 3.2494913041591644\nÉpoca 596\nPerdida entrenamiento: 0.09378410044770974\nPerdida validación: 3.2207201719284058\nÉpoca 597\nPerdida entrenamiento: 0.09273648376648243\nPerdida validación: 2.8693348169326782\nÉpoca 598\nPerdida entrenamiento: 0.09436917047087963\nPerdida validación: 2.8971500992774963\nÉpoca 599\nPerdida entrenamiento: 0.09192508573715504\nPerdida validación: 3.5734232664108276\nÉpoca 600\nPerdida entrenamiento: 0.0922428432565469\nPerdida validación: 3.286315381526947\nÉpoca 601\nPerdida entrenamiento: 0.090951818972826\nPerdida validación: 2.839483904186636\nÉpoca 602\nPerdida entrenamiento: 0.09206941953072181\nPerdida validación: 6.175304114818573\nÉpoca 603\nPerdida entrenamiento: 0.0930221310028663\nPerdida validación: 3.414512574672699\nÉpoca 604\nPerdida entrenamiento: 0.09010667654757316\nPerdida validación: 2.8338278711307794\nÉpoca 605\nPerdida entrenamiento: 0.09371261155376068\nPerdida validación: 3.4049655497074127\nÉpoca 606\nPerdida entrenamiento: 0.09388583640639599\nPerdida validación: 3.5773722529411316\nÉpoca 607\nPerdida entrenamiento: 0.09048281996869124\nPerdida validación: 3.2947387397289276\nÉpoca 608\nPerdida entrenamiento: 0.09159044520213054\nPerdida validación: 2.9430512189865112\nÉpoca 609\nPerdida entrenamiento: 0.08964369574991557\nPerdida validación: 3.3014421463012695\nÉpoca 610\nPerdida entrenamiento: 0.08908333887274449\nPerdida validación: 2.998455196619034\nÉpoca 611\nPerdida entrenamiento: 0.09090320049570157\nPerdida validación: 5.645829796791077\nÉpoca 612\nPerdida entrenamiento: 0.08766440416757877\nPerdida validación: 2.9032982736825943\nÉpoca 613\nPerdida entrenamiento: 0.08854922107779063\nPerdida validación: 3.060891628265381\nÉpoca 614\nPerdida entrenamiento: 0.08976021638283363\nPerdida validación: 3.0479705929756165\nÉpoca 615\nPerdida entrenamiento: 0.08961896913555953\nPerdida validación: 4.045959830284119\nÉpoca 616\nPerdida entrenamiento: 0.08848642328610787\nPerdida validación: 5.979500740766525\nÉpoca 617\nPerdida entrenamiento: 0.08795142374359645\nPerdida validación: 3.2142326831817627\nÉpoca 618\nPerdida entrenamiento: 0.08949532818335754\nPerdida validación: 3.4921406507492065\nÉpoca 619\nPerdida entrenamiento: 0.08757467159571555\nPerdida validación: 2.9816556125879288\nÉpoca 620\nPerdida entrenamiento: 0.0879586089688998\nPerdida validación: 3.0630840808153152\nÉpoca 621\nPerdida entrenamiento: 0.08634372141498786\nPerdida validación: 4.073459208011627\nÉpoca 622\nPerdida entrenamiento: 0.08796885366050097\nPerdida validación: 2.9151867516338825\nÉpoca 623\nPerdida entrenamiento: 0.08707575729260078\nPerdida validación: 3.223273813724518\nÉpoca 624\nPerdida entrenamiento: 0.08563883115465824\nPerdida validación: 3.0873585641384125\nÉpoca 625\nPerdida entrenamiento: 0.08584944187448575\nPerdida validación: 2.9525046534836292\nÉpoca 626\nPerdida entrenamiento: 0.08701738285330626\nPerdida validación: 3.099105030298233\nÉpoca 627\nPerdida entrenamiento: 0.08607068084753476\nPerdida validación: 5.73407855629921\nÉpoca 628\nPerdida entrenamiento: 0.08767787438745682\nPerdida validación: 2.8967090360820293\nÉpoca 629\nPerdida entrenamiento: 0.08825744960743648\nPerdida validación: 3.380082130432129\nÉpoca 630\nPerdida entrenamiento: 0.0873606692139919\nPerdida validación: 3.1084282398223877\nÉpoca 631\nPerdida entrenamiento: 0.08586964011192322\nPerdida validación: 3.7326546162366867\nÉpoca 632\nPerdida entrenamiento: 0.08663071577365582\nPerdida validación: 5.914897799491882\nÉpoca 633\nPerdida entrenamiento: 0.08718680790983714\nPerdida validación: 2.9612930342555046\nÉpoca 634\nPerdida entrenamiento: 0.085944925649808\nPerdida validación: 3.224094897508621\nÉpoca 635\nPerdida entrenamiento: 0.0844750301196025\nPerdida validación: 3.0974116921424866\nÉpoca 636\nPerdida entrenamiento: 0.08396346781116265\nPerdida validación: 3.4633867144584656\nÉpoca 637\nPerdida entrenamiento: 0.08545709831210282\nPerdida validación: 2.9578521959483624\nÉpoca 638\nPerdida entrenamiento: 0.08674065195597135\nPerdida validación: 2.949578620493412\nÉpoca 639\nPerdida entrenamiento: 0.08519237488508224\nPerdida validación: 3.2103909254074097\nÉpoca 640\nPerdida entrenamiento: 0.08840005414990279\nPerdida validación: 3.0627825558185577\nÉpoca 641\nPerdida entrenamiento: 0.0849433932453394\nPerdida validación: 3.172268331050873\nÉpoca 642\nPerdida entrenamiento: 0.08262179534022625\nPerdida validación: 3.236430197954178\nÉpoca 643\nPerdida entrenamiento: 0.08367389583816895\nPerdida validación: 2.942924888804555\nÉpoca 644\nPerdida entrenamiento: 0.08231127118835083\nPerdida validación: 3.27776700258255\nÉpoca 645\nPerdida entrenamiento: 0.08604721839611347\nPerdida validación: 2.9394181985408068\nÉpoca 646\nPerdida entrenamiento: 0.08392453394257106\nPerdida validación: 3.0016921162605286\nÉpoca 647\nPerdida entrenamiento: 0.08415115481385818\nPerdida validación: 3.1223526895046234\nÉpoca 648\nPerdida entrenamiento: 0.08276968549650449\nPerdida validación: 2.978962305933237\nÉpoca 649\nPerdida entrenamiento: 0.08537436477266826\nPerdida validación: 3.432997077703476\nÉpoca 650\nPerdida entrenamiento: 0.0837293887654176\nPerdida validación: 3.4656736850738525\nÉpoca 651\nPerdida entrenamiento: 0.08413175550790933\nPerdida validación: 3.3202735409140587\nÉpoca 652\nPerdida entrenamiento: 0.08189639592399964\nPerdida validación: 3.8872807025909424\nÉpoca 653\nPerdida entrenamiento: 0.08280348534194323\nPerdida validación: 6.082957550883293\nÉpoca 654\nPerdida entrenamiento: 0.08127718963302098\nPerdida validación: 3.207852452993393\nÉpoca 655\nPerdida entrenamiento: 0.08102134758463272\nPerdida validación: 3.252897948026657\nÉpoca 656\nPerdida entrenamiento: 0.08139984109080754\nPerdida validación: 2.9737558010965586\nÉpoca 657\nPerdida entrenamiento: 0.08038559813912098\nPerdida validación: 3.310336619615555\nÉpoca 658\nPerdida entrenamiento: 0.07984856028969471\nPerdida validación: 3.006955109536648\nÉpoca 659\nPerdida entrenamiento: 0.08055987037145175\nPerdida validación: 3.5304589942097664\nÉpoca 660\nPerdida entrenamiento: 0.08210009408111756\nPerdida validación: 3.9923764169216156\nÉpoca 661\nPerdida entrenamiento: 0.08106890879571438\nPerdida validación: 3.647656798362732\nÉpoca 662\nPerdida entrenamiento: 0.0803337491189058\nPerdida validación: 3.0062214881181717\nÉpoca 663\nPerdida entrenamiento: 0.08178974587756854\nPerdida validación: 3.8203519582748413\nÉpoca 664\nPerdida entrenamiento: 0.07993544179659623\nPerdida validación: 5.766702353954315\nÉpoca 665\nPerdida entrenamiento: 0.07951982949788754\nPerdida validación: 3.537745386362076\nÉpoca 666\nPerdida entrenamiento: 0.07966543834369916\nPerdida validación: 3.3440269827842712\nÉpoca 667\nPerdida entrenamiento: 0.07974013012762253\nPerdida validación: 3.4005532264709473\nÉpoca 668\nPerdida entrenamiento: 0.08048110283338107\nPerdida validación: 6.076398730278015\nÉpoca 669\nPerdida entrenamiento: 0.07910338760568546\nPerdida validación: 3.1290396749973297\nÉpoca 670\nPerdida entrenamiento: 0.07919158643254867\nPerdida validación: 3.0483686476945877\nÉpoca 671\nPerdida entrenamiento: 0.07788696125722848\nPerdida validación: 6.258003294467926\nÉpoca 672\nPerdida entrenamiento: 0.08138983582074825\nPerdida validación: 3.043996773660183\nÉpoca 673\nPerdida entrenamiento: 0.08381304632012661\nPerdida validación: 2.9912613732740283\nÉpoca 674\nPerdida entrenamiento: 0.08171401430781071\nPerdida validación: 3.2535914480686188\nÉpoca 675\nPerdida entrenamiento: 0.07973616025768794\nPerdida validación: 3.008113071322441\nÉpoca 676\nPerdida entrenamiento: 0.08049123103802021\nPerdida validación: 3.3409511744976044\nÉpoca 677\nPerdida entrenamiento: 0.0830245754466607\nPerdida validación: 6.382318615913391\nÉpoca 678\nPerdida entrenamiento: 0.0790841830177949\nPerdida validación: 3.5300813168287277\nÉpoca 679\nPerdida entrenamiento: 0.07988710758777764\nPerdida validación: 3.441707044839859\nÉpoca 680\nPerdida entrenamiento: 0.07954001054167747\nPerdida validación: 3.0263784900307655\nÉpoca 681\nPerdida entrenamiento: 0.08027764732161394\nPerdida validación: 3.698488086462021\nÉpoca 682\nPerdida entrenamiento: 0.07939692701284702\nPerdida validación: 6.145058274269104\nÉpoca 683\nPerdida entrenamiento: 0.07660764312514892\nPerdida validación: 4.3174373507499695\nÉpoca 684\nPerdida entrenamiento: 0.07766298620173565\nPerdida validación: 6.3749352395534515\nÉpoca 685\nPerdida entrenamiento: 0.07970923471909303\nPerdida validación: 4.056097626686096\nÉpoca 686\nPerdida entrenamiento: 0.07719844278807823\nPerdida validación: 3.051921732723713\nÉpoca 687\nPerdida entrenamiento: 0.0781680206553294\nPerdida validación: 3.4439048767089844\nÉpoca 688\nPerdida entrenamiento: 0.07667693667686902\nPerdida validación: 3.182342290878296\nÉpoca 689\nPerdida entrenamiento: 0.0783315381178489\nPerdida validación: 3.228578358888626\nÉpoca 690\nPerdida entrenamiento: 0.07471121217195804\nPerdida validación: 3.2710892260074615\nÉpoca 691\nPerdida entrenamiento: 0.07603253968633138\nPerdida validación: 3.523540109395981\nÉpoca 692\nPerdida entrenamiento: 0.07471496525865334\nPerdida validación: 3.411119043827057\nÉpoca 693\nPerdida entrenamiento: 0.0752135177071278\nPerdida validación: 3.4445889592170715\nÉpoca 694\nPerdida entrenamiento: 0.07611862613031498\nPerdida validación: 3.559295654296875\nÉpoca 695\nPerdida entrenamiento: 0.0759881936873381\nPerdida validación: 3.5824018120765686\nÉpoca 696\nPerdida entrenamiento: 0.07466840600738159\nPerdida validación: 3.9484466910362244\nÉpoca 697\nPerdida entrenamiento: 0.0735154255078389\nPerdida validación: 3.0945662409067154\nÉpoca 698\nPerdida entrenamiento: 0.07556946203112602\nPerdida validación: 3.3838585913181305\nÉpoca 699\nPerdida entrenamiento: 0.075852148521405\nPerdida validación: 3.9069823026657104\nÉpoca 700\nPerdida entrenamiento: 0.07505714750060669\nPerdida validación: 3.286153644323349\nÉpoca 701\nPerdida entrenamiento: 0.07513145830195683\nPerdida validación: 3.0753321163356304\nÉpoca 702\nPerdida entrenamiento: 0.07591709723839393\nPerdida validación: 3.383682131767273\nÉpoca 703\nPerdida entrenamiento: 0.07662103439752872\nPerdida validación: 6.287557303905487\nÉpoca 704\nPerdida entrenamiento: 0.074071651038069\nPerdida validación: 3.51538348197937\nÉpoca 705\nPerdida entrenamiento: 0.07326486592109387\nPerdida validación: 3.647996246814728\nÉpoca 706\nPerdida entrenamiento: 0.07368115650919768\nPerdida validación: 3.0932504013180733\nÉpoca 707\nPerdida entrenamiento: 0.0751225554312651\nPerdida validación: 5.895449340343475\nÉpoca 708\nPerdida entrenamiento: 0.07395617950421113\nPerdida validación: 5.860315516591072\nÉpoca 709\nPerdida entrenamiento: 0.07535010304015416\nPerdida validación: 3.0919011384248734\nÉpoca 710\nPerdida entrenamiento: 0.07465821561905053\nPerdida validación: 5.954198464751244\nÉpoca 711\nPerdida entrenamiento: 0.07308040587947918\nPerdida validación: 3.787451297044754\nÉpoca 712\nPerdida entrenamiento: 0.07293918241675083\nPerdida validación: 3.5140918493270874\nÉpoca 713\nPerdida entrenamiento: 0.07424381232032409\nPerdida validación: 3.5032528042793274\nÉpoca 714\nPerdida entrenamiento: 0.07196107234519261\nPerdida validación: 3.103741290047765\nÉpoca 715\nPerdida entrenamiento: 0.07321044630729236\nPerdida validación: 3.2048414945602417\nÉpoca 716\nPerdida entrenamiento: 0.07338270552169818\nPerdida validación: 3.4842203855514526\nÉpoca 717\nPerdida entrenamiento: 0.07320698207387558\nPerdida validación: 3.547133982181549\nÉpoca 718\nPerdida entrenamiento: 0.07335239849411525\nPerdida validación: 3.3462226688861847\nÉpoca 719\nPerdida entrenamiento: 0.07362754786243805\nPerdida validación: 3.0637363731259484\nÉpoca 720\nPerdida entrenamiento: 0.07329921933034292\nPerdida validación: 3.5014507174491882\nÉpoca 721\nPerdida entrenamiento: 0.07308094232128216\nPerdida validación: 3.600960463285446\nÉpoca 722\nPerdida entrenamiento: 0.07359824429910916\nPerdida validación: 3.6419607996940613\nÉpoca 723\nPerdida entrenamiento: 0.0702361033942837\nPerdida validación: 3.3048584163188934\nÉpoca 724\nPerdida entrenamiento: 0.07198195188091351\nPerdida validación: 3.635326474905014\nÉpoca 725\nPerdida entrenamiento: 0.07143456402879494\nPerdida validación: 3.1239943015389144\nÉpoca 726\nPerdida entrenamiento: 0.07296538524902783\nPerdida validación: 3.9761489629745483\nÉpoca 727\nPerdida entrenamiento: 0.06996076797636655\nPerdida validación: 3.673790752887726\nÉpoca 728\nPerdida entrenamiento: 0.07061829260335518\nPerdida validación: 3.527384489774704\nÉpoca 729\nPerdida entrenamiento: 0.07066990879292671\nPerdida validación: 3.565238893032074\nÉpoca 730\nPerdida entrenamiento: 0.06986354305767097\nPerdida validación: 3.1452227979898453\nÉpoca 731\nPerdida entrenamiento: 0.07251900878663246\nPerdida validación: 3.676050305366516\nÉpoca 732\nPerdida entrenamiento: 0.07029389106453611\nPerdida validación: 6.303750157356262\nÉpoca 733\nPerdida entrenamiento: 0.07063901882905227\nPerdida validación: 3.6955054998397827\nÉpoca 734\nPerdida entrenamiento: 0.07026771971812615\nPerdida validación: 3.6877950727939606\nÉpoca 735\nPerdida entrenamiento: 0.07010470860852645\nPerdida validación: 3.8105451464653015\nÉpoca 736\nPerdida entrenamiento: 0.07092373674878708\nPerdida validación: 6.272245496511459\nÉpoca 737\nPerdida entrenamiento: 0.06938746227667882\nPerdida validación: 4.11859667301178\nÉpoca 738\nPerdida entrenamiento: 0.07033284137455317\nPerdida validación: 3.489028960466385\nÉpoca 739\nPerdida entrenamiento: 0.07005046737881807\nPerdida validación: 3.9497650265693665\nÉpoca 740\nPerdida entrenamiento: 0.06991838477551937\nPerdida validación: 3.5906466245651245\nÉpoca 741\nPerdida entrenamiento: 0.07006746086363609\nPerdida validación: 4.010214567184448\nÉpoca 742\nPerdida entrenamiento: 0.06976071902765678\nPerdida validación: 3.903961181640625\nÉpoca 743\nPerdida entrenamiento: 0.07007302042956536\nPerdida validación: 3.373776465654373\nÉpoca 744\nPerdida entrenamiento: 0.06779414845200685\nPerdida validación: 3.4710806906223297\nÉpoca 745\nPerdida entrenamiento: 0.06950925863706149\nPerdida validación: 3.2723368108272552\nÉpoca 746\nPerdida entrenamiento: 0.06822979550522107\nPerdida validación: 3.880464196205139\nÉpoca 747\nPerdida entrenamiento: 0.06774935606293954\nPerdida validación: 4.389346688985825\nÉpoca 748\nPerdida entrenamiento: 0.06761566936396636\nPerdida validación: 3.15746596394456\nÉpoca 749\nPerdida entrenamiento: 0.06839605879325134\nPerdida validación: 3.3875818252563477\nÉpoca 750\nPerdida entrenamiento: 0.06772242185588066\nPerdida validación: 3.1746858982369304\nÉpoca 751\nPerdida entrenamiento: 0.06843308130135903\nPerdida validación: 3.2046142797917128\nÉpoca 752\nPerdida entrenamiento: 0.06832610113689533\nPerdida validación: 3.952906757593155\nÉpoca 753\nPerdida entrenamiento: 0.0690260434953066\nPerdida validación: 3.7516192197799683\nÉpoca 754\nPerdida entrenamiento: 0.06749802698882726\nPerdida validación: 3.1946978587657213\nÉpoca 755\nPerdida entrenamiento: 0.06692473447093597\nPerdida validación: 3.173951795324683\nÉpoca 756\nPerdida entrenamiento: 0.06698934733867645\nPerdida validación: 3.6998668909072876\nÉpoca 757\nPerdida entrenamiento: 0.06710446482667556\nPerdida validación: 6.106452941894531\nÉpoca 758\nPerdida entrenamiento: 0.06671396270394325\nPerdida validación: 3.59967178106308\nÉpoca 759\nPerdida entrenamiento: 0.0667688400986103\nPerdida validación: 4.006033331155777\nÉpoca 760\nPerdida entrenamiento: 0.06433771564983405\nPerdida validación: 9.396792531013489\nÉpoca 761\nPerdida entrenamiento: 0.0658060577339851\nPerdida validación: 3.6313920319080353\nÉpoca 762\nPerdida entrenamiento: 0.06626230678879298\nPerdida validación: 3.1925170212052763\nÉpoca 763\nPerdida entrenamiento: 0.06445745751261711\nPerdida validación: 3.2214292294811457\nÉpoca 764\nPerdida entrenamiento: 0.0656591676748716\nPerdida validación: 3.7026621997356415\nÉpoca 765\nPerdida entrenamiento: 0.06652211283261959\nPerdida validación: 4.019250392913818\nÉpoca 766\nPerdida entrenamiento: 0.0645568874449684\nPerdida validación: 3.2478851601481438\nÉpoca 767\nPerdida entrenamiento: 0.0645436357993346\nPerdida validación: 3.634760797023773\nÉpoca 768\nPerdida entrenamiento: 0.06626242198623143\nPerdida validación: 3.2138933995738626\nÉpoca 769\nPerdida entrenamiento: 0.06454834657219741\nPerdida validación: 3.4520061314105988\nÉpoca 770\nPerdida entrenamiento: 0.06424231254137479\nPerdida validación: 6.513358294963837\nÉpoca 771\nPerdida entrenamiento: 0.0674513099858394\nPerdida validación: 3.208299418911338\nÉpoca 772\nPerdida entrenamiento: 0.06449403012028107\nPerdida validación: 3.4559914767742157\nÉpoca 773\nPerdida entrenamiento: 0.06507012119086888\nPerdida validación: 3.4043886959552765\nÉpoca 774\nPerdida entrenamiento: 0.06500616096533261\nPerdida validación: 3.7424195408821106\nÉpoca 775\nPerdida entrenamiento: 0.06445603316219953\nPerdida validación: 3.2316817604005337\nÉpoca 776\nPerdida entrenamiento: 0.06395076867192984\nPerdida validación: 3.3793974220752716\nÉpoca 777\nPerdida entrenamiento: 0.06544297073896115\nPerdida validación: 3.6280748546123505\nÉpoca 778\nPerdida entrenamiento: 0.06932021118700504\nPerdida validación: 3.5138529241085052\nÉpoca 779\nPerdida entrenamiento: 0.07144579004782897\nPerdida validación: 3.281018428504467\nÉpoca 780\nPerdida entrenamiento: 0.06321389299745743\nPerdida validación: 4.2752964198589325\nÉpoca 781\nPerdida entrenamiento: 0.06387096292410906\nPerdida validación: 6.191157042980194\nÉpoca 782\nPerdida entrenamiento: 0.06328819821087214\nPerdida validación: 4.009998798370361\nÉpoca 783\nPerdida entrenamiento: 0.06345390198895565\nPerdida validación: 3.5408129692077637\nÉpoca 784\nPerdida entrenamiento: 0.06154564581811428\nPerdida validación: 3.728050410747528\nÉpoca 785\nPerdida entrenamiento: 0.06283387785347608\nPerdida validación: 3.271757125854492\nÉpoca 786\nPerdida entrenamiento: 0.06242528486137207\nPerdida validación: 3.5932647585868835\nÉpoca 787\nPerdida entrenamiento: 0.0626249214491019\nPerdida validación: 6.087800234556198\nÉpoca 788\nPerdida entrenamiento: 0.06314485878325425\nPerdida validación: 3.6031576097011566\nÉpoca 789\nPerdida entrenamiento: 0.0641820035301722\nPerdida validación: 3.6429638266563416\nÉpoca 790\nPerdida entrenamiento: 0.06248174120600407\nPerdida validación: 4.228351831436157\nÉpoca 791\nPerdida entrenamiento: 0.06177817901166586\nPerdida validación: 4.137951165437698\nÉpoca 792\nPerdida entrenamiento: 0.0609730864660098\nPerdida validación: 3.5382475554943085\nÉpoca 793\nPerdida entrenamiento: 0.0613269078043791\nPerdida validación: 3.2661752179265022\nÉpoca 794\nPerdida entrenamiento: 0.06030727149202274\nPerdida validación: 6.637757331132889\nÉpoca 795\nPerdida entrenamiento: 0.06137405077998455\nPerdida validación: 3.8624553084373474\nÉpoca 796\nPerdida entrenamiento: 0.0609011253198752\nPerdida validación: 3.3248483315110207\nÉpoca 797\nPerdida entrenamiento: 0.06208982662512706\nPerdida validación: 3.9522294402122498\nÉpoca 798\nPerdida entrenamiento: 0.060166037999666654\nPerdida validación: 3.2770682722330093\nÉpoca 799\nPerdida entrenamiento: 0.06056450558109926\nPerdida validación: 3.343050740659237\nÉpoca 800\nPerdida entrenamiento: 0.06177033111453056\nPerdida validación: 3.580229103565216\nÉpoca 801\nPerdida entrenamiento: 0.060246036746180974\nPerdida validación: 3.505081385374069\nÉpoca 802\nPerdida entrenamiento: 0.061356705326873526\nPerdida validación: 4.062293261289597\nÉpoca 803\nPerdida entrenamiento: 0.05942604003044275\nPerdida validación: 4.110773056745529\nÉpoca 804\nPerdida entrenamiento: 0.060502128245738834\nPerdida validación: 3.8822240233421326\nÉpoca 805\nPerdida entrenamiento: 0.05999588966369629\nPerdida validación: 6.7766527235507965\nÉpoca 806\nPerdida entrenamiento: 0.059047887495790534\nPerdida validación: 4.154969960451126\nÉpoca 807\nPerdida entrenamiento: 0.058758083587655656\nPerdida validación: 4.048469461500645\nÉpoca 808\nPerdida entrenamiento: 0.059343369104541265\nPerdida validación: 3.914748638868332\nÉpoca 809\nPerdida entrenamiento: 0.06124117999122693\nPerdida validación: 3.564255177974701\nÉpoca 810\nPerdida entrenamiento: 0.05879233297533714\nPerdida validación: 3.761751651763916\nÉpoca 811\nPerdida entrenamiento: 0.059525275316375956\nPerdida validación: 3.518033117055893\nÉpoca 812\nPerdida entrenamiento: 0.058720690986284844\nPerdida validación: 3.7310802340507507\nÉpoca 813\nPerdida entrenamiento: 0.059426360118847624\nPerdida validación: 3.907933384180069\nÉpoca 814\nPerdida entrenamiento: 0.05819435217059576\nPerdida validación: 3.6875914335250854\nÉpoca 815\nPerdida entrenamiento: 0.058877732748022445\nPerdida validación: 3.6664465963840485\nÉpoca 816\nPerdida entrenamiento: 0.05832370979568133\nPerdida validación: 3.8303341567516327\nÉpoca 817\nPerdida entrenamiento: 0.05997598550927181\nPerdida validación: 4.546199798583984\nÉpoca 818\nPerdida entrenamiento: 0.06107013658262216\nPerdida validación: 4.69145804643631\nÉpoca 819\nPerdida entrenamiento: 0.056150777981831476\nPerdida validación: 3.3038771846331656\nÉpoca 820\nPerdida entrenamiento: 0.058985657416857205\nPerdida validación: 3.8559694290161133\nÉpoca 821\nPerdida entrenamiento: 0.05928831898535673\nPerdida validación: 4.11640003323555\nÉpoca 822\nPerdida entrenamiento: 0.05734322563960002\nPerdida validación: 4.668489754199982\nÉpoca 823\nPerdida entrenamiento: 0.056264102745514646\nPerdida validación: 3.920742154121399\nÉpoca 824\nPerdida entrenamiento: 0.05873554816039709\nPerdida validación: 3.493961662054062\nÉpoca 825\nPerdida entrenamiento: 0.05683453810902742\nPerdida validación: 6.510374307632446\nÉpoca 826\nPerdida entrenamiento: 0.055070443222155936\nPerdida validación: 4.398071765899658\nÉpoca 827\nPerdida entrenamiento: 0.05675230762706353\nPerdida validación: 4.375220954418182\nÉpoca 828\nPerdida entrenamiento: 0.055023180607419744\nPerdida validación: 6.8428884744644165\nÉpoca 829\nPerdida entrenamiento: 0.05631783174780699\nPerdida validación: 4.441886872053146\nÉpoca 830\nPerdida entrenamiento: 0.05498757557227062\nPerdida validación: 4.170099914073944\nÉpoca 831\nPerdida entrenamiento: 0.05439775250852108\nPerdida validación: 4.17107766866684\nÉpoca 832\nPerdida entrenamiento: 0.05483622884807678\nPerdida validación: 4.0521272122859955\nÉpoca 833\nPerdida entrenamiento: 0.054396349363602124\nPerdida validación: 4.2378314435482025\nÉpoca 834\nPerdida entrenamiento: 0.0537837570389876\nPerdida validación: 6.800297603011131\nÉpoca 835\nPerdida entrenamiento: 0.05468137791523567\nPerdida validación: 4.214636117219925\nÉpoca 836\nPerdida entrenamiento: 0.05472402432217048\nPerdida validación: 4.283179759979248\nÉpoca 837\nPerdida entrenamiento: 0.054236042886399306\nPerdida validación: 4.970643877983093\nÉpoca 838\nPerdida entrenamiento: 0.053958216395515665\nPerdida validación: 4.149262264370918\nÉpoca 839\nPerdida entrenamiento: 0.05368467112286733\nPerdida validación: 4.775151491165161\nÉpoca 840\nPerdida entrenamiento: 0.05479082651436329\nPerdida validación: 4.5180723667144775\nÉpoca 841\nPerdida entrenamiento: 0.05527265548992615\nPerdida validación: 4.143805742263794\nÉpoca 842\nPerdida entrenamiento: 0.05225516497515715\nPerdida validación: 4.767333805561066\nÉpoca 843\nPerdida entrenamiento: 0.05295462655619933\nPerdida validación: 4.054084673523903\nÉpoca 844\nPerdida entrenamiento: 0.052490573591337755\nPerdida validación: 4.043152339756489\nÉpoca 845\nPerdida entrenamiento: 0.05167995869683532\nPerdida validación: 4.035788454610156\nÉpoca 846\nPerdida entrenamiento: 0.05253026355057955\nPerdida validación: 4.491959989070892\nÉpoca 847\nPerdida entrenamiento: 0.05272071479031673\nPerdida validación: 4.08733955770731\nÉpoca 848\nPerdida entrenamiento: 0.051107910461723804\nPerdida validación: 4.299175828695297\nÉpoca 849\nPerdida entrenamiento: 0.05270489319585837\nPerdida validación: 4.7589231133461\nÉpoca 850\nPerdida entrenamiento: 0.05218249845963258\nPerdida validación: 4.42910698056221\nÉpoca 851\nPerdida entrenamiento: 0.0517392076838475\nPerdida validación: 4.063683340325952\nÉpoca 852\nPerdida entrenamiento: 0.05056576960935043\nPerdida validación: 4.544508397579193\nÉpoca 853\nPerdida entrenamiento: 0.050385619298769876\nPerdida validación: 7.497417986392975\nÉpoca 854\nPerdida entrenamiento: 0.051967507729736656\nPerdida validación: 4.558947831392288\nÉpoca 855\nPerdida entrenamiento: 0.050523535993236765\nPerdida validación: 7.215233594179153\nÉpoca 856\nPerdida entrenamiento: 0.05060775463397686\nPerdida validación: 4.495422422885895\nÉpoca 857\nPerdida entrenamiento: 0.05093105721215789\nPerdida validación: 7.129923522472382\nÉpoca 858\nPerdida entrenamiento: 0.05117681049383604\nPerdida validación: 4.351238787174225\nÉpoca 859\nPerdida entrenamiento: 0.05049055363409794\nPerdida validación: 4.08912917599082\nÉpoca 860\nPerdida entrenamiento: 0.05090016857362711\nPerdida validación: 4.626007974147797\nÉpoca 861\nPerdida entrenamiento: 0.0504580932454421\nPerdida validación: 4.207754582166672\nÉpoca 862\nPerdida entrenamiento: 0.050872162414284855\nPerdida validación: 4.572880119085312\nÉpoca 863\nPerdida entrenamiento: 0.05100252135441853\nPerdida validación: 7.2558281272649765\nÉpoca 864\nPerdida entrenamiento: 0.04953286008766064\nPerdida validación: 4.496209770441055\nÉpoca 865\nPerdida entrenamiento: 0.05012407168172873\nPerdida validación: 4.0990868136286736\nÉpoca 866\nPerdida entrenamiento: 0.048918719618366316\nPerdida validación: 4.131444938480854\nÉpoca 867\nPerdida entrenamiento: 0.04928459671254341\nPerdida validación: 5.020654857158661\nÉpoca 868\nPerdida entrenamiento: 0.04903019620822026\nPerdida validación: 4.551450133323669\nÉpoca 869\nPerdida entrenamiento: 0.04945437524181146\nPerdida validación: 4.500010818243027\nÉpoca 870\nPerdida entrenamiento: 0.04856425581070093\nPerdida validación: 4.7949676513671875\nÉpoca 871\nPerdida entrenamiento: 0.04902963899075985\nPerdida validación: 7.995621174573898\nÉpoca 872\nPerdida entrenamiento: 0.04977420273308571\nPerdida validación: 7.18223363161087\nÉpoca 873\nPerdida entrenamiento: 0.04900971413231813\nPerdida validación: 5.231534659862518\nÉpoca 874\nPerdida entrenamiento: 0.049250427060402356\nPerdida validación: 4.179678939282894\nÉpoca 875\nPerdida entrenamiento: 0.048545404337346554\nPerdida validación: 7.5138179659843445\nÉpoca 876\nPerdida entrenamiento: 0.04902011091605975\nPerdida validación: 7.690000653266907\nÉpoca 877\nPerdida entrenamiento: 0.049634022459101215\nPerdida validación: 4.181770049035549\nÉpoca 878\nPerdida entrenamiento: 0.04979390636659586\nPerdida validación: 4.789144668728113\nÉpoca 879\nPerdida entrenamiento: 0.04782095207617833\nPerdida validación: 7.752316355705261\nÉpoca 880\nPerdida entrenamiento: 0.047524592480980433\nPerdida validación: 4.361296311020851\nÉpoca 881\nPerdida entrenamiento: 0.04772741806048613\nPerdida validación: 5.283886909484863\nÉpoca 882\nPerdida entrenamiento: 0.049345526414421886\nPerdida validación: 5.229241371154785\nÉpoca 883\nPerdida entrenamiento: 0.04679644315575178\nPerdida validación: 7.914421200752258\nÉpoca 884\nPerdida entrenamiento: 0.04703991981939627\nPerdida validación: 5.433315575122833\nÉpoca 885\nPerdida entrenamiento: 0.049513145278279595\nPerdida validación: 7.677872061729431\nÉpoca 886\nPerdida entrenamiento: 0.04793915123893665\nPerdida validación: 5.197003066539764\nÉpoca 887\nPerdida entrenamiento: 0.04776551424024197\nPerdida validación: 5.358761668205261\nÉpoca 888\nPerdida entrenamiento: 0.0485514304958857\nPerdida validación: 4.744048622378614\nÉpoca 889\nPerdida entrenamiento: 0.049604152114345476\nPerdida validación: 8.026496231555939\nÉpoca 890\nPerdida entrenamiento: 0.04807417854093588\nPerdida validación: 5.384512186050415\nÉpoca 891\nPerdida entrenamiento: 0.04864290915429592\nPerdida validación: 5.179917335510254\nÉpoca 892\nPerdida entrenamiento: 0.04812890613594881\nPerdida validación: 5.456477701663971\nÉpoca 893\nPerdida entrenamiento: 0.04833104031590315\nPerdida validación: 8.13897693157196\nÉpoca 894\nPerdida entrenamiento: 0.04785565258218692\nPerdida validación: 7.886135160923004\nÉpoca 895\nPerdida entrenamiento: 0.049369161805281274\nPerdida validación: 7.536204218864441\nÉpoca 896\nPerdida entrenamiento: 0.05050841332055055\nPerdida validación: 5.33561635017395\nÉpoca 897\nPerdida entrenamiento: 0.04976207891908976\nPerdida validación: 7.572638392448425\nÉpoca 898\nPerdida entrenamiento: 0.048271565626447015\nPerdida validación: 5.2607505321502686\nÉpoca 899\nPerdida entrenamiento: 0.0469307591422246\nPerdida validación: 4.9310347735881805\nÉpoca 900\nPerdida entrenamiento: 0.046212898853879705\nPerdida validación: 10.429802477359772\nÉpoca 901\nPerdida entrenamiento: 0.04607743311386842\nPerdida validación: 8.391501128673553\nÉpoca 902\nPerdida entrenamiento: 0.0450165058987645\nPerdida validación: 7.945931136608124\nÉpoca 903\nPerdida entrenamiento: 0.04573409936319177\nPerdida validación: 6.206254571676254\nÉpoca 904\nPerdida entrenamiento: 0.046273574662896305\nPerdida validación: 4.837220882647671\nÉpoca 905\nPerdida entrenamiento: 0.04536168943517483\nPerdida validación: 5.7693856954574585\nÉpoca 906\nPerdida entrenamiento: 0.04983616161804933\nPerdida validación: 4.874648252502084\nÉpoca 907\nPerdida entrenamiento: 0.048089443491055414\nPerdida validación: 4.867903176695108\nÉpoca 908\nPerdida entrenamiento: 0.04482537740841508\nPerdida validación: 5.361008048057556\nÉpoca 909\nPerdida entrenamiento: 0.04441759233864454\nPerdida validación: 8.161953628063202\nÉpoca 910\nPerdida entrenamiento: 0.04429550490413721\nPerdida validación: 5.4278759360313416\nÉpoca 911\nPerdida entrenamiento: 0.04375691038484757\nPerdida validación: 5.562376141548157\nÉpoca 912\nPerdida entrenamiento: 0.04385505602336847\nPerdida validación: 5.063310891389847\nÉpoca 913\nPerdida entrenamiento: 0.04419422715615768\nPerdida validación: 5.079816937446594\nÉpoca 914\nPerdida entrenamiento: 0.043570125833726846\nPerdida validación: 5.188879191875458\nÉpoca 915\nPerdida entrenamiento: 0.043833284853742674\nPerdida validación: 4.941752478480339\nÉpoca 916\nPerdida entrenamiento: 0.04390216339379549\nPerdida validación: 4.89091937802732\nÉpoca 917\nPerdida entrenamiento: 0.04507616391548744\nPerdida validación: 5.422266781330109\nÉpoca 918\nPerdida entrenamiento: 0.043265287119608656\nPerdida validación: 5.867627322673798\nÉpoca 919\nPerdida entrenamiento: 0.04298393084452702\nPerdida validación: 7.655619859695435\nÉpoca 920\nPerdida entrenamiento: 0.04295176403740278\nPerdida validación: 10.454034566879272\nÉpoca 921\nPerdida entrenamiento: 0.04356664985131759\nPerdida validación: 5.592731535434723\nÉpoca 922\nPerdida entrenamiento: 0.042768083369502656\nPerdida validación: 4.900315457955003\nÉpoca 923\nPerdida entrenamiento: 0.045229774326659165\nPerdida validación: 5.696951985359192\nÉpoca 924\nPerdida entrenamiento: 0.04300991954425207\nPerdida validación: 4.877590395510197\nÉpoca 925\nPerdida entrenamiento: 0.04320732837256331\nPerdida validación: 5.988415837287903\nÉpoca 926\nPerdida entrenamiento: 0.04337704124358984\nPerdida validación: 8.132118225097656\nÉpoca 927\nPerdida entrenamiento: 0.043636782381397024\nPerdida validación: 5.575676202774048\nÉpoca 928\nPerdida entrenamiento: 0.043071469435325034\nPerdida validación: 7.69149649143219\nÉpoca 929\nPerdida entrenamiento: 0.04279871220485522\nPerdida validación: 8.94551944732666\nÉpoca 930\nPerdida entrenamiento: 0.04158741343193329\nPerdida validación: 5.9363309144973755\nÉpoca 931\nPerdida entrenamiento: 0.042360139437592946\nPerdida validación: 5.669342577457428\nÉpoca 932\nPerdida entrenamiento: 0.04308424804073114\nPerdida validación: 7.684343189001083\nÉpoca 933\nPerdida entrenamiento: 0.042666685265990406\nPerdida validación: 11.007444053888321\nÉpoca 934\nPerdida entrenamiento: 0.04146604684109871\nPerdida validación: 5.555517554283142\nÉpoca 935\nPerdida entrenamiento: 0.04259964572982146\nPerdida validación: 5.175597250461578\nÉpoca 936\nPerdida entrenamiento: 0.04205227105949934\nPerdida validación: 5.40211808681488\nÉpoca 937\nPerdida entrenamiento: 0.04228109278931068\nPerdida validación: 6.1808552742004395\nÉpoca 938\nPerdida entrenamiento: 0.04311830536104166\nPerdida validación: 10.741185247898102\nÉpoca 939\nPerdida entrenamiento: 0.043163470637339815\nPerdida validación: 5.921260833740234\nÉpoca 940\nPerdida entrenamiento: 0.04055054041628654\nPerdida validación: 5.262785702943802\nÉpoca 941\nPerdida entrenamiento: 0.04157177903331243\nPerdida validación: 5.35451865196228\nÉpoca 942\nPerdida entrenamiento: 0.0415198694771299\nPerdida validación: 7.973495125770569\nÉpoca 943\nPerdida entrenamiento: 0.040533507314439006\nPerdida validación: 4.92364627122879\nÉpoca 944\nPerdida entrenamiento: 0.04062959207938267\nPerdida validación: 5.073706194758415\nÉpoca 945\nPerdida entrenamiento: 0.040624873067897097\nPerdida validación: 8.072493553161621\nÉpoca 946\nPerdida entrenamiento: 0.040667824447155\nPerdida validación: 5.12357422709465\nÉpoca 947\nPerdida entrenamiento: 0.04132207554693405\nPerdida validación: 4.931139972992241\nÉpoca 948\nPerdida entrenamiento: 0.041251580589092694\nPerdida validación: 6.213336825370789\nÉpoca 949\nPerdida entrenamiento: 0.03960881582819498\nPerdida validación: 5.1579442620277405\nÉpoca 950\nPerdida entrenamiento: 0.04065688083378168\nPerdida validación: 5.068708926439285\nÉpoca 951\nPerdida entrenamiento: 0.041666437370272785\nPerdida validación: 5.178554832935333\nÉpoca 952\nPerdida entrenamiento: 0.04248258535965131\nPerdida validación: 7.714734971523285\nÉpoca 953\nPerdida entrenamiento: 0.03928559345121567\nPerdida validación: 4.913980485871434\nÉpoca 954\nPerdida entrenamiento: 0.041722226314819776\nPerdida validación: 5.258084446191788\nÉpoca 955\nPerdida entrenamiento: 0.04159032173741322\nPerdida validación: 5.252501457929611\nÉpoca 956\nPerdida entrenamiento: 0.04170346489319435\nPerdida validación: 4.984535411000252\nÉpoca 957\nPerdida entrenamiento: 0.04048321252832046\nPerdida validación: 8.03850769996643\nÉpoca 958\nPerdida entrenamiento: 0.04004818967615183\nPerdida validación: 8.282288789749146\nÉpoca 959\nPerdida entrenamiento: 0.04017204476090578\nPerdida validación: 8.028823256492615\nÉpoca 960\nPerdida entrenamiento: 0.03906387448883974\nPerdida validación: 5.145549774169922\nÉpoca 961\nPerdida entrenamiento: 0.041092993978124395\nPerdida validación: 5.181346893310547\nÉpoca 962\nPerdida entrenamiento: 0.03917228444837607\nPerdida validación: 5.263754636049271\nÉpoca 963\nPerdida entrenamiento: 0.03960341867059469\nPerdida validación: 5.101293057203293\nÉpoca 964\nPerdida entrenamiento: 0.03922462800087837\nPerdida validación: 5.038782596588135\nÉpoca 965\nPerdida entrenamiento: 0.03790095942811324\nPerdida validación: 4.954838437348371\nÉpoca 966\nPerdida entrenamiento: 0.03930759118296779\nPerdida validación: 5.001334883272648\nÉpoca 967\nPerdida entrenamiento: 0.03813998795186098\nPerdida validación: 6.026365399360657\nÉpoca 968\nPerdida entrenamiento: 0.038181327283382416\nPerdida validación: 5.887161493301392\nÉpoca 969\nPerdida entrenamiento: 0.03895379753353504\nPerdida validación: 5.548644781112671\nÉpoca 970\nPerdida entrenamiento: 0.03912664047227456\nPerdida validación: 5.311693072319031\nÉpoca 971\nPerdida entrenamiento: 0.03870617698591489\nPerdida validación: 5.490020513534546\nÉpoca 972\nPerdida entrenamiento: 0.03748865955724166\nPerdida validación: 10.62033686041832\nÉpoca 973\nPerdida entrenamiento: 0.03864966748425594\nPerdida validación: 5.311264842748642\nÉpoca 974\nPerdida entrenamiento: 0.03776480472431733\nPerdida validación: 6.198935285210609\nÉpoca 975\nPerdida entrenamiento: 0.03823253541038586\nPerdida validación: 6.116997182369232\nÉpoca 976\nPerdida entrenamiento: 0.037811676756693766\nPerdida validación: 5.664330780506134\nÉpoca 977\nPerdida entrenamiento: 0.038681479170918465\nPerdida validación: 5.71380490064621\nÉpoca 978\nPerdida entrenamiento: 0.03898881017588652\nPerdida validación: 5.0552245527505875\nÉpoca 979\nPerdida entrenamiento: 0.0369387546984049\nPerdida validación: 5.013122085481882\nÉpoca 980\nPerdida entrenamiento: 0.03696431670911037\nPerdida validación: 5.435646593570709\nÉpoca 981\nPerdida entrenamiento: 0.0377054988191678\nPerdida validación: 7.99576997756958\nÉpoca 982\nPerdida entrenamiento: 0.03688380738290457\nPerdida validación: 5.6264747977256775\nÉpoca 983\nPerdida entrenamiento: 0.03905959971822225\nPerdida validación: 5.130975678563118\nÉpoca 984\nPerdida entrenamiento: 0.03906594059215142\nPerdida validación: 5.282015740871429\nÉpoca 985\nPerdida entrenamiento: 0.040465183269519076\nPerdida validación: 5.062030218541622\nÉpoca 986\nPerdida entrenamiento: 0.039131697912055716\nPerdida validación: 5.825139343738556\nÉpoca 987\nPerdida entrenamiento: 0.03985199138808709\nPerdida validación: 4.996991615742445\nÉpoca 988\nPerdida entrenamiento: 0.03810182027518749\nPerdida validación: 5.061925791203976\nÉpoca 989\nPerdida entrenamiento: 0.03756197885825084\nPerdida validación: 6.193111687898636\nÉpoca 990\nPerdida entrenamiento: 0.037496679104291476\nPerdida validación: 5.766824841499329\nÉpoca 991\nPerdida entrenamiento: 0.037181258703080505\nPerdida validación: 5.420461535453796\nÉpoca 992\nPerdida entrenamiento: 0.03704871022357391\nPerdida validación: 8.288544058799744\nÉpoca 993\nPerdida entrenamiento: 0.03609542168963414\nPerdida validación: 5.090890198945999\nÉpoca 994\nPerdida entrenamiento: 0.03537790541752027\nPerdida validación: 7.8367608189582825\nÉpoca 995\nPerdida entrenamiento: 0.036478488777692504\nPerdida validación: 8.35268884897232\nÉpoca 996\nPerdida entrenamiento: 0.03573003110404198\nPerdida validación: 8.260665535926819\nÉpoca 997\nPerdida entrenamiento: 0.0378370895408667\nPerdida validación: 5.0253689478267916\nÉpoca 998\nPerdida entrenamiento: 0.03472784552006768\nPerdida validación: 7.795221388339996\nÉpoca 999\nPerdida entrenamiento: 0.035625782007208236\nPerdida validación: 5.025393606225407\nÉpoca 1000\nPerdida entrenamiento: 0.034889969401634656\nPerdida validación: 6.157822489738464\n\n\nComo se puede observar la pérdida de validación empieza a ser mucho mayor que la pérdida de entrenamiento, esto es un claro indicador de Overfitting"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html",
    "href": "codigo/ASIM/cod001_Kaggle.html",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "href": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\ndata = pd.read_csv(\"../../data/diabetes.csv\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values\n\ndata.describe()\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n\n\n\ncol_entradas = [\n    \"Pregnancies\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"BMI\",\n    \"DiabetesPedigreeFunction\",\n    \"Age\"\n]\ncol_salidas = [\n    \"Outcome\"\n]\n\n\ndata[col_salidas].head()\n\n\n\n\n\n\n\n\nOutcome\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n2\n1\n\n\n3\n0\n\n\n4\n1"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship\n\nsns.countplot(data=data, x=\"Outcome\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data\n\nstandarScaler_features = StandardScaler().fit(data[col_entradas])\nentradas_norm = standarScaler_features.transform(data[col_entradas])\nsalida_norm = data[col_salidas].values"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#create-neural-network-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#create-neural-network-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network data",
    "text": "Create neural network data\n\nCreate Dataset\n\nclass TabularDataset(Dataset):\n    def __init__(self, ent, sal):\n        self.inputs = torch.tensor(ent, dtype=torch.float32)\n        self.outputs = torch.tensor(sal, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return self.inputs[idx], self.outputs[idx]\n\n\nconjuntoDatos = TabularDataset(ent=entradas_norm, sal=salida_norm)\n\ntrain_ds, val_ds, test_ds = random_split(conjuntoDatos, [0.7, 0.15, 0.15])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=True)\n\n\nfor batch in train_loader:\n    X_batch, y_batch = batch\n    print(X_batch.shape, y_batch.shape)\n\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([26, 8]) torch.Size([26, 1])"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model\n\nclass RedNeuronal(nn.Module):\n    def __init__(self, ent, sal):\n        super(RedNeuronal, self).__init__()\n        self.num_caract = ent\n        self.num_salidas = sal\n        self.fc1 = nn.Linear(self.num_caract, 10)  # Capa oculta 1\n        self.act1 = nn.ReLU()\n        self.fc2 = nn.Linear(10, 12) # Capa oculta 2\n        self.act2 = nn.ReLU()\n        self.fc3 = nn.Linear(12, 13)  # Capa oculta 3\n        self.act3 = nn.ReLU()\n        self.fc4 = nn.Linear(13, self.num_salidas)  # Capa de salida\n        self.act4 = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.act1(self.fc1(x))\n        x = self.act2(self.fc2(x))\n        x = self.act3(self.fc3(x))\n        x = self.act4(self.fc4(x))\n        return x\n\n\nepocas = 1000  # Número de épocas de entrenamiento\nbatch_size = 32  # Tamaño del lote\n\n\nred = RedNeuronal(8, 1)\nred = red.to(device=device1)\n\n\nprint(red.parameters())\n\n&lt;generator object Module.parameters at 0x7f7ae23a5ee0&gt;\n\n\n\ncriterio = nn.BCELoss()\noptimizador = optim.Adam(red.parameters(), lr=0.001)\n\n\n# Entrenar la red neuronal\nfor epoca in range(epocas):\n    perdida_entrenamiento = 0\n    for X_batch, y_batch in train_loader:\n        # Pasar los datos por la red neuronal\n        salida = red(X_batch.to(device=device1))\n\n        # Calcular la pérdida\n        perdida = criterio(salida, y_batch.to(device=device1))\n\n        # Actualizar los pesos\n        optimizador.zero_grad()\n        perdida.backward()\n        optimizador.step()\n        perdida_entrenamiento += perdida.item()\n\n    # Imprimir la pérdida en cada época\n    #print(f\"Época {epoca+1}, pérdida: {perdida.item():.8f}\")\n    perdida_validacion = 0\n    con_exactitud = 0\n    total = 0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            # Pasar los datos por la red neuronal\n            salida = red(X_batch.to(device=device1))\n\n            # Calcular la pérdida\n            perdida = criterio(salida, y_batch.to(device=device1))\n\n            perdida_validacion += perdida.item()\n\n            # Calcular la exactitud\n            _, predicciones = torch.max(salida, 1)\n            con_exactitud += (predicciones.cpu().numpy() == y_batch.cpu().numpy()).sum().item()\n            total += y_batch.shape[0]\n\n    # Imprimir los resultados\n    print(f\"Época {epoca+1}\")\n    print(f\"Perdida entrenamiento: {perdida_entrenamiento/len(train_loader)}\")\n    print(f\"Perdida validación: {perdida_validacion/len(val_loader)}\")\n    print(f\"Exactitud validación: {con_exactitud/total:.4f}\")\n\nÉpoca 1\nPerdida entrenamiento: 0.6791575761402354\nPerdida validación: 0.6788250803947449\nExactitud validación: 18.0609\nÉpoca 2\nPerdida entrenamiento: 0.672294301145217\nPerdida validación: 0.6751690059900284\nExactitud validación: 18.4000\nÉpoca 3\nPerdida entrenamiento: 0.6647399173063391\nPerdida validación: 0.6713864207267761\nExactitud validación: 18.7391\nÉpoca 4\nPerdida entrenamiento: 0.6535137961892521\nPerdida validación: 0.6575797200202942\nExactitud validación: 18.4000\nÉpoca 5\nPerdida entrenamiento: 0.6389946797314812\nPerdida validación: 0.6436730623245239\nExactitud validación: 18.2870\nÉpoca 6\nPerdida entrenamiento: 0.6213853324160856\nPerdida validación: 0.6348690390586853\nExactitud validación: 18.6261\nÉpoca 7\nPerdida entrenamiento: 0.5960922311334049\nPerdida validación: 0.6058164685964584\nExactitud validación: 18.5130\nÉpoca 8\nPerdida entrenamiento: 0.5712940009201274\nPerdida validación: 0.5880416631698608\nExactitud validación: 18.7391\nÉpoca 9\nPerdida entrenamiento: 0.5457583104862886\nPerdida validación: 0.5503197610378265\nExactitud validación: 18.4000\nÉpoca 10\nPerdida entrenamiento: 0.5210335955900305\nPerdida validación: 0.5285529047250748\nExactitud validación: 18.4000\nÉpoca 11\nPerdida entrenamiento: 0.4988165813333848\nPerdida validación: 0.5061830580234528\nExactitud validación: 18.2870\nÉpoca 12\nPerdida entrenamiento: 0.48283538572928486\nPerdida validación: 0.5024331212043762\nExactitud validación: 18.5130\nÉpoca 13\nPerdida entrenamiento: 0.4708527694730198\nPerdida validación: 0.5093462020158768\nExactitud validación: 18.4000\nÉpoca 14\nPerdida entrenamiento: 0.4619144955102135\nPerdida validación: 0.4764373451471329\nExactitud validación: 18.4000\nÉpoca 15\nPerdida entrenamiento: 0.4541836258243112\nPerdida validación: 0.4746478497982025\nExactitud validación: 17.9478\nÉpoca 16\nPerdida entrenamiento: 0.4520234956460841\nPerdida validación: 0.48348189145326614\nExactitud validación: 18.5130\nÉpoca 17\nPerdida entrenamiento: 0.44661900751730976\nPerdida validación: 0.47032642364501953\nExactitud validación: 18.0609\nÉpoca 18\nPerdida entrenamiento: 0.44420213033171263\nPerdida validación: 0.4675467982888222\nExactitud validación: 18.4000\nÉpoca 19\nPerdida entrenamiento: 0.44500470512053547\nPerdida validación: 0.46534235775470734\nExactitud validación: 18.5130\nÉpoca 20\nPerdida entrenamiento: 0.44122909447726083\nPerdida validación: 0.49303658306598663\nExactitud validación: 18.4000\nÉpoca 21\nPerdida entrenamiento: 0.439960497267106\nPerdida validación: 0.4710696116089821\nExactitud validación: 18.0609\nÉpoca 22\nPerdida entrenamiento: 0.43822164395276236\nPerdida validación: 0.4644882157444954\nExactitud validación: 18.4000\nÉpoca 23\nPerdida entrenamiento: 0.43539681855370016\nPerdida validación: 0.48128364980220795\nExactitud validación: 18.4000\nÉpoca 24\nPerdida entrenamiento: 0.43452516373466044\nPerdida validación: 0.49383869767189026\nExactitud validación: 18.5130\nÉpoca 25\nPerdida entrenamiento: 0.4337502367356244\nPerdida validación: 0.461711123585701\nExactitud validación: 18.1739\nÉpoca 26\nPerdida entrenamiento: 0.4328044530223398\nPerdida validación: 0.4867813438177109\nExactitud validación: 18.6261\nÉpoca 27\nPerdida entrenamiento: 0.4315945961896111\nPerdida validación: 0.49709317088127136\nExactitud validación: 18.8522\nÉpoca 28\nPerdida entrenamiento: 0.43218792361371655\nPerdida validación: 0.4762030094861984\nExactitud validación: 18.6261\nÉpoca 29\nPerdida entrenamiento: 0.42929310570744905\nPerdida validación: 0.4678042158484459\nExactitud validación: 18.4000\nÉpoca 30\nPerdida entrenamiento: 0.42652833286453695\nPerdida validación: 0.4651280418038368\nExactitud validación: 18.6261\nÉpoca 31\nPerdida entrenamiento: 0.4259583511773278\nPerdida validación: 0.48188481479883194\nExactitud validación: 18.6261\nÉpoca 32\nPerdida entrenamiento: 0.4245906016405891\nPerdida validación: 0.48621364682912827\nExactitud validación: 18.1739\nÉpoca 33\nPerdida entrenamiento: 0.4256867608603309\nPerdida validación: 0.5174973607063293\nExactitud validación: 18.6261\nÉpoca 34\nPerdida entrenamiento: 0.4248025277081658\nPerdida validación: 0.4981654956936836\nExactitud validación: 18.7391\nÉpoca 35\nPerdida entrenamiento: 0.42286987865672393\nPerdida validación: 0.4870433583855629\nExactitud validación: 18.7391\nÉpoca 36\nPerdida entrenamiento: 0.42132503057227416\nPerdida validación: 0.48050128668546677\nExactitud validación: 18.6261\nÉpoca 37\nPerdida entrenamiento: 0.422717108446009\nPerdida validación: 0.4715006574988365\nExactitud validación: 18.2870\nÉpoca 38\nPerdida entrenamiento: 0.41828276742907133\nPerdida validación: 0.4957212060689926\nExactitud validación: 18.4000\nÉpoca 39\nPerdida entrenamiento: 0.41759711153366985\nPerdida validación: 0.4781687557697296\nExactitud validación: 18.1739\nÉpoca 40\nPerdida entrenamiento: 0.4186316009830026\nPerdida validación: 0.467018261551857\nExactitud validación: 18.7391\nÉpoca 41\nPerdida entrenamiento: 0.41757552763995004\nPerdida validación: 0.47248195111751556\nExactitud validación: 18.5130\nÉpoca 42\nPerdida entrenamiento: 0.41657427479239073\nPerdida validación: 0.5107008069753647\nExactitud validación: 18.9652\nÉpoca 43\nPerdida entrenamiento: 0.41385892559500304\nPerdida validación: 0.48618149757385254\nExactitud validación: 18.6261\nÉpoca 44\nPerdida entrenamiento: 0.4130455264273812\nPerdida validación: 0.48718027025461197\nExactitud validación: 18.1739\nÉpoca 45\nPerdida entrenamiento: 0.4121672230608323\nPerdida validación: 0.49359724670648575\nExactitud validación: 18.4000\nÉpoca 46\nPerdida entrenamiento: 0.4103984973009895\nPerdida validación: 0.5008325800299644\nExactitud validación: 18.6261\nÉpoca 47\nPerdida entrenamiento: 0.40746283005265627\nPerdida validación: 0.5021576881408691\nExactitud validación: 18.4000\nÉpoca 48\nPerdida entrenamiento: 0.4073647067827337\nPerdida validación: 0.4890240281820297\nExactitud validación: 18.5130\nÉpoca 49\nPerdida entrenamiento: 0.40921850765452666\nPerdida validación: 0.5141201466321945\nExactitud validación: 18.4000\nÉpoca 50\nPerdida entrenamiento: 0.40371377503170686\nPerdida validación: 0.5138585902750492\nExactitud validación: 18.4000\nÉpoca 51\nPerdida entrenamiento: 0.40545569798525644\nPerdida validación: 0.49403806775808334\nExactitud validación: 18.7391\nÉpoca 52\nPerdida entrenamiento: 0.4029516472535975\nPerdida validación: 0.4981403201818466\nExactitud validación: 18.4000\nÉpoca 53\nPerdida entrenamiento: 0.40148040301659527\nPerdida validación: 0.470258504152298\nExactitud validación: 18.1739\nÉpoca 54\nPerdida entrenamiento: 0.4014539648504818\nPerdida validación: 0.5071394890546799\nExactitud validación: 18.5130\nÉpoca 55\nPerdida entrenamiento: 0.4001041352748871\nPerdida validación: 0.5059882402420044\nExactitud validación: 18.7391\nÉpoca 56\nPerdida entrenamiento: 0.398499013746486\nPerdida validación: 0.465816680341959\nExactitud validación: 18.1739\nÉpoca 57\nPerdida entrenamiento: 0.39581065318163705\nPerdida validación: 0.4719567634165287\nExactitud validación: 18.4000\nÉpoca 58\nPerdida entrenamiento: 0.3962685343097238\nPerdida validación: 0.49108629673719406\nExactitud validación: 17.9478\nÉpoca 59\nPerdida entrenamiento: 0.3972399699337342\nPerdida validación: 0.5343546643853188\nExactitud validación: 18.4000\nÉpoca 60\nPerdida entrenamiento: 0.39424481111414295\nPerdida validación: 0.5204134956002235\nExactitud validación: 18.0609\nÉpoca 61\nPerdida entrenamiento: 0.3933473562493044\nPerdida validación: 0.48885199427604675\nExactitud validación: 18.2870\nÉpoca 62\nPerdida entrenamiento: 0.39581848593319163\nPerdida validación: 0.5045148134231567\nExactitud validación: 18.6261\nÉpoca 63\nPerdida entrenamiento: 0.39225762381273155\nPerdida validación: 0.49928755313158035\nExactitud validación: 18.5130\nÉpoca 64\nPerdida entrenamiento: 0.39095135120784535\nPerdida validación: 0.49818097054958344\nExactitud validación: 18.4000\nÉpoca 65\nPerdida entrenamiento: 0.39278412917081046\nPerdida validación: 0.51187414675951\nExactitud validación: 18.4000\nÉpoca 66\nPerdida entrenamiento: 0.3880087408949347\nPerdida validación: 0.5048925578594208\nExactitud validación: 18.4000\nÉpoca 67\nPerdida entrenamiento: 0.3891824781894684\nPerdida validación: 0.49526503682136536\nExactitud validación: 18.6261\nÉpoca 68\nPerdida entrenamiento: 0.38694337185691385\nPerdida validación: 0.520538330078125\nExactitud validación: 18.7391\nÉpoca 69\nPerdida entrenamiento: 0.3850225508213043\nPerdida validación: 0.4962310940027237\nExactitud validación: 18.1739\nÉpoca 70\nPerdida entrenamiento: 0.3856160588124219\nPerdida validación: 0.5117396265268326\nExactitud validación: 18.6261\nÉpoca 71\nPerdida entrenamiento: 0.38290825836798725\nPerdida validación: 0.48271531239151955\nExactitud validación: 18.7391\nÉpoca 72\nPerdida entrenamiento: 0.3842119478127536\nPerdida validación: 0.5159867852926254\nExactitud validación: 18.1739\nÉpoca 73\nPerdida entrenamiento: 0.38493889570236206\nPerdida validación: 0.5417948067188263\nExactitud validación: 18.5130\nÉpoca 74\nPerdida entrenamiento: 0.38206734727410707\nPerdida validación: 0.4967944473028183\nExactitud validación: 18.4000\nÉpoca 75\nPerdida entrenamiento: 0.3789928336353863\nPerdida validación: 0.518608808517456\nExactitud validación: 18.5130\nÉpoca 76\nPerdida entrenamiento: 0.3797504796701319\nPerdida validación: 0.5038291662931442\nExactitud validación: 18.2870\nÉpoca 77\nPerdida entrenamiento: 0.3783522914437687\nPerdida validación: 0.5356133580207825\nExactitud validación: 18.1739\nÉpoca 78\nPerdida entrenamiento: 0.37765972754534555\nPerdida validación: 0.5259551480412483\nExactitud validación: 18.4000\nÉpoca 79\nPerdida entrenamiento: 0.3763415795915267\nPerdida validación: 0.5199824124574661\nExactitud validación: 18.0609\nÉpoca 80\nPerdida entrenamiento: 0.3773508159553303\nPerdida validación: 0.49937019497156143\nExactitud validación: 18.2870\nÉpoca 81\nPerdida entrenamiento: 0.37419071442940655\nPerdida validación: 0.5143114551901817\nExactitud validación: 18.6261\nÉpoca 82\nPerdida entrenamiento: 0.37580522544243755\nPerdida validación: 0.5341081693768501\nExactitud validación: 18.4000\nÉpoca 83\nPerdida entrenamiento: 0.3732707009595983\nPerdida validación: 0.5355776324868202\nExactitud validación: 18.6261\nÉpoca 84\nPerdida entrenamiento: 0.37286416923298554\nPerdida validación: 0.5186856985092163\nExactitud validación: 18.4000\nÉpoca 85\nPerdida entrenamiento: 0.3705448946532081\nPerdida validación: 0.5483004599809647\nExactitud validación: 18.4000\nÉpoca 86\nPerdida entrenamiento: 0.3727482636185253\nPerdida validación: 0.5254365280270576\nExactitud validación: 18.2870\nÉpoca 87\nPerdida entrenamiento: 0.3692259718390072\nPerdida validación: 0.5111869126558304\nExactitud validación: 18.5130\nÉpoca 88\nPerdida entrenamiento: 0.37127525315565224\nPerdida validación: 0.5337236076593399\nExactitud validación: 18.4000\nÉpoca 89\nPerdida entrenamiento: 0.37246738461887136\nPerdida validación: 0.5206818729639053\nExactitud validación: 18.1739\nÉpoca 90\nPerdida entrenamiento: 0.3690295158063664\nPerdida validación: 0.5593036413192749\nExactitud validación: 18.5130\nÉpoca 91\nPerdida entrenamiento: 0.369259593241355\nPerdida validación: 0.5117775499820709\nExactitud validación: 18.2870\nÉpoca 92\nPerdida entrenamiento: 0.3679639767198002\nPerdida validación: 0.5290718674659729\nExactitud validación: 18.4000\nÉpoca 93\nPerdida entrenamiento: 0.36736031928483176\nPerdida validación: 0.5078761726617813\nExactitud validación: 18.4000\nÉpoca 94\nPerdida entrenamiento: 0.3644753282561022\nPerdida validación: 0.5632258951663971\nExactitud validación: 18.7391\nÉpoca 95\nPerdida entrenamiento: 0.36306865776286407\nPerdida validación: 0.5218587443232536\nExactitud validación: 18.2870\nÉpoca 96\nPerdida entrenamiento: 0.3643888498053831\nPerdida validación: 0.5354526937007904\nExactitud validación: 18.2870\nÉpoca 97\nPerdida entrenamiento: 0.3653539445470361\nPerdida validación: 0.51034265011549\nExactitud validación: 18.4000\nÉpoca 98\nPerdida entrenamiento: 0.36249710707103505\nPerdida validación: 0.5734138116240501\nExactitud validación: 18.6261\nÉpoca 99\nPerdida entrenamiento: 0.36265045316780314\nPerdida validación: 0.5656266584992409\nExactitud validación: 18.7391\nÉpoca 100\nPerdida entrenamiento: 0.3610046874074375\nPerdida validación: 0.521674856543541\nExactitud validación: 18.2870\nÉpoca 101\nPerdida entrenamiento: 0.35992640081573934\nPerdida validación: 0.5487679094076157\nExactitud validación: 18.2870\nÉpoca 102\nPerdida entrenamiento: 0.3585259414771024\nPerdida validación: 0.548629879951477\nExactitud validación: 18.5130\nÉpoca 103\nPerdida entrenamiento: 0.35833654684178967\nPerdida validación: 0.5379441231489182\nExactitud validación: 18.4000\nÉpoca 104\nPerdida entrenamiento: 0.3592461680664736\nPerdida validación: 0.543404832482338\nExactitud validación: 18.4000\nÉpoca 105\nPerdida entrenamiento: 0.3567296178901897\nPerdida validación: 0.5594352409243584\nExactitud validación: 18.2870\nÉpoca 106\nPerdida entrenamiento: 0.3556781069320791\nPerdida validación: 0.5586513355374336\nExactitud validación: 18.4000\nÉpoca 107\nPerdida entrenamiento: 0.35517681609181795\nPerdida validación: 0.5655415803194046\nExactitud validación: 18.4000\nÉpoca 108\nPerdida entrenamiento: 0.35475079189328584\nPerdida validación: 0.5609813407063484\nExactitud validación: 18.8522\nÉpoca 109\nPerdida entrenamiento: 0.3557695606175591\nPerdida validación: 0.5627079755067825\nExactitud validación: 18.2870\nÉpoca 110\nPerdida entrenamiento: 0.3561686961089863\nPerdida validación: 0.5387836992740631\nExactitud validación: 18.4000\nÉpoca 111\nPerdida entrenamiento: 0.35163088756449085\nPerdida validación: 0.5590721815824509\nExactitud validación: 18.1739\nÉpoca 112\nPerdida entrenamiento: 0.35371597812456246\nPerdida validación: 0.5587764009833336\nExactitud validación: 18.2870\nÉpoca 113\nPerdida entrenamiento: 0.3535332837525536\nPerdida validación: 0.5312048122286797\nExactitud validación: 18.5130\nÉpoca 114\nPerdida entrenamiento: 0.35189832834636464\nPerdida validación: 0.6044761911034584\nExactitud validación: 18.8522\nÉpoca 115\nPerdida entrenamiento: 0.3514702092198765\nPerdida validación: 0.5321017280220985\nExactitud validación: 18.6261\nÉpoca 116\nPerdida entrenamiento: 0.351543351131327\nPerdida validación: 0.5573963150382042\nExactitud validación: 18.6261\nÉpoca 117\nPerdida entrenamiento: 0.3497464911026113\nPerdida validación: 0.5573238208889961\nExactitud validación: 18.4000\nÉpoca 118\nPerdida entrenamiento: 0.3498367386705735\nPerdida validación: 0.5645684897899628\nExactitud validación: 18.2870\nÉpoca 119\nPerdida entrenamiento: 0.35061120899284587\nPerdida validación: 0.5626191198825836\nExactitud validación: 18.5130\nÉpoca 120\nPerdida entrenamiento: 0.34882452558068666\nPerdida validación: 0.5745996534824371\nExactitud validación: 18.2870\nÉpoca 121\nPerdida entrenamiento: 0.3476862302597831\nPerdida validación: 0.5468194410204887\nExactitud validación: 18.4000\nÉpoca 122\nPerdida entrenamiento: 0.34637948432389426\nPerdida validación: 0.533638957887888\nExactitud validación: 17.9478\nÉpoca 123\nPerdida entrenamiento: 0.34753450838958516\nPerdida validación: 0.5294349901378155\nExactitud validación: 18.1739\nÉpoca 124\nPerdida entrenamiento: 0.3470301829716739\nPerdida validación: 0.5638434365391731\nExactitud validación: 18.4000\nÉpoca 125\nPerdida entrenamiento: 0.3439143107217901\nPerdida validación: 0.5707154497504234\nExactitud validación: 18.8522\nÉpoca 126\nPerdida entrenamiento: 0.34399966369656954\nPerdida validación: 0.5750905275344849\nExactitud validación: 18.5130\nÉpoca 127\nPerdida entrenamiento: 0.3459861094460768\nPerdida validación: 0.5637594535946846\nExactitud validación: 18.2870\nÉpoca 128\nPerdida entrenamiento: 0.3425804122405894\nPerdida validación: 0.5966473817825317\nExactitud validación: 18.7391\nÉpoca 129\nPerdida entrenamiento: 0.34382107065004464\nPerdida validación: 0.5452658385038376\nExactitud validación: 18.4000\nÉpoca 130\nPerdida entrenamiento: 0.3432043326251647\nPerdida validación: 0.568010963499546\nExactitud validación: 18.5130\nÉpoca 131\nPerdida entrenamiento: 0.34486333587590384\nPerdida validación: 0.5764288678765297\nExactitud validación: 18.4000\nÉpoca 132\nPerdida entrenamiento: 0.3452732370180242\nPerdida validación: 0.5937597900629044\nExactitud validación: 18.5130\nÉpoca 133\nPerdida entrenamiento: 0.343221268233131\nPerdida validación: 0.6223113089799881\nExactitud validación: 18.7391\nÉpoca 134\nPerdida entrenamiento: 0.3406377662630642\nPerdida validación: 0.6121482476592064\nExactitud validación: 18.7391\nÉpoca 135\nPerdida entrenamiento: 0.34228555770481334\nPerdida validación: 0.5532180443406105\nExactitud validación: 18.1739\nÉpoca 136\nPerdida entrenamiento: 0.3407059855320874\nPerdida validación: 0.6256612241268158\nExactitud validación: 18.6261\nÉpoca 137\nPerdida entrenamiento: 0.33841385210261626\nPerdida validación: 0.6118277311325073\nExactitud validación: 18.7391\nÉpoca 138\nPerdida entrenamiento: 0.3379518126740175\nPerdida validación: 0.5608039274811745\nExactitud validación: 18.4000\nÉpoca 139\nPerdida entrenamiento: 0.33698144818053527\nPerdida validación: 0.6184676513075829\nExactitud validación: 18.6261\nÉpoca 140\nPerdida entrenamiento: 0.3397687033695333\nPerdida validación: 0.6316100880503654\nExactitud validación: 18.5130\nÉpoca 141\nPerdida entrenamiento: 0.33633708515587973\nPerdida validación: 0.5819898918271065\nExactitud validación: 18.6261\nÉpoca 142\nPerdida entrenamiento: 0.33748694290133086\nPerdida validación: 0.6265446171164513\nExactitud validación: 18.1739\nÉpoca 143\nPerdida entrenamiento: 0.3356994197649114\nPerdida validación: 0.6239243969321251\nExactitud validación: 18.4000\nÉpoca 144\nPerdida entrenamiento: 0.33472176159129424\nPerdida validación: 0.6359140202403069\nExactitud validación: 18.4000\nÉpoca 145\nPerdida entrenamiento: 0.3353544543771183\nPerdida validación: 0.623450018465519\nExactitud validación: 18.4000\nÉpoca 146\nPerdida entrenamiento: 0.33618306412416343\nPerdida validación: 0.5927932560443878\nExactitud validación: 18.0609\nÉpoca 147\nPerdida entrenamiento: 0.3340167955440633\nPerdida validación: 0.6286558359861374\nExactitud validación: 18.6261\nÉpoca 148\nPerdida entrenamiento: 0.33400292519260855\nPerdida validación: 0.6745086014270782\nExactitud validación: 18.1739\nÉpoca 149\nPerdida entrenamiento: 0.3350304067134857\nPerdida validación: 0.6481637880206108\nExactitud validación: 18.5130\nÉpoca 150\nPerdida entrenamiento: 0.3336921281674329\nPerdida validación: 0.6298792809247971\nExactitud validación: 18.7391\nÉpoca 151\nPerdida entrenamiento: 0.3350611933890511\nPerdida validación: 0.5883950218558311\nExactitud validación: 18.0609\nÉpoca 152\nPerdida entrenamiento: 0.3336448108448702\nPerdida validación: 0.6367370784282684\nExactitud validación: 18.5130\nÉpoca 153\nPerdida entrenamiento: 0.3326067302156897\nPerdida validación: 0.6520734950900078\nExactitud validación: 18.2870\nÉpoca 154\nPerdida entrenamiento: 0.3309824501766878\nPerdida validación: 0.6116059124469757\nExactitud validación: 18.2870\nÉpoca 155\nPerdida entrenamiento: 0.3331507540800992\nPerdida validación: 0.590815544128418\nExactitud validación: 18.5130\nÉpoca 156\nPerdida entrenamiento: 0.33216743872446175\nPerdida validación: 0.6476473957300186\nExactitud validación: 18.2870\nÉpoca 157\nPerdida entrenamiento: 0.3311873867231257\nPerdida validación: 0.6468140035867691\nExactitud validación: 18.0609\nÉpoca 158\nPerdida entrenamiento: 0.32796593273387237\nPerdida validación: 0.6146449446678162\nExactitud validación: 18.1739\nÉpoca 159\nPerdida entrenamiento: 0.33034057389287386\nPerdida validación: 0.6230598539113998\nExactitud validación: 18.5130\nÉpoca 160\nPerdida entrenamiento: 0.3273730260484359\nPerdida validación: 0.6443871557712555\nExactitud validación: 18.4000\nÉpoca 161\nPerdida entrenamiento: 0.330964570536333\nPerdida validación: 0.6126606613397598\nExactitud validación: 18.6261\nÉpoca 162\nPerdida entrenamiento: 0.33085155487060547\nPerdida validación: 0.6176680326461792\nExactitud validación: 18.5130\nÉpoca 163\nPerdida entrenamiento: 0.32789769067483787\nPerdida validación: 0.5946464017033577\nExactitud validación: 18.5130\nÉpoca 164\nPerdida entrenamiento: 0.3267712610609391\nPerdida validación: 0.6227770447731018\nExactitud validación: 18.2870\nÉpoca 165\nPerdida entrenamiento: 0.3263696502236759\nPerdida validación: 0.6890445426106453\nExactitud validación: 18.2870\nÉpoca 166\nPerdida entrenamiento: 0.3250192473916447\nPerdida validación: 0.6499665081501007\nExactitud validación: 18.5130\nÉpoca 167\nPerdida entrenamiento: 0.3261696854058434\nPerdida validación: 0.6132025644183159\nExactitud validación: 18.2870\nÉpoca 168\nPerdida entrenamiento: 0.3261833287337247\nPerdida validación: 0.6634091883897781\nExactitud validación: 18.5130\nÉpoca 169\nPerdida entrenamiento: 0.32349429411046643\nPerdida validación: 0.6630931124091148\nExactitud validación: 18.6261\nÉpoca 170\nPerdida entrenamiento: 0.3271436393260956\nPerdida validación: 0.612961657345295\nExactitud validación: 18.5130\nÉpoca 171\nPerdida entrenamiento: 0.32476263098856983\nPerdida validación: 0.6598226502537727\nExactitud validación: 18.2870\nÉpoca 172\nPerdida entrenamiento: 0.324515997486956\nPerdida validación: 0.6418932229280472\nExactitud validación: 18.4000\nÉpoca 173\nPerdida entrenamiento: 0.32433526919168587\nPerdida validación: 0.7335801050066948\nExactitud validación: 18.2870\nÉpoca 174\nPerdida entrenamiento: 0.3219207516487907\nPerdida validación: 0.653811901807785\nExactitud validación: 18.2870\nÉpoca 175\nPerdida entrenamiento: 0.3205060888739193\nPerdida validación: 0.6664783358573914\nExactitud validación: 18.5130\nÉpoca 176\nPerdida entrenamiento: 0.3207370875512852\nPerdida validación: 0.6229857131838799\nExactitud validación: 18.0609\nÉpoca 177\nPerdida entrenamiento: 0.3227768680628608\nPerdida validación: 0.6437440887093544\nExactitud validación: 18.2870\nÉpoca 178\nPerdida entrenamiento: 0.3209051349583794\nPerdida validación: 0.6665943264961243\nExactitud validación: 18.4000\nÉpoca 179\nPerdida entrenamiento: 0.32111615643781777\nPerdida validación: 0.6589837148785591\nExactitud validación: 18.5130\nÉpoca 180\nPerdida entrenamiento: 0.3208710200646344\nPerdida validación: 0.6451635211706161\nExactitud validación: 18.4000\nÉpoca 181\nPerdida entrenamiento: 0.3188728216816397\nPerdida validación: 0.6509027481079102\nExactitud validación: 18.4000\nÉpoca 182\nPerdida entrenamiento: 0.3178029682706384\nPerdida validación: 0.6660331636667252\nExactitud validación: 18.2870\nÉpoca 183\nPerdida entrenamiento: 0.31673886320170236\nPerdida validación: 0.6581268012523651\nExactitud validación: 18.2870\nÉpoca 184\nPerdida entrenamiento: 0.31750109002870675\nPerdida validación: 0.6372020319104195\nExactitud validación: 18.5130\nÉpoca 185\nPerdida entrenamiento: 0.31816011930213256\nPerdida validación: 0.7313763499259949\nExactitud validación: 18.4000\nÉpoca 186\nPerdida entrenamiento: 0.3156069096396951\nPerdida validación: 0.6771089732646942\nExactitud validación: 18.4000\nÉpoca 187\nPerdida entrenamiento: 0.31772204532342796\nPerdida validación: 0.6511183455586433\nExactitud validación: 18.4000\nÉpoca 188\nPerdida entrenamiento: 0.31324949685265036\nPerdida validación: 0.6433937773108482\nExactitud validación: 18.1739\nÉpoca 189\nPerdida entrenamiento: 0.31725497894427357\nPerdida validación: 0.68333500623703\nExactitud validación: 18.1739\nÉpoca 190\nPerdida entrenamiento: 0.3123554464648752\nPerdida validación: 0.6660071387887001\nExactitud validación: 18.8522\nÉpoca 191\nPerdida entrenamiento: 0.3153311452444862\nPerdida validación: 0.7063699811697006\nExactitud validación: 18.7391\nÉpoca 192\nPerdida entrenamiento: 0.31404705433284535\nPerdida validación: 0.6741388291120529\nExactitud validación: 18.7391\nÉpoca 193\nPerdida entrenamiento: 0.31402675632168264\nPerdida validación: 0.6543318554759026\nExactitud validación: 18.1739\nÉpoca 194\nPerdida entrenamiento: 0.3119946630562053\nPerdida validación: 0.6574038416147232\nExactitud validación: 18.5130\nÉpoca 195\nPerdida entrenamiento: 0.3136322226594476\nPerdida validación: 0.7180648446083069\nExactitud validación: 18.2870\nÉpoca 196\nPerdida entrenamiento: 0.3097478344159968\nPerdida validación: 0.6812009885907173\nExactitud validación: 18.2870\nÉpoca 197\nPerdida entrenamiento: 0.3116472389768152\nPerdida validación: 0.6507846117019653\nExactitud validación: 18.4000\nÉpoca 198\nPerdida entrenamiento: 0.31110472188276406\nPerdida validación: 0.6414782479405403\nExactitud validación: 18.2870\nÉpoca 199\nPerdida entrenamiento: 0.3103514997398152\nPerdida validación: 0.6524050757288933\nExactitud validación: 18.4000\nÉpoca 200\nPerdida entrenamiento: 0.31179756802671094\nPerdida validación: 0.6920239329338074\nExactitud validación: 18.7391\nÉpoca 201\nPerdida entrenamiento: 0.3084581047296524\nPerdida validación: 0.764978215098381\nExactitud validación: 18.0609\nÉpoca 202\nPerdida entrenamiento: 0.30916617986033945\nPerdida validación: 0.7176909744739532\nExactitud validación: 18.4000\nÉpoca 203\nPerdida entrenamiento: 0.3087397515773773\nPerdida validación: 0.7063323929905891\nExactitud validación: 18.2870\nÉpoca 204\nPerdida entrenamiento: 0.3106594672974418\nPerdida validación: 0.6954813897609711\nExactitud validación: 18.4000\nÉpoca 205\nPerdida entrenamiento: 0.30759740226409016\nPerdida validación: 0.7038579732179642\nExactitud validación: 18.1739\nÉpoca 206\nPerdida entrenamiento: 0.3062534963383394\nPerdida validación: 0.7156248390674591\nExactitud validación: 18.2870\nÉpoca 207\nPerdida entrenamiento: 0.30647197278106914\nPerdida validación: 0.688948281109333\nExactitud validación: 18.5130\nÉpoca 208\nPerdida entrenamiento: 0.3078196758733076\nPerdida validación: 0.692335918545723\nExactitud validación: 18.6261\nÉpoca 209\nPerdida entrenamiento: 0.30704403011237874\nPerdida validación: 0.6741050034761429\nExactitud validación: 17.9478\nÉpoca 210\nPerdida entrenamiento: 0.30527643508770885\nPerdida validación: 0.6659369245171547\nExactitud validación: 18.5130\nÉpoca 211\nPerdida entrenamiento: 0.3071153356748469\nPerdida validación: 0.7391846030950546\nExactitud validación: 18.6261\nÉpoca 212\nPerdida entrenamiento: 0.30531730371363025\nPerdida validación: 0.7998167648911476\nExactitud validación: 18.5130\nÉpoca 213\nPerdida entrenamiento: 0.3038189893259722\nPerdida validación: 0.7052174434065819\nExactitud validación: 17.9478\nÉpoca 214\nPerdida entrenamiento: 0.30341966976137724\nPerdida validación: 0.7350720167160034\nExactitud validación: 18.5130\nÉpoca 215\nPerdida entrenamiento: 0.30246863645665784\nPerdida validación: 0.7088495343923569\nExactitud validación: 18.5130\nÉpoca 216\nPerdida entrenamiento: 0.30353131013758045\nPerdida validación: 0.6834466755390167\nExactitud validación: 18.6261\nÉpoca 217\nPerdida entrenamiento: 0.30161605074125175\nPerdida validación: 0.7241852506995201\nExactitud validación: 17.9478\nÉpoca 218\nPerdida entrenamiento: 0.3025359528906205\nPerdida validación: 0.6786011755466461\nExactitud validación: 18.1739\nÉpoca 219\nPerdida entrenamiento: 0.3013206886894563\nPerdida validación: 0.679993025958538\nExactitud validación: 18.5130\nÉpoca 220\nPerdida entrenamiento: 0.3010849926401587\nPerdida validación: 0.8055609986186028\nExactitud validación: 18.7391\nÉpoca 221\nPerdida entrenamiento: 0.299965525374693\nPerdida validación: 0.6772769540548325\nExactitud validación: 18.4000\nÉpoca 222\nPerdida entrenamiento: 0.3033907431013444\nPerdida validación: 0.736585833132267\nExactitud validación: 18.5130\nÉpoca 223\nPerdida entrenamiento: 0.3007599991910598\nPerdida validación: 0.7596707493066788\nExactitud validación: 18.2870\nÉpoca 224\nPerdida entrenamiento: 0.30001555558513193\nPerdida validación: 0.6992309913039207\nExactitud validación: 18.2870\nÉpoca 225\nPerdida entrenamiento: 0.2969650775194168\nPerdida validación: 0.7044773250818253\nExactitud validación: 18.2870\nÉpoca 226\nPerdida entrenamiento: 0.29871873557567596\nPerdida validación: 0.6746115535497665\nExactitud validación: 18.5130\nÉpoca 227\nPerdida entrenamiento: 0.2973190230481765\nPerdida validación: 0.684038981795311\nExactitud validación: 18.4000\nÉpoca 228\nPerdida entrenamiento: 0.2981330340399462\nPerdida validación: 0.7490448206663132\nExactitud validación: 18.8522\nÉpoca 229\nPerdida entrenamiento: 0.29559924935593324\nPerdida validación: 0.694603718817234\nExactitud validación: 18.4000\nÉpoca 230\nPerdida entrenamiento: 0.2944230069132412\nPerdida validación: 0.7294625043869019\nExactitud validación: 18.5130\nÉpoca 231\nPerdida entrenamiento: 0.29362457640030803\nPerdida validación: 0.7362787425518036\nExactitud validación: 18.6261\nÉpoca 232\nPerdida entrenamiento: 0.294377674074734\nPerdida validación: 0.7065712809562683\nExactitud validación: 18.5130\nÉpoca 233\nPerdida entrenamiento: 0.29613833129405975\nPerdida validación: 0.7128828167915344\nExactitud validación: 18.2870\nÉpoca 234\nPerdida entrenamiento: 0.29697078904684854\nPerdida validación: 0.7355586439371109\nExactitud validación: 18.2870\nÉpoca 235\nPerdida entrenamiento: 0.2928716233547996\nPerdida validación: 0.8148213103413582\nExactitud validación: 18.7391\nÉpoca 236\nPerdida entrenamiento: 0.2956160175449708\nPerdida validación: 0.7032250016927719\nExactitud validación: 18.5130\nÉpoca 237\nPerdida entrenamiento: 0.29322683942668576\nPerdida validación: 0.7366586253046989\nExactitud validación: 18.6261\nÉpoca 238\nPerdida entrenamiento: 0.29531940730179057\nPerdida validación: 0.716269001364708\nExactitud validación: 18.2870\nÉpoca 239\nPerdida entrenamiento: 0.29456058582838845\nPerdida validación: 0.8046405576169491\nExactitud validación: 18.6261\nÉpoca 240\nPerdida entrenamiento: 0.2919597485486199\nPerdida validación: 0.7698554992675781\nExactitud validación: 18.1739\nÉpoca 241\nPerdida entrenamiento: 0.2926513622788822\nPerdida validación: 0.6973117738962173\nExactitud validación: 18.7391\nÉpoca 242\nPerdida entrenamiento: 0.2892984853071325\nPerdida validación: 0.7638273388147354\nExactitud validación: 18.4000\nÉpoca 243\nPerdida entrenamiento: 0.29051580937469706\nPerdida validación: 0.7815098166465759\nExactitud validación: 18.7391\nÉpoca 244\nPerdida entrenamiento: 0.2899246417424258\nPerdida validación: 0.7704179286956787\nExactitud validación: 18.1739\nÉpoca 245\nPerdida entrenamiento: 0.28837614375002246\nPerdida validación: 0.7450488656759262\nExactitud validación: 18.4000\nÉpoca 246\nPerdida entrenamiento: 0.29001492174232707\nPerdida validación: 0.7398979514837265\nExactitud validación: 18.1739\nÉpoca 247\nPerdida entrenamiento: 0.28900785919497995\nPerdida validación: 0.7784785479307175\nExactitud validación: 18.0609\nÉpoca 248\nPerdida entrenamiento: 0.28841665474807515\nPerdida validación: 0.7403790205717087\nExactitud validación: 18.5130\nÉpoca 249\nPerdida entrenamiento: 0.2894595230326933\nPerdida validación: 0.7213053703308105\nExactitud validación: 18.2870\nÉpoca 250\nPerdida entrenamiento: 0.2888253462665221\nPerdida validación: 0.766401544213295\nExactitud validación: 18.2870\nÉpoca 251\nPerdida entrenamiento: 0.2866971107090221\nPerdida validación: 0.7406387180089951\nExactitud validación: 18.5130\nÉpoca 252\nPerdida entrenamiento: 0.2872468583724078\nPerdida validación: 0.7808045633137226\nExactitud validación: 18.5130\nÉpoca 253\nPerdida entrenamiento: 0.2877846333910437\nPerdida validación: 0.7809512466192245\nExactitud validación: 18.4000\nÉpoca 254\nPerdida entrenamiento: 0.2867770826115328\nPerdida validación: 0.7319426983594894\nExactitud validación: 18.1739\nÉpoca 255\nPerdida entrenamiento: 0.28648798080051646\nPerdida validación: 0.7230148687958717\nExactitud validación: 18.4000\nÉpoca 256\nPerdida entrenamiento: 0.2846994154593524\nPerdida validación: 0.7592649683356285\nExactitud validación: 18.4000\nÉpoca 257\nPerdida entrenamiento: 0.2864809036254883\nPerdida validación: 0.7423518821597099\nExactitud validación: 18.2870\nÉpoca 258\nPerdida entrenamiento: 0.2850097224992864\nPerdida validación: 0.8285829573869705\nExactitud validación: 18.2870\nÉpoca 259\nPerdida entrenamiento: 0.2860611309023464\nPerdida validación: 0.7817785143852234\nExactitud validación: 18.5130\nÉpoca 260\nPerdida entrenamiento: 0.28397778027197895\nPerdida validación: 0.7759557962417603\nExactitud validación: 18.1739\nÉpoca 261\nPerdida entrenamiento: 0.2851453958188786\nPerdida validación: 0.773240715265274\nExactitud validación: 18.1739\nÉpoca 262\nPerdida entrenamiento: 0.28346505322877097\nPerdida validación: 0.8145815879106522\nExactitud validación: 18.4000\nÉpoca 263\nPerdida entrenamiento: 0.2839648855083129\nPerdida validación: 0.8247283324599266\nExactitud validación: 18.2870\nÉpoca 264\nPerdida entrenamiento: 0.2820875758633894\nPerdida validación: 0.7470234334468842\nExactitud validación: 18.1739\nÉpoca 265\nPerdida entrenamiento: 0.2828727487255545\nPerdida validación: 0.7517593279480934\nExactitud validación: 18.4000\nÉpoca 266\nPerdida entrenamiento: 0.28342335364397836\nPerdida validación: 0.745085820555687\nExactitud validación: 18.0609\nÉpoca 267\nPerdida entrenamiento: 0.28173114271724925\nPerdida validación: 0.8318959027528763\nExactitud validación: 18.5130\nÉpoca 268\nPerdida entrenamiento: 0.28258827241028056\nPerdida validación: 0.7550449594855309\nExactitud validación: 18.5130\nÉpoca 269\nPerdida entrenamiento: 0.2806198824854458\nPerdida validación: 0.815860778093338\nExactitud validación: 17.9478\nÉpoca 270\nPerdida entrenamiento: 0.2798441560829387\nPerdida validación: 0.8292346000671387\nExactitud validación: 18.7391\nÉpoca 271\nPerdida entrenamiento: 0.28328849813517404\nPerdida validación: 0.84027498960495\nExactitud validación: 17.9478\nÉpoca 272\nPerdida entrenamiento: 0.27925308399340687\nPerdida validación: 0.8446707427501678\nExactitud validación: 18.5130\nÉpoca 273\nPerdida entrenamiento: 0.279740308137501\nPerdida validación: 0.7891214042901993\nExactitud validación: 18.4000\nÉpoca 274\nPerdida entrenamiento: 0.2804296621504952\nPerdida validación: 0.7523273676633835\nExactitud validación: 18.6261\nÉpoca 275\nPerdida entrenamiento: 0.2786500278641196\nPerdida validación: 0.8763114959001541\nExactitud validación: 18.5130\nÉpoca 276\nPerdida entrenamiento: 0.2789465942803551\nPerdida validación: 0.7518940791487694\nExactitud validación: 18.4000\nÉpoca 277\nPerdida entrenamiento: 0.2798019025255652\nPerdida validación: 0.8489273488521576\nExactitud validación: 18.7391\nÉpoca 278\nPerdida entrenamiento: 0.280226955519003\nPerdida validación: 0.766749732196331\nExactitud validación: 18.5130\nÉpoca 279\nPerdida entrenamiento: 0.2779183343929403\nPerdida validación: 0.7820227146148682\nExactitud validación: 18.4000\nÉpoca 280\nPerdida entrenamiento: 0.2765612396247247\nPerdida validación: 0.7857282161712646\nExactitud validación: 18.4000\nÉpoca 281\nPerdida entrenamiento: 0.27886566169121685\nPerdida validación: 0.8160237297415733\nExactitud validación: 18.6261\nÉpoca 282\nPerdida entrenamiento: 0.2769961637609145\nPerdida validación: 0.8009995818138123\nExactitud validación: 18.5130\nÉpoca 283\nPerdida entrenamiento: 0.2754744019578485\nPerdida validación: 0.8242090195417404\nExactitud validación: 18.2870\nÉpoca 284\nPerdida entrenamiento: 0.27566534894354205\nPerdida validación: 0.8263423070311546\nExactitud validación: 18.4000\nÉpoca 285\nPerdida entrenamiento: 0.275710387264981\nPerdida validación: 0.7984395027160645\nExactitud validación: 18.7391\nÉpoca 286\nPerdida entrenamiento: 0.2722511160023072\nPerdida validación: 0.7776636183261871\nExactitud validación: 18.7391\nÉpoca 287\nPerdida entrenamiento: 0.2785680565763922\nPerdida validación: 0.8693821281194687\nExactitud validación: 18.1739\nÉpoca 288\nPerdida entrenamiento: 0.2776385243324673\nPerdida validación: 0.8111721277236938\nExactitud validación: 18.5130\nÉpoca 289\nPerdida entrenamiento: 0.2753101648653255\nPerdida validación: 0.7979157716035843\nExactitud validación: 18.6261\nÉpoca 290\nPerdida entrenamiento: 0.2721212304690305\nPerdida validación: 0.8984339684247971\nExactitud validación: 18.1739\nÉpoca 291\nPerdida entrenamiento: 0.27208081150756164\nPerdida validación: 0.8066085278987885\nExactitud validación: 18.0609\nÉpoca 292\nPerdida entrenamiento: 0.2724810707218507\nPerdida validación: 0.858610674738884\nExactitud validación: 18.1739\nÉpoca 293\nPerdida entrenamiento: 0.2749691465321709\nPerdida validación: 0.8009930029511452\nExactitud validación: 18.4000\nÉpoca 294\nPerdida entrenamiento: 0.2745845510679133\nPerdida validación: 0.8322249576449394\nExactitud validación: 18.6261\nÉpoca 295\nPerdida entrenamiento: 0.27191179903114543\nPerdida validación: 0.8544426411390305\nExactitud validación: 18.5130\nÉpoca 296\nPerdida entrenamiento: 0.2718319112763685\nPerdida validación: 0.7973638772964478\nExactitud validación: 18.2870\nÉpoca 297\nPerdida entrenamiento: 0.27322857257197886\nPerdida validación: 0.8390850126743317\nExactitud validación: 18.2870\nÉpoca 298\nPerdida entrenamiento: 0.2706087967928718\nPerdida validación: 0.8332074135541916\nExactitud validación: 18.2870\nÉpoca 299\nPerdida entrenamiento: 0.27064647394068103\nPerdida validación: 0.7855604067444801\nExactitud validación: 18.6261\nÉpoca 300\nPerdida entrenamiento: 0.27028607620912437\nPerdida validación: 0.844075620174408\nExactitud validación: 18.5130\nÉpoca 301\nPerdida entrenamiento: 0.27047083395368915\nPerdida validación: 0.7950586900115013\nExactitud validación: 18.7391\nÉpoca 302\nPerdida entrenamiento: 0.2688707393758437\nPerdida validación: 0.8446274772286415\nExactitud validación: 18.4000\nÉpoca 303\nPerdida entrenamiento: 0.27010226337348714\nPerdida validación: 0.8923372030258179\nExactitud validación: 18.1739\nÉpoca 304\nPerdida entrenamiento: 0.26951658988700194\nPerdida validación: 0.8144352659583092\nExactitud validación: 18.7391\nÉpoca 305\nPerdida entrenamiento: 0.2690744391259025\nPerdida validación: 0.9116105735301971\nExactitud validación: 18.4000\nÉpoca 306\nPerdida entrenamiento: 0.26870520588229685\nPerdida validación: 0.8943951576948166\nExactitud validación: 18.6261\nÉpoca 307\nPerdida entrenamiento: 0.27256863783387575\nPerdida validación: 0.9162701666355133\nExactitud validación: 18.2870\nÉpoca 308\nPerdida entrenamiento: 0.26849985648604\nPerdida validación: 0.8575167655944824\nExactitud validación: 18.1739\nÉpoca 309\nPerdida entrenamiento: 0.2659115265397465\nPerdida validación: 0.8369210362434387\nExactitud validación: 18.9652\nÉpoca 310\nPerdida entrenamiento: 0.26523913004819083\nPerdida validación: 0.8102370351552963\nExactitud validación: 18.5130\nÉpoca 311\nPerdida entrenamiento: 0.26695583322468924\nPerdida validación: 0.8106616139411926\nExactitud validación: 18.5130\nÉpoca 312\nPerdida entrenamiento: 0.26486619518083687\nPerdida validación: 0.862990252673626\nExactitud validación: 18.7391\nÉpoca 313\nPerdida entrenamiento: 0.2670781770173241\nPerdida validación: 0.9409219324588776\nExactitud validación: 18.2870\nÉpoca 314\nPerdida entrenamiento: 0.26387015773969535\nPerdida validación: 0.8297825679183006\nExactitud validación: 18.5130\nÉpoca 315\nPerdida entrenamiento: 0.2630258443600991\nPerdida validación: 0.8401200473308563\nExactitud validación: 18.6261\nÉpoca 316\nPerdida entrenamiento: 0.26609305248540993\nPerdida validación: 0.8802365660667419\nExactitud validación: 18.4000\nÉpoca 317\nPerdida entrenamiento: 0.26455171406269073\nPerdida validación: 0.85386922955513\nExactitud validación: 18.7391\nÉpoca 318\nPerdida entrenamiento: 0.2650342899210313\nPerdida validación: 0.913348600268364\nExactitud validación: 18.6261\nÉpoca 319\nPerdida entrenamiento: 0.2632635078009437\nPerdida validación: 0.8332754224538803\nExactitud validación: 18.6261\nÉpoca 320\nPerdida entrenamiento: 0.2620505313662922\nPerdida validación: 0.8459868878126144\nExactitud validación: 18.1739\nÉpoca 321\nPerdida entrenamiento: 0.2629975974559784\nPerdida validación: 0.96159228682518\nExactitud validación: 18.8522\nÉpoca 322\nPerdida entrenamiento: 0.26157911384806914\nPerdida validación: 0.8396739363670349\nExactitud validación: 18.6261\nÉpoca 323\nPerdida entrenamiento: 0.2618062881862416\nPerdida validación: 0.8706338852643967\nExactitud validación: 18.1739\nÉpoca 324\nPerdida entrenamiento: 0.26290398397866416\nPerdida validación: 0.9644896686077118\nExactitud validación: 18.6261\nÉpoca 325\nPerdida entrenamiento: 0.2609732878558776\nPerdida validación: 0.9126636236906052\nExactitud validación: 18.0609\nÉpoca 326\nPerdida entrenamiento: 0.26105780110639687\nPerdida validación: 0.9232337772846222\nExactitud validación: 18.1739\nÉpoca 327\nPerdida entrenamiento: 0.26264332410167246\nPerdida validación: 0.8974900245666504\nExactitud validación: 18.4000\nÉpoca 328\nPerdida entrenamiento: 0.2613668257699293\nPerdida validación: 0.8862783759832382\nExactitud validación: 18.4000\nÉpoca 329\nPerdida entrenamiento: 0.25836709930616264\nPerdida validación: 0.8626670092344284\nExactitud validación: 18.5130\nÉpoca 330\nPerdida entrenamiento: 0.25922364522429076\nPerdida validación: 0.8830067962408066\nExactitud validación: 18.4000\nÉpoca 331\nPerdida entrenamiento: 0.26386993597535524\nPerdida validación: 0.8540544435381889\nExactitud validación: 18.2870\nÉpoca 332\nPerdida entrenamiento: 0.2593020134988953\nPerdida validación: 0.9039890021085739\nExactitud validación: 18.6261\nÉpoca 333\nPerdida entrenamiento: 0.2595018516568577\nPerdida validación: 0.8899291157722473\nExactitud validación: 17.9478\nÉpoca 334\nPerdida entrenamiento: 0.25665878986611085\nPerdida validación: 0.8394737765192986\nExactitud validación: 18.5130\nÉpoca 335\nPerdida entrenamiento: 0.25748301604214835\nPerdida validación: 0.9290647059679031\nExactitud validación: 18.7391\nÉpoca 336\nPerdida entrenamiento: 0.2590382677667281\nPerdida validación: 0.8649090602993965\nExactitud validación: 18.2870\nÉpoca 337\nPerdida entrenamiento: 0.2554243496235679\nPerdida validación: 0.9593407809734344\nExactitud validación: 18.7391\nÉpoca 338\nPerdida entrenamiento: 0.25691094906891093\nPerdida validación: 0.9706677794456482\nExactitud validación: 18.2870\nÉpoca 339\nPerdida entrenamiento: 0.25731626678915587\nPerdida validación: 0.9453080892562866\nExactitud validación: 18.6261\nÉpoca 340\nPerdida entrenamiento: 0.25507257659645644\nPerdida validación: 1.0293856039643288\nExactitud validación: 18.1739\nÉpoca 341\nPerdida entrenamiento: 0.25653984616784486\nPerdida validación: 0.9515304788947105\nExactitud validación: 18.6261\nÉpoca 342\nPerdida entrenamiento: 0.2530783467433032\nPerdida validación: 0.9056045934557915\nExactitud validación: 18.5130\nÉpoca 343\nPerdida entrenamiento: 0.25274669072207284\nPerdida validación: 0.918601781129837\nExactitud validación: 18.5130\nÉpoca 344\nPerdida entrenamiento: 0.25438859269899483\nPerdida validación: 0.8851798251271248\nExactitud validación: 18.6261\nÉpoca 345\nPerdida entrenamiento: 0.25582583599230824\nPerdida validación: 0.8939363956451416\nExactitud validación: 18.5130\nÉpoca 346\nPerdida entrenamiento: 0.25355858443414464\nPerdida validación: 0.9068932980298996\nExactitud validación: 18.5130\nÉpoca 347\nPerdida entrenamiento: 0.2524866067311343\nPerdida validación: 0.8788146674633026\nExactitud validación: 18.1739\nÉpoca 348\nPerdida entrenamiento: 0.2536166170064141\nPerdida validación: 0.9186953902244568\nExactitud validación: 18.5130\nÉpoca 349\nPerdida entrenamiento: 0.25076256341793957\nPerdida validación: 0.9136313498020172\nExactitud validación: 18.1739\nÉpoca 350\nPerdida entrenamiento: 0.2505396744784187\nPerdida validación: 0.8769859820604324\nExactitud validación: 18.1739\nÉpoca 351\nPerdida entrenamiento: 0.2476857444819282\nPerdida validación: 0.9611544162034988\nExactitud validación: 18.1739\nÉpoca 352\nPerdida entrenamiento: 0.2510046801146339\nPerdida validación: 0.8769300132989883\nExactitud validación: 18.7391\nÉpoca 353\nPerdida entrenamiento: 0.2519538367495817\nPerdida validación: 1.009942501783371\nExactitud validación: 18.6261\nÉpoca 354\nPerdida entrenamiento: 0.25590333780821634\nPerdida validación: 1.0110169053077698\nExactitud validación: 18.4000\nÉpoca 355\nPerdida entrenamiento: 0.24665287882089615\nPerdida validación: 0.963760256767273\nExactitud validación: 18.4000\nÉpoca 356\nPerdida entrenamiento: 0.24831677973270416\nPerdida validación: 0.9520362615585327\nExactitud validación: 18.4000\nÉpoca 357\nPerdida entrenamiento: 0.25036969605614157\nPerdida validación: 0.9705468714237213\nExactitud validación: 18.1739\nÉpoca 358\nPerdida entrenamiento: 0.2493774198433932\nPerdida validación: 0.9390139281749725\nExactitud validación: 18.2870\nÉpoca 359\nPerdida entrenamiento: 0.24896152755793402\nPerdida validación: 0.9668420851230621\nExactitud validación: 18.8522\nÉpoca 360\nPerdida entrenamiento: 0.24545341993079467\nPerdida validación: 0.9598726183176041\nExactitud validación: 18.4000\nÉpoca 361\nPerdida entrenamiento: 0.2458833907456959\nPerdida validación: 0.9334637522697449\nExactitud validación: 18.1739\nÉpoca 362\nPerdida entrenamiento: 0.24675725137486176\nPerdida validación: 0.9621522575616837\nExactitud validación: 18.0609\nÉpoca 363\nPerdida entrenamiento: 0.24821498946231954\nPerdida validación: 0.9556918889284134\nExactitud validación: 18.7391\nÉpoca 364\nPerdida entrenamiento: 0.24909637824577444\nPerdida validación: 0.8772937767207623\nExactitud validación: 18.4000\nÉpoca 365\nPerdida entrenamiento: 0.2441341666614308\nPerdida validación: 0.9345356523990631\nExactitud validación: 18.6261\nÉpoca 366\nPerdida entrenamiento: 0.2470776263405295\nPerdida validación: 1.1278765723109245\nExactitud validación: 18.4000\nÉpoca 367\nPerdida entrenamiento: 0.24338742038782904\nPerdida validación: 0.9173186719417572\nExactitud validación: 18.7391\nÉpoca 368\nPerdida entrenamiento: 0.24587972418350332\nPerdida validación: 0.9912368655204773\nExactitud validación: 18.0609\nÉpoca 369\nPerdida entrenamiento: 0.2427884471767089\nPerdida validación: 0.9538993611931801\nExactitud validación: 18.7391\nÉpoca 370\nPerdida entrenamiento: 0.243407864780987\nPerdida validación: 1.0761137753725052\nExactitud validación: 18.4000\nÉpoca 371\nPerdida entrenamiento: 0.24230772344505086\nPerdida validación: 0.968388170003891\nExactitud validación: 18.6261\nÉpoca 372\nPerdida entrenamiento: 0.2439663826542742\nPerdida validación: 0.9714508131146431\nExactitud validación: 18.6261\nÉpoca 373\nPerdida entrenamiento: 0.24384574592113495\nPerdida validación: 0.9771965891122818\nExactitud validación: 18.4000\nÉpoca 374\nPerdida entrenamiento: 0.24184141614857843\nPerdida validación: 0.9964085817337036\nExactitud validación: 18.4000\nÉpoca 375\nPerdida entrenamiento: 0.24101467518245473\nPerdida validación: 0.9356465041637421\nExactitud validación: 17.9478\nÉpoca 376\nPerdida entrenamiento: 0.24006997969220667\nPerdida validación: 0.9156605526804924\nExactitud validación: 18.0609\nÉpoca 377\nPerdida entrenamiento: 0.23987779985455907\nPerdida validación: 1.0531059503555298\nExactitud validación: 18.2870\nÉpoca 378\nPerdida entrenamiento: 0.24004541951067307\nPerdida validación: 1.0218062326312065\nExactitud validación: 18.6261\nÉpoca 379\nPerdida entrenamiento: 0.23972525666741765\nPerdida validación: 1.0781173408031464\nExactitud validación: 18.4000\nÉpoca 380\nPerdida entrenamiento: 0.23826756415998235\nPerdida validación: 1.0114049911499023\nExactitud validación: 18.2870\nÉpoca 381\nPerdida entrenamiento: 0.24126425473129048\nPerdida validación: 0.9385729283094406\nExactitud validación: 18.2870\nÉpoca 382\nPerdida entrenamiento: 0.23986119557829463\nPerdida validación: 1.0387549847364426\nExactitud validación: 18.5130\nÉpoca 383\nPerdida entrenamiento: 0.2385270192342646\nPerdida validación: 0.9609201848506927\nExactitud validación: 18.6261\nÉpoca 384\nPerdida entrenamiento: 0.23623030238291798\nPerdida validación: 0.9485830962657928\nExactitud validación: 18.9652\nÉpoca 385\nPerdida entrenamiento: 0.2384230853880153\nPerdida validación: 0.9416188150644302\nExactitud validación: 18.4000\nÉpoca 386\nPerdida entrenamiento: 0.23678378015756607\nPerdida validación: 0.9777514040470123\nExactitud validación: 18.5130\nÉpoca 387\nPerdida entrenamiento: 0.2363624467569239\nPerdida validación: 1.0215286016464233\nExactitud validación: 18.7391\nÉpoca 388\nPerdida entrenamiento: 0.23862669660764582\nPerdida validación: 0.9029609151184559\nExactitud validación: 18.1739\nÉpoca 389\nPerdida entrenamiento: 0.23591116070747375\nPerdida validación: 0.981246717274189\nExactitud validación: 18.6261\nÉpoca 390\nPerdida entrenamiento: 0.23835155718466816\nPerdida validación: 1.0086095109581947\nExactitud validación: 18.2870\nÉpoca 391\nPerdida entrenamiento: 0.2371460374663858\nPerdida validación: 1.0065960884094238\nExactitud validación: 18.1739\nÉpoca 392\nPerdida entrenamiento: 0.23677723285029917\nPerdida validación: 0.9826027452945709\nExactitud validación: 18.5130\nÉpoca 393\nPerdida entrenamiento: 0.23566791196079814\nPerdida validación: 1.0341725945472717\nExactitud validación: 18.7391\nÉpoca 394\nPerdida entrenamiento: 0.23627526444547317\nPerdida validación: 1.0409796610474586\nExactitud validación: 18.6261\nÉpoca 395\nPerdida entrenamiento: 0.23617835518191843\nPerdida validación: 1.6217666417360306\nExactitud validación: 18.5130\nÉpoca 396\nPerdida entrenamiento: 0.233415008029517\nPerdida validación: 0.9137831814587116\nExactitud validación: 18.4000\nÉpoca 397\nPerdida entrenamiento: 0.2343826009070172\nPerdida validación: 1.7579079121351242\nExactitud validación: 18.7391\nÉpoca 398\nPerdida entrenamiento: 0.23368020224220612\nPerdida validación: 1.0100515186786652\nExactitud validación: 18.7391\nÉpoca 399\nPerdida entrenamiento: 0.2321076200288885\nPerdida validación: 1.6793339550495148\nExactitud validación: 18.6261\nÉpoca 400\nPerdida entrenamiento: 0.23293223012896144\nPerdida validación: 1.610338568687439\nExactitud validación: 18.6261\nÉpoca 401\nPerdida entrenamiento: 0.23105231278082905\nPerdida validación: 1.6416560858488083\nExactitud validación: 18.4000\nÉpoca 402\nPerdida entrenamiento: 0.23033762372591915\nPerdida validación: 1.66363063454628\nExactitud validación: 18.4000\nÉpoca 403\nPerdida entrenamiento: 0.23017951057237737\nPerdida validación: 1.6514071226119995\nExactitud validación: 18.4000\nÉpoca 404\nPerdida entrenamiento: 0.23135478268651402\nPerdida validación: 1.703551098704338\nExactitud validación: 18.6261\nÉpoca 405\nPerdida entrenamiento: 0.23199564174694173\nPerdida validación: 1.6757195889949799\nExactitud validación: 18.2870\nÉpoca 406\nPerdida entrenamiento: 0.23011183563400717\nPerdida validación: 2.195468708872795\nExactitud validación: 18.5130\nÉpoca 407\nPerdida entrenamiento: 0.2305179115603952\nPerdida validación: 2.174595355987549\nExactitud validación: 18.7391\nÉpoca 408\nPerdida entrenamiento: 0.23433966364930658\nPerdida validación: 1.7009802162647247\nExactitud validación: 18.5130\nÉpoca 409\nPerdida entrenamiento: 0.23122593146913192\nPerdida validación: 1.6614426672458649\nExactitud validación: 18.9652\nÉpoca 410\nPerdida entrenamiento: 0.22980902212507584\nPerdida validación: 1.6923879534006119\nExactitud validación: 18.5130\nÉpoca 411\nPerdida entrenamiento: 0.2278544008731842\nPerdida validación: 1.6532950922846794\nExactitud validación: 18.4000\nÉpoca 412\nPerdida entrenamiento: 0.22777951815549066\nPerdida validación: 1.680533990263939\nExactitud validación: 18.6261\nÉpoca 413\nPerdida entrenamiento: 0.22783642744316773\nPerdida validación: 1.6505683958530426\nExactitud validación: 18.4000\nÉpoca 414\nPerdida entrenamiento: 0.22797440430697272\nPerdida validación: 1.6364076286554337\nExactitud validación: 18.2870\nÉpoca 415\nPerdida entrenamiento: 0.22762182880850398\nPerdida validación: 1.630989708006382\nExactitud validación: 18.2870\nÉpoca 416\nPerdida entrenamiento: 0.227926942793762\nPerdida validación: 1.6618505418300629\nExactitud validación: 18.6261\nÉpoca 417\nPerdida entrenamiento: 0.22629480239223032\nPerdida validación: 1.6968141943216324\nExactitud validación: 18.4000\nÉpoca 418\nPerdida entrenamiento: 0.22488318559001474\nPerdida validación: 1.7578092515468597\nExactitud validación: 18.2870\nÉpoca 419\nPerdida entrenamiento: 0.2263673219610663\nPerdida validación: 1.6131335943937302\nExactitud validación: 18.1739\nÉpoca 420\nPerdida entrenamiento: 0.22987113630070405\nPerdida validación: 1.7163729965686798\nExactitud validación: 18.1739\nÉpoca 421\nPerdida entrenamiento: 0.22674175527165918\nPerdida validación: 1.6752920597791672\nExactitud validación: 18.8522\nÉpoca 422\nPerdida entrenamiento: 0.22827263702364528\nPerdida validación: 1.7154240310192108\nExactitud validación: 18.5130\nÉpoca 423\nPerdida entrenamiento: 0.2220915402559673\nPerdida validación: 1.6310960724949837\nExactitud validación: 18.1739\nÉpoca 424\nPerdida entrenamiento: 0.22505173613043392\nPerdida validación: 1.6115675866603851\nExactitud validación: 18.1739\nÉpoca 425\nPerdida entrenamiento: 0.22220089418046615\nPerdida validación: 2.214143306016922\nExactitud validación: 18.1739\nÉpoca 426\nPerdida entrenamiento: 0.2250201561871697\nPerdida validación: 1.64544016122818\nExactitud validación: 18.1739\nÉpoca 427\nPerdida entrenamiento: 0.22550559876596227\nPerdida validación: 1.6851514726877213\nExactitud validación: 18.7391\nÉpoca 428\nPerdida entrenamiento: 0.22317052457262487\nPerdida validación: 1.7038426101207733\nExactitud validación: 18.7391\nÉpoca 429\nPerdida entrenamiento: 0.22356641993803136\nPerdida validación: 1.710338070988655\nExactitud validación: 18.4000\nÉpoca 430\nPerdida entrenamiento: 0.22142810199190588\nPerdida validación: 1.7483271360397339\nExactitud validación: 18.7391\nÉpoca 431\nPerdida entrenamiento: 0.22034293062546673\nPerdida validación: 1.6430785655975342\nExactitud validación: 18.7391\nÉpoca 432\nPerdida entrenamiento: 0.22316901824053595\nPerdida validación: 1.7672994136810303\nExactitud validación: 18.4000\nÉpoca 433\nPerdida entrenamiento: 0.22463338383856943\nPerdida validación: 1.6433425098657608\nExactitud validación: 18.4000\nÉpoca 434\nPerdida entrenamiento: 0.22231091646587148\nPerdida validación: 1.6801955252885818\nExactitud validación: 18.5130\nÉpoca 435\nPerdida entrenamiento: 0.2208845168352127\nPerdida validación: 1.6813064217567444\nExactitud validación: 18.2870\nÉpoca 436\nPerdida entrenamiento: 0.22095614584053264\nPerdida validación: 1.6760065108537674\nExactitud validación: 18.6261\nÉpoca 437\nPerdida entrenamiento: 0.22033456712961197\nPerdida validación: 1.678830772638321\nExactitud validación: 18.7391\nÉpoca 438\nPerdida entrenamiento: 0.22007577559527228\nPerdida validación: 1.6954376250505447\nExactitud validación: 18.6261\nÉpoca 439\nPerdida entrenamiento: 0.22003603507490718\nPerdida validación: 1.725928619503975\nExactitud validación: 18.8522\nÉpoca 440\nPerdida entrenamiento: 0.22195249708259807\nPerdida validación: 1.8037448972463608\nExactitud validación: 18.5130\nÉpoca 441\nPerdida entrenamiento: 0.21979504736030803\nPerdida validación: 1.6947238594293594\nExactitud validación: 18.1739\nÉpoca 442\nPerdida entrenamiento: 0.21700231205014622\nPerdida validación: 1.7131413221359253\nExactitud validación: 18.5130\nÉpoca 443\nPerdida entrenamiento: 0.21716881061301513\nPerdida validación: 1.7016572207212448\nExactitud validación: 18.2870\nÉpoca 444\nPerdida entrenamiento: 0.21755946778199253\nPerdida validación: 2.2080706506967545\nExactitud validación: 18.4000\nÉpoca 445\nPerdida entrenamiento: 0.21960881308597677\nPerdida validación: 2.2232966125011444\nExactitud validación: 18.2870\nÉpoca 446\nPerdida entrenamiento: 0.2177817536627545\nPerdida validación: 1.674214854836464\nExactitud validación: 18.2870\nÉpoca 447\nPerdida entrenamiento: 0.22076668239691677\nPerdida validación: 1.6826488673686981\nExactitud validación: 18.4000\nÉpoca 448\nPerdida entrenamiento: 0.2175587897791582\nPerdida validación: 1.684437245130539\nExactitud validación: 18.4000\nÉpoca 449\nPerdida entrenamiento: 0.21597974396803798\nPerdida validación: 1.7088166177272797\nExactitud validación: 18.2870\nÉpoca 450\nPerdida entrenamiento: 0.21813132044147043\nPerdida validación: 1.733146995306015\nExactitud validación: 18.1739\nÉpoca 451\nPerdida entrenamiento: 0.21773759976905935\nPerdida validación: 1.6941641122102737\nExactitud validación: 18.2870\nÉpoca 452\nPerdida entrenamiento: 0.21535080583656535\nPerdida validación: 1.76713265478611\nExactitud validación: 18.4000\nÉpoca 453\nPerdida entrenamiento: 0.21499554462292614\nPerdida validación: 1.725937306880951\nExactitud validación: 18.4000\nÉpoca 454\nPerdida entrenamiento: 0.21762167399420457\nPerdida validación: 1.745834544301033\nExactitud validación: 18.4000\nÉpoca 455\nPerdida entrenamiento: 0.21529359852566438\nPerdida validación: 1.7183891236782074\nExactitud validación: 18.6261\nÉpoca 456\nPerdida entrenamiento: 0.21322160959243774\nPerdida validación: 1.665738008916378\nExactitud validación: 18.5130\nÉpoca 457\nPerdida entrenamiento: 0.21297074021661982\nPerdida validación: 1.6415093056857586\nExactitud validación: 18.1739\nÉpoca 458\nPerdida entrenamiento: 0.2120342228342505\nPerdida validación: 1.6675629317760468\nExactitud validación: 18.5130\nÉpoca 459\nPerdida entrenamiento: 0.21290872377507827\nPerdida validación: 1.7062142491340637\nExactitud validación: 18.1739\nÉpoca 460\nPerdida entrenamiento: 0.2155881883466945\nPerdida validación: 1.6664244383573532\nExactitud validación: 18.6261\nÉpoca 461\nPerdida entrenamiento: 0.2123072870513972\nPerdida validación: 1.6892398595809937\nExactitud validación: 18.1739\nÉpoca 462\nPerdida entrenamiento: 0.21215057285392985\nPerdida validación: 1.71298286318779\nExactitud validación: 18.5130\nÉpoca 463\nPerdida entrenamiento: 0.2131307668545667\nPerdida validación: 2.3371381908655167\nExactitud validación: 18.4000\nÉpoca 464\nPerdida entrenamiento: 0.21063883252003612\nPerdida validación: 1.6871272176504135\nExactitud validación: 18.4000\nÉpoca 465\nPerdida entrenamiento: 0.21041779746027553\nPerdida validación: 1.7584034204483032\nExactitud validación: 18.8522\nÉpoca 466\nPerdida entrenamiento: 0.20908518573817084\nPerdida validación: 1.7399623692035675\nExactitud validación: 18.2870\nÉpoca 467\nPerdida entrenamiento: 0.20974228049025817\nPerdida validación: 1.7392813563346863\nExactitud validación: 18.0609\nÉpoca 468\nPerdida entrenamiento: 0.20860017222516677\nPerdida validación: 1.7459359467029572\nExactitud validación: 18.6261\nÉpoca 469\nPerdida entrenamiento: 0.20901529490947723\nPerdida validación: 1.6576770320534706\nExactitud validación: 18.2870\nÉpoca 470\nPerdida entrenamiento: 0.20985684850636652\nPerdida validación: 1.6809408068656921\nExactitud validación: 17.8348\nÉpoca 471\nPerdida entrenamiento: 0.20888636611840306\nPerdida validación: 1.7095791101455688\nExactitud validación: 18.4000\nÉpoca 472\nPerdida entrenamiento: 0.20915422983029308\nPerdida validación: 1.735638752579689\nExactitud validación: 18.6261\nÉpoca 473\nPerdida entrenamiento: 0.21087617295629837\nPerdida validación: 2.223282590508461\nExactitud validación: 18.8522\nÉpoca 474\nPerdida entrenamiento: 0.21059176501105814\nPerdida validación: 2.2696365863084793\nExactitud validación: 18.4000\nÉpoca 475\nPerdida entrenamiento: 0.20993135518887462\nPerdida validación: 2.3144669383764267\nExactitud validación: 18.4000\nÉpoca 476\nPerdida entrenamiento: 0.2069975641720435\nPerdida validación: 1.7147362232208252\nExactitud validación: 17.9478\nÉpoca 477\nPerdida entrenamiento: 0.20739179674316854\nPerdida validación: 1.7762307822704315\nExactitud validación: 18.4000\nÉpoca 478\nPerdida entrenamiento: 0.20736681187854095\nPerdida validación: 1.7321285605430603\nExactitud validación: 18.7391\nÉpoca 479\nPerdida entrenamiento: 0.20850269627921722\nPerdida validación: 1.7248305529356003\nExactitud validación: 18.5130\nÉpoca 480\nPerdida entrenamiento: 0.20808968561537125\nPerdida validación: 1.6793062910437584\nExactitud validación: 18.5130\nÉpoca 481\nPerdida entrenamiento: 0.2063585151644314\nPerdida validación: 2.3160250037908554\nExactitud validación: 18.4000\nÉpoca 482\nPerdida entrenamiento: 0.20922441298470779\nPerdida validación: 1.7382783144712448\nExactitud validación: 18.7391\nÉpoca 483\nPerdida entrenamiento: 0.2089783260050942\nPerdida validación: 1.675756473094225\nExactitud validación: 18.2870\nÉpoca 484\nPerdida entrenamiento: 0.20955036317600922\nPerdida validación: 1.7968875467777252\nExactitud validación: 18.5130\nÉpoca 485\nPerdida entrenamiento: 0.20719658802537358\nPerdida validación: 2.281432792544365\nExactitud validación: 18.2870\nÉpoca 486\nPerdida entrenamiento: 0.20671694988713546\nPerdida validación: 2.290306895971298\nExactitud validación: 18.5130\nÉpoca 487\nPerdida entrenamiento: 0.20706017490695505\nPerdida validación: 1.7116160094738007\nExactitud validación: 18.4000\nÉpoca 488\nPerdida entrenamiento: 0.20524413971339955\nPerdida validación: 1.8093033283948898\nExactitud validación: 18.5130\nÉpoca 489\nPerdida entrenamiento: 0.2051747401847559\nPerdida validación: 1.7765755355358124\nExactitud validación: 18.6261\nÉpoca 490\nPerdida entrenamiento: 0.20630764128530726\nPerdida validación: 1.7870673686265945\nExactitud validación: 18.2870\nÉpoca 491\nPerdida entrenamiento: 0.20644442780929453\nPerdida validación: 2.2809912860393524\nExactitud validación: 18.5130\nÉpoca 492\nPerdida entrenamiento: 0.2057285668218837\nPerdida validación: 2.258572533726692\nExactitud validación: 17.8348\nÉpoca 493\nPerdida entrenamiento: 0.2029068154447219\nPerdida validación: 1.6803431659936905\nExactitud validación: 18.7391\nÉpoca 494\nPerdida entrenamiento: 0.2028874272809309\nPerdida validación: 1.8127751350402832\nExactitud validación: 18.7391\nÉpoca 495\nPerdida entrenamiento: 0.2052424208206289\nPerdida validación: 1.7849414199590683\nExactitud validación: 18.7391\nÉpoca 496\nPerdida entrenamiento: 0.20392162791069815\nPerdida validación: 1.7237890660762787\nExactitud validación: 18.4000\nÉpoca 497\nPerdida entrenamiento: 0.20092843429130666\nPerdida validación: 2.2871531173586845\nExactitud validación: 18.6261\nÉpoca 498\nPerdida entrenamiento: 0.20234436278834061\nPerdida validación: 2.2854884639382362\nExactitud validación: 18.2870\nÉpoca 499\nPerdida entrenamiento: 0.20332733541727066\nPerdida validación: 1.7827043235301971\nExactitud validación: 18.6261\nÉpoca 500\nPerdida entrenamiento: 0.20469026092220755\nPerdida validación: 2.3745395615696907\nExactitud validación: 18.5130\nÉpoca 501\nPerdida entrenamiento: 0.20449996783452876\nPerdida validación: 1.7906746417284012\nExactitud validación: 18.6261\nÉpoca 502\nPerdida entrenamiento: 0.20517864034456365\nPerdida validación: 1.732749417424202\nExactitud validación: 18.5130\nÉpoca 503\nPerdida entrenamiento: 0.20195804273380952\nPerdida validación: 2.2683166712522507\nExactitud validación: 18.5130\nÉpoca 504\nPerdida entrenamiento: 0.2007514510084601\nPerdida validación: 1.7528420686721802\nExactitud validación: 18.4000\nÉpoca 505\nPerdida entrenamiento: 0.2026394693290486\nPerdida validación: 1.7850606441497803\nExactitud validación: 18.4000\nÉpoca 506\nPerdida entrenamiento: 0.20051894775208304\nPerdida validación: 1.7376345694065094\nExactitud validación: 18.5130\nÉpoca 507\nPerdida entrenamiento: 0.1994068114196553\nPerdida validación: 1.813426986336708\nExactitud validación: 18.2870\nÉpoca 508\nPerdida entrenamiento: 0.20079496415222392\nPerdida validación: 2.327720493078232\nExactitud validación: 18.2870\nÉpoca 509\nPerdida entrenamiento: 0.20256532158921747\nPerdida validación: 1.7458709627389908\nExactitud validación: 18.4000\nÉpoca 510\nPerdida entrenamiento: 0.20124467067858753\nPerdida validación: 1.7705589160323143\nExactitud validación: 18.5130\nÉpoca 511\nPerdida entrenamiento: 0.19941148468676737\nPerdida validación: 1.796208769083023\nExactitud validación: 18.4000\nÉpoca 512\nPerdida entrenamiento: 0.19882883394465728\nPerdida validación: 1.749910831451416\nExactitud validación: 18.4000\nÉpoca 513\nPerdida entrenamiento: 0.2000570288475822\nPerdida validación: 1.796690434217453\nExactitud validación: 18.5130\nÉpoca 514\nPerdida entrenamiento: 0.19875034295460758\nPerdida validación: 1.7634713500738144\nExactitud validación: 18.4000\nÉpoca 515\nPerdida entrenamiento: 0.19847256471129024\nPerdida validación: 1.7303752601146698\nExactitud validación: 18.2870\nÉpoca 516\nPerdida entrenamiento: 0.19714518767945907\nPerdida validación: 1.7873051464557648\nExactitud validación: 18.7391\nÉpoca 517\nPerdida entrenamiento: 0.19987665379748626\nPerdida validación: 2.3726578801870346\nExactitud validación: 18.0609\nÉpoca 518\nPerdida entrenamiento: 0.19713971062618144\nPerdida validación: 1.8600481450557709\nExactitud validación: 18.6261\nÉpoca 519\nPerdida entrenamiento: 0.19719707089311936\nPerdida validación: 1.7947774976491928\nExactitud validación: 18.5130\nÉpoca 520\nPerdida entrenamiento: 0.19800057525143905\nPerdida validación: 1.8386373445391655\nExactitud validación: 18.4000\nÉpoca 521\nPerdida entrenamiento: 0.19503561845597098\nPerdida validación: 1.86511692404747\nExactitud validación: 18.0609\nÉpoca 522\nPerdida entrenamiento: 0.19703502164167516\nPerdida validación: 2.2786576449871063\nExactitud validación: 18.7391\nÉpoca 523\nPerdida entrenamiento: 0.1965047695180949\nPerdida validación: 1.7550715208053589\nExactitud validación: 18.5130\nÉpoca 524\nPerdida entrenamiento: 0.19743618281448588\nPerdida validación: 1.7788794338703156\nExactitud validación: 18.4000\nÉpoca 525\nPerdida entrenamiento: 0.19581336571889765\nPerdida validación: 2.3412183597683907\nExactitud validación: 18.6261\nÉpoca 526\nPerdida entrenamiento: 0.19735115065294154\nPerdida validación: 1.7944573611021042\nExactitud validación: 18.5130\nÉpoca 527\nPerdida entrenamiento: 0.1972572623806841\nPerdida validación: 1.7847600281238556\nExactitud validación: 18.4000\nÉpoca 528\nPerdida entrenamiento: 0.19613027397324057\nPerdida validación: 1.8530294448137283\nExactitud validación: 18.2870\nÉpoca 529\nPerdida entrenamiento: 0.19604966395041523\nPerdida validación: 1.8482124507427216\nExactitud validación: 18.6261\nÉpoca 530\nPerdida entrenamiento: 0.19563549099599614\nPerdida validación: 1.7713856101036072\nExactitud validación: 18.6261\nÉpoca 531\nPerdida entrenamiento: 0.1955263259656289\nPerdida validación: 1.8069935888051987\nExactitud validación: 17.9478\nÉpoca 532\nPerdida entrenamiento: 0.19411977774956646\nPerdida validación: 1.8041860908269882\nExactitud validación: 18.6261\nÉpoca 533\nPerdida entrenamiento: 0.1945977715008399\nPerdida validación: 1.825106680393219\nExactitud validación: 18.2870\nÉpoca 534\nPerdida entrenamiento: 0.1952920450883753\nPerdida validación: 2.3135114312171936\nExactitud validación: 18.6261\nÉpoca 535\nPerdida entrenamiento: 0.19248855683733435\nPerdida validación: 1.8990767300128937\nExactitud validación: 18.4000\nÉpoca 536\nPerdida entrenamiento: 0.19831059960757985\nPerdida validación: 1.80620726197958\nExactitud validación: 18.2870\nÉpoca 537\nPerdida entrenamiento: 0.1929608224069371\nPerdida validación: 1.7912742048501968\nExactitud validación: 18.4000\nÉpoca 538\nPerdida entrenamiento: 0.19296798898893244\nPerdida validación: 1.7543442994356155\nExactitud validación: 18.1739\nÉpoca 539\nPerdida entrenamiento: 0.1950954786118339\nPerdida validación: 1.8118992149829865\nExactitud validación: 18.4000\nÉpoca 540\nPerdida entrenamiento: 0.1945850323228275\nPerdida validación: 1.8098999336361885\nExactitud validación: 18.2870\nÉpoca 541\nPerdida entrenamiento: 0.19389351413530462\nPerdida validación: 2.289820373058319\nExactitud validación: 18.2870\nÉpoca 542\nPerdida entrenamiento: 0.19105484468095443\nPerdida validación: 1.794912725687027\nExactitud validación: 18.0609\nÉpoca 543\nPerdida entrenamiento: 0.19384890005869024\nPerdida validación: 1.875189632177353\nExactitud validación: 18.1739\nÉpoca 544\nPerdida entrenamiento: 0.19117492963286006\nPerdida validación: 1.809283822774887\nExactitud validación: 18.4000\nÉpoca 545\nPerdida entrenamiento: 0.19236618893987992\nPerdida validación: 2.2911151945590973\nExactitud validación: 18.6261\nÉpoca 546\nPerdida entrenamiento: 0.19125396495356278\nPerdida validación: 1.7524409666657448\nExactitud validación: 18.5130\nÉpoca 547\nPerdida entrenamiento: 0.19026901047019398\nPerdida validación: 1.8327823728322983\nExactitud validación: 18.4000\nÉpoca 548\nPerdida entrenamiento: 0.1921607873895589\nPerdida validación: 2.307979680597782\nExactitud validación: 18.2870\nÉpoca 549\nPerdida entrenamiento: 0.19157351816401763\nPerdida validación: 1.8872595876455307\nExactitud validación: 18.4000\nÉpoca 550\nPerdida entrenamiento: 0.19094288480632446\nPerdida validación: 1.9153790324926376\nExactitud validación: 18.6261\nÉpoca 551\nPerdida entrenamiento: 0.19048834592103958\nPerdida validación: 1.7659415304660797\nExactitud validación: 18.5130\nÉpoca 552\nPerdida entrenamiento: 0.19038300785948248\nPerdida validación: 1.7611987218260765\nExactitud validación: 18.4000\nÉpoca 553\nPerdida entrenamiento: 0.18965064383604946\nPerdida validación: 1.871100902557373\nExactitud validación: 18.2870\nÉpoca 554\nPerdida entrenamiento: 0.19062230779844172\nPerdida validación: 1.8860596120357513\nExactitud validación: 18.2870\nÉpoca 555\nPerdida entrenamiento: 0.18969056185554056\nPerdida validación: 2.3548885583877563\nExactitud validación: 18.0609\nÉpoca 556\nPerdida entrenamiento: 0.18985140696167946\nPerdida validación: 2.386777237057686\nExactitud validación: 18.5130\nÉpoca 557\nPerdida entrenamiento: 0.19206796192071018\nPerdida validación: 1.804469645023346\nExactitud validación: 18.2870\nÉpoca 558\nPerdida entrenamiento: 0.1930651068687439\nPerdida validación: 1.8630142956972122\nExactitud validación: 18.4000\nÉpoca 559\nPerdida entrenamiento: 0.1930370124823907\nPerdida validación: 1.7798155397176743\nExactitud validación: 18.4000\nÉpoca 560\nPerdida entrenamiento: 0.1902738498414264\nPerdida validación: 1.8318945318460464\nExactitud validación: 18.4000\nÉpoca 561\nPerdida entrenamiento: 0.19049055655212963\nPerdida validación: 1.7881848067045212\nExactitud validación: 18.4000\nÉpoca 562\nPerdida entrenamiento: 0.18791185231769786\nPerdida validación: 1.8009058833122253\nExactitud validación: 18.7391\nÉpoca 563\nPerdida entrenamiento: 0.18878159409060197\nPerdida validación: 2.3612941056489944\nExactitud validación: 18.2870\nÉpoca 564\nPerdida entrenamiento: 0.18708483611836152\nPerdida validación: 1.795827567577362\nExactitud validación: 18.6261\nÉpoca 565\nPerdida entrenamiento: 0.18627881477860844\nPerdida validación: 1.8481564670801163\nExactitud validación: 18.5130\nÉpoca 566\nPerdida entrenamiento: 0.18686316863578908\nPerdida validación: 1.8827480152249336\nExactitud validación: 18.5130\nÉpoca 567\nPerdida entrenamiento: 0.18734496525105307\nPerdida validación: 2.437557488679886\nExactitud validación: 18.6261\nÉpoca 568\nPerdida entrenamiento: 0.18700052578659618\nPerdida validación: 1.8809164464473724\nExactitud validación: 18.6261\nÉpoca 569\nPerdida entrenamiento: 0.1859943498583401\nPerdida validación: 2.3979000598192215\nExactitud validación: 18.5130\nÉpoca 570\nPerdida entrenamiento: 0.1867598135243444\nPerdida validación: 2.401433676481247\nExactitud validación: 18.4000\nÉpoca 571\nPerdida entrenamiento: 0.18641008743468454\nPerdida validación: 1.8099213689565659\nExactitud validación: 18.4000\nÉpoca 572\nPerdida entrenamiento: 0.1878149176345152\nPerdida validación: 1.8095275163650513\nExactitud validación: 18.7391\nÉpoca 573\nPerdida entrenamiento: 0.1844573288279421\nPerdida validación: 1.815418690443039\nExactitud validación: 18.4000\nÉpoca 574\nPerdida entrenamiento: 0.18568310711313696\nPerdida validación: 1.7979236990213394\nExactitud validación: 18.5130\nÉpoca 575\nPerdida entrenamiento: 0.1849901847103063\nPerdida validación: 1.8825554847717285\nExactitud validación: 18.4000\nÉpoca 576\nPerdida entrenamiento: 0.18612053245306015\nPerdida validación: 1.80270117521286\nExactitud validación: 18.4000\nÉpoca 577\nPerdida entrenamiento: 0.1876081745414173\nPerdida validación: 1.8711232542991638\nExactitud validación: 18.2870\nÉpoca 578\nPerdida entrenamiento: 0.18576577305793762\nPerdida validación: 1.908687710762024\nExactitud validación: 18.2870\nÉpoca 579\nPerdida entrenamiento: 0.18641850834383683\nPerdida validación: 1.86570705473423\nExactitud validación: 17.9478\nÉpoca 580\nPerdida entrenamiento: 0.1835003499599064\nPerdida validación: 1.8697331100702286\nExactitud validación: 18.6261\nÉpoca 581\nPerdida entrenamiento: 0.18529456985347412\nPerdida validación: 1.7919117659330368\nExactitud validación: 18.2870\nÉpoca 582\nPerdida entrenamiento: 0.1841503298457931\nPerdida validación: 2.4412302374839783\nExactitud validación: 18.7391\nÉpoca 583\nPerdida entrenamiento: 0.18371729158303318\nPerdida validación: 1.8544679284095764\nExactitud validación: 18.8522\nÉpoca 584\nPerdida entrenamiento: 0.18499108140959458\nPerdida validación: 1.8232229053974152\nExactitud validación: 18.5130\nÉpoca 585\nPerdida entrenamiento: 0.1860760952181676\nPerdida validación: 1.841095194220543\nExactitud validación: 18.5130\nÉpoca 586\nPerdida entrenamiento: 0.18593923703712575\nPerdida validación: 1.8760543167591095\nExactitud validación: 18.5130\nÉpoca 587\nPerdida entrenamiento: 0.18209941509891958\nPerdida validación: 1.9005913734436035\nExactitud validación: 18.5130\nÉpoca 588\nPerdida entrenamiento: 0.18258259160553708\nPerdida validación: 1.858061134815216\nExactitud validación: 18.6261\nÉpoca 589\nPerdida entrenamiento: 0.18598782183492885\nPerdida validación: 2.420540153980255\nExactitud validación: 18.2870\nÉpoca 590\nPerdida entrenamiento: 0.1828598489656168\nPerdida validación: 1.8328881710767746\nExactitud validación: 18.6261\nÉpoca 591\nPerdida entrenamiento: 0.1841830584932776\nPerdida validación: 1.8384827971458435\nExactitud validación: 18.5130\nÉpoca 592\nPerdida entrenamiento: 0.1838392247171963\nPerdida validación: 2.3826200664043427\nExactitud validación: 18.6261\nÉpoca 593\nPerdida entrenamiento: 0.18054470770499287\nPerdida validación: 2.3773992508649826\nExactitud validación: 18.7391\nÉpoca 594\nPerdida entrenamiento: 0.18052921707139297\nPerdida validación: 1.9906710982322693\nExactitud validación: 18.0609\nÉpoca 595\nPerdida entrenamiento: 0.18146830621887655\nPerdida validación: 2.434752732515335\nExactitud validación: 18.5130\nÉpoca 596\nPerdida entrenamiento: 0.17948470089365454\nPerdida validación: 1.852248728275299\nExactitud validación: 18.7391\nÉpoca 597\nPerdida entrenamiento: 0.17860462297411525\nPerdida validación: 2.346190959215164\nExactitud validación: 18.5130\nÉpoca 598\nPerdida entrenamiento: 0.18151379288995967\nPerdida validación: 1.9093308448791504\nExactitud validación: 18.5130\nÉpoca 599\nPerdida entrenamiento: 0.17953513781814015\nPerdida validación: 1.927807793021202\nExactitud validación: 18.6261\nÉpoca 600\nPerdida entrenamiento: 0.18134287832414403\nPerdida validación: 1.8202008605003357\nExactitud validación: 17.9478\nÉpoca 601\nPerdida entrenamiento: 0.18065105510108612\nPerdida validación: 2.4191258996725082\nExactitud validación: 18.0609\nÉpoca 602\nPerdida entrenamiento: 0.17909427337786732\nPerdida validación: 2.3444060534238815\nExactitud validación: 17.9478\nÉpoca 603\nPerdida entrenamiento: 0.1807249688050326\nPerdida validación: 1.859527364373207\nExactitud validación: 18.6261\nÉpoca 604\nPerdida entrenamiento: 0.17981747581678278\nPerdida validación: 1.8991383910179138\nExactitud validación: 18.4000\nÉpoca 605\nPerdida entrenamiento: 0.18046181123046315\nPerdida validación: 1.9196833372116089\nExactitud validación: 18.2870\nÉpoca 606\nPerdida entrenamiento: 0.17735964761060827\nPerdida validación: 1.8872027397155762\nExactitud validación: 18.4000\nÉpoca 607\nPerdida entrenamiento: 0.17956263265189001\nPerdida validación: 1.8883287459611893\nExactitud validación: 18.2870\nÉpoca 608\nPerdida entrenamiento: 0.17843612239641302\nPerdida validación: 2.382715880870819\nExactitud validación: 18.2870\nÉpoca 609\nPerdida entrenamiento: 0.17757347269969828\nPerdida validación: 1.932212918996811\nExactitud validación: 18.6261\nÉpoca 610\nPerdida entrenamiento: 0.1786287356825436\nPerdida validación: 1.9283054769039154\nExactitud validación: 18.4000\nÉpoca 611\nPerdida entrenamiento: 0.17991680958691766\nPerdida validación: 2.5501490607857704\nExactitud validación: 18.2870\nÉpoca 612\nPerdida entrenamiento: 0.18011304056819746\nPerdida validación: 1.7971415668725967\nExactitud validación: 18.4000\nÉpoca 613\nPerdida entrenamiento: 0.17593874650843003\nPerdida validación: 2.426175683736801\nExactitud validación: 18.4000\nÉpoca 614\nPerdida entrenamiento: 0.17618215829133987\nPerdida validación: 2.452900141477585\nExactitud validación: 18.5130\nÉpoca 615\nPerdida entrenamiento: 0.17730087129508748\nPerdida validación: 1.8392793536186218\nExactitud validación: 18.5130\nÉpoca 616\nPerdida entrenamiento: 0.1800769615699263\nPerdida validación: 1.9838367700576782\nExactitud validación: 18.8522\nÉpoca 617\nPerdida entrenamiento: 0.17642011405790553\nPerdida validación: 1.9059662222862244\nExactitud validación: 18.7391\nÉpoca 618\nPerdida entrenamiento: 0.17710689542924657\nPerdida validación: 1.862879142165184\nExactitud validación: 18.5130\nÉpoca 619\nPerdida entrenamiento: 0.17686956814106772\nPerdida validación: 1.8814306408166885\nExactitud validación: 18.4000\nÉpoca 620\nPerdida entrenamiento: 0.17600232581881917\nPerdida validación: 1.8020828627049923\nExactitud validación: 18.1739\nÉpoca 621\nPerdida entrenamiento: 0.17544799276134548\nPerdida validación: 1.811521127820015\nExactitud validación: 18.6261\nÉpoca 622\nPerdida entrenamiento: 0.17697353485752554\nPerdida validación: 1.877358078956604\nExactitud validación: 18.5130\nÉpoca 623\nPerdida entrenamiento: 0.17406106301966837\nPerdida validación: 1.8654315024614334\nExactitud validación: 18.1739\nÉpoca 624\nPerdida entrenamiento: 0.17648298687794628\nPerdida validación: 1.8686436414718628\nExactitud validación: 18.5130\nÉpoca 625\nPerdida entrenamiento: 0.17434970179901405\nPerdida validación: 1.919616162776947\nExactitud validación: 18.9652\nÉpoca 626\nPerdida entrenamiento: 0.17567084598190644\nPerdida validación: 1.9153682887554169\nExactitud validación: 18.0609\nÉpoca 627\nPerdida entrenamiento: 0.17896952392423854\nPerdida validación: 1.8582693189382553\nExactitud validación: 18.0609\nÉpoca 628\nPerdida entrenamiento: 0.17745003915008375\nPerdida validación: 1.9257307648658752\nExactitud validación: 18.5130\nÉpoca 629\nPerdida entrenamiento: 0.1788088896257036\nPerdida validación: 1.931223213672638\nExactitud validación: 18.5130\nÉpoca 630\nPerdida entrenamiento: 0.17631110548973083\nPerdida validación: 2.3573699593544006\nExactitud validación: 18.6261\nÉpoca 631\nPerdida entrenamiento: 0.17479468860170422\nPerdida validación: 1.9445046782493591\nExactitud validación: 18.6261\nÉpoca 632\nPerdida entrenamiento: 0.1756579818971017\nPerdida validación: 1.973215788602829\nExactitud validación: 18.1739\nÉpoca 633\nPerdida entrenamiento: 0.17561784189413576\nPerdida validación: 1.9100207686424255\nExactitud validación: 18.8522\nÉpoca 634\nPerdida entrenamiento: 0.1757204962127349\nPerdida validación: 1.939280390739441\nExactitud validación: 18.1739\nÉpoca 635\nPerdida entrenamiento: 0.17755503207445145\nPerdida validación: 1.981196641921997\nExactitud validación: 18.5130\nÉpoca 636\nPerdida entrenamiento: 0.17460980178678737\nPerdida validación: 1.9405174255371094\nExactitud validación: 18.4000\nÉpoca 637\nPerdida entrenamiento: 0.17348291571525967\nPerdida validación: 1.8273062705993652\nExactitud validación: 18.4000\nÉpoca 638\nPerdida entrenamiento: 0.1731029485954958\nPerdida validación: 2.380571126937866\nExactitud validación: 18.0609\nÉpoca 639\nPerdida entrenamiento: 0.17311051268787944\nPerdida validación: 2.059565246105194\nExactitud validación: 18.4000\nÉpoca 640\nPerdida entrenamiento: 0.17420342915198384\nPerdida validación: 1.9567348062992096\nExactitud validación: 18.6261\nÉpoca 641\nPerdida entrenamiento: 0.17315113938906612\nPerdida validación: 1.9034782350063324\nExactitud validación: 18.5130\nÉpoca 642\nPerdida entrenamiento: 0.1723686158657074\nPerdida validación: 1.9813492596149445\nExactitud validación: 18.5130\nÉpoca 643\nPerdida entrenamiento: 0.1716386500526877\nPerdida validación: 1.9668281972408295\nExactitud validación: 18.4000\nÉpoca 644\nPerdida entrenamiento: 0.17454188360887415\nPerdida validación: 2.3830559104681015\nExactitud validación: 18.2870\nÉpoca 645\nPerdida entrenamiento: 0.17409280687570572\nPerdida validación: 1.8761438131332397\nExactitud validación: 18.1739\nÉpoca 646\nPerdida entrenamiento: 0.17281085559550455\nPerdida validación: 1.8756016343832016\nExactitud validación: 18.4000\nÉpoca 647\nPerdida entrenamiento: 0.17153984615031412\nPerdida validación: 1.9308282732963562\nExactitud validación: 18.7391\nÉpoca 648\nPerdida entrenamiento: 0.17411951852195404\nPerdida validación: 1.8359106853604317\nExactitud validación: 17.8348\nÉpoca 649\nPerdida entrenamiento: 0.17255713790655136\nPerdida validación: 1.8988316506147385\nExactitud validación: 18.5130\nÉpoca 650\nPerdida entrenamiento: 0.17018533541875727\nPerdida validación: 1.949387177824974\nExactitud validación: 18.6261\nÉpoca 651\nPerdida entrenamiento: 0.17180895630051107\nPerdida validación: 1.9061071127653122\nExactitud validación: 18.5130\nÉpoca 652\nPerdida entrenamiento: 0.1712561582817751\nPerdida validación: 1.9416884183883667\nExactitud validación: 18.9652\nÉpoca 653\nPerdida entrenamiento: 0.17215262353420258\nPerdida validación: 1.8685024976730347\nExactitud validación: 18.8522\nÉpoca 654\nPerdida entrenamiento: 0.16887790841214798\nPerdida validación: 1.8882263749837875\nExactitud validación: 18.2870\nÉpoca 655\nPerdida entrenamiento: 0.17128623868612683\nPerdida validación: 2.458386555314064\nExactitud validación: 18.1739\nÉpoca 656\nPerdida entrenamiento: 0.170212522149086\nPerdida validación: 1.954999327659607\nExactitud validación: 18.5130\nÉpoca 657\nPerdida entrenamiento: 0.1741621494293213\nPerdida validación: 1.9523300230503082\nExactitud validación: 18.5130\nÉpoca 658\nPerdida entrenamiento: 0.17083424548892415\nPerdida validación: 1.959117352962494\nExactitud validación: 18.7391\nÉpoca 659\nPerdida entrenamiento: 0.16970867137698567\nPerdida validación: 1.8965559303760529\nExactitud validación: 18.4000\nÉpoca 660\nPerdida entrenamiento: 0.16913258941734538\nPerdida validación: 1.9195391535758972\nExactitud validación: 18.2870\nÉpoca 661\nPerdida entrenamiento: 0.16958869686898062\nPerdida validación: 2.4342183619737625\nExactitud validación: 17.7217\nÉpoca 662\nPerdida entrenamiento: 0.1689609788796481\nPerdida validación: 1.990819126367569\nExactitud validación: 18.6261\nÉpoca 663\nPerdida entrenamiento: 0.17155426433857748\nPerdida validación: 2.4798940420150757\nExactitud validación: 18.6261\nÉpoca 664\nPerdida entrenamiento: 0.17054487940143137\nPerdida validación: 1.982157289981842\nExactitud validación: 18.5130\nÉpoca 665\nPerdida entrenamiento: 0.16904305841992884\nPerdida validación: 1.8254309445619583\nExactitud validación: 18.4000\nÉpoca 666\nPerdida entrenamiento: 0.16776984053499558\nPerdida validación: 1.9470479041337967\nExactitud validación: 18.6261\nÉpoca 667\nPerdida entrenamiento: 0.16710532982559764\nPerdida validación: 2.491328239440918\nExactitud validación: 18.8522\nÉpoca 668\nPerdida entrenamiento: 0.16992384808904984\nPerdida validación: 1.9949734210968018\nExactitud validación: 18.7391\nÉpoca 669\nPerdida entrenamiento: 0.16685624595950632\nPerdida validación: 1.8857195228338242\nExactitud validación: 18.4000\nÉpoca 670\nPerdida entrenamiento: 0.16876719979678884\nPerdida validación: 1.880652368068695\nExactitud validación: 18.8522\nÉpoca 671\nPerdida entrenamiento: 0.1676985665279276\nPerdida validación: 1.9278014451265335\nExactitud validación: 18.0609\nÉpoca 672\nPerdida entrenamiento: 0.1676903353894458\nPerdida validación: 1.950418546795845\nExactitud validación: 18.6261\nÉpoca 673\nPerdida entrenamiento: 0.1701295621254865\nPerdida validación: 1.8648300468921661\nExactitud validación: 17.9478\nÉpoca 674\nPerdida entrenamiento: 0.17001822459347107\nPerdida validación: 1.8509264029562473\nExactitud validación: 18.1739\nÉpoca 675\nPerdida entrenamiento: 0.16711394970907884\nPerdida validación: 1.954179808497429\nExactitud validación: 18.5130\nÉpoca 676\nPerdida entrenamiento: 0.16708773023941936\nPerdida validación: 1.924515724182129\nExactitud validación: 18.2870\nÉpoca 677\nPerdida entrenamiento: 0.16858496648423812\nPerdida validación: 2.000500962138176\nExactitud validación: 18.4000\nÉpoca 678\nPerdida entrenamiento: 0.16450631793807535\nPerdida validación: 2.566338747739792\nExactitud validación: 18.2870\nÉpoca 679\nPerdida entrenamiento: 0.16761167566565907\nPerdida validación: 2.0148858428001404\nExactitud validación: 18.4000\nÉpoca 680\nPerdida entrenamiento: 0.16833147757193623\nPerdida validación: 2.074228048324585\nExactitud validación: 18.6261\nÉpoca 681\nPerdida entrenamiento: 0.16532384385080898\nPerdida validación: 1.9695260673761368\nExactitud validación: 18.6261\nÉpoca 682\nPerdida entrenamiento: 0.16553058124640407\nPerdida validación: 1.9510675370693207\nExactitud validación: 18.4000\nÉpoca 683\nPerdida entrenamiento: 0.16487656051621719\nPerdida validación: 2.4368354082107544\nExactitud validación: 18.0609\nÉpoca 684\nPerdida entrenamiento: 0.1665136836030904\nPerdida validación: 1.9446289241313934\nExactitud validación: 18.6261\nÉpoca 685\nPerdida entrenamiento: 0.16706801074392655\nPerdida validación: 2.0074078142642975\nExactitud validación: 18.2870\nÉpoca 686\nPerdida entrenamiento: 0.16774573746849508\nPerdida validación: 1.9531133472919464\nExactitud validación: 18.2870\nÉpoca 687\nPerdida entrenamiento: 0.1662634378846954\nPerdida validación: 1.9650149643421173\nExactitud validación: 18.1739\nÉpoca 688\nPerdida entrenamiento: 0.165897518834647\nPerdida validación: 1.9263443648815155\nExactitud validación: 18.5130\nÉpoca 689\nPerdida entrenamiento: 0.16783844898728764\nPerdida validación: 2.5158949941396713\nExactitud validación: 18.1739\nÉpoca 690\nPerdida entrenamiento: 0.1632937078966814\nPerdida validación: 2.1293532699346542\nExactitud validación: 18.4000\nÉpoca 691\nPerdida entrenamiento: 0.16604621116729343\nPerdida validación: 1.994159609079361\nExactitud validación: 18.2870\nÉpoca 692\nPerdida entrenamiento: 0.16435301785959916\nPerdida validación: 1.955128014087677\nExactitud validación: 18.5130\nÉpoca 693\nPerdida entrenamiento: 0.16429974248304086\nPerdida validación: 1.9711505323648453\nExactitud validación: 18.4000\nÉpoca 694\nPerdida entrenamiento: 0.1655895092031535\nPerdida validación: 1.929766833782196\nExactitud validación: 18.4000\nÉpoca 695\nPerdida entrenamiento: 0.16631515455596588\nPerdida validación: 2.5120222568511963\nExactitud validación: 18.6261\nÉpoca 696\nPerdida entrenamiento: 0.16254296022302964\nPerdida validación: 2.6067320108413696\nExactitud validación: 18.5130\nÉpoca 697\nPerdida entrenamiento: 0.16614514501655803\nPerdida validación: 1.9055406600236893\nExactitud validación: 18.2870\nÉpoca 698\nPerdida entrenamiento: 0.16295288327862234\nPerdida validación: 2.6316159069538116\nExactitud validación: 18.4000\nÉpoca 699\nPerdida entrenamiento: 0.16373521878438838\nPerdida validación: 1.9525791704654694\nExactitud validación: 18.4000\nÉpoca 700\nPerdida entrenamiento: 0.16521619216484182\nPerdida validación: 2.574406772851944\nExactitud validación: 18.4000\nÉpoca 701\nPerdida entrenamiento: 0.1622587906963685\nPerdida validación: 2.044219732284546\nExactitud validación: 18.5130\nÉpoca 702\nPerdida entrenamiento: 0.16276384846252553\nPerdida validación: 2.4917390048503876\nExactitud validación: 18.2870\nÉpoca 703\nPerdida entrenamiento: 0.16085231830092037\nPerdida validación: 2.0034276843070984\nExactitud validación: 18.7391\nÉpoca 704\nPerdida entrenamiento: 0.1621255900929956\nPerdida validación: 1.8788238018751144\nExactitud validación: 18.0609\nÉpoca 705\nPerdida entrenamiento: 0.16276478811221964\nPerdida validación: 2.609136253595352\nExactitud validación: 18.7391\nÉpoca 706\nPerdida entrenamiento: 0.16290473981815226\nPerdida validación: 2.039955824613571\nExactitud validación: 18.1739\nÉpoca 707\nPerdida entrenamiento: 0.1612090832170318\nPerdida validación: 2.555538982152939\nExactitud validación: 18.6261\nÉpoca 708\nPerdida entrenamiento: 0.16272959770525203\nPerdida validación: 2.6732825934886932\nExactitud validación: 18.6261\nÉpoca 709\nPerdida entrenamiento: 0.16046422807609334\nPerdida validación: 2.65529066324234\nExactitud validación: 18.2870\nÉpoca 710\nPerdida entrenamiento: 0.1593300660743433\nPerdida validación: 2.6579330414533615\nExactitud validación: 18.1739\nÉpoca 711\nPerdida entrenamiento: 0.16260490128222635\nPerdida validación: 3.1879926919937134\nExactitud validación: 18.2870\nÉpoca 712\nPerdida entrenamiento: 0.1639710743637646\nPerdida validación: 2.5582952350378036\nExactitud validación: 18.1739\nÉpoca 713\nPerdida entrenamiento: 0.16152114859398672\nPerdida validación: 3.1042632460594177\nExactitud validación: 18.0609\nÉpoca 714\nPerdida entrenamiento: 0.16002430547686183\nPerdida validación: 2.019172251224518\nExactitud validación: 18.5130\nÉpoca 715\nPerdida entrenamiento: 0.162712872685755\nPerdida validación: 2.5908713340759277\nExactitud validación: 18.2870\nÉpoca 716\nPerdida entrenamiento: 0.16232478969237385\nPerdida validación: 3.1466260999441147\nExactitud validación: 18.6261\nÉpoca 717\nPerdida entrenamiento: 0.15897689803558238\nPerdida validación: 2.5849307030439377\nExactitud validación: 18.1739\nÉpoca 718\nPerdida entrenamiento: 0.16153902823434158\nPerdida validación: 2.647393435239792\nExactitud validación: 18.1739\nÉpoca 719\nPerdida entrenamiento: 0.16119855642318726\nPerdida validación: 2.612269088625908\nExactitud validación: 18.5130\nÉpoca 720\nPerdida entrenamiento: 0.15967204334104762\nPerdida validación: 2.601207673549652\nExactitud validación: 18.0609\nÉpoca 721\nPerdida entrenamiento: 0.15950890805791407\nPerdida validación: 2.5986678898334503\nExactitud validación: 18.4000\nÉpoca 722\nPerdida entrenamiento: 0.1589717917582568\nPerdida validación: 2.7100989818573\nExactitud validación: 18.5130\nÉpoca 723\nPerdida entrenamiento: 0.16081694338251562\nPerdida validación: 3.600108325481415\nExactitud validación: 18.2870\nÉpoca 724\nPerdida entrenamiento: 0.16270827458185308\nPerdida validación: 2.6002797037363052\nExactitud validación: 18.2870\nÉpoca 725\nPerdida entrenamiento: 0.1581830897313707\nPerdida validación: 2.6805626302957535\nExactitud validación: 18.4000\nÉpoca 726\nPerdida entrenamiento: 0.1591141451807583\nPerdida validación: 2.6532941460609436\nExactitud validación: 18.9652\nÉpoca 727\nPerdida entrenamiento: 0.157598956981126\nPerdida validación: 2.572138734161854\nExactitud validación: 18.2870\nÉpoca 728\nPerdida entrenamiento: 0.15787621149245432\nPerdida validación: 2.6060239374637604\nExactitud validación: 18.1739\nÉpoca 729\nPerdida entrenamiento: 0.15959105903611465\nPerdida validación: 2.6934962272644043\nExactitud validación: 18.2870\nÉpoca 730\nPerdida entrenamiento: 0.1582015459151829\nPerdida validación: 2.60768923163414\nExactitud validación: 18.5130\nÉpoca 731\nPerdida entrenamiento: 0.157621492357815\nPerdida validación: 3.6954606622457504\nExactitud validación: 18.6261\nÉpoca 732\nPerdida entrenamiento: 0.15893621874206207\nPerdida validación: 2.7011904567480087\nExactitud validación: 18.6261\nÉpoca 733\nPerdida entrenamiento: 0.15736218322725856\nPerdida validación: 2.8146928548812866\nExactitud validación: 18.6261\nÉpoca 734\nPerdida entrenamiento: 0.1576247026815134\nPerdida validación: 3.218151092529297\nExactitud validación: 18.4000\nÉpoca 735\nPerdida entrenamiento: 0.15623568064149687\nPerdida validación: 2.5988488644361496\nExactitud validación: 18.2870\nÉpoca 736\nPerdida entrenamiento: 0.1571689445306273\nPerdida validación: 2.706854522228241\nExactitud validación: 18.2870\nÉpoca 737\nPerdida entrenamiento: 0.15617569579797633\nPerdida validación: 2.713013231754303\nExactitud validación: 18.8522\nÉpoca 738\nPerdida entrenamiento: 0.15783894587965572\nPerdida validación: 2.7247913777828217\nExactitud validación: 18.4000\nÉpoca 739\nPerdida entrenamiento: 0.15578018676708727\nPerdida validación: 2.6655010879039764\nExactitud validación: 18.5130\nÉpoca 740\nPerdida entrenamiento: 0.15636154088903875\nPerdida validación: 3.165435329079628\nExactitud validación: 18.2870\nÉpoca 741\nPerdida entrenamiento: 0.15926396539982626\nPerdida validación: 2.5721025094389915\nExactitud validación: 18.0609\nÉpoca 742\nPerdida entrenamiento: 0.156381642774624\nPerdida validación: 2.6201601326465607\nExactitud validación: 18.2870\nÉpoca 743\nPerdida entrenamiento: 0.15768505413742626\nPerdida validación: 2.618269592523575\nExactitud validación: 18.5130\nÉpoca 744\nPerdida entrenamiento: 0.1584767182083691\nPerdida validación: 2.642210215330124\nExactitud validación: 18.2870\nÉpoca 745\nPerdida entrenamiento: 0.1547083705663681\nPerdida validación: 2.74025359749794\nExactitud validación: 18.2870\nÉpoca 746\nPerdida entrenamiento: 0.15429270661929073\nPerdida validación: 2.722310483455658\nExactitud validación: 18.9652\nÉpoca 747\nPerdida entrenamiento: 0.15567336516345248\nPerdida validación: 2.602600187063217\nExactitud validación: 18.4000\nÉpoca 748\nPerdida entrenamiento: 0.15859329021152327\nPerdida validación: 2.6595190167427063\nExactitud validación: 18.4000\nÉpoca 749\nPerdida entrenamiento: 0.1617139963542714\nPerdida validación: 2.670899897813797\nExactitud validación: 18.2870\nÉpoca 750\nPerdida entrenamiento: 0.1628905837150181\nPerdida validación: 3.219875618815422\nExactitud validación: 18.6261\nÉpoca 751\nPerdida entrenamiento: 0.16012920132454703\nPerdida validación: 3.225644052028656\nExactitud validación: 18.2870\nÉpoca 752\nPerdida entrenamiento: 0.15868979188449242\nPerdida validación: 2.67586637288332\nExactitud validación: 18.4000\nÉpoca 753\nPerdida entrenamiento: 0.1629258720752071\nPerdida validación: 2.6681269705295563\nExactitud validación: 18.4000\nÉpoca 754\nPerdida entrenamiento: 0.15711017215953155\nPerdida validación: 3.1297914385795593\nExactitud validación: 17.8348\nÉpoca 755\nPerdida entrenamiento: 0.1531862835673725\nPerdida validación: 2.726800709962845\nExactitud validación: 18.6261\nÉpoca 756\nPerdida entrenamiento: 0.15572210028767586\nPerdida validación: 2.682586520910263\nExactitud validación: 18.4000\nÉpoca 757\nPerdida entrenamiento: 0.15500885072876425\nPerdida validación: 2.609253168106079\nExactitud validación: 18.6261\nÉpoca 758\nPerdida entrenamiento: 0.1528870090842247\nPerdida validación: 2.7033819258213043\nExactitud validación: 18.4000\nÉpoca 759\nPerdida entrenamiento: 0.15350659870926073\nPerdida validación: 3.182022213935852\nExactitud validación: 18.2870\nÉpoca 760\nPerdida entrenamiento: 0.15298916180344188\nPerdida validación: 2.600184068083763\nExactitud validación: 18.4000\nÉpoca 761\nPerdida entrenamiento: 0.1532105700496365\nPerdida validación: 2.6323400884866714\nExactitud validación: 18.2870\nÉpoca 762\nPerdida entrenamiento: 0.15355657391688404\nPerdida validación: 2.684819757938385\nExactitud validación: 18.7391\nÉpoca 763\nPerdida entrenamiento: 0.15543739366180756\nPerdida validación: 3.7091951966285706\nExactitud validación: 18.4000\nÉpoca 764\nPerdida entrenamiento: 0.15140601116068222\nPerdida validación: 3.2474584877490997\nExactitud validación: 18.1739\nÉpoca 765\nPerdida entrenamiento: 0.1533643844373086\nPerdida validación: 2.633063405752182\nExactitud validación: 18.5130\nÉpoca 766\nPerdida entrenamiento: 0.15192966732908697\nPerdida validación: 3.1432758569717407\nExactitud validación: 18.1739\nÉpoca 767\nPerdida entrenamiento: 0.15253492926850037\nPerdida validación: 3.246622011065483\nExactitud validación: 18.5130\nÉpoca 768\nPerdida entrenamiento: 0.15309041738510132\nPerdida validación: 2.62382273375988\nExactitud validación: 18.6261\nÉpoca 769\nPerdida entrenamiento: 0.15307236353264136\nPerdida validación: 3.6945867389440536\nExactitud validación: 17.9478\nÉpoca 770\nPerdida entrenamiento: 0.15285500949796507\nPerdida validación: 2.6508836895227432\nExactitud validación: 18.2870\nÉpoca 771\nPerdida entrenamiento: 0.15295826271176338\nPerdida validación: 2.6306875497102737\nExactitud validación: 17.8348\nÉpoca 772\nPerdida entrenamiento: 0.15547319151022854\nPerdida validación: 2.6264542788267136\nExactitud validación: 18.2870\nÉpoca 773\nPerdida entrenamiento: 0.1503035711014972\nPerdida validación: 2.7056295573711395\nExactitud validación: 18.4000\nÉpoca 774\nPerdida entrenamiento: 0.15113376037162893\nPerdida validación: 3.1897840797901154\nExactitud validación: 18.2870\nÉpoca 775\nPerdida entrenamiento: 0.15134701746351578\nPerdida validación: 2.728394031524658\nExactitud validación: 18.4000\nÉpoca 776\nPerdida entrenamiento: 0.1525684919427423\nPerdida validación: 2.6042723059654236\nExactitud validación: 18.1739\nÉpoca 777\nPerdida entrenamiento: 0.1504207696108257\nPerdida validación: 2.600286602973938\nExactitud validación: 18.0609\nÉpoca 778\nPerdida entrenamiento: 0.14879275551613638\nPerdida validación: 3.278126984834671\nExactitud validación: 18.6261\nÉpoca 779\nPerdida entrenamiento: 0.1492233626982745\nPerdida validación: 3.162637710571289\nExactitud validación: 17.9478\nÉpoca 780\nPerdida entrenamiento: 0.15052652950672543\nPerdida validación: 3.2997718304395676\nExactitud validación: 18.5130\nÉpoca 781\nPerdida entrenamiento: 0.1493004634976387\nPerdida validación: 2.6290631741285324\nExactitud validación: 18.4000\nÉpoca 782\nPerdida entrenamiento: 0.15232405197971008\nPerdida validación: 2.6413462162017822\nExactitud validación: 18.1739\nÉpoca 783\nPerdida entrenamiento: 0.149240040603806\nPerdida validación: 3.256709098815918\nExactitud validación: 18.6261\nÉpoca 784\nPerdida entrenamiento: 0.15085110112148173\nPerdida validación: 3.1722599267959595\nExactitud validación: 18.4000\nÉpoca 785\nPerdida entrenamiento: 0.151833686101086\nPerdida validación: 2.7989502251148224\nExactitud validación: 18.6261\nÉpoca 786\nPerdida entrenamiento: 0.1522596204543815\nPerdida validación: 3.242053836584091\nExactitud validación: 18.2870\nÉpoca 787\nPerdida entrenamiento: 0.14921585799140089\nPerdida validación: 2.6283081024885178\nExactitud validación: 18.0609\nÉpoca 788\nPerdida entrenamiento: 0.14916231044951608\nPerdida validación: 2.6112345829606056\nExactitud validación: 18.5130\nÉpoca 789\nPerdida entrenamiento: 0.14993023477932987\nPerdida validación: 2.7713897675275803\nExactitud validación: 18.5130\nÉpoca 790\nPerdida entrenamiento: 0.14652396913836985\nPerdida validación: 2.666732057929039\nExactitud validación: 18.2870\nÉpoca 791\nPerdida entrenamiento: 0.14829734318396626\nPerdida validación: 2.7664362490177155\nExactitud validación: 18.5130\nÉpoca 792\nPerdida entrenamiento: 0.14896368410657435\nPerdida validación: 2.713522434234619\nExactitud validación: 18.1739\nÉpoca 793\nPerdida entrenamiento: 0.1503126388963531\nPerdida validación: 2.7845799028873444\nExactitud validación: 18.4000\nÉpoca 794\nPerdida entrenamiento: 0.1479355679715381\nPerdida validación: 3.245860606431961\nExactitud validación: 18.2870\nÉpoca 795\nPerdida entrenamiento: 0.14547785524936283\nPerdida validación: 3.1711438596248627\nExactitud validación: 17.9478\nÉpoca 796\nPerdida entrenamiento: 0.14639997482299805\nPerdida validación: 2.6832973659038544\nExactitud validación: 18.0609\nÉpoca 797\nPerdida entrenamiento: 0.14787339857395956\nPerdida validación: 3.2161754816770554\nExactitud validación: 18.8522\nÉpoca 798\nPerdida entrenamiento: 0.14859987883006825\nPerdida validación: 2.6865431666374207\nExactitud validación: 18.4000\nÉpoca 799\nPerdida entrenamiento: 0.1477495445048108\nPerdida validación: 2.63492251932621\nExactitud validación: 18.2870\nÉpoca 800\nPerdida entrenamiento: 0.14877094437970834\nPerdida validación: 2.6738118827342987\nExactitud validación: 18.1739\nÉpoca 801\nPerdida entrenamiento: 0.1459410251939998\nPerdida validación: 2.6356877088546753\nExactitud validación: 18.2870\nÉpoca 802\nPerdida entrenamiento: 0.14662704945487134\nPerdida validación: 2.6701188534498215\nExactitud validación: 18.0609\nÉpoca 803\nPerdida entrenamiento: 0.14530917300897486\nPerdida validación: 2.6025548111647367\nExactitud validación: 18.0609\nÉpoca 804\nPerdida entrenamiento: 0.14726974793216763\nPerdida validación: 2.7442044615745544\nExactitud validación: 18.6261\nÉpoca 805\nPerdida entrenamiento: 0.14796733768547282\nPerdida validación: 2.7691594064235687\nExactitud validación: 18.4000\nÉpoca 806\nPerdida entrenamiento: 0.144820795777966\nPerdida validación: 2.7950679063796997\nExactitud validación: 18.1739\nÉpoca 807\nPerdida entrenamiento: 0.1451437639839509\nPerdida validación: 2.794357866048813\nExactitud validación: 18.4000\nÉpoca 808\nPerdida entrenamiento: 0.14519775439711177\nPerdida validación: 3.242251545190811\nExactitud validación: 18.5130\nÉpoca 809\nPerdida entrenamiento: 0.14527228825232563\nPerdida validación: 3.215233623981476\nExactitud validación: 18.4000\nÉpoca 810\nPerdida entrenamiento: 0.14561747715753667\nPerdida validación: 2.7339600920677185\nExactitud validación: 18.1739\nÉpoca 811\nPerdida entrenamiento: 0.1456113238545025\nPerdida validación: 2.7056923508644104\nExactitud validación: 18.6261\nÉpoca 812\nPerdida entrenamiento: 0.14788693189620972\nPerdida validación: 2.826267398893833\nExactitud validación: 18.6261\nÉpoca 813\nPerdida entrenamiento: 0.14552707049776525\nPerdida validación: 2.6988613605499268\nExactitud validación: 18.2870\nÉpoca 814\nPerdida entrenamiento: 0.14622166621334412\nPerdida validación: 2.7413794100284576\nExactitud validación: 18.6261\nÉpoca 815\nPerdida entrenamiento: 0.143801851745914\nPerdida validación: 2.6483813747763634\nExactitud validación: 18.6261\nÉpoca 816\nPerdida entrenamiento: 0.14336932428619442\nPerdida validación: 2.7818442583084106\nExactitud validación: 18.7391\nÉpoca 817\nPerdida entrenamiento: 0.14512714743614197\nPerdida validación: 3.2018503546714783\nExactitud validación: 18.1739\nÉpoca 818\nPerdida entrenamiento: 0.14359367025249145\nPerdida validación: 3.8155419528484344\nExactitud validación: 18.4000\nÉpoca 819\nPerdida entrenamiento: 0.14185754341237686\nPerdida validación: 2.6466083750128746\nExactitud validación: 18.7391\nÉpoca 820\nPerdida entrenamiento: 0.14415400869706096\nPerdida validación: 2.8113376051187515\nExactitud validación: 18.7391\nÉpoca 821\nPerdida entrenamiento: 0.14479920443366556\nPerdida validación: 2.733074575662613\nExactitud validación: 18.2870\nÉpoca 822\nPerdida entrenamiento: 0.14300062858006535\nPerdida validación: 2.66407323628664\nExactitud validación: 17.9478\nÉpoca 823\nPerdida entrenamiento: 0.14438624636215322\nPerdida validación: 2.725124940276146\nExactitud validación: 18.6261\nÉpoca 824\nPerdida entrenamiento: 0.14179060323273435\nPerdida validación: 3.7919468730688095\nExactitud validación: 18.7391\nÉpoca 825\nPerdida entrenamiento: 0.14401953755056157\nPerdida validación: 2.940170705318451\nExactitud validación: 18.8522\nÉpoca 826\nPerdida entrenamiento: 0.14078793148784077\nPerdida validación: 2.730820268392563\nExactitud validación: 18.6261\nÉpoca 827\nPerdida entrenamiento: 0.14310375184697263\nPerdida validación: 2.7902650237083435\nExactitud validación: 18.8522\nÉpoca 828\nPerdida entrenamiento: 0.1415631906951175\nPerdida validación: 2.798295736312866\nExactitud validación: 18.5130\nÉpoca 829\nPerdida entrenamiento: 0.1424680740079459\nPerdida validación: 2.751399964094162\nExactitud validación: 18.4000\nÉpoca 830\nPerdida entrenamiento: 0.1435266877798473\nPerdida validación: 2.73421211540699\nExactitud validación: 18.1739\nÉpoca 831\nPerdida entrenamiento: 0.14105699036051245\nPerdida validación: 2.752659022808075\nExactitud validación: 18.1739\nÉpoca 832\nPerdida entrenamiento: 0.1436002629206461\nPerdida validación: 2.6599045991897583\nExactitud validación: 18.5130\nÉpoca 833\nPerdida entrenamiento: 0.14401213079690933\nPerdida validación: 2.719948261976242\nExactitud validación: 18.2870\nÉpoca 834\nPerdida entrenamiento: 0.14162796144099796\nPerdida validación: 3.2921559512615204\nExactitud validación: 18.2870\nÉpoca 835\nPerdida entrenamiento: 0.14128982319551356\nPerdida validación: 2.6709438040852547\nExactitud validación: 18.4000\nÉpoca 836\nPerdida entrenamiento: 0.14059947935097358\nPerdida validación: 2.7341255843639374\nExactitud validación: 18.4000\nÉpoca 837\nPerdida entrenamiento: 0.1398994068012518\nPerdida validación: 2.786491632461548\nExactitud validación: 18.5130\nÉpoca 838\nPerdida entrenamiento: 0.14133495618315303\nPerdida validación: 2.690669760107994\nExactitud validación: 18.2870\nÉpoca 839\nPerdida entrenamiento: 0.1424069856019581\nPerdida validación: 3.295660972595215\nExactitud validación: 18.4000\nÉpoca 840\nPerdida entrenamiento: 0.1393086116980104\nPerdida validación: 2.660525068640709\nExactitud validación: 18.5130\nÉpoca 841\nPerdida entrenamiento: 0.14105064158930497\nPerdida validación: 2.737117111682892\nExactitud validación: 18.4000\nÉpoca 842\nPerdida entrenamiento: 0.13984821671072176\nPerdida validación: 2.802027255296707\nExactitud validación: 18.5130\nÉpoca 843\nPerdida entrenamiento: 0.14101365844116492\nPerdida validación: 2.8786006718873978\nExactitud validación: 18.6261\nÉpoca 844\nPerdida entrenamiento: 0.14051969480865142\nPerdida validación: 2.7385316342115402\nExactitud validación: 18.6261\nÉpoca 845\nPerdida entrenamiento: 0.14059160868911183\nPerdida validación: 3.7438178658485413\nExactitud validación: 18.4000\nÉpoca 846\nPerdida entrenamiento: 0.1408574015778654\nPerdida validación: 3.268863081932068\nExactitud validación: 18.2870\nÉpoca 847\nPerdida entrenamiento: 0.14002320258056417\nPerdida validación: 3.4570556730031967\nExactitud validación: 18.5130\nÉpoca 848\nPerdida entrenamiento: 0.14203892955008676\nPerdida validación: 2.8030443489551544\nExactitud validación: 18.4000\nÉpoca 849\nPerdida entrenamiento: 0.14011239435742884\nPerdida validación: 2.820237874984741\nExactitud validación: 18.2870\nÉpoca 850\nPerdida entrenamiento: 0.1396850124001503\nPerdida validación: 3.243169218301773\nExactitud validación: 18.5130\nÉpoca 851\nPerdida entrenamiento: 0.13872243946089463\nPerdida validación: 2.7179784178733826\nExactitud validación: 18.5130\nÉpoca 852\nPerdida entrenamiento: 0.13912279465619257\nPerdida validación: 2.7133824974298477\nExactitud validación: 18.1739\nÉpoca 853\nPerdida entrenamiento: 0.13690624988692648\nPerdida validación: 2.8744891583919525\nExactitud validación: 18.1739\nÉpoca 854\nPerdida entrenamiento: 0.1364170865100973\nPerdida validación: 2.780077964067459\nExactitud validación: 18.4000\nÉpoca 855\nPerdida entrenamiento: 0.13848148680785122\nPerdida validación: 2.732403054833412\nExactitud validación: 18.4000\nÉpoca 856\nPerdida entrenamiento: 0.13774363828056\nPerdida validación: 2.748747408390045\nExactitud validación: 18.1739\nÉpoca 857\nPerdida entrenamiento: 0.13970747677718892\nPerdida validación: 2.7384248077869415\nExactitud validación: 18.7391\nÉpoca 858\nPerdida entrenamiento: 0.13931907012182124\nPerdida validación: 2.7981139421463013\nExactitud validación: 18.5130\nÉpoca 859\nPerdida entrenamiento: 0.13711956625475602\nPerdida validación: 2.746776044368744\nExactitud validación: 18.4000\nÉpoca 860\nPerdida entrenamiento: 0.14136996602310853\nPerdida validación: 2.961911305785179\nExactitud validación: 18.8522\nÉpoca 861\nPerdida entrenamiento: 0.1371486279017785\nPerdida validación: 2.920855939388275\nExactitud validación: 18.9652\nÉpoca 862\nPerdida entrenamiento: 0.1369148339418804\nPerdida validación: 3.3346258997917175\nExactitud validación: 17.9478\nÉpoca 863\nPerdida entrenamiento: 0.1381302679724553\nPerdida validación: 2.696602389216423\nExactitud validación: 18.1739\nÉpoca 864\nPerdida entrenamiento: 0.13654666306341395\nPerdida validación: 2.7097426876425743\nExactitud validación: 18.5130\nÉpoca 865\nPerdida entrenamiento: 0.1373768339262289\nPerdida validación: 2.822031795978546\nExactitud validación: 17.8348\nÉpoca 866\nPerdida entrenamiento: 0.1341216191649437\nPerdida validación: 2.705332897603512\nExactitud validación: 18.1739\nÉpoca 867\nPerdida entrenamiento: 0.1376872159102384\nPerdida validación: 2.7694733440876007\nExactitud validación: 18.0609\nÉpoca 868\nPerdida entrenamiento: 0.13436881759587457\nPerdida validación: 2.782355934381485\nExactitud validación: 18.6261\nÉpoca 869\nPerdida entrenamiento: 0.13662084586480083\nPerdida validación: 2.75421804189682\nExactitud validación: 18.1739\nÉpoca 870\nPerdida entrenamiento: 0.1360327185076826\nPerdida validación: 2.8113476634025574\nExactitud validación: 18.7391\nÉpoca 871\nPerdida entrenamiento: 0.13782303298220916\nPerdida validación: 2.779130682349205\nExactitud validación: 18.5130\nÉpoca 872\nPerdida entrenamiento: 0.13344334416529713\nPerdida validación: 2.784419059753418\nExactitud validación: 18.2870\nÉpoca 873\nPerdida entrenamiento: 0.13555954462465117\nPerdida validación: 2.7529250234365463\nExactitud validación: 18.2870\nÉpoca 874\nPerdida entrenamiento: 0.1355480694157236\nPerdida validación: 3.300339162349701\nExactitud validación: 18.4000\nÉpoca 875\nPerdida entrenamiento: 0.13865461638745138\nPerdida validación: 2.9780090004205704\nExactitud validación: 18.7391\nÉpoca 876\nPerdida entrenamiento: 0.1376051098546561\nPerdida validación: 2.8903158009052277\nExactitud validación: 18.2870\nÉpoca 877\nPerdida entrenamiento: 0.13494748030515277\nPerdida validación: 2.7917942702770233\nExactitud validación: 18.6261\nÉpoca 878\nPerdida entrenamiento: 0.1352824815275038\nPerdida validación: 3.3168766498565674\nExactitud validación: 18.6261\nÉpoca 879\nPerdida entrenamiento: 0.1324736436500269\nPerdida validación: 2.7636314928531647\nExactitud validación: 18.4000\nÉpoca 880\nPerdida entrenamiento: 0.13348486493615544\nPerdida validación: 2.871694028377533\nExactitud validación: 18.5130\nÉpoca 881\nPerdida entrenamiento: 0.13614112927633173\nPerdida validación: 2.82409131526947\nExactitud validación: 18.7391\nÉpoca 882\nPerdida entrenamiento: 0.13355802678886583\nPerdida validación: 2.7636439353227615\nExactitud validación: 18.4000\nÉpoca 883\nPerdida entrenamiento: 0.1327956191757146\nPerdida validación: 2.812580853700638\nExactitud validación: 18.1739\nÉpoca 884\nPerdida entrenamiento: 0.13378482684493065\nPerdida validación: 2.7658906280994415\nExactitud validación: 18.2870\nÉpoca 885\nPerdida entrenamiento: 0.1324151684256161\nPerdida validación: 2.857463538646698\nExactitud validación: 18.4000\nÉpoca 886\nPerdida entrenamiento: 0.1337796228335184\nPerdida validación: 3.4032358527183533\nExactitud validación: 18.4000\nÉpoca 887\nPerdida entrenamiento: 0.13265221697442672\nPerdida validación: 3.3464408963918686\nExactitud validación: 18.2870\nÉpoca 888\nPerdida entrenamiento: 0.13283191577476613\nPerdida validación: 2.790514573454857\nExactitud validación: 18.5130\nÉpoca 889\nPerdida entrenamiento: 0.13208355623133042\nPerdida validación: 2.8009232729673386\nExactitud validación: 18.5130\nÉpoca 890\nPerdida entrenamiento: 0.13509997550178976\nPerdida validación: 2.8039220198988914\nExactitud validación: 18.5130\nÉpoca 891\nPerdida entrenamiento: 0.13466739829848795\nPerdida validación: 2.90687495470047\nExactitud validación: 18.2870\nÉpoca 892\nPerdida entrenamiento: 0.1318563308347674\nPerdida validación: 2.8616604059934616\nExactitud validación: 18.6261\nÉpoca 893\nPerdida entrenamiento: 0.13101407315801172\nPerdida validación: 2.96872079372406\nExactitud validación: 18.6261\nÉpoca 894\nPerdida entrenamiento: 0.13524135245996363\nPerdida validación: 2.829436719417572\nExactitud validación: 18.5130\nÉpoca 895\nPerdida entrenamiento: 0.13446547616930568\nPerdida validación: 2.8921854197978973\nExactitud validación: 18.4000\nÉpoca 896\nPerdida entrenamiento: 0.13377005256274166\nPerdida validación: 2.9073114544153214\nExactitud validación: 18.5130\nÉpoca 897\nPerdida entrenamiento: 0.13366495949380539\nPerdida validación: 2.869605004787445\nExactitud validación: 18.4000\nÉpoca 898\nPerdida entrenamiento: 0.13367976116783478\nPerdida validación: 2.8357715904712677\nExactitud validación: 18.2870\nÉpoca 899\nPerdida entrenamiento: 0.13272172037292929\nPerdida validación: 3.323453515768051\nExactitud validación: 18.2870\nÉpoca 900\nPerdida entrenamiento: 0.132703357759644\nPerdida validación: 2.9263442158699036\nExactitud validación: 18.6261\nÉpoca 901\nPerdida entrenamiento: 0.13167799373759942\nPerdida validación: 3.4298669397830963\nExactitud validación: 18.0609\nÉpoca 902\nPerdida entrenamiento: 0.1339989497381098\nPerdida validación: 2.8030209839344025\nExactitud validación: 18.2870\nÉpoca 903\nPerdida entrenamiento: 0.1287992243819377\nPerdida validación: 2.8654688000679016\nExactitud validación: 18.7391\nÉpoca 904\nPerdida entrenamiento: 0.13100341444506364\nPerdida validación: 3.4879584312438965\nExactitud validación: 18.4000\nÉpoca 905\nPerdida entrenamiento: 0.1310742236673832\nPerdida validación: 2.7952137142419815\nExactitud validación: 18.2870\nÉpoca 906\nPerdida entrenamiento: 0.12950651961214402\nPerdida validación: 2.8933157920837402\nExactitud validación: 18.5130\nÉpoca 907\nPerdida entrenamiento: 0.12948743275859775\nPerdida validación: 2.920369252562523\nExactitud validación: 18.9652\nÉpoca 908\nPerdida entrenamiento: 0.12981591811951468\nPerdida validación: 2.874404937028885\nExactitud validación: 18.2870\nÉpoca 909\nPerdida entrenamiento: 0.1289715587216265\nPerdida validación: 3.2992987632751465\nExactitud validación: 18.7391\nÉpoca 910\nPerdida entrenamiento: 0.1300869676120141\nPerdida validación: 3.415118455886841\nExactitud validación: 18.1739\nÉpoca 911\nPerdida entrenamiento: 0.1314496520687552\nPerdida validación: 2.855779469013214\nExactitud validación: 18.4000\nÉpoca 912\nPerdida entrenamiento: 0.13039520207573385\nPerdida validación: 2.863826960325241\nExactitud validación: 18.2870\nÉpoca 913\nPerdida entrenamiento: 0.12854845580809257\nPerdida validación: 3.4703205823898315\nExactitud validación: 18.5130\nÉpoca 914\nPerdida entrenamiento: 0.1311737588223289\nPerdida validación: 2.8276840299367905\nExactitud validación: 18.1739\nÉpoca 915\nPerdida entrenamiento: 0.12898599926163168\nPerdida validación: 2.808225929737091\nExactitud validación: 18.2870\nÉpoca 916\nPerdida entrenamiento: 0.12826384625890674\nPerdida validación: 2.954753652215004\nExactitud validación: 18.0609\nÉpoca 917\nPerdida entrenamiento: 0.1291312752839397\nPerdida validación: 3.455663487315178\nExactitud validación: 18.2870\nÉpoca 918\nPerdida entrenamiento: 0.1272546608439263\nPerdida validación: 2.840626373887062\nExactitud validación: 18.6261\nÉpoca 919\nPerdida entrenamiento: 0.12807583589764202\nPerdida validación: 2.908486932516098\nExactitud validación: 18.7391\nÉpoca 920\nPerdida entrenamiento: 0.12984531920622377\nPerdida validación: 2.949549823999405\nExactitud validación: 18.1739\nÉpoca 921\nPerdida entrenamiento: 0.12714826140333624\nPerdida validación: 2.9026261270046234\nExactitud validación: 18.0609\nÉpoca 922\nPerdida entrenamiento: 0.12683334858978496\nPerdida validación: 3.4384027123451233\nExactitud validación: 18.4000\nÉpoca 923\nPerdida entrenamiento: 0.12668604359907262\nPerdida validación: 3.4019243717193604\nExactitud validación: 17.9478\nÉpoca 924\nPerdida entrenamiento: 0.1273968097041635\nPerdida validación: 3.4543668031692505\nExactitud validación: 18.0609\nÉpoca 925\nPerdida entrenamiento: 0.1270380519768771\nPerdida validación: 2.9080685824155807\nExactitud validación: 18.4000\nÉpoca 926\nPerdida entrenamiento: 0.12678182059351137\nPerdida validación: 2.854278191924095\nExactitud validación: 18.6261\nÉpoca 927\nPerdida entrenamiento: 0.1272417313474066\nPerdida validación: 3.409367948770523\nExactitud validación: 18.5130\nÉpoca 928\nPerdida entrenamiento: 0.12685667372801723\nPerdida validación: 4.08304163813591\nExactitud validación: 18.4000\nÉpoca 929\nPerdida entrenamiento: 0.12677246003466494\nPerdida validación: 2.8712600469589233\nExactitud validación: 18.4000\nÉpoca 930\nPerdida entrenamiento: 0.12664389434982748\nPerdida validación: 2.9682075679302216\nExactitud validación: 18.5130\nÉpoca 931\nPerdida entrenamiento: 0.12917877909015207\nPerdida validación: 2.8417866826057434\nExactitud validación: 18.1739\nÉpoca 932\nPerdida entrenamiento: 0.12731395530350068\nPerdida validación: 2.898645430803299\nExactitud validación: 18.4000\nÉpoca 933\nPerdida entrenamiento: 0.12507441157803817\nPerdida validación: 2.914635419845581\nExactitud validación: 18.5130\nÉpoca 934\nPerdida entrenamiento: 0.12594195674447453\nPerdida validación: 2.912827104330063\nExactitud validación: 18.4000\nÉpoca 935\nPerdida entrenamiento: 0.1251837317557896\nPerdida validación: 3.5243859738111496\nExactitud validación: 18.4000\nÉpoca 936\nPerdida entrenamiento: 0.12473153717377607\nPerdida validación: 2.9899864494800568\nExactitud validación: 18.6261\nÉpoca 937\nPerdida entrenamiento: 0.12627896666526794\nPerdida validación: 2.940245568752289\nExactitud validación: 17.9478\nÉpoca 938\nPerdida entrenamiento: 0.12539050552774877\nPerdida validación: 3.506003439426422\nExactitud validación: 18.6261\nÉpoca 939\nPerdida entrenamiento: 0.12461071943535525\nPerdida validación: 2.9693265557289124\nExactitud validación: 18.8522\nÉpoca 940\nPerdida entrenamiento: 0.12703695104402654\nPerdida validación: 3.0138815343379974\nExactitud validación: 18.6261\nÉpoca 941\nPerdida entrenamiento: 0.12593218640369527\nPerdida validación: 3.412371516227722\nExactitud validación: 18.8522\nÉpoca 942\nPerdida entrenamiento: 0.12484191182781668\nPerdida validación: 2.875510886311531\nExactitud validación: 18.4000\nÉpoca 943\nPerdida entrenamiento: 0.12549839157830267\nPerdida validación: 3.0640504956245422\nExactitud validación: 18.2870\nÉpoca 944\nPerdida entrenamiento: 0.1243065052172717\nPerdida validación: 3.010021924972534\nExactitud validación: 18.5130\nÉpoca 945\nPerdida entrenamiento: 0.12402418606421527\nPerdida validación: 2.888392746448517\nExactitud validación: 18.6261\nÉpoca 946\nPerdida entrenamiento: 0.12377885378458921\nPerdida validación: 2.8283270969986916\nExactitud validación: 18.1739\nÉpoca 947\nPerdida entrenamiento: 0.12332157023689326\nPerdida validación: 3.4357332587242126\nExactitud validación: 18.1739\nÉpoca 948\nPerdida entrenamiento: 0.12415540525141884\nPerdida validación: 2.9335389137268066\nExactitud validación: 18.7391\nÉpoca 949\nPerdida entrenamiento: 0.12486725640209283\nPerdida validación: 2.931018203496933\nExactitud validación: 18.6261\nÉpoca 950\nPerdida entrenamiento: 0.12408434424330206\nPerdida validación: 3.054698035120964\nExactitud validación: 18.6261\nÉpoca 951\nPerdida entrenamiento: 0.12574190032832763\nPerdida validación: 3.0038841366767883\nExactitud validación: 18.2870\nÉpoca 952\nPerdida entrenamiento: 0.12242736294865608\nPerdida validación: 4.074982047080994\nExactitud validación: 18.4000\nÉpoca 953\nPerdida entrenamiento: 0.12435674601617981\nPerdida validación: 2.973332405090332\nExactitud validación: 18.5130\nÉpoca 954\nPerdida entrenamiento: 0.12533021915484877\nPerdida validación: 3.4903931617736816\nExactitud validación: 18.5130\nÉpoca 955\nPerdida entrenamiento: 0.12362913436749402\nPerdida validación: 2.894077181816101\nExactitud validación: 18.0609\nÉpoca 956\nPerdida entrenamiento: 0.1241259554072338\nPerdida validación: 3.5641388595104218\nExactitud validación: 18.8522\nÉpoca 957\nPerdida entrenamiento: 0.12326250049997778\nPerdida validación: 2.894750624895096\nExactitud validación: 18.7391\nÉpoca 958\nPerdida entrenamiento: 0.12201590529259514\nPerdida validación: 3.554157704114914\nExactitud validación: 18.7391\nÉpoca 959\nPerdida entrenamiento: 0.12234444193103734\nPerdida validación: 3.0658498108386993\nExactitud validación: 18.7391\nÉpoca 960\nPerdida entrenamiento: 0.1225890420815524\nPerdida validación: 2.9639132916927338\nExactitud validación: 18.2870\nÉpoca 961\nPerdida entrenamiento: 0.12655563323813326\nPerdida validación: 3.4610494822263718\nExactitud validación: 18.2870\nÉpoca 962\nPerdida entrenamiento: 0.12557828514014974\nPerdida validación: 3.0472725331783295\nExactitud validación: 18.7391\nÉpoca 963\nPerdida entrenamiento: 0.12406371117514722\nPerdida validación: 3.4296689927577972\nExactitud validación: 18.5130\nÉpoca 964\nPerdida entrenamiento: 0.12306797109982547\nPerdida validación: 2.8831294775009155\nExactitud validación: 18.6261\nÉpoca 965\nPerdida entrenamiento: 0.12154533823623377\nPerdida validación: 3.0393559336662292\nExactitud validación: 18.0609\nÉpoca 966\nPerdida entrenamiento: 0.12231333071694654\nPerdida validación: 2.893571987748146\nExactitud validación: 18.2870\nÉpoca 967\nPerdida entrenamiento: 0.12442432300132863\nPerdida validación: 2.8784404695034027\nExactitud validación: 18.8522\nÉpoca 968\nPerdida entrenamiento: 0.12219117998200305\nPerdida validación: 3.0569884181022644\nExactitud validación: 18.5130\nÉpoca 969\nPerdida entrenamiento: 0.1204835956587511\nPerdida validación: 3.0531783998012543\nExactitud validación: 18.1739\nÉpoca 970\nPerdida entrenamiento: 0.12147321595865138\nPerdida validación: 3.105465844273567\nExactitud validación: 18.5130\nÉpoca 971\nPerdida entrenamiento: 0.11965199538013514\nPerdida validación: 2.9067180305719376\nExactitud validación: 18.2870\nÉpoca 972\nPerdida entrenamiento: 0.1203617955393651\nPerdida validación: 2.853972941637039\nExactitud validación: 18.2870\nÉpoca 973\nPerdida entrenamiento: 0.12197020540342611\nPerdida validación: 2.951186329126358\nExactitud validación: 18.6261\nÉpoca 974\nPerdida entrenamiento: 0.12436810749418595\nPerdida validación: 3.067672148346901\nExactitud validación: 18.6261\nÉpoca 975\nPerdida entrenamiento: 0.12134960271856364\nPerdida validación: 3.5442528426647186\nExactitud validación: 18.2870\nÉpoca 976\nPerdida entrenamiento: 0.1222062270869227\nPerdida validación: 3.071064904332161\nExactitud validación: 18.7391\nÉpoca 977\nPerdida entrenamiento: 0.12381410642581828\nPerdida validación: 2.9515878558158875\nExactitud validación: 18.1739\nÉpoca 978\nPerdida entrenamiento: 0.11919486478847616\nPerdida validación: 2.987251326441765\nExactitud validación: 18.8522\nÉpoca 979\nPerdida entrenamiento: 0.12118908982066547\nPerdida validación: 2.964499592781067\nExactitud validación: 18.2870\nÉpoca 980\nPerdida entrenamiento: 0.11982706517857664\nPerdida validación: 2.884852759540081\nExactitud validación: 18.2870\nÉpoca 981\nPerdida entrenamiento: 0.12243366482503273\nPerdida validación: 2.9526966214179993\nExactitud validación: 18.5130\nÉpoca 982\nPerdida entrenamiento: 0.12023616615025436\nPerdida validación: 2.892222762107849\nExactitud validación: 18.5130\nÉpoca 983\nPerdida entrenamiento: 0.11949533388456877\nPerdida validación: 3.0738677978515625\nExactitud validación: 18.5130\nÉpoca 984\nPerdida entrenamiento: 0.11815058308489182\nPerdida validación: 2.943865194916725\nExactitud validación: 18.1739\nÉpoca 985\nPerdida entrenamiento: 0.12010063581606921\nPerdida validación: 3.0461696088314056\nExactitud validación: 18.2870\nÉpoca 986\nPerdida entrenamiento: 0.1200608185985509\nPerdida validación: 4.0663831532001495\nExactitud validación: 18.4000\nÉpoca 987\nPerdida entrenamiento: 0.11974002442815725\nPerdida validación: 3.468088820576668\nExactitud validación: 18.1739\nÉpoca 988\nPerdida entrenamiento: 0.11906973097254248\nPerdida validación: 2.943978175520897\nExactitud validación: 18.0609\nÉpoca 989\nPerdida entrenamiento: 0.12085146150168251\nPerdida validación: 3.0875197649002075\nExactitud validación: 18.4000\nÉpoca 990\nPerdida entrenamiento: 0.11931220442056656\nPerdida validación: 3.4530164301395416\nExactitud validación: 18.2870\nÉpoca 991\nPerdida entrenamiento: 0.1200842373073101\nPerdida validación: 3.108154445886612\nExactitud validación: 18.4000\nÉpoca 992\nPerdida entrenamiento: 0.11944863528889768\nPerdida validación: 3.4121116399765015\nExactitud validación: 18.2870\nÉpoca 993\nPerdida entrenamiento: 0.11968237862867467\nPerdida validación: 2.9360441118478775\nExactitud validación: 18.2870\nÉpoca 994\nPerdida entrenamiento: 0.11799231237348388\nPerdida validación: 3.036650687456131\nExactitud validación: 18.4000\nÉpoca 995\nPerdida entrenamiento: 0.11872703187605914\nPerdida validación: 2.939451888203621\nExactitud validación: 18.4000\nÉpoca 996\nPerdida entrenamiento: 0.1186886644538711\nPerdida validación: 3.0029216408729553\nExactitud validación: 18.4000\nÉpoca 997\nPerdida entrenamiento: 0.11697329558870372\nPerdida validación: 2.912400111556053\nExactitud validación: 18.1739\nÉpoca 998\nPerdida entrenamiento: 0.11653838547713616\nPerdida validación: 3.0047235190868378\nExactitud validación: 18.1739\nÉpoca 999\nPerdida entrenamiento: 0.11792571338660576\nPerdida validación: 4.158627465367317\nExactitud validación: 18.5130\nÉpoca 1000\nPerdida entrenamiento: 0.11670456804773387\nPerdida validación: 2.9439720809459686\nExactitud validación: 18.1739"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/preparing_slides.html",
    "href": "codigo/preparing_slides.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport pywt\nimport matplotlib.pyplot as plt\nimport imageio\nfrom scipy import signal\n\n# 1. Generate a sample noisy signal\nnp.random.seed(0)\nt = np.linspace(0, 1, 500)\noriginal_signal = signal.sawtooth(2 * np.pi * 5 * t)  # Original signal\nnoise = np.random.normal(0, 0.5, t.shape)\nnoisy_signal = original_signal + noise  # Noisy signal\n\n# 2. Define wavelet and apply wavelet transform\nwavelet = \"db4\"  # Daubechies wavelet\ncoeffs = pywt.wavedec(noisy_signal, wavelet, level=5)\n\n# 3. Denoising by thresholding coefficients\nthreshold = 0.3  # Set threshold for denoising\ncoeffs_thresholded = [pywt.threshold(c, threshold * max(c)) for c in coeffs]\n\n# 4. Initialize list for frames\nframes = []\n\n# 5. Reconstruct the signal at each thresholding level and save each frame\nfor i in range(1, len(coeffs_thresholded) + 1):\n    # Zero out coefficients above level i\n    coeffs_temp = coeffs_thresholded[:i] + [\n        np.zeros_like(c) for c in coeffs_thresholded[i:]\n    ]\n    denoised_signal = pywt.waverec(coeffs_temp, wavelet)\n\n    # Plot the original, noisy, and partially denoised signal\n    fig, ax = plt.subplots(figsize=(8, 4))\n    ax.plot(t, noisy_signal, label=\"Noisy Signal\", color=\"gray\", alpha=0.6)\n    ax.plot(t, original_signal, label=\"Original Signal\", color=\"black\", linestyle=\"--\")\n    ax.plot(t, denoised_signal, label=f\"Wavelet Denoising (Level {i})\", color=\"blue\")\n    ax.legend()\n    ax.set_title(f\"Wavelet Denoising Progression - Level {i}\")\n    ax.set_xlabel(\"Time\")\n    ax.set_ylabel(\"Amplitude\")\n\n    # Save frame as image in memory\n    fig.canvas.draw()\n    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype=\"uint8\")\n    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n    frames.append(image)\n    plt.close(fig)  # Close figure to save memory\n\n# 6. Save frames as a GIF\nimageio.mimsave(\"wavelet_transform_denoising.gif\", frames, fps=2)\nprint(\"GIF saved as 'wavelet_transform_denoising.gif'\")\n\n\nimport numpy as np\nimport pywt\nimport matplotlib.pyplot as plt\n\n# Generate a synthetic signal with features\nnp.random.seed(0)\nt = np.linspace(0, 1, 500)\nsignal = np.sin(2 * np.pi * 5 * t)  # Base signal (5 Hz)\nsignal[100:120] += 2  # Add a spike (feature at t=0.2)\nsignal[300:320] -= 1.5  # Add another feature (t=0.6)\n\n# Perform wavelet decomposition (using Daubechies 4 wavelet)\nwavelet = \"db4\"\nmax_level = 5  # Maximum decomposition level\ncoeffs = pywt.wavedec(signal, wavelet, level=max_level)\n\n# Plot the original signal with features\nplt.figure(figsize=(10, 6))\nplt.subplot(3, 1, 1)\nplt.plot(t, signal, label=\"Original Signal with Features\", color=\"black\")\nplt.title(\"Original Signal\")\nplt.xlim(0, 1)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\n\n# Plot the wavelet transform coefficients at different levels\nfor i in range(1, max_level + 1):\n    plt.subplot(3, 2, i + 1)\n    # Plot detail coefficients for the current level\n    # Zero out other levels to highlight the current level's detail coefficients\n    coeffs_temp = [\n        coeffs[0] if j == 0 else np.zeros_like(coeff) for j, coeff in enumerate(coeffs)\n    ]\n    coeffs_temp[i] = coeffs[i]  # Keep the detail coefficients for level i\n\n    # Reconstruct the signal using only the current level's details\n    feature_detection = pywt.waverec(coeffs_temp, wavelet)\n    plt.plot(\n        t,\n        feature_detection[: len(signal)],\n        label=f\"Level {i} Feature Detection\",\n        color=\"red\",\n    )\n    plt.title(f\"Detected Features - Level {i}\")\n    plt.xlim(0, 1)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Amplitude\")\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Configuración del vector\nvx, vy = 4, 3  # Componentes del vector\n\n# Crear la figura y los ejes\nfig, ax = plt.subplots()\n\n# Dibujar los ejes\nax.axhline(0, color=\"black\", linewidth=0.5)\nax.axvline(0, color=\"black\", linewidth=0.5)\n\n# Dibujar el vector\nax.quiver(\n    0,\n    0,\n    vx,\n    vy,\n    angles=\"xy\",\n    scale_units=\"xy\",\n    scale=1,\n    color=\"blue\",\n)\n\n# Dibujar el vector con estilo de línea punteada\nax.plot([0, vx], [0, 0], \"k--\")  # Línea punteada para el vector\nax.plot(vx, 0, \"ko\")  # Punto en el extremo del vector\nax.plot([0, 0], [0, vy], \"k--\")  # Línea punteada para el vector\nax.plot(0, vy, \"ko\")  # Punto en el extremo del vector\n\n# Dibujar las proyecciones en los ejes\nax.plot([vx, vx], [0, vy], \"r:\")\nax.plot([0, vx], [vy, vy], \"g:\")\n\n# Etiquetas para las proyecciones\nax.text(vx, -0.1, r\"$X_1$\", ha=\"center\", va=\"top\")\nax.text(-0.1, vy, r\"$Y_1$\", ha=\"right\", va=\"center\")\nax.text(vx, vy, r\"$(X_1, Y_1)$\", ha=\"left\", va=\"bottom\")\nax.text(-0.3, -0.3, \"O\", ha=\"center\", va=\"center\")\n\n# Configurar los límites de la gráfica\nax.set_xlim(-1, vx + 2)\nax.set_ylim(-1, vy + 2)\n\n# Añadir etiquetas y leyendas\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.legend()\n\n# Configurar la cuadrícula\nax.grid(True)\nax.set_aspect(\"equal\")\n\n# Mostrar el gráfico\nplt.show()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time vector\nt = np.linspace(-3, 3, 500)\n\n# Define the original function and its components\nf_t = np.exp(t)  # Original function: e^t\nf_even = (np.exp(t) + np.exp(-t)) / 2  # Even part: cosh(t)\nf_odd = (np.exp(t) - np.exp(-t)) / 2  # Odd part: sinh(t)\n\n# Create the subplots\nfig, axs = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n\n# Plot the original function\naxs[0].plot(t, f_t, label=r\"$f(t) = e^t$\", color=\"blue\", linewidth=2)\naxs[0].set_title(\"Original Function\", fontsize=14)\naxs[0].set_ylabel(\"Amplitude\", fontsize=12)\naxs[0].legend(fontsize=12)\naxs[0].grid(True)\n\n# Plot the even part\naxs[1].plot(\n    t, f_even, label=r\"$f_{\\text{even}}(t) = \\cosh(t)$\", color=\"green\", linewidth=2\n)\naxs[1].set_title(\"Even Part of the Function\", fontsize=14)\naxs[1].set_ylabel(\"Amplitude\", fontsize=12)\naxs[1].legend(fontsize=12)\naxs[1].grid(True)\n\n# Plot the odd part\naxs[2].plot(t, f_odd, label=r\"$f_{\\text{odd}}(t) = \\sinh(t)$\", color=\"red\", linewidth=2)\naxs[2].set_title(\"Odd Part of the Function\", fontsize=14)\naxs[2].set_xlabel(\"Time (s)\", fontsize=12)\naxs[2].set_ylabel(\"Amplitude\", fontsize=12)\naxs[2].legend(fontsize=12)\naxs[2].grid(True)\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n\n\nimport requests\n\nresponse = requests.get(\n    \"https://charts-spotify-com-service.spotify.com/public/v0/charts\"\n)\n\ndata = response.json()\n\nfor entry in response.json()[\"chartEntryViewResponses\"][0][\"entries\"]:\n    meta = entry[\"trackMetadata\"]\n    entry = entry[\"chartEntryData\"]\n\n    track = meta[\"trackName\"]\n    artists = \", \".join([artist[\"name\"] for artist in meta[\"artists\"]])\n\n    print(f\"{entry['currentRank']:3} | {track:50} | {artists}\")\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nbeta = 2  # Amplitude scaling factor\nt = np.linspace(-5, 5, 400)\n\n# Scaled functions\nu_t = beta * np.heaviside(t, 1)  # Amplitude-Scaled Unit Step\nr_t = beta * np.maximum(t, 0)  # Amplitude-Scaled Unit Ramp\nsinc_t = beta * np.sinc(t)  # Amplitude-Scaled Sinc\ndelta_t = beta * np.exp(-100 * t**2)  # Amplitude-Scaled Dirac Delta (approximated)\n\n# Plot all functions in a single figure\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n# Unit Step Function\naxes[0, 0].plot(t, u_t, label=\"Amplitude-Scaled Unit Step\", linewidth=2)\naxes[0, 0].set_title(\"Amplitude-Scaled Unit Step Function\")\naxes[0, 0].set_xlabel(\"Time (t)\")\naxes[0, 0].set_ylabel(\"Amplitude\")\naxes[0, 0].grid(True)\naxes[0, 0].legend()\n\n# Unit Ramp Function\naxes[0, 1].plot(t, r_t, label=\"Amplitude-Scaled Unit Ramp\", linewidth=2)\naxes[0, 1].set_title(\"Amplitude-Scaled Unit Ramp Function\")\naxes[0, 1].set_xlabel(\"Time (t)\")\naxes[0, 1].set_ylabel(\"Amplitude\")\naxes[0, 1].grid(True)\naxes[0, 1].legend()\n\n# Sinc Function\naxes[1, 0].plot(t, sinc_t, label=\"Amplitude-Scaled Sinc Function\", linewidth=2)\naxes[1, 0].set_title(\"Amplitude-Scaled Sinc Function\")\naxes[1, 0].set_xlabel(\"Time (t)\")\naxes[1, 0].set_ylabel(\"Amplitude\")\naxes[1, 0].grid(True)\naxes[1, 0].legend()\n\n# Dirac Delta Function\naxes[1, 1].plot(t, delta_t, label=\"Amplitude-Scaled Dirac Delta (Approx.)\", linewidth=2)\naxes[1, 1].set_title(\"Amplitude-Scaled Dirac Delta Function (Approx.)\")\naxes[1, 1].set_xlabel(\"Time (t)\")\naxes[1, 1].set_ylabel(\"Amplitude\")\naxes[1, 1].grid(True)\naxes[1, 1].legend()\n\n# Adjust layout and show the plot\nplt.tight_layout()\nplt.show()\n\n\nt = np.linspace(-10,10,1000)\nx = np.zeros(t.shape)\n\nx = (\n    np.maximum(t + 5, 0)\n    - np.maximum(t + 0, 0)\n    - 3 * np.heaviside(t - 5, 1)\n    - np.maximum(t - 7.5, 0)\n    + np.maximum(t-9.5, 0)\n)\nplt.figure(figsize=(16,6.75))\nplt.plot(t,x)\nplt.grid()\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Amplitude\")\n\n\n# Re-import necessary libraries after execution state reset\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define time range for three periods\nT = 2 * np.pi  # Period of sine function\nt = np.linspace(-T, 2 * T, 1000)  # Three periods\ny = np.sin(t)\n\n# Define one period to highlight in blue\nt_highlight = np.linspace(0, T, 300)\ny_highlight = np.sin(t_highlight)\n\n# Plot the sine function\nplt.figure(figsize=(12, 6))\nplt.plot(t, y, label=\"Sine Function\", linewidth=2, color=\"black\")\nplt.plot(\n    t_highlight, y_highlight, linewidth=3, color=\"blue\", label=\"Highlighted Period\"\n)\n\n# Labels and grid\nplt.xlabel(\"Time (t)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Sine Function Over Three Periods\")\nplt.axhline(0, color=\"black\", linewidth=0.8)\nplt.axvline(T, color=\"gray\", linestyle=\"--\", linewidth=1)  # Marking one period end\nplt.axvline(\n    2 * T, color=\"gray\", linestyle=\"--\", linewidth=1\n)  # Marking second period end\nplt.grid(True, linestyle=\"--\", alpha=0.6)\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n# Define fundamental periods\nT1 = 10  # Period of first signal\nT2 = 3  # Period of second signal\n\n# Time range covering multiple periods\nt = np.linspace(0, 20, 1000)\n\n# Define two periodic signals\nx1 = np.sin((2 * np.pi / T1) * t)  # First periodic signal\nx2 = np.cos((2 * np.pi / T2) * t)  # Second periodic signal\n\n# Sum of both signals\nx_sum = x1 + x2\n\n# Plot signals\nplt.figure(figsize=(12, 6))\n\nplt.plot(t, x1, label=f\"Signal 1: Period {T1}\", linestyle=\"dashed\")\nplt.plot(t, x2, label=f\"Signal 2: Period {T2}\", linestyle=\"dotted\")\nplt.plot(t, x_sum, label=\"Sum of Signals\", linewidth=2, color=\"black\")\n\nplt.xlabel(\"Time (t)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Sum of Two Periodic Signals\")\nplt.axhline(0, color=\"gray\", linewidth=0.8)\nplt.grid(True, linestyle=\"--\", alpha=0.6)\nplt.legend()\n\nplt.show()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros de la señal\nduration = 2  # Duración en segundos\nfs = 1000  # Frecuencia de muestreo en Hz\nt = np.linspace(0, duration, duration * fs, endpoint=False)  # Vector de tiempo\n\n# Señal senoidal de 10 Hz\nfreq = 10\nsine_wave = np.sin(2 * np.pi * freq * t)\n\n# Señal de ruido aleatorio con distribución normal\nnoise_normal = np.random.normal(0, 1, len(t))\n\n# Señal con ruido aleatorio de 2 a 5 Hz\nlow_freq_noise = np.sin(2 * np.pi * np.random.uniform(2, 5) * t)\nsignal_with_low_freq_noise = sine_wave + low_freq_noise\n\n# Señal con ruido aleatorio uniforme sumado\nuniform_noise = np.random.uniform(-0.5, 0.5, len(t))\nsignal_with_uniform_noise = sine_wave + uniform_noise\n\n# Señal con ruido aleatorio uniforme multiplicado\nmultiplicative_noise = np.random.uniform(0.5, 1.5, len(t))\nsignal_with_mult_noise = sine_wave * multiplicative_noise\n\n# Graficamos las señales\nfig, axes = plt.subplots(5, 1, figsize=(10, 10), sharex=True)\n\naxes[0].plot(t, sine_wave, label=\"Sine wave (10 Hz)\")\naxes[0].set_title(\"Sine Wave (10 Hz)\")\naxes[0].legend()\n\naxes[1].plot(\n    t, noise_normal, label=\"Random Noise (Normal Distribution)\", color=\"orange\"\n)\naxes[1].set_title(\"Random Noise (Normal Distribution)\")\naxes[1].legend()\n\naxes[2].plot(\n    t, signal_with_low_freq_noise, label=\"Sine + Low Freq Noise (2-5 Hz)\", color=\"green\"\n)\naxes[2].set_title(\"Sine + Low Freq Noise (2-5 Hz)\")\naxes[2].legend()\n\naxes[3].plot(t, signal_with_uniform_noise, label=\"Sine + Uniform Noise\", color=\"red\")\naxes[3].set_title(\"Sine + Uniform Noise\")\naxes[3].legend()\n\naxes[4].plot(t, signal_with_mult_noise, label=\"Sine * Uniform Noise\", color=\"purple\")\naxes[4].set_title(\"Sine * Uniform Noise\")\naxes[4].legend()\n\nplt.xlabel(\"Time [s]\")\nplt.tight_layout()\nplt.show()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros\nFs = 10  # Frecuencia de muestreo (Hz)\nF1 = 3  # Frecuencia de la primera señal (Hz)\nF2 = F1 + Fs  # Frecuencia de la segunda señal (F1 + Fs) - Produce aliasing\n\nT = 1  # Duración en segundos\nt_continuo = np.linspace(0, T, 1000)  # Tiempo continuo para la señal original\nn_discreto = np.arange(0, T, 1 / Fs)  # Instantes de muestreo\n\n# Generar señales en tiempo continuo\nx_continuo1 = np.cos(2 * np.pi * F1 * t_continuo)\nx_continuo2 = np.cos(2 * np.pi * F2 * t_continuo)\n\n# Generar señales muestreadas\nx_discreto1 = np.cos(2 * np.pi * F1 * n_discreto)\nx_discreto2 = np.cos(2 * np.pi * F2 * n_discreto)\n\n# Crear figura con ejes alineados\nfig, axs = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n\n# Graficar señales continuas\naxs[0].plot(t_continuo, x_continuo1, label=f\"Frequency {F1} Hz\", linestyle=\"dashed\")\naxs[0].plot(t_continuo, x_continuo2, label=f\"Frequency {F2} Hz\", linestyle=\"dotted\")\naxs[0].set_title(\"Continous-Time Signals\")\naxs[0].set_ylabel(\"Amplitude\")\naxs[0].legend()\naxs[0].grid()\n\n# Graficar señales muestreadas con puntos diferenciados\naxs[1].stem(\n    n_discreto,\n    x_discreto1,\n    linefmt=\"k-\",\n    markerfmt=\"ko\",\n    basefmt=\"g-\",\n    label=f\"Samples {F1} Hz\",\n)\n\n# Añadir puntos sin relleno para diferenciar la segunda señal\naxs[1].scatter(\n    n_discreto,\n    x_discreto2,\n    facecolors=\"none\",\n    edgecolors=\"r\",\n    s=80,\n    label=f\"Samples {F2} Hz\",\n)\n\naxs[1].set_title(\"Discrete Signals (Sampled)\")\naxs[1].set_xlabel(\"Time(s)\")\naxs[1].set_ylabel(\"Amplitude\")\naxs[1].legend()\naxs[1].grid()\n\nplt.tight_layout()\nplt.show()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros\nFs = 10  # Frecuencia de muestreo (Hz)\nF1 = 3  # Frecuencia de la primera señal (Hz)\nF2 = F1 + Fs  # Frecuencia de la segunda señal (F1 + Fs) - Produce aliasing\n\nT = 1  # Duración en segundos\nt_continuo = np.linspace(0, T, 1000)  # Tiempo continuo para la señal original\nn_discreto = np.arange(0, T, 1 / Fs)  # Instantes de muestreo\n\n# Generar señales en tiempo continuo\nx_continuo1 = np.cos(2 * np.pi * F1 * t_continuo)\nx_continuo2 = np.cos(2 * np.pi * F2 * t_continuo)\n\n# Generar señales muestreadas\nx_discreto1 = np.cos(2 * np.pi * F1 * n_discreto)\nx_discreto2 = np.cos(2 * np.pi * F2 * n_discreto)\n\nplt.figure(figsize=(10, 6))\nplt.plot(t_continuo, x_continuo1, label=f\"Frecuencia {F1} Hz\", linestyle=\"dashed\", color=\"brown\")\nplt.plot(t_continuo, x_continuo2, label=f\"Frecuencia {F2} Hz\", linestyle=\"dotted\", color=\"black\")\nplt.scatter(\n    n_discreto,\n    x_discreto1,\n    facecolors='none',\n    edgecolors='red',\n    s=100,\n    label=f\"Muestras {F1} Hz\",\n)\nplt.scatter(\n    n_discreto,\n    x_discreto2,\n    facecolors=\"blue\",\n    edgecolors=\"blue\",\n    label=f\"Muestras {F2} Hz\",\n)\n\nplt.title(\"Discrete Signals (Sampled)\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\n\nplt.legend()\nplt.grid()\nplt.show()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import freqz, butter, cheby1, firwin\n\n\ndef plot_filter_response(b, a=1, fs=1.0):\n    \"\"\"Grafica la respuesta en frecuencia de un filtro dado.\"\"\"\n    w, h = freqz(b, a, worN=2048, fs=fs)  # Calcula la respuesta en frecuencia\n\n    # Magnitud de la respuesta en frecuencia\n    plt.figure(figsize=(10, 6))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(w, 20 * np.log10(abs(h)), \"b\")\n    plt.title(\"Respuesta en Frecuencia del Filtro\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Magnitud [dB]\")\n    plt.grid()\n\n    # Fase de la respuesta en frecuencia\n    plt.subplot(2, 1, 2)\n    plt.plot(w, np.angle(h), \"g\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Fase [radianes]\")\n    plt.grid()\n\n    plt.tight_layout()\n    plt.show()\n\n\n# Parámetros del filtro\nfs = 1000  # Frecuencia de muestreo en Hz\ncutoff = 200  # Frecuencia de corte en Hz\norder = 4  # Orden del filtro\n\n# Filtro IIR Butterworth\nb_iir, a_iir = butter(order, cutoff, fs=fs, btype=\"low\", analog=False)\nprint(\"Filtro IIR Butterworth\")\nplot_filter_response(b_iir, a_iir, fs=fs)\n\n# Filtro FIR (ventana de Hamming)\nnumtaps = 51  # Número de coeficientes del FIR\nb_fir = firwin(numtaps, cutoff, fs=fs, window=\"hamming\")\nprint(\"Filtro FIR (Ventana de Hamming)\")\nplot_filter_response(b_fir, fs=fs)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Función para generar la respuesta ideal en el dominio del tiempo\ndef ideal_impulse_response(filter_type, fc1, fc2=None, fs=1.0, N=51):\n    \"\"\"\n    Calcula la respuesta al impulso ideal de un filtro FIR.\n\n    Parámetros:\n    - filter_type: Tipo de filtro ('lowpass', 'highpass', 'bandpass', 'bandstop')\n    - fc1: Frecuencia de corte (Hz) para LPF y HPF, Frecuencia baja para BPF y BSF\n    - fc2: Frecuencia alta (Hz) para BPF y BSF (no usada en LPF y HPF)\n    - fs: Frecuencia de muestreo (Hz)\n    - N: Tamaño del filtro (debe ser impar para centrado en cero)\n\n    Retorna:\n    - h: Respuesta al impulso en el dominio del tiempo\n    - n: Índices del tiempo\n    \"\"\"\n    n = np.arange(-(N // 2), (N // 2) + 1)  # Centrado en n=0\n\n    # Filtro Pasa-Bajas (LPF)\n    if filter_type == \"lowpass\":\n        h = np.sinc(2 * fc1 * n / fs)\n\n    # Filtro Pasa-Altas (HPF)\n    elif filter_type == \"highpass\":\n        h = np.sinc(n) - np.sinc(2 * fc1 * n / fs)\n\n    # Filtro Pasa-Banda (BPF)\n    elif filter_type == \"bandpass\":\n        if fc2 is None:\n            raise ValueError(\"Se necesita fc2 para un filtro pasa-banda\")\n        h = np.sinc(2 * fc2 * n / fs) - np.sinc(2 * fc1 * n / fs)\n\n    # Filtro Rechaza-Banda (BSF)\n    elif filter_type == \"bandstop\":\n        if fc2 is None:\n            raise ValueError(\"Se necesita fc2 para un filtro rechaza-banda\")\n        h = np.sinc(n) - (np.sinc(2 * fc2 * n / fs) - np.sinc(2 * fc1 * n / fs))\n\n    else:\n        raise ValueError(\"Tipo de filtro no válido\")\n\n    return h, n\n\n\n# Parámetros\nfs = 1000  # Frecuencia de muestreo (Hz)\nfc1 = 100  # Frecuencia de corte (Hz) para LPF y HPF\nfc2 = 300  # Frecuencia de corte superior para BPF y BSF\nN = 51  # Orden del filtro (impar para centrado en 0)\n\n# Calcular respuestas al impulso\nfilters = [\"lowpass\", \"highpass\", \"bandpass\", \"bandstop\"]\nresponses = {f: ideal_impulse_response(f, fc1, fc2, fs, N) for f in filters}\n\n# Graficar respuestas\nfig, axs = plt.subplots(2, 2, figsize=(12, 8))\n\nfor ax, (key, (h, n)) in zip(axs.flatten(), responses.items()):\n    ax.stem(n, h)\n    ax.set_title(f\"{key.upper()} Ideal\")\n    ax.set_xlabel(\"n (muestras)\")\n    ax.set_ylabel(\"h[n]\")\n    ax.grid()\n\nplt.tight_layout()\nplt.show()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import chirp\n\n# Generate a synthetic ECG-like signal (chirp function as approximation)\nfs_original = 10000  # High sampling rate (Hz) - \"continuous\" signal\nt = np.linspace(0, 1, fs_original, endpoint=False)  # 1-second signal\nsignal = np.sin(2 * np.pi * 1.7 * (t**2))  # Simulated chirp (similar to ECG waves)\n\n# Downsample (Sampling Process)\nfs_sampled = 200  # Sampling frequency in Hz (e.g., ECG sampled at 200 Hz)\nt_sampled = np.arange(0, 1, 1 / fs_sampled)\nsignal_sampled = np.sin(2 * np.pi * 1.7 * (t_sampled**2))\n\n\n# Quantization (8-bit and 4-bit)\ndef quantize(signal, bits):\n    levels = 2**bits\n    min_val, max_val = signal.min(), signal.max()\n    step = (max_val - min_val) / levels\n    quantized_signal = np.round((signal - min_val) / step) * step + min_val\n    return quantized_signal\n\n\nsignal_quantized_8bit = quantize(signal_sampled, 8)\nsignal_quantized_4bit = quantize(signal_sampled, 4)\n\n# Plot Results\nplt.figure(figsize=(12, 6))\n\n# Original vs Sampled Signal\nplt.subplot(2, 1, 1)\nplt.plot(t, signal, \"k\", alpha=0.3, label=\"Original Signal (High Resolution)\")\nplt.plot(t_sampled, signal_sampled, \"ro-\", label=f\"Sampled Signal ({fs_sampled} Hz)\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Sampling Process\")\n\n# Quantized Signals\nplt.subplot(2, 1, 2)\nplt.plot(t_sampled, signal_quantized_4bit, \"ro-\", alpha=0.5, label=\"Quantized 4-bit\")\nplt.plot(t_sampled, signal_quantized_8bit, \"go-\", alpha=0.5, label=\"Quantized 8-bit\")\nplt.plot(t_sampled, signal_sampled, \"b-\", alpha=0.5, label=\"Original Sampled\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Quantization Effect\")\n\nplt.tight_layout()\nplt.show()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import resample, butter, filtfilt\n\n# --- Parámetros de la Señal ---\nfs_original = 20  # Frecuencia de muestreo baja (Hz)\nt_original = np.linspace(0, 1, fs_original, endpoint=False)  # 1 segundo de duración\nfreq_signal = 3  # Frecuencia de la señal en Hz\nsignal_original = np.sin(2 * np.pi * freq_signal * t_original)  # Señal senoidal\n\n# --- Añadir Ruido ---\nnoise_amplitude = 0.5\nnoise = noise_amplitude * np.random.randn(len(t_original))  # Ruido gaussiano\nsignal_noisy = signal_original + noise  # Señal con ruido\n\n# --- Aplicar Sobremuestreo ---\noversampling_factor = 5  # Aumentamos la frecuencia de muestreo 5 veces\nfs_oversampled = fs_original * oversampling_factor  # Nueva frecuencia de muestreo\nt_oversampled = np.linspace(0, 1, fs_oversampled, endpoint=False)  # Nuevo eje de tiempo\nsignal_oversampled = np.interp(\n    t_oversampled, t_original, signal_noisy\n)  # Interpolación lineal\n\n\n# --- Filtrado de Ruido después del Sobremuestreo ---\ndef butter_lowpass_filter(data, cutoff, fs, order=4):\n    nyquist = 0.5 * fs  # Frecuencia de Nyquist\n    normal_cutoff = cutoff / nyquist  # Normalización\n    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n    filtered_data = filtfilt(b, a, data)  # Filtrado sin desfase\n    return filtered_data\n\n\ncutoff_freq = (\n    freq_signal * 1.5\n)  # Frecuencia de corte del filtro (ligeramente mayor a la señal)\nsignal_filtered = butter_lowpass_filter(signal_oversampled, cutoff_freq, fs_oversampled)\n\n# --- Visualización ---\nplt.figure(figsize=(12, 6))\n\n# Señal original con ruido\nplt.subplot(3, 1, 1)\nplt.plot(t_original, signal_noisy, \"bo-\", label=\"Señal con ruido (Baja Fs)\")\nplt.xlabel(\"Tiempo (s)\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.title(\"Señal Original con Ruido\")\n\n# Señal sobremuestreada con ruido\nplt.subplot(3, 1, 2)\nplt.plot(\n    t_oversampled,\n    signal_oversampled,\n    \"r-\",\n    alpha=0.7,\n    label=f\"Sobremuestreada ({fs_oversampled} Hz)\",\n)\nplt.xlabel(\"Tiempo (s)\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.title(\"Señal Sobremuestreada con Ruido\")\n\n# Señal sobremuestreada y filtrada\nplt.subplot(3, 1, 3)\nplt.plot(\n    t_oversampled, signal_filtered, \"g-\", label=\"Señal Filtrada (Reducción de Ruido)\"\n)\nplt.xlabel(\"Tiempo (s)\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.title(\"Señal Filtrada después del Sobremuestreo\")\n\nplt.tight_layout()\nplt.show()\n\n\nimport random\nlista = [\n    \"a\",\n    \"b\",\n    \"c\",\n    \"d\",\n    \"e\",\n    \"f\",\n    \"g\",\n    \"h\",\n    \"i\"\n]\nrandom.shuffle(lista)\nprint(lista)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros de la simulación\nfs = 1000  # Frecuencia de muestreo (Hz)\nT = 2  # Duración total de la simulación (s)\nt = np.linspace(0, T, T * fs)  # Vector de tiempo\nf_emg = 50  # Frecuencia típica de la señal EMG\n\n# Función de activación para simular el ciclo de marcha (aproximado)\ndef activation_pattern(t, phase_shift=0):\n    \"\"\"Función que simula la activación del músculo durante el ciclo de marcha.\"\"\"\n    return np.abs(np.sin(2 * np.pi * 1 * t + phase_shift))  # 1 Hz ciclo de marcha\n\n# Señales de EMG simuladas\nnp.random.seed(42)\nemg_agonista = activation_pattern(t) * (np.sin(2 * np.pi * f_emg * t) + 0.3 * np.random.randn(len(t)))\nemg_antagonista = activation_pattern(t, phase_shift=np.pi) * (np.sin(2 * np.pi * f_emg * t) + 0.3 * np.random.randn(len(t)))\n\n# Graficar la señal EMG simulada\nplt.figure(figsize=(10, 5))\nplt.plot(t, emg_agonista, label=\"Músculo Agonista (Cuádriceps)\", color='b')\nplt.plot(t, emg_antagonista, label=\"Músculo Antagonista (Isquiotibiales)\", color='r', alpha=0.7)\nplt.xlabel(\"Tiempo (s)\")\nplt.ylabel(\"Amplitud EMG (mV)\")\nplt.title(\"Simulación de señal EMG durante la marcha\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Aplicar FFT a las señales\nN = len(t)  # Número de puntos en la FFT\nfrequencies = np.fft.fftfreq(N, d=1 / fs)  # Vector de frecuencias\nfft_agonista = np.fft.fft(emg_agonista)\nfft_antagonista = np.fft.fft(emg_antagonista)\n\n# Magnitud y fase de la FFT (solo tomamos la parte positiva)\npos_mask = frequencies &gt;= 0\nfreqs_pos = frequencies[pos_mask]\nmag_agonista = np.abs(fft_agonista[pos_mask])\nphase_agonista = np.angle(fft_agonista[pos_mask])\nmag_antagonista = np.abs(fft_antagonista[pos_mask])\nphase_antagonista = np.angle(fft_antagonista[pos_mask])\n\n# Graficar el espectro de magnitud\nplt.figure(figsize=(12, 5))\n\nplt.subplot(2, 1, 1)\nplt.plot(freqs_pos, mag_agonista, label=\"EMG Agonista\", color=\"b\")\nplt.plot(\n    freqs_pos, mag_antagonista, label=\"EMG Antagonista\", color=\"r\", linestyle=\"dashed\"\n)\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.title(\"Espectro de Magnitud de la Señal EMG\")\nplt.legend()\nplt.grid()\n\n# Graficar el espectro de fase\nplt.subplot(2, 1, 2)\nplt.plot(freqs_pos, phase_agonista, label=\"Fase EMG Agonista\", color=\"b\")\nplt.plot(\n    freqs_pos,\n    phase_antagonista,\n    label=\"Fase EMG Antagonista\",\n    color=\"r\",\n    linestyle=\"dashed\",\n)\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Fase (radianes)\")\nplt.title(\"Espectro de Fase de la Señal EMG\")\nplt.legend()\nplt.grid()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nmag_agonista.max()\n\nnp.float64(623.9382421708299)\n\n\n\nfrom scipy.signal import butter, filtfilt, firwin, lfilter\n\n# Frecuencia de corte\nfc = 100  # Hz\n\n# Diseño del filtro IIR Butterworth de orden 6\norder_iir = 6\nb_iir, a_iir = butter(order_iir, fc / (fs / 2), btype=\"low\", analog=False)\n\n# Diseño del filtro FIR con 81 coeficientes (taps)\nnum_taps = 81\nfir_coeff = firwin(num_taps, fc / (fs / 2), window=\"hamming\")\n\n# Filtrado de la señal EMG\nemg_agonista_iir = filtfilt(b_iir, a_iir, emg_agonista)\nemg_antagonista_iir = filtfilt(b_iir, a_iir, emg_antagonista)\n\nemg_agonista_fir = lfilter(fir_coeff, 1.0, emg_agonista)\nemg_antagonista_fir = lfilter(fir_coeff, 1.0, emg_antagonista)\n\n# Graficar las señales filtradas\nplt.figure(figsize=(12, 6))\n\nplt.subplot(2, 1, 1)\nplt.plot(t, emg_agonista, label=\"Original Agonista\", color=\"gray\", alpha=0.5)\nplt.plot(t, emg_agonista_iir, label=\"Filtrado IIR\", color=\"b\")\nplt.plot(t, emg_agonista_fir, label=\"Filtrado FIR\", color=\"r\", linestyle=\"dashed\")\nplt.xlabel(\"Tiempo (s)\")\nplt.ylabel(\"Amplitud EMG\")\nplt.title(\"Filtrado de EMG Agonista - IIR vs FIR\")\nplt.legend()\nplt.grid()\n\nplt.subplot(2, 1, 2)\nplt.plot(t, emg_antagonista, label=\"Original Antagonista\", color=\"gray\", alpha=0.5)\nplt.plot(t, emg_antagonista_iir, label=\"Filtrado IIR\", color=\"b\")\nplt.plot(t, emg_antagonista_fir, label=\"Filtrado FIR\", color=\"r\", linestyle=\"dashed\")\nplt.xlabel(\"Tiempo (s)\")\nplt.ylabel(\"Amplitud EMG\")\nplt.title(\"Filtrado de EMG Antagonista - IIR vs FIR\")\nplt.legend()\nplt.grid()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.signal import freqz\n\n# Obtener la respuesta en frecuencia de ambos filtros\nw_iir, h_iir = freqz(b_iir, a_iir, worN=1024, fs=fs)\nw_fir, h_fir = freqz(fir_coeff, 1, worN=1024, fs=fs)\n\n# Graficar la respuesta en magnitud con las especificaciones solicitadas\nplt.figure(figsize=(10, 5))\n\n# Filtro IIR\nplt.plot(w_iir, 20 * np.log10(abs(h_iir)), label=\"Filtro IIR Butterworth (Orden 6)\", \n         color='black', linewidth=3)\n\n# Filtro FIR\nplt.plot(w_fir, 20 * np.log10(abs(h_fir)), label=\"Filtro FIR (81 taps, Hamming)\", \n         color='black', linestyle='dashed', linewidth=1)\n\n\n# Configuración de etiquetas y título\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud (dB)\")\nplt.title(\"Comparación de la Respuesta en Magnitud de los Filtros IIR y FIR\")\nplt.legend()\nplt.grid()\n\n# Mostrar la gráfica\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\n# Define the input signal x[n] (example waveform)\nx = np.array([0, 1, 2, 3, 2, 1, 0])\nn_x = np.arange(len(x))\n\n# Define the impulse response h[n] (example filter)\nh = np.array([0.2, 0.5, 0.2])\nn_h = np.arange(len(h))\n\n# Compute the full convolution result\ny = np.convolve(x, h, mode=\"full\")\nn_y = np.arange(len(y))\n\n# Create the figure and axis\nfig, ax = plt.subplots(figsize=(6, 4))\n\nax.set_xlim(-1, len(y))\nax.set_ylim(-0.5, max(y) + 1)\nax.set_xlabel(\"n (Time Index)\")\nax.set_ylabel(\"Amplitude\")\nax.set_title(\"Convolution Process Animation\")\nax.grid(True)\n\n# Initialize the plot elements\n(line_x,) = ax.plot([], [], \"bo-\", label=\"Input Signal x[n]\")\n(line_h,) = ax.plot([], [], \"go-\", label=\"Impulse Response h[n]\")\n(line_y,) = ax.plot([], [], \"mo-\", label=\"Output Signal y[n]\")\n\nax.legend()\n\n\n# Animation function\ndef update(frame):\n    if frame &lt; len(x):\n        line_x.set_data(n_x[: frame + 1], x[: frame + 1])\n    if frame &lt; len(h):\n        line_h.set_data(n_h[: frame + 1], h[: frame + 1])\n    if frame &lt; len(y):\n        line_y.set_data(n_y[: frame + 1], y[: frame + 1])\n    return line_x, line_h, line_y\n\n\n# Create animation\nani = animation.FuncAnimation(fig, update, frames=len(y), interval=500, blit=True)\n\n# Save animation as GIF\ngif_path = \"./convolution_animation.gif\"\nani.save(gif_path, writer=\"pillow\", fps=2)\n\n# Return the file path\ngif_path\n\n'./convolution_animation.gif'\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define signal parameters\nfs = 10  # Sampling frequency in Hz\nT = 1  # Signal duration in seconds\nn = np.arange(0, T, 1 / fs)  # Discrete time vector\nx = np.random.randint(n)  # Discrete signal of ones\n\n# Plot the discrete signal\nplt.figure(figsize=(8, 4))\nplt.stem(n, x, linefmt=\"b-\", markerfmt=\"bo\", basefmt=\"r-\", label=\"Discrete Signal\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Discrete Signal (1s duration, 10 Hz Sampling Frequency)\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[6], line 8\n      6 T = 1  # Signal duration in seconds\n      7 n = np.arange(0, T, 1 / fs)  # Discrete time vector\n----&gt; 8 x = np.random.randint(n)  # Discrete signal of ones\n     10 # Plot the discrete signal\n     11 plt.figure(figsize=(8, 4))\n\nFile numpy/random/mtrand.pyx:798, in numpy.random.mtrand.RandomState.randint()\n\nFile numpy/random/_bounded_integers.pyx:1349, in numpy.random._bounded_integers._rand_int64()\n\nFile numpy/random/_bounded_integers.pyx:776, in numpy.random._bounded_integers._rand_int64_broadcast()\n\nValueError: high &lt;= 0\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Define the data path\ndata_path = \"../data/\"  # Change this to the correct path if needed\ndata = pd.read_csv(data_path + \"diabetes.csv\")\n\n# Identify variable types\ndiscrete_vars = [\"Pregnancies\"]  # Discrete numerical variable\ncategorical_vars = [\"Outcome\"]  # Class label\ncontinuous_vars = [\n    col\n    for col in data.select_dtypes(include=[np.number]).columns\n    if col not in discrete_vars + [\"Outcome\"]\n]\n\n# Basic dataset information\nprint(\"Dataset Information:\\n\", data.info())\nprint(\"\\nSummary Statistics:\\n\", data.describe())\nprint(\"\\nMissing Values:\\n\", data.isnull().sum())\n\n# Ensure numeric data and handle NaN or infinite values\nnumeric_data = data.select_dtypes(include=[np.number]).dropna()\nnumeric_data = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n\n# Dynamically determine the number of rows for subplots\nnum_cont_vars = len(continuous_vars)\nrows = (num_cont_vars // 3) + (num_cont_vars % 3 &gt; 0)  # Ensures proper grid layout\n\n# Plot distributions for continuous variables\nplt.figure(figsize=(12, 4 * rows))\nfor i, column in enumerate(continuous_vars, 1):\n    plt.subplot(rows, 3, i)\n    sns.histplot(numeric_data[column], kde=True, bins=20, color=\"skyblue\")\n    plt.title(f\"Distribution of {column}\")\nplt.tight_layout()\nplt.show()\n\n# Plot distribution for discrete variable (Pregnancies) using a countplot\nplt.figure(figsize=(8, 4))\nsns.countplot(x=\"Pregnancies\", data=numeric_data, palette=\"viridis\")\nplt.title(\"Count of Pregnancies\")\nplt.show()\n\n# Plot class distribution for Outcome\nplt.figure(figsize=(6, 4))\nsns.countplot(x=\"Outcome\", data=data, palette=\"coolwarm\")\nplt.title(\"Class Distribution of Outcome\")\nplt.xlabel(\"Diabetes Diagnosis (0: No, 1: Yes)\")\nplt.ylabel(\"Count\")\nplt.show()\n\n# Correlation heatmap to check relationships\nplt.figure(figsize=(10, 6))\nsns.heatmap(numeric_data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   768 non-null    int64  \n 2   BloodPressure             768 non-null    int64  \n 3   SkinThickness             768 non-null    int64  \n 4   Insulin                   768 non-null    int64  \n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\nDataset Information:\n None\n\nSummary Statistics:\n        Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  120.894531      69.105469      20.536458   79.799479   \nstd       3.369578   31.972618      19.355807      15.952218  115.244002   \nmin       0.000000    0.000000       0.000000       0.000000    0.000000   \n25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n75%       6.000000  140.250000      80.000000      32.000000  127.250000   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  768.000000                768.000000  768.000000  768.000000  \nmean    31.992578                  0.471876   33.240885    0.348958  \nstd      7.884160                  0.331329   11.760232    0.476951  \nmin      0.000000                  0.078000   21.000000    0.000000  \n25%     27.300000                  0.243750   24.000000    0.000000  \n50%     32.000000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  \n\nMissing Values:\n Pregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n\n\n\n\n\n\n\n\n\n/tmp/ipykernel_94704/900495043.py:43: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.countplot(x=\"Pregnancies\", data=numeric_data, palette=\"viridis\")\n\n\n\n\n\n\n\n\n\n/tmp/ipykernel_94704/900495043.py:49: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.countplot(x=\"Outcome\", data=data, palette=\"coolwarm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define two orthogonal vectors\nv1 = np.array([1, 0])  # X-axis unit vector\nv2 = np.array([0, 1])  # Y-axis unit vector\n\n# Define a third vector\nv3 = np.array([2, 3])  # Arbitrary vector\n\n# Compute projections of v3 onto v1 and v2\nproj_v1 = (np.dot(v3, v1) / np.dot(v1, v1)) * v1\nproj_v2 = (np.dot(v3, v2) / np.dot(v2, v2)) * v2\n\n# Create a figure\nfig, ax = plt.subplots(figsize=(6, 6))\n\n# Plot the orthogonal vectors\nax.quiver(\n    0, 0, *v1, color=\"r\", angles=\"xy\", scale_units=\"xy\", scale=1, label=\"v1 (X-axis)\"\n)\nax.quiver(\n    0, 0, *v2, color=\"g\", angles=\"xy\", scale_units=\"xy\", scale=1, label=\"v2 (Y-axis)\"\n)\n\n# Plot the third vector\nax.quiver(0, 0, *v3, color=\"b\", angles=\"xy\", scale_units=\"xy\", scale=1, label=\"v3\")\n\n# Plot projections using quiver\nax.quiver(\n    0,\n    0,\n    *proj_v1,\n    color=\"purple\",\n    angles=\"xy\",\n    scale_units=\"xy\",\n    scale=1,\n    label=\"Projection on v1\"\n)\nax.quiver(\n    0,\n    0,\n    *proj_v2,\n    color=\"orange\",\n    angles=\"xy\",\n    scale_units=\"xy\",\n    scale=1,\n    label=\"Projection on v2\"\n)\n\n# Plot dashed lines to show projection points\nax.plot([proj_v1[0], v3[0]], [proj_v1[1], v3[1]], \"k--\", alpha=0.5)  # Projection to v1\nax.plot([proj_v2[0], v3[0]], [proj_v2[1], v3[1]], \"k--\", alpha=0.5)  # Projection to v2\n\n# Set grid and limits\nax.set_xlim(-1, 4)\nax.set_ylim(-1, 4)\nax.set_xlabel(\"X-axis\")\nax.set_ylabel(\"Y-axis\")\nax.set_title(\"Two Orthogonal Vectors & Projection of a Third Vector\")\nax.axhline(0, color=\"black\", linewidth=1)\nax.axvline(0, color=\"black\", linewidth=1)\nax.grid()\nax.legend()\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "codigo/SYSB/remuestreo.html",
    "href": "codigo/SYSB/remuestreo.html",
    "title": "Parámetros Iniciales de la señal",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\\[x\\left(t\\right) = 10\\sin\\left(2\\pi3t\\right)\\]\n\\[t\\in\\left[0, 5\\right]\\]\n\\[f_{s_1} = 20Hz\\]\n\\[f_{s_2} = 100Hz\\]\nt0 = 0\ntf = 1"
  },
  {
    "objectID": "codigo/SYSB/remuestreo.html#gráficas-iniciales",
    "href": "codigo/SYSB/remuestreo.html#gráficas-iniciales",
    "title": "Parámetros Iniciales de la señal",
    "section": "Gráficas iniciales",
    "text": "Gráficas iniciales\n\nt_graph = np.linspace(t0, tf, 1000)\nx = 10*np.sin(2*np.pi*3*t_graph)\nplt.figure(figsize=(10,6))\nplt.plot(t_graph, x)\n\n\n\n\n\n\n\n\n\nfs1 = 20\nt_1 = np.linspace(t0, tf, fs1*(tf-t0), endpoint=False)\nx_1 = 10 * np.sin(2 * np.pi * 3 * t_1)\nplt.figure(figsize=(10, 6))\nplt.plot(t_graph, x)\nplt.plot(t_1, x_1, 'r*')\nplt.grid()\n\n\n\n\n\n\n\n\n\nt_oversample = [t0]\nx_1_over = [x_1[0]]\n\ndelta_t1 = np.mean(np.diff(t_1))\n\nt_oversample = np.empty(len(t_1)+len(t_1))\nt_oversample[0::2] = t_1\nt_oversample[1::2] = t_1 + (delta_t1/2)\n\nx_1_over = np.empty(len(t_1) + len(t_1))\nx_1_over[0::2] = x_1\nx_1_over[1::2] = (x_1+np.roll(x_1,-1))/2\n\nplt.figure(figsize=(10, 6))\nplt.plot(t_graph, x, \"k\")\nplt.plot(t_oversample, x_1_over, \"g*\")\nplt.plot(t_1, x_1, \"r*\")\nplt.grid()\n\n\n\n\n\n\n\n\n\n4//2\n\n2\n\n\n\n4%3\n\n1"
  },
  {
    "objectID": "codigo/PSIM/cod003_FourierImage.html",
    "href": "codigo/PSIM/cod003_FourierImage.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Step 1: Load the Ultrasound Image\nimage = cv2.imread(\n    \"../../data/malignant_breast_cancer.png\", \n    cv2.IMREAD_GRAYSCALE\n)\n\n\nsharpening_kernel1 = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\nsharpening_kernel2 = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n\nsharpened_image1 = cv2.filter2D(image, -1, sharpening_kernel1)\nsharpened_image2 = cv2.filter2D(image, -1, sharpening_kernel2)\n\n\n# Step 4: Display the Original and Sharpened Images Side-by-Side\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 3, 1)\nplt.title(\"Original Ultrasound Image\")\nplt.imshow(image, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 2)\nplt.title(\"Sharpened Ultrasound Image Kernel1\")\nplt.imshow(sharpened_image1, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 3)\nplt.title(\"Sharpened Ultrasound Image Kernel2\")\nplt.imshow(sharpened_image2, cmap=\"gray\")\nplt.axis(\"off\")\n\n\n\n\n\n\n\n\n\ndft1 = cv2.dft(np.float32(image), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift1 = np.fft.fftshift(dft1)\nmagnitude_spectrum1 = 20 * np.log(cv2.magnitude(dft_shift1[:, :, 0], dft_shift1[:, :, 1]))\n\ndft2 = cv2.dft(np.float32(sharpened_image1), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift2 = np.fft.fftshift(dft2)\nmagnitude_spectrum2 = 20 * np.log(\n    cv2.magnitude(dft_shift2[:, :, 0], dft_shift2[:, :, 1])\n)\n\ndft3 = cv2.dft(np.float32(sharpened_image2), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift3 = np.fft.fftshift(dft3)\nmagnitude_spectrum3 = 20 * np.log(\n    cv2.magnitude(dft_shift3[:, :, 0], dft_shift3[:, :, 1])\n)\n\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(3, 1, 1)\nplt.title(\"Magnitude Spectrum of initial image in log scale\")\nplt.imshow(magnitude_spectrum1, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(3, 1, 2)\nplt.title(\"Magnitude Spectrum of the first sharpended image in log scale\")\nplt.imshow(magnitude_spectrum2, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(3, 1, 3)\nplt.title(\"Magnitude Spectrum of the second sharpended image in log scale\")\nplt.imshow(magnitude_spectrum3, cmap=\"gray\")\nplt.axis(\"off\")\n\n\n\n\n\n\n\n\n\nrows, cols = image.shape\ncrow, ccol = rows // 2, cols // 2  # Coordenadas del centro\n\n# Crear una máscara pasa-altas\n# Empezamos con una matriz de unos\nmask = np.ones((rows, cols, 2), np.uint8)\n\n# Crear una región cuadrada en el centro de la máscara que representa las bajas frecuencias\nr = 10  # Radio de la región de bajas frecuencias que queremos eliminar\nmask[crow - r : crow + r, ccol - r : ccol + r] = (\n    0  # Zona central donde eliminamos las bajas frecuencias\n)\n\nplt.imshow(mask[:,:,1])\n\n\n\n\n\n\n\n\n\n# Aplicar la máscara pasa-altas al espectro DFT\nfshift = dft_shift1 * mask\n\n# Desplazar de vuelta las frecuencias (inverso de fftshift)\nf_ishift = np.fft.ifftshift(fshift)\n\n# Aplicar la transformada inversa de Fourier (IDFT)\nimg_back = cv2.idft(f_ishift)\n\n# Calcular la magnitud para obtener la imagen final filtrada\nimg_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n\n# Mostrar las imágenes original y filtrada\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.imshow(image, cmap=\"gray\")\nplt.title(\"Imagen Original\")\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(img_back, cmap=\"gray\")\nplt.title(\"Imagen Filtrada (Pasa-Altas)\")\nplt.axis(\"off\")\n\nplt.show()"
  },
  {
    "objectID": "codigo/PSIM/cod004_wavelet_explain.html",
    "href": "codigo/PSIM/cod004_wavelet_explain.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nFs = 100\nt = np.arange(0,8, 1/Fs)\nx1 = np.exp(-t)\nx1[np.uint(2/0.01)]=0.8\nplt.plot(t,x1)\nplt.show()\n\n\n\n\n\n\n\n\n\ndef EspectroMagnitudFourier(t, x):\n    N = len(t)\n    Fs = 1/np.mean(np.diff(t))\n    x_fft = np.fft.fftshift(np.fft.fft(x))\n    f = np.fft.fftshift(np.fft.fftfreq(N, 1/Fs))\n    plt.plot(f, np.abs(x_fft))\n\n\nEspectroMagnitudFourier(t,x1)\n\n\n\n\n\n\n\n\n\nfrom scipy.signal import chirp\n\n\nx2 = np.sin(2*np.pi*2*t)+np.sin(2*np.pi*5*t)+np.sin(2*np.pi*10*t)\nEspectroMagnitudFourier(t,x2)\n\n\n\n\n\n\n\n\n\nx3 = np.zeros(t.shape)\nt1 = np.uint(3/0.01)\nt2 = np.uint(5/0.01)\nx3[0:t1] = np.sin(2*np.pi*2*t[0:t1])\n\nx3[t1:t2] = np.sin(2*np.pi*5*t[t1:t2])\nx3[t2:] = np.sin(2*np.pi*10*t[t2:])\nplt.plot(t,x3)\nplt.show()\n\n\n\nEspectroMagnitudFourier(t,x3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport scaleogram as scg  # Assuming you have `scaleogram` installed.\nimport pywt\n\n\n# Define the scales (`scales`)\nnum_points = x3.shape[0]\nmax_scale2 = 50  # You can adjust this based on your requirements\nscales = np.arange(1, max_scale2 + 1)  # Proper definition of scales\n\n# Define the wavelet to be used for the CWT\nwavelet_name = \"cmor0.5-1.0\"  \n\n# Compute the Continuous Wavelet Transform (CWT)\ncoef, freqs = pywt.cwt(x3, scales, wavelet=wavelet_name)\n\n# Plot the scalogram\nplt.figure(figsize=(10, 6))\nplt.imshow(\n    np.abs(coef),\n    aspect=\"auto\",\n    extent=[0, num_points, scales[-1], scales[0]],\n    cmap=\"viridis\",\n)\nplt.colorbar(label=\"Magnitude\")\nplt.ylabel(\"Scales\")\nplt.xlabel(\"Time\")\nplt.title(f\"Continuous Wavelet Transform (Scalogram) using {wavelet_name} wavelet\")\nplt.gca().invert_yaxis()  # Invert y-axis to have larger scales at the bottom\nplt.show()\n\n# Plot the mother wavelet function\nwavelet = pywt.ContinuousWavelet(wavelet_name)\n\n# Get the wavelet function (psi) and time points (x)\npsi, x = wavelet.wavefun(level=10)  # Level determines the resolution\n\n# Plotting the wavelet function (psi)\nplt.figure(figsize=(10, 6))\nplt.plot(x, psi, label=f\"{wavelet_name} wavelet\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.title(f\"Wavelet Function: {wavelet_name}\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport pywt\nimport scaleogram as scg\nimport scipy.io as sio\n\nanchos = np.uint(np.arange(1,np.log2(x3.shape[0])))\n\ncoef, freqs = pywt.cwt(x3,anchos,\"gaus1\") \nplt.matshow(coef)\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\ndata = sio.loadmat(\"../../data/JS00001.mat\")\necg001 = data[\"val\"][9, :]\nt = np.linspace(0,10, 5000)\nplt.plot(t,ecg001)\n\n\n\n\n\n\n\n\n\nimport scipy.signal as sig\nt_decimate=sig.decimate(t, 2)\n\n\ncoef_lvl1 = pywt.dwt(ecg001, wavelet=\"db1\")\nplt.plot(t_decimate, coef_lvl1[0]/np.max(coef_lvl1[0]))\nplt.plot(t_decimate, coef_lvl1[1]/np.max(coef_lvl1[1]))\nplt.show()\n\nplt.plot(t_decimate, coef_lvl1[0])\nplt.plot(t, ecg001)\nplt.show()\n\nplt.plot(t_decimate, coef_lvl1[1]/np.max(coef_lvl1[1]))\nplt.plot(t,ecg001/np.max(ecg001))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Descomposición con la Transformada Wavelet Discreta\nwavelet = \"db4\"  # Elegimos la wavelet Daubechies de nivel 4\nmax_level = pywt.dwt_max_level(len(ecg001), wavelet)\ncoeffs = pywt.wavedec(ecg001, wavelet, level=max_level)\n\n\n# Apply soft thresholding to detail coefficients\ncoeffs_thresh = [coeffs[0]]  # Keep approximation coefficients unchanged\ncoeffs_thresh.extend(\n    pywt.threshold(detail, 2000, mode=\"soft\") for detail in coeffs[1:]\n)\n\n\n# Reconstrucción de la señal desde los coeficientes\nreconstructed_signal = pywt.waverec(coeffs_thresh, wavelet)\n\n# Visualización de la señal original, ruidosa y reconstruida\nplt.figure(figsize=(12, 8))\n\n# Señal image\nplt.plot(t, ecg001, label=\"Señal Ruidosa\", color=\"orange\")\nplt.plot(t, reconstructed_signal, label=\"Señal Reconstruida\", color=\"green\")\n\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport cv2\nfrom scipy.signal import convolve2d\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pywt\nimport pywt.data\n\noriginal = cv2.imread(\"../../data/female-chest-x-ray.jpg\", cv2.IMREAD_GRAYSCALE)\n\n\nfrom scipy.signal import convolve2d\n\n# Filtros de paso bajo y paso alto para la wavelet Haar\nlow_pass = np.array([1, 1]) / np.sqrt(2)\nhigh_pass = np.array([1, -1]) / np.sqrt(2)\n\nprint(low_pass[:, None])\n\n# Convolución en las filas\nLL_rows = convolve2d(original, low_pass[:, None], mode=\"same\")  # Paso bajo en filas\nHL_rows = convolve2d(original, high_pass[:, None], mode=\"same\")  # Paso alto en filas\n\n# Convolución en las columnas\nLL_scratch = convolve2d(LL_rows, low_pass[None, :], mode=\"same\")  # Paso bajo en columnas\nLH_scratch = convolve2d(LL_rows, high_pass[None, :], mode=\"same\")  # Paso alto en columnas\nHL_scratch = convolve2d(\n    HL_rows, low_pass[None, :], mode=\"same\"\n)  # Paso bajo en columnas\nHH_scratch = convolve2d(\n    HL_rows, high_pass[None, :], mode=\"same\"\n)  # Paso alto en columnas\n\n# Visualización de las subbandas\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 3, 1)\nplt.title(\"Imagen Original\")\nplt.imshow(original, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 2)\nplt.title(\"Subbanda LL (Low-Low)\")\nplt.imshow(LL_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 3)\nplt.title(\"Subbanda LH (Low-High)\")\nplt.imshow(LH_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 5)\nplt.title(\"Subbanda HL (High-Low)\")\nplt.imshow(HL_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 6)\nplt.title(\"Subbanda HH (High-High)\")\nplt.imshow(HH_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\n[[0.70710678]\n [0.70710678]]\nfloat32\n\n\n\n\n\n\n\n\n\n\nimagen_oscura = np.uint8(cv2.normalize(LL_scratch, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX))\nhistograma = cv2.calcHist([imagen_oscura], [0], None, [256], [0, 256])\nplt.plot(histograma)\n\n\n\n\n\n\n\n\n\n\n# Load image\n#original = pywt.data.camera()\n\n# Wavelet transform of image, and plot approximation and details\ntitles = ['Approximation', ' Horizontal detail',\n          'Vertical detail', 'Diagonal detail']\ncoeffs2 = pywt.dwt2(original, 'haar')\nLL, (LH, HL, HH) = coeffs2\nfig = plt.figure(figsize=(12, 3))\nfor i, a in enumerate([LL, LH, HL, HH]):\n    ax = fig.add_subplot(1, 4, i + 1)\n    ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n    ax.set_title(titles[i], fontsize=10)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfig.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nth1 = 0.7*np.max([LL,HL,LH,HH])\nLL[LL&lt;th1]=0\nHL[HL&lt;th1]=0\nLH[LH&lt;th1]=0\nHH[HH&lt;th1]=0\ncoeffs2_denoise = (LL, (LH, HL, HH))\nimagen_recons=pywt.idwt2(coeffs2_denoise, wavelet=\"haar\")\nplt.imshow(np.hstack((original, imagen_recons)), cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(original-imagen_recons, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#what-is-convolution",
    "href": "presentaciones/ASIM/lect005_CNN.html#what-is-convolution",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "What is Convolution?",
    "text": "What is Convolution?\n\nConvolution: A mathematical operation used to extract features from input data.\nFilter/Kernels:\n\nA small matrix (e.g., 3x3) that slides over the input.\nDetects patterns such as edges, textures, and colors.\n\nStride: Number of pixels by which the filter moves at each step.\nPadding: Adds extra pixels around the border of the input, preserving spatial dimensions."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#convolution-in-action",
    "href": "presentaciones/ASIM/lect005_CNN.html#convolution-in-action",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Convolution in Action",
    "text": "Convolution in Action\n\nInput: A matrix of pixel values (e.g., an image).\nOutput (Feature Map): A matrix where each value represents the result of applying the filter over a region of the input."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#what-are-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#what-are-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "What are CNNs?",
    "text": "What are CNNs?\n\nDefinition: CNNs are deep learning models primarily used for visual recognition tasks.\nKey Concept: CNNs learn and detect hierarchical patterns in image data (e.g., edges, shapes, textures).\nImportance: Automatically extract features, reducing the need for manual feature engineering."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#why-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#why-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Why CNNs?",
    "text": "Why CNNs?\n\nFully Connected Networks struggle with large images due to high dimensionality.\nCNNs reduce the number of parameters by using local connectivity (convolutions) and weight sharing.\nEfficient in Learning: They exploit spatial hierarchies in images."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#cnn-architecture-overview",
    "href": "presentaciones/ASIM/lect005_CNN.html#cnn-architecture-overview",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "CNN Architecture Overview",
    "text": "CNN Architecture Overview\n\nInput Layer: Raw image data (e.g., 28x28 pixels for MNIST).\nConvolutional Layer: Detects features from input images using filters.\nActivation Function: Typically ReLU to introduce non-linearity.\nPooling Layer: Reduces the spatial dimensions (downsampling).\nFully Connected Layer: Performs classification based on extracted features."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#activation-function-relu",
    "href": "presentaciones/ASIM/lect005_CNN.html#activation-function-relu",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Activation Function (ReLU)",
    "text": "Activation Function (ReLU)\n\nPurpose: Introduce non-linearity into the network, allowing CNNs to learn complex patterns.\nReLU Formula: ( f(x) = (0, x) )\nWhy ReLU?:\n\nFaster convergence compared to sigmoid or tanh.\nAvoids the vanishing gradient problem."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#pooling-layers",
    "href": "presentaciones/ASIM/lect005_CNN.html#pooling-layers",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Pooling Layers",
    "text": "Pooling Layers\n\nPurpose: Reduce the spatial dimensions of feature maps, decrease computational load, and control overfitting.\nTypes of Pooling:\n\nMax Pooling: Selects the maximum value within a specified window.\nAverage Pooling: Calculates the average value within a specified window.\n\nBenefits:\n\nRetains the most important features (Max Pooling).\nSmooths the feature maps (Average Pooling).\n\nCommon Parameters:\n\nKernel Size: Size of the window (e.g., 2x2).\nStride: Step size for moving the window."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#fully-connected-layers",
    "href": "presentaciones/ASIM/lect005_CNN.html#fully-connected-layers",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Fully Connected Layers",
    "text": "Fully Connected Layers\n\nFlattening: Converts the 2D feature maps into a 1D vector for input into fully connected layers.\nFully Connected (Dense) Layers: Every neuron in the previous layer is connected to every neuron in the next layer.\nRole: Performs classification based on features learned from convolution and pooling layers."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#training-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#training-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Training CNNs",
    "text": "Training CNNs\n\nLoss Function: Cross-entropy loss is commonly used for classification tasks.\nOptimization: Backpropagation combined with optimizers like stochastic gradient descent (SGD) or Adam.\nTraining Concepts:\n\nEpochs: Number of complete passes over the dataset.\nMini-batches: Small subsets of the dataset used in each iteration."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#challenges",
    "href": "presentaciones/ASIM/lect005_CNN.html#challenges",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Challenges",
    "text": "Challenges\n\nComputational Resources: CNNs require powerful hardware (e.g., GPUs) for training large models.\nLarge Datasets: CNNs often need vast amounts of labeled data to perform well.\nOverfitting: Common problem in CNNs when trained on small datasets. Solutions include:\n\nData augmentation (rotating, flipping, or zooming images).\nDropout layers to randomly drop neurons during training."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#future-of-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#future-of-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Future of CNNs",
    "text": "Future of CNNs\n\nAdvanced Architectures:\n\nResidual Networks (ResNet):\n\nDeeper networks can be trained by using skip connections to bypass layers and avoid the vanishing gradient problem.\n\nInception Networks:\n\nUtilize multiple filters of different sizes in parallel to capture features at different scales.\n\nEfficientNet:\n\nBalances network depth, width, and resolution, creating more efficient models with fewer parameters while maintaining accuracy."
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant “free” sources of data\n\n\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción a inteligencia artificial en el borde (EDGE AI).\nHardware y software para EDGE AI.\nEl flujo de trabajo de EDGE AI.\nDiseño, desarrollo y evaluación de sistemas EDGE AI."
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluación",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nLaboratorios (60%)\nProyecto Final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluación-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (30%)\nLaboratorios (30%)\nProyecto final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201.\n\nInterpretes: R y python.\nOS: Linux\nLenguajes: C/C++\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#bibliografía",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980.\n[42] D. Situnayake y J. Plunkett, AI at the Edge: solving real-world problems with embedded machine learning. Sebastopol: O’Reilly, 2023.\n[43] X. Wang, Y. Han, V. C. M. Leung, D. Niyato, X. Yan, y X. Chen, Edge AI: Convergence of Edge Computing and Artificial Intelligence. Singapore: Springer Singapore, 2020. doi: 10.1007/978-981-15-6186-3.\n[44] A. Koul, S. Ganju, y M. Kasam, «Practical Deep Learning for Cloud, Mobile, and Edge».\n[45] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[46] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[47] V. Subramanian, Deep learning with PyTorch: a practical approach to building neural network models using PyTorch. Birmingham, UK: Packt Publishing, 2018.\n[48] Diagnostic Biomedical Signal and Image Processing Applications with Deep Learning Methods. Elsevier, 2023. doi: 10.1016/C2021-0-02190-8.\n[49] J. D. Kelleher, B. Mac Namee, y A. D’Arcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed. Cambridge: The MIT press, 2020.\n[50] A. A. Patel, «Hands-On Unsupervised Learning Using Python».\n[51] P. Raj, P. B. Soundarabai, y P. Augustine, Machine Intelligence: Computer Vision and Natural Language Processing, 1.ª ed. Boca Raton: Auerbach Publications, 2023. doi: 10.1201/9781003424550.\n[52] M. Roy y L. R. Gupta, Eds., Machine Learning and Data Analytics for Predicting, Managing, and Monitoring Disease: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2021. doi: 10.4018/978-1-7998-7188-0.\n[53] A. R. Jha, Mastering PyTorch: create and deploy deep learning models from CNNs to multimodal models, LLMs, and beyond, Second edition. en Expert insight. Birmingham: Packt Publishing Limited, 2024.\n[54] V. K. Ayyadevara y Y. Reddy, Modern computer vision with PyTorch: a practical roadmap from deep learning fundamentals to advanced applications and Generative AI, Second edition. Birmingham, UK: Packt Publishing Ltd., 2024.\n[55] E. Priya y V. Rajinikanth, Eds., Signal and Image Processing Techniques for the Development of Intelligent Healthcare Systems. Singapore: Springer Singapore, 2021. doi: 10.1007/978-981-15-6141-2.\n[56] M. M. Richter, S. Paul, V. Këpuska, y M. Silaghi, Signal Processing and Machine Learning with Applications. Cham: Springer International Publishing, 2022. doi: 10.1007/978-3-319-45372-9."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Edge AI",
    "text": "Edge AI\n\n\n\n\n\n\n\nDefinition\n\n\nEdge AI Is the combination of EDGE devices and Artificial Intelligence Algorithms\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nThe accelerometer-based wristband sensor."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI\n\nTaken from “Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing” (Zhou et. al., Proceedings of the IEEE, 2019)"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI\n\n\n\n\n\n\n\nEmbedded ML\n\n\n\nEmbedded ML is the art and science of running machine learning models on embedded systems.\nEmbedded ML, we’re usually refers to machine learning inference.\nThe training part usually still takes place on a conventional computer.\nHigh requirements of ROM(Model Storing), RAM(Storing intermediate results), computer capabilities(computational intensive tasks).\nEmbedded machine learning is often deployed alongside digital signal processing algorithms\nTiny machine learning, or TinyML, is the concept of doing this on the most constrained embedded hardware available."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-3",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "BLERP",
    "text": "BLERP\n\n\n\n\n\n\n\n\n\nBandwith\n\n\nIt’s related to the quantity of information you could send via some kind of connection. More bandwith it’s needed to send more data. Example: Imagine a smart sensor that monitors the vibration of an magnetic resonator to determine if it is operating correctly. It might use a simple thresholding algorithm to understand when the machine is vibrating too much, or not enough, and then communicate this information via a low bandwidth radio connection.\n\n\n\n\n\n\n\n\n\n\n\nLatency\n\n\nIt’s related to the time you must wait for the reponse of the sensor. Example: Edge AI solves this problem by removing the round-trip time altogether. A great example of this is a self-driving car. The car’s AI systems run on onboard computers. This allows it to react nearly instantly to changing conditions, like the driver in front slamming on their brakes.\n\n\n\n\n\n\n\n\n\n\n\n\nEconomy\n\n\nConnectivity costs a lot of money. By processing data on-device, edge AI systems reduce or avoid the costs of transmitting data over a network and processing it in the cloud. Example: Edge AI enables healthcare providers to monitor patients in real time without sending data to the cloud for processing. For example, wearable devices with built-in AI algorithms can analyze physiological signals such as heart rate, oxygen levels, and ECG data locally. This reduces the reliance on cloud services for data transmission and processing.\n\n\n\n\n\n\n\n\n\n\n\nReliability\n\n\nSystems controlled by on-device AI are potentially more reliable than those that depend on a connection to the cloud. When you add wireless connectivity to a device, you’re adding a vast, overwhelmingly complex web of dependencies, from link-layer communications technologies to the internet servers that may run your application. Example: Traditional Cloud-Based Systems: Data collected by wearable devices must be transmitted to a cloud server, analyzed, and then results are sent back to caregivers or emergency responders. This can introduce delays due to network latency or connectivity issues. Edge AI Systems: Processes the sensor data locally in real time, enabling instant detection of falls or other anomalies.Improvement: Reduces detection and response time from minutes to milliseconds, ensuring immediate action during emergencies.\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy\n\n\nEdge AI provides an alternative. Rather than streaming live video and audio to a remote server, a security camera could use some onboard intelligence to identify that an intruder is present when the owners are out at work. It could then alert the owners in an appropriate way. When data is processed on an embedded system and is never transmitted to the cloud, user privacy is protected and there is less chance of abuse."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nKey Term\n\n\nThe term edge AI is a union of two buzzwords, fused together into one mighty term. It’s often heard alongside its siblings, embedded machine learning and TinyML.\n\n\n\n\n\n\n\n\n\n\n\nEmbedded\n\n\n\nEmbedded systems are the computers that control the electronics of all sorts of physical devices.\nIn contrast to general-purpose computers, embedded systems are usually meant to perform one specific, dedicated task.\nIt’s common for embedded systems to reflect the constraints of the environments into which they are deployed. For example, many embedded systems are required to run on battery power, so they’re designed with energy efficiency in mind—perhaps with limited memory or an extremely slow clock rate.\nProgramming embedded systems is the art of navigating these constraints, writing software that performs the task required while making the most out of limited resources."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nThe history of computer networks has been a gigantic tug of war.\nIn the first systems—individual computers the size of a room—computation was inherently centralized.\nComputers were connected to terminals that took over some of their responsibilities. Example the terminal renders the letters in an monitor."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nOver time, terminals became more and more sophisticated, taking over more and more functions that were previously the job of the central computer. The personal computer was invented.\nSmall computers could do useful work without even being connected to another machine.\nThe growth of the internet, along with web applications and services, made it possible to do some really cool stuff\nOver the past decade, most of our computing has become centralized again—this time in the “cloud.”"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-3",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nThe Internet of Things (IoT) includes everything you can think of: industrial sensors, smart refrigerators, internet-connected security cameras, personal automobiles, shipping containers, fitness trackers, and coffee machines.\nAll of these devices are embedded systems.\nSince they’re at the edge of the network, we can also call them edge devices.\nThe edge isn’t a single place; it’s more like a broad region.\nThe edge is where all the data comes from!\nEdge devices are our link between the internet and the physical world"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\n\n\nAI\n\n\n\nSince the dawn of time, humans have dreamed of creating intelligent entities that can help us in our struggle to survive.\nIn the modern world we dream of robot sidekicks who assist us.\nTo define AI, we have to define intelligence\n\n\n\n\n\n\n\n\n\n“Slime Mould Solves Maze in One Pass Assisted by Gradient of Chemo-Attractants” (Andrew Adamatzky, arXiv, 2011)"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-6",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-6",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#el-profesor",
    "title": "Sistemas y Señales Biomédicas",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción al procesado de señales.\nConceptos de señales contínuas & discretas.\nMuestreo.\nExtracción de características de una señal.\nFiltraje de señales."
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluación final\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nExamen parcial 1 (15%)\nExamen parcial 2 (15%)\nExamen final (20%)\nLaboratorios (30%)\nProyecto Final (20%)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación-1",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (15%)\nLaboratorios (15%)\nProyecto final (20%)\n\n\nExamen Parcial 1 (15%)\nExamen Parcial 2 (15%)\nExamen final (20%)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#recursos",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nLunes 10:00am-11:30am F-204. Jueves 10:00am-11:30am F-206.\nLaboratorio\nMartes 10:00am-11:30am. I1-308\n\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#bibliografía",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition",
    "text": "Introduction to data adquisition\n\n\n\nThere are two main roles in data: capture the information and encode the data in a form tha machine can process.\nData adquisition has three stages:\n\nTransduction\nSignal conditioning\nAnalog-to-digital conversion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Transduction",
    "text": "Introduction to data adquisition - Transduction\n\n\n\nTransduction is the conversion from one form of energy to another.\nThe only energy suitable for computer processing is the electrical\nTherefore signals need to be converted to analog voltages whose waveforms are ideally the same as those of the original signals.\nExist two components a captured signal: one component carries the information (signal), the other one is a probabilistic distorsion of the information(noise)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nNoise refers to any unwanted or random variations in a signal that interfere with the desired information. It is an unpredictable disturbance that can distort or obscure the actual data, making it harder to interpret or analyze.\n\n\n\n\nTypes of noise\n\nThermal Noise (Random Noise)\nElectromagnetic Interference (EMI)\nMotion Artifacts\nPhysiological Noise\nQuantization Noise"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\nModelling the noise\n\nAdditive White Gaussian Noise (AWGN): Modeled as a random process with a normal distribution.\nBand-limited Noise: Affects only specific frequency ranges and can be removed with filters.\nAdditive Noise: Adds directly to the original signal.\nMultiplicative Noise: Multiplies the original signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\nGraphsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros de la señal\nduration = 2  # Duración en segundos\nfs = 1000  # Frecuencia de muestreo en Hz\nt = np.linspace(0, duration, duration * fs, endpoint=False)  # Vector de tiempo\n\n# Señal senoidal de 10 Hz\nfreq = 10\nsine_wave = np.sin(2 * np.pi * freq * t)\n\n# Señal de ruido aleatorio con distribución normal\nnoise_normal = np.random.normal(0, 1, len(t))\n\n# Señal con ruido aleatorio de 2 a 5 Hz\nlow_freq_noise = np.sin(2 * np.pi * np.random.uniform(2, 5) * t)\nsignal_with_low_freq_noise = sine_wave + low_freq_noise\n\n# Señal con ruido aleatorio uniforme sumado\nuniform_noise = np.random.uniform(-0.5, 0.5, len(t))\nsignal_with_uniform_noise = sine_wave + uniform_noise\n\n# Señal con ruido aleatorio uniforme multiplicado\nmultiplicative_noise = np.random.uniform(0.5, 1.5, len(t))\nsignal_with_mult_noise = sine_wave * multiplicative_noise\n\n# Graficamos las señales\nfig, axes = plt.subplots(5, 1, figsize=(10, 10), sharex=True)\n\naxes[0].plot(t, sine_wave, label=\"Sine wave (10 Hz)\")\naxes[0].set_title(\"Sine Wave (10 Hz)\")\naxes[0].legend()\n\naxes[1].plot(\n    t, noise_normal, label=\"Random Noise (Normal Distribution)\", color=\"orange\"\n)\naxes[1].set_title(\"Random Noise (Normal Distribution)\")\naxes[1].legend()\n\naxes[2].plot(\n    t, signal_with_low_freq_noise, label=\"Sine + Low Freq Noise (2-5 Hz)\", color=\"green\"\n)\naxes[2].set_title(\"Sine + Low Freq Noise (2-5 Hz)\")\naxes[2].legend()\n\naxes[3].plot(t, signal_with_uniform_noise, label=\"Sine + Uniform Noise\", color=\"red\")\naxes[3].set_title(\"Sine + Uniform Noise\")\naxes[3].legend()\n\naxes[4].plot(t, signal_with_mult_noise, label=\"Sine * Uniform Noise\", color=\"purple\")\naxes[4].set_title(\"Sine * Uniform Noise\")\naxes[4].legend()\n\nplt.xlabel(\"Time [s]\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - ASP",
    "text": "Introduction to data adquisition - ASP\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAnalog signal processing (ASP) refers to the manipulation of continuous-time signals after they have been acquired from a transducer but before digital conversion. This type of processing is performed using electronic circuits that modify the signal in the analog domain to enhance its quality, extract useful information, or prepare it for further processing.\n\n\n\n\n\n\n\n\n\n\n\nCommon tasks\n\n\n\nAmplification: Increases the signal strength to match the required voltage levels. Example: ECG signals are weak (~1 mV) and need to be amplified before analysis.\nFiltering: Removes unwanted frequency components such as noise or interference.\nModulation/Demodulation: Used for communication systems where signals are modulated onto a higher-frequency carrier wave. Example: Biomedical telemetry systems use amplitude modulation (AM) or frequency modulation (FM) to transmit patient data wirelessly.\nDifferentiation & Integration: Differentiation: Highlights rapid changes in the signal. Example: Used in QRS detection for ECG signal analysis. Integration: Smooths out signals and accumulates values over time. Example: Used in electromyography (EMG) processing to estimate muscle activation.\nSignal Conditioning: Includes impedance matching, offset correction, and dynamic range adjustments. Example: Removing DC offsets in biosignals before digitization."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - analog-to-digital convertion",
    "text": "Introduction to data adquisition - analog-to-digital convertion\n\n\n\n\n\n\n\nDefinition\n\n\nAn analog-to-digital converter (ADC) is a device that converts a continuous-time signal, obtained through a transducer, into a digital signal that can be processed by a computer. This process consists of two fundamental operations, which occur simultaneously in practical implementations: sampling and quantization.\n\n\n\n\nOperations\n\nSampling involves converting the continuous-time analog signal into a discrete-time signal, where the amplitude remains unrestricted.\nQuantization then maps this continuous-amplitude signal to a finite set of discrete values, making it fully digital."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\nTo explain the analog-to-digital conversion process, we will assume that the input signal is a cosine wave with frequency \\(F\\), angular frequency \\(\\Omega\\) and amplitude \\(a\\).\n\\[x\\left(t\\right) = a \\cos\\left(\\Omega t + \\phi\\right) = a \\cos\\left(2\\pi F t + \\phi\\right)\\]\nObtaining\n\\[x\\left[n\\right] = a \\cos\\left(\\omega n + \\phi\\right) = a \\cos\\left(2\\pi f n + \\phi\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\n\n\n\n\n\n\n\nWhat?\n\n\nMathematically, the sampling process is:\n\\[x[n] = x(nT_s), \\quad -\\infty &lt; n &lt; \\infty\\]\n\n\n\n\nReplacing in previous equations, we have the expression:\n\\[x[n] = x(nT_s) = a \\cos\\left( 2\\pi F n T_s + \\phi \\right) = a \\cos\\left( 2\\pi n \\frac{F}{F_s} + \\phi \\right)\n\\]\nWhere:\n\\[\\omega = \\Omega T_s, \\quad f = \\frac{F}{F_s}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sample and quantization of an ECG signal",
    "text": "Sample and quantization of an ECG signal\n\nTaskGraphCode\n\n\n\nGenerate a synthetic ECG-like signal.\nSample it at different rates.\nApply quantization with different bit depths.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import chirp\n\n# Generate a synthetic ECG-like signal (chirp function as approximation)\nfs_original = 10000  # High sampling rate (Hz) - \"continuous\" signal\nt = np.linspace(0, 1, fs_original, endpoint=False)  # 1-second signal\nsignal = np.sin(2 * np.pi * 1.7 * (t**2))  # Simulated chirp (similar to ECG waves)\n\n# Downsample (Sampling Process)\nfs_sampled = 200  # Sampling frequency in Hz (e.g., ECG sampled at 200 Hz)\nt_sampled = np.arange(0, 1, 1/fs_sampled)\nsignal_sampled = np.sin(2 * np.pi * 1.7 * (t_sampled**2))\n\n# Quantization (8-bit and 4-bit)\ndef quantize(signal, bits):\n    levels = 2**bits\n    min_val, max_val = signal.min(), signal.max()\n    step = (max_val - min_val) / levels\n    quantized_signal = np.round((signal - min_val) / step) * step + min_val\n    return quantized_signal\n\nsignal_quantized_8bit = quantize(signal_sampled, 8)\nsignal_quantized_4bit = quantize(signal_sampled, 4)\n\n# Plot Results\nplt.figure(figsize=(12, 6))\n\n# Original vs Sampled Signal\nplt.subplot(2, 1, 1)\nplt.plot(t, signal, 'k', alpha=0.3, label='Original Signal (High Resolution)')\nplt.plot(t_sampled, signal_sampled, 'ro-', label=f'Sampled Signal ({fs_sampled} Hz)')\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Sampling Process\")\n\n# Quantized Signals\nplt.subplot(2, 1, 2)\nplt.plot(t_sampled, signal_sampled, 'bo-', alpha=0.5, label=\"Original Sampled\")\nplt.plot(t_sampled, signal_quantized_8bit, 'go-', label=\"Quantized 8-bit\")\nplt.plot(t_sampled, signal_quantized_4bit, 'ro-', label=\"Quantized 4-bit\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Quantization Effect\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-step",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-step",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Unit Step",
    "text": "Unit Step\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[u(t) =\n\\begin{cases}\n0, & t &lt; 0 \\\\\n1, & t \\geq 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[u[n] =\n\\begin{cases}\n0, & n &lt; 0 \\\\\n1, & n \\geq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-ramp",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-ramp",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Unit Ramp",
    "text": "Unit Ramp\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[u(t) =\n\\begin{cases}\n0, & t &lt; 0 \\\\\nt, & t \\geq 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[u[n] =\n\\begin{cases}\n0, & n &lt; 0 \\\\\nn, & n \\geq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#sync-function",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#sync-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sync Function",
    "text": "Sync Function\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[\\text{sinc}(t) =\n\\begin{cases}\n\\frac{\\sin(\\pi t)}{\\pi t}, & t \\neq 0 \\\\\n1, & t = 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\text{sinc}[n] =\n\\begin{cases}\n\\frac{\\sin(\\pi n)}{\\pi n}, & n \\neq 0 \\\\\n1, & n = 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#diracs-delta",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#diracs-delta",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Dirac’s Delta",
    "text": "Dirac’s Delta\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[\\delta(t) =\n\\begin{cases}\n+\\infty, & t = 0 \\\\\n0, & t \\neq 0\n\\end{cases}\\]\n\\(\\int_{-\\infty}^{\\infty} \\delta(t) dt = 1\\)\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\delta[n] =\n\\begin{cases}\n1, & n = 0 \\\\\n0, & n \\neq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-time",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-time",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – Translation in time",
    "text": "Basic Transformations on Singular signals – Translation in time"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-amplitude",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-amplitude",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – Translation in amplitude",
    "text": "Basic Transformations on Singular signals – Translation in amplitude"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-time",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-time",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – scailing in time",
    "text": "Basic Transformations on Singular signals – scailing in time"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-amplitude",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-amplitude",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – scailing in amplitude",
    "text": "Basic Transformations on Singular signals – scailing in amplitude"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#example",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\n\nQuestionSolutionCode for the graph 1/2Code for the graph 2/2\n\n\nHow can i create the following signal using only singular signals\n\n\n\n\n\n\n\n\n\n\n\n\\[x(t) = 5u(t) - 5(t-3)\\]\n\n\n\nt = np.linspace(-10,10,1000)\nx = np.zeros(t.shape)\n\nx[t&gt;=0]=5\nx[t&gt;=3]=0\n\nplt.figure(figsize=(16,6.75))\nplt.plot(t,x)\nplt.grid()\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Amplitude\")\n\n\n\n\nt = np.linspace(-10,10,1000)\nx = np.zeros(t.shape)\n\nx=5*np.heaviside(t,1)-5*np.heaviside(t-3,1)\n\nplt.figure(figsize=(16,6.75))\nplt.plot(t,x)\nplt.grid()\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Amplitude\")"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#exercisae-singular-signals",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#exercisae-singular-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Exercisae Singular Signals",
    "text": "Exercisae Singular Signals\n\nQuestion\n\n\nHow can i create the following signal using only singular signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción al procesado de señales e imágenes biomédicas.\nFundamentos procesado de señales e imágenes biomédicas\nExtracción de características de señales biomédicas.\nExtracción de características de imágenes biomédicas."
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluación final\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nExamen parcial 1 (15%)\nExamen parcial 2 (15%)\nExamen final (20%)\nLaboratorios (30%)\nProyecto Final (20%)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (15%)\nLaboratorios (15%)\nProyecto final (20%)\n\n\nExamen Parcial 1 (15%)\nExamen Parcial 2 (15%)\nExamen final (20%)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nLunes 2:30pm-4:00pm F-105. Martes 2:30pm-4:00pm D-201.\nLaboratorio\nJUEVES 2:30pm-4:00pm. I1-304\n\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#bibliografía",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\nDefinition\n\n\n\nTwo-dimensional function, f(x, y)\nWhere x and y are spatial coordinates.\nThe amplitude of f at any pair of coordinates (x, y) is called the intensity.\n\n\n\n\n\n\n\n\n\n\n\n\nThe digital image\n\n\nIf the coordinates and the intensity are discrete quantities the image turns into a digital image."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\nDefinition\n\n\nA digital image is composed by a finite number of elements called PIXEL.\n\n\n\n\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\n\nDepth\n\n\n\nA digital image is composed by a finite number of elements called PIXEL. Bpp( Bits per pixel)\n\n1bpp. B/W image, monochrome.\n2bpp. CGA Image.\n4bpp. Minimun for VGA standard.\n8bpp. Super-VGA image.\n24bpp. Truecolor image.\n48bpp. Professional-level images."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\n\nColor Space\n\n\nHow can i represent the color\n\nRGB.\nCMYK.\nHSV.\nAmong others."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"image01.tif\")\nfig001 = plt.figure()\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"lena.tif\")\nRGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig002 = plt.figure()\nplt.imshow(RGB_img)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nThe paradigm surrounding the conceptualization of light and perception has undergone significant evolution.\nInitially, the prevailing understanding within humanity posited that visual stimuli emanated from the eye itself.\nHowever, contemporary knowledge has elucidated that light originates from external sources, undergoes reflection from objects within the environment, and is subsequently captured by the eye."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nImportant\n\n\nWe also understand that light is a type of electromagnetic radiation, and its wavelength falls within a range from 400 nanometers to 700 nanometers.\n\n\n\n\n\nTaken from Corke 2023"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nImportant\n\n\n\nThe most common way light is made is by something getting really hot. This makes energy that comes out as light.\nSome important term are:\n\nAbsortion: It is the fraction of light which a body absorbs depending on the wavelength.\nReflectance: It is the fraction of the incoming light which a body reflects. It’s a number between 0 to 1 and also depends on wavelength.\nLuminance: It is the fraction of the incoming light which a surface reflects. It’s a function of absortion and reflectance, and because of that luminance depends on wavelength."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nThe eye\n\n\n\nOur eye has two types of cells. Cones and Rods.\nCones are the most sensitive cells but above all these are color sensitive.\nRods responds only two intensity and they used on night, mostly.\nHumans, like most primates, are trichomats. This means that humans have three types of cones (Long, Medium and shorts).\n\n65% of longs (Sense red)\n33% of mediums (Sense green)\n2% of shortsv(Sense blue)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nThe artificial eye\n\n\n\n\n\nTaken from Corke 2023\n\n\n\n\n\n\nThe currents from each sensor are function of the luminance and the spectral response filter."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\n\n\n\n\n\n\nDefinition\n\n\nSampling: Digitalization of the spatial coordinates.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nQuantiazation: Digitalization of the light intensity (amplitude)."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1bit\n\n\n\n\n\n\n\n\n\n2bit\n\n\n\n\n\n\n\n\n\n3bit\n\n\n\n\n\n\n\n\n\n4bit\n\n\n\n\n\n\n\n\n\n\n\n5bit\n\n\n\n\n\n\n\n\n\n6bit\n\n\n\n\n\n\n\n\n\n7bit\n\n\n\n\n\n\n\n\n\n8bit"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Linear indexing",
    "text": "Linear indexing\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\nFrom normal to linear\n\n\n\\[\\alpha = My+x\\]\n\n\n\n\n\n\n\n\n\n\n\n\nFrom linear to normal\n\n\n\\[x = \\alpha \\bmod M\\]\n\\[y = \\frac{\\alpha - x}{M}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Spatial resolution",
    "text": "Spatial resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Intensity resolution",
    "text": "Intensity resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Intensity resolution",
    "text": "Intensity resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "“A simple problem”",
    "text": "“A simple problem”\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "“A simple problem”",
    "text": "“A simple problem”\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\nNeighborhood\n\n\n\n\n\n\n\n\n\n\nN4\n\n\n\n\n\n\n\nND\n\n\n\n\n\n\n\nN8\n\n\n\n\n\n\nFigura 1"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Neighborhood",
    "text": "Relationships between pixels – Neighborhood\n\n\n\n\n\n\n\nNeighborhood\n\n\n\n\n\n\n\n\n\n\nN4-\\(N_4\\left(p\\right)\\)\n\n\n\n\n\n\n\nND-\\(N_D\\left(p\\right)\\)\n\n\n\n\n\n\n\nN8-\\(N_8\\left(p\\right)\\)\n\n\n\n\n\n\nFigura 2: Neighborhoods"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Adjacency",
    "text": "Relationships between pixels – Adjacency\n\n\n\n\n\n\n\nRules for adjecency\n\n\n\n4-Adjecncy: Two pixels p and q with values from V are 4-adjacent if q is in the set \\(N_4\\left(p\\right)\\)\n8-adjacency. Two pixels p and q with values from V are 8-adjacent if q is in the set \\(N_8\\left(p\\right)\\)\nm-adjacency (also called mixed adjacency). Two pixels p and q with values from V are m-adjacent if:\n\nq is in \\(N_4\\left(p\\right)\\).\nq is in \\(N_D\\left(p\\right)\\) and the set \\(N_4\\left(p\\right) \\cap N_4\\left(q\\right)\\) has no pixels whose values are from V."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\nAdjacency"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\n\n\n\n\n\n\nA4\n\n\n\n\n\n\n\n\n\n\n\nA8\n\n\n\n\n\n\n\n\n\n\n\n\n\nA-m"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Path",
    "text": "Relationships between pixels – Path\n\n\n\n\n\n\n\nDigital path\n\n\nIt is a sequence of adjacent pixels.\n\\[\\left(x_0, y_0\\right), \\left(x_1, y_1\\right), \\left(x_2, y_2\\right), \\dots \\left(x_n, y_n\\right)\\]\nIf \\(\\left(x_0, y_0\\right)=\\left(x_n, y_n\\right)\\) the path is known as closed path\nLet S represent a subset of pixels in an image. Two pixels p and q are said to be connected in S if there exists a path between them consisting entirely of pixels in S."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Path, Connected Subset",
    "text": "Relationships between pixels – Path, Connected Subset"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Regions",
    "text": "Relationships between pixels – Regions"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Boundary",
    "text": "Relationships between pixels – Boundary"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Distance",
    "text": "Relationships between pixels – Distance\n\n\n\n\n\n\n\nDistance\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\nDistance\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\n\nBio - That came from a biological being\nSignal - A signal is a function that conveys information about a physical phenomenon.\nBiosignals - The search for information from living systems to know its health state"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\nThe codification of biosignals into variations: * Electrical * Mechanical * Chemical * Thermal"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1791: Luigi Galvani discovers electrical signals in living tissues (frog legs)\n1830s: Carlo Matteucci studies electrical signals in the heart\n1887: Willem Einthoven invents the first electrocardiograph (ECG)\n1900s: James Mackenzie develops the first clinical ECG machine"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1920s: Electroencephalography (EEG) is developed by Hans Berger\n1930s: Electromyography (EMG) is developed by John Humphrey and others\n1940s: Development of the first commercial ECG machines\n1950s: Signal processing techniques are applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1960s: Digital signal processing and computer analysis of biomedical signals emerge\n1970s: Biomedical signal processing becomes a recognized field\n1980s: Development of Holter monitoring (24-hour ECG)\n1990s: Advances in signal processing and machine learning applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n2000s: Development of wearable devices and mobile health (mHealth) technologies\n2010s: Emergence of big data analytics and cloud computing in biomedical signal processing\n2020s: Integration of artificial intelligence (AI) and machine learning (ML) in biomedical signal processing"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1895: Wilhelm Roentgen discovers X-rays, leading to medical imaging\n1900s: X-ray technology improves with development of modern X-ray tubes\n1913: Albert Salomon develops mammography\n1920s: Ultrasound technology is developed by Karl Dussik and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1930s: Nuclear medicine emerges with development of radioactive tracers\n1950s: Computed Tomography (CT) scans are developed by Godfrey Hounsfield and Allan McLeod Cormack\n1960s: Development of medical ultrasound imaging\n1970s: Magnetic Resonance Imaging (MRI) is developed by Richard Ernst and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1980s: Digital image processing and analysis techniques are applied to biomedical images\n1990s: Advances in MRI and CT scan technology, including 3D imaging\n2000s: Development of functional MRI (fMRI), diffusion tensor imaging (DTI), and other advanced MRI techniques\n2010s: Emergence of artificial intelligence (AI) and machine learning in medical imaging"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nAdditional Milestones:\n\n1950s: Development of medical electronics and instrumentation\n1960s: First medical imaging computers are developed\n1970s: Development of digital image processing and analysis software\n1980s: Emergence of medical imaging informatics and PACS (Picture Archiving and Communication Systems)\n1990s: Development of telemedicine and teleradiology\n2000s: Emergence of electronic health records (EHRs) and health information exchanges (HIEs)\n2010s: Development of personalized medicine and precision health initiatives"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\n\n\n\n\n\n\nDefinition\n\n\nAn experiment is a physical procedure that produces some kind of result.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAn event is a set of experiment’s possible results.\n\n\n\n\n\n\n\n\n\n\n\nConsejo\n\n\nA sample space is the set of ALL possibles results of an experiment."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\nGraphCodeSample SpaceResultDataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata = np.genfromtxt(\"../../data/mitbih_train.csv\", delimiter=\",\")\necg1 = data[1, :-1]\ntime = np.array(range(0,len(ecg1)))/125\nfig = plt.figure()\nplt.plot(time, ecg1)\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Normalized ECG\")\n\n\n\n\nprint(\"Maximun Value: \"+ str(ecg1.max()))\n\nMaximun Value: 1.0\n\nprint(\"Minimun Value: \"+ str(ecg1.min()))\n\nMinimun Value: 0.0\n\n\n\n\n\nprint(ecg1[np.random.choice(ecg1.shape[0], 1, replace=False)])\n\n[0.]\n\n\n\n\nName: ECG Heartbeat Categorization Dataset.\nURL: https://www.kaggle.com/datasets/shayanfazeli/heartbeat?resource=download"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Probability Axioms",
    "text": "Probability Axioms\nFor the given events A and B that are in a sample space S:\n\n\n\n\n\n\n\nAxioms\n\n\n\n\\(0 \\leq P_r \\left(A\\right) \\leq 1\\)\n\\(P_r\\left(S\\right) = 1\\)\nIf \\(A \\cap B = \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right)\\)\nIf \\(A \\cap B \\neq \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right) - P_r\\left(A \\cap B \\right)\\)\n\\(P_r\\left(\\bar{A}\\right) = 1-P_r \\left(A\\right)\\)\nIf \\(A\\subset B\\) then \\(P_r \\left(A\\right)\\leq P_r \\left(B\\right)\\)\n\\(P_r \\left(A|B\\right)=\\frac{P_r \\left(A\\cap B\\right)}{P_r \\left(B\\right)}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable\n\n\n\n\n\n\n\nDefinition\n\n\nA random variable is a real valued function of the elements of a sample space, S . Given an experiment, E , with sample space, S, the random variable maps each possible outcome of E.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nThe probability mass function (PMF), \\(P_X\\left(x\\right)\\), of a random variable, X, is a function that assigns a probability to each possible value of the random variable, X."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nConditions\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sum_{\\chi \\in X}P_X\\left(\\chi \\right) = 1\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\int_{-\\infty}^{\\infty}P_X\\left(\\chi \\right)d\\chi = 1\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nExpected Values\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\mu = \\sum_{\\chi \\in X}\\chi P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\mu=\\int_{-\\infty}^{\\infty}\\chi P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nVariance\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sigma^2 = \\sum_{\\chi \\in X}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\sigma^2 = \\int_{-\\infty}^{\\infty}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "PDF Estimation",
    "text": "PDF Estimation\n\nGraphCodeExp. ValueVariance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncounts01, bin_edges01 = np.histogram(ecg1, bins=10, density=True)\ncounts02, bin_edges02 = np.histogram(ecg1, bins=50, density=True)\ncounts03, bin_edges03 = np.histogram(ecg1, bins=100, density=True)\nfig01=plt.figure()\nplt.plot(bin_edges01[1:], counts01/sum(counts01), label=\"Estimation with 10 bins\")\nplt.plot(bin_edges02[1:], counts02/sum(counts02), label=\"Estimation with 50 bins\")\nplt.plot(bin_edges03[1:], counts03/sum(counts03), label=\"Estimation with 100 bins\")\nplt.legend()\nplt.grid()\nplt.xlabel(\"Normalised ECG Value\")\nplt.ylabel(\"Estimated PDF Value\")\n\n\n\n\n\n0.09001020772910533\n\n\n\n\n\n\n0.02551116143316462"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n(-1.0, 6.0)\n\n\n(-1.0, 5.0)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\nIt’s a mathematical tool for signal decomposition, like Fourier’s Transform.\nJust as the Fourier transform decomposes a signal into a series of sine and cosine functions, the wavelet transform does so using a set of functions known as wavelets.\nWavelets are functions generated by scaling and shifting a base function known as the mother wavelet."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\nMorlet: Popular for time-frequency analysis in EEG and ECG.\nMexican Hat (Ricker): Often used in spike detection in neural signals.\nHaar: Useful in quick decomposition of signals and feature extraction.\nDaubechies: Frequently used in ECG signal denoising and compression.\nSymlet: Another option for signal processing and feature extraction in EEG.\nCoiflet: Useful for denoising and baseline correction in biomedical signals."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-4",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-4",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\nConditionsIIIIIIIVV\n\n\n\nHave a mean of zero (to capture details in the signal).\nBe square integrable (finite energy).\nSatisfy the admissibility condition on its Fourier transform.\nBe oscillatory to capture frequency information.\n(Optionally) have compact support for efficient computation and localization.\n\n\n\n\n\n\n\n\n\n\nZero Mean (Admissibility Condition)\n\n\nThe function must have an average value of zero. Mathematically, this is expressed as:\n\\[\\int_{-\\infty}^{\\infty} \\psi(t) \\, dt = 0\\]\nThis condition ensures that the wavelet can detect changes or “details” in the signal rather than its average or constant components.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSquare Integrability\n\n\nThe function \\(\\psi(t)\\) must be square integrable, meaning it has finite energy:\n\\[\\int_{-\\infty}^{\\infty} |\\psi(t)|^2 \\, dt &lt; \\infty\\]\nThis requirement ensures that the wavelet’s energy is finite, making it possible to localize the function in both time and frequency domains. Functions that satisfy this belong to the \\(L^2(\\rm I\\!R)\\) space, which is the space of all functions with finite energy.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdmissibility Constant\n\n\nThe wavelet’s Fourier transform, \\(\\hat{\\psi}(\\omega)\\), should satisfy the admissibility condition:\n\\[C_\\psi = \\int_{-\\infty}^{\\infty} \\frac{|\\hat{\\psi}(\\omega)|^2}{|\\omega|} \\, d\\omega &lt; \\infty\\]\nwhere \\(\\hat{\\psi}(\\omega)\\) is the Fourier transform of \\(\\psi(t)\\), and \\(\\omega\\) represents angular frequency. This condition implies that \\(\\hat{\\psi}(\\omega)\\) must approach zero as \\(\\omega \\rightarrow 0\\) meaning the wavelet has no component at zero frequency (or DC component). This condition is crucial for ensuring that the wavelet transform is invertible.\n\n\n\n\n\n\n\n\n\n\n\n\n\nOscillatory Nature\n\n\nA mother wavelet should generally be oscillatory or “wavelike” (hence the term “wavelet”). This oscillatory behavior allows the wavelet to capture variations in the signal. For example, wavelets like the Morlet wavelet resemble decaying sinusoids. This oscillatory nature helps the wavelet capture both high-frequency and low-frequency components effectively.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompact Support\n\n\nAlthough not strictly necessary, compact support is often a desirable property. Compact support means that the function is non-zero only over a finite interval, making it well-localized in time. This allows for efficient computation and good localization in the time domain. For example, the Haar wavelet has compact support, while others, like the Morlet wavelet, do not have strict compact support but still decay rapidly."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "A wavelet transformation",
    "text": "A wavelet transformation\n\n\n(0.0, 1.0)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "A wavelet transformation",
    "text": "A wavelet transformation"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe continuous wavelet transform of a signal \\(f(t)\\) is defined as:\n\\[W_f(a, b) = \\int_{-\\infty}^{\\infty} f(t) \\, \\psi^*\\left(\\frac{t - b}{a}\\right) \\, dt\\]\nwhere:\n\n\\(f(t)\\) is the input signal,\n\\(\\psi\\) is the mother wavelet,\n\\(a\\) is the scale parameter (controls the width of the wavelet),\n\\(b\\) is the translation parameter (controls the position of the wavelet),\n\\(\\psi^*\\) denotes the complex conjugate of the mother wavelet. ## Mathematical Expressions\n\nThe continuous wavelet transform of a signal \\(f(t)\\) is defined as:\n\\[W_f(a, b) = \\int_{-\\infty}^{\\infty} f(t) \\, \\psi^*\\left(\\frac{t - b}{a}\\right) \\, dt\\]\nwhere:\n\n\\(f(t)\\) is the input signal,\n\\(\\psi\\) is the mother wavelet,\n\\(a\\) is the scale parameter (controls the width of the wavelet),\n\\(b\\) is the translation parameter (controls the position of the wavelet),\n\\(\\psi^*\\) denotes the complex conjugate of the mother wavelet."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe inverse continuous wavelet transform is given by:\n\\[f(t) = \\frac{1}{C_{\\psi}} \\int_{0}^{\\infty} \\int_{-\\infty}^{\\infty} W_f(a, b) \\, \\psi\\left(\\frac{t - b}{a}\\right) \\frac{db \\, da}{a^2}\\]\nwhere:\nwhere \\(C_{\\psi}\\) is a normalization constant, defined as:\n\\[C_{\\psi} = \\int_{0}^{\\infty} \\frac{|\\hat{\\psi}(\\omega)|^2}{\\omega} \\, d\\omega\\]\nand \\(\\hat{\\psi}(\\omega)\\) is the Fourier transform of the wavelet \\(\\psi(t)\\)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe discrete wavelet transform decomposes the signal at discrete levels of scale. For a signal \\(x[n]\\), the wavelet decomposition is defined as:\n\\[c_{j, k} = \\sum_{n} x[n] \\, \\psi_{j, k}(n)\\]\nwhere:\n\n\\(\\psi_{j, k}(n)= \\frac{1}{\\sqrt{2}}\\psi\\left(\\frac{n-2^{j}k}{2^{j}}\\right)\\) represents the scaled and translated versions of the mother wavelet \\(\\psi\\)\n\\(j\\) is the scale index, and \\(k\\) is the translation index.\n\nThe decomposition typically consists of approximation and detail coefficients at each scale:\nApproximation coefficients \\(a_j\\): capture the low-frequency components. Detail coefficients \\(d_j\\) capture the high-frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe inverse discrete wavelet transform reconstructs the original signal from its approximation and detail coefficients: \\[x[n] = \\sum_{j} \\sum_{k} c_{j, k} \\, \\psi_{j, k}(n)\\]\nThis reconstruction process involves upsampling and filtering of the approximation and detail coefficients at each scale."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#using-cwt",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#using-cwt",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Using CWT",
    "text": "Using CWT\n\nPurpose: The CWT is used when you need a highly detailed, continuous analysis of a signal over all possible scales and positions.\nOutput: CWT gives you a “heatmap” of wavelet coefficients, showing which frequencies (or scales) are present in the signal at each point in time. This allows for a continuous representation.\nApplications: CWT is useful for analyzing signals where you want to see the evolution of frequencies over time, such as:\n\nDetecting subtle changes in frequencies over time (like brainwave analysis in EEG).\nSignals with non-repeating, transient features (like spikes in biomedical signals, e.g., ECG).\n\nTrade-Off: CWT is more computationally expensive because it analyzes all scales and translations continuously. It gives lots of data but is slower and requires more memory.\n\n\n\n\n\n\n\n\nUse CWT when:\n\n\n\nYou need a detailed, continuous representation.\nYou want to detect subtle or fast-changing features across time.\nYou’re okay with higher computational costs to get very fine-grained analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#using-dwt",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#using-dwt",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Using DWT",
    "text": "Using DWT\n\nPurpose: The DWT is used when you want a compact, efficient representation of a signal, usually for compression or feature extraction. It analyzes only specific scales (powers of two), not continuously.\nOutput: DWT gives you a set of coefficients at each level (or scale), capturing information at that specific scale. It’s efficient and uses fewer data points.\nApplications: DWT is ideal when you want to reduce the size of data or focus on a smaller set of frequencies, such as:\n\nImage and audio compression (like JPEG 2000 or MP3 formats).\nFeature extraction for machine learning (e.g., identifying specific patterns).\nDe-noising signals by discarding certain scales that contain noise.\n\nTrade-Off: DWT is computationally cheaper but less detailed than CWT. It doesn’t give a continuous heatmap but rather a discrete set of scales.\n\n\n\n\n\n\n\n\nUse DWT when:\n\n\n\nYou need a compact and efficient representation.\nYou’re focused on data compression, de-noising, or feature extraction.\nYou want faster computations with less data storage requirements."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\nData acquisition is to capture the signal and encode in a form suitable for computer processing.\nSignal conditioning is to remove noise and artifacts from the signal.\nFeature extraction is to extract relevant information from the signal.\nHypothesis testing is to test the hypothesis based on the extracted features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal condtioning",
    "text": "Signal condtioning\n\n\n\n\n\n\n\nBase Information\n\n\n\nA 12-lead electrocardiogram for arrhythmia study - Article\nA 12-lead electrocardiogram for arrhythmia study - Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning\n\ndata  = sio.loadmat(path_ecg+\"/JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\nprint(data.keys())\n\ndict_keys(['val'])\n\nprint(type(data['val']))\n\n&lt;class 'numpy.ndarray'&gt;\n\nprint(data['val'].shape)\n\n(12, 5000)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning"
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#importance-of-frequency-response-filters",
    "href": "presentaciones/PSIM/prueba.html#importance-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Importance of Frequency-Response Filters",
    "text": "Importance of Frequency-Response Filters\n\nFrequency-response filters are critical for enhancing specific features or reducing noise in images.\nWidely used in MRI, CT, and ultrasound imaging."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#what-is-a-frequency-response-filter",
    "href": "presentaciones/PSIM/prueba.html#what-is-a-frequency-response-filter",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is a Frequency-Response Filter?",
    "text": "What is a Frequency-Response Filter?\n\nA frequency-response filter modifies the frequency components of a signal.\nApplied in image processing to control which frequencies (details) pass or are suppressed."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#types-of-frequency-response-filters",
    "href": "presentaciones/PSIM/prueba.html#types-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Types of Frequency-Response Filters",
    "text": "Types of Frequency-Response Filters\n\nLow-pass filters: Allow low frequencies, suppress high frequencies (smoothes image).\nHigh-pass filters: Allow high frequencies, suppress low frequencies (sharpens image).\nBand-pass filters: Allow frequencies in a certain range."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#spatial-vs.-frequency-domain",
    "href": "presentaciones/PSIM/prueba.html#spatial-vs.-frequency-domain",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Spatial vs. Frequency Domain",
    "text": "Spatial vs. Frequency Domain\n\nSpatial domain: Operations on pixel values directly.\nFrequency domain: Operations on the image’s frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#fourier-transform",
    "href": "presentaciones/PSIM/prueba.html#fourier-transform",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Fourier Transform",
    "text": "Fourier Transform\n\nConverts an image from the spatial domain to the frequency domain.\nFormula: \\[F\\left(u,v\\right) = \\sum\\sum f\\left(x,y\\right) e^{-j2\\pi(\\frac{ux}{M} + \\frac{vy}{N})}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#low-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#low-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low-Pass Filters",
    "text": "Low-Pass Filters\n\nRemoves high-frequency components (e.g., noise, sharp edges).\nExample: Gaussian filter, Butterworth filter."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#high-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#high-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "High-Pass Filters",
    "text": "High-Pass Filters\n\nEnhances edges and high-frequency details.\nExample: Laplacian filter."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#band-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#band-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Band-Pass Filters",
    "text": "Band-Pass Filters\n\nAllows frequencies within a specific range.\nUseful for isolating specific image features."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#noise-reduction-in-mri",
    "href": "presentaciones/PSIM/prueba.html#noise-reduction-in-mri",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Noise Reduction in MRI",
    "text": "Noise Reduction in MRI\n\nLow-pass filters reduce noise and artifacts in MRI scans.\nSmoothes the image without losing crucial details."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#edge-enhancement-in-ultrasound-images",
    "href": "presentaciones/PSIM/prueba.html#edge-enhancement-in-ultrasound-images",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge Enhancement in Ultrasound Images",
    "text": "Edge Enhancement in Ultrasound Images\n\nHigh-pass filters help in detecting tissue boundaries by enhancing edges.\nImproves clarity of anatomical structures."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#feature-extraction-in-ct-scans",
    "href": "presentaciones/PSIM/prueba.html#feature-extraction-in-ct-scans",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Feature Extraction in CT Scans",
    "text": "Feature Extraction in CT Scans\n\nFilters can help in extracting features like tumors or vessels.\nBand-pass filters isolate structures of interest at specific frequency ranges."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "href": "presentaciones/PSIM/prueba.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process",
    "text": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process\n\nLoad MRI image.\nApply Fourier Transform to move the image into the frequency domain.\nDesign and apply a low-pass filter.\nPerform Inverse Fourier Transform to return to the spatial domain.\nVisualize the result."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#summary",
    "href": "presentaciones/PSIM/prueba.html#summary",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Summary",
    "text": "Summary\n\nFrequency-response filters play a crucial role in biomedical image processing.\nHelp enhance key features and suppress unwanted noise."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#future-trends",
    "href": "presentaciones/PSIM/prueba.html#future-trends",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Future Trends",
    "text": "Future Trends\n\nDeep learning integration with traditional filters.\nDevelopment of adaptive filters for real-time processing."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "",
    "text": "Profesor Asociado en la Universidad Escuela Colombiana de Ingenieria, Analista de Datos con un sólido trasfondo como Ingeniero en Electrónica y Telecomunicaciones y Doctor en Ciencias de la Electrónica. Cuento con 20 años de experiencia en Educación Universitaria y una destacada participación en proyectos de investigación en el campo de la Ciencia de los Datos aplicada a las organizaciones, el aprendizaje y la ciencia. Mi enfoque se centra en utilizar mis habilidades técnicas y experiencia para analizar grandes conjuntos de datos y extraer conocimientos valiosos que impulsen la toma de decisiones informadas."
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2016",
    "text": "2016\n- P. E. Caicedo-Rodríguez, Rengifo-Rodas, Carlos Felipe, y Rodríguez-Cheu, Luis Eduardo, «Contributions of electronic sciences to the problem of falls of old age population», 2016, doi: 10.17488/RMIB.37.3.6."
  },
  {
    "objectID": "about.html#section-1",
    "href": "about.html#section-1",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2017",
    "text": "2017\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, y L. E. Rodríguez-Cheu, «A human gait temporal parameters calculation algorithm», en VII Latin American Congress on Biomedical Engineering CLAIB 2016, Bucaramanga, Santander, Colombia, October 26th -28th, 2016, vol. 60, I. Torres, J. Bustamante, y D. A. Sierra, Eds., en IFMBE Proceedings, vol. 60. , Singapore: Springer Singapore, 2017, pp. 285-288. doi: 10.1007/978-981-10-4086-3_72."
  },
  {
    "objectID": "about.html#section-2",
    "href": "about.html#section-2",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2018",
    "text": "2018\n-  S. P. Castillo-Landínez y P. E. Caicedo-Rodríguez, «EL BLOG COMO HERRAMIENTA DE ENSEÑANZA EN LOS CURSOS DE INVESTIGACIÓN», presentado en Encuentro Internacional de Educación en Ingeniería ACOFI, Cartagena, Colombia, 2018."
  },
  {
    "objectID": "about.html#section-3",
    "href": "about.html#section-3",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2019",
    "text": "2019\n- N. Valencia-Jimenez et al., «A Comparative Study of Markerless Systems Based on Color-Depth Cameras, Polymer Optical Fiber Curvature Sensors, and Inertial Measurement Units: Towards Increasing the Accuracy in Joint Angle Estimation», Electronics, vol. 8, n.º 2, p. 173, feb. 2019, doi: 10.3390/electronics8020173.\n- S. P. Castillo-Landinez, P. E. Caicedo-Rodríguez, y D. F. Sánchez-Gómez, «Diseño e implementación de un software para la trazabilidad del proceso de beneficio del café», CTA, vol. 20, n.º 3, sep. 2019, doi: 10.21930/rcta.vol20_num3_art:1588.\n- P. E. Caicedo-Rodriguez, C. F. Rengifo-Rodas, L. E. Rodríguez-Cheu, y W. A. Sierra-Arevalo, «Gait Phase Detection for Lower Limb Prosthetic Devices», en Wearable Robotics: Challenges and Trends, vol. 22, M. C. Carrozza, S. Micera, y J. L. Pons, Eds., en Biosystems & Biorobotics, vol. 22. , Cham: Springer International Publishing, 2019, pp. 201-205. doi: 10.1007/978-3-030-01887-0_39.\n- S. P. Castillo-Landínez y P. E. Caicedo-Rodríguez, «ANÁLISIS DE SENTIMIENTOS, UNA HERRAMIENTA PARA VALORAR LA ACTITUD DEL ESTUDIANTE FRENTE A UN CURSO», presentado en Encuentro internacional de educación en ingeniería, Cartagena, Colombia, 2019.\nP. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, y L. E. Rodriguez-Cheu, «LA VELOCIDAD DE MARCHA COMO FACTOR DISCRIMINATORIO DEL RIESGO DE CAÍDA EN ADULTOS MAYORES», presentado en Encuentro internacional de educación en ingeniería, Cartagena, Colombia, 2019. doi: 10.26507/ponencia.282."
  },
  {
    "objectID": "about.html#section-4",
    "href": "about.html#section-4",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2020",
    "text": "2020\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. Gómez-Guevara, «Dataset for gait analysis and assessment of fall risk for older adults», Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. Gómez-Guevara, «Dataset for gait analysis and assessment of fall risk for older adults», Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- Y. H. Bolaños-Muñoz, C. F. Rengifo-Rodas, P. E. Caicedo-Rodríguez, L. E. Rodriguez-Cheu, y W. A. Sierra-Arevalo, «Electronic system for step width estimation using programmable system-on-chip technology and time of flight cameras», HardwareX, vol. 8, p. e00126, oct. 2020, doi: 10.1016/j.ohx.2020.e00126.\n- S. P. Castillo Landínez, P. E. Caicedo Rodríguez, y S. A. Muñoz De La Rosa, «LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA CUARENTENA A TRAVÉS DEL ANÁLISIS DE SENTIMIENTOS. UN CASO DE ESTUDIO EN LA UNIAUTÓNOMA DEL CAUCA», en Encuentro Internacional de Educación en Ingeniería ACOFI 2020, Asociacion Colombiana de Facultades de Ingeniería - ACOFI, ago. 2020, pp. 1-8. doi: 10.26507/ponencia.820.\n- J. P. Henao-Pereira, A. E. Tovar-Leon, S. P. Castillo-Landínez, y P. E. Caicedo-Rodríguez, «Los accidentes de tránsito desde la perspectiva de la minería de datos. Una revisión de la literatura», Aibi revista investig. adm. ing., pp. 133-141, ago. 2020, doi: 10.15649/2346030X.743."
  },
  {
    "objectID": "about.html#section-5",
    "href": "about.html#section-5",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2021",
    "text": "2021\n- P. E. Caicedo-Rodríguez, Incidencia de los sistemas electrónicos de medición de variables biomecánicas en la concordancia intra e inter evaluador del examen POMA de función motora, Primera. Popayán, Colombia: Sello Editorial Uniautónoma del Cauca, 2021.\n- S. Castillo Landínez, P. E. Caicedo Rodríguez, S. A. Muñoz De La Rosa, y J. P. Sandoval Paz, «LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA PANDEMIA, UN AÑO DESPUÉS», en Encuentro Internacional de Educación en Ingeniería ACOFI 2021, Asociacion Colombiana de Facultades de Ingeniería - ACOFI, sep. 2021, pp. 1-9. doi: 10.26507/ponencia.2005.\n- L. S. Vargas-Valencia et al., «Sleeve for Knee Angle Monitoring: An IMU-POF Sensor Fusion System», IEEE J. Biomed. Health Inform., vol. 25, n.º 2, pp. 465-474, feb. 2021, doi: 10.1109/JBHI.2020.2988360.\n- C. R. Malaver-Flor y M. Y. Astorquiza-Velasco, «Técnicas de Procesamiento Para Variables Posturales Enfocadas en Detección Temprana Del Microtraumatismo Tisular de un Ciclista», PROSPECTIVA, vol. 19, n.º 2, 2021."
  },
  {
    "objectID": "about.html#section-6",
    "href": "about.html#section-6",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2022",
    "text": "2022\n- S. Castillo Landínez, P. E. Caicedo Rodríguez, y J. A. Mosquera Bolaños, «Los adolescentes y el uso de las redes sociales. Un análisis desde la óptica de la ciencia de datos y el procesamiento de lenguaje natural», presentado en Nuevas realidades para la educación en ingeniería: currículo, tecnología, medio ambiente y desarrollo, sep. 2022, pp. 1-8. doi: 10.26507/paper.2693.\n- V. Cerón Monje, C. E. Zúñiga Muñoz, S. P. Castillo Landínez, y P. E. Caicedo Rodríguez, «Análisis de sentimientos aplicado a la evaluación docente de la Corporación Universitaria Autónoma del Cauca», presentado en Nuevas realidades para la educación en ingeniería: currículo, tecnología, medio ambiente y desarrollo, sep. 2022, pp. 1-10. doi: 10.26507/paper.2308."
  },
  {
    "objectID": "about.html#section-7",
    "href": "about.html#section-7",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2023",
    "text": "2023\n- J. M. Cabrera Ángel, P. E. Caicedo-Rodríguez, y S. Castillo-Landínez, «Así nos vemos», Uniautonoma del Cauca, Popayán, 2023.\n- S. Castillo Landínez y P. E. Caicedo Rodríguez, «¡¡¡Ahora sí tocó poner atención porque hay que evaluar!!!», presentado en Ingeniería para transformar territorios, sep. 2023, pp. 1-10. doi: 10.26507/paper.2941."
  },
  {
    "objectID": "about.html#section-8",
    "href": "about.html#section-8",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2024",
    "text": "2024"
  },
  {
    "objectID": "laboratorios/ASIM/lab002_CNN.html",
    "href": "laboratorios/ASIM/lab002_CNN.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torchvision\n\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader\n\nimport torch.nn as nn\n\nfrom torch import utils\nfrom torch import optim\nfrom torch import device\nfrom torch import inference_mode\n\nimport tqdm\n\nfrom timeit import default_timer as timer\nfrom tqdm.auto import tqdm\n\nfrom torchmetrics import ConfusionMatrix\nimport mlxtend\nfrom mlxtend.plotting import plot_confusion_matrix\nimport numpy\nfrom torchvision.transforms.v2 import (\n    ConvertImageDtype,\n    Normalize,\n    Resize,\n    CenterCrop,\n    ToTensor,\n    ToImage,\n    Compose\n)\n\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0\n\n\n\ntransformacion = Compose([\n    ToTensor(), \n    Normalize(mean=[0.5], std=[0.5])\n    ])\n\n/home/pablo/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n\n\n\ndata_flag = \"pathmnist\"\ninfo = INFO[data_flag]\nDataClass = getattr(medmnist, info[\"python_class\"])\n\n# Load the training and testing datasets\ntrain_data = DataClass(split=\"train\", transform=transformacion, download=True)\nval_data = DataClass(split=\"val\", transform=transformacion, download=True)\ntest_data = DataClass(split=\"test\", transform=transformacion, download=True)\n\nDownloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /home/pablo/.medmnist/pathmnist.npz\n\n\n100%|██████████| 205615438/205615438 [00:20&lt;00:00, 10059790.46it/s]\n\n\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\n\n\n\n# check data properties\nimg = train_data[0][0]\nlabel = train_data[0][1]\n\nprint(f\"Image:\\n {img}\")\nprint(f\"Label:\\n {label}\")\n\nprint(f\"Image shape: {img.shape}\")\nprint(f\"Label: {label}\")\n\nImage:\n tensor([[[0.7255, 0.7176, 0.7255,  ..., 0.7255, 0.7176, 0.7333],\n         [0.7098, 0.7255, 0.7176,  ..., 0.5451, 0.5059, 0.4902],\n         [0.7255, 0.7255, 0.7176,  ..., 0.6314, 0.6235, 0.6392],\n         ...,\n         [0.7098, 0.7020, 0.7333,  ..., 0.7333, 0.7255, 0.7333],\n         [0.6706, 0.7020, 0.7333,  ..., 0.7333, 0.7333, 0.7333],\n         [0.6863, 0.7255, 0.7333,  ..., 0.7255, 0.7333, 0.7412]],\n\n        [[0.6314, 0.6235, 0.6235,  ..., 0.6314, 0.6235, 0.6314],\n         [0.6157, 0.6235, 0.6157,  ..., 0.3882, 0.3490, 0.3176],\n         [0.6314, 0.6235, 0.6078,  ..., 0.4980, 0.5059, 0.5216],\n         ...,\n         [0.6078, 0.5765, 0.6314,  ..., 0.6314, 0.6314, 0.6392],\n         [0.5059, 0.5686, 0.6314,  ..., 0.6314, 0.6392, 0.6314],\n         [0.5294, 0.6235, 0.6314,  ..., 0.6314, 0.6314, 0.6392]],\n\n        [[0.7804, 0.7804, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7725, 0.7725, 0.7725,  ..., 0.5843, 0.5451, 0.5294],\n         [0.7725, 0.7725, 0.7647,  ..., 0.6706, 0.6706, 0.6941],\n         ...,\n         [0.7647, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7098, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7255, 0.7725, 0.7804,  ..., 0.7804, 0.7804, 0.7882]]])\nLabel:\n [0]\nImage shape: torch.Size([3, 28, 28])\nLabel: [0]\n\n\n\n# Number of image channels\nn_channels = info[\"n_channels\"]\nprint(f\"number of channels: {n_channels}\")\n\n# Number of classes\nn_classes = len(info[\"label\"])\nprint(f\"number of classes: {n_classes}\")\n\n# Get the class names from the dataset\nclass_names = info[\"label\"]\nprint(f\"class names: {class_names}\")\n\nnumber of channels: 3\nnumber of classes: 9\nclass names: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n\n\n\nfor i in range(3):\n    img = train_data[i][0]\n    label = train_data[i][1]\n    plt.figure(figsize=(3, 3))\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(label)\n    plt.axis(False)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.6313726..0.84313726].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.372549..0.85882354].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# change data into dataloader form\nBATCH_SIZE = 128\ntrain_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n\n\n# check dataloader\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")\n\nDataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53cd0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53490&gt;)\nLength of train dataloader: 704 batches of 128\nLength of test dataloader: 57 batches of 128\nLength of val dataloader: 79 batches of 128\n\n\n\n# define training loop functions\ndef train_step(\n    model: torch.nn.Module,\n    data_loader: torch.utils.data.DataLoader,\n    loss_fn: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    train_loss, train_acc = 0, 0\n    model.to(device)\n\n    for batch, (X, y) in enumerate(data_loader):\n        # need to change target shape for this medmnist data\n        y = y.squeeze().long()\n\n        # Send data to selected device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. loss and accuracy\n        loss = loss_fn(y_pred, y)\n        train_loss += loss\n        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n    # Calculate loss and accuracy per epoch\n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n\n    return train_loss, train_acc\n\n\ndef test_step(\n    data_loader: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    test_loss, test_acc = 0, 0\n    model.to(device)\n\n    model.eval()  # eval mode for testing\n    with torch.inference_mode():  # Inference context manager\n        for X, y in data_loader:\n            # need to change target shape for this medmnist data\n            y = y.squeeze().long()\n\n            # Send data to selected device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred = model(X)\n\n            # 2. Calculate loss and accuracy\n            test_loss += loss_fn(test_pred, y)\n            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n\n        # Adjust metrics and print out\n        test_loss /= len(data_loader)\n        test_acc /= len(data_loader)\n\n        return test_loss, test_acc\n\n\ndef eval_func(\n    data_loader: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    eval_loss, eval_acc = 0, 0\n    model.to(device)\n\n    model.eval()\n    y_preds = []\n    y_targets = []\n    with torch.inference_mode():\n        for batch, (X, y) in tqdm(enumerate(data_loader)):\n            # need to change target shape for this medmnist data\n            y = y.squeeze().long()\n\n            # Send data to selected device\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass\n            eval_pred = model(X)\n\n            # Find loss and accuracy\n            eval_loss += loss_fn(eval_pred, y)\n            eval_acc += accuracy_fn(y_true=y, y_pred=eval_pred.argmax(dim=1))\n\n            # Add prediction and target labels to list\n            eval_labels = torch.argmax(torch.softmax(eval_pred, dim=1), dim=1)\n            y_preds.append(eval_labels)\n            y_targets.append(y)\n\n        # Scale loss and acc\n        eval_loss /= len(data_loader)\n        eval_acc /= len(data_loader)\n\n        # Put predictions on CPU for evaluation\n        y_preds = torch.cat(y_preds).cpu()\n        y_targets = torch.cat(y_targets).cpu()\n\n        return {\n            \"model_name\": model.__class__.__name__,\n            \"loss\": eval_loss.item(),\n            \"accuracy\": eval_acc,\n            \"predictions\": y_preds,\n            \"targets\": y_targets,\n        }\n\n\ndef print_train_time(start: float, end: float, device: torch.device = None):\n    total_time = end - start\n    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n    return total_time\n\n\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct / len(y_pred)) * 100\n    return acc\n\n\nclass cnn(torch.nn.Module):\n    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n        super().__init__()\n\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=input_shape, out_channels=hidden_units, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n        )\n\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units, out_channels=hidden_units, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units, out_channels=hidden_units * 4, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n        )\n\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units * 4,\n                out_channels=hidden_units * 4,\n                kernel_size=3,\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n        )\n\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units * 4,\n                out_channels=hidden_units * 4,\n                kernel_size=3,\n                padding=1,\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_units * 4 * 4 * 4, hidden_units * 8),\n            nn.ReLU(),\n            nn.Linear(hidden_units * 8, hidden_units * 8),\n            nn.ReLU(),\n            nn.Linear(hidden_units * 8, n_classes),\n        )\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\n# Define Model\nmodel = cnn(input_shape=n_channels, hidden_units=16, output_shape=n_classes).to(device)\n\n\n# Setup loss and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# View Model\nmodel\n\ncnn(\n  (layer1): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer2): Sequential(\n    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (layer3): Sequential(\n    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer4): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer5): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=1024, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=128, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=128, out_features=9, bias=True)\n  )\n)\n\n\n\ntorch.manual_seed(42)\n\n# Measure Time\n\ntrain_time_start_model = timer()\n\niteration_loss_list = []\niteration_accuracy_list = []\n\n# set parameters\nepochs = 10\nbest_loss = 10\n\n# call train and test function\nfor epoch in tqdm(range(epochs)):\n    train_loss, train_acc = train_step(\n        data_loader=train_dataloader,\n        model=model,\n        loss_fn=loss_fn,\n        optimizer=optimizer,\n        accuracy_fn=accuracy_fn,\n        device=device1,\n    )\n\n    test_loss, test_acc = test_step(\n        data_loader=test_dataloader,\n        model=model,\n        loss_fn=loss_fn,\n        accuracy_fn=accuracy_fn,\n        device=device1,\n    )\n\n    for iteration, (x, y) in enumerate(train_dataloader):\n        iteration_loss_list.append(train_loss.item())\n        iteration_accuracy_list.append(train_acc)\n\n    print(\n        f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\"\n    )\n\n    # save best model instance\n\n    if test_loss &lt; best_loss:\n        best_loss = test_loss\n        print(f\"Saving best model for epoch: {epoch}\")\n        torch.save(obj=model.state_dict(), f=\"./model.pth\")\n\n\ntrain_time_end_model = timer()\ntotal_train_time_model = print_train_time(\n    start=train_time_start_model, end=train_time_end_model, device=device1\n)\n\n\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[17], line 33\n     16 train_loss, train_acc = train_step(\n     17     data_loader=train_dataloader,\n     18     model=model,\n   (...)\n     22     device=device1,\n     23 )\n     25 test_loss, test_acc = test_step(\n     26     data_loader=test_dataloader,\n     27     model=model,\n   (...)\n     30     device=device1,\n     31 )\n---&gt; 33 for iteration, (x, y) in enumerate(train_dataloader):\n     34     iteration_loss_list.append(train_loss.item())\n     35     iteration_accuracy_list.append(train_acc)\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630, in _BaseDataLoaderIter.__next__(self)\n    627 if self._sampler_iter is None:\n    628     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    629     self._reset()  # type: ignore[call-arg]\n--&gt; 630 data = self._next_data()\n    631 self._num_yielded += 1\n    632 if self._dataset_kind == _DatasetKind.Iterable and \\\n    633         self._IterableDataset_len_called is not None and \\\n    634         self._num_yielded &gt; self._IterableDataset_len_called:\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673, in _SingleProcessDataLoaderIter._next_data(self)\n    671 def _next_data(self):\n    672     index = self._next_index()  # may raise StopIteration\n--&gt; 673     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    674     if self._pin_memory:\n    675         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52, in _MapDatasetFetcher.fetch(self, possibly_batched_index)\n     50         data = self.dataset.__getitems__(possibly_batched_index)\n     51     else:\n---&gt; 52         data = [self.dataset[idx] for idx in possibly_batched_index]\n     53 else:\n     54     data = self.dataset[possibly_batched_index]\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52, in &lt;listcomp&gt;(.0)\n     50         data = self.dataset.__getitems__(possibly_batched_index)\n     51     else:\n---&gt; 52         data = [self.dataset[idx] for idx in possibly_batched_index]\n     53 else:\n     54     data = self.dataset[possibly_batched_index]\n\nFile ~/.local/lib/python3.10/site-packages/medmnist/dataset.py:138, in MedMNIST2D.__getitem__(self, index)\n    132 \"\"\"\n    133 return: (without transform/target_transofrm)\n    134     img: PIL.Image\n    135     target: np.array of `L` (L=1 for single-label)\n    136 \"\"\"\n    137 img, target = self.imgs[index], self.labels[index].astype(int)\n--&gt; 138 img = Image.fromarray(img)\n    140 if self.as_rgb:\n    141     img = img.convert(\"RGB\")\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3304, in fromarray(obj, mode)\n   3301         msg = \"'strides' requires either tobytes() or tostring()\"\n   3302         raise ValueError(msg)\n-&gt; 3304 return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3206, in frombuffer(mode, size, data, decoder_name, *args)\n   3203         im.readonly = 1\n   3204         return im\n-&gt; 3206 return frombytes(mode, size, data, decoder_name, args)\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3138, in frombytes(mode, size, data, decoder_name, *args)\n   3135 _check_size(size)\n   3137 im = new(mode, size)\n-&gt; 3138 if im.width != 0 and im.height != 0:\n   3139     decoder_args: Any = args\n   3140     if len(decoder_args) == 1 and isinstance(decoder_args[0], tuple):\n   3141         # may pass tuple instead of argument list\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:559, in Image.height(self)\n    555 @property\n    556 def width(self) -&gt; int:\n    557     return self.size[0]\n--&gt; 559 @property\n    560 def height(self) -&gt; int:\n    561     return self.size[1]\n    563 @property\n    564 def size(self) -&gt; tuple[int, int]:\n\nKeyboardInterrupt: \n\n\n\n\n# Load model\nloaded_model = cnn(input_shape=n_channels, hidden_units=16, output_shape=n_classes).to(\n    device\n)\n\nloaded_model.load_state_dict(torch.load(f=\"./model.pth\"))\n\n# get results\nmodel_results = eval_func(\n    data_loader=val_dataloader,\n    model=loaded_model,\n    loss_fn=loss_fn,\n    accuracy_fn=accuracy_fn,\n    device=device,\n)\n\nmodel_results\n\n\n# Get Model predictions and true targets\ny_targets = model_results[\"targets\"]\ny_preds = model_results[\"predictions\"]\n\n# Setup confusion matrix\nconfmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\nconfmat_tensor = confmat(preds=y_preds, target=y_targets)\n\n# Plot the confusion matrix\nfix, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), class_names=class_names, figsize=(10, 7)\n)\n\n\n# Get Model predictions and true targets\ny_targets = model_results[\"targets\"]\ny_preds = model_results[\"predictions\"]\n\n# Setup confusion matrix\nconfmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\nconfmat_tensor = confmat(preds=y_preds, target=y_targets)\n\n# Plot the confusion matrix\nfix, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), class_names=class_names, figsize=(10, 7)\n)"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html",
    "href": "laboratorios/APSB/lab01_Linux.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes serán capaces de aplicar comandos esenciales de Linux para la manipulación de archivos, gestión de procesos y análisis de datos biomédicos.\n\n\n\n1.5 horas\n\n\n\n\nComputador con Linux (instalado o máquina virtual), WSL2 con Ubuntu, o emulado.\nHoja de trucos de Linux.\nArchivo de datos biomédicos en formato .csv (proporcionado).\n\n\n\n\n\n\n\n\nExplora los archivos y directorios disponibles en el sistema.\nCrea una estructura de directorios organizada para almacenar datos biomédicos.\nMueve y organiza el archivo de datos de pacientes dentro de la estructura creada.\nModifica los permisos del archivo para restringir o permitir accesos según corresponda.\n\nPreguntas de reflexión:\n- ¿Por qué es importante organizar archivos en un entorno de trabajo biomédico?\n- ¿Cómo podrías utilizar permisos de archivos para proteger datos de pacientes en un hospital?\n\n\n\n\n\n\n\n\nExamina las primeras líneas del archivo de pacientes para entender su estructura.\nCuenta la cantidad total de registros para determinar el número de pacientes.\nFiltra los registros de pacientes con presión arterial alta.\nOrdena los pacientes por edad para identificar a los de mayor edad.\nExtrae información relevante, como edad y frecuencia cardíaca, y guárdala en un nuevo archivo.\n\nPreguntas de análisis:\n- ¿Cómo podríamos automatizar estos análisis para realizarlos diariamente en un hospital?\n- ¿Qué otros patrones en los datos podríamos detectar utilizando solo comandos de Linux?\n\n\n\n\n\n\n\n\nEscribe un script en python que realice los análisis anteriores y guarde los resultados en un archivo de reporte.\nAsigna los permisos adecuados al script para poder ejecutarlo.\nEjecuta el script y verifica el contenido del reporte generado.\n\nReflexión final:\n- ¿Cómo podríamos modificar el script para hacerlo más interactivo?\n- ¿Cómo podríamos programarlo para que se ejecute automáticamente cada cierto tiempo?\n\n\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nDescripción\nPuntos\n\n\n\n\nUso de comandos básicos\nAplicación correcta de comandos de navegación y manipulación de archivos\n20\n\n\nProcesamiento de datos\nUso adecuado de herramientas para análisis de datos\n30\n\n\nAutomatización con scripts\nCreación y ejecución correcta de un script funcional\n30\n\n\nReflexión y análisis\nRespuestas argumentadas a preguntas de reflexión\n20\n\n\n\nTotal: 100 puntos.\n\nEsta actividad permite a los estudiantes desarrollar habilidades prácticas en Linux con aplicaciones directas en bioinformática y análisis de datos biomédicos."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#objetivo-de-aprendizaje",
    "href": "laboratorios/APSB/lab01_Linux.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes serán capaces de aplicar comandos esenciales de Linux para la manipulación de archivos, gestión de procesos y análisis de datos biomédicos."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#duración",
    "href": "laboratorios/APSB/lab01_Linux.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "1.5 horas"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#materiales",
    "href": "laboratorios/APSB/lab01_Linux.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador con Linux (instalado o máquina virtual), WSL2 con Ubuntu, o emulado.\nHoja de trucos de Linux.\nArchivo de datos biomédicos en formato .csv (proporcionado)."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-1-exploración-y-gestión-de-archivos-30-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-1-exploración-y-gestión-de-archivos-30-min",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Explora los archivos y directorios disponibles en el sistema.\nCrea una estructura de directorios organizada para almacenar datos biomédicos.\nMueve y organiza el archivo de datos de pacientes dentro de la estructura creada.\nModifica los permisos del archivo para restringir o permitir accesos según corresponda.\n\nPreguntas de reflexión:\n- ¿Por qué es importante organizar archivos en un entorno de trabajo biomédico?\n- ¿Cómo podrías utilizar permisos de archivos para proteger datos de pacientes en un hospital?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-2-procesamiento-de-datos-biomédicos-en-la-terminal-40-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-2-procesamiento-de-datos-biomédicos-en-la-terminal-40-min",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Examina las primeras líneas del archivo de pacientes para entender su estructura.\nCuenta la cantidad total de registros para determinar el número de pacientes.\nFiltra los registros de pacientes con presión arterial alta.\nOrdena los pacientes por edad para identificar a los de mayor edad.\nExtrae información relevante, como edad y frecuencia cardíaca, y guárdala en un nuevo archivo.\n\nPreguntas de análisis:\n- ¿Cómo podríamos automatizar estos análisis para realizarlos diariamente en un hospital?\n- ¿Qué otros patrones en los datos podríamos detectar utilizando solo comandos de Linux?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-3-automatización-con-scripts-20-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-3-automatización-con-scripts-20-min",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Escribe un script en python que realice los análisis anteriores y guarde los resultados en un archivo de reporte.\nAsigna los permisos adecuados al script para poder ejecutarlo.\nEjecuta el script y verifica el contenido del reporte generado.\n\nReflexión final:\n- ¿Cómo podríamos modificar el script para hacerlo más interactivo?\n- ¿Cómo podríamos programarlo para que se ejecute automáticamente cada cierto tiempo?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#criterios-de-evaluación",
    "href": "laboratorios/APSB/lab01_Linux.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Criterio\nDescripción\nPuntos\n\n\n\n\nUso de comandos básicos\nAplicación correcta de comandos de navegación y manipulación de archivos\n20\n\n\nProcesamiento de datos\nUso adecuado de herramientas para análisis de datos\n30\n\n\nAutomatización con scripts\nCreación y ejecución correcta de un script funcional\n30\n\n\nReflexión y análisis\nRespuestas argumentadas a preguntas de reflexión\n20\n\n\n\nTotal: 100 puntos.\n\nEsta actividad permite a los estudiantes desarrollar habilidades prácticas en Linux con aplicaciones directas en bioinformática y análisis de datos biomédicos."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 4, 2025. The defense will be carried out by one of the team members chosen at random.\nThe python libraries allow for this laboratory are: matplotlib and random"
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 1: Mean and Median",
    "text": "Exercise 1: Mean and Median\nWrite a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g. normal, binomial)."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes’ Theorem",
    "text": "Exercise 6: Bayes’ Theorem\nWrite a Python program that applies Bayes’ theorem to update the probability of a hypothesis given new evidence."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g. normal, uniform)."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10:Function visualization - I",
    "text": "Exercise 10:Function visualization - I\nGenerate a python code that allows the visualization (in one figure) of the real (blue) part and the imaginary (red) part, magnitude (green) and phase of the following signals:\n\\[f\\left(t\\right) = e^{-j10 \\pi t}\\]\n\\[g\\left(t\\right) = 10cos\\left(2 \\pi t\\right) + j10sin\\left(2 \\pi t\\right)\\]\nThe visualization mus be in the range \\(\\left[-10, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 6, 2025. The defense will be carried out by one of the team members chosen at random."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 1: Mean and Median",
    "text": "Exercise 1: Mean and Median\nWrite a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g. normal, binomial)."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes’ Theorem",
    "text": "Exercise 6: Bayes’ Theorem\nWrite a Python program that applies Bayes’ theorem to update the probability of a hypothesis given new evidence."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g. normal, uniform)."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10:Function visualization - I",
    "text": "Exercise 10:Function visualization - I\nGenerate a python code that allows the visualization (in one figure) of the real (blue) part and the imaginary (red) part, magnitude (green) and phase of the following signals:\n\\[f\\left(t\\right) = e^{-j10 \\pi t}\\]\n\\[g\\left(t\\right) = 10cos\\left(2 \\pi t\\right) + j10sin\\left(2 \\pi t\\right)\\]\nThe visualization must be in the range of t \\(\\left[-10, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab04_ImagProc02.html",
    "href": "laboratorios/PSIM/Previous/lab04_ImagProc02.html",
    "title": "Algoritmos básicos de procesamiento de imágenes",
    "section": "",
    "text": "Usando la imagen fresas.png la cual fue tomada de la página Geeks for geeks resuelva las siguientes cuestiones.\n\nAplique las siguientes transformaciones y describa el efecto de cada transformación:\n\nTransformación n-potencial con \\(1&lt;n&lt;2\\)\nTransformación n-potencial con \\(0.5&lt;n&lt;1\\)\nTransformación LOG (Logaritmo Natural)\nTransformación exponencial\nDescriba en un diagrama de bloques el algoritmo necesario para realizar este tipo de transformaciones.\nInvestigue y desarrolle el algoritmo de la transformación \\(\\Gamma\\). La información básica la puede encontrar aqui\n\n\nRecuerde: Si una imagen queda completamente blanca o completamente negra, es probable que sea por mal manejo de rangos de intensidad\n\nSea los siguientes kernels de convolución:\n\n\\(\\begin{bmatrix}\n1 & 1 & 1 \\\\\n1 & -8 & 1 \\\\\n1 & 1 & 1\n\\end{bmatrix}\\)\n\\(\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n-1 & 8 & -1 \\\\\n-1 & -1 & -1\n\\end{bmatrix}\\)\n\n\nExplique las siguientes cuestiones:\n\nInvestigue las formas de realizar la convolución con opencv.\nAplique cada uno de los kernels de convolución y compare los resultados.\nExplique cuales son las respectivas resoluciónes de pixel de las imagenes resultantes así como su máximo y su mínimo.\n\n\nUtilizando la imagen radiografía, aplique cada tipo de matriz afine presente en las diapositivas de clase\nDeterminar proyecto final para PSIM.\n\nDeterminar el problema a resolver.\nDeterminar el objetivo a alcanzar\nDeterminar el dataset\n\n\nRecuerde, en su proyecto final, NO podrá hacer uso de algoritmos de machine learning."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab02_SignalProcessing.html",
    "href": "laboratorios/PSIM/Previous/lab02_SignalProcessing.html",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "href": "laboratorios/PSIM/Previous/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab02_SignalProcessing.html#requisitos",
    "href": "laboratorios/PSIM/Previous/lab02_SignalProcessing.html#requisitos",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Requisitos:",
    "text": "Requisitos:\n\nIdentificar un problema de salud específico y relevante, relacionado con los ODS.\nJustificar la importancia del problema y la necesidad de una solución innovadora.\nEstablecer objetivos claros y medibles para el proyecto.\nElegir un dataset apropiado de señales (1D).\nDesarrollar una solución técnica que satisfaga los indicadores de solución de problema, con descripción matemática, física y/o estadística.\nImplementar la solución en Python."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "href": "laboratorios/PSIM/Previous/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Rúbrica de evaluación",
    "text": "Rúbrica de evaluación\n\n\n\n\n\n\n\n\n\n\nCriterio\nPuntos\nBueno\nRegular\nMalo\n\n\n\n\nProblema de salud identificado\n15\nProblema claro, relevante y bien justificado (15puntos)\nProblema claro, pero justificación débil (7puntos)\nProblema no claro o no relevante (0puntos)\n\n\nJustificación y objetivos\n15\nJustificación sólida y objetivos claros y medibles (15puntos)\nJustificación débil y objetivos poco claros (7puntos)\nJustificación y objetivos no claros (0puntos)\n\n\nSolución técnica\n20\nSolución innovadora, bien fundamentada y correctamente implementada en Python (20puntos)\nSolución adecuada, pero con errores en la implementación (10puntos)\nSolución no innovadora o con errores graves (0puntos)\n\n\nDiseño de indicadores\n20\nIndicadores bien definidos, con descripción matemática, médica y estadística clara y precisa (20puntos)\nIndicadores bien definidos, pero con descripción no clara o incompleta (10puntos)\nIndicadores no bien definidos o sin descripción (0puntos)\n\n\nContribución a los ODS\n10\nContribución clara y significativa a los ODS (10puntos)\nContribución moderada a los ODS (7puntos)\nContribución no clara o nula a los ODS (0puntos)\n\n\nImpacto potencial en la salud\n10\nImpacto potencial alto y bien justificado (10puntos)\nImpacto potencial moderado y justificación débil (7puntos)\nImpacto potencial bajo o no justificado (0puntos)\n\n\nPresentación y documentación\n10\nPresentación clara y documentación precisa y completa (10puntos)\nPresentación clara, pero documentación no precisa (7puntos)\nPresentación no clara o documentación no está presente (0puntos)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/Proyecto_Final_2024-2.html",
    "href": "laboratorios/PSIM/Previous/Proyecto_Final_2024-2.html",
    "title": "Proyecto Final: PSIM 2024-1",
    "section": "",
    "text": "Horarios de Sustentación\n\n\nMonitoría del Curso\nKevin Martínez\n\n\nRúbrica\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (100%)\nBueno (80%)\nRegular (60%)\nInsuficiente (40%)\nNo presentado (0%)\n\n\n\n\nUso de técnicas de procesamiento de imágenes o señales\nDemuestra un dominio profundo y una aplicación adecuada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nDemuestra una comprensión sólida y una aplicación adecuada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nDemuestra una comprensión básica y una aplicación limitada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nDemuestra una comprensión deficiente y una aplicación inadecuada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nNo se evidencia la aplicación de técnicas de procesamiento de imágenes o señales.\n\n\nCoherencia entre objetivos y resultados\nLos objetivos del proyecto están claramente definidos y alineados con los resultados obtenidos.\nLos objetivos del proyecto están definidos y alineados en gran medida con los resultados obtenidos.\nLos objetivos del proyecto están definidos, pero no se alinean completamente con los resultados obtenidos.\nLos objetivos del proyecto están poco definidos y no se alinean con los resultados obtenidos.\nNo se definen objetivos para el proyecto.\n\n\nTiempo de exposición\nLa exposición del proyecto es clara, concisa y organizada, permitiendo una comprensión completa del trabajo realizado.\nLa exposición del proyecto es clara y organizada, permitiendo una buena comprensión del trabajo realizado.\nLa exposición del proyecto es clara, pero con algunas deficiencias en la organización, lo que dificulta la comprensión completa del trabajo realizado.\nLa exposición del proyecto es poco clara y desorganizada, lo que dificulta la comprensión del trabajo realizado.\nNo se realiza una exposición del proyecto.\n\n\nPresentación\nLa presentación del proyecto es visualmente atractiva, profesional y utiliza recursos multimedia de manera efectiva para comunicar los resultados.\nLa presentación del proyecto es visualmente atractiva y profesional, utilizando algunos recursos multimedia para comunicar los resultados.\nLa presentación del proyecto es visualmente aceptable, pero con algunos errores o falta de recursos multimedia para comunicar los resultados.\nLa presentación del proyecto es poco visualmente atractiva, con errores y falta de recursos multimedia para comunicar los resultados.\nNo se realiza una presentación del proyecto.\n\n\nNivel de la codificación\nEl código está bien escrito, documentado, organizado y utiliza las mejores prácticas de programación.\nEl código está bien escrito, documentado y organizado.\nEl código está escrito, pero con algunas deficiencias en la documentación y organización.\nEl código está escrito de manera deficiente, con mala documentación y organización.\nEl código no está escrito o está escrito de manera no funcional.\n\n\nCreatividad en el algoritmo\nEl algoritmo utilizado en el proyecto es novedoso, original y efectivo para resolver el problema planteado.\nEl algoritmo utilizado en el proyecto es creativo, original y efectivo para resolver el problema planteado.\nEl algoritmo utilizado en el proyecto es creativo, pero con algunas limitaciones en su originalidad o efectividad.\nEl algoritmo utilizado en el proyecto es poco creativo, con limitaciones en su originalidad y efectividad.\nEl algoritmo utilizado en el proyecto no es creativo ni efectivo para resolver el problema planteado.\n\n\nTrabajo en equipo\nSe evidencia un trabajo en equipo efectivo, con una clara división de roles, comunicación constante y colaboración entre los miembros del equipo.\nSe evidencia un trabajo en equipo colaborativo, con una clara división de roles y comunicación entre los miembros del equipo.\nSe evidencia un trabajo en equipo con algunas dificultades en la colaboración o comunicación entre los miembros del equipo.\nSe evidencia un trabajo en equipo deficiente, con falta de colaboración y comunicación entre los miembros del equipo.\nNo se evidencia un trabajo en equipo.\n\n\nTrabajo individual\nCada miembro del equipo demuestra un alto nivel de compromiso, responsabilidad y contribución individual al proyecto.\nCada miembro del equipo demuestra un buen nivel de compromiso, responsabilidad y contribución individual al proyecto.\nCada miembro del equipo demuestra un nivel aceptable de compromiso, responsabilidad y contribución individual al proyecto.\nCada miembro del equipo demuestra un bajo nivel de compromiso, responsabilidad y contribución individual al proyecto.\nNo se evidencia el trabajo individual de los miembros del equipo."
  },
  {
    "objectID": "clases/Class_APSB.html",
    "href": "clases/Class_APSB.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Procesamiento en Tiempo Real\nEn entornos biomédicos, muchas aplicaciones requieren procesamiento en tiempo real, como el monitoreo de pacientes críticos, análisis de imágenes médicas (por ejemplo, ultrasonido, radiografías) y dispositivos portátiles. Edge AI permite procesar datos localmente, reduciendo la latencia en comparación con el envío de datos a servidores remotos. Ejemplo: Un dispositivo portátil para monitoreo continuo de ECG puede detectar arritmias en tiempo real sin depender de una conexión a internet.\nMayor Privacidad y Seguridad\nLos datos médicos son altamente sensibles y están protegidos por regulaciones estrictas (como la HIPAA o el GDPR). Edge AI permite que los datos se procesen y almacenen localmente, minimizando el riesgo de violaciones de seguridad o filtraciones. Ejemplo: Un sensor de glucosa implantable que analiza niveles de glucosa sin enviar los datos a la nube asegura mayor privacidad del paciente.\nReducción de Costos Operativos\nEl procesamiento en el borde elimina la necesidad de transmitir grandes volúmenes de datos a servidores en la nube, lo que reduce costos relacionados con la conectividad y el almacenamiento en línea. Ejemplo: Un sistema de detección de caídas para personas mayores puede analizar los datos del acelerómetro directamente en el dispositivo sin enviar grandes volúmenes de datos a la nube.\nAplicaciones en Zonas Remotas\nEn áreas rurales o zonas con conectividad limitada, Edge AI permite el uso de dispositivos médicos avanzados sin depender de conexiones de internet robustas. Ejemplo: Una máquina portátil de ultrasonido que utiliza Edge AI para interpretar imágenes en tiempo real podría usarse en campañas de salud en comunidades remotas.\nEficiencia Energética\nLos modelos de Edge AI están diseñados para operar en dispositivos de bajo consumo energético, lo que es ideal para dispositivos médicos portátiles y sistemas implantables. Ejemplo: Monitores de salud wearables, como relojes inteligentes o biosensores, que analizan parámetros fisiológicos continuamente.\nPersonalización y Adaptación en el Lugar\nLos modelos de Edge AI pueden adaptarse a los datos del usuario en tiempo real, permitiendo personalización sin enviar datos sensibles a servidores externos. Ejemplo: Un dispositivo de rehabilitación motora que analiza el movimiento del paciente y ajusta los ejercicios en tiempo real según su progreso.\nInterdisciplinariedad y Tendencia Futurista\nLa integración de Edge AI con la ingeniería biomédica fomenta una combinación única de hardware, software y conocimiento médico, lo que te posiciona en el centro de las innovaciones tecnológicas en salud.\nEl curso está dividido en 4 partes:\n1. Introducción a inteligencia artificial en el borde (EDGE AI).\n2. Hardware y software para EDGE AI.\n3. El flujo de trabajo de EDGE AI.\n4. Diseño, desarrollo y evaluación de sistemas EDGE AI."
  },
  {
    "objectID": "clases/Class_APSB.html#presentaciones",
    "href": "clases/Class_APSB.html#presentaciones",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción 1/2\nIntroducción 2/2\nLinux\nMetodología de desarrollo\nIntroducción al machine learning\nFlujo de trabajo para proyectos de machine learning"
  },
  {
    "objectID": "clases/Class_APSB.html#datos",
    "href": "clases/Class_APSB.html#datos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_APSB.html#códigos",
    "href": "clases/Class_APSB.html#códigos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_APSB.html#laboratorios",
    "href": "clases/Class_APSB.html#laboratorios",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio001: Conociendo LINUX."
  },
  {
    "objectID": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores"
  },
  {
    "objectID": "clases/Class_APSB.html#clases",
    "href": "clases/Class_APSB.html#clases",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Clases",
    "text": "Clases\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201."
  },
  {
    "objectID": "clases/Class_SYSB.html",
    "href": "clases/Class_SYSB.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "El estudio del procesamiento de señales es fundamental en la ingeniería biomédica debido a la amplia variedad de aplicaciones que tiene en el análisis, interpretación y mejora de datos biomédicos. A continuación, se presenta una justificación estructurada de su relevancia:\nNaturaleza de las señales biomédicas\nLas señales biomédicas, como las señales electrocardiográficas (ECG), electromiográficas (EMG), electroencefalográficas (EEG), o incluso imágenes médicas (resonancias magnéticas o tomografías), son complejas y están afectadas por ruido y artefactos.\nEl procesamiento de señales permite extraer información útil, filtrar interferencias y maximizar la calidad de los datos obtenidos.\nDiagnóstico y monitoreo\nLas señales biomédicas son esenciales para el diagnóstico de enfermedades y el monitoreo continuo de pacientes. Por ejemplo, el procesamiento de un ECG ayuda a detectar arritmias, mientras que el análisis de un EEG puede identificar epilepsia o trastornos del sueño.\nEn entornos de cuidado intensivo, el procesamiento en tiempo real de señales vitales garantiza decisiones clínicas rápidas y precisas.\nOptimización de dispositivos biomédicos\nEl diseño de dispositivos biomédicos como marcapasos, desfibriladores implantables y prótesis inteligentes requiere algoritmos avanzados de procesamiento de señales para interpretar datos en tiempo real y responder adecuadamente a las necesidades del paciente.\nAvances en tecnología médica\nTecnologías emergentes como el análisis de datos en telemedicina, dispositivos portátiles (wearables) y sistemas de salud móvil (mHealth) dependen del procesamiento de señales para garantizar la precisión y la utilidad de la información presentada.\nIntegración con otras disciplinas\nEl procesamiento de señales se combina con inteligencia artificial y aprendizaje automático para desarrollar modelos predictivos, clasificar patrones patológicos y personalizar tratamientos.\nInvestigación en fisiología y biomecánica\nEl análisis avanzado de señales contribuye a la comprensión profunda de procesos fisiológicos complejos, como la dinámica del corazón, el cerebro o el sistema musculoesquelético.\nEducación y competencias profesionales\nLa formación en procesamiento de señales biomédicas dota a los futuros ingenieros de herramientas matemáticas y computacionales para enfrentar problemas del mundo real, desarrollar soluciones innovadoras y avanzar en el campo de la ingeniería biomédica.\nEl curso está dividido en 5 partes:\n1. Introducción al procesado de señales.\n2. Conceptos de señales contínuas & discretas.\n3. Muestreo.\n4. Extracción de características de una señal.\n5. Filtraje de señales."
  },
  {
    "objectID": "clases/Class_SYSB.html#presentaciones",
    "href": "clases/Class_SYSB.html#presentaciones",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción\nClasificacion de sañales\nSeñales Notables 1/2\nSeñales Notables 2/2\nAdquisición y Muestreo\nFiltros Digitales\nContenido Frecuencial"
  },
  {
    "objectID": "clases/Class_SYSB.html#datos",
    "href": "clases/Class_SYSB.html#datos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_SYSB.html#códigos",
    "href": "clases/Class_SYSB.html#códigos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorios",
    "href": "clases/Class_SYSB.html#laboratorios",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLAB01: Código python, estadística, y números complejos.\nLAB02: El electrocardiograma. Fundamentos Teóricos.\nLAB03: Análisis de información base del dataset (Demografía y estadística inicial)"
  },
  {
    "objectID": "clases/Class_SYSB.html#grupos-2025-1",
    "href": "clases/Class_SYSB.html#grupos-2025-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Grupos 2025-1",
    "text": "Grupos 2025-1\n\n\n\n\n\n\n\n\n\nID Estudiante\nNombre\nCorreo Electrónico\nGrupo\n\n\n\n\n 1000098844\nCRISTIAN STIVEN CAPERA CERQUERA\ncristian.capera-c@mail.escuelaing.edu.co\nA\n\n\n 1000044331\nMARIA ALEJANDRA URIBE RODRIGUEZ\nmaria.uribe-r@mail.escuelaing.edu.co\nA\n\n\n 1000098887\nNICOLE JULIANA AYURE MATAMOROS\nnicole.ayure-m@mail.escuelaing.edu.co\nA\n\n\n 1000097259\nJENNIFER SOFIA SANCHEZ RAMOS\njennifer.sanchez-r@mail.escuelaing.edu.co\nB\n\n\n 1000097273\nMARIA JOSE PIÑEROS ACUÑA\nmaria.pineros-a@mail.escuelaing.edu.co\nB\n\n\n 1000097287\nMARÍA JOSÉ HERNÁNDEZ GUERRA\nmaria.hguerra@mail.escuelaing.edu.co\nB\n\n\n 1000099348\nJAIME LEONARDO CALDERÓN BETANCURT\njaime.calderon-b@mail.escuelaing.edu.co\nC\n\n\n 1000098221\nLAURA CAMILA REYES MUÑOZ\nlaura.reyes-m@mail.escuelaing.edu.co\nC\n\n\n 1000045047\nDANIEL FELIPE BRU MENESES\ndaniel.bru@mail.escuelaing.edu.co\nD\n\n\n 1000053815\nKEVIN DANIEL BEJARANO OSORIO\nkevin.bejarano@mail.escuelaing.edu.co\nD\n\n\n 1000046321\nSANTIAGO ACUÑA MONCADA\nsantiago.acuna@mail.escuelaing.edu.co\nD\n\n\n 1000095641\nANA SOFIA GRANADA LEIVA\nana.granada-l@mail.escuelaing.edu.co\nE\n\n\n 1000092619\nLUISA FERNANDA PEREZ SALGADO\nluisa.perez-s@mail.escuelaing.edu.co\nE\n\n\n 1000094974\nMARIA FERNANDA GOMEZ CUBIDES\nmaria.gcubides@mail.escuelaing.edu.co\nF\n\n\n 1000095693\nMARÍA PAULA CORTES AVILA\nmaria.cortes-a@mail.escuelaing.edu.co\nF\n\n\n 1000053831\nLUISA LORETTA VERGARA ROMERO\nluisa.vergara-r@mail.escuelaing.edu.co\nG\n\n\n 1000095027\nPAULA MELISSA MARTINEZ BARRERA\npaula.martinez-b@mail.escuelaing.edu.co\nG\n\n\n 1000095101\nSANTIAGO PATIÑO MEJIA\nsantiago.pmejia@mail.escuelaing.edu.co\nG\n\n\n 1000098222\nJULIANA MAYORGA AVILA\njuliana.mayorga-a@mail.escuelaing.edu.co\nH\n\n\n 1000099556\nMARIANA FRANCO CARO\nmariana.franco-c@mail.escuelaing.edu.co\nH\n\n\n 1000098162\nMARÍA PAULA GÓMEZ NIÑO\nmaria.gomez-n@mail.escuelaing.edu.co\nI"
  },
  {
    "objectID": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nTaller1: Introduccion al procesamiento de señales\nPrimer Parcial 2025-1 A\nPrimer Parcial 2025-1 B"
  },
  {
    "objectID": "clases/Class_SYSB.html#clases",
    "href": "clases/Class_SYSB.html#clases",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Clases",
    "text": "Clases\nLunes: 10:00am-11:30am. F204. Jueves: 10:00am-11:30am. F206."
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorio",
    "href": "clases/Class_SYSB.html#laboratorio",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laboratorio",
    "text": "Laboratorio\nMartes: 10:00am-11:30am. I1-308."
  },
  {
    "objectID": "clases/Class_SYSB.html#atención-a-estudiantes",
    "href": "clases/Class_SYSB.html#atención-a-estudiantes",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes\nGrupo 80:\nGrupo 81:"
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html",
    "href": "clases/Class_NumericalAnalysis.html",
    "title": "Análisis Numérico",
    "section": "",
    "text": "El análisis numérico es una rama de las matemáticas y la ciencia computacional que se enfoca en desarrollar algoritmos y técnicas para resolver problemas matemáticos mediante aproximaciones numéricas. Su objetivo es encontrar soluciones aproximadas a problemas que pueden ser difíciles o imposibles de resolver de manera exacta debido a su complejidad o naturaleza continua."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#física",
    "href": "clases/Class_NumericalAnalysis.html#física",
    "title": "Análisis Numérico",
    "section": "Física",
    "text": "Física\n\nSimulación de sistemas dinámicos\nMuchos sistemas físicos son gobernados por ecuaciones diferenciales que describen su comportamiento en el tiempo. Sin embargo, en muchos casos, estas ecuaciones son demasiado complejas para obtener soluciones analíticas. Aquí es donde entra en juego el análisis numérico, que permite simular el comportamiento de estos sistemas mediante la resolución numérica de las ecuaciones diferenciales. Por ejemplo, en la mecánica clásica, se pueden simular sistemas de partículas bajo la influencia de fuerzas gravitacionales o electromagnéticas para estudiar movimientos planetarios, trayectorias de proyectiles, etc. También en la mecánica cuántica, se pueden simular sistemas de partículas subatómicas para comprender su comportamiento y propiedades.\n\n\nResolución de problemas de transferencia de calor y fluidos\nEn la física, es común enfrentarse a problemas que involucran la transferencia de calor o el flujo de fluidos en sistemas complejos, como en la termodinámica, la hidrodinámica o la aerodinámica. Estos problemas a menudo están representados por ecuaciones diferenciales parciales, las cuales son difíciles o imposibles de resolver analíticamente. Aquí, el análisis numérico se convierte en una herramienta esencial para resolver estas ecuaciones y obtener soluciones aproximadas. Mediante técnicas como la simulación de Monte Carlo o los métodos de elementos finitos, es posible estudiar el comportamiento térmico y fluido de sistemas complejos, como la distribución de temperatura en un motor o la aerodinámica de un avión, lo que es crucial para el diseño y la optimización de muchos dispositivos y sistemas en la ingeniería y la industria."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#ingeniería",
    "href": "clases/Class_NumericalAnalysis.html#ingeniería",
    "title": "Análisis Numérico",
    "section": "Ingeniería",
    "text": "Ingeniería\n\nAnálisis estructural y diseño de ingeniería\nEn la ingeniería civil y mecánica, el análisis numérico es fundamental para el análisis y diseño de estructuras como puentes, edificios, presas, aviones, automóviles, entre otros. El método de elementos finitos (MEF) es una de las técnicas más utilizadas en esta área. Permite dividir estructuras complejas en elementos más pequeños, como triángulos o tetraedros, y aproximadamente resolver las ecuaciones de equilibrio y comportamiento mecánico de cada elemento. Estos métodos numéricos permiten calcular deformaciones, tensiones y cargas en las estructuras, así como determinar su resistencia, estabilidad y seguridad, lo que es crucial para garantizar que las construcciones sean seguras y eficientes.\n\n\nSimulación y modelado en ingeniería\nOtra aplicación importante del análisis numérico en la ingeniería es la simulación y modelado de sistemas complejos. Por ejemplo, en la ingeniería aeroespacial, se utilizan técnicas numéricas para simular el flujo de aire alrededor de aviones o cohetes, lo que permite estudiar la aerodinámica y optimizar el diseño de las aeronaves. En la ingeniería eléctrica, el análisis numérico se emplea para simular circuitos electrónicos complejos y analizar su comportamiento en diferentes condiciones. En la ingeniería química, se utilizan métodos numéricos para simular procesos de transporte de masa y calor en reactores y separadores. Estas simulaciones numéricas permiten a los ingenieros comprender mejor el comportamiento de sistemas complejos, realizar experimentos virtuales y realizar cambios de diseño de manera más rápida y económica antes de pasar a la fase de construcción y producción."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#economía",
    "href": "clases/Class_NumericalAnalysis.html#economía",
    "title": "Análisis Numérico",
    "section": "Economía",
    "text": "Economía\n\nModelado y simulación económica\nEl análisis numérico se utiliza extensamente para modelar y simular sistemas económicos complejos. Por ejemplo, en macroeconomía, se pueden desarrollar modelos computacionales que representen la interacción de múltiples variables económicas, como la inversión, el consumo, la inflación y el crecimiento económico. Estos modelos pueden ser sistemas de ecuaciones diferenciales o de diferencia que describen la dinámica de la economía a lo largo del tiempo. Mediante técnicas numéricas, como el método de Euler o métodos más sofisticados de resolución de ecuaciones diferenciales, se pueden realizar simulaciones para estudiar el comportamiento del sistema económico bajo diferentes condiciones y escenarios, lo que ayuda a los economistas a tomar decisiones informadas y entender mejor las implicaciones de las políticas económicas.\n\n\nValoración de activos financieros\nEn el ámbito financiero, el análisis numérico es esencial para la valoración de activos, como opciones, bonos y otros instrumentos financieros. Por ejemplo, en el mercado de opciones, los modelos de valoración de opciones, como el modelo Black-Scholes, implican resolver ecuaciones diferenciales parciales complejas. El análisis numérico permite calcular de manera eficiente los precios de las opciones y otros derivados financieros, lo que es crucial para los inversores, gestores de fondos y compañías que utilizan estos instrumentos para gestionar riesgos y tomar decisiones de inversión. Además, el análisis numérico es útil para calcular métricas financieras como el valor actual neto (VAN) y la tasa interna de retorno (TIR), que son fundamentales para la toma de decisiones en proyectos de inversión y evaluación de negocios."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#biología",
    "href": "clases/Class_NumericalAnalysis.html#biología",
    "title": "Análisis Numérico",
    "section": "Biología",
    "text": "Biología\n\nModelado de sistemas biológicos\nEl análisis numérico se utiliza para desarrollar modelos matemáticos que describen el comportamiento y la dinámica de sistemas biológicos. Por ejemplo, en la ecología, se pueden crear modelos que describan las interacciones entre diferentes especies en un ecosistema, incluidas las tasas de crecimiento, la competencia por recursos y la depredación. Estos modelos pueden ser representados mediante ecuaciones diferenciales o sistemas de ecuaciones que reflejen las relaciones entre las variables biológicas relevantes. El análisis numérico permite simular el comportamiento de estos sistemas y estudiar cómo cambian con el tiempo o en respuesta a cambios en las condiciones ambientales. Además, en la biología molecular, se utilizan modelos numéricos para simular la dinámica de sistemas bioquímicos, como redes de reacciones enzimáticas o interacciones entre moléculas, lo que es crucial para comprender los mecanismos subyacentes de procesos biológicos complejos.\n\n\nAnálisis de datos biológicos\nEn biología, se generan grandes cantidades de datos a partir de técnicas experimentales como la secuenciación genética, la microscopía y otros métodos de análisis molecular. El análisis numérico es esencial para procesar y analizar estos datos de manera eficiente y extraer información relevante. Por ejemplo, en bioinformática, se utilizan algoritmos numéricos para analizar secuencias de ADN y proteínas, identificar genes importantes, realizar análisis de expresión génica y buscar similitudes entre secuencias biológicas. Además, el análisis numérico se aplica en la imagenología médica para procesar imágenes de resonancia magnética (IRM), tomografía computarizada (TC) o imágenes microscópicas, lo que permite detectar patrones y características específicas en las imágenes que son relevantes para el diagnóstico y la investigación en biología y medicina."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#ciencia-de-datos",
    "href": "clases/Class_NumericalAnalysis.html#ciencia-de-datos",
    "title": "Análisis Numérico",
    "section": "Ciencia de datos",
    "text": "Ciencia de datos\n\nAprendizaje automático (Machine Learning)\nEl análisis numérico es esencial en el campo del aprendizaje automático, donde se utilizan algoritmos para entrenar modelos y hacer predicciones a partir de datos. En el aprendizaje supervisado, se utilizan técnicas numéricas para ajustar los parámetros de los modelos y minimizar la diferencia entre las predicciones y las salidas reales. Ejemplos de algoritmos de aprendizaje supervisado son las máquinas de soporte vectorial (SVM), regresión lineal, regresión logística, árboles de decisión, etc. Además, en el aprendizaje no supervisado, como el clustering y la reducción de dimensionalidad, se emplean técnicas numéricas para agrupar datos y encontrar estructuras ocultas en ellos. El análisis numérico permite realizar estos cálculos complejos de manera eficiente y precisa, lo que es crucial para el desarrollo y despliegue de modelos de aprendizaje automático en aplicaciones prácticas.\n\n\nAnálisis exploratorio de datos y visualización\nEn el análisis de datos, es común realizar tareas de exploración y visualización para entender mejor las características y patrones presentes en los conjuntos de datos. El análisis numérico es esencial para calcular resúmenes estadísticos, como promedios, medianas, desviaciones estándar y cuartiles, que proporcionan información valiosa sobre la distribución de los datos. Además, las técnicas de visualización de datos, como gráficos y diagramas, también se basan en el análisis numérico para representar de manera efectiva la información contenida en los datos. Algoritmos numéricos como el muestreo, la interpolación y la aproximación se utilizan para generar gráficos y visualizaciones informativas que facilitan la comprensión y toma de decisiones basadas en datos."
  },
  {
    "objectID": "clases/Class_ASIM.html",
    "href": "clases/Class_ASIM.html",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "",
    "text": "Aprender procesamiento de señales e imágenes con aprendizaje automático en medicina es crucial para mejorar la precisión y eficiencia en el diagnóstico y tratamiento de enfermedades. El aprendizaje automático permite analizar grandes cantidades de datos de imágenes médicas y señales biomédicas, como rayos X, tomografías computarizadas, resonancia magnética, ECG, EEG y EMG, para identificar patrones y anomalías que pueden indicar la presencia de enfermedades. Esto puede llevar a un diagnóstico más preciso y temprano, lo que a su vez puede mejorar los resultados para los pacientes y reducir la morbilidad y mortalidad.\nAdemás, el aprendizaje automático puede ayudar a personalizar tratamientos para pacientes individuales según sus características únicas de imágenes médicas y señales. También puede automatizar tareas clínicas rutinarias, como segmentación de imágenes, extracción de características y análisis de datos, lo que permite a los médicos centrarse en la toma de decisiones de alto nivel.\nLa aplicación del aprendizaje automático en medicina también puede facilitar la investigación médica, analizando grandes conjuntos de datos para identificar tendencias y patrones que pueden revelar nuevos conocimientos sobre enfermedades y tratamientos. Además, puede permitir la monitorización remota de pacientes y la telemedicina, ampliando el acceso a servicios de atención médica."
  },
  {
    "objectID": "clases/Class_ASIM.html#presentaciones",
    "href": "clases/Class_ASIM.html#presentaciones",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nLect002: Introducción al Machine Learning\nLect003: Introducción al Machine Learning\nLect004: Neural Network\nLect005: CNN"
  },
  {
    "objectID": "clases/Class_ASIM.html#laboratorios",
    "href": "clases/Class_ASIM.html#laboratorios",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLab00: Conducta de entrada\nLab01: Programación orientada a objetos\nSolución Lab01: Programación orientada a objetos\nLab02: Regresión lineal\nLab:03 Red Neuronal"
  },
  {
    "objectID": "clases/Class_ASIM.html#clases",
    "href": "clases/Class_ASIM.html#clases",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Clases",
    "text": "Clases\nSábado 7:00am-8:30am I1-304."
  },
  {
    "objectID": "clases/Class_ASIM.html#laboratorio",
    "href": "clases/Class_ASIM.html#laboratorio",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Laboratorio",
    "text": "Laboratorio\nSábado 8:30am-10:00am I1-304."
  },
  {
    "objectID": "clases/Class_ASIM.html#atención-a-estudiantes",
    "href": "clases/Class_ASIM.html#atención-a-estudiantes",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#python",
    "href": "tutoriales/pythonprogrammin.html#python",
    "title": "Python programming",
    "section": "Python",
    "text": "Python\n\nPython is a high-level, interpreted, multi-paradigm, and general-purpose programming language.\nIts design philosophy emphasizes code readability.\nIt is one of the most popular programming languages in use today, and is used for a wide range of applications, including web development, data science, machine learning, and artificial intelligence."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advantages",
    "href": "tutoriales/pythonprogrammin.html#advantages",
    "title": "Python programming",
    "section": "Advantages",
    "text": "Advantages\n\nPython is a multi-paradigm programming language, meaning it can be used for different types of programming, such as object-oriented programming, imperative programming, and functional programming.\nPython is an interpreted programming language, meaning it does not need to be compiled before being executed. This makes Python very fast to develop and debug.\nPython is a highly portable programming language, meaning it can be run on different platforms, such as Windows, Mac OS X, and Linux. It can also be run in the cloud. Python has a large community of users and developers, meaning there are many resources available to learn and use Python."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#disadvantages",
    "href": "tutoriales/pythonprogrammin.html#disadvantages",
    "title": "Python programming",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nPython can be a bit slower than compiled languages, such as C or C++.\nPython has a slightly more complex syntax than some other programming languages, such as Java or JavaScript.\nPython may not be the best programming language for certain types of applications, such as game applications or high-performance applications."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#basic-syntax",
    "href": "tutoriales/pythonprogrammin.html#basic-syntax",
    "title": "Python programming",
    "section": "Basic Syntax",
    "text": "Basic Syntax\n\nIndentation is used to denote block-level structure\nVariables are assigned using the = operator\nPrint output using the print() function\nComments: # for single-line, ''' or \"\"\" for multi-line"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#data-types",
    "href": "tutoriales/pythonprogrammin.html#data-types",
    "title": "Python programming",
    "section": "Data Types",
    "text": "Data Types\n\nIntegers: int (e.g., 1, 2, 3)\nFloats: float (e.g., 3.14, -0.5)\nStrings: str (e.g., 'hello', \"hello\")\nBoolean: bool (e.g., True, False)\nList: list (e.g., [1, 2, 3], ['a', 'b', 'c'])\nDictionary: dict (e.g., {'name': 'John', 'age': 30})"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#control-structures",
    "href": "tutoriales/pythonprogrammin.html#control-structures",
    "title": "Python programming",
    "section": "Control Structures",
    "text": "Control Structures\n\nConditional statements:\n\nif statements: if condition : code\nelif statements: elif condition : code\nelse statements: else : code\n\nLoops:\n\nfor loops: for variable in iterable : code\nwhile loops: while condition : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#functions",
    "href": "tutoriales/pythonprogrammin.html#functions",
    "title": "Python programming",
    "section": "Functions",
    "text": "Functions\n\nReusable blocks of code\nTake arguments and return values\nCan be used to:\n\nOrganize code\nReduce repetition\nEncapsulate complex logic\n\nFunction definition: def function_name (arguments) : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#modules",
    "href": "tutoriales/pythonprogrammin.html#modules",
    "title": "Python programming",
    "section": "Modules",
    "text": "Modules\n\nPre-written code libraries\nImported using the import statement\nExamples:\n\nmath: mathematical functions (e.g., sin(), cos())\nrandom: random number generation (e.g., randint(), uniform())\ntime: time-related functions (e.g., time(), sleep())"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#exception-handling",
    "href": "tutoriales/pythonprogrammin.html#exception-handling",
    "title": "Python programming",
    "section": "Exception Handling",
    "text": "Exception Handling\n\nTry-except blocks:\n\ntry block: code that might raise an exception\nexcept block: code to handle the exception\n\nCatching specific exceptions:\n\nexcept ValueError : code\nexcept TypeError : code\n\nRaising exceptions:\n\nraise ValueError(message)"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "href": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "title": "Python programming",
    "section": "Object-Oriented Programming",
    "text": "Object-Oriented Programming\n\nClasses:\n\nDefine custom data types\nEncapsulate data and behavior\n\nObjects:\n\nInstances of classes\nHave attributes (data) and methods (behavior)\n\nInheritance:\n\nCreate new classes based on existing ones\nInherit attributes and methods"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advanced-topics",
    "href": "tutoriales/pythonprogrammin.html#advanced-topics",
    "title": "Python programming",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nDecorators:\n\nModify function behavior\nUse @ symbol to apply\n\nGenerators:\n\nSpecial type of iterable\nUse yield statement to define\n\nLambda functions:\n\nSmall, anonymous functions\nUse lambda keyword to define"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#decorators",
    "href": "tutoriales/pythonprogrammin.html#decorators",
    "title": "Python programming",
    "section": "Decorators",
    "text": "Decorators\n\ndef my_decorator(func):\n    def wrapper():\n        print(\"Something is happening before the function is called.\")\n        func()\n        print(\"Something is happening after the function is called.\")\n\n    return wrapper\n\n\n@my_decorator\ndef say_hello():\n    print(\"Hello!\")\n\n\nsay_hello()\n\nSomething is happening before the function is called.\nHello!\nSomething is happening after the function is called."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#generators",
    "href": "tutoriales/pythonprogrammin.html#generators",
    "title": "Python programming",
    "section": "Generators",
    "text": "Generators\n\ndef infinite_sequence():\n    num = 0\n    while True:\n        yield num\n        num += 1\n\ngen = infinite_sequence()\nprint(next(gen))\n\n0\n\nprint(next(gen))\n\n1\n\nprint(next(gen))\n\n2"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#lambda-function",
    "href": "tutoriales/pythonprogrammin.html#lambda-function",
    "title": "Python programming",
    "section": "Lambda Function",
    "text": "Lambda Function\n\nrectangle_area_calculation = lambda base, height: base * height\nprint(rectangle_area_calculation(4, 6))  # Salida: 24\n\n24"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#conclusion",
    "href": "tutoriales/pythonprogrammin.html#conclusion",
    "title": "Python programming",
    "section": "Conclusion",
    "text": "Conclusion\n\nPython is a powerful and versatile language\nContinuously learning and practicing will help you master it\nExplore advanced topics and libraries to become proficient"
  },
  {
    "objectID": "tutoriales/TutorialPython.html",
    "href": "tutoriales/TutorialPython.html",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Tomado del libro Ciencia de Datos para Ciencias Naturales\nSi no tiene experiencia con el lenguaje Markdown utilice esta guía para enriquecer sus celdas de texto.\n\n\n\nPlataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código\n\n\n\n\n\nNo requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos.\n\n\n\n\n\nNo se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia.\n\n\n\n\n\nCódigo: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#características",
    "href": "tutoriales/TutorialPython.html#características",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Plataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#ventajas",
    "href": "tutoriales/TutorialPython.html#ventajas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "href": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "href": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Código: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#strings",
    "href": "tutoriales/TutorialPython.html#strings",
    "title": "Tutorial de Python",
    "section": "Strings",
    "text": "Strings\n\ncadena_caracteres = \" Diplomado en Analítica para la Banca \"\n\n#Tamaño de la cadena de caracteres\nprint(len(cadena_caracteres))\n\n#Corte de variable\nprint(cadena_caracteres[0:10])\nprint(cadena_caracteres[20:30])\n\n#Convertir la variable a mayúsculas\nprint(cadena_caracteres.upper())\n\n#Convertir la variable a minúscula\nprint(cadena_caracteres.lower())\n\n#Contar cuantas veces aparece una cadena de caracteres\nprint(cadena_caracteres.count(\"ca\"))\n\n#Reemplazar en una cadena, una letra con otra\nprint(cadena_caracteres.replace(\"a\", \"0\"))\n\n#Partir la cadena de caracteres cada vez que se encuentre un caracter\nprint(cadena_caracteres.split(\" \"))\n\n#Concatenar dos cadenas de caracteres\ncadena01 = \"Pablo Eduardo\"\ncadena02 = \"Caicedo Rodríguez\"\nprint(cadena01+\" \"+cadena02)\n\n38\n Diplomado\nica para l\n DIPLOMADO EN ANALÍTICA PARA LA BANCA \n diplomado en analítica para la banca \n2\n Diplom0do en An0lític0 p0r0 l0 B0nc0 \n['', 'Diplomado', 'en', 'Analítica', 'para', 'la', 'Banca', '']\nPablo Eduardo Caicedo Rodríguez"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#listas",
    "href": "tutoriales/TutorialPython.html#listas",
    "title": "Tutorial de Python",
    "section": "Listas",
    "text": "Listas\n\nlista = [3, 2, 1, 0.5, \"hora del cafe\", \"torta chilena\", \"pinto\", \"jugo\"]\nprint(lista)\nlista.append(\"empanadita\")\nprint(lista)\n\"pinto\" in lista\n\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo']\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo', 'empanadita']\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#diccionarios",
    "href": "tutoriales/TutorialPython.html#diccionarios",
    "title": "Tutorial de Python",
    "section": "Diccionarios",
    "text": "Diccionarios\n\ntel = {'Maria': 4098, 'Jorge': 4139}\nprint(tel)\nprint(tel[\"Maria\"])\nprint(tel.keys())\nprint(tel.values)\n'Maria' in tel\n\n{'Maria': 4098, 'Jorge': 4139}\n4098\ndict_keys(['Maria', 'Jorge'])\n&lt;built-in method values of dict object at 0x7fb47828b080&gt;\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tuplas",
    "href": "tutoriales/TutorialPython.html#tuplas",
    "title": "Tutorial de Python",
    "section": "Tuplas",
    "text": "Tuplas\n\nfrutas = ('naranja', 'mango', 'sandia', 'banano', 'kiwi')\nprint(type(frutas))\nfrutas[1]\n\n&lt;class 'tuple'&gt;\n\n\n'mango'"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#numpy",
    "href": "tutoriales/TutorialPython.html#numpy",
    "title": "Tutorial de Python",
    "section": "Numpy",
    "text": "Numpy\nNumPy (Numerical Python), es una biblioteca de Python que da soporte para crear vectores y matrices grandes multidimensionales, junto con una gran colección de funciones matemáticas de alto nivel. La funcionalidad principal de NumPy es su estructura de datos ndarray (arreglos), para una matriz de n dimensiones, sobre las cuales se pueden realizar operaciones matemátias de manera eficiente.\nCrearemos una lista usando código nativo de Python y lo convertiremos en una matriz unidimensional con la función np.array()\n\nimport numpy as np\n\nlist1 = [6,8,10,12]\narray1 = np.array(list1)\nprint(array1)\n\n[ 6  8 10 12]\n\n\nLos ndarrays son estructuras de datos genéricas para almacenar datos homogéneos. Son equivalentes a las matrices y los vectores en álgebra, por lo que también se les puede aplicar operaciones matemáticas. Notar que las operaciones matemáticas se pueden realizar en todos los valores en un ndarray a la vez.\n\nprint(array1 - 2)\nprint(array1 * array1, \"\\n\\n\")\n\n[ 4  6  8 10]\n[ 36  64 100 144] \n\n\n\n\nLos arreglos se encierran entre [], pero al imprimirlos no están separados por comas. Hay diferentes formas de crear arreglos con propiedades específicas, lo que les provee bastante flexibilidad.\n\n# Crea una matriz con datos específicos\nprint(np.array([[1,2],[3,4]]),'\\n')\n# Crea una matriz con unos: tres filas y cuatro columnas\nprint(np.ones((3,4)),'\\n')\n# Crea una matriz con ceros: tres filas y cuatro columnas\nprint(np.zeros((3,4)),'\\n')\n# Crea una matriz con un dato específico: tres filas y cuatro columnas\nprint(np.full((3,4), 7.3),'\\n')\n# Crea un arreglo con datos seguidos: empieza en 10 termina en 30(sin incluir) con incrementos de 5.\nprint(np.arange(10,30,5),'\\n')\n# # Crea un arreglo con inicio y fin y una cantidad de datos: arreglo de 6 datos entre 0 y 5/3 .\nprint(np.linspace(0,5/3,6),'\\n')\n# Crea una matriz con datos aleatorios entre 0 y 1: dos filas y tres columnas\nprint(np.random.rand(2,3),'\\n')\n\n[[1 2]\n [3 4]] \n\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]] \n\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]] \n\n[[7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]] \n\n[10 15 20 25] \n\n[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] \n\n[[0.75904529 0.42453707 0.53785781]\n [0.10662848 0.62024464 0.34760393]] \n\n\n\n\narr1 = np.array([np.arange(0,5), np.arange(0,5)*5])\n#Arreglo\nprint(arr1, \"\\n\")\n# Forma\nprint(arr1.shape, \"\\n\")\n# Tamaño\nprint(arr1.size, \"\\n\")\n# Número de Dimensiones\nprint(arr1.ndim, \"\\n\")\n# Transpuesta\nprint(arr1.T, \"\\n\")\n\n[[ 0  1  2  3  4]\n [ 0  5 10 15 20]] \n\n(2, 5) \n\n10 \n\n2 \n\n[[ 0  0]\n [ 1  5]\n [ 2 10]\n [ 3 15]\n [ 4 20]] \n\n\n\n\narr = np.array([1,2,3,4,5,6,7])\n# Porcionar\nprint(arr[1:3])# de 1 al 3 en índice\nprint(arr[4:])# de la posición 4 en adelante\nprint(arr[::2])# de uno por medio\n\n[2 3]\n[5 6 7]\n[1 3 5 7]"
  },
  {
    "objectID": "rubricas/Rubrica_EDA.html",
    "href": "rubricas/Rubrica_EDA.html",
    "title": "Rúbrica: Análisis Exploratorio de Datos",
    "section": "",
    "text": "Indicador\nBueno\nSuficiente\nInsuficiente\n\n\n\n\nLimpieza del Dataset\nEl dataset no presenta ni registros nulos, ni vacíos. Existe una estrategia para manejo de atípicos (100%)\nEl dataset no presenta ni registros nulos, ni vacíos (50%)\nEl dataset presenta registros nulos y/o vacíos. No existe una estrategia para manejo de atípicos (0%)\n\n\nConsumo de información\nSe consumen al menos 2 fuentes de datos provenientes de las sugerencias de los organizadores (100%)\nSe consume una fuente de datos proveniente de las sugerencias de los organizadores (50%)\nNo se consume ninguna fuente de datos conocida (0%)\n\n\nEDA sobre nuevas variables\nSe plantean correctamente las relaciones entre la variables y estas se demuestran a plenitud utilizando matemática y/o estadística (100%)\nSe plantean dos relaciones entre las variables (50%)\nNo se plantean las relaciones entre las variables (0%)\n\n\nUso de plantilla\nUsan la plantilla rmarkdown (100%)\n\nNo se usa la plantilla rmarkdown(0%)\n\n\nVisualización de la informacion\nLa información de TODAS las gráficas se observa plenamente (100%)\nLa información de las gráficas se observa parcialmente(50%)\nLa información de la gráfica no se observa (0%)\n\n\nJustificación del problema\nExiste una justificación del problema(100%)\n\nNo Existe justificación al problema resuelto (0%)\n\n\nUbicación del problema\nSe plantea correctamente la ubicación del problema 100%\n\nNo se plantea correctamente la ubicación del problema 0%"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "href": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "title": "Proyecto Final: PSIM 2024-1",
    "section": "",
    "text": "Criterio\n5.0  (Excelente)\n4.0  (Bueno)\n3.0  (Aceptable)\n1.0  (Deficiente)\n\n\n\n\n1. Objetivo del Proyecto\nClaramente definido, específico, relevante y alcanzable, alineado con la problemática.\nClaro y relevante, pero carece de precisión o profundidad.\nComprensible, pero general o no bien alineado con la problemática.\nConfuso, irrelevante o ausente.\n\n\n2. Justificación\nSólida, argumenta importancia e impacto con evidencia o literatura relevante.\nAdecuada, pero le falta profundidad o evidencia clara.\nBásica y poco convincente; argumentos débiles o generales.\nInexistente o carente de lógica.\n\n\n3. Metodología\nBien estructurada, clara y adecuada para los objetivos. Técnicas y procedimientos relevantes.\nAdecuada, pero carece de detalle o presenta leves inconsistencias.\nVaga, incompleta o no alineada con los objetivos.\nConfusa, inapropiada o ausente.\n\n\n4. Resultados\nClaros, organizados y rigurosamente analizados. Uso efectivo de herramientas visuales.\nClaros, pero carecen de profundidad en análisis u organización.\nConfusos, incompletos o mal interpretados.\nIrrelevantes, incorrectos o ausentes.\n\n\n5. Discusión\nInterpreta resultados, relaciona con objetivos y literatura, propone mejoras futuras.\nAborda puntos principales, pero falta profundidad o conexión con literatura previa.\nSuperficial, no interpreta correctamente resultados ni plantea ideas futuras.\nAusente o irrelevante.\n\n\n6. Respuesta a Preguntas\nResponde con claridad, precisión y seguridad. Demuestra dominio y análisis crítico del tema.\nResponde adecuadamente, pero muestra inseguridad en algunos aspectos.\nResponde vagamente, con dificultades para argumentar.\nRespuestas incorrectas, confusas o incapacidad para responder."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#objetivo-de-aprendizaje",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes conocerán las principales teorías concernientes a la generación del electrocardiograma y su relación con el funcionamiento del corazón."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#duración",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#materiales",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#actividad-1-revisión-al-electrocardiograms",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#actividad-1-revisión-al-electrocardiograms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 1: Revisión al electrocardiograms",
    "text": "Actividad 1: Revisión al electrocardiograms\n\n¿Qué es un electrocardiograma (ECG) y cuál es su importancia en el diagnóstico clínico?\n¿Qué información electrofisiológica proporciona un ECG y cómo se relaciona con la actividad del corazón?\n¿Qué es una derivación (lead) en el contexto de un ECG y cuál es su función?\n¿Cuántas derivaciones existen en un ECG estándar y cómo se clasifican?\nObserve la Figura 1 proporcionada y determine a qué derivación corresponde el diagrama mostrado. Justifique su respuesta.\n¿Qué es una arritmia y qué tipos existen? Describa las características de cada tipo de arritmia."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#actividad-2-análisis-del-articulo",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#actividad-2-análisis-del-articulo",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 2: Análisis del articulo",
    "text": "Actividad 2: Análisis del articulo\n\n¿Cuáles son las principales clases de arritmias que el artículo estudia y cómo se agrupan?\n¿Qué impacto tienen las arritmias en la salud pública según el artículo? Mencione datos estadísticos relevantes.\n¿Por qué es importante mejorar la precisión en la clasificación automática de arritmias?\n¿Cuáles son las principales fuentes de ruido en una señal de ECG y qué técnicas se utilizaron en el artículo para reducirlas?\n¿Por qué se aplicó normalización a las señales ECG? ¿Qué impacto tuvo en la clasificación? Explique el método de normalización.\n¿Cuáles son las principales características extraídas de la señal ECG en este estudio?\n¿Por qué es importante la selección de características para el entrenamiento de un algoritmo de clasificación?"
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#actividad-3-análisis-de-la-base-de-datos",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#actividad-3-análisis-de-la-base-de-datos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 3: Análisis de la base de datos",
    "text": "Actividad 3: Análisis de la base de datos\n\n¿Cuáles fueron los criterios de selección de los pacientes?\n¿Cuántos registros de ECG se recopilaron en total y qué duración tienen las señales analizadas?\n¿Cómo se realizó la toma de datos del ECG? Especifique el número de derivaciones, la duración del registro y la frecuencia de muestreo.\n¿Cuáles fueron las características demográficas de la población estudiada? Describa la distribución por edad y género.\n¿Cuál fue la prevalencia de cada tipo de arritmia en la base de datos? ¿Qué arritmias fueron las más frecuentes y cuáles fueron las menos comunes?"
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#criterios-de-evaluación",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Criterios de Evaluación",
    "text": "Criterios de Evaluación\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nNivel Excelente (5.0 - 4.5)\nNivel Satisfactorio (4.4 - 3.5)\nNivel Aceptable (3.4 - 2.5)\nNivel Deficiente (&lt;2.5)\nPeso (%)\n\n\n\n\nComprensión teórica del ECG y su relevancia clínica\nExplica de manera clara y detallada la importancia del ECG, su función diagnóstica y la información electrofisiológica que proporciona. Responde con precisión todas las preguntas teóricas.\nResponde la mayoría de las preguntas con claridad, pero algunas respuestas pueden carecer de profundidad o detalles.\nResponde las preguntas de manera parcial o con imprecisiones conceptuales. Falta claridad en algunos conceptos.\nRespuestas incompletas o con errores fundamentales en la comprensión del ECG y su relevancia.\n20%\n\n\nAnálisis del artículo de Zheng et al.\nIdentifica y sintetiza correctamente las clases de arritmias, impacto en salud pública, técnicas de reducción de ruido y normalización. Argumenta con evidencia del artículo.\nPresenta un buen análisis, aunque algunas respuestas carecen de profundidad o precisión. Uso adecuado pero limitado de la evidencia.\nMuestra dificultad en identificar o explicar correctamente algunos conceptos clave del artículo.\nAnálisis deficiente, respuestas vagas o incorrectas, falta de relación con el artículo.\n20%\n\n\nAnálisis de la base de datos de ECG\nDescribe con precisión los criterios de selección, número de registros, condiciones de adquisición y características demográficas. Utiliza correctamente los datos del artículo.\nExplica la mayoría de los aspectos, aunque con algunas omisiones o falta de precisión en los datos.\nResponde parcialmente, con confusión en algunos aspectos metodológicos o demográficos.\nNo logra describir correctamente los criterios de la base de datos o presenta errores graves en su interpretación.\n20%\n\n\nJustificación y análisis de derivaciones\nIdentifica correctamente la derivación del ECG mostrado en la Figura 1, justificando con base en conocimientos teóricos.\nIdentifica la derivación con una justificación aceptable, aunque podría ser más clara.\nPresenta una identificación incorrecta o incompleta con una justificación débil.\nNo justifica o identifica erróneamente la derivación.\n15%\n\n\nPresentación y redacción del informe\nInforme bien estructurado, sin errores gramaticales o de formato. Uso adecuado de referencias. Argumentación clara y precisa.\nInforme organizado, aunque con algunos errores menores de gramática o formato. Argumentación adecuada.\nPresentación con errores de redacción y formato. Explicaciones poco estructuradas.\nInforme desorganizado, con errores graves de gramática y sin referencias adecuadas.\n15%\n\n\nParticipación y trabajo en equipo\nDemuestra alto compromiso y participación en la sesión de laboratorio. Contribuye activamente al desarrollo del informe.\nParticipa en la mayoría de las actividades, aunque con algunas intervenciones limitadas.\nParticipa de forma esporádica o depende en exceso del grupo para completar las actividades.\nNo participa o su aporte al equipo es mínimo.\n10%\n\n\n\nTotal: 100% puntos."
  },
  {
    "objectID": "recursos/talleres/Taller_2025_1.html",
    "href": "recursos/talleres/Taller_2025_1.html",
    "title": "Taller 1 - Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Taller 1\nProfesores\nJenny Carolina Castiblanco Sánchez\nPablo Eduardo Caicedo Rodríguez\nDescripción\nA través de este taller se reforzarán los conocimientos en: señales, transformaciones de la variable independiente, clasificación de señales, ADC y DAC.\nProcedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\nConsidere la señal\nDibuje:\nDetermine si las siguientes señales son periódicas y encuentre su periodo\nPara las siguientes señales encuentre, la potencia instantánea, la energía y la potencia promedio. Indique si la señal se considera de energía o de potencia.\nDemuestre que si y son señales impares, entonces:\n, es una señal par\nes una señal impar.\nSiendo y , grafique en Python y . ¿se cumple lo indicado en el numeral a y b?\nEncuentre la expresión analítica de las señales mostradas a continuación utilizando funciones y (escalón unitario y rampa).\nPara una señal análoga encontrar\nIndique si la señal es una señal periódica, en caso afirmativo, indique el periodo de la señal.\nFrecuencia de muestro que cumpla con el teorema de Nyquist.\nEncontrar con la frecuencia de muestreo encontrada en el punto anterior.\nIndique si la señal es una señal periódica, en caso afirmativo, indique el periodo de la señal.\nConsidere el sistema de procesamiento de señales mostrado en la figura:\nRecuerde que . Si la entrada es , encontrar:\nLa salida si . ¿Con esta frecuencia se puede reconstruir la señal en si ? Justifique su respuesta.\nLa salida si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¿La señal es periódica en tiempo discreto? Justifique su respuesta.\nPara la señal del punto b, encontrar la señal cuantizada de un ciclo de la señal si el tamaño del registro es de 4bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#descripción",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\n\\(x(t)\\)\n\\(x(t - 2)\\)\n\\(x(2t + 1)\\)\n\\(x(-3t)\\)\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\n\\(x(t) = e^{-j(\\frac{4\\pi}{3})t} + e^{j(\\frac{2\\pi}{5})t}\\)\n\n\\(x(n) = \\cos(n/8) \\cos(\\pi n/8)\\)\n\n\\(x(n) = \\cos(3\\pi n/2) - \\sin(\\frac{\\pi n}{8}) + 3\\cos(\\frac{\\pi n}{4} + \\frac{\\pi}{3})\\)\n\n\n\n3. Demuestre que si \\(x(t)\\) y \\(y(t)\\) son señales impares, entonces:\n\n\\(z(t) = x(t)y(t)\\) es una señal par\n\n\\(g(t) = x(t) + y(t)\\) es una señal impar.\n\nSiendo \\(x(t) = \\sin(t)\\) y \\(y(t) = t\\), grafique en Python \\(z(t)\\) y \\(g(t)\\). ¿Se cumple lo indicado en los numerales a y b?\n\n\n\n4. Encuentre la expresión analítica de las señales mostradas a continuación utilizando funciones \\(u(t)\\) y \\(r(t)\\) (escalón unitario y rampa).\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nIndique si la señal \\(x_a(t)\\) es una señal periódica, en caso afirmativo, indique el periodo de la señal.\n\nFrecuencia de muestreo que cumpla con el teorema de Nyquist.\n\nEncontrar \\(x_a[n]\\) con la frecuencia de muestreo encontrada en el punto anterior.\n\nIndique si la señal \\(x_a[n]\\) es una señal periódica, en caso afirmativo, indique el periodo de la señal.\n\n\n\n6. Considere el sistema de procesamiento de señales mostrado en la figura:\n\nSi la entrada es \\(x_a(t) = 2 \\sin(720\\pi t) + 2\\), encontrar:\n\nLa salida \\(x_a[n]\\) si \\(T_{m1} = 12.5ms\\). ¿Con esta frecuencia se puede reconstruir la señal \\(x_a(t)\\) en \\(y(t)\\) si \\(T_{m2} = T_{m1}\\)? Justifique su respuesta.\n\nLa salida \\(x_a[n]\\) si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¿La señal es periódica en tiempo discreto? Justifique su respuesta.\n\nPara la señal del punto b, encontrar la señal cuantizada de un ciclo de la señal si el tamaño del registro es de 4 bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "clases/Class_SYSB.html#talleres",
    "href": "clases/Class_SYSB.html#talleres",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Talleres",
    "text": "Talleres\n\nTaller1: Introduccion al procesamiento de señales"
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripción",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\nSolución\nSe grafican las transformaciones solicitadas en Python con Matplotlib.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_t(t):\n    return np.piecewise(t, [(-1 &lt;= t) & (t &lt;= 0), (0 &lt; t) & (t &lt;= 2), (2 &lt; t) & (t &lt;= 3)],\n                         [lambda t: t + 1, 2, 1, 0])\n\nt = np.linspace(-2, 4, 1000)\nplt.plot(t, x_t(t), label='x(t)')\nplt.xlabel('t')\nplt.ylabel('x(t)')\nplt.legend()\nplt.show()\n\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\nSolución\nAnalizamos si \\(\\frac{f_0}{f_s}\\) es racional.\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\nPeríodos: \\(T_1 = \\frac{2\\pi}{2} = \\pi\\), \\(T_2 = \\frac{2\\pi}{\\pi} = 2\\)\nMínimo común múltiplo: **Período = 2*\n\n\\(x(t) = e^{-j(4\\pi/3)t} + e^{j(2\\pi/5)t}\\)\n\nSe buscan los períodos fundamentales.\nNo es periódica porque las razones de frecuencias son irracionales.\n\n\n…\n\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nSolución\n\nPeríodo de la señal:\n\nFrecuencias: \\(f_1 = 300Hz\\), \\(f_2 = 240Hz\\)\nMCM de \\(\\frac{1}{300}\\) y \\(\\frac{1}{240}\\) → T = 1/60 s\n\nFrecuencia de muestreo\n\nTeorema de Nyquist: \\(f_s &gt; 2f_{max} = 600Hz\\)\n\nSeñal muestreada:\nfs = 600  # Hz\nn = np.arange(0, 100)\nxa_n = np.sin(600*np.pi*n/fs) + 3*np.sin(480*np.pi*n/fs)\nplt.stem(n, xa_n)\nplt.show()\n\n…\n\n\n\n6. Muestreo y cuantización\n\nSolución\n\nFrecuencia de muestreo:\n\n\\(T_m1 = 12.5ms\\) → \\(f_s = 80Hz\\)\nNo cumple Nyquist → No se puede reconstruir\n\nMuestreo a 8 veces Nyquist:\n\n\\(f_s = 5760Hz\\)\nSe evalúa si \\(\\frac{f_0}{f_s}\\) es racional → Sí es periódica\n\nCuantización (4 bits, rango 0-5):\n\nPaso de cuantización: \\(\\Delta = \\frac{5}{2^4}\\)\nSe discretiza la señal según niveles de cuantización.\n\n\nimport numpy as np\nlevels = np.linspace(0, 5, 16)\nquantized_signal = np.digitize(xa_n, levels) * (5 / 16)\nplt.stem(n, quantized_signal)\nplt.show()\n\nFin del taller."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Requisitos:",
    "text": "Requisitos:\n\nIdentificar un problema de salud específico y relevante, relacionado con los ODS.\nJustificar la importancia del problema y la necesidad de una solución innovadora.\nEstablecer objetivos claros y medibles para el proyecto.\nElegir un dataset apropiado de señales (1D).\nDesarrollar una solución técnica que satisfaga los indicadores de solución de problema, con descripción matemática, física y/o estadística.\nImplementar la solución en Python."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Rúbrica de evaluación",
    "text": "Rúbrica de evaluación\n\n\n\n\n\n\n\n\n\n\nCriterio\nPuntos\nBueno\nRegular\nMalo\n\n\n\n\nProblema de salud identificado\n15\nProblema claro, relevante y bien justificado (15puntos)\nProblema claro, pero justificación débil (7puntos)\nProblema no claro o no relevante (0puntos)\n\n\nJustificación y objetivos\n15\nJustificación sólida y objetivos claros y medibles (15puntos)\nJustificación débil y objetivos poco claros (7puntos)\nJustificación y objetivos no claros (0puntos)\n\n\nSolución técnica\n20\nSolución innovadora, bien fundamentada y correctamente implementada en Python (20puntos)\nSolución adecuada, pero con errores en la implementación (10puntos)\nSolución no innovadora o con errores graves (0puntos)\n\n\nDiseño de indicadores\n20\nIndicadores bien definidos, con descripción matemática, médica y estadística clara y precisa (20puntos)\nIndicadores bien definidos, pero con descripción no clara o incompleta (10puntos)\nIndicadores no bien definidos o sin descripción (0puntos)\n\n\nContribución a los ODS\n10\nContribución clara y significativa a los ODS (10puntos)\nContribución moderada a los ODS (7puntos)\nContribución no clara o nula a los ODS (0puntos)\n\n\nImpacto potencial en la salud\n10\nImpacto potencial alto y bien justificado (10puntos)\nImpacto potencial moderado y justificación débil (7puntos)\nImpacto potencial bajo o no justificado (0puntos)\n\n\nPresentación y documentación\n10\nPresentación clara y documentación precisa y completa (10puntos)\nPresentación clara, pero documentación no precisa (7puntos)\nPresentación no clara o documentación no está presente (0puntos)"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "href": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "title": "Proyecto Final: APSB1",
    "section": "",
    "text": "Criterio\n1 - Deficiente\n2 - Insuficiente\n3 - Aceptable\n4 - Bueno\n5 - Excelente\nPonderación\n\n\n\n\nDefinición del Problema y Justificación\nNo se identifica un problema biomédico claro.\nSe identifica un problema, pero sin relevancia biomédica o justificación.\nSe plantea un problema relevante con justificación básica.\nProblema bien definido con referencias científicas.\nProblema biomédico bien formulado, con justificación sólida basada en literatura científica.\n15%\n\n\nAdquisición y Procesamiento de Datos en el Borde\nNo se especifica el tipo de datos ni sensores.\nSe mencionan sensores, pero sin detalles sobre la captura y preprocesamiento.\nSe describe la adquisición de datos con procesamiento básico.\nSe justifica la selección de sensores y se menciona un preprocesamiento adecuado.\nSelección óptima de sensores con procesamiento avanzado y justificación técnica detallada.\n20%\n\n\nDesarrollo e Implementación del Modelo de IA\nNo se propone un modelo de IA.\nSe menciona un modelo, pero sin adecuación a Edge AI.\nSe plantea un modelo básico con justificación limitada.\nSe elige un modelo adecuado y optimizado para Edge AI.\nModelo avanzado con técnicas de optimización y justificadas con métricas.\n20%\n\n\nValidación y Pruebas en Tiempo Real\nNo se contempla validación del modelo.\nSe menciona validación, pero sin metodología clara.\nSe plantea una validación con datos simulados.\nSe incluyen pruebas con datos reales y métricas de rendimiento.\nValidación robusta con pruebas extensivas y comparación con estándares biomédicos.\n20%\n\n\nEscalabilidad y Aplicabilidad en la Industria Biomédica\nNo se considera la escalabilidad del proyecto.\nSe menciona la escalabilidad, pero sin detalles técnicos.\nSe plantea una estrategia básica de escalabilidad.\nEstrategia clara de implementación y compatibilidad con sistemas médicos.\nProyecto altamente escalable, con integración en entornos clínicos y estándares como HL7 o FHIR.\n15%\n\n\nPresentación y Documentación\nNo hay documentación ni presentación clara.\nDocumentación incompleta o desordenada.\nPresentación básica con documentación limitada.\nPresentación clara y documentada correctamente.\nDocumentación profesional con detalles técnicos y presentación estructurada.\n10%"
  },
  {
    "objectID": "clases/Class_APSB.html#rúbrica",
    "href": "clases/Class_APSB.html#rúbrica",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Rúbrica",
    "text": "Rúbrica\n-Planteamiento del problema"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nMachine Learning (ML) is a data-driven approach to building predictive models.\nIt is used in various applications such as healthcare, finance, and automation.\nIt is based on identifying patterns in data to make predictions or decisions."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning",
    "text": "Types of Machine Learning\n\nSupervised Learning:\n\nUses labeled data to train models.\nExample: Spam detection in emails (spam vs. non-spam).\nCommon algorithms: Linear Regression, Decision Trees, Support Vector Machines (SVM), Neural Networks.\n\nUnsupervised Learning:\n\nFinds patterns in unlabeled data.\nExample: Customer segmentation in marketing.\nCommon algorithms: K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA).\n\nReinforcement Learning:\n\nOptimizes decision-making through rewards.\nExample: Training an AI to play a game like Chess or Go.\nKey components: Agent, Environment, Reward Signal."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nData:\n\nThe quality and quantity of data are fundamental.\nData preprocessing (cleaning, normalization, feature extraction) is crucial.\n\nModel:\n\nA mathematical representation of the problem.\nChosen based on the problem type (classification, regression, clustering)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nInductive Bias:\n\nPrior assumptions that the model uses to generalize.\nExample: Linear models assume data relationships are linear.\n\nSample Bias:\n\nDifferences between training data and real-world data.\nExample: A face recognition system trained on a specific demographic may perform poorly on others."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Example of Bias and Variance",
    "text": "Example of Bias and Variance"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nML enables systems to learn from experience without being explicitly programmed.\nKey application areas include image recognition, natural language processing, and autonomous systems."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Supervised Learning",
    "text": "Types of Machine Learning – Supervised Learning\nSupervised Learning: - Uses labeled data to train models. - Example: Spam detection in emails (spam vs. non-spam). - Common algorithms: Linear Regression, Decision Trees, Support Vector Machines (SVM), Neural Networks."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Unsupervised Learnin",
    "text": "Types of Machine Learning – Unsupervised Learnin\nUnsupervised Learning: - Finds patterns in unlabeled data. - Example: Customer segmentation in marketing. - Common algorithms: K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Reinforcement Learning",
    "text": "Types of Machine Learning – Reinforcement Learning\nReinforcement Learning: - Optimizes decision-making through rewards. - Example: Training an AI to play a game like Chess or Go. - Key components: Agent, Environment, Reward Signal."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nError function:\n\nEvaluates the difference between prediction and actual value.\nExample: Mean Squared Error (MSE) for regression, Cross-Entropy Loss for classification.\n\nOptimization:\n\nAlgorithms that adjust the model parameters to minimize error.\nCommon optimization techniques: Gradient Descent, Adam Optimizer."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nBias-Variance Tradeoff:\n\nHigh Bias (Underfitting): The model is too simple, failing to capture patterns.\nHigh Variance (Overfitting): The model memorizes training data but fails on new data."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n1. Linear Regression (Supervised Learning - Regression)\n\nPredicts a continuous value based on input features.\nEquation: ( y = mx + b )\nExample: Predicting house prices based on square footage.\n\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression() \n\n\nSlope: [0.6]\n\n\nIntercept: 2.2"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n2. Decision Trees (Supervised Learning - Classification & Regression)\n\nSplits data into decision nodes to make predictions.\nExample: Diagnosing a disease based on symptoms.\n\n\n\nDecisionTreeClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier() \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n3. K-Means Clustering (Unsupervised Learning)\n\nGroups similar data points together.\nExample: Customer segmentation in marketing.\n\n\n\nCluster Centers: [[10.  2.]\n [ 1.  2.]]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n4. Support Vector Machines (SVM) (Supervised Learning - Classification)\n\nFinds a hyperplane that best separates different classes.\nExample: Classifying tumors as benign or malignant.\n\n\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC() \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n5. Reinforcement Learning Example\n\nUses rewards and penalties to train an agent to make optimal decisions.\nExample: A robot learning to navigate a maze.\n\n\n\nTrained Q-Table:\n [[0.21339436 0.23154682 0.30755091 0.47471941 0.55535712]\n [0.25172938 0.32616156 0.50539633 0.61354565 0.92199991]\n [0.32407604 0.50371897 0.88304774 1.08983768 1.55796586]\n [0.44230092 0.66295912 1.24704589 2.65871548 4.55653567]\n [0.68756566 1.27099064 2.72216073 5.42893782 0.        ]]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution",
    "text": "Convolution"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "It is a mathematical algorithm or system that processes digital signals.\nThey enhance, suppress, or modify specific frequency components.\nThese filters are essential for removing noise, extracting relevant information, and improving signal quality.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nThe digital filter separates the noise and the information of a discrete signal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose a discrete time system\n\\[ y[n] = \\sum_{k=1}^{K} a_k y[n - k] + \\sum_{m=0}^{M} b_m x[n - m]\\]\n\nK y M are the order of the filter.\nWe must know the initial condition.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGain\n\n\n\n\\[y[n] = G x[n]\\]\n\n\n\n\n\n\n\n\nDelay of \\(n_0\\) samples\n\n\n\n\\[y[n] = x[n - n_0]\\]\n\n\n\n\n\n\n\n\nTwo points moving average\n\n\n\n\\[y[n] = \\frac{1}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\nEuler approximation of the derivative\n\n\n\n\\[y[n] = \\frac{x[n] - x[n - 1]}{T_s}\\]\n\n\n\n\n\n\n\n\n\nAveraging over N consecutive epochs of duration L\n\n\n\n\\[y[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} x[n - kL]\\]\n\n\n\n\n\n\n\n\nTrapezoidal integration formula\n\n\n\n\\[y[n] = y[n - 1] + \\frac{T_s}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\nDigital “leaky integrator” (First-order lowpass filter)\n\n\n\n\\[y[n] = a y[n - 1] + x[n], \\quad 0 &lt; a &lt; 1\\]\n\n\n\n\n\n\n\n\nDigital resonator (Second-order system)\n\n\n\n\\[y[n] = a_1 y[n - 1] + a_2 y[n - 2] + b x[n], \\quad a_1^2 + 4a_2 &lt; 0\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe impulse response, denoted as \\(ℎ[n]\\), is the output of a digital filter when the input is a unit impulse function \\(\\delta[n]\\)\nThe impulse response fully describes the system. Given \\(h[n]\\), we can determine the output for any input using convolution.\nDifferent types of filters (low-pass, high-pass, band-pass, etc.) have characteristic impulse responses.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor a system’s response to be fully described by its impulse response, the system must satisfy the following key conditions.\n\n\n\n\n\n\nLinearity\n\n\n\nIf the system responds to \\(x_1[n]\\) with \\(y_1[n]\\) and to \\(x_2[n]\\) with \\(y_2[n]\\), then:\n\\[y[n] = y_1[n] + y_2[n]\\]\n\n\n\n\n\n\n\n\nHomogeneity\n\n\n\nIf the input is scaled by a constant \\(c\\), the output is also scaled:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } cx[n] \\rightarrow cy[n]\\]\n\n\n\n\n\n\n\n\nTime Invariance\n\n\n\nA system must be time-invariant, meaning a time shift in the input causes the same shift in the output:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } x[n - n_0] \\rightarrow y[n - n_0]\\]\n\n\n\n\n\n\n\n\nCausality\n\n\n\nA causal system is one where the output at time \\(n\\) depends only on present and past inputs:\n\\[h[n] = 0 \\quad \\forall n &lt; 0\\]\n\n\n\n\n\n\n\n\nStability\n\n\n\nIf the impulse response does not satisfy this condition, the system may produce unbounded outputs.\n\\[\\sum_{n=-\\infty}^{\\infty} |h[n]| &lt; \\infty\\]\n\n\n\n\n\n\n\n\nConvolution Representation\n\n\n\nIf all condition met then\n\\[y[n] = x[n] * h[n] = \\sum_{m=-\\infty}^{\\infty} x[m] h[n - m]\\]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#what-is-machine-learning",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#what-is-machine-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nMachine Learning (ML) is a data-driven approach to building predictive models.\nIt is used in various applications such as healthcare, finance, and automation.\nIt is based on identifying patterns in data to make predictions or decisions."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#what-is-machine-learning-1",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#what-is-machine-learning-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nML enables systems to learn from experience without being explicitly programmed.\nKey application areas include image recognition, natural language processing, and autonomous systems."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#types-of-machine-learning-supervised-learning",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#types-of-machine-learning-supervised-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Supervised Learning",
    "text": "Types of Machine Learning – Supervised Learning\nSupervised Learning:\n- Uses labeled data to train models.\n- Example: Spam detection in emails (spam vs. non-spam).\n- Common algorithms: Linear Regression, Decision Trees, Support Vector Machines (SVM), Neural Networks."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#types-of-machine-learning-unsupervised-learnin",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#types-of-machine-learning-unsupervised-learnin",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Unsupervised Learnin",
    "text": "Types of Machine Learning – Unsupervised Learnin\nUnsupervised Learning:\n- Finds patterns in unlabeled data.\n- Example: Customer segmentation in marketing.\n- Common algorithms: K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA)."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#types-of-machine-learning-reinforcement-learning",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#types-of-machine-learning-reinforcement-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Reinforcement Learning",
    "text": "Types of Machine Learning – Reinforcement Learning\nReinforcement Learning:\n- Optimizes decision-making through rewards.\n- Example: Training an AI to play a game like Chess or Go.\n- Key components: Agent, Environment, Reward Signal."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#key-components-of-an-ml-model",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#key-components-of-an-ml-model",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nData:\n\nThe quality and quantity of data are fundamental.\nData preprocessing (cleaning, normalization, feature extraction) is crucial.\n\nModel:\n\nA mathematical representation of the problem.\nChosen based on the problem type (classification, regression, clustering)."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#key-components-of-an-ml-model-1",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#key-components-of-an-ml-model-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nError function:\n\nEvaluates the difference between prediction and actual value.\nExample: Mean Squared Error (MSE) for regression, Cross-Entropy Loss for classification.\n\nOptimization:\n\nAlgorithms that adjust the model parameters to minimize error.\nCommon optimization techniques: Gradient Descent, Adam Optimizer."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#bias-and-inductivity",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#bias-and-inductivity",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nInductive Bias:\n\nPrior assumptions that the model uses to generalize.\nExample: Linear models assume data relationships are linear.\n\nSample Bias:\n\nDifferences between training data and real-world data.\nExample: A face recognition system trained on a specific demographic may perform poorly on others."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#bias-and-inductivity-1",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#bias-and-inductivity-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nBias-Variance Tradeoff:\n\nHigh Bias (Underfitting): The model is too simple, failing to capture patterns.\nHigh Variance (Overfitting): The model memorizes training data but fails on new data."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#example-of-bias-and-variance",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#example-of-bias-and-variance",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Example of Bias and Variance",
    "text": "Example of Bias and Variance"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n1. Linear Regression (Supervised Learning - Regression)\n\nPredicts a continuous value based on input features.\nEquation: ( y = mx + b )\nExample: Predicting house prices based on square footage.\n\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression() \n\n\nSlope: [0.6]\n\n\nIntercept: 2.2"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms-1",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n2. Decision Trees (Supervised Learning - Classification & Regression)\n\nSplits data into decision nodes to make predictions.\nExample: Diagnosing a disease based on symptoms.\n\n\n\nDecisionTreeClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier() \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms-2",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n3. K-Means Clustering (Unsupervised Learning)\n\nGroups similar data points together.\nExample: Customer segmentation in marketing.\n\n\n\nCluster Centers: [[10.  2.]\n [ 1.  2.]]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms-3",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n4. Support Vector Machines (SVM) (Supervised Learning - Classification)\n\nFinds a hyperplane that best separates different classes.\nExample: Classifying tumors as benign or malignant.\n\n\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC() \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms-4",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#basic-machine-learning-algorithms-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n5. Reinforcement Learning Example\n\nUses rewards and penalties to train an agent to make optimal decisions.\nExample: A robot learning to navigate a maze.\n\n\n\nTrained Q-Table:\n [[0.23147481 0.28116546 0.35966911 0.53481771 0.52154113]\n [0.26372687 0.38811904 0.61390523 0.75204772 0.70655714]\n [0.32869523 0.45763046 0.88132857 1.66364651 2.40418824]\n [0.4318695  0.79080144 1.73635441 2.73236287 4.77875799]\n [0.45225018 0.83902691 2.21164033 4.32734074 0.        ]]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-4",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Understanding Workflow.",
    "text": "Data Understanding Workflow.\n\n\n\n\n\n\n\nExploratory data analysis\n\n\n\nData Loading.\nBasic Statistics: Displays summary statistics.\nMissing Values Check: Identifies missing values.\nFeature Distributions: Visualizes distributions using histograms or countplots.\nRelationship between variables."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Understanding Workflow",
    "text": "Data Understanding Workflow\n\n# Identify variable types\ndiscrete_vars = [\"Pregnancies\"]  # Discrete numerical variable\ncategorical_vars = [\"Outcome\"]  # Class label\ncontinuous_vars = [\n    col\n    for col in data.select_dtypes(include=[np.number]).columns\n    if col not in discrete_vars + [\"Outcome\"]\n]\n\n# Basic dataset information\nprint(\"Dataset Information:\\n\", data.info())\nprint(\"\\nSummary Statistics:\\n\", data.describe())\nprint(\"\\nMissing Values:\\n\", data.isnull().sum())\n\n# Ensure numeric data and handle NaN or infinite values\nnumeric_data = data.select_dtypes(include=[np.number]).dropna()\nnumeric_data = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n\n# Dynamically determine the number of rows for subplots\nnum_cont_vars = len(continuous_vars)\nrows = (num_cont_vars // 3) + (num_cont_vars % 3 &gt; 0)  # Ensures proper grid layout\n\n# Plot distributions for continuous variables\nplt.figure(figsize=(12, 4 * rows))\nfor i, column in enumerate(continuous_vars, 1):\n    plt.subplot(rows, 3, i)\n    sns.histplot(numeric_data[column], kde=True, bins=20, color=\"skyblue\")\n    plt.title(f\"Distribution of {column}\")\nplt.tight_layout()\nplt.show()\n\n# Plot distribution for discrete variable (Pregnancies) using a countplot\nplt.figure(figsize=(8, 4))\nsns.countplot(x=\"Pregnancies\", data=numeric_data, palette=\"viridis\")\nplt.title(\"Count of Pregnancies\")\nplt.show()\n\n# Plot class distribution for Outcome\nplt.figure(figsize=(6, 4))\nsns.countplot(x=\"Outcome\", data=data, palette=\"coolwarm\")\nplt.title(\"Class Distribution of Outcome\")\nplt.xlabel(\"Diabetes Diagnosis (0: No, 1: Yes)\")\nplt.ylabel(\"Count\")\nplt.show()\n\n# Correlation heatmap to check relationships\nplt.figure(figsize=(10, 6))\nsns.heatmap(numeric_data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Antes de realizar el procesamiento de señales en estudios biomédicos, es fundamental llevar a cabo un análisis descriptivo de los participantes. Este paso permite contextualizar los datos y asegurar que cualquier resultado obtenido sea válido, representativo y adecuado para su interpretación clínica y científica. A continuación, se detallan las razones clave para realizar este análisis previo:\n\nCaracterización de la Población Estudiada: El análisis descriptivo permite conocer la distribución de variables clave.\nIdentificación de Posibles Sesgos en los Datos: Un estudio bien diseñado debe asegurarse de que los datos sean representativos de la población objetivo.\nEvaluación de la Calidad de los Datos: El análisis descriptivo ayuda a detectar inconsistencias en los datos antes de aplicar técnicas de procesamiento de señales.\nJustificación del Preprocesamiento de Señales: Al conocer las características de los participantes, se pueden tomar decisiones informadas sobre qué técnicas de procesamiento aplicar.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#objetivo-de-aprendizaje",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes conocerán las principales teorías concernientes a la generación del electrocardiograma y su relación con el funcionamiento del corazón."
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#duración",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#materiales",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-revisión-al-electrocardiograms",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-revisión-al-electrocardiograms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 1: Revisión al electrocardiograms",
    "text": "Actividad 1: Revisión al electrocardiograms\n\n¿Qué es un electrocardiograma (ECG) y cuál es su importancia en el diagnóstico clínico?\n¿Qué información electrofisiológica proporciona un ECG y cómo se relaciona con la actividad del corazón?\n¿Qué es una derivación (lead) en el contexto de un ECG y cuál es su función?\n¿Cuántas derivaciones existen en un ECG estándar y cómo se clasifican?\nObserve la Figura 1 proporcionada y determine a qué derivación corresponde el diagrama mostrado. Justifique su respuesta.\n¿Qué es una arritmia y qué tipos existen? Describa las características de cada tipo de arritmia."
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-análisis-del-articulo",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-análisis-del-articulo",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 2: Análisis del articulo",
    "text": "Actividad 2: Análisis del articulo\n\n¿Cuáles son las principales clases de arritmias que el artículo estudia y cómo se agrupan?\n¿Qué impacto tienen las arritmias en la salud pública según el artículo? Mencione datos estadísticos relevantes.\n¿Por qué es importante mejorar la precisión en la clasificación automática de arritmias?\n¿Cuáles son las principales fuentes de ruido en una señal de ECG y qué técnicas se utilizaron en el artículo para reducirlas?\n¿Por qué se aplicó normalización a las señales ECG? ¿Qué impacto tuvo en la clasificación? Explique el método de normalización.\n¿Cuáles son las principales características extraídas de la señal ECG en este estudio?\n¿Por qué es importante la selección de características para el entrenamiento de un algoritmo de clasificación?"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-3-análisis-de-la-base-de-datos",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-3-análisis-de-la-base-de-datos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 3: Análisis de la base de datos",
    "text": "Actividad 3: Análisis de la base de datos\n\n¿Cuáles fueron los criterios de selección de los pacientes?\n¿Cuántos registros de ECG se recopilaron en total y qué duración tienen las señales analizadas?\n¿Cómo se realizó la toma de datos del ECG? Especifique el número de derivaciones, la duración del registro y la frecuencia de muestreo.\n¿Cuáles fueron las características demográficas de la población estudiada? Describa la distribución por edad y género.\n¿Cuál fue la prevalencia de cada tipo de arritmia en la base de datos? ¿Qué arritmias fueron las más frecuentes y cuáles fueron las menos comunes?"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#criterios-de-evaluación",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Criterios de Evaluación",
    "text": "Criterios de Evaluación\nSustentación del trabajo. Cada equipo deberá responder tres preguntas:\n\nPregunta aleatoria basada en la actividad 2.\nPregunta basada en estadísticas que se obtienen a partir de la tabla de la actividad 1\nPregunta sobre el código utilizado para realizar el laboratorio."
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-generación-de-la-información-base",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-generación-de-la-información-base",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 1: Generación de la información base",
    "text": "Actividad 1: Generación de la información base\nUtilizando el dataset, realice las siguiente tareas:\n\nEnumere todos los posibles diagnósticos que los pacientes pueden tener.\nPara todos los pacientes genere una tabla que debe tener la siguiente información:\n\nID: Identificador del paciente.\nEdad: Edad del paciente.\nSexo: Sexo del paciente.\nDiagnosticos: A partir de aquí se genera una columna por cada diagnóstico posible de un paciente. En cada paciente se registrará un 1 si este fue diagnósticado con la dolencia respectiva. Recomendación: Use los archivos .hea adjuntos en el dataset."
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-análisis-de-la-información",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-análisis-de-la-información",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 2: Análisis de la información",
    "text": "Actividad 2: Análisis de la información\nA partir de la tabla generado en la actividad anterior responda de forma clara y concisa las siguientes preguntas:\n\n¿Cuál es la frecuencia y el porcentaje de casos de Bradicardia Sinusal (SB) en la muestra?\n¿Cuál es la edad promedio y su desviación estándar para los pacientes con Bradicardia #. Sinusal (SB)?\n¿Cuál es el porcentaje de hombres en la categoría de Bradicardia Sinusal (SB)?\n¿Cuántos pacientes fueron diagnosticados con Ritmo Sinusal (SR) y qué porcentaje representa del total?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Ritmo Sinusal (SR)?\n¿Qué porcentaje de los pacientes con Ritmo Sinusal (SR) son hombres?\n¿Cuántos casos de Fibrilación Auricular (AFIB) se reportaron y qué porcentaje representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Fibrilación Auricular (AFIB)?\n¿Qué porcentaje de los pacientes con Fibrilación Auricular (AFIB) son hombres?\n¿Cuántos pacientes presentan Taquicardia Sinusal (ST) y qué porcentaje del total representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia Sinusal (ST)?\n¿Qué porcentaje de los pacientes con Taquicardia Sinusal (ST) son hombres?\n¿Cuál es la frecuencia y el porcentaje de casos de Flutter Auricular (AF) en la muestra?\n¿Cuál es la edad promedio y su desviación estándar para los pacientes con Flutter Auricular (AF)?\n¿Cuál es el porcentaje de hombres en la categoría de Flutter Auricular (AF)?\n¿Cuántos pacientes presentan Irregularidad Sinusal (SI) y qué porcentaje del total representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Irregularidad Sinusal (SI)?\n¿Qué porcentaje de los pacientes con Irregularidad Sinusal (SI) son hombres?\n¿Cuál es la frecuencia y el porcentaje de casos de Taquicardia Supraventricular (SVT) en la muestra?\n¿Cuál es la edad promedio y su desviación estándar para los pacientes con Taquicardia Supraventricular (SVT)?\n¿Cuál es el porcentaje de hombres en la categoría de Taquicardia Supraventricular (SVT)?\n¿Cuántos casos de Taquicardia Auricular (AT) se registraron y qué porcentaje del total representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia Auricular (AT)?\n¿Qué porcentaje de los pacientes con Taquicardia Auricular (AT) son hombres?\n¿Cuántos casos de Taquicardia por Reentrada en el Nodo AV (AVNRT) se reportaron y qué porcentaje representan?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia por Reentrada en el Nodo AV (AVNRT)?\n¿Qué porcentaje de los pacientes con Taquicardia por Reentrada en el Nodo AV (AVNRT) son hombres?\n¿Cuántos pacientes fueron diagnosticados con Taquicardia por Reentrada Auriculoventricular (AVRT) y qué porcentaje representan?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia por Reentrada Auriculoventricular (AVRT)?\n¿Qué porcentaje de los pacientes con Taquicardia por Reentrada Auriculoventricular (AVRT) son hombres?\n¿Cuántos casos de Ritmo de deambulamiento auricular sinusal a auricular (SAAWR) se registraron y qué porcentaje representan?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Ritmo de deambulamiento auricular sinusal a auricular (SAAWR)?\n¿Qué porcentaje de los pacientes con Ritmo de deambulamiento auricular sinusal a auricular (SAAWR) son hombres?\n¿Cuál es el número total de pacientes en la muestra y su edad promedio?\n¿Cuál es el porcentaje total de hombres en la muestra?"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#introduction",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nThe Z-transform is a fundamental tool in digital signal processing (DSP), widely used in biomedical signal processing.\nIt allows analysis of discrete-time biomedical signals such as:\n\nECG (Electrocardiogram): Heart activity\nEEG (Electroencephalogram): Brain waves\nEMG (Electromyogram): Muscle activity\n\nIt helps design digital filters, analyze system stability, and perform signal reconstruction."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#definition-of-the-z-transform",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#definition-of-the-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Definition of the Z-Transform",
    "text": "Definition of the Z-Transform\nThe Z-transform of a discrete-time signal \\(x[n]\\) is defined as:\n\\[X(z) = \\sum_{n=-\\infty}^{\\infty} x[n] z^{-n}\\]\nwhere: - \\(X(z)\\) is the Z-domain representation of \\(x[n]\\). - \\(z\\) is a complex variable: \\(z = r e^{j\\omega}\\), where \\(r\\) is the magnitude and \\(\\omega\\) is the frequency. - The Z-transform provides a way to study frequency characteristics of biomedical signals."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#relationship-with-sampling-frequency",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#relationship-with-sampling-frequency",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Relationship with Sampling Frequency",
    "text": "Relationship with Sampling Frequency\n\nBiomedical signals are continuous in nature, meaning they must be sampled to be processed in a digital system.\nThe sampling frequency ( f_s ) determines how frequently the signal is measured.\nThe relationship between the sampling period ( T_s ) and the sampling frequency is:\n\\[ T_s = \\frac{1}{f_s} \\]\nWhen we apply the Z-transform to a sampled signal, it is closely related to the Discrete-Time Fourier Transform (DTFT):\n\\[ X(e^{j\\omega}) = \\sum_{n=-\\infty}^{\\infty} x[n] e^{-j\\omega n} \\]\n\nSetting ( z = e^{j} ) in the Z-transform equation allows us to evaluate the system in terms of frequency.\nThe Nyquist frequency is ( f_N = ), beyond which aliasing occurs.\n\n\nExample: ECG Sampling - The standard ECG sampling frequency is 250 Hz or 500 Hz. - This means the Z-transform of an ECG signal operates within the frequency range 0 to 125 Hz (or 250 Hz in a 500 Hz system)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#region-of-convergence-roc",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#region-of-convergence-roc",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Region of Convergence (ROC)",
    "text": "Region of Convergence (ROC)\n\nThe Region of Convergence (ROC) determines where the Z-transform sum converges.\nThe ROC provides insights into:\n\nSystem stability\nCausality\nInvertibility\n\n\nTypes of ROC:\n\nRight-sided signals (causal systems):\n\nThe ROC is outside the outermost pole.\nThe system is stable if the ROC includes the unit circle (\\(|z| = 1\\)).\n\nLeft-sided signals (anti-causal systems):\n\nThe ROC is inside the innermost pole.\n\nTwo-sided signals:\n\nThe ROC lies between poles.\n\n\nExample: Stability of a Biomedical Filter\n\nA high-pass ECG filter with transfer function:\n\n\\[H(z) = \\frac{1 - z^{-1}}{1 - 0.95 z^{-1}}\\]\n\nThe pole at 0.95 means the system is stable since \\(|0.95| &lt; 1\\).\nIf the pole were outside the unit circle, the system would be unstable."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#relationship-with-convolution",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#relationship-with-convolution",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Relationship with Convolution",
    "text": "Relationship with Convolution\n\nIn biomedical DSP, filtering operations rely on convolution.\nConvolution in time domain:\n\n\\[y[n] = x[n] * h[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n-k]\\]\n\nMultiplication in Z-domain:\n\n\\[Y(z) = X(z) H(z)\\]\n\nThis simplifies filter design, allowing us to analyze biomedical signals efficiently.\n\nExample: EEG Band-Pass Filtering\n\nEEG signals contain different frequency bands:\n\nDelta (0.5–4 Hz): Deep sleep\nTheta (4–8 Hz): Relaxation\nAlpha (8–12 Hz): Resting state\nBeta (12–30 Hz): Active thinking\n\nA band-pass filter for extracting alpha waves (8–12 Hz) is designed as:\n\n\\[H(z) = \\frac{b_0 + b_1 z^{-1} + b_2 z^{-2}}{1 + a_1 z^{-1} + a_2 z^{-2}}\\]\nThe Z-transform allows us to analyze and optimize this filter."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#example-high-pass-filter-for-ecg-baseline-wander-removal",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#example-high-pass-filter-for-ecg-baseline-wander-removal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example: High-Pass Filter for ECG Baseline Wander Removal",
    "text": "Example: High-Pass Filter for ECG Baseline Wander Removal\nProblem:\nECG signals often suffer from baseline wander, a low-frequency drift due to patient movement or respiration.\nSolution: Use a High-Pass Filter\nA simple first-order high-pass filter is defined by the difference equation:\n\\[ y[n] = x[n] - x[n-1] + 0.95 y[n-1] \\]\nApplying the Z-transform:\n\\[ Y(z) = X(z) - X(z)z^{-1} + 0.95 Y(z) z^{-1} \\]\nRearrange to express the transfer function:\n\\[ H(z) = \\frac{1 - z^{-1}}{1 - 0.95 z^{-1}} \\]\nInterpretation:\n\nThe numerator ( (1 - z^{-1}) ) acts as a high-pass filter by attenuating low frequencies.\nThe denominator ( (1 - 0.95 z^{-1}) ) controls system stability.\nThis filter effectively removes baseline wander while preserving heartbeats."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#conclusion",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#conclusion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe Z-transform is crucial for analyzing and processing biomedical signals.\nIt enables:\n\nStability analysis (Region of Convergence)\nFiltering and feature extraction (EEG, ECG, EMG signals)\nEfficient signal convolution\n\nThe inverse Z-transform reconstructs signals for further analysis.\nUnderstanding the Z-transform helps in filter design, denoising, and feature extraction in biomedical applications."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#references",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#references",
    "title": "Sistemas y Señales Biomédicos",
    "section": "References",
    "text": "References\n\nOppenheim, A. V., & Schafer, R. W. (2010). Discrete-Time Signal Processing.\nIngle, V. K., & Proakis, J. G. (2011). Digital Signal Processing using MATLAB.\nRangayyan, R. M. (2015). Biomedical Signal Analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#the-inverse-z-transform",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#the-inverse-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "The Inverse Z-Transform",
    "text": "The Inverse Z-Transform\n\nThe Inverse Z-Transform allows us to retrieve the original discrete-time signal from \\(X(z)\\).\nIt is given by:\n\n\\[x[n] = \\frac{1}{2\\pi j} \\oint_{C} X(z) z^{n-1} dz\\]\n\nCommon methods to compute the inverse Z-transform:\n\nPartial Fraction Expansion: Used when dealing with rational functions.\nPower Series Expansion: Expanding \\(X(z)\\) as a series to identify coefficients.\nResidue Method: Using contour integration for more complex cases.\n\n\nExample: Step Response in Biomedical Systems\n\nA simple low-pass filter used for smoothing an ECG signal has:\n\n\\[H(z) = \\frac{1}{1 - 0.9z^{-1}}\\]\nExpanding in a power series:\n\\[H(z) = 1 + 0.9z^{-1} + 0.81z^{-2} + 0.729z^{-3} + ...\\]\nThe inverse Z-transform reveals an exponentially decaying impulse response, modeling the smoothing effect of the filter."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_DigitalFilters.html#relationship-with-sampling-method",
    "href": "presentaciones/SYSB/Lect008_DigitalFilters.html#relationship-with-sampling-method",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Relationship with Sampling Method",
    "text": "Relationship with Sampling Method\n\nBiomedical signals originate in continuous time and must be sampled for digital processing.\nSampling frequency (\\(f_s\\)) determines the accuracy of the digital representation:\n\n\\[T_s = \\frac{1}{f_s}\\]\n\nThe Z-transform relates to sampling through the Discrete-Time Fourier Transform (DTFT):\n\n\\[X(e^{j\\omega}) = \\sum_{n=-\\infty}^{\\infty} x[n] e^{-j\\omega n}\\]\nwhere \\(X(e^{j\\omega})\\) is obtained by evaluating the Z-transform along the unit circle: \\(z = e^{j\\omega}\\).\nExample: ECG Sampling Rate\n\nStandard ECG systems sample at 250 Hz or 500 Hz.\nThe Nyquist frequency is 125 Hz or 250 Hz, respectively.\nUsing the Z-transform, we analyze how filters modify the frequency content of ECG signals."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nSignals can be analyzed in both time domain and frequency domain.\nThe frequency content of a signal describes how different frequency components contribute to the overall signal.\nApplications in biomedical signals, audio processing, communications, and image processing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#convolution-in-time-domain",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#convolution-in-time-domain",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution in Time Domain",
    "text": "Convolution in Time Domain\n\nConvolution is a fundamental operation in signal processing.\nGiven two signals ( x(t) ) and ( h(t) ), their convolution is defined as:\n\\[ y(t) = x(t) * h(t) = \\int_{-\\infty}^{\\infty} x(\\tau) h(t - \\tau) d\\tau \\]\nIn discrete-time, convolution is:\n\\[ y[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n-k] \\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#convolution-theorem",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#convolution-theorem",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution Theorem",
    "text": "Convolution Theorem\n\nConvolution in time domain corresponds to multiplication in frequency domain:\n\\[ X(f) H(f) = Y(f) \\]\nThis property is crucial in filter design and system analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-to-fourier-series",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-to-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\n\n(-1.0, 4.0)\n\n\n(-1.0, 4.0)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#fourier-coefficients",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#fourier-coefficients",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fourier Coefficients",
    "text": "Fourier Coefficients\n\nThe Fourier coefficients ( C_n ) are computed as:\n\\[ C_n = \\frac{1}{T} \\int_{0}^{T} x(t) e^{-jn\\omega_0 t} dt \\]\nDetermines how much of each frequency is present in the signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-of-fourier-series-expansion",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-of-fourier-series-expansion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example of Fourier Series Expansion",
    "text": "Example of Fourier Series Expansion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relationship-between-frequency-content-and-sampling-frequency",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relationship-between-frequency-content-and-sampling-frequency",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Relationship Between Frequency Content and Sampling Frequency",
    "text": "Relationship Between Frequency Content and Sampling Frequency\n\nSampling theorem: A signal must be sampled at a frequency at least twice its highest frequency component:\n\\[ f_s \\geq 2 f_{max} \\]\nAliasing occurs if sampling frequency is too low."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-to-fourier-series-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-to-fourier-series-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\nFourier series represents periodic signals as a sum of sinusoids:\n\\[ x(t) = \\sum_{n=-\\infty}^{\\infty} C_n e^{jn\\omega_0 t} \\]\nwhere ( C_n ) are the Fourier coefficients.\nDecomposing a signal into sinusoidal components allows frequency analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nSignals can be analyzed in both time domain and frequency domain.\nThe frequency content of a signal describes how different frequency components contribute to the overall signal.\nApplications in biomedical signals, audio processing, communications, and image processing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-in-time-domain",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-in-time-domain",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution in Time Domain",
    "text": "Convolution in Time Domain\n\nConvolution is a fundamental operation in signal processing.\nGiven two signals \\(x(t)\\) and \\(h(t)\\), their convolution is defined as:\n\\[ y(t) = x(t) * h(t) = \\int_{-\\infty}^{\\infty} x(\\tau) h(t - \\tau) d\\tau \\]\nIn discrete-time, convolution is:\n\\[ y[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n-k] \\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-theorem",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution Theorem",
    "text": "Convolution Theorem\n\nConvolution in time domain corresponds to multiplication in frequency domain:\n\\[ X(f) H(f) = Y(f) \\]\nThis property is crucial in filter design and system analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\n\n(-1.0, 4.0)\n\n\n(-1.0, 4.0)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\nConvolution requiere the representation of the signal in a sum of impulse functions.\nFourier series represents periodic signals as a sum of sinusoids:\n\\[ x(t) = \\sum_{n=-\\infty}^{\\infty} C_n e^{jn\\omega_0 t} \\]\nwhere \\(C_n\\) are the Fourier coefficients.\nDecomposing a signal into sinusoidal components allows frequency analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#fourier-coefficients",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#fourier-coefficients",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fourier Coefficients",
    "text": "Fourier Coefficients\n\nThe Fourier coefficients \\(C_n\\) are computed as:\n\\[ C_n = \\frac{1}{T} \\int_{0}^{T} x(t) e^{-jn\\omega_0 t} dt \\]\nDetermines how much of each frequency is present in the signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-fourier-series-expansion",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-fourier-series-expansion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example of Fourier Series Expansion",
    "text": "Example of Fourier Series Expansion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#relationship-between-frequency-content-and-sampling-frequency",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#relationship-between-frequency-content-and-sampling-frequency",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Relationship Between Frequency Content and Sampling Frequency",
    "text": "Relationship Between Frequency Content and Sampling Frequency\n\nSampling theorem: A signal must be sampled at a frequency at least twice its highest frequency component:\n\\[ f_s \\geq 2 f_{max} \\]\nAliasing occurs if sampling frequency is too low."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example 2 of Fourier Series",
    "text": "Example 2 of Fourier Series\n\n\n(array([-5.,  0.,  5., 10., 15., 20., 25., 30., 35.]), [Text(-5.0, 0, '−5'), Text(0.0, 0, '0'), Text(5.0, 0, '5'), Text(10.0, 0, '10'), Text(15.0, 0, '15'), Text(20.0, 0, '20'), Text(25.0, 0, '25'), Text(30.0, 0, '30'), Text(35.0, 0, '35')])\n\n\n(array([4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5]), [Text(0, 4.5, '4.5'), Text(0, 5.0, '5.0'), Text(0, 5.5, '5.5'), Text(0, 6.0, '6.0'), Text(0, 6.5, '6.5'), Text(0, 7.0, '7.0'), Text(0, 7.5, '7.5'), Text(0, 8.0, '8.0'), Text(0, 8.5, '8.5')])"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example 2 of Fourier Series",
    "text": "Example 2 of Fourier Series\n\n\n(array([-40., -30., -20., -10.,   0.,  10.,  20.,  30.,  40.]), [Text(-40.0, 0, '−40'), Text(-30.0, 0, '−30'), Text(-20.0, 0, '−20'), Text(-10.0, 0, '−10'), Text(0.0, 0, '0'), Text(10.0, 0, '10'), Text(20.0, 0, '20'), Text(30.0, 0, '30'), Text(40.0, 0, '40')])\n\n\n(array([4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5]), [Text(0, 4.5, '4.5'), Text(0, 5.0, '5.0'), Text(0, 5.5, '5.5'), Text(0, 6.0, '6.0'), Text(0, 6.5, '6.5'), Text(0, 7.0, '7.0'), Text(0, 7.5, '7.5'), Text(0, 8.0, '8.0'), Text(0, 8.5, '8.5')])"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Linearity",
    "text": "Linearity\n\nIf \\(f_1(x)\\) and \\(f_2(x)\\) have Fourier series,\nThen for any constants \\(a, b\\),\n\\(a f_1(x) + b f_2(x)\\) has a Fourier series,\nWith coefficients scaled accordingly."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#time-shifting",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#time-shifting",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time Shifting",
    "text": "Time Shifting\n\nIf \\(f(x)\\) has Fourier coefficients \\(a_n, b_n\\),\nThen \\(f(x - x_0)\\) has coefficients:\n\\(a_n \\cos(n\\omega x_0) + b_n \\sin(n\\omega x_0)\\),\nAnd \\(b_n \\cos(n\\omega x_0) - a_n \\sin(n\\omega x_0)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-scaling",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-scaling",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Frequency Scaling",
    "text": "Frequency Scaling\n\nIf \\(g(x) = f(cx)\\),\nThen the period scales by \\(c\\),\nThe fundamental frequency changes to \\(c\\omega\\),\nFourier coefficients adjust accordingly."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#differentiation-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#differentiation-property",
    "title": "Sistemas y Señales Biomédicos",
    "section": "** Differentiation Property**",
    "text": "** Differentiation Property**\n\nIf \\(f(x)\\) is differentiable,\nThen \\(f'(x)\\) has Fourier series,\nWith coefficients scaled as \\(n a_n, n b_n\\),\nHigher frequencies get amplified."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#integration-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#integration-property",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Integration Property",
    "text": "Integration Property\n\nIf \\(f(x)\\) has a Fourier series,\nThen \\(\\int f(x) dx\\) has a Fourier series,\nWith coefficients scaled as \\(\\frac{a_n}{n}, \\frac{b_n}{n}\\),\nLower frequencies get emphasized."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#parsevals-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#parsevals-theorem",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Parseval’s Theorem",
    "text": "Parseval’s Theorem\n\nThe total signal energy is conserved,\nEnergy in time domain equals energy in frequency domain,\nGiven by:\n\\(\\sum (a_n^2 + b_n^2) = \\frac{1}{T} \\int |f(x)|^2 dx\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-property",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution Property",
    "text": "Convolution Property\n\nConvolution in time domain,\nIs multiplication in Fourier series coefficients,\nIf \\(f_1\\) and \\(f_2\\) are convoluted,\nTheir Fourier coefficients multiply component-wise."
  }
]