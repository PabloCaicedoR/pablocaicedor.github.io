[
  {
    "objectID": "proyectos/Sabana/fileProof.html",
    "href": "proyectos/Sabana/fileProof.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport scipy.io as sio\nimport scipy.signal as sig\nfrom scipy.signal import tf2zpk\nfrom scipy.spatial.transform import Rotation as R\n\npath_ecg = \"../../data\"\n\n\ndef plot_imu_frame(axis_length=1.0, arrow_ratio=0.1):\n    \"\"\"\n    Dibuja el sistema de coordenadas de una IMU en 3D.\n\n    Par√°metros:\n    - axis_length: longitud de cada eje.\n    - arrow_ratio: fracci√≥n del eje destinada a la cabeza de la flecha.\n    \"\"\"\n    # Creamos la figura y el eje 3D\n    fig = plt.figure(figsize=(6, 6))\n    ax = fig.add_subplot(111, projection=\"3d\")\n\n    # Origen de los ejes\n    origin = np.array([0, 0, 0])\n\n    # Vectores unitarios para X, Y, Z\n    axes = np.eye(3) * axis_length\n    colors = [\"r\", \"g\", \"b\"]\n    labels = [\"N\", \"Y\", \"-g\"]\n\n    # Dibujar cada eje con quiver (flecha)\n    for vec, c, lab in zip(axes, colors, labels):\n        ax.quiver(\n            origin[0],\n            origin[1],\n            origin[2],\n            vec[0],\n            vec[1],\n            vec[2],\n            color=c,\n            arrow_length_ratio=arrow_ratio,\n            linewidth=2,\n        )\n        # Etiquetar el extremo del eje\n        ax.text(\n            vec[0] * 1.05,\n            vec[1] * 1.05,\n            vec[2] * 1.05,\n            lab,\n            color=c,\n            fontsize=14,\n            fontweight=\"bold\",\n        )\n\n    # Ajustes de estilo\n    ax.set_xlim(0, axis_length * 1.2)\n    ax.set_ylim(0, axis_length * 1.2)\n    ax.set_zlim(0, axis_length * 1.2)\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n    ax.set_zlabel(\"Z\")\n    ax.set_title(\"Sistema de coordenadas IMU\")\n    ax.grid(True)\n\n    # Mostrar proporci√≥n igual para los tres ejes\n    ax.set_box_aspect([1, 1, 1])\n\n    plt.tight_layout()\n    plt.show()\n\n\ndef calcular_relacion_romberg(\n    param_eyes_open: float,\n    param_eyes_close: float,\n) -&gt; float:\n    return param_eyes_close / param_eyes_open\n\n\ndef calcular_rms(signal1):\n    return np.sqrt(np.mean(np.square(signal1)))\n\n\ndef calcular_magnitud_angular_velocity(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleraci√≥n global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Gyr_Global_Mag\"] = np.sqrt(\n        df[\"Gyr_X_global\"] ** 2 + df[\"Gyr_Y_global\"] ** 2 + df[\"Gyr_Z_global\"] ** 2\n    )\n    return df.copy()\n\n\ndef calcular_magnitud_aceleracion_local(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleraci√≥n global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Acc_Local_Mag\"] = np.sqrt(df[\"Acc_Y\"] ** 2 + df[\"Acc_Z\"] ** 2)\n    return df.copy()\n\n\ndef calcular_magnitud_aceleracion(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleraci√≥n global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Acc_Global_Mag\"] = np.sqrt(df[\"Acc_X_global\"] ** 2 + df[\"Acc_Y_global\"] ** 2)\n    return df.copy()\n\n\ndef CalculateGlobalVectors(df):\n    # Cuaterniones y aceleraci√≥n local\n    quaternions = df[[\"Quat_q0\", \"Quat_q1\", \"Quat_q2\", \"Quat_q3\"]].values\n    acc_local = df[[\"Acc_X\", \"Acc_Y\", \"Acc_Z\"]].values\n    ang_vel_local = df[[\"Gyr_X\", \"Gyr_Y\", \"Gyr_Z\"]].values\n\n    sig_filtersos = sig.butter(10, 4, \"low\", fs=100, output=\"sos\")\n\n    # Aplicar filtro a las columnas de aceleraci√≥n\n    acc_local = sig.sosfilt(sig_filtersos, acc_local)\n    ang_vel_local = sig.sosfilt(sig_filtersos, ang_vel_local)\n    df[[\"Acc_X\", \"Acc_Y\", \"Acc_Z\"]] = acc_local\n    df[[\"Gyr_X\", \"Gyr_Y\", \"Gyr_Z\"]] = ang_vel_local\n\n    # Rotar aceleraciones al sistema global\n    rot = R.from_quat(quaternions)\n    acc_global = rot.apply(acc_local)\n    ang_vel_global = rot.apply(ang_vel_local)\n\n    # üîÅ Normalizar Y y Z a m√°ximo absoluto de 1\n    # acc_global[:, 1] = acc_global[:, 1] / np.max(np.abs(acc_global[:, 1]))\n    # acc_global[:, 2] = acc_global[:, 2] / np.max(np.abs(acc_global[:, 2]))\n\n    # Guardar aceleraciones normalizadas\n    df[\"Acc_X_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 0])\n    df[\"Acc_Y_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 1])\n    df[\"Acc_Z_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 2])\n    df[\"Gyr_X_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 0])\n    df[\"Gyr_Y_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 1])\n    df[\"Gyr_Z_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 2])\n    return df.copy()\n\n\ndef select_mid_segment(\n    df: pd.DataFrame,\n    time_col: str = \"Time\",\n    half_length: float = 10.0,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Selecciona el segmento de df que comprende `pre_sec` segundos\n    antes y `post_sec` segundos despu√©s del punto medio de la serie\n    temporal indicada por `time_col`.\n\n    Par√°metros\n    ----------\n    df : pd.DataFrame\n        DataFrame que debe contener la columna de tiempo `time_col`.\n    time_col : str\n        Nombre de la columna de tiempo (en segundos).\n    pre_sec : float\n        Segundos a incluir antes del punto medio.\n    post_sec : float\n        Segundos a incluir despu√©s del punto medio.\n\n    Devuelve\n    -------\n    pd.DataFrame\n        Sub-DataFrame con las mismas columnas que `df`, filtrado\n        para el intervalo [midpoint - pre_sec, midpoint + post_sec].\n    \"\"\"\n    # Calcular extremo inferior y superior del tiempo\n    t_min = df[time_col].min()\n    t_max = df[time_col].max()\n    midpoint = (t_min + t_max) / 2\n\n    start_time = midpoint - half_length\n    end_time = midpoint + half_length\n\n    # Filtrar el DataFrame por el rango de tiempo\n    segment = df[(df[time_col] &gt;= start_time) & (df[time_col] &lt;= end_time)].copy()\n\n    return segment\n\n\ndataDualTask = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/dt_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeClosed = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/ec_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeOpen = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/eo_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeClosed = dataEyeClosed.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\ndataDualTask = dataDualTask.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\ndataEyeOpen = dataEyeOpen.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\nfs = 100\nTs = 1 / fs\ndataEyeOpen[\"Time\"] = Ts * np.arange(0, len(dataEyeOpen))\ndataEyeClosed[\"Time\"] = Ts * np.arange(0, len(dataEyeClosed))\ndataDualTask[\"Time\"] = Ts * np.arange(0, len(dataDualTask))\ndataDualTask = CalculateGlobalVectors(dataDualTask)\ndataEyeClosed = CalculateGlobalVectors(dataEyeClosed)\ndataEyeOpen = CalculateGlobalVectors(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_aceleracion(dataDualTask)\ndataEyeClosed = calcular_magnitud_aceleracion(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_aceleracion(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_aceleracion_local(dataDualTask)\ndataEyeClosed = calcular_magnitud_aceleracion_local(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_aceleracion_local(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_angular_velocity(dataDualTask)\ndataEyeClosed = calcular_magnitud_angular_velocity(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_angular_velocity(dataEyeOpen)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2\n\n\ndef ellipse_sway_area(x, y, confidence=0.95, plot=True):\n    \"\"\"\n    Calcula el √°rea y dibuja la elipse de oscilaci√≥n para los datos (x,y)\n    cubriendo el porcentaje de confianza dado (p.ej. 0.95 para 95%).\n\n    Par√°metros:\n    - x, y: arrays de coordenadas (misma longitud).\n    - confidence: nivel de confianza (entre 0 y 1).\n    - plot: si True, dibuja los puntos y la elipse.\n\n    Retorna:\n    - area: √°rea de la elipse.\n    - width, height: semiejes mayor y menor.\n    - angle: √°ngulo de rotaci√≥n en grados.\n    \"\"\"\n    # Centro (media)\n    mu = np.array([np.mean(x), np.mean(y)])\n    # Matriz de covarianza\n    cov = np.cov(x, y)\n    # Eigenvalores y eigenvectores\n    vals, vecs = np.linalg.eigh(cov)\n    # Ordenar de mayor a menor\n    order = vals.argsort()[::-1]\n    vals = vals[order]\n    vecs = vecs[:, order]\n\n    # Factor de escala: chi-cuadrado inverso para 2 grados y nivel dado\n    chi2_val = chi2.ppf(confidence, df=2)\n    # Semiejes\n    a = np.sqrt(vals[0] * chi2_val)\n    b = np.sqrt(vals[1] * chi2_val)\n    area = np.pi * a * b\n\n    # √Ångulo de rotaci√≥n (en grados) del semieje mayor respecto al eje X\n    angle = np.degrees(np.arctan2(vecs[1, 0], vecs[0, 0]))\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(6, 6))\n        ax.scatter(x, y, s=10, alpha=0.5, label=\"Datos\")\n        # Dibujo de la elipse\n        from matplotlib.patches import Ellipse\n\n        ellipse = Ellipse(\n            xy=mu,\n            width=2 * a,\n            height=2 * b,\n            angle=angle,\n            edgecolor=\"r\",\n            facecolor=\"none\",\n            lw=2,\n            label=f\"{int(confidence*100)}% Elipse\",\n        )\n        ax.add_patch(ellipse)\n        ax.set_aspect(\"equal\")\n        ax.set_xlabel(\"X\")\n        ax.set_ylabel(\"Y\")\n        ax.set_title(\n            f\"Elipse de oscilaci√≥n ({int(confidence*100)}% conf.)\\n√Årea = {area:.2f}\"\n        )\n        ax.legend()\n        plt.grid(True)\n        plt.show()\n\n    return area, a, b, angle\n\n\n# Ejemplo de uso:\nif __name__ == \"__main__\":\n    # Simulamos datos de sway\n    np.random.seed(0)\n    x = np.random.normal(0, 1, size=500)\n    y = 0.5 * x + np.random.normal(0, 0.8, size=500)\n\n    area, a, b, angle = ellipse_sway_area(\n        dataDualTask[\"Acc_X_global\"], dataDualTask[\"Acc_Y_global\"], confidence=0.95\n    )\n    print(f\"√Årea de la elipse al 95 %: {area:.4f}\")\n    print(f\"Semiejes: a={a:.2f}, b={b:.2f}, √°ngulo={angle:.1f}¬∞\")\n\n\n\n\n\n\n\n\n√Årea de la elipse al 95 %: 0.0000\nSemiejes: a=0.00, b=0.00, √°ngulo=67.1¬∞\n\n\n\nrmsAccX_eo = calcular_rms(dataEyeOpen[\"Acc_X_global\"])\nrmsAccY_eo = calcular_rms(dataEyeOpen[\"Acc_Y_global\"])\nrmsAccZ_eo = calcular_rms(dataEyeOpen[\"Acc_Z_global\"])\n\nrmsGyrX_eo = calcular_rms(dataEyeOpen[\"Gyr_X_global\"])\nrmsGyrY_eo = calcular_rms(dataEyeOpen[\"Gyr_Y_global\"])\nrmsGyrZ_eo = calcular_rms(dataEyeOpen[\"Gyr_Z_global\"])\n\npathTrajectAcc_eo = np.sum(dataEyeOpen[\"Acc_Local_Mag\"])\nareaAcc_eo, a, b, angle = ellipse_sway_area(\n    dataEyeOpen[\"Acc_X_global\"],\n    dataEyeOpen[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\n\nrmsAccX_ec = calcular_rms(dataEyeClosed[\"Acc_X_global\"])\nrmsAccY_ec = calcular_rms(dataEyeClosed[\"Acc_Y_global\"])\nrmsAccZ_ec = calcular_rms(dataEyeClosed[\"Acc_Z_global\"])\n\nrmsGyrX_ec = calcular_rms(dataEyeClosed[\"Gyr_X_global\"])\nrmsGyrY_ec = calcular_rms(dataEyeClosed[\"Gyr_Y_global\"])\nrmsGyrZ_ec = calcular_rms(dataEyeClosed[\"Gyr_Z_global\"])\n\npathTrajectAcc_ec = np.sum(dataEyeClosed[\"Acc_Local_Mag\"])\nareaAcc_ec, a, b, angle = ellipse_sway_area(\n    dataEyeClosed[\"Acc_X_global\"],\n    dataEyeClosed[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\n\nrmsAccX_dt = calcular_rms(dataDualTask[\"Acc_X_global\"])\nrmsAccY_dt = calcular_rms(dataDualTask[\"Acc_Y_global\"])\nrmsAccZ_dt = calcular_rms(dataDualTask[\"Acc_Z_global\"])\n\nrmsGyrX_dt = calcular_rms(dataDualTask[\"Gyr_X_global\"])\nrmsGyrY_dt = calcular_rms(dataDualTask[\"Gyr_Y_global\"])\nrmsGyrZ_dt = calcular_rms(dataDualTask[\"Gyr_Z_global\"])\n\npathTrajectAcc_dt = np.sum(dataDualTask[\"Acc_Local_Mag\"])\nareaAcc_dt, a, b, angle = ellipse_sway_area(\n    dataDualTask[\"Acc_X_global\"], dataDualTask[\"Acc_Y_global\"], confidence=0.95,plot=False\n)\n\n\nrmsAccX_dt = calcular_rms(dataDualTask[\"Acc_X_global\"])\nrmsAccY_dt = calcular_rms(dataDualTask[\"Acc_Y_global\"])\nrmsAccZ_dt = calcular_rms(dataDualTask[\"Acc_Z_global\"])\n\nrmsGyrX_dt = calcular_rms(dataDualTask[\"Gyr_X_global\"])\nrmsGyrY_dt = calcular_rms(dataDualTask[\"Gyr_Y_global\"])\nrmsGyrZ_dt = calcular_rms(dataDualTask[\"Gyr_Z_global\"])\n\npathTrajectAcc_dt = np.sum(dataDualTask[\"Acc_Local_Mag\"])\nareaAcc_dt, a, b, angle = ellipse_sway_area(\n    dataDualTask[\"Acc_X_global\"],\n    dataDualTask[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\nrmsAccX_ec = calcular_rms(dataEyeClosed[\"Acc_X_global\"])\nrmsAccY_ec = calcular_rms(dataEyeClosed[\"Acc_Y_global\"])\nrmsAccZ_ec = calcular_rms(dataEyeClosed[\"Acc_Z_global\"])\n\nrmsGyrX_ec = calcular_rms(dataEyeClosed[\"Gyr_X_global\"])\nrmsGyrY_ec = calcular_rms(dataEyeClosed[\"Gyr_Y_global\"])\nrmsGyrZ_ec = calcular_rms(dataEyeClosed[\"Gyr_Z_global\"])\n\npathTrajectAcc_ec = np.sum(dataEyeClosed[\"Acc_Local_Mag\"])\nareaAcc_ec, a, b, angle = ellipse_sway_area(\n    dataEyeClosed[\"Acc_X_global\"],\n    dataEyeClosed[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\nrmsAccX_eo = calcular_rms(dataEyeOpen[\"Acc_X_global\"])\nrmsAccY_eo = calcular_rms(dataEyeOpen[\"Acc_Y_global\"])\nrmsAccZ_eo = calcular_rms(dataEyeOpen[\"Acc_Z_global\"])\n\nrmsGyrX_eo = calcular_rms(dataEyeOpen[\"Gyr_X_global\"])\nrmsGyrY_eo = calcular_rms(dataEyeOpen[\"Gyr_Y_global\"])\nrmsGyrZ_eo = calcular_rms(dataEyeOpen[\"Gyr_Z_global\"])\n\npathTrajectAcc_eo = np.sum(dataEyeOpen[\"Acc_Local_Mag\"])\nareaAcc_eo, a, b, angle = ellipse_sway_area(\n    dataEyeOpen[\"Acc_X_global\"],\n    dataEyeOpen[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)"
  },
  {
    "objectID": "clases/talleres.html",
    "href": "clases/talleres.html",
    "title": "Talleres",
    "section": "",
    "text": "Taller Primer Semestre"
  },
  {
    "objectID": "clases/Class_PSIM.html",
    "href": "clases/Class_PSIM.html",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "‚ÄúUn √°rea de r√°pido crecimiento y variedad de aplicaciones en la ingenier√≠a biom√©dica a nivel nacional y global es el procesamiento digital de se√±ales e im√°genes m√©dicas. Es por eso, que a trav√©s de este curso se desea dar las herramientas necesarias para los graduados del programa puedan tener competencias b√°sicas en las t√©cnicas cl√°sicas y algunas t√©cnicas modernas de procesamiento de se√±ales e im√°genes. La primera parte del curso se encuentra enfocada al desarrollo de t√©cnicas de procesamiento para se√±ales biom√©dicas unidimensionales, exponiendo primero su origen fisiol√≥gico y siguiendo con la presentaci√≥n de las principales t√©cnicas para su an√°lisis y procesamiento. La segunda parte del curso hace √©nfasis en el estudio de im√°genes m√©dicas, partiendo de una explicaci√≥n de los principales m√©todos computacionales utilizados para procesamiento digital de im√°genes y luego exponiendo brevemente el proceso de su formaci√≥n. A trav√©s de pr√°cticas de laboratorio con se√±ales e im√°genes m√©dicas (reales o simuladas), el estudiante podr√° aplicar y reforzar los conocimientos aprendidos en el curso‚Äù fragmento tomado del microcurriculo de la asignatura.\nEl curso est√° dividido en 4 partes:\n1. Introducci√≥n al procesado de se√±ales e im√°genes biom√©dicas.\n2. Fundamentos procesado de se√±ales e im√°genes biom√©dicas\n3. Extracci√≥n de caracter√≠sticas de se√±ales biom√©dicas.\n4. Extracci√≥n de caracter√≠sticas de im√°genes biom√©dicas."
  },
  {
    "objectID": "clases/Class_PSIM.html#presentaciones",
    "href": "clases/Class_PSIM.html#presentaciones",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentaci√≥n del curso\nIntroducci√≥n\nIntroducci√≥n al procesamiento de imagenes\nLa imagen digital. Procesamiento de Im√°genes 1/4\nLa imagen digital. Procesamiento de Im√°genes 2/4\nRespuesta en frecuencia. (3/4)\nWavelets 4/4"
  },
  {
    "objectID": "clases/Class_PSIM.html#datos",
    "href": "clases/Class_PSIM.html#datos",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_PSIM.html#c√≥digos",
    "href": "clases/Class_PSIM.html#c√≥digos",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "C√≥digos",
    "text": "C√≥digos"
  },
  {
    "objectID": "clases/Class_PSIM.html#laboratorios",
    "href": "clases/Class_PSIM.html#laboratorios",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio 01\nLaboratorio 02\nLaboratorio 03"
  },
  {
    "objectID": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "href": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nPrimer Parcial\nSegundo Parcial\nTercer Parcial"
  },
  {
    "objectID": "clases/Class_ASIM.html",
    "href": "clases/Class_ASIM.html",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "",
    "text": "Aprender procesamiento de se√±ales e im√°genes con aprendizaje autom√°tico en medicina es crucial para mejorar la precisi√≥n y eficiencia en el diagn√≥stico y tratamiento de enfermedades. El aprendizaje autom√°tico permite analizar grandes cantidades de datos de im√°genes m√©dicas y se√±ales biom√©dicas, como rayos X, tomograf√≠as computarizadas, resonancia magn√©tica, ECG, EEG y EMG, para identificar patrones y anomal√≠as que pueden indicar la presencia de enfermedades. Esto puede llevar a un diagn√≥stico m√°s preciso y temprano, lo que a su vez puede mejorar los resultados para los pacientes y reducir la morbilidad y mortalidad.\nAdem√°s, el aprendizaje autom√°tico puede ayudar a personalizar tratamientos para pacientes individuales seg√∫n sus caracter√≠sticas √∫nicas de im√°genes m√©dicas y se√±ales. Tambi√©n puede automatizar tareas cl√≠nicas rutinarias, como segmentaci√≥n de im√°genes, extracci√≥n de caracter√≠sticas y an√°lisis de datos, lo que permite a los m√©dicos centrarse en la toma de decisiones de alto nivel.\nLa aplicaci√≥n del aprendizaje autom√°tico en medicina tambi√©n puede facilitar la investigaci√≥n m√©dica, analizando grandes conjuntos de datos para identificar tendencias y patrones que pueden revelar nuevos conocimientos sobre enfermedades y tratamientos. Adem√°s, puede permitir la monitorizaci√≥n remota de pacientes y la telemedicina, ampliando el acceso a servicios de atenci√≥n m√©dica."
  },
  {
    "objectID": "clases/Class_ASIM.html#presentaciones",
    "href": "clases/Class_ASIM.html#presentaciones",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nClase 001: Introducci√≥n al machine learning"
  },
  {
    "objectID": "clases/Class_ASIM.html#laboratorios",
    "href": "clases/Class_ASIM.html#laboratorios",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLab00: Conducta de entrada\nLab01: Programaci√≥n orientada a objetos"
  },
  {
    "objectID": "clases/Class_ASIM.html#atenci√≥n-a-estudiantes",
    "href": "clases/Class_ASIM.html#atenci√≥n-a-estudiantes",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Atenci√≥n a estudiantes",
    "text": "Atenci√≥n a estudiantes"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "href": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "title": "Proyecto Final: APSB1",
    "section": "",
    "text": "Criterio\n1 - Deficiente\n2 - Insuficiente\n3 - Aceptable\n4 - Bueno\n5 - Excelente\nPonderaci√≥n\n\n\n\n\nDefinici√≥n del Problema y Justificaci√≥n\nNo se identifica un problema biom√©dico claro.\nSe identifica un problema, pero sin relevancia biom√©dica o justificaci√≥n.\nSe plantea un problema relevante con justificaci√≥n b√°sica.\nProblema bien definido con referencias cient√≠ficas.\nProblema biom√©dico bien formulado, con justificaci√≥n s√≥lida basada en literatura cient√≠fica.\n15%\n\n\nAdquisici√≥n y Procesamiento de Datos en el Borde\nNo se especifica el tipo de datos ni sensores.\nSe mencionan sensores, pero sin detalles sobre la captura y preprocesamiento.\nSe describe la adquisici√≥n de datos con procesamiento b√°sico.\nSe justifica la selecci√≥n de sensores y se menciona un preprocesamiento adecuado.\nSelecci√≥n √≥ptima de sensores con procesamiento avanzado y justificaci√≥n t√©cnica detallada.\n20%\n\n\nDesarrollo e Implementaci√≥n del Modelo de IA\nNo se propone un modelo de IA.\nSe menciona un modelo, pero sin adecuaci√≥n a Edge AI.\nSe plantea un modelo b√°sico con justificaci√≥n limitada.\nSe elige un modelo adecuado y optimizado para Edge AI.\nModelo avanzado con t√©cnicas de optimizaci√≥n y justificadas con m√©tricas.\n20%\n\n\nValidaci√≥n y Pruebas en Tiempo Real\nNo se contempla validaci√≥n del modelo.\nSe menciona validaci√≥n, pero sin metodolog√≠a clara.\nSe plantea una validaci√≥n con datos simulados.\nSe incluyen pruebas con datos reales y m√©tricas de rendimiento.\nValidaci√≥n robusta con pruebas extensivas y comparaci√≥n con est√°ndares biom√©dicos.\n20%\n\n\nEscalabilidad y Aplicabilidad en la Industria Biom√©dica\nNo se considera la escalabilidad del proyecto.\nSe menciona la escalabilidad, pero sin detalles t√©cnicos.\nSe plantea una estrategia b√°sica de escalabilidad.\nEstrategia clara de implementaci√≥n y compatibilidad con sistemas m√©dicos.\nProyecto altamente escalable, con integraci√≥n en entornos cl√≠nicos y est√°ndares como HL7 o FHIR.\n15%\n\n\nPresentaci√≥n y Documentaci√≥n\nNo hay documentaci√≥n ni presentaci√≥n clara.\nDocumentaci√≥n incompleta o desordenada.\nPresentaci√≥n b√°sica con documentaci√≥n limitada.\nPresentaci√≥n clara y documentada correctamente.\nDocumentaci√≥n profesional con detalles t√©cnicos y presentaci√≥n estructurada.\n10%"
  },
  {
    "objectID": "rubricas/Rubrica_EDA.html",
    "href": "rubricas/Rubrica_EDA.html",
    "title": "R√∫brica: An√°lisis Exploratorio de Datos",
    "section": "",
    "text": "Indicador\nBueno\nSuficiente\nInsuficiente\n\n\n\n\nLimpieza del Dataset\nEl dataset no presenta ni registros nulos, ni vac√≠os. Existe una estrategia para manejo de at√≠picos (100%)\nEl dataset no presenta ni registros nulos, ni vac√≠os (50%)\nEl dataset presenta registros nulos y/o vac√≠os. No existe una estrategia para manejo de at√≠picos (0%)\n\n\nConsumo de informaci√≥n\nSe consumen al menos 2 fuentes de datos provenientes de las sugerencias de los organizadores (100%)\nSe consume una fuente de datos proveniente de las sugerencias de los organizadores (50%)\nNo se consume ninguna fuente de datos conocida (0%)\n\n\nEDA sobre nuevas variables\nSe plantean correctamente las relaciones entre la variables y estas se demuestran a plenitud utilizando matem√°tica y/o estad√≠stica (100%)\nSe plantean dos relaciones entre las variables (50%)\nNo se plantean las relaciones entre las variables (0%)\n\n\nUso de plantilla\nUsan la plantilla rmarkdown (100%)\n\nNo se usa la plantilla rmarkdown(0%)\n\n\nVisualizaci√≥n de la informacion\nLa informaci√≥n de TODAS las gr√°ficas se observa plenamente (100%)\nLa informaci√≥n de las gr√°ficas se observa parcialmente(50%)\nLa informaci√≥n de la gr√°fica no se observa (0%)\n\n\nJustificaci√≥n del problema\nExiste una justificaci√≥n del problema(100%)\n\nNo Existe justificaci√≥n al problema resuelto (0%)\n\n\nUbicaci√≥n del problema\nSe plantea correctamente la ubicaci√≥n del problema 100%\n\nNo se plantea correctamente la ubicaci√≥n del problema 0%"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Procesado de Se√±ales e Im√°genes M√©dicas en la Escuela Colombiana de Ingenier√≠a\n\n\n\n10 oct 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Se√±ales e Im√°genes M√©dicas en la Escuela Colombiana de Ingenier√≠a\n\n\n\n25 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de Talleres Ingenier√≠a Biom√©dica en la Escuela Colombiana de Ingenier√≠a\n\n\n\n11 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Sistemas y Se√±ales Biom√©dicoss en la Escuela Colombiana de Ingenier√≠a\n\n\n\n9 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde en la Escuela Colombiana de Ingenier√≠a\n\n\n\n8 sept 2025\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#clases",
    "href": "index.html#clases",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Procesado de Se√±ales e Im√°genes M√©dicas en la Escuela Colombiana de Ingenier√≠a\n\n\n\n10 oct 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Se√±ales e Im√°genes M√©dicas en la Escuela Colombiana de Ingenier√≠a\n\n\n\n25 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de Talleres Ingenier√≠a Biom√©dica en la Escuela Colombiana de Ingenier√≠a\n\n\n\n11 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Sistemas y Se√±ales Biom√©dicoss en la Escuela Colombiana de Ingenier√≠a\n\n\n\n9 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde en la Escuela Colombiana de Ingenier√≠a\n\n\n\n8 sept 2025\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#tutoriales",
    "href": "index.html#tutoriales",
    "title": "PECR Knowledge Hub",
    "section": "Tutoriales",
    "text": "Tutoriales\n\n\n\n\n\n\n\n\n\n\nInstalaci√≥n de Entorno de trabajo. Ubuntu WSL2\n\n\nTutorial\n\n\n\n8 sept 2025\n\n\n\n\n\n\n\n\n\n\n\nCaso pr√°ctico: An√°lisis de se√±ales EMG en rendimiento deportivo con ML/DL\n\n\nASIM_M\n\n\n\n23 jul 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython programming\n\n\nA small tutorial in python in slides\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\nMicrobit ‚Äì El minicomputador\n\n\nTutorial: Electr√≥nica B√°sica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\nMicrobit ‚Äì El minicomputador\n\n\nTutorial: Electr√≥nica B√°sica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial de Python\n\n\nBreve Tutorial de Python\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputaci√≥n de seno y coseno usando expansi√≥n de Taylor\n\n\nUn ejemplo de clase del c√°lculo de una serie de Taylor sin uso de librer√≠as especiales de Python ‚Äì En construcci√≥n ‚Äì\n\n\n\n6 feb 2023\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#proyectos",
    "href": "index.html#proyectos",
    "title": "PECR Knowledge Hub",
    "section": "Proyectos",
    "text": "Proyectos\n\n\n\n\n\n\n\n\n\n\nPredictive modeling for seizure detection in pharmacoresistant epilepsy: a machine learning approach\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparing different Machine Learning architectures for classifying medical terms in Colombian sign language\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "recursos/talleres/SYSB/Taller_2025_1.html",
    "href": "recursos/talleres/SYSB/Taller_2025_1.html",
    "title": "Taller 1 - Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Taller 1\nProfesores\nJenny Carolina Castiblanco S√°nchez\nPablo Eduardo Caicedo Rodr√≠guez\nDescripci√≥n\nA trav√©s de este taller se reforzar√°n los conocimientos en: se√±ales, transformaciones de la variable independiente, clasificaci√≥n de se√±ales, ADC y DAC.\nProcedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuaci√≥n.\nConsidere la se√±al\nDibuje:\nDetermine si las siguientes se√±ales son peri√≥dicas y encuentre su periodo\nPara las siguientes se√±ales encuentre, la potencia instant√°nea, la energ√≠a y la potencia promedio. Indique si la se√±al se considera de energ√≠a o de potencia.\nDemuestre que si y son se√±ales impares, entonces:\n, es una se√±al par\nes una se√±al impar.\nSiendo y , grafique en Python y . ¬øse cumple lo indicado en el numeral a y b?\nEncuentre la expresi√≥n anal√≠tica de las se√±ales mostradas a continuaci√≥n utilizando funciones y (escal√≥n unitario y rampa).\nPara una se√±al an√°loga encontrar\nIndique si la se√±al es una se√±al peri√≥dica, en caso afirmativo, indique el periodo de la se√±al.\nFrecuencia de muestro que cumpla con el teorema de Nyquist.\nEncontrar con la frecuencia de muestreo encontrada en el punto anterior.\nIndique si la se√±al es una se√±al peri√≥dica, en caso afirmativo, indique el periodo de la se√±al.\nConsidere el sistema de procesamiento de se√±ales mostrado en la figura:\nRecuerde que . Si la entrada es , encontrar:\nLa salida si . ¬øCon esta frecuencia se puede reconstruir la se√±al en si ? Justifique su respuesta.\nLa salida si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¬øLa se√±al es peri√≥dica en tiempo discreto? Justifique su respuesta.\nPara la se√±al del punto b, encontrar la se√±al cuantizada de un ciclo de la se√±al si el tama√±o del registro es de 4bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "A trav√©s de este taller se reforzar√°n los conocimientos en: se√±ales, transformaciones de la\nvariable independiente, clasificaci√≥n de se√±ales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripci√≥n",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "A trav√©s de este taller se reforzar√°n los conocimientos en: se√±ales, transformaciones de la\nvariable independiente, clasificaci√≥n de se√±ales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuaci√≥n.\n\n1. Considere la se√±al\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\nSoluci√≥n\nSe grafican las transformaciones solicitadas en Python con Matplotlib.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_t(t):\n    return np.piecewise(t, [(-1 &lt;= t) & (t &lt;= 0), (0 &lt; t) & (t &lt;= 2), (2 &lt; t) & (t &lt;= 3)],\n                         [lambda t: t + 1, 2, 1, 0])\n\nt = np.linspace(-2, 4, 1000)\nplt.plot(t, x_t(t), label='x(t)')\nplt.xlabel('t')\nplt.ylabel('x(t)')\nplt.legend()\nplt.show()\n\n\n\n\n2. Determine si las siguientes se√±ales son peri√≥dicas y encuentre su periodo\n\nSoluci√≥n\nAnalizamos si \\(\\frac{f_0}{f_s}\\) es racional.\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\nPer√≠odos: \\(T_1 = \\frac{2\\pi}{2} = \\pi\\), \\(T_2 = \\frac{2\\pi}{\\pi} = 2\\)\nM√≠nimo com√∫n m√∫ltiplo: **Per√≠odo = 2*\n\n\\(x(t) = e^{-j(4\\pi/3)t} + e^{j(2\\pi/5)t}\\)\n\nSe buscan los per√≠odos fundamentales.\nNo es peri√≥dica porque las razones de frecuencias son irracionales.\n\n\n‚Ä¶\n\n\n\n\n5. Para una se√±al an√°loga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nSoluci√≥n\n\nPer√≠odo de la se√±al:\n\nFrecuencias: \\(f_1 = 300Hz\\), \\(f_2 = 240Hz\\)\nMCM de \\(\\frac{1}{300}\\) y \\(\\frac{1}{240}\\) ‚Üí T = 1/60 s\n\nFrecuencia de muestreo\n\nTeorema de Nyquist: \\(f_s &gt; 2f_{max} = 600Hz\\)\n\nSe√±al muestreada:\nfs = 600  # Hz\nn = np.arange(0, 100)\nxa_n = np.sin(600*np.pi*n/fs) + 3*np.sin(480*np.pi*n/fs)\nplt.stem(n, xa_n)\nplt.show()\n\n‚Ä¶\n\n\n\n6. Muestreo y cuantizaci√≥n\n\nSoluci√≥n\n\nFrecuencia de muestreo:\n\n\\(T_m1 = 12.5ms\\) ‚Üí \\(f_s = 80Hz\\)\nNo cumple Nyquist ‚Üí No se puede reconstruir\n\nMuestreo a 8 veces Nyquist:\n\n\\(f_s = 5760Hz\\)\nSe eval√∫a si \\(\\frac{f_0}{f_s}\\) es racional ‚Üí S√≠ es peri√≥dica\n\nCuantizaci√≥n (4 bits, rango 0-5):\n\nPaso de cuantizaci√≥n: \\(\\Delta = \\frac{5}{2^4}\\)\nSe discretiza la se√±al seg√∫n niveles de cuantizaci√≥n.\n\n\nimport numpy as np\nlevels = np.linspace(0, 5, 16)\nquantized_signal = np.digitize(xa_n, levels) * (5 / 16)\nplt.stem(n, quantized_signal)\nplt.show()\n\nFin del taller."
  },
  {
    "objectID": "recursos/documentos/Teoria_Se√±alesEnergiaPotencia.html",
    "href": "recursos/documentos/Teoria_Se√±alesEnergiaPotencia.html",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "¬øPor qu√© distinguir entre se√±ales de energ√≠a y se√±ales de potencia en procesamiento de se√±ales?\n\nEl conjunto matem√°tico adecuado.Las se√±ales de energ√≠a pertenecen a \\(L^{2}\\) con norma finita \\(\\lVert x\\rVert_{2}=\\sqrt{E}\\), lo que habilita resultados como Parseval/Plancherel (p.¬†ej., \\(\\int_{-\\infty}^{\\infty}\\lvert x(t)\\rvert^{2},dt=\\tfrac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert X(\\omega)\\rvert^{2},d\\omega\\)). Las se√±ales de potencia suelen requerir promedios temporales y estad√≠sticas de segundo orden en lugar de normas finitas.\nEl an√°lisis espectral difiere. En se√±ales de energ√≠a, el objeto natural es la transformada de Fourier \\(X(\\omega)\\) y la energ√≠a se concentra en \\(\\lvert X(\\omega)\\rvert^{2}\\). En se√±ales de potencia (p.¬†ej., peri√≥dicas o estacionarias), el objeto clave es la densidad espectral de potencia (PSD) \\(S_{X}(\\omega)\\), obtenida a partir de la autocorrelaci√≥n \\(R_{X}(\\tau)\\) v√≠a Wiener‚ÄìKhinchin: \\(S_{X}(\\omega)=\\mathcal{F}{R_{X}(\\tau)}\\).\nLas m√©tricas de desempe√±o dependen de la clase. La relaci√≥n se√±al-ruido se formula como SNR de energ√≠a \\(\\mathrm{SNR}=E_{s}/E_{n}\\) para pulsos/transitorios y como SNR de potencia \\(\\mathrm{SNR}=P_{s}/P_{n}\\) para procesos de larga duraci√≥n o estacionarios. Usar la m√©trica incorrecta sesga el dise√±o de detectores/estimadores.\nDise√±o y evaluaci√≥n de filtros. Para se√±ales de energ√≠a, la detecci√≥n √≥ptima usa filtros casados que maximizan la energ√≠a de salida. Para se√±ales de potencia/estacionarias, se modela el ruido mediante la PSD (p.¬†ej., filtrado de Wiener) y se eval√∫a la potencia o varianza de salida.\nMuestreo, ventanas y pr√°ctica con DFT/FFT. Se√±ales de energ√≠a: se integra la energ√≠a en el intervalo observado e interprete \\(\\lvert X[k]\\rvert^{2}\\) como distribuci√≥n de energ√≠a por bins de la DFT. Se√±ales de potencia: se estima la PSD con periodogramas/Welch; \\(S_{X}(\\omega)\\) tiene unidades de potencia por Hz y se promedia entre ventanas para reducir varianza.\nModelado de biosenÃÉales reales. Muchos estallidos/transitorios biom√©dicos (r√°fagas de EMG, potenciales evocados) se comportan como se√±ales de energ√≠a; componentes cuasi-peri√≥dicos o estacionarios de larga duraci√≥n (fundamental del ECG en reposo, respiraci√≥n en minutos) se comportan como se√±ales de potencia. Modelarlas correctamente gu√≠a la extracci√≥n de rasgos (envolventes basadas en energ√≠a vs.¬†bandas de PSD).\nArgumentos de convergencia y estabilidad. Demostraciones de convergencia para estimadores y cotas de estabilidad para sistemas suelen asumir energ√≠a finita o potencia promedio finita; clasificar mal invalida esas garant√≠as.\nUnidades e interpretaci√≥n. Los espectros de energ√≠a se relacionan con \\(\\lvert X(\\omega)\\rvert^{2}\\) (su integral total da \\(E\\)). La PSD integra a potencia promedio: \\(\\tfrac{1}{2\\pi}\\int_{-\\infty}^{\\infty}S_{X}(\\omega),d\\omega=P\\).\nRegla r√°pida. Si la se√±al se extingue o es estrictamente acotada en tiempo y \\(\\int\\lvert x\\rvert^{2}\\) es finita, tr√°tela como energ√≠a; si persiste indefinidamente con promedio bien definido, tr√°tela como potencia y use \\(R_{X}(\\tau)\\)/\\(S_{X}(\\omega)\\)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html",
    "href": "recursos/documentos/SYSB/cuantizacion.html",
    "title": "Quantization",
    "section": "",
    "text": "Quantization maps a continuous-amplitude signal to a finite set of discrete levels so that it can be represented by digits. After anti-alias filtering and sampling, an analog-to-digital converter (ADC) applies quantization. This process introduces an error that acts like noise under standard conditions; understanding its magnitude is essential to sizing bit depth, gain, and dynamic range in biomedical systems (ECG, EEG, EMG, PPG).\n\n\n\nLet the ADC input range be \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\) with \\(b\\) bits and \\(L=2^b\\) levels. The step size (LSB) is\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nTwo common realizations:\n\nMid-tread (rounding): \\(Q(x)=\\Delta,\\mathrm{round}\\left(\\frac{x}{\\Delta}\\right)\\) for \\(x\\in(V\\_{\\min},V\\_{\\max})\\).\nMid-rise (truncate with half-step offset): \\(Q(x)=\\Delta!\\left(\\left\\lfloor\\frac{x}{\\Delta}\\right\\rfloor+\\tfrac12\\right)\\).\n\nOutside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\), overload/clipping occurs: \\(\\tilde{x}=Q(x)=V\\_{\\max}\\) if \\(x&gt;V\\_{\\max}\\) and \\(\\tilde{x}=V\\_{\\min}\\) if \\(x\\&lt;V\\_{\\min}\\).\nCodebook and decision thresholds: Decision thresholds lie at \\(k\\Delta\\) and reconstruction levels at either \\(k\\Delta\\) (mid-tread) or \\((k+\\tfrac12)\\Delta\\) (mid-rise).\n\n\n\nDefine the quantization error \\(e=x-Q(x)\\). Under the high-resolution assumptions (signal varies slowly relative to \\(\\Delta\\), input well distributed within the range, and no overload), the error is modeled as white, signal-independent, and uniformly distributed on \\(\\left[-\\frac{\\Delta}{2},\\frac{\\Delta}{2}\\right]\\):\n\nMean: \\(\\mathbb{E}\\left[e\\right]=0\\).\nVariance (power): \\(\\sigma\\_e^2=\\dfrac{\\Delta^2}{12}\\).\nRMS: \\(\\sigma\\_e=\\dfrac{\\Delta}{\\sqrt{12}}\\).\n\nFor a full-scale sinusoid, the theoretical SNR is\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nIf the signal uses only a fraction \\(\\rho\\) (\\(0&lt;\\rho\\le 1\\)) of full scale (FS) in RMS, then\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]\nEffective Number of Bits (ENOB) from a measured in-band SNR:\n\\[\n\\mathrm{ENOB} \\approx \\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]\n\n\n\nFront-end analog gain \\(G\\) maps a biomedical signal \\(x\\_{\\text{in}}\\) to the ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\). The input-referred LSB is\n\\[\n\\Delta_{\\text{in}}=\\frac{\\Delta}{G}.\n\\]\nChoose \\(G\\) to:\n\navoid overload for rare peaks, and 2) maximize FS utilization to improve SNR. Poor gain wastes bits (small \\(\\rho\\)) or clips clinically relevant transients (e.g., ECG pacer spikes).\n\n\n\n\nSuppose a resting ECG has peak amplitudes around \\(\\pm 5,\\text{mV}\\) at the electrodes. We design the analog front end so that \\(\\pm 5,\\text{mV}\\) maps to \\(\\pm 1,\\text{V}\\) at the ADC, i.e., \\(G=200\\). Use a \\(b=12\\)-bit ADC over \\(\\left[-1,\\text{V},,1,\\text{V}\\right]\\):\n\nADC LSB: \\(\\Delta = \\dfrac{2,\\text{V}}{2^{12}} \\approx 0.488,\\text{mV}\\) (at the ADC input).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\dfrac{0.488,\\text{mV}}{200}\\approx 2.44,\\mu\\text{V}\\).\nInput-referred quantization-noise RMS: \\(\\dfrac{\\Delta\\_{\\text{in}}}{\\sqrt{12}}\\approx 0.704,\\mu\\text{V}\\_{\\mathrm{RMS}}\\).\n\nIf the ECG uses \\(\\rho=0.5\\) of full scale (typical margin against clipping), the quantization-limited SNR is approximately\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\times 12 + 1.76 + 20\\log_{10}(0.5) \\approx 74.0 - 6.0 \\approx 68\\,\\text{dB}.\n\\]\nThis is usually below amplifier and electrode noise constraints, so 12 bits are adequate for diagnostic ECG in this setting. If the chain is quieter (e.g., invasive potentials), higher bit depth or larger \\(G\\) may be justified.\n\n\n\nWhen the amplitude distribution is strongly non-uniform, companding transforms \\(x\\) before uniform quantization to allocate more levels where the signal spends more time. Classical laws:\n\n\\(\\mu\\)-law: \\(y=\\mathrm{sgn}(x),\\dfrac{\\ln(1+\\mu |x|/X\\_{\\max})}{\\ln(1+\\mu)}\\), \\(\\mu\\approx 255\\) (telephony).\n\\(A\\)-law: piecewise logarithmic with parameter \\(A\\) (Europe).\n\nCompanding is common in speech/audio telemetry; in biomedicine it is less standard for primary acquisition, but can help in low-bit-rate wireless monitoring where dynamic range is wide (e.g., PPG with motion).\n\n\n\nAdding small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization decorrelates the error from the signal, eliminating patterning and bias at low amplitudes. This linearizes averages at the cost of a small SNR penalty. Dither can be beneficial for low-level EEG/EMG features and precise baseline estimates.\n\n\n\n\nChoose \\(b\\) so that \\(\\mathrm{SNR}\\_{\\mathrm{dB}}\\) exceeds clinical SNR needs by margin (10‚Äì20 dB).\nSet \\(G\\) so typical peaks use \\(50\\)‚Äì\\(80%\\) FS; verify pacer spikes and motion spikes do not clip.\nBudget noise: electrode + amplifier + ADC quantization; the largest non-white source often dominates.\nValidate with a calibrated source (sinusoidal and biomedical-like waveforms) and measure in-band SNR/ENOB.\n\n\n\n\n\n\n# Synthetic ECG, uniform quantization at multiple bit depths, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# --- 1) Build a simple ECG template (P-QRS-T) using Gaussians ---\nfs = 360.0                      # sampling rate [Hz]\nT = 5.0                         # duration [s]\nt = np.arange(0, T, 1/fs)\n\nhr = 60.0                       # heart rate [bpm]\nRR = 60.0/hr                    # seconds per beat\n\n# Gaussian helper\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\n# One-beat template (times in seconds relative to beat onset)\ndef ecg_template(t):\n    # amplitudes in mV, widths in s (very simplified)\n    P  = g(t, 0.20, 0.045,  0.10)\n    Q  = g(t, 0.36, 0.010, -0.25)\n    R  = g(t, 0.40, 0.012,  1.00)\n    S  = g(t, 0.44, 0.016, -0.35)\n    T  = g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + T\n\n# Tile the template every RR seconds\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    tau = t - k*RR\n    ecg_mV += ecg_template(tau)\n\n# Optional baseline wander + small EMG-like noise (for realism)\nwander = 0.05*np.sin(2*np.pi*0.3*t)        # 0.05 mV @ 0.3 Hz\nnoise  = 0.02*np.random.randn(len(t))      # 0.02 mV RMS\necg_mV = ecg_mV + wander + noise\n\n# --- 2) Analog front-end gain and ADC setup ---\nG = 200.0                     # gain: mV (input) -&gt; V (ADC input)\nVfs = 1.0                     # full-scale = +/-1 V\nVmin, Vmax = -Vfs, Vfs\n\nx_adc = (ecg_mV/1000.0)*G     # convert mV to V and apply gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    # Saturate to avoid numeric overflow\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)  # ensure within codebook range\n    return y, Delta\n\ndef snr_db(x, y):\n    # SNR over the un-clipped region; compute RMS of signal and error\n    e = x - y\n    # Remove DC for SNR assessment\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\n# --- 3) Quantize at different bit depths ---\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\n# Print a small summary (ADC-domain). Input-referred values via division by G.\nprint(\"Summary (ADC domain):\")\nfor b in bits_list:\n    Delta = results[b][\"Delta\"]\n    snr = results[b][\"snr_db\"]\n    print(f\"{b:2d}-bit -&gt; LSB Œî = {Delta*1e3:.3f} mV, Theoretical/Measured SNR ‚âà {snr:5.1f} dB\")\n\n# Input-referred LSB and noise RMS for the 12-bit case\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Œî_in = {Delta_in*1e6:.3f} ¬µV, œÉ_q ‚âà {sigma_q_in*1e6:.3f} ¬µV RMS\")\n\n# --- 4) Plot: original vs quantized (choose 10-bit for visibility) ---\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)  # show about one beat\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- 5) Plot: quantization error histogram (8-bit to exaggerate steps) ---\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()\n\nSummary (ADC domain):\n 8-bit -&gt; LSB Œî = 7.812 mV, Theoretical/Measured SNR ‚âà  24.1 dB\n10-bit -&gt; LSB Œî = 1.953 mV, Theoretical/Measured SNR ‚âà  36.0 dB\n12-bit -&gt; LSB Œî = 0.488 mV, Theoretical/Measured SNR ‚âà  48.1 dB\n\nInput-referred (12-bit): Œî_in = 2.441 ¬µV, œÉ_q ‚âà 0.705 ¬µV RMS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nThe summary reports the measured SNR from the synthetic ECG after quantization for 8/10/12 bits; values will be below the \\(6.02b+1.76\\) bound because the signal does not use full scale constantly and includes non-sinusoidal content.\nThe input-referred \\(\\Delta\\_{\\text{in}}\\) and \\(\\sigma\\_q\\) for 12 bits match the analytical estimates in Section 5 (a few \\(\\mu\\text{V}\\)), consistent with common ECG design targets.\nThe error histogram approaches a uniform distribution as assumptions hold; deviations indicate correlation (e.g., at low amplitudes or with deterministic waveforms)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#purpose-and-big-picture",
    "href": "recursos/documentos/SYSB/cuantizacion.html#purpose-and-big-picture",
    "title": "Quantization",
    "section": "",
    "text": "Quantization maps a continuous-amplitude signal to a finite set of discrete levels so that it can be represented by digits. After anti-alias filtering and sampling, an analog-to-digital converter (ADC) applies quantization. This process introduces an error that acts like noise under standard conditions; understanding its magnitude is essential to sizing bit depth, gain, and dynamic range in biomedical systems (ECG, EEG, EMG, PPG)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#uniform-quantizer-model",
    "href": "recursos/documentos/SYSB/cuantizacion.html#uniform-quantizer-model",
    "title": "Quantization",
    "section": "",
    "text": "Let the ADC input range be \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\) with \\(b\\) bits and \\(L=2^b\\) levels. The step size (LSB) is\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nTwo common realizations:\n\nMid-tread (rounding): \\(Q(x)=\\Delta,\\mathrm{round}\\left(\\frac{x}{\\Delta}\\right)\\) for \\(x\\in(V\\_{\\min},V\\_{\\max})\\).\nMid-rise (truncate with half-step offset): \\(Q(x)=\\Delta!\\left(\\left\\lfloor\\frac{x}{\\Delta}\\right\\rfloor+\\tfrac12\\right)\\).\n\nOutside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\), overload/clipping occurs: \\(\\tilde{x}=Q(x)=V\\_{\\max}\\) if \\(x&gt;V\\_{\\max}\\) and \\(\\tilde{x}=V\\_{\\min}\\) if \\(x\\&lt;V\\_{\\min}\\).\nCodebook and decision thresholds: Decision thresholds lie at \\(k\\Delta\\) and reconstruction levels at either \\(k\\Delta\\) (mid-tread) or \\((k+\\tfrac12)\\Delta\\) (mid-rise)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#quantization-error-and-its-statistics",
    "href": "recursos/documentos/SYSB/cuantizacion.html#quantization-error-and-its-statistics",
    "title": "Quantization",
    "section": "",
    "text": "Define the quantization error \\(e=x-Q(x)\\). Under the high-resolution assumptions (signal varies slowly relative to \\(\\Delta\\), input well distributed within the range, and no overload), the error is modeled as white, signal-independent, and uniformly distributed on \\(\\left[-\\frac{\\Delta}{2},\\frac{\\Delta}{2}\\right]\\):\n\nMean: \\(\\mathbb{E}\\left[e\\right]=0\\).\nVariance (power): \\(\\sigma\\_e^2=\\dfrac{\\Delta^2}{12}\\).\nRMS: \\(\\sigma\\_e=\\dfrac{\\Delta}{\\sqrt{12}}\\).\n\nFor a full-scale sinusoid, the theoretical SNR is\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nIf the signal uses only a fraction \\(\\rho\\) (\\(0&lt;\\rho\\le 1\\)) of full scale (FS) in RMS, then\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]\nEffective Number of Bits (ENOB) from a measured in-band SNR:\n\\[\n\\mathrm{ENOB} \\approx \\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]"
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#input-range-gain-and-clipping",
    "href": "recursos/documentos/SYSB/cuantizacion.html#input-range-gain-and-clipping",
    "title": "Quantization",
    "section": "",
    "text": "Front-end analog gain \\(G\\) maps a biomedical signal \\(x\\_{\\text{in}}\\) to the ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\). The input-referred LSB is\n\\[\n\\Delta_{\\text{in}}=\\frac{\\Delta}{G}.\n\\]\nChoose \\(G\\) to:\n\navoid overload for rare peaks, and 2) maximize FS utilization to improve SNR. Poor gain wastes bits (small \\(\\rho\\)) or clips clinically relevant transients (e.g., ECG pacer spikes)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#biomedical-example-ecg-acquisition",
    "href": "recursos/documentos/SYSB/cuantizacion.html#biomedical-example-ecg-acquisition",
    "title": "Quantization",
    "section": "",
    "text": "Suppose a resting ECG has peak amplitudes around \\(\\pm 5,\\text{mV}\\) at the electrodes. We design the analog front end so that \\(\\pm 5,\\text{mV}\\) maps to \\(\\pm 1,\\text{V}\\) at the ADC, i.e., \\(G=200\\). Use a \\(b=12\\)-bit ADC over \\(\\left[-1,\\text{V},,1,\\text{V}\\right]\\):\n\nADC LSB: \\(\\Delta = \\dfrac{2,\\text{V}}{2^{12}} \\approx 0.488,\\text{mV}\\) (at the ADC input).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\dfrac{0.488,\\text{mV}}{200}\\approx 2.44,\\mu\\text{V}\\).\nInput-referred quantization-noise RMS: \\(\\dfrac{\\Delta\\_{\\text{in}}}{\\sqrt{12}}\\approx 0.704,\\mu\\text{V}\\_{\\mathrm{RMS}}\\).\n\nIf the ECG uses \\(\\rho=0.5\\) of full scale (typical margin against clipping), the quantization-limited SNR is approximately\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\times 12 + 1.76 + 20\\log_{10}(0.5) \\approx 74.0 - 6.0 \\approx 68\\,\\text{dB}.\n\\]\nThis is usually below amplifier and electrode noise constraints, so 12 bits are adequate for diagnostic ECG in this setting. If the chain is quieter (e.g., invasive potentials), higher bit depth or larger \\(G\\) may be justified."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#non-uniform-quantization-and-companding-brief",
    "href": "recursos/documentos/SYSB/cuantizacion.html#non-uniform-quantization-and-companding-brief",
    "title": "Quantization",
    "section": "",
    "text": "When the amplitude distribution is strongly non-uniform, companding transforms \\(x\\) before uniform quantization to allocate more levels where the signal spends more time. Classical laws:\n\n\\(\\mu\\)-law: \\(y=\\mathrm{sgn}(x),\\dfrac{\\ln(1+\\mu |x|/X\\_{\\max})}{\\ln(1+\\mu)}\\), \\(\\mu\\approx 255\\) (telephony).\n\\(A\\)-law: piecewise logarithmic with parameter \\(A\\) (Europe).\n\nCompanding is common in speech/audio telemetry; in biomedicine it is less standard for primary acquisition, but can help in low-bit-rate wireless monitoring where dynamic range is wide (e.g., PPG with motion)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#dither-optional-but-practical",
    "href": "recursos/documentos/SYSB/cuantizacion.html#dither-optional-but-practical",
    "title": "Quantization",
    "section": "",
    "text": "Adding small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization decorrelates the error from the signal, eliminating patterning and bias at low amplitudes. This linearizes averages at the cost of a small SNR penalty. Dither can be beneficial for low-level EEG/EMG features and precise baseline estimates."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#practical-checklist",
    "href": "recursos/documentos/SYSB/cuantizacion.html#practical-checklist",
    "title": "Quantization",
    "section": "",
    "text": "Choose \\(b\\) so that \\(\\mathrm{SNR}\\_{\\mathrm{dB}}\\) exceeds clinical SNR needs by margin (10‚Äì20 dB).\nSet \\(G\\) so typical peaks use \\(50\\)‚Äì\\(80%\\) FS; verify pacer spikes and motion spikes do not clip.\nBudget noise: electrode + amplifier + ADC quantization; the largest non-white source often dominates.\nValidate with a calibrated source (sinusoidal and biomedical-like waveforms) and measure in-band SNR/ENOB."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#python-demonstration-ecg-quantization-snr-and-error-statistics",
    "href": "recursos/documentos/SYSB/cuantizacion.html#python-demonstration-ecg-quantization-snr-and-error-statistics",
    "title": "Quantization",
    "section": "",
    "text": "# Synthetic ECG, uniform quantization at multiple bit depths, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# --- 1) Build a simple ECG template (P-QRS-T) using Gaussians ---\nfs = 360.0                      # sampling rate [Hz]\nT = 5.0                         # duration [s]\nt = np.arange(0, T, 1/fs)\n\nhr = 60.0                       # heart rate [bpm]\nRR = 60.0/hr                    # seconds per beat\n\n# Gaussian helper\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\n# One-beat template (times in seconds relative to beat onset)\ndef ecg_template(t):\n    # amplitudes in mV, widths in s (very simplified)\n    P  = g(t, 0.20, 0.045,  0.10)\n    Q  = g(t, 0.36, 0.010, -0.25)\n    R  = g(t, 0.40, 0.012,  1.00)\n    S  = g(t, 0.44, 0.016, -0.35)\n    T  = g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + T\n\n# Tile the template every RR seconds\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    tau = t - k*RR\n    ecg_mV += ecg_template(tau)\n\n# Optional baseline wander + small EMG-like noise (for realism)\nwander = 0.05*np.sin(2*np.pi*0.3*t)        # 0.05 mV @ 0.3 Hz\nnoise  = 0.02*np.random.randn(len(t))      # 0.02 mV RMS\necg_mV = ecg_mV + wander + noise\n\n# --- 2) Analog front-end gain and ADC setup ---\nG = 200.0                     # gain: mV (input) -&gt; V (ADC input)\nVfs = 1.0                     # full-scale = +/-1 V\nVmin, Vmax = -Vfs, Vfs\n\nx_adc = (ecg_mV/1000.0)*G     # convert mV to V and apply gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    # Saturate to avoid numeric overflow\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)  # ensure within codebook range\n    return y, Delta\n\ndef snr_db(x, y):\n    # SNR over the un-clipped region; compute RMS of signal and error\n    e = x - y\n    # Remove DC for SNR assessment\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\n# --- 3) Quantize at different bit depths ---\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\n# Print a small summary (ADC-domain). Input-referred values via division by G.\nprint(\"Summary (ADC domain):\")\nfor b in bits_list:\n    Delta = results[b][\"Delta\"]\n    snr = results[b][\"snr_db\"]\n    print(f\"{b:2d}-bit -&gt; LSB Œî = {Delta*1e3:.3f} mV, Theoretical/Measured SNR ‚âà {snr:5.1f} dB\")\n\n# Input-referred LSB and noise RMS for the 12-bit case\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Œî_in = {Delta_in*1e6:.3f} ¬µV, œÉ_q ‚âà {sigma_q_in*1e6:.3f} ¬µV RMS\")\n\n# --- 4) Plot: original vs quantized (choose 10-bit for visibility) ---\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)  # show about one beat\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- 5) Plot: quantization error histogram (8-bit to exaggerate steps) ---\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()\n\nSummary (ADC domain):\n 8-bit -&gt; LSB Œî = 7.812 mV, Theoretical/Measured SNR ‚âà  24.1 dB\n10-bit -&gt; LSB Œî = 1.953 mV, Theoretical/Measured SNR ‚âà  36.0 dB\n12-bit -&gt; LSB Œî = 0.488 mV, Theoretical/Measured SNR ‚âà  48.1 dB\n\nInput-referred (12-bit): Œî_in = 2.441 ¬µV, œÉ_q ‚âà 0.705 ¬µV RMS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nThe summary reports the measured SNR from the synthetic ECG after quantization for 8/10/12 bits; values will be below the \\(6.02b+1.76\\) bound because the signal does not use full scale constantly and includes non-sinusoidal content.\nThe input-referred \\(\\Delta\\_{\\text{in}}\\) and \\(\\sigma\\_q\\) for 12 bits match the analytical estimates in Section 5 (a few \\(\\mu\\text{V}\\)), consistent with common ECG design targets.\nThe error histogram approaches a uniform distribution as assumptions hold; deviations indicate correlation (e.g., at low amplitudes or with deterministic waveforms)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html",
    "title": "SYSB ‚Äî Primer Parcial Supletorio 2025: Soluci√≥n explicada",
    "section": "",
    "text": "Nota: Documento en formato Quarto listo para renderizar a HTML (quarto render). Incluye respuestas correctas y una explicaci√≥n breve por √≠tem."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-1",
    "title": "SYSB ‚Äî Primer Parcial Supletorio 2025: Soluci√≥n explicada",
    "section": "1 Pregunta 1",
    "text": "1 Pregunta 1\nEnunciado resumido: Sea \\(y(t)=x(3-1{,}5\\,t)\\). Sobre la relaci√≥n temporal entre \\(x(t)\\) y \\(y(t)\\), marca las correctas.\nRespuestas correctas: A, B, D, E.\nExplicaci√≥n\nEscribimos \\(y(t)=x(3-1{,}5\\,t)=x\\big(-1{,}5\\,(t-2)\\big)\\).\n- A: Verdadera, es la misma forma \\(x\\big(-1{,}5\\,(t-2)\\big)\\).\n- B: Verdadera, el factor negativo implica inversi√≥n temporal (time-reversal).\n- C: Falsa, no es solo desplazamiento; hay inversi√≥n y escala temporal.\n- D: Verdadera, al comprimir en el tiempo por \\(|a|=1{,}5\\) la frecuencia aparente se multiplica por 1,5.\n- E: Verdadera, \\(|a|=1{,}5&gt;1\\) implica compresi√≥n temporal por 1,5 (la se√±al ‚Äúva m√°s r√°pido‚Äù)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-2",
    "title": "SYSB ‚Äî Primer Parcial Supletorio 2025: Soluci√≥n explicada",
    "section": "2 Pregunta 2",
    "text": "2 Pregunta 2\nEnunciado: \\(x(t)=\\cos\\big(2\\pi\\frac{12}{5}t\\big)+\\sin\\big(2\\pi\\frac{7}{3}t\\big)\\). Periodicidad en TC.\nRespuestas correctas: B, D, E.\nExplicaci√≥n\nLas frecuencias son \\(f_1=12/5\\) y \\(f_2=7/3\\). La raz√≥n \\(f_1/f_2=(12/5)/(7/3)=36/35\\) es racional, por tanto la suma es peri√≥dica en TC.\nLos periodos individuales: \\(T_1=5/12\\) y \\(T_2=3/7\\). El periodo fundamental conjunto cumple \\(36T_1=35T_2=15\\text{s}\\).\n- A: Falsa, s√≠ comparten m√∫ltiplos enteros.\n- B: Verdadera, al cambiar \\(12/5\\) por \\(12/5+1/\\pi\\) la raz√≥n de frecuencias t√≠picamente deja de ser racional \\(\\Rightarrow\\) no peri√≥dica.\n- C: Falsa, sumar un DC no rompe la periodicidad.\n- D: Verdadera, \\(T_0=15\\text{s}\\) es un periodo fundamental posible.\n- E: Verdadera, todo m√∫ltiplo entero de \\(15\\text{s}\\) tambi√©n es periodo."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-3",
    "title": "SYSB ‚Äî Primer Parcial Supletorio 2025: Soluci√≥n explicada",
    "section": "3 Pregunta 3",
    "text": "3 Pregunta 3\nEnunciado: \\(x[n]=\\sin\\big(\\frac{5\\pi}{14}n\\big)+\\cos\\big(\\frac{3\\pi}{7}n+\\frac{\\pi}{6}\\big)\\). Periodicidad en TD.\nRespuestas correctas: A, D, E.\nExplicaci√≥n\nPara \\(\\sin(\\Omega n)\\) o \\(\\cos(\\Omega n+\\phi)\\) hay periodicidad si \\(\\Omega/2\\pi\\) es racional.\n- \\(\\Omega_1=5\\pi/14=(5/28)\\,2\\pi\\Rightarrow N_1=28\\).\n- \\(\\Omega_2=3\\pi/7=(3/14)\\,2\\pi\\Rightarrow N_2=14\\).\nEl periodo conjunto es \\(\\mathrm{{lcm}}(28,14)=28\\). La fase no altera la periodicidad.\n- A: Verdadera, \\(N_0=28\\).\n- B: Falsa, cambiar \\(\\pi/6\\) no rompe periodicidad.\n- C: Falsa, \\(\\sin(5\\pi/14\\,n)\\) sigue siendo peri√≥dica por s√≠ sola.\n- D: Verdadera, al sumar \\(\\sin(\\pi/3\\,n)\\) (periodo 6), el conjunto sigue siendo peri√≥dico con \\(N_0=\\mathrm{{lcm}}(28,6)=84\\).\n- E: Verdadera, el t√©rmino coseno tiene periodo 14."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-4",
    "title": "SYSB ‚Äî Primer Parcial Supletorio 2025: Soluci√≥n explicada",
    "section": "4 Pregunta 4",
    "text": "4 Pregunta 4\nEnunciado: Sea \\(x(t)=x_p(t)+x_i(t)\\) con \\(x_p\\) par y \\(x_i\\) impar. Def√≠nase\n\\[ y(t)=x_p(t+1)\\,x_i(t-1)+\\frac{d}{dt}x_i(t). \\]\nRespuestas correctas: B, C, D, E.\nExplicaci√≥n\n- Un desplazamiento rompe la paridad: \\(x_p(t+1)\\) y \\(x_i(t-1)\\) son, en general, ni pares ni impares (\\(\\Rightarrow\\) B verdadera).\n- El producto \\(x_p(t+1)\\,x_i(t-1)\\) no resulta ni par ni impar en general (no es impar) (\\(\\Rightarrow\\) A falsa).\n- Si se cambiara el segundo t√©rmino por $ frac{d}{dt}x_p(t)$ (derivada de funci√≥n par), √©sta es impar; sumada con un t√©rmino ‚Äúni par ni impar‚Äù el total puede seguir siendo ‚Äúni par ni impar‚Äù (\\(\\Rightarrow\\) C verdadera).\n- La derivada de una funci√≥n impar es par (\\(\\Rightarrow\\) E verdadera).\n- Suma de un t√©rmino ‚Äúni par ni impar‚Äù con un t√©rmino par da, en general, una funci√≥n ni par ni impar (\\(\\Rightarrow\\) D verdadera)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-5",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-5",
    "title": "SYSB ‚Äî Primer Parcial Supletorio 2025: Soluci√≥n explicada",
    "section": "5 Pregunta 5",
    "text": "5 Pregunta 5\nEnunciado: Tres pulsos con solapamiento\n- Pulso 1: amplitud \\(2\\), de \\(t=0{,}8\\) a \\(1{,}4\\).\n- Pulso 2: amplitud \\(1{,}5\\), de \\(t=1{,}2\\) a \\(1{,}8\\).\n- Pulso 3: amplitud \\(-1\\), de \\(t=1{,}6\\) a \\(2{,}0\\).\nSea \\(v(t)\\) la suma. Representaci√≥n con \\(u(t)\\) y propiedades.\nRespuestas correctas: B, C, D, E.\nExplicaci√≥n\n- Alturas por intervalos:\n- \\(0{,}8-1{,}2\\): \\(2\\)\n- \\(1{,}2-1{,}4\\): \\(2+1{,}5=3{,}5\\) (m√°ximo)\n- \\(1{,}4-1{,}6\\): \\(1{,}5\\)\n- \\(1{,}6-1{,}8\\): \\(1{,}5-1=0{,}5\\)\n- \\(1{,}8-2{,}0\\): \\(-1\\)\nPor tanto A es falsa (el m√°ximo \\(3{,}5\\) ocurre en \\(1{,}2-1{,}4\\)).\n- Forma por escalones:\n\\[ v(t)=2[u(t-0{,}8)-u(t-1{,}4)]+1{,}5[u(t-1{,}2)-u(t-1{,}8)]- [u(t-1{,}6)-u(t-2{,}0)], \\]\nequivalente a la suma de saltos en \\(t_k\\in\\{0{,}8,1{,}2,1{,}4,1{,}6,1{,}8,2{,}0\\}\\) con amplitudes \\(\\{+2,+1{,}5,-2,-1,-1{,}5,+1\\}\\).\nAs√≠, B, C y D son verdaderas.\n- √Årea total (linealidad del integral):\n\\[ \\int v(t)\\,dt=2\\cdot0{,}6+1{,}5\\cdot0{,}6-1\\cdot0{,}4=1{,}7, \\]\nindependiente del solapamiento (\\(\\Rightarrow\\) E verdadera)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#resumen-de-respuestas-clave",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#resumen-de-respuestas-clave",
    "title": "SYSB ‚Äî Primer Parcial Supletorio 2025: Soluci√≥n explicada",
    "section": "6 Resumen de respuestas (clave)",
    "text": "6 Resumen de respuestas (clave)\n\nP1: A, B, D, E\n\nP2: B, D, E\n\nP3: A, D, E\n\nP4: B, C, D, E\n\nP5: B, C, D, E"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html",
    "title": "Ejemplo de CRISP-DM",
    "section": "",
    "text": "# %% ------------------ Imports y RNG ------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n\nrng = np.random.default_rng(42)\n\n# %% ------------------ Simulador cohorte rehab ictus ------------------\ndef simulate_stroke_rehab_regression(n=300):\n    age = rng.normal(62, 12, n).clip(18, 90)\n    sex = rng.choice([\"F\",\"M\"], size=n, p=[0.52, 0.48])\n    nihss = rng.integers(0, 16, n)                             # muestra ambulatoria\n    days_since_stroke = rng.integers(14, 180, n)               # 2 semanas a 6 meses\n    comorb = rng.poisson(1.2, n).clip(0, 6)\n\n    sixmwt_base = rng.normal(250, 95, n).clip(30, 600)         # m\n    tug_base = rng.normal(25, 10, n).clip(8, 120)              # s\n\n    therapy_min = rng.normal(160, 40, n).clip(40, 360)         # min/semana\n    cadence = rng.normal(90, 15, n).clip(40, 140)              # pasos/min\n    step_var = np.abs(rng.normal(0.12, 0.05, n))               # CV (adimensional)\n\n    # Mecanismo generador para Œî6MWT (se√±al + ruido)\n    signal = (\n        0.30*(therapy_min-160) +\n        1.2*(cadence-90) -\n        120*(step_var-0.12) -\n        4.0*nihss -\n        0.08*(days_since_stroke-60) -\n        2.0*(tug_base-25) -\n        8.0*comorb +\n        0.12*(sixmwt_base-250)\n    )\n    noise = rng.normal(0, 40, n)\n    delta_6mwt = (120 + signal + noise).clip(-50, 300)         # m, plausibilidad\n\n    df = pd.DataFrame({\n        \"age\": age.round(1),\n        \"sex\": sex,\n        \"nihss\": nihss.astype(int),\n        \"days_since_stroke\": days_since_stroke.astype(int),\n        \"comorb\": comorb.astype(int),\n        \"sixmwt_base\": sixmwt_base.round(1),\n        \"tug_base\": tug_base.round(1),\n        \"therapy_min\": therapy_min.round(1),\n        \"cadence\": cadence.round(1),\n        \"step_var\": step_var.round(3),\n        \"delta_6mwt\": delta_6mwt.round(1)\n    })\n\n    # Problemas de calidad intencionales para practicar:\n    # 1) Faltantes en ~5% de columnas clave\n    for col in [\"sixmwt_base\", \"tug_base\", \"therapy_min\"]:\n        idx = rng.choice(df.index, size=int(0.05*n), replace=False)\n        df.loc[idx, col] = np.nan\n\n    # 2) Outliers puntuales en dosis de terapia\n    idx_hi = rng.choice(df.index, size=max(1, n//100), replace=False)\n    df.loc[idx_hi, \"therapy_min\"] = df[\"therapy_min\"].max() * 3\n\n    return df\n\ndf = simulate_stroke_rehab_regression(n=1000)\nprint(df.head())\nprint(\"\\nShape:\", df.shape)\n\n    age sex  nihss  days_since_stroke  comorb  sixmwt_base  tug_base  \\\n0  65.7   M      1                164       2        264.1      21.0   \n1  49.5   F     12                111       0        354.0      13.0   \n2  71.0   F     13                 42       1        180.6      44.9   \n3  73.3   F     15                143       3        253.0      24.0   \n4  38.6   F      5                 37       2          NaN      31.4   \n\n   therapy_min  cadence  step_var  delta_6mwt  \n0        230.4    103.2     0.104       132.7  \n1        180.9     93.2     0.073        72.9  \n2        238.6     98.3     0.143        43.7  \n3        196.0     85.3     0.143        74.2  \n4         87.8     91.7     0.097        56.7  \n\nShape: (1000, 11)"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#simluaci√≥n-de-datos",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#simluaci√≥n-de-datos",
    "title": "Ejemplo de CRISP-DM",
    "section": "",
    "text": "# %% ------------------ Imports y RNG ------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n\nrng = np.random.default_rng(42)\n\n# %% ------------------ Simulador cohorte rehab ictus ------------------\ndef simulate_stroke_rehab_regression(n=300):\n    age = rng.normal(62, 12, n).clip(18, 90)\n    sex = rng.choice([\"F\",\"M\"], size=n, p=[0.52, 0.48])\n    nihss = rng.integers(0, 16, n)                             # muestra ambulatoria\n    days_since_stroke = rng.integers(14, 180, n)               # 2 semanas a 6 meses\n    comorb = rng.poisson(1.2, n).clip(0, 6)\n\n    sixmwt_base = rng.normal(250, 95, n).clip(30, 600)         # m\n    tug_base = rng.normal(25, 10, n).clip(8, 120)              # s\n\n    therapy_min = rng.normal(160, 40, n).clip(40, 360)         # min/semana\n    cadence = rng.normal(90, 15, n).clip(40, 140)              # pasos/min\n    step_var = np.abs(rng.normal(0.12, 0.05, n))               # CV (adimensional)\n\n    # Mecanismo generador para Œî6MWT (se√±al + ruido)\n    signal = (\n        0.30*(therapy_min-160) +\n        1.2*(cadence-90) -\n        120*(step_var-0.12) -\n        4.0*nihss -\n        0.08*(days_since_stroke-60) -\n        2.0*(tug_base-25) -\n        8.0*comorb +\n        0.12*(sixmwt_base-250)\n    )\n    noise = rng.normal(0, 40, n)\n    delta_6mwt = (120 + signal + noise).clip(-50, 300)         # m, plausibilidad\n\n    df = pd.DataFrame({\n        \"age\": age.round(1),\n        \"sex\": sex,\n        \"nihss\": nihss.astype(int),\n        \"days_since_stroke\": days_since_stroke.astype(int),\n        \"comorb\": comorb.astype(int),\n        \"sixmwt_base\": sixmwt_base.round(1),\n        \"tug_base\": tug_base.round(1),\n        \"therapy_min\": therapy_min.round(1),\n        \"cadence\": cadence.round(1),\n        \"step_var\": step_var.round(3),\n        \"delta_6mwt\": delta_6mwt.round(1)\n    })\n\n    # Problemas de calidad intencionales para practicar:\n    # 1) Faltantes en ~5% de columnas clave\n    for col in [\"sixmwt_base\", \"tug_base\", \"therapy_min\"]:\n        idx = rng.choice(df.index, size=int(0.05*n), replace=False)\n        df.loc[idx, col] = np.nan\n\n    # 2) Outliers puntuales en dosis de terapia\n    idx_hi = rng.choice(df.index, size=max(1, n//100), replace=False)\n    df.loc[idx_hi, \"therapy_min\"] = df[\"therapy_min\"].max() * 3\n\n    return df\n\ndf = simulate_stroke_rehab_regression(n=1000)\nprint(df.head())\nprint(\"\\nShape:\", df.shape)\n\n    age sex  nihss  days_since_stroke  comorb  sixmwt_base  tug_base  \\\n0  65.7   M      1                164       2        264.1      21.0   \n1  49.5   F     12                111       0        354.0      13.0   \n2  71.0   F     13                 42       1        180.6      44.9   \n3  73.3   F     15                143       3        253.0      24.0   \n4  38.6   F      5                 37       2          NaN      31.4   \n\n   therapy_min  cadence  step_var  delta_6mwt  \n0        230.4    103.2     0.104       132.7  \n1        180.9     93.2     0.073        72.9  \n2        238.6     98.3     0.143        43.7  \n3        196.0     85.3     0.143        74.2  \n4         87.8     91.7     0.097        56.7  \n\nShape: (1000, 11)"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-understanding",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-understanding",
    "title": "Ejemplo de CRISP-DM",
    "section": "Data Understanding",
    "text": "Data Understanding\n\n# %% ------------------ Perfil exploratorio b√°sico ------------------\ndef describe_cardinality(s: pd.Series):\n    return pd.Series({\n        \"dtype\": s.dtype,\n        \"n_unique\": s.nunique(dropna=True),\n        \"pct_unique\": 100*s.nunique(dropna=True)/len(s),\n        \"n_missing\": s.isna().sum(),\n        \"pct_missing\": 100*s.isna().mean()\n    })\n\nprofile = df.apply(describe_cardinality).T\nsummary = df.describe(include=\"all\").T\n\nprint(\"\\n=== Cardinalidad & Faltantes ===\")\nprint(profile)\n\nprint(\"\\n=== Resumen num√©rico ===\")\nprint(summary)\n\n# %% ------------------ Detecci√≥n simple de outliers (IQR) ------------------\ndef iqr_outliers_report(df_numeric: pd.DataFrame, k=1.5):\n    rows = []\n    for col in df_numeric.columns:\n        x = df_numeric[col].dropna().values\n        q1, q3 = np.percentile(x, [25, 75])\n        iqr = q3 - q1\n        lo, hi = q1 - k*iqr, q3 + k*iqr\n        n_lo = (df_numeric[col] &lt; lo).sum()\n        n_hi = (df_numeric[col] &gt; hi).sum()\n        rows.append({\"variable\": col, \"q1\": q1, \"q3\": q3, \"iqr\": iqr,\n                     \"low_thresh\": lo, \"high_thresh\": hi,\n                     \"n_low\": int(n_lo), \"n_high\": int(n_hi)})\n    return pd.DataFrame(rows).sort_values(\"n_high\", ascending=False)\n\nnum_cols = df.select_dtypes(include=[np.number]).columns.tolist()\noutliers_table = iqr_outliers_report(df[num_cols])\nprint(\"\\n=== Outliers (IQR 1.5) ===\")\nprint(outliers_table)\n\n# %% ------------------ Visual quick checks (opcional) ------------------\nplt.figure()\ndf[\"delta_6mwt\"].hist(bins=30)\nplt.title(\"Distribuci√≥n Œî6MWT (m)\")\nplt.xlabel(\"m\"); plt.ylabel(\"frecuencia\")\nplt.show()\n\nplt.figure()\ndf.boxplot(column=[\"therapy_min\"])\nplt.title(\"Boxplot therapy_min (detecci√≥n outliers)\")\nplt.show()\n\n\n=== Cardinalidad & Faltantes ===\n                     dtype n_unique pct_unique n_missing pct_missing\nage                float64      411       41.1         0         0.0\nsex                 object        2        0.2         0         0.0\nnihss                int64       16        1.6         0         0.0\ndays_since_stroke    int64      166       16.6         0         0.0\ncomorb               int64        7        0.7         0         0.0\nsixmwt_base        float64      821       82.1        50         5.0\ntug_base           float64      336       33.6        50         5.0\ntherapy_min        float64      677       67.7        50         5.0\ncadence            float64      495       49.5         0         0.0\nstep_var           float64      222       22.2         0         0.0\ndelta_6mwt         float64      771       77.1         0         0.0\n\n=== Resumen num√©rico ===\n                    count unique  top freq        mean        std   min  \\\nage                1000.0    NaN  NaN  NaN     61.6208  11.779899  18.2   \nsex                  1000      2    F  527         NaN        NaN   NaN   \nnihss              1000.0    NaN  NaN  NaN       7.453   4.708924   0.0   \ndays_since_stroke  1000.0    NaN  NaN  NaN      95.709  46.490727  14.0   \ncomorb             1000.0    NaN  NaN  NaN       1.139   1.064336   0.0   \nsixmwt_base         950.0    NaN  NaN  NaN  255.519474  94.649212  30.0   \ntug_base            950.0    NaN  NaN  NaN      25.284   9.764767   8.0   \ntherapy_min         950.0    NaN  NaN  NaN  166.018737  83.033507  40.0   \ncadence            1000.0    NaN  NaN  NaN     90.4363  15.165442  40.0   \nstep_var           1000.0    NaN  NaN  NaN    0.117729   0.050345   0.0   \ndelta_6mwt         1000.0    NaN  NaN  NaN     78.8412  56.194987 -50.0   \n\n                       25%     50%      75%    max  \nage                   53.6    62.1     69.1   90.0  \nsex                    NaN     NaN      NaN    NaN  \nnihss                  4.0     7.0     12.0   15.0  \ndays_since_stroke     55.0    96.0    136.0  179.0  \ncomorb                 0.0     1.0      2.0    6.0  \nsixmwt_base          190.8  256.95   317.35  557.9  \ntug_base              18.5    24.4   32.275   56.0  \ntherapy_min          133.9  158.35  185.275  875.4  \ncadence               80.5    90.5    100.5  140.0  \nstep_var           0.08375   0.117    0.152  0.282  \ndelta_6mwt            41.2    79.8  116.075  262.5  \n\n=== Outliers (IQR 1.5) ===\n            variable         q1       q3        iqr  low_thresh  high_thresh  \\\n6        therapy_min  133.90000  185.275   51.37500   56.837500   262.337500   \n8           step_var    0.08375    0.152    0.06825   -0.018625     0.254375   \n9         delta_6mwt   41.20000  116.075   74.87500  -71.112500   228.387500   \n7            cadence   80.50000  100.500   20.00000   50.500000   130.500000   \n4        sixmwt_base  190.80000  317.350  126.55000    0.975000   507.175000   \n3             comorb    0.00000    2.000    2.00000   -3.000000     5.000000   \n5           tug_base   18.50000   32.275   13.77500   -2.162500    52.937500   \n0                age   53.60000   69.100   15.50000   30.350000    92.350000   \n1              nihss    4.00000   12.000    8.00000   -8.000000    24.000000   \n2  days_since_stroke   55.00000  136.000   81.00000  -66.500000   257.500000   \n\n   n_low  n_high  \n6      7      15  \n8      0       6  \n9      0       4  \n7      4       4  \n4      0       4  \n3      0       2  \n5      0       1  \n0      4       0  \n1      0       0  \n2      0       0"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-quality",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-quality",
    "title": "Ejemplo de CRISP-DM",
    "section": "Data Quality",
    "text": "Data Quality\n\n# %% ------------------ Plan de calidad de datos ------------------\n# 1) Imputaci√≥n: media para num√©ricos; mant√©n categ√≥ricas como 'missing' si aplica.\nnumeric_features = [\"age\",\"nihss\",\"days_since_stroke\",\"comorb\",\n                    \"sixmwt_base\",\"tug_base\",\"therapy_min\",\"cadence\",\"step_var\"]\ncategorical_features = [\"sex\"]\n\nnum_imputer = SimpleImputer(strategy=\"median\")\ncat_imputer = SimpleImputer(strategy=\"most_frequent\")\n\n# 2) Escalado (para modelos lineales/regularizados)\nnum_scaler = StandardScaler()\n\n# 3) Codificaci√≥n one-hot de categ√≥ricas\nohe = OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\")\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"num\", Pipeline([(\"imputer\", num_imputer), (\"scaler\", num_scaler)]), numeric_features),\n        (\"cat\", Pipeline([(\"imputer\", cat_imputer), (\"ohe\", ohe)]), categorical_features),\n    ]\n)"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#baseline-de-modelado",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#baseline-de-modelado",
    "title": "Ejemplo de CRISP-DM",
    "section": "Baseline de Modelado",
    "text": "Baseline de Modelado\n\n# %% ------------------ Partici√≥n y m√©tricas ------------------\nX = df.drop(columns=[\"delta_6mwt\"])\ny = df[\"delta_6mwt\"].values\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=7\n)\n\nscorers = {\n    \"MAE\": make_scorer(mean_absolute_error),\n    \"RMSE\": make_scorer(lambda yt, yp: mean_squared_error(yt, yp)),\n    \"R2\": make_scorer(r2_score),\n}\n\ncv = KFold(n_splits=5, shuffle=True, random_state=7)\n\ndef evaluate_model(model, name):\n    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", model)])\n    cvres = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scorers, n_jobs=-1)\n    print(f\"\\n{name} - CV resultados (train):\")\n    for m in scorers.keys():\n        print(f\"  {m}: {cvres['test_'+m].mean():.2f} ¬± {cvres['test_'+m].std():.2f}\")\n    pipe.fit(X_train, y_train)\n    yhat = pipe.predict(X_test)\n    print(f\"{name} - Test:\")\n    print(f\"  MAE:  {mean_absolute_error(y_test, yhat):.2f}\")\n    print(f\"  RMSE: {mean_squared_error(y_test, yhat):.2f}\")\n    print(f\"  R2:   {r2_score(y_test, yhat):.3f}\")\n    return pipe\n\nlin = evaluate_model(LinearRegression(), \"LinearRegression\")\nrid = evaluate_model(Ridge(alpha=1.0), \"Ridge(alpha=1.0)\")\nlas = evaluate_model(Lasso(alpha=0.05, max_iter=5000), \"Lasso(alpha=0.05)\")\n\n\nLinearRegression - CV resultados (train):\n  MAE: 34.25 ¬± 2.12\n  RMSE: 1809.09 ¬± 156.01\n  R2: 0.42 ¬± 0.06\nLinearRegression - Test:\n  MAE:  32.75\n  RMSE: 1691.19\n  R2:   0.464\n\nRidge(alpha=1.0) - CV resultados (train):\n  MAE: 34.25 ¬± 2.12\n  RMSE: 1808.99 ¬± 155.65\n  R2: 0.42 ¬± 0.06\nRidge(alpha=1.0) - Test:\n  MAE:  32.75\n  RMSE: 1690.92\n  R2:   0.464\n\nLasso(alpha=0.05) - CV resultados (train):\n  MAE: 34.24 ¬± 2.12\n  RMSE: 1809.04 ¬± 155.68\n  R2: 0.42 ¬± 0.06\nLasso(alpha=0.05) - Test:\n  MAE:  32.73\n  RMSE: 1689.67\n  R2:   0.465"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit",
    "href": "tutoriales/tut002_IA.html#que-es-microbit",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nEs una computadora port√°til y programable\nEnfocada en inspirar y desarrollar habilidades t√©cnicas b√°sicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educaci√≥n en computaci√≥n.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales est√°n a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanz√≥ como parte de la iniciativa ‚ÄúMake it Digital‚Äù de la BBC, con el objetivo de introducir la codificaci√≥n y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#componentes",
    "href": "tutoriales/tut002_IA.html#componentes",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Componentes",
    "text": "Componentes"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#como-la-puedo-programar",
    "href": "tutoriales/tut002_IA.html#como-la-puedo-programar",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Como la puedo programar?",
    "text": "Como la puedo programar?"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programaci√≥n C"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#distribuci√≥n-e-impacto",
    "href": "tutoriales/tut002_IA.html#distribuci√≥n-e-impacto",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Distribuci√≥n e impacto",
    "text": "Distribuci√≥n e impacto\n\nDistribuci√≥n: La Microbit se distribuy√≥ de forma gratuita a todos los ni√±os de 12-13 a√±os (Year 7) en todo el Reino Unido, con el objetivo de llegar a m√°s de 1 mill√≥n de ni√±os.\nImpacto: En su primer a√±o, la Microbit mostr√≥ un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayud√≥ a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#problema",
    "href": "tutoriales/tut002_IA.html#problema",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable en 0.\nMostrar el n√∫mero en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el n√∫mero es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "href": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#lets-code",
    "href": "tutoriales/tut002_IA.html#lets-code",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Let‚Äôs Code",
    "text": "Let‚Äôs Code\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#editor",
    "href": "tutoriales/tut002_IA.html#editor",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Editor",
    "text": "Editor\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "href": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable con el n√∫mero a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el n√∫mero es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "tutoriales/ExpansionTaylor.html",
    "href": "tutoriales/ExpansionTaylor.html",
    "title": "Computaci√≥n de seno y coseno usando expansi√≥n de Taylor",
    "section": "",
    "text": "Las ecuaciones de las expansiones de Taylor (centradas en cero) fueron extra√≠das de la recopilaci√≥n que hizo Wikipedia\n\\[cos\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{x^{2n}}{2n!}\\left(-1\\right)^{n}}\\]\n\\[sin\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{\\left(-1\\right)^{n}}{\\left(2n+1\\right)!}x^{2n+1}}\\]\n\ndef factorial(x):\n    output = 1\n    for k in range(1,x+1):\n        output = output*k\n    return output\n\n\ndef sin_taylor_expansion(x,n):\n    pi = 3.141592653589793238462643383279502884197169399375105820974944\n    x = pi*x/180\n    output = 0\n    for k in range(0, n):\n        term = (((-1)**k)/factorial(2*k + 1))*(x**(2*k+1))\n        output = output+term\n    return output\n\n\nv_est = sin_taylor_expansion(30,5)\n\nprint(v_est)\n\nprint(\"Error Relativo:\", abs(0.5-v_est)/0.5)\n\n0.5000000000202799\nError Relativo: 4.0559777758630844e-11"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html",
    "href": "tutoriales/tutInstallPythonR.html",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "",
    "text": "Antes de compilar Python, es necesario disponer de Ubuntu corriendo bajo WSL2 en Windows 11. Sigue estos pasos:\n\nVerificar requisitos:\n\nWindows 11 (build 22000 o superior).\nVirtualizaci√≥n habilitada en BIOS/UEFI (Intel VT-x o AMD SVM).\nPermisos de administrador en Windows.\n\nHabilitar WSL y plataforma de m√°quina virtual:\nAbre PowerShell como administrador y ejecuta:\npowershell  wsl --install\n\nEsto activa las caracter√≠sticas ‚ÄúVirtual Machine Platform‚Äù y ‚ÄúWindows Subsystem for Linux‚Äù.\nDescarga e instala Ubuntu por defecto (puedes ignorar o desinstalar luego).\nReinicia el equipo si se solicita.\n\nInstalar Ubuntu:\n\nV√≠a PowerShell:\nwsl --install -d Ubuntu\nO desde Microsoft Store:\n\nAbre Microsoft Store.\nBusca ‚ÄúUbuntu‚Äù y pulsa Instalar.\n\n\nPrimer arranque de Ubuntu:\n\nAbre Ubuntu desde el men√∫ Inicio o Windows Terminal.\npowershell      wsl -d Ubuntu\nCrea tu usuario y contrase√±a de Linux.\n\nActualizar paquetes del sistema:\nsudo apt update && sudo apt upgrade -y"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-repositorios-e-instalar-dependencias-de-compilaci√≥n",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-repositorios-e-instalar-dependencias-de-compilaci√≥n",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "1. Actualizar repositorios e instalar dependencias de compilaci√≥n",
    "text": "1. Actualizar repositorios e instalar dependencias de compilaci√≥n\nEjecuta los siguientes comandos para actualizar el sistema e instalar las bibliotecas necesarias para compilar Python desde el c√≥digo fuente:\nsudo apt update\nsudo apt install -y \\\n  build-essential \\\n  checkinstall \\\n  libncurses-dev \\\n  libssl-dev \\\n  zlib1g \\\n  zlib1g-dev \\\n  libreadline-dev \\\n  libsqlite3-dev \\\n  libgdbm-dev libdb5.3-dev \\\n  libbz2-dev \\\n  libexpat1-dev \\\n  libc6-dev \\\n  libffi-dev \\\n  liblzma-dev \\\n  tk-dev \\\n  dirmngr \\\n  gnupg \\\n  apt-transport-https \\\n  ca-certificates \\\n  software-properties-common wget \\\n  libxml2-dev \\\n  libharfbuzz-dev \\\n  libfribidi-dev \\\n  libcurl4-openssl-dev \\\n  libmagick++-dev \\\n  libnsl-dev \\\n  cmake\\\n  wget"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#obtener-el-kit-de-repositorio-cuda-de-nvidia",
    "href": "tutoriales/tutInstallPythonR.html#obtener-el-kit-de-repositorio-cuda-de-nvidia",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "2. Obtener el kit de repositorio CUDA de NVIDIA:",
    "text": "2. Obtener el kit de repositorio CUDA de NVIDIA:\ncd ~\nmkdir instaladores\ncd instaladores\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/12.9.1/local_installers/cuda-repo-wsl-ubuntu-12-9-local_12.9.1-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-12-9-local_12.9.1-1_amd64.deb\nsudo apt update\nsudo apt -y install cuda-toolkit-12-9"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-instalaci√≥n",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-instalaci√≥n",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "3. Verificar la instalaci√≥n:",
    "text": "3. Verificar la instalaci√≥n:\n# Verifica la versi√≥n de nvcc\nnvcc --version\n# Verifica que la GPU sea detectada\nnvidia-smi"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#instalaci√≥n-de-la-versi√≥n-m√°s-reciente-de-r",
    "href": "tutoriales/tutInstallPythonR.html#instalaci√≥n-de-la-versi√≥n-m√°s-reciente-de-r",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "4. Instalaci√≥n de la versi√≥n m√°s reciente de R",
    "text": "4. Instalaci√≥n de la versi√≥n m√°s reciente de R\nPara instalar la versi√≥n m√°s reciente de R en Ubuntu bajo WSL2, sigue estos pasos:\n\n1. Agregar la clave y el repositorio oficial de CRAN:\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\nsudo add-apt-repository \"deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/\"\n\n\n2. Instalar R:\nsudo apt update\nsudo apt install -y r-base r-base-dev r-recommended\n\n\n3. Verificar la instalaci√≥n:\nR --version    # Debe mostrar la versi√≥n de R reci√©n instalada\nsudo R\ninstall.packages(c(\"DiagrammeR\", \"reticulate\", \"kableExtra\", \"tidyverse\", \"knitr\", \"cowplot\", \"ggfx\", \"rstatix\", \"languageserver\", \"bibliometrix\"))"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#descargar-y-extraer-python-3.12",
    "href": "tutoriales/tutInstallPythonR.html#descargar-y-extraer-python-3.12",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "5. Descargar y extraer Python 3.12",
    "text": "5. Descargar y extraer Python 3.12\n\n1. Descarga el c√≥digo fuente de Python 3.12 y descompr√≠melo en /usr/src:\ncd /usr/src\nsudo wget https://www.python.org/ftp/python/3.12.11/Python-3.12.11.tgz\nsudo tar -xzf Python-3.12.11.tgz\ncd Python-3.12.11\n\n\n2. Configura la compilaci√≥n con optimizaciones y el instalador de pip integrado:\n```bash\nsudo ./configure --enable-optimizations --with-ensurepip=install --enable-shared\n```\n\n\n3. Compila utilizando todos los n√∫cleos disponibles:\n```bash\nsudo make -j $(nproc)\n```\n\n\n4. Instala Python 3.12 sin sobrescribir la versi√≥n del sistema por defecto:\n```bash\nsudo make altinstall\n```\nLos ejecutables quedar√°n en /usr/local/bin/python3.12 y /usr/local/bin/pip3.12.\n\n\n5. Verificaci√≥n de la instalaci√≥n\nComprueba las versiones instaladas:\n/usr/local/bin/python3.12 --version   # Debe mostrar Python 3.12.0\n/usr/local/bin/pip3.12 --version      # Debe mostrar la versi√≥n de pip correspondiente\necho 'export PATH=\"$PATH:/home/sylph/.local/bin\"' &gt;&gt; ~/.bashrc\nsource\n\n\n6. Crear y activar un entorno virtual\n\n1. Crea un directorio de trabajo\n```bash\nmkdir -p ~/proyectos\ncd ~/proyectos\n```\n\n\n2. Crea un entorno virtual (mienv) con Python 3.12:\n```bash\n/usr/local/bin/python3.12 -m venv mienv\n```\n\n\n3. Activa el entorno:\n```bash\nsource mienv/bin/activate\n```\n\n\n4. Verifica que python y pip apunten a la versi√≥n 3.12:\n```bash\npython --version   # Python 3.12.X\npip --version      # pip x.y.z\n```\n\n\n5. Instala las bibliotecas necesarias:\n```bash\npython -m pip cache purge\npython -m pip install -U --upgrade-strategy eager pip setuptools wheel packaging build\npython -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu129\npython -m pip install pandas matplotlib scikit-learn opencv-contrib-python opencv-python pywavelets statsmodels scipy seaborn plotly scikit-image scikit-image[data] scikit-image[optional] jupyter scikit-image\n```\n\n\n5. desactivar el entorno, ejecuta:\ndeactivate"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-√≠ndices-de-paquetes",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-√≠ndices-de-paquetes",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "1. Actualizar √≠ndices de paquetes",
    "text": "1. Actualizar √≠ndices de paquetes\nsudo apt update"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#descargar-el-instalador-oficial",
    "href": "tutoriales/tutInstallPythonR.html#descargar-el-instalador-oficial",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "2. Descargar el instalador oficial",
    "text": "2. Descargar el instalador oficial\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-integridad-opcional",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-integridad-opcional",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "3. Verificar la integridad (opcional)",
    "text": "3. Verificar la integridad (opcional)\nCompara el hash SHA‚Äë256 generado con el publicado en el sitio oficial:\nsha256sum ~/miniconda.sh\n# Comprueba que el resultado coincida con el valor en https://repo.anaconda.com/miniconda/"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#ejecutar-el-instalador-en-modo-silencioso",
    "href": "tutoriales/tutInstallPythonR.html#ejecutar-el-instalador-en-modo-silencioso",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "4. Ejecutar el instalador en modo silencioso",
    "text": "4. Ejecutar el instalador en modo silencioso\nEsto instalar√° Miniconda en ~/miniconda sin interacci√≥n:\nbash ~/miniconda.sh -b -p $HOME/miniconda"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#inicializar-conda-en-tu-shell",
    "href": "tutoriales/tutInstallPythonR.html#inicializar-conda-en-tu-shell",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "5. Inicializar Conda en tu shell",
    "text": "5. Inicializar Conda en tu shell\nPara que conda est√© disponible cada vez que abras la terminal:\neval \"$(~/miniconda/bin/conda shell.bash hook)\"\nconda init"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#recargar-la-configuraci√≥n-de-shell",
    "href": "tutoriales/tutInstallPythonR.html#recargar-la-configuraci√≥n-de-shell",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "6. Recargar la configuraci√≥n de shell",
    "text": "6. Recargar la configuraci√≥n de shell\nsource ~/.bashrc"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-conda-a-la-√∫ltima-versi√≥n",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-conda-a-la-√∫ltima-versi√≥n",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "7. Actualizar Conda a la √∫ltima versi√≥n",
    "text": "7. Actualizar Conda a la √∫ltima versi√≥n\nconda tos interactive\nconda update -n base -c defaults conda -y"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-instalaci√≥n-2",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-instalaci√≥n-2",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "8. Verificar la instalaci√≥n",
    "text": "8. Verificar la instalaci√≥n\nconda --version\n# Deber√≠as ver algo como: conda 23.x.x"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#crear-un-entorno-virtual",
    "href": "tutoriales/tutInstallPythonR.html#crear-un-entorno-virtual",
    "title": "Instalaci√≥n de Entorno de trabajo. Ubuntu WSL2",
    "section": "9. Crear un entorno virtual",
    "text": "9. Crear un entorno virtual\nconda create -n ai-env python=3.12"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Introduction",
    "text": "Introduction\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Data Understanding Workflow.",
    "text": "Data Understanding Workflow.\n\n\n\n\n\n\n\nExploratory data analysis\n\n\n\nData Loading.\nBasic Statistics: Displays summary statistics.\nMissing Values Check: Identifies missing values.\nFeature Distributions: Visualizes distributions using histograms or countplots.\nRelationship between variables."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Data Understanding Workflow",
    "text": "Data Understanding Workflow\n\n# Identify variable types\ndiscrete_vars = [\"Pregnancies\"]  # Discrete numerical variable\ncategorical_vars = [\"Outcome\"]  # Class label\ncontinuous_vars = [\n    col\n    for col in data.select_dtypes(include=[np.number]).columns\n    if col not in discrete_vars + [\"Outcome\"]\n]\n\n# Basic dataset information\nprint(\"Dataset Information:\\n\", data.info())\nprint(\"\\nSummary Statistics:\\n\", data.describe())\nprint(\"\\nMissing Values:\\n\", data.isnull().sum())\n\n# Ensure numeric data and handle NaN or infinite values\nnumeric_data = data.select_dtypes(include=[np.number]).dropna()\nnumeric_data = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n\n# Dynamically determine the number of rows for subplots\nnum_cont_vars = len(continuous_vars)\nrows = (num_cont_vars // 3) + (num_cont_vars % 3 &gt; 0)  # Ensures proper grid layout\n\n# Plot distributions for continuous variables\nplt.figure(figsize=(12, 4 * rows))\nfor i, column in enumerate(continuous_vars, 1):\n    plt.subplot(rows, 3, i)\n    sns.histplot(numeric_data[column], kde=True, bins=20, color=\"skyblue\")\n    plt.title(f\"Distribution of {column}\")\nplt.tight_layout()\nplt.show()\n\n# Plot distribution for discrete variable (Pregnancies) using a countplot\nplt.figure(figsize=(8, 4))\nsns.countplot(x=\"Pregnancies\", data=numeric_data, palette=\"viridis\")\nplt.title(\"Count of Pregnancies\")\nplt.show()\n\n# Plot class distribution for Outcome\nplt.figure(figsize=(6, 4))\nsns.countplot(x=\"Outcome\", data=data, palette=\"coolwarm\")\nplt.title(\"Class Distribution of Outcome\")\nplt.xlabel(\"Diabetes Diagnosis (0: No, 1: Yes)\")\nplt.ylabel(\"Count\")\nplt.show()\n\n# Correlation heatmap to check relationships\nplt.figure(figsize=(10, 6))\nsns.heatmap(numeric_data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nKey Term\n\n\nThe term edge AI is a union of two buzzwords, fused together into one mighty term. It‚Äôs often heard alongside its siblings, embedded machine learning and TinyML.\n\n\n\n\n\n\n\n\n\n\n\nEmbedded\n\n\n\nEmbedded systems are the computers that control the electronics of all sorts of physical devices.\nIn contrast to general-purpose computers, embedded systems are usually meant to perform one specific, dedicated task.\nIt‚Äôs common for embedded systems to reflect the constraints of the environments into which they are deployed. For example, many embedded systems are required to run on battery power, so they‚Äôre designed with energy efficiency in mind‚Äîperhaps with limited memory or an extremely slow clock rate.\nProgramming embedded systems is the art of navigating these constraints, writing software that performs the task required while making the most out of limited resources."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nThe history of computer networks has been a gigantic tug of war.\nIn the first systems‚Äîindividual computers the size of a room‚Äîcomputation was inherently centralized.\nComputers were connected to terminals that took over some of their responsibilities. Example the terminal renders the letters in an monitor."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nOver time, terminals became more and more sophisticated, taking over more and more functions that were previously the job of the central computer. The personal computer was invented.\nSmall computers could do useful work without even being connected to another machine.\nThe growth of the internet, along with web applications and services, made it possible to do some really cool stuff\nOver the past decade, most of our computing has become centralized again‚Äîthis time in the ‚Äúcloud.‚Äù"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-3",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-3",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nThe Internet of Things (IoT) includes everything you can think of: industrial sensors, smart refrigerators, internet-connected security cameras, personal automobiles, shipping containers, fitness trackers, and coffee machines.\nAll of these devices are embedded systems.\nSince they‚Äôre at the edge of the network, we can also call them edge devices.\nThe edge isn‚Äôt a single place; it‚Äôs more like a broad region.\nThe edge is where all the data comes from!\nEdge devices are our link between the internet and the physical world"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\n\n\nAI\n\n\n\nSince the dawn of time, humans have dreamed of creating intelligent entities that can help us in our struggle to survive.\nIn the modern world we dream of robot sidekicks who assist us.\nTo define AI, we have to define intelligence\n\n\n\n\n\n\n\n\n\n‚ÄúSlime Mould Solves Maze in One Pass Assisted by Gradient of Chemo-Attractants‚Äù (Andrew Adamatzky, arXiv, 2011)"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-6",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-6",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "href": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Methodology for designing an edge ai device",
    "text": "Methodology for designing an edge ai device\n\nProblem Definition & Use Case Analysis\nData Collection & Preprocessing\nModel Selection & Optimization\nHardware Selection\nDeployment & Model Inference\nTesting, Validation, and Continuous Improvement\nFinal Deployment & Scaling"
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Problem Definition & Use Case Analysis",
    "text": "Problem Definition & Use Case Analysis\n\nIdentify the specific AI task (e.g., real-time ECG analysis, fall detection, predictive maintenance in IoT).\nDetermine operational constraints, including:\n\nPower consumption (battery-operated vs.¬†wired).\nLatency requirements (real-time processing vs.¬†periodic updates).\nCommunication needs (Wi-Fi, Bluetooth, LoRa, standalone processing)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Data Collection & Preprocessing",
    "text": "Data Collection & Preprocessing\n\nSensor Selection: Choose sensors relevant to the application (e.g., accelerometers for motion tracking, biosensors for health monitoring).\nEdge-Compatible Data Acquisition: Optimize data formats to reduce memory and computational load.\nPreprocessing on Edge:\n\nSignal filtering (e.g., noise reduction in biomedical signals).\nFeature extraction (e.g., time-series features for motion classification)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Model Selection & Optimization",
    "text": "Model Selection & Optimization\n\nModel Selection:\n\nLightweight CNNs (for image processing).\nRecurrent Neural Networks (RNNs) / LSTMs (for time-series data like ECG).\nTinyML models optimized for microcontrollers (e.g., TensorFlow Lite, PyTorch Mobile).\n\nModel Optimization for Edge Deployment:\n\nQuantization: Convert floating-point models to int8 or int16 to reduce size and computation load.\nPruning: Remove unnecessary neurons or layers while preserving accuracy.\nDistillation: Train a smaller model using knowledge from a larger one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Hardware Selection",
    "text": "Hardware Selection\n\nProcessing Unit:\n\nMicrocontrollers (MCUs) (e.g., ARM Cortex-M, ESP32) ‚Üí Low-power, simple AI tasks.\nEdge AI Accelerators (e.g., Google Edge TPU, NVIDIA Jetson Nano) ‚Üí More complex AI processing.\nFPGAs (Field-Programmable Gate Arrays) ‚Üí Custom AI workloads for high-speed processing.\n\nMemory & Storage:\n\nRAM Optimization: Choose embedded SRAM or external DRAM depending on model size.\nFlash Storage: Store inference models efficiently.\n\nConnectivity:\n\nOffline processing for low-latency applications.\nEdge-to-cloud integration for periodic updates."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Deployment & Model Inference",
    "text": "Deployment & Model Inference\n\nConvert trained AI models into optimized edge-compatible formats (e.g., TensorFlow Lite, ONNX).\nImplement real-time inference using hardware-accelerated libraries (e.g., TensorRT, OpenVINO).\nOptimize firmware for energy efficiency using duty-cycling techniques (process only when necessary)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Testing, Validation, and Continuous Improvement",
    "text": "Testing, Validation, and Continuous Improvement\n\nEdge Benchmarking:\n\nMeasure inference speed and power consumption.\nValidate model accuracy on real-world edge-generated data.\n\nSecurity & Reliability:\n\nImplement secure boot & firmware updates to prevent cyber threats.\nEnsure robust error handling for sensor malfunctions.\n\nFeedback & Model Updating:\n\nIf connected to a cloud system, update models periodically using federated learning.\nOptimize AI pipelines with incremental learning on-device where feasible."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Final Deployment & Scaling",
    "text": "Final Deployment & Scaling\n\nDeploy at scale, ensuring the Edge AI model adapts to different environments.\nImplement remote monitoring & diagnostics for predictive maintenance.\nEnable over-the-air (OTA) updates to improve AI models post-deployment."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "href": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Abstract",
    "text": "Abstract\nThe hardware-software co-design approach is the most widely used methodology for Edge AI device development. It ensures:\n\nReal-time performance with optimized AI models.\nEnergy-efficient processing for battery-operated or low-power devices.\nScalability and security in edge environments.\n\nThis methodology is industry-standard and used by leading companies in healthcare, automotive, and industrial IoT, ensuring robust and reliable Edge AI solutions."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "href": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Example of application",
    "text": "Example of application\n\n\n\n\n\n\n\nUse case\n\n\nA wearable ECG monitoring device designed for continuous heart health tracking and arrhythmia detection. This Edge AI-based solution analyzes ECG signals in real-time on a low-power microcontroller, providing instant alerts for cardiac irregularities without relying on cloud computing."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Step 1: Problem Definition & Use Case Analysis",
    "text": "Step 1: Problem Definition & Use Case Analysis\n\n\n\n\n\n\n\nObjective\n\n\nDetect abnormal heart rhythms (arrhythmias) in real-time using a wearable ECG device.\n\n\n\n\nOperational Constraints:\n\nMust be energy-efficient (battery-operated, low power consumption).\nNeeds real-time inference for immediate alerts.\nShould operate offline, but sync with mobile apps for periodic review.\n\nKey Challenges:\n\nProcessing ECG data on a low-power Edge device.\nMinimizing false positives/negatives in arrhythmia detection.\nEnsuring high reliability and accuracy."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Step 2: Data Collection & Preprocessing",
    "text": "Step 2: Data Collection & Preprocessing\nSensor Selection:\n\nECG sensor (e.g., AD8232) captures raw heart signals.\nAccelerometer (optional) for motion artifacts reduction.\n\nEdge-Compatible Data Acquisition:\n\nSample rate: 250 Hz (sufficient for arrhythmia detection).\nUse on-device filtering (low-pass filters) to remove noise.\n\nPreprocessing on Edge:\n\nApply Butterworth filters for noise reduction.\nR-peak detection using Pan-Tompkins algorithm for heart rate calculation.\nExtract features like RR intervals, QRS width, and HR variability."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Step 3: Model Selection & Optimization",
    "text": "Step 3: Model Selection & Optimization\nAI Model:\n\nUse 1D CNN + LSTM hybrid model (efficient for ECG signal processing).\nTrain the model using MIT-BIH Arrhythmia Database.\n\nModel Optimization for Edge AI:\n\nQuantization: Convert model to int8 precision using TensorFlow Lite.\nPruning: Remove redundant neurons to reduce computation load.\nKnowledge Distillation: Train a smaller model from a high-performing one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Step 4: Hardware Selection",
    "text": "Step 4: Hardware Selection\nMicrocontroller (MCU):\n\nNordic nRF52840 (low-power ARM Cortex-M4 + BLE connectivity).\nAlternative: ESP32 (for low-cost AI inference).\n\nMemory & Storage:\n\nRAM: 512KB (optimized for Edge AI processing).\nFlash storage: 4MB (stores ECG data logs for later analysis).\n\nConnectivity:\n\nBluetooth Low Energy (BLE) for periodic sync with mobile apps.\nCan function offline with real-time alerts."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Step 5: Deployment & Model Inference",
    "text": "Step 5: Deployment & Model Inference\n\nConvert trained TensorFlow model ‚Üí TensorFlow Lite for Edge AI inference.\nDeploy on the Nordic nRF52840 MCU using TensorFlow Lite for Microcontrollers.\nUse hardware-accelerated inference for efficient processing.\nImplement event-driven processing (AI runs only on abnormal detections to save power)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Step 6: Testing, Validation, and Continuous Improvement",
    "text": "Step 6: Testing, Validation, and Continuous Improvement\nEdge Benchmarking:\n\nReal-time inference latency: &lt;10 ms per ECG segment.\nPower consumption: 5mW (optimized for long battery life).\n\nSecurity & Reliability:\n\nSecure Boot & Firmware Updates to prevent hacking.\nAdaptive AI Models: Learns individual patient heart patterns to reduce false alarms.\n\nFeedback & Model Updating:\n\nSync detected arrhythmia events with a cloud server for validation.\nUse federated learning to improve AI models without sharing raw patient data."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Step 7: Final Deployment & Scaling",
    "text": "Step 7: Final Deployment & Scaling\n\nMass production of the device for hospitals, clinics, and home use.\nIntegration with mobile apps for patient-doctor communication.\nRegulatory Approval: Submit for FDA/CE certification for medical device compliance.\nOver-the-Air (OTA) Updates: Allow model updates based on new ECG patterns."
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducaci√≥n\nDoctor en Ciencias de la Electr√≥nica. Magister en Ingenier√≠a Electr√≥nica y Telecomunicaciones Ingeniero en Electr√≥nica y Telecomunicaciones\nIntereses\nProcesamiento de Im√°genes, Dispositivos para el an√°lisis de movimiento humano, ciencia de los datos, IA.\n\nDesempe√±o\nProfesor del Centro de Estudios en Biom√©dica y Biotecnog√≠a\nProfesor en la l√≠nea de Procesmiento de Se√±ales e Im√°genes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducci√≥n a inteligencia artificial en el borde (EDGE AI).\nHardware y software para EDGE AI.\nEl flujo de trabajo de EDGE AI.\nDise√±o, desarrollo y evaluaci√≥n de sistemas EDGE AI."
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#estrateg√≠as-de-aprendizaje",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#estrateg√≠as-de-aprendizaje",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Estrateg√≠as de Aprendizaje",
    "text": "Estrateg√≠as de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nPr√°cticas de laboratorio, donde se utilizar√°n herramientas computacionales y se aplicar√°n conocimientos y destrezas adquiridas en otros cursos\nLecturas de la tem√°tica a tratar, previas a las clases magistrales\nLecturas de art√≠culos cient√≠ficos de inter√©s para el √°rea de procesamiento de se√±ales e im√°genes\nDesarrollo de talleres fuera de la clase\nProyecto pr√°ctico de fin de curso"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluaci√≥n",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluaci√≥n",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Evaluaci√≥n",
    "text": "Evaluaci√≥n\n\n\n\nLaboratorios (60%)\nProyecto Final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluaci√≥n-1",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluaci√≥n-1",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Evaluaci√≥n",
    "text": "Evaluaci√≥n\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (30%)\nLaboratorios (30%)\nProyecto final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201.\n\nInterpretes: R y python.\nOS: Linux\nLenguajes: C/C++\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#bibliograf√≠a",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#bibliograf√≠a",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Bibliograf√≠a",
    "text": "Bibliograf√≠a\n[1] ¬´Medical Image Analysis and Informatics¬ª.\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.¬™ ed.¬†Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. Ant√≥nio, C. Mora, y S. Jardim, ¬´Developments in Image Processing Using Deep Learning and Reinforcement Learning¬ª, J. Imaging, vol.¬†9, n.¬∫ 10, p.¬†207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, ¬´Biomedical Signal and Image Processing, Second Edition¬ª.\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.¬™ ed.¬†Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press‚ÄØ; CRC Press, 2022.\n[14] R. Raut, ¬´Intelligent Systems for Rehabilitation Engineering¬ª.\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, ¬´Biomedical Signal Analysis¬ª.\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et¬†al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et¬†al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.¬™ ed.¬†Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, ¬´Artificial Intelligence, Robots, and Philosophy¬ª.\n[23] L. N. McKinnis, ¬´Fundamentals of Musculoskeletal Imaging, Fifth Edition¬ª.\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et¬†al., ¬´Advances in Deep Learning-Based Medical Image Analysis¬ª, Health Data Sci, vol.¬†2021, p.¬†8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol.¬†228. en Intelligent Systems Reference Library, vol.¬†228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK‚ÄØ: Hoboken, NJ: ISTE‚ÄØ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, ¬´A review of the application of deep learning in medical image classification and segmentation¬ª, Ann Transl Med, vol.¬†8, n.¬∫ 11, pp.¬†713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed.¬†en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.¬™ ed.¬†NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980.\n[42] D. Situnayake y J. Plunkett, AI at the Edge: solving real-world problems with embedded machine learning. Sebastopol: O‚ÄôReilly, 2023.\n[43] X. Wang, Y. Han, V. C. M. Leung, D. Niyato, X. Yan, y X. Chen, Edge AI: Convergence of Edge Computing and Artificial Intelligence. Singapore: Springer Singapore, 2020. doi: 10.1007/978-981-15-6186-3.\n[44] A. Koul, S. Ganju, y M. Kasam, ¬´Practical Deep Learning for Cloud, Mobile, and Edge¬ª.\n[45] C. Paunwala et¬†al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[46] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.¬™ ed.¬†Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[47] V. Subramanian, Deep learning with PyTorch: a practical approach to building neural network models using PyTorch. Birmingham, UK: Packt Publishing, 2018.\n[48] Diagnostic Biomedical Signal and Image Processing Applications with Deep Learning Methods. Elsevier, 2023. doi: 10.1016/C2021-0-02190-8.\n[49] J. D. Kelleher, B. Mac Namee, y A. D‚ÄôArcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed.¬†Cambridge: The MIT press, 2020.\n[50] A. A. Patel, ¬´Hands-On Unsupervised Learning Using Python¬ª.\n[51] P. Raj, P. B. Soundarabai, y P. Augustine, Machine Intelligence: Computer Vision and Natural Language Processing, 1.¬™ ed.¬†Boca Raton: Auerbach Publications, 2023. doi: 10.1201/9781003424550.\n[52] M. Roy y L. R. Gupta, Eds., Machine Learning and Data Analytics for Predicting, Managing, and Monitoring Disease: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2021. doi: 10.4018/978-1-7998-7188-0.\n[53] A. R. Jha, Mastering PyTorch: create and deploy deep learning models from CNNs to multimodal models, LLMs, and beyond, Second edition. en Expert insight. Birmingham: Packt Publishing Limited, 2024.\n[54] V. K. Ayyadevara y Y. Reddy, Modern computer vision with PyTorch: a practical roadmap from deep learning fundamentals to advanced applications and Generative AI, Second edition. Birmingham, UK: Packt Publishing Ltd., 2024.\n[55] E. Priya y V. Rajinikanth, Eds., Signal and Image Processing Techniques for the Development of Intelligent Healthcare Systems. Singapore: Springer Singapore, 2021. doi: 10.1007/978-981-15-6141-2.\n[56] M. M. Richter, S. Paul, V. K√´puska, y M. Silaghi, Signal Processing and Machine Learning with Applications. Cham: Springer International Publishing, 2022. doi: 10.1007/978-3-319-45372-9."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#importance-of-frequency-response-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#importance-of-frequency-response-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Importance of Frequency-Response Filters",
    "text": "Importance of Frequency-Response Filters\n\nFrequency-response filters are critical for enhancing specific features or reducing noise in images.\nWidely used in MRI, CT, and ultrasound imaging."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#what-is-a-frequency-response-filter",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#what-is-a-frequency-response-filter",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "What is a Frequency-Response Filter?",
    "text": "What is a Frequency-Response Filter?\n\nA frequency-response filter modifies the frequency components of a signal.\nApplied in image processing to control which frequencies (details) pass or are suppressed."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#types-of-frequency-response-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#types-of-frequency-response-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Types of Frequency-Response Filters",
    "text": "Types of Frequency-Response Filters\n\nLow-pass filters: Allow low frequencies, suppress high frequencies (smoothes image).\nHigh-pass filters: Allow high frequencies, suppress low frequencies (sharpens image).\nBand-pass filters: Allow frequencies in a certain range."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#spatial-vs.-frequency-domain",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#spatial-vs.-frequency-domain",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Spatial vs.¬†Frequency Domain",
    "text": "Spatial vs.¬†Frequency Domain\n\nSpatial domain: Operations on pixel values directly.\nFrequency domain: Operations on the image‚Äôs frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#fourier-transform",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#fourier-transform",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Fourier Transform",
    "text": "Fourier Transform\n\nConverts an image from the spatial domain to the frequency domain.\nFormula: \\[F\\left(u,v\\right) = \\sum\\sum f\\left(x,y\\right) e^{-j2\\pi(\\frac{ux}{M} + \\frac{vy}{N})}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#low-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#low-pass-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Low-Pass Filters",
    "text": "Low-Pass Filters\n\nRemoves high-frequency components (e.g., noise, sharp edges).\nExample: Gaussian filter, Butterworth filter."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#high-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#high-pass-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "High-Pass Filters",
    "text": "High-Pass Filters\n\nEnhances edges and high-frequency details.\nExample: Laplacian filter."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#band-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#band-pass-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Band-Pass Filters",
    "text": "Band-Pass Filters\n\nAllows frequencies within a specific range.\nUseful for isolating specific image features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#noise-reduction-in-mri",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#noise-reduction-in-mri",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Noise Reduction in MRI",
    "text": "Noise Reduction in MRI\n\nLow-pass filters reduce noise and artifacts in MRI scans.\nSmoothes the image without losing crucial details."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#edge-enhancement-in-ultrasound-images",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#edge-enhancement-in-ultrasound-images",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Edge Enhancement in Ultrasound Images",
    "text": "Edge Enhancement in Ultrasound Images\n\nHigh-pass filters help in detecting tissue boundaries by enhancing edges.\nImproves clarity of anatomical structures."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#feature-extraction-in-ct-scans",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#feature-extraction-in-ct-scans",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Feature Extraction in CT Scans",
    "text": "Feature Extraction in CT Scans\n\nFilters can help in extracting features like tumors or vessels.\nBand-pass filters isolate structures of interest at specific frequency ranges."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process",
    "text": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process\n\nLoad MRI image.\nApply Fourier Transform to move the image into the frequency domain.\nDesign and apply a low-pass filter.\nPerform Inverse Fourier Transform to return to the spatial domain.\nVisualize the result."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#summary",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#summary",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Summary",
    "text": "Summary\n\nFrequency-response filters play a crucial role in biomedical image processing.\nHelp enhance key features and suppress unwanted noise."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#future-trends",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#future-trends",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Future Trends",
    "text": "Future Trends\n\nDeep learning integration with traditional filters.\nDevelopment of adaptive filters for real-time processing."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n(-1.0, 6.0)\n\n\n(-1.0, 5.0)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\nIt‚Äôs a mathematical tool for signal decomposition, like Fourier‚Äôs Transform.\nJust as the Fourier transform decomposes a signal into a series of sine and cosine functions, the wavelet transform does so using a set of functions known as wavelets.\nWavelets are functions generated by scaling and shifting a base function known as the mother wavelet."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-2",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-3",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\nMorlet: Popular for time-frequency analysis in EEG and ECG.\nMexican Hat (Ricker): Often used in spike detection in neural signals.\nHaar: Useful in quick decomposition of signals and feature extraction.\nDaubechies: Frequently used in ECG signal denoising and compression.\nSymlet: Another option for signal processing and feature extraction in EEG.\nCoiflet: Useful for denoising and baseline correction in biomedical signals."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-4",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-4",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\nConditionsIIIIIIIVV\n\n\n\nHave a mean of zero (to capture details in the signal).\nBe square integrable (finite energy).\nSatisfy the admissibility condition on its Fourier transform.\nBe oscillatory to capture frequency information.\n(Optionally) have compact support for efficient computation and localization.\n\n\n\n\n\n\n\n\n\n\nZero Mean (Admissibility Condition)\n\n\nThe function must have an average value of zero. Mathematically, this is expressed as:\n\\[\\int_{-\\infty}^{\\infty} \\psi(t) \\, dt = 0\\]\nThis condition ensures that the wavelet can detect changes or ‚Äúdetails‚Äù in the signal rather than its average or constant components.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSquare Integrability\n\n\nThe function \\(\\psi(t)\\) must be square integrable, meaning it has finite energy:\n\\[\\int_{-\\infty}^{\\infty} |\\psi(t)|^2 \\, dt &lt; \\infty\\]\nThis requirement ensures that the wavelet‚Äôs energy is finite, making it possible to localize the function in both time and frequency domains. Functions that satisfy this belong to the \\(L^2(\\rm I\\!R)\\) space, which is the space of all functions with finite energy.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdmissibility Constant\n\n\nThe wavelet‚Äôs Fourier transform, \\(\\hat{\\psi}(\\omega)\\), should satisfy the admissibility condition:\n\\[C_\\psi = \\int_{-\\infty}^{\\infty} \\frac{|\\hat{\\psi}(\\omega)|^2}{|\\omega|} \\, d\\omega &lt; \\infty\\]\nwhere \\(\\hat{\\psi}(\\omega)\\) is the Fourier transform of \\(\\psi(t)\\), and \\(\\omega\\) represents angular frequency. This condition implies that \\(\\hat{\\psi}(\\omega)\\) must approach zero as \\(\\omega \\rightarrow 0\\) meaning the wavelet has no component at zero frequency (or DC component). This condition is crucial for ensuring that the wavelet transform is invertible.\n\n\n\n\n\n\n\n\n\n\n\n\n\nOscillatory Nature\n\n\nA mother wavelet should generally be oscillatory or ‚Äúwavelike‚Äù (hence the term ‚Äúwavelet‚Äù). This oscillatory behavior allows the wavelet to capture variations in the signal. For example, wavelets like the Morlet wavelet resemble decaying sinusoids. This oscillatory nature helps the wavelet capture both high-frequency and low-frequency components effectively.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompact Support\n\n\nAlthough not strictly necessary, compact support is often a desirable property. Compact support means that the function is non-zero only over a finite interval, making it well-localized in time. This allows for efficient computation and good localization in the time domain. For example, the Haar wavelet has compact support, while others, like the Morlet wavelet, do not have strict compact support but still decay rapidly."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "A wavelet transformation",
    "text": "A wavelet transformation\n\n\n(0.0, 1.0)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "A wavelet transformation",
    "text": "A wavelet transformation"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe continuous wavelet transform of a signal \\(f(t)\\) is defined as:\n\\[W_f(a, b) = \\int_{-\\infty}^{\\infty} f(t) \\, \\psi^*\\left(\\frac{t - b}{a}\\right) \\, dt\\]\nwhere:\n\n\\(f(t)\\) is the input signal,\n\\(\\psi\\) is the mother wavelet,\n\\(a\\) is the scale parameter (controls the width of the wavelet),\n\\(b\\) is the translation parameter (controls the position of the wavelet),\n\\(\\psi^*\\) denotes the complex conjugate of the mother wavelet. ## Mathematical Expressions\n\nThe continuous wavelet transform of a signal \\(f(t)\\) is defined as:\n\\[W_f(a, b) = \\int_{-\\infty}^{\\infty} f(t) \\, \\psi^*\\left(\\frac{t - b}{a}\\right) \\, dt\\]\nwhere:\n\n\\(f(t)\\) is the input signal,\n\\(\\psi\\) is the mother wavelet,\n\\(a\\) is the scale parameter (controls the width of the wavelet),\n\\(b\\) is the translation parameter (controls the position of the wavelet),\n\\(\\psi^*\\) denotes the complex conjugate of the mother wavelet."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe inverse continuous wavelet transform is given by:\n\\[f(t) = \\frac{1}{C_{\\psi}} \\int_{0}^{\\infty} \\int_{-\\infty}^{\\infty} W_f(a, b) \\, \\psi\\left(\\frac{t - b}{a}\\right) \\frac{db \\, da}{a^2}\\]\nwhere:\nwhere \\(C_{\\psi}\\) is a normalization constant, defined as:\n\\[C_{\\psi} = \\int_{0}^{\\infty} \\frac{|\\hat{\\psi}(\\omega)|^2}{\\omega} \\, d\\omega\\]\nand \\(\\hat{\\psi}(\\omega)\\) is the Fourier transform of the wavelet \\(\\psi(t)\\)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-2",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe discrete wavelet transform decomposes the signal at discrete levels of scale. For a signal \\(x[n]\\), the wavelet decomposition is defined as:\n\\[c_{j, k} = \\sum_{n} x[n] \\, \\psi_{j, k}(n)\\]\nwhere:\n\n\\(\\psi_{j, k}(n)= \\frac{1}{\\sqrt{2}}\\psi\\left(\\frac{n-2^{j}k}{2^{j}}\\right)\\) represents the scaled and translated versions of the mother wavelet \\(\\psi\\)\n\\(j\\) is the scale index, and \\(k\\) is the translation index.\n\nThe decomposition typically consists of approximation and detail coefficients at each scale:\nApproximation coefficients \\(a_j\\): capture the low-frequency components. Detail coefficients \\(d_j\\) capture the high-frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-3",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe inverse discrete wavelet transform reconstructs the original signal from its approximation and detail coefficients: \\[x[n] = \\sum_{j} \\sum_{k} c_{j, k} \\, \\psi_{j, k}(n)\\]\nThis reconstruction process involves upsampling and filtering of the approximation and detail coefficients at each scale."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#using-cwt",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#using-cwt",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Using CWT",
    "text": "Using CWT\n\nPurpose: The CWT is used when you need a highly detailed, continuous analysis of a signal over all possible scales and positions.\nOutput: CWT gives you a ‚Äúheatmap‚Äù of wavelet coefficients, showing which frequencies (or scales) are present in the signal at each point in time. This allows for a continuous representation.\nApplications: CWT is useful for analyzing signals where you want to see the evolution of frequencies over time, such as:\n\nDetecting subtle changes in frequencies over time (like brainwave analysis in EEG).\nSignals with non-repeating, transient features (like spikes in biomedical signals, e.g., ECG).\n\nTrade-Off: CWT is more computationally expensive because it analyzes all scales and translations continuously. It gives lots of data but is slower and requires more memory.\n\n\n\n\n\n\n\n\nUse CWT when:\n\n\n\nYou need a detailed, continuous representation.\nYou want to detect subtle or fast-changing features across time.\nYou‚Äôre okay with higher computational costs to get very fine-grained analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#using-dwt",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#using-dwt",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Using DWT",
    "text": "Using DWT\n\nPurpose: The DWT is used when you want a compact, efficient representation of a signal, usually for compression or feature extraction. It analyzes only specific scales (powers of two), not continuously.\nOutput: DWT gives you a set of coefficients at each level (or scale), capturing information at that specific scale. It‚Äôs efficient and uses fewer data points.\nApplications: DWT is ideal when you want to reduce the size of data or focus on a smaller set of frequencies, such as:\n\nImage and audio compression (like JPEG 2000 or MP3 formats).\nFeature extraction for machine learning (e.g., identifying specific patterns).\nDe-noising signals by discarding certain scales that contain noise.\n\nTrade-Off: DWT is computationally cheaper but less detailed than CWT. It doesn‚Äôt give a continuous heatmap but rather a discrete set of scales.\n\n\n\n\n\n\n\n\nUse DWT when:\n\n\n\nYou need a compact and efficient representation.\nYou‚Äôre focused on data compression, de-noising, or feature extraction.\nYou want faster computations with less data storage requirements."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-analyzing-complex-signals",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-analyzing-complex-signals",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Introduction: Analyzing Complex Signals",
    "text": "Introduction: Analyzing Complex Signals\n\nSignals like ECG are often non-stationary.\nTheir frequency content and characteristics change over time.\nTraditional methods (e.g., Fourier Transform) analyze the signal globally, losing temporal information.\nNeed a method to analyze signals at different time scales and frequency bands simultaneously."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#what-is-multiresolution-analysis-mra",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#what-is-multiresolution-analysis-mra",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "What is Multiresolution Analysis (MRA)?",
    "text": "What is Multiresolution Analysis (MRA)?\n\nA mathematical framework to decompose a signal into components at different levels of resolution or detail.\nThink of it like looking at a picture:\n\nCoarse view (low resolution): See the overall structure.\nFine view (high resolution): See small details.\n\nMRA decomposes a signal into a series of approximations and details, capturing information across various scales.\nOften implemented using Wavelet Transforms (specifically the Discrete Wavelet Transform - DWT)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mra-the-nested-subspace-concept",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mra-the-nested-subspace-concept",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "MRA: The Nested Subspace Concept",
    "text": "MRA: The Nested Subspace Concept\n\nMRA is built upon a sequence of nested subspaces \\(V_j\\) in \\(L^2(\\mathbb{R})\\).\nThese subspaces represent approximations of the signal at different resolutions.\nKey Properties:\n\nNesting: \\(\\dots \\subset V_2 \\subset V_1 \\subset V_0 \\subset V_{-1} \\subset V_{-2} \\subset \\dots\\)\nDensity: The union of \\(V_j\\) is dense in \\(L^2(\\mathbb{R})\\).\nSeparation: The intersection of \\(V_j\\) is \\(\\{0\\}\\).\nScaling: \\(f(t) \\in V_j \\iff f(2t) \\in V_{j-1}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#the-scaling-function-phi",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#the-scaling-function-phi",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "The Scaling Function (\\(\\phi\\))",
    "text": "The Scaling Function (\\(\\phi\\))\n\nEach subspace \\(V_j\\) is generated by scaled and translated versions of a single function called the scaling function, \\(\\phi(t)\\).\n\\(\\{\\phi(t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(V_0\\).\n\\(\\{\\sqrt{2^j}\\phi(2^j t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(V_j\\).\nThe scaling function captures the ‚Äúsmooth‚Äù or low-frequency components ‚Äì the approximation of the signal at a given scale."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#the-wavelet-function-psi",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#the-wavelet-function-psi",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "The Wavelet Function (\\(\\psi\\))",
    "text": "The Wavelet Function (\\(\\psi\\))\n\nThe difference in information between two successive approximation spaces (\\(V_j\\) and \\(V_{j-1}\\)) is captured by the detail spaces, \\(W_j\\).\n\\(V_{j-1} = V_j \\oplus W_j\\), where \\(W_j\\) is the orthogonal complement of \\(V_j\\) in \\(V_{j-1}\\).\nThere exists a function \\(\\psi(t) \\in W_0\\), the wavelet function (or mother wavelet).\n\\(\\{\\psi(t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(W_0\\).\n\\(\\{\\sqrt{2^j}\\psi(2^j t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(W_j\\).\nThe wavelet function captures the ‚Äúdetails‚Äù or high-frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#linking-phi-and-psi-two-scale-equations",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#linking-phi-and-psi-two-scale-equations",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Linking \\(\\phi\\) and \\(\\psi\\): Two-Scale Equations",
    "text": "Linking \\(\\phi\\) and \\(\\psi\\): Two-Scale Equations\n\nThe scaling and wavelet functions are related through coefficients \\(h_k\\) and \\(g_k\\).\n\\(\\phi(t) = \\sqrt{2} \\sum_k h_k \\phi(2t - k)\\)\n\\(\\psi(t) = \\sqrt{2} \\sum_k g_k \\phi(2t - k)\\)\nThese equations show how functions at one scale (left side) are constructed from functions at a finer scale (right side).\nThe coefficients \\(h_k\\) and \\(g_k\\) are critical ‚Äì they define the specific wavelet and are the impulse responses of filters used in discrete implementations."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#from-math-to-practice-filters",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#from-math-to-practice-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "From Math to Practice: Filters",
    "text": "From Math to Practice: Filters\n\nThe sequences \\(h_k\\) and \\(g_k\\) correspond to digital filters:\n\n\\(H = \\{h_k\\}\\) is a low-pass filter.\n\\(G = \\{g_k\\}\\) is a high-pass filter.\n\nThese filters are designed such that \\(G\\) is derived from \\(H\\) (for orthonormal wavelets, \\(g_k = (-1)^k h_{N-1-k}\\)).\nApplying the low-pass filter and downsampling corresponds to projecting the signal onto \\(V_j\\).\nApplying the high-pass filter and downsampling corresponds to projecting the signal onto \\(W_j\\)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#discrete-mra-mallats-algorithm",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#discrete-mra-mallats-algorithm",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Discrete MRA: Mallat‚Äôs Algorithm",
    "text": "Discrete MRA: Mallat‚Äôs Algorithm\n\nThe discrete implementation of MRA is efficiently computed using Mallat‚Äôs Algorithm (or the Fast Wavelet Transform - FWT).\nIt‚Äôs a pyramidal algorithm based on filter banks and downsampling/upsampling.\nDecomposes the discrete signal into approximation (\\(A\\)) and detail (\\(D\\)) coefficients at successive levels."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-decomposition",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-decomposition",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Mallat‚Äôs Algorithm: Decomposition",
    "text": "Mallat‚Äôs Algorithm: Decomposition\nStarting with signal \\(x[n]\\) (considered \\(A_0\\)):\n\nConvolve \\(A_j\\) with low-pass filter \\(H\\) and high-pass filter \\(G\\).\nDownsample outputs by 2 (\\(\\downarrow 2\\)).\n\nOutput of \\(H \\to \\downarrow 2\\) gives approximation coefficients \\(A_{j+1}\\).\nOutput of \\(G \\to \\downarrow 2\\) gives detail coefficients \\(D_{j+1}\\).\n\nRepeat the process on the approximation coefficients \\(A_{j+1}\\) for the next level.\n\n\\[ A_{j+1} = (A_j * H) \\downarrow 2 \\] \\[ D_{j+1} = (A_j * G) \\downarrow 2 \\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-reconstruction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-reconstruction",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Mallat‚Äôs Algorithm: Reconstruction",
    "text": "Mallat‚Äôs Algorithm: Reconstruction\nReconstructing signal \\(A_j\\) from \\(A_{j+1}\\) and \\(D_{j+1}\\):\n\nUpsample \\(A_{j+1}\\) and \\(D_{j+1}\\) by 2 (\\(\\uparrow 2\\), insert zeros).\nConvolve upsampled coefficients with reconstruction filters \\(H'\\) and \\(G'\\).\nAdd the results to get \\(A_j\\).\nRepeat until the original signal \\(A_0\\) is reconstructed.\n\n\\[ A_j = (A_{j+1} \\uparrow 2 * H') + (D_{j+1} \\uparrow 2 * G') \\] (For orthonormal wavelets, \\(H'\\) and \\(G'\\) are time-reversed \\(H\\) and \\(G\\))"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mra-architecture",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mra-architecture",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "MRA Architecture",
    "text": "MRA Architecture"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#why-mra-for-ecg",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#why-mra-for-ecg",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Why MRA for ECG?",
    "text": "Why MRA for ECG?\n\nECG signals are non-stationary and have features at different scales:\n\nQRS complex: Sharp, high frequency, short duration.\nP and T waves: Broader, lower frequency, longer duration.\nBaseline wander: Very low frequency.\nMuscle noise: High frequency.\n\nMRA naturally separates these components into different frequency bands (detail levels), making analysis easier."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-denoising",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-denoising",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Applications of MRA in ECG: Denoising",
    "text": "Applications of MRA in ECG: Denoising\n\nNoise (powerline, muscle, baseline wander) occupies different frequency bands.\nDecompose noisy ECG using MRA.\nNoise components are isolated in specific detail coefficients:\n\nHigh-frequency noise in fine detail levels.\nBaseline wander in coarse approximation/detail levels.\n\nApply thresholding to the noise-dominated coefficients (e.g., set small values to zero).\nReconstruct the signal from the modified coefficients to get a denoised ECG."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-feature-extraction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-feature-extraction",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Applications of MRA in ECG: Feature Extraction",
    "text": "Applications of MRA in ECG: Feature Extraction\n\nDifferent ECG waves are highlighted in different MRA levels:\n\nQRS complex: Often prominent in mid-to-high frequency detail coefficients.\nP and T waves: Appear in lower frequency detail coefficients or approximation coefficients.\n\nAnalyze coefficients at relevant scales:\n\nDetect QRS peaks by finding local maxima in specific detail levels.\nDelineate P and T waves by analyzing the shape and zero-crossings of coefficients at coarser scales.\n\nExtract clinically relevant features (intervals, amplitudes) from the detected waves."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#other-applications-in-ecg",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#other-applications-in-ecg",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Other Applications in ECG",
    "text": "Other Applications in ECG\n\nCompression: MRA provides a sparse representation; many coefficients are small and can be discarded or quantized, reducing data size.\nAbnormality Detection and Classification: Features derived from the distribution or patterns of coefficients across different MRA levels can be used as input for machine learning algorithms to classify arrhythmias or other heart conditions."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#practical-implementation-steps",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#practical-implementation-steps",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Practical Implementation Steps",
    "text": "Practical Implementation Steps\n\nAcquisition & Preprocessing: Get digitized ECG data. Basic filtering might precede MRA if necessary.\nChoose Wavelet: Select a wavelet family (e.g., Daubechies ‚ÄòdbN‚Äô, Symlets ‚ÄòsymN‚Äô). Consider similarity of wavelet shape to ECG features (e.g., QRS) and vanishing moments.\nDetermine Decomposition Levels: Choose the number of levels (\\(J\\)) based on sampling frequency (\\(F_s\\)) and the frequency bands of interest. Detail level \\(j\\) covers frequencies approx. \\([F_s/2^{j+1}, F_s/2^j]\\).\nPerform Decomposition: Apply Mallat‚Äôs algorithm (DWT) to get approximation and detail coefficients.\nAnalyze/Process Coefficients: Apply denoising (thresholding) or feature extraction techniques to the relevant coefficients.\nReconstruct (Optional): Reconstruct the signal if a filtered or modified ECG is needed."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#implementation-wavelet-choice-levels",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#implementation-wavelet-choice-levels",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Implementation: Wavelet Choice & Levels",
    "text": "Implementation: Wavelet Choice & Levels\n\nWavelet Family: Daubechies (db) and Symlets (sym) are common for ECG. ‚Äòdb4‚Äô is often cited for its similarity to the QRS complex.\nNumber of Levels (\\(J\\)):\n\nHigher levels give coarser approximations and lower frequency details.\nChoose \\(J\\) so that key ECG features fall into specific, separable detail levels.\nE.g., for a 360 Hz ECG, QRS (10-50 Hz) might be in D3-D5, P/T (1-10 Hz) in D5-D7, baseline wander (&lt;1 Hz) in A7 or D8+."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#conclusion",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#conclusion",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Conclusion",
    "text": "Conclusion\n\nMultiresolution Analysis is a powerful technique for analyzing non-stationary signals like ECG.\nIt decomposes the signal into different frequency bands/scales using scaling and wavelet functions.\nImplemented efficiently via Mallat‚Äôs algorithm (DWT).\nEnables effective ECG denoising by isolating noise at specific levels.\nFacilitates robust feature extraction (P, QRS, T) by highlighting them in different detail coefficients.\nA fundamental tool in modern automated ECG analysis systems."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis\n\n# Elegir wavelet y nivel de descomposici√≥n\nwavelet = \"db4\"\nmax_level = 3\n\n# Descomposici√≥n multiresoluci√≥n\ncoeffs = pywt.wavedec(ecg001, wavelet, level=max_level)\n# coeffs[0]: coeficientes de aproximaci√≥n al nivel 3 (cA3)\n# coeffs[1:], coeficientes de detalle en niveles 3, 2, 1 (cD3, cD2, cD1)\n\n# Reconstruir aproximaci√≥n al nivel m√°ximo\narr_approx = [coeffs[0]] + [np.zeros_like(c) for c in coeffs[1:]]\napprox = pywt.waverec(arr_approx, wavelet)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis\n\n\n# Reconstruir detalles por cada nivel\ndetails = []\nfor i in range(1, max_level + 1):\n    arr_detail = [np.zeros_like(c) for c in coeffs]\n    arr_detail[i] = coeffs[i]\n    detail = pywt.waverec(arr_detail, wavelet)\n    details.append(detail)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-2",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-3",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-4",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-4",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---element-wise-operation",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---element-wise-operation",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Basic Mathematic - Element-Wise Operation",
    "text": "Basic Mathematic - Element-Wise Operation\n\n\n\n\n\n\n\nDefinition\n\n\nOperation involving one or more images is carried out on a pixel-bypixel basis\n\n\n\n\n\\[\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{bmatrix} \\oplus \\begin{bmatrix} b_{11} & b_{12} \\\\  b_{21} & b_{22}\\end{bmatrix} = \\begin{bmatrix} a_{11}+b_{11} & a_{12}+b_{12} \\\\  a_{21}+b_{21} & a_{22}+b_{22}\\end{bmatrix} \\]\n\\[\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{bmatrix} \\odot \\begin{bmatrix} b_{11} & b_{12} \\\\  b_{21} & b_{22}\\end{bmatrix} = \\begin{bmatrix} a_{11}.b_{11} & a_{12}.b_{12} \\\\  a_{21}.b_{21} & a_{22}.b_{22}\\end{bmatrix} \\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---linear-operations",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---linear-operations",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Basic Mathematic - Linear Operations",
    "text": "Basic Mathematic - Linear Operations\n\n\n\n\n\n\n\nDefinition\n\n\nGiven two arbitrary constants, \\(\\alpha_1\\) and \\(\\alpha_2\\), and two arbitrary images \\(f_1\\left(x,y\\right)\\) and \\(f_2\\left(x,y\\right)\\), \\(\\varkappa\\) is said to be a linear operator if:\n\\[ \\begin{equation}\\begin{split} \\varkappa\\left[\\alpha_1 f_1\\left(x,y\\right) + \\alpha_2 f_2\\left(x,y\\right)\\right] & =  \\alpha_1 \\varkappa\\left[ f_1\\left(x,y\\right)\\right] + \\alpha_2 \\varkappa\\left[f_2\\left(x,y\\right)\\right] \\\\ & = \\alpha_1 g_1\\left(x,y\\right) + \\alpha_2 g_2\\left(x,y\\right) \\end{split}\\end{equation} \\]\n\n\n\n\nSupose \\(\\alpha_1 = 5\\), \\(\\alpha_2 = 2\\), \\(\\varkappa = max\\) and consider:\n\\[f_1 = \\begin{bmatrix}0 & -1 \\\\2 & 4\\end{bmatrix}\\], \\[f_2 = \\begin{bmatrix}30 & 4 \\\\-2 & -3\\end{bmatrix}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Basic Mathematic - Adding",
    "text": "Basic Mathematic - Adding"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Basic Mathematic - Adding",
    "text": "Basic Mathematic - Adding\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_ray_chest = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/female-chest-x-ray.jpg\")\nplt.imshow(x_ray_chest, cmap=\"gray\")\nplt.show()\nimage_synt1 = 100*np.abs(np.random.normal(0, 1, x_ray_chest.shape))\nplt.imshow(image_synt1)\nplt.show()\nfinal_image = np.uint8(x_ray_chest+image_synt1)\nplt.imshow(final_image)\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---multiplying",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---multiplying",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Basic Mathematic - Multiplying",
    "text": "Basic Mathematic - Multiplying\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_ray_chest = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/female-chest-x-ray.jpg\")\nmask = np.uint8(np.zeros(x_ray_chest.shape))\nmask[400:700, 250:600, :]=1\nplt.imshow(x_ray_chest)\nplt.show()\nplt.imshow(255*mask)\nplt.show()\nplt.imshow(np.multiply(x_ray_chest,mask))\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---basic-transformation",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---basic-transformation",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Basic Mathematic - Basic transformation",
    "text": "Basic Mathematic - Basic transformation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[x_{\\text{rescaled}} = n_{\\min} + \\frac{(x - \\min)}{\\max - \\min} \\, (n_{\\max} - n_{\\min})\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\nImagesCode\n\n\n\n\n\n\n\n\nExp=1.2\n\n\n\n\n\n\n\nExp=0.2\n\n\n\n\n\n\n\nExp=0.30\n\n\n\n\n\n\n\n\n\nExp=0.5\n\n\n\n\n\n\n\nOriginal\n\n\n\n\n\n\n\nExp=1.1\n\n\n\n\n\n\n\n\nx_ray_chest_gray = cv2.cvtColor(x_ray_chest, cv2.COLOR_BGR2GRAY)\nplt.imshow(x_ray_chest_gray, cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,1.1), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,1.2), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.2), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.3), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.5), cmap=\"gray\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-2",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Neighborhood Operations",
    "text": "Neighborhood Operations\n\nFor example, suppose that the specified operation is to compute the average value of the pixels in a rectangular neighborhood of size mn √ó centered on \\(\\left(x,y\\right)\\). The coordinates of pixels in this region are the elements of set \\(S_{xy}\\).\n\n\nImagescode\n\n\n\n\n\n\n\n\n\nElderly woman image\n\n\n\n\n\n\n\n\n\n\nGray-scale image\n\n\n\n\n\n\n\n\n#|\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nplt.imshow(elderly)\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-2",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nOriginalAveragingCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN = 10\nkernel = np.ones((N,N),np.float32)/(N*N)\ndst = cv2.filter2D(elderly_gray,-1,kernel)\nplt.imshow(dst, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-3",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-3",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nOriginalMedianCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN=11\n\ndst1 = cv2.medianBlur(elderly_gray, N)\nplt.imshow(dst1, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-4",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-4",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nMeanMedian"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-5",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-5",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-6",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-6",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: http://datagenetics.com/blog/august32013/index.html"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Edge dection",
    "text": "Edge dection"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Edge dection",
    "text": "Edge dection"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-2",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Edge dection",
    "text": "Edge dection\n\nImages Grad YImages Grad XImages Grad Trunc YImages Trunc Grad XCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndst = cv2.Sobel(elderly_gray, cv2.CV_16S, 1, 0,  ksize=3, scale=1, delta=0, borderType= cv2.BORDER_DEFAULT)\ndst1 = np.uint8(255*dst/np.max(dst))\nplt.imshow(dst1, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Histogram",
    "text": "Histogram\n\nHistogramCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-2",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Histogram",
    "text": "Histogram\n\nFirst thing to doImageCodeRecommended Reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n3\n2\n2\n1\n1\n0\n3\n0\n1\n\n\n2\n2\n2\n3\n2\n2\n0\n2\n2\n1\n\n\n0\n3\n2\n0\n1\n1\n3\n1\n1\n1\n\n\n3\n0\n2\n0\n2\n3\n1\n0\n2\n1\n\n\n2\n2\n0\n0\n3\n1\n3\n1\n3\n1\n\n\n3\n3\n2\n0\n3\n0\n3\n2\n0\n3\n\n\n3\n3\n1\n1\n2\n3\n0\n3\n1\n3\n\n\n3\n1\n3\n3\n2\n0\n3\n0\n2\n1\n\n\n2\n1\n1\n3\n3\n1\n3\n2\n2\n1\n\n\n0\n3\n2\n2\n1\n1\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\n\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"red\")\nplt.show()\n\n\n\ncv2.calcHist(images, channels, mask, histSize, ranges)\nHelp Docs Opencv"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-3",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-3",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Histogram",
    "text": "Histogram\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef adjust_gamma(image, gamma=1.0):\n   invGamma = 1.0 / gamma\n   table = np.array([((i / 255.0) ** invGamma) * 255\n      for i in np.arange(0, 256)]).astype(\"uint8\")\n\n   return cv2.LUT(image, table)\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"red\")\nplt.show()\nelderly_gray_light = adjust_gamma(image=elderly_gray, gamma=2)\nplt.imshow(elderly_gray_light, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_light = cv2.calcHist(elderly_gray_light, [0], None, [256], [0,256])\nplt.plot(elderly_hist_light, color=\"red\")\nplt.show()\nelderly_gray_dark = adjust_gamma(image=elderly_gray, gamma=0.3)\nplt.imshow(elderly_gray_dark, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_dark = cv2.calcHist(elderly_gray_dark, [0], None, [256], [0,256])\nplt.plot(elderly_hist_dark, color=\"red\")\nplt.show()\nelderly_gray_lowcontrast=np.uint8(0.1*elderly_gray)+172\nplt.imshow(elderly_gray_lowcontrast, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_lowcontrast = cv2.calcHist(elderly_gray_lowcontrast, [0], None, [256], [0,256])\nplt.plot(elderly_hist_lowcontrast, color=\"red\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Histogram Equalization",
    "text": "Histogram Equalization\n\n\n\n\n\n\n\nAlgorithm\n\n\n\nCalculate Histogram: Calculate the histogram of the original image, showing the frequency distribution of each intensity level.\nCalculate Cumulative Distribution Function (CDF): Calculate the cumulative distribution function (CDF) of the histogram. The CDF represents the cumulative sum of frequencies for each intensity level.\nEqualization: For each pixel in the original image, calculate the new intensity value using the formula: \\[New_value = (CDF(old value) * (L-1))\\] where L is the number of intensity levels (e.g., 256 for an 8-bit image).\nAssign New Values: Assign the new intensity values calculated in step 3 to the equalized image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Histogram Equalization",
    "text": "Histogram Equalization\n\nImagesCodeRecommended Reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.imshow(elderly_gray_lowcontrast, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\nplt.plot(elderly_hist_lowcontrast, color=\"red\")\nplt.show()\n\nelderly_hist_equ = cv2.equalizeHist(elderly_gray_lowcontrast)\nplt.imshow(elderly_hist_equ, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\nelderly_hist_equ = cv2.calcHist(elderly_hist_equ, [0], None, [256], [0,256])\nplt.plot(elderly_hist_equ, color=\"red\")\nplt.show()\n\n\n\nHistogram Equalization OPENCV tutorial"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-matching",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-matching",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Histogram Matching",
    "text": "Histogram Matching\n\nExplainAlgorithmResultCode\n\n\n\n\n\nTaken from PyImageSearch\n\n\n\n\nStep 1: Calculate Histograms Compute the histograms of the source image (Hs) and target image (Ht) for intensity values (r).\nStep 2: Calculate CDFs Compute the cumulative distribution functions (CDFs) for the source image (CDFs) and target image (CDFt).\nStep 3: Establish Correspondence Find the corresponding intensity values between the source and target images using the inverse CDF of the target image.\nStep 4: Apply Transformation Apply the intensity transformation to the source image using the established correspondence.\nStep 5: Verify Similarity Calculate the mean absolute difference between the transformed source image and the target image to verify their similarity.\n\n\n\n\n\n\n\n\n\n\n\n(np.float64(-0.5), np.float64(1199.5), np.float64(799.5), np.float64(-0.5))\n\n\n\n\n\n\n\n\n\nDiferencia media absoluta: 4.501011458333333\n\n\n\n\n\n# Cargar la imagen fuente y objetivo\nimg_s = cv2.imread('imagen_fuente.jpg')\nimg_t = cv2.imread('imagen_objetivo.jpg')\n\n# Calcula los histogramas\nhist_s = cv2.calcHist([img_s], [0], None, [256], [0, 256])\nhist_t = cv2.calcHist([img_t], [0], None, [256], [0, 256])\n\n# Calcula las CDF\ncdf_s = np.cumsum(hist_s)\ncdf_t = np.cumsum(hist_t)\n\n# Establece la correspondencia\nr_t = np.interp(cdf_s, cdf_t, np.arange(256))\n\n# Aplica la transformaci√≥n\nimg_t_match = cv2.LUT(img_s, r_t)\n\n# Verifica la similitud\ndiff = np.mean(np.abs(img_t_match - img_t))\n\nprint(f'Diferencia media absoluta: {diff}')"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducaci√≥n\nDoctor en Ciencias de la Electr√≥nica. Magister en Ingenier√≠a Electr√≥nica y Telecomunicaciones Ingeniero en Electr√≥nica y Telecomunicaciones\nIntereses\nProcesamiento de Im√°genes, Dispositivos para el an√°lisis de movimiento humano, ciencia de los datos, IA.\n\nDesempe√±o\nProfesor del Centro de Estudios en Biom√©dica y Biotecnog√≠a\nProfesor en la l√≠nea de Procesmiento de Se√±ales e Im√°genes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducci√≥n al procesado de se√±ales e im√°genes biom√©dicas.\nFundamentos procesado de se√±ales e im√°genes biom√©dicas\nExtracci√≥n de caracter√≠sticas de se√±ales biom√©dicas.\nExtracci√≥n de caracter√≠sticas de im√°genes biom√©dicas."
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#estrateg√≠as-de-aprendizaje",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#estrateg√≠as-de-aprendizaje",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Estrateg√≠as de Aprendizaje",
    "text": "Estrateg√≠as de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluaci√≥n final\nPr√°cticas de laboratorio, donde se utilizar√°n herramientas computacionales y se aplicar√°n conocimientos y destrezas adquiridas en otros cursos\nLecturas de la tem√°tica a tratar, previas a las clases magistrales\nLecturas de art√≠culos cient√≠ficos de inter√©s para el √°rea de procesamiento de se√±ales e im√°genes\nDesarrollo de talleres fuera de la clase\nProyecto pr√°ctico de fin de curso"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluaci√≥n",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluaci√≥n",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Evaluaci√≥n",
    "text": "Evaluaci√≥n\n\n\n\nExamen parcial 1 (15%)\nExamen parcial 2 (15%)\nExamen final (20%)\nLaboratorios (30%)\nProyecto Final (20%)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluaci√≥n-1",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluaci√≥n-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Evaluaci√≥n",
    "text": "Evaluaci√≥n\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (15%)\nLaboratorios (15%)\nProyecto final (20%)\n\n\nExamen Parcial 1 (15%)\nExamen Parcial 2 (15%)\nExamen final (20%)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nLunes 2:30pm-4:00pm F-105. Martes 2:30pm-4:00pm D-201.\nLaboratorio\nJUEVES 2:30pm-4:00pm. I1-304\n\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#bibliograf√≠a",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#bibliograf√≠a",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Bibliograf√≠a",
    "text": "Bibliograf√≠a\n[1] ¬´Medical Image Analysis and Informatics¬ª.\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.¬™ ed.¬†Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. Ant√≥nio, C. Mora, y S. Jardim, ¬´Developments in Image Processing Using Deep Learning and Reinforcement Learning¬ª, J. Imaging, vol.¬†9, n.¬∫ 10, p.¬†207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, ¬´Biomedical Signal and Image Processing, Second Edition¬ª.\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.¬™ ed.¬†Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press‚ÄØ; CRC Press, 2022.\n[14] R. Raut, ¬´Intelligent Systems for Rehabilitation Engineering¬ª.\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, ¬´Biomedical Signal Analysis¬ª.\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et¬†al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et¬†al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.¬™ ed.¬†Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, ¬´Artificial Intelligence, Robots, and Philosophy¬ª.\n[23] L. N. McKinnis, ¬´Fundamentals of Musculoskeletal Imaging, Fifth Edition¬ª.\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et¬†al., ¬´Advances in Deep Learning-Based Medical Image Analysis¬ª, Health Data Sci, vol.¬†2021, p.¬†8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol.¬†228. en Intelligent Systems Reference Library, vol.¬†228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK‚ÄØ: Hoboken, NJ: ISTE‚ÄØ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, ¬´A review of the application of deep learning in medical image classification and segmentation¬ª, Ann Transl Med, vol.¬†8, n.¬∫ 11, pp.¬†713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed.¬†en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.¬™ ed.¬†NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\nDefinition\n\n\n\nTwo-dimensional function, f(x, y)\nWhere x and y are spatial coordinates.\nThe amplitude of f at any pair of coordinates (x, y) is called the intensity.\n\n\n\n\n\n\n\n\n\n\n\n\nThe digital image\n\n\nIf the coordinates and the intensity are discrete quantities the image turns into a digital image."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\nDefinition\n\n\nA digital image is composed by a finite number of elements called PIXEL.\n\n\n\n\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\n\nDepth\n\n\n\nA digital image is composed by a finite number of elements called PIXEL. Bpp( Bits per pixel)\n\n1bpp. B/W image, monochrome.\n2bpp. CGA Image.\n4bpp. Minimun for VGA standard.\n8bpp. Super-VGA image.\n24bpp. Truecolor image.\n48bpp. Professional-level images."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\n\nColor Space\n\n\nHow can i represent the color\n\nRGB.\nCMYK.\nHSV.\nAmong others."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"image01.tif\")\nfig001 = plt.figure()\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"lena.tif\")\nRGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig002 = plt.figure()\nplt.imshow(RGB_img)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nThe paradigm surrounding the conceptualization of light and perception has undergone significant evolution.\nInitially, the prevailing understanding within humanity posited that visual stimuli emanated from the eye itself.\nHowever, contemporary knowledge has elucidated that light originates from external sources, undergoes reflection from objects within the environment, and is subsequently captured by the eye."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nImportant\n\n\nWe also understand that light is a type of electromagnetic radiation, and its wavelength falls within a range from 400 nanometers to 700 nanometers.\n\n\n\n\n\nTaken from Corke 2023"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nImportant\n\n\n\nThe most common way light is made is by something getting really hot. This makes energy that comes out as light.\nSome important term are:\n\nAbsortion: It is the fraction of light which a body absorbs depending on the wavelength.\nReflectance: It is the fraction of the incoming light which a body reflects. It‚Äôs a number between 0 to 1 and also depends on wavelength.\nLuminance: It is the fraction of the incoming light which a surface reflects. It‚Äôs a function of absortion and reflectance, and because of that luminance depends on wavelength."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nThe eye\n\n\n\nOur eye has two types of cells. Cones and Rods.\nCones are the most sensitive cells but above all these are color sensitive.\nRods responds only two intensity and they used on night, mostly.\nHumans, like most primates, are trichomats. This means that humans have three types of cones (Long, Medium and shorts).\n\n65% of longs (Sense red)\n33% of mediums (Sense green)\n2% of shortsv(Sense blue)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nThe artificial eye\n\n\n\n\n\nTaken from Corke 2023\n\n\n\n\n\n\nThe currents from each sensor are function of the luminance and the spectral response filter."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\n\n\n\n\n\n\nDefinition\n\n\nSampling: Digitalization of the spatial coordinates.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nQuantiazation: Digitalization of the light intensity (amplitude)."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1bit\n\n\n\n\n\n\n\n\n\n2bit\n\n\n\n\n\n\n\n\n\n3bit\n\n\n\n\n\n\n\n\n\n4bit\n\n\n\n\n\n\n\n\n\n\n\n5bit\n\n\n\n\n\n\n\n\n\n6bit\n\n\n\n\n\n\n\n\n\n7bit\n\n\n\n\n\n\n\n\n\n8bit"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Linear indexing",
    "text": "Linear indexing\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\nFrom normal to linear\n\n\n\\[\\alpha = My+x\\]\n\n\n\n\n\n\n\n\n\n\n\n\nFrom linear to normal\n\n\n\\[x = \\alpha \\bmod M\\]\n\\[y = \\frac{\\alpha - x}{M}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Spatial resolution",
    "text": "Spatial resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Intensity resolution",
    "text": "Intensity resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Intensity resolution",
    "text": "Intensity resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "‚ÄúA simple problem‚Äù",
    "text": "‚ÄúA simple problem‚Äù\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "‚ÄúA simple problem‚Äù",
    "text": "‚ÄúA simple problem‚Äù\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\nNeighborhood\n\n\n\n\n\n\n\n\n\n\nN4\n\n\n\n\n\n\n\nND\n\n\n\n\n\n\n\nN8\n\n\n\n\n\n\nFigura¬†1"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels ‚Äì Neighborhood",
    "text": "Relationships between pixels ‚Äì Neighborhood\n\n\n\n\n\n\n\nNeighborhood\n\n\n\n\n\n\n\n\n\n\nN4-\\(N_4\\left(p\\right)\\)\n\n\n\n\n\n\n\nND-\\(N_D\\left(p\\right)\\)\n\n\n\n\n\n\n\nN8-\\(N_8\\left(p\\right)\\)\n\n\n\n\n\n\nFigura¬†2: Neighborhoods"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels ‚Äì Adjacency",
    "text": "Relationships between pixels ‚Äì Adjacency\n\n\n\n\n\n\n\nRules for adjecency\n\n\n\n4-Adjecncy: Two pixels p and q with values from V are 4-adjacent if q is in the set \\(N_4\\left(p\\right)\\)\n8-adjacency. Two pixels p and q with values from V are 8-adjacent if q is in the set \\(N_8\\left(p\\right)\\)\nm-adjacency (also called mixed adjacency). Two pixels p and q with values from V are m-adjacent if:\n\nq is in \\(N_4\\left(p\\right)\\).\nq is in \\(N_D\\left(p\\right)\\) and the set \\(N_4\\left(p\\right) \\cap N_4\\left(q\\right)\\) has no pixels whose values are from V."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\nAdjacency"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\n\n\n\nA4\n\n\n\n\n\n\n\n\n\n\n\nA8\n\n\n\n\n\n\n\n\n\n\n\n\n\nA-m"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels ‚Äì Path",
    "text": "Relationships between pixels ‚Äì Path\n\n\n\n\n\n\n\nDigital path\n\n\nIt is a sequence of adjacent pixels.\n\\[\\left(x_0, y_0\\right), \\left(x_1, y_1\\right), \\left(x_2, y_2\\right), \\dots \\left(x_n, y_n\\right)\\]\nIf \\(\\left(x_0, y_0\\right)=\\left(x_n, y_n\\right)\\) the path is known as closed path\nLet S represent a subset of pixels in an image. Two pixels p and q are said to be connected in S if there exists a path between them consisting entirely of pixels in S."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels ‚Äì Path, Connected Subset",
    "text": "Relationships between pixels ‚Äì Path, Connected Subset"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels ‚Äì Regions",
    "text": "Relationships between pixels ‚Äì Regions"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels ‚Äì Boundary",
    "text": "Relationships between pixels ‚Äì Boundary"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels ‚Äì Distance",
    "text": "Relationships between pixels ‚Äì Distance\n\n\n\n\n\n\n\nDistance\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\nDistance\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction",
    "text": "Introduction\n\nSignals can be analyzed in both time domain and frequency domain.\nThe frequency content of a signal describes how different frequency components contribute to the overall signal.\nApplications in biomedical signals, audio processing, communications, and image processing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-in-time-domain",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-in-time-domain",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Convolution in Time Domain",
    "text": "Convolution in Time Domain\n\nConvolution is a fundamental operation in signal processing.\nGiven two signals \\(x(t)\\) and \\(h(t)\\), their convolution is defined as:\n\\[ y(t) = x(t) * h(t) = \\int_{-\\infty}^{\\infty} x(\\tau) h(t - \\tau) d\\tau \\]\nIn discrete-time, convolution is:\n\\[ y[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n-k] \\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-theorem",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Convolution Theorem",
    "text": "Convolution Theorem\n\nConvolution in time domain corresponds to multiplication in frequency domain:\n\\[ X(f) H(f) = Y(f) \\]\nThis property is crucial in filter design and system analysis.\n\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\n\n(-1.0, 4.0)\n\n\n(-1.0, 4.0)\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\nConvolution requiere the representation of the signal in a sum of impulse functions.\nFourier series represents periodic signals as a sum of sinusoids:\n\\[ x(t) = \\sum_{n=-\\infty}^{\\infty} C_n e^{jn\\omega_0 t} \\]\nwhere \\(C_n\\) are the Fourier coefficients.\nDecomposing a signal into sinusoidal components allows frequency analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#fourier-coefficients",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#fourier-coefficients",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Fourier Coefficients",
    "text": "Fourier Coefficients\n\nThe Fourier coefficients \\(C_n\\) are computed as:\n\\[ C_n = \\frac{1}{T} \\int_{0}^{T} x(t) e^{-jn\\omega_0 t} dt \\]\nDetermines how much of each frequency is present in the signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-fourier-series-expansion",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-fourier-series-expansion",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example of Fourier Series Expansion",
    "text": "Example of Fourier Series Expansion\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example 2 of Fourier Series",
    "text": "Example 2 of Fourier Series\n\n\n(array([-5.,  0.,  5., 10., 15., 20., 25., 30., 35.]), [Text(-5.0, 0, '‚àí5'), Text(0.0, 0, '0'), Text(5.0, 0, '5'), Text(10.0, 0, '10'), Text(15.0, 0, '15'), Text(20.0, 0, '20'), Text(25.0, 0, '25'), Text(30.0, 0, '30'), Text(35.0, 0, '35')])\n\n\n(array([4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5]), [Text(0, 4.5, '4.5'), Text(0, 5.0, '5.0'), Text(0, 5.5, '5.5'), Text(0, 6.0, '6.0'), Text(0, 6.5, '6.5'), Text(0, 7.0, '7.0'), Text(0, 7.5, '7.5'), Text(0, 8.0, '8.0'), Text(0, 8.5, '8.5')])\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example 2 of Fourier Series",
    "text": "Example 2 of Fourier Series\n\n\n(array([-40., -30., -20., -10.,   0.,  10.,  20.,  30.,  40.]), [Text(-40.0, 0, '‚àí40'), Text(-30.0, 0, '‚àí30'), Text(-20.0, 0, '‚àí20'), Text(-10.0, 0, '‚àí10'), Text(0.0, 0, '0'), Text(10.0, 0, '10'), Text(20.0, 0, '20'), Text(30.0, 0, '30'), Text(40.0, 0, '40')])\n\n\n(array([4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5]), [Text(0, 4.5, '4.5'), Text(0, 5.0, '5.0'), Text(0, 5.5, '5.5'), Text(0, 6.0, '6.0'), Text(0, 6.5, '6.5'), Text(0, 7.0, '7.0'), Text(0, 7.5, '7.5'), Text(0, 8.0, '8.0'), Text(0, 8.5, '8.5')])\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Linearity",
    "text": "Linearity\n\nIf \\(f_1(x)\\) and \\(f_2(x)\\) have Fourier series,\nThen for any constants \\(a, b\\),\n\\(a f_1(x) + b f_2(x)\\) has a Fourier series,\nWith coefficients scaled accordingly."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#time-shifting",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#time-shifting",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time Shifting",
    "text": "Time Shifting\n\nIf \\(f(x)\\) has Fourier coefficients \\(a_n, b_n\\),\nThen \\(f(x - x_0)\\) has coefficients:\n\\(a_n \\cos(n\\omega x_0) + b_n \\sin(n\\omega x_0)\\),\nAnd \\(b_n \\cos(n\\omega x_0) - a_n \\sin(n\\omega x_0)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-scaling",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-scaling",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Frequency Scaling",
    "text": "Frequency Scaling\n\nIf \\(g(x) = f(cx)\\),\nThen the period scales by \\(c\\),\nThe fundamental frequency changes to \\(c\\omega\\),\nFourier coefficients adjust accordingly."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#differentiation-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#differentiation-property",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "** Differentiation Property**",
    "text": "** Differentiation Property**\n\nIf \\(f(x)\\) is differentiable,\nThen \\(f'(x)\\) has Fourier series,\nWith coefficients scaled as \\(n a_n, n b_n\\),\nHigher frequencies get amplified."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#integration-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#integration-property",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Integration Property",
    "text": "Integration Property\n\nIf \\(f(x)\\) has a Fourier series,\nThen \\(\\int f(x) dx\\) has a Fourier series,\nWith coefficients scaled as \\(\\frac{a_n}{n}, \\frac{b_n}{n}\\),\nLower frequencies get emphasized."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#parsevals-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#parsevals-theorem",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Parseval‚Äôs Theorem",
    "text": "Parseval‚Äôs Theorem\n\nThe total signal energy is conserved,\nEnergy in time domain equals energy in frequency domain,\nGiven by:\n\\(\\sum (a_n^2 + b_n^2) = \\frac{1}{T} \\int |f(x)|^2 dx\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-property",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Convolution Property",
    "text": "Convolution Property\n\nConvolution in time domain,\nIs multiplication in Fourier series coefficients,\nIf \\(f_1\\) and \\(f_2\\) are convoluted,\nTheir Fourier coefficients multiply component-wise."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#discrete-time-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#discrete-time-fourier-series",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Discrete Time Fourier Series",
    "text": "Discrete Time Fourier Series\n\nRepresents periodic discrete signals using harmonics.\nExtends Fourier series to discrete-time domain.\nFundamental in digital signal processing.\nBasis for the Discrete Fourier Transform (DFT)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-expression",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-expression",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Mathematical Expression",
    "text": "Mathematical Expression\n\nA periodic sequence \\(x[n]\\) can be expressed as:\n\\[x[n] = \\sum_{k=0}^{N-1} C_k e^{j(2\\pi k n / N)}\\].\nThe coefficients \\(C_k\\) are computed as:\n\\(C_k = \\frac{1}{N} \\sum_{n=0}^{N-1} x[n] e^{-j(2\\pi k n / N)}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#periodicity-and-symmetry",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#periodicity-and-symmetry",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Periodicity and Symmetry",
    "text": "Periodicity and Symmetry\n\nThe coefficients \\(C_k\\) repeat every \\(N\\).\nEnsures correct reconstruction of signals.\nExplains frequency domain representation.\nBasis for spectral analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#key-properties",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#key-properties",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Key Properties",
    "text": "Key Properties\n\nLinearity: Superposition holds.\nTime Shift: Causes phase shift in coefficients.\nParseval‚Äôs Theorem: Energy conservation.\nConvolution: Time convolution ‚Üí Frequency multiplication."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-domain-interpretation",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-domain-interpretation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Frequency Domain Interpretation",
    "text": "Frequency Domain Interpretation\n\n\\(C_k\\) represents discrete frequency content.\nThe spectrum consists of \\(N\\) harmonics.\nResolution improves with larger \\(N\\).\nEssential for analyzing periodic discrete signals."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#comparison-with-continuous-case",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#comparison-with-continuous-case",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Comparison with Continuous Case",
    "text": "Comparison with Continuous Case\n\nDTFS applies to discrete periodic signals.\nContinuous Fourier series applies to continuous functions.\nBoth represent signals as sums of sinusoids.\nDTFS is used in digital communications and audio processing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-th-dtfs",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-th-dtfs",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example of th DTFS",
    "text": "Example of th DTFS\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\n\n\n\nDTFS Coefficients:\n\n\nC[0] = 2.0000+0.0000j\nC[1] = -0.6036-0.6036j\nC[2] = 0.0000+0.0000j\nC[3] = 0.1036-0.1036j\nC[4] = 0.0000+0.0000j\nC[5] = 0.1036+0.1036j\nC[6] = 0.0000+0.0000j\nC[7] = -0.6036+0.6036j"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-02",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-02",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example 02",
    "text": "Example 02\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#conceptual-foundation",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#conceptual-foundation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Conceptual Foundation",
    "text": "Conceptual Foundation\n\nFourier Series represents periodic signals in terms of sinusoids.\nAs period \\(T \\to \\infty\\), the signal becomes aperiodic.\nThe Fourier Transform generalizes Fourier Series to aperiodic signals.\nTransforms signals from time to frequency domain."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-transition",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-transition",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Mathematical Transition",
    "text": "Mathematical Transition\n\nFourier Series of a periodic signal:\n\\[f(x) = \\sum_{n=-\\infty}^{\\infty} C_n e^{j(2\\pi n x / T)}\\].\nAs \\(T \\to \\infty\\), frequency spacing \\(\\frac{1}{T}\\) ‚Üí differential.\nLeads to the Fourier Transform:\n\\[F(\\omega) = \\int_{-\\infty}^{\\infty} f(x) e^{-j\\omega x} dx\\]."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-spectrum-interpretation",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-spectrum-interpretation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Frequency Spectrum Interpretation",
    "text": "Frequency Spectrum Interpretation\n\nFourier Series: discrete frequency spectrum.\nFourier Transform: continuous frequency spectrum.\nCoefficients \\(C_n\\) become the function \\(F(\\omega)\\).\nAllows analysis of arbitrary signals in frequency domain."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#inverse-fourier-transform",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#inverse-fourier-transform",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Inverse Fourier Transform",
    "text": "Inverse Fourier Transform\n\nRecovers time-domain signal from \\(F(\\omega)\\).\nDefined as:\n\\[f(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} F(\\omega) e^{j\\omega x} d\\omega\\].\nEnsures complete information preservation.\nBasis for signal reconstruction in DSP."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#energy-and-parsevals-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#energy-and-parsevals-theorem",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Energy and Parseval‚Äôs Theorem",
    "text": "Energy and Parseval‚Äôs Theorem\n\nEnergy conservation in time and frequency domains.\nParseval‚Äôs theorem states:\n\\[\\int |f(x)|^2 dx = \\frac{1}{2\\pi} \\int |F(\\omega)|^2 d\\omega\\]\nEnsures no energy loss between domains."
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-step",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-step",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Unit Step",
    "text": "Unit Step\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[u(t) =\n\\begin{cases}\n0, & t &lt; 0 \\\\\n1, & t \\geq 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[u[n] =\n\\begin{cases}\n0, & n &lt; 0 \\\\\n1, & n \\geq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-ramp",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-ramp",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Unit Ramp",
    "text": "Unit Ramp\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[u(t) =\n\\begin{cases}\n0, & t &lt; 0 \\\\\nt, & t \\geq 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[u[n] =\n\\begin{cases}\n0, & n &lt; 0 \\\\\nn, & n \\geq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#sync-function",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#sync-function",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Sync Function",
    "text": "Sync Function\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[\\text{sinc}(t) =\n\\begin{cases}\n\\frac{\\sin(\\pi t)}{\\pi t}, & t \\neq 0 \\\\\n1, & t = 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\text{sinc}[n] =\n\\begin{cases}\n\\frac{\\sin(\\pi n)}{\\pi n}, & n \\neq 0 \\\\\n1, & n = 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#diracs-delta",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#diracs-delta",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Dirac‚Äôs Delta",
    "text": "Dirac‚Äôs Delta\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[\\delta(t) =\n\\begin{cases}\n+\\infty, & t = 0 \\\\\n0, & t \\neq 0\n\\end{cases}\\]\n\\(\\int_{-\\infty}^{\\infty} \\delta(t) dt = 1\\)\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\delta[n] =\n\\begin{cases}\n1, & n = 0 \\\\\n0, & n \\neq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-time",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-time",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Basic Transformations on Singular signals ‚Äì Translation in time",
    "text": "Basic Transformations on Singular signals ‚Äì Translation in time"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-amplitude",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-amplitude",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Basic Transformations on Singular signals ‚Äì Translation in amplitude",
    "text": "Basic Transformations on Singular signals ‚Äì Translation in amplitude"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-time",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-time",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Basic Transformations on Singular signals ‚Äì scailing in time",
    "text": "Basic Transformations on Singular signals ‚Äì scailing in time"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-amplitude",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-amplitude",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Basic Transformations on Singular signals ‚Äì scailing in amplitude",
    "text": "Basic Transformations on Singular signals ‚Äì scailing in amplitude"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#example",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#example",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example",
    "text": "Example\n\nQuestionSolutionCode for the graph 1/2Code for the graph 2/2\n\n\nHow can i create the following signal using only singular signals\n\n\n\n\n\n\n\n\n\n\n\n\\[x(t) = 5u(t) - 5(t-3)\\]\n\n\n\nt = np.linspace(-10,10,1000)\nx = np.zeros(t.shape)\n\nx[t&gt;=0]=5\nx[t&gt;=3]=0\n\nplt.figure(figsize=(16,6.75))\nplt.plot(t,x)\nplt.grid()\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Amplitude\")\n\n\n\n\nt = np.linspace(-10,10,1000)\nx = np.zeros(t.shape)\n\nx=5*np.heaviside(t,1)-5*np.heaviside(t-3,1)\n\nplt.figure(figsize=(16,6.75))\nplt.plot(t,x)\nplt.grid()\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Amplitude\")"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#exercisae-singular-signals",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#exercisae-singular-signals",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Exercisae Singular Signals",
    "text": "Exercisae Singular Signals\n\nQuestion\n\n\nHow can i create the following signal using only singular signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\n\nBio - That came from a biological being\nSignal - A signal is a function that conveys information about a physical phenomenon.\nBiosignals - The search for information from living systems to know its health state"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-1",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\nThe codification of biosignals into variations: * Electrical * Mechanical * Chemical * Thermal"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-2",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-2",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-3",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-3",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1791: Luigi Galvani discovers electrical signals in living tissues (frog legs)\n1830s: Carlo Matteucci studies electrical signals in the heart\n1887: Willem Einthoven invents the first electrocardiograph (ECG)\n1900s: James Mackenzie develops the first clinical ECG machine"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-1",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1920s: Electroencephalography (EEG) is developed by Hans Berger\n1930s: Electromyography (EMG) is developed by John Humphrey and others\n1940s: Development of the first commercial ECG machines\n1950s: Signal processing techniques are applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-2",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-2",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1960s: Digital signal processing and computer analysis of biomedical signals emerge\n1970s: Biomedical signal processing becomes a recognized field\n1980s: Development of Holter monitoring (24-hour ECG)\n1990s: Advances in signal processing and machine learning applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-3",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-3",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n2000s: Development of wearable devices and mobile health (mHealth) technologies\n2010s: Emergence of big data analytics and cloud computing in biomedical signal processing\n2020s: Integration of artificial intelligence (AI) and machine learning (ML) in biomedical signal processing"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-4",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-4",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1895: Wilhelm Roentgen discovers X-rays, leading to medical imaging\n1900s: X-ray technology improves with development of modern X-ray tubes\n1913: Albert Salomon develops mammography\n1920s: Ultrasound technology is developed by Karl Dussik and others"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-5",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-5",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1930s: Nuclear medicine emerges with development of radioactive tracers\n1950s: Computed Tomography (CT) scans are developed by Godfrey Hounsfield and Allan McLeod Cormack\n1960s: Development of medical ultrasound imaging\n1970s: Magnetic Resonance Imaging (MRI) is developed by Richard Ernst and others"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-6",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-6",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1980s: Digital image processing and analysis techniques are applied to biomedical images\n1990s: Advances in MRI and CT scan technology, including 3D imaging\n2000s: Development of functional MRI (fMRI), diffusion tensor imaging (DTI), and other advanced MRI techniques\n2010s: Emergence of artificial intelligence (AI) and machine learning in medical imaging"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-7",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-7",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time line",
    "text": "Time line\nAdditional Milestones:\n\n1950s: Development of medical electronics and instrumentation\n1960s: First medical imaging computers are developed\n1970s: Development of digital image processing and analysis software\n1980s: Emergence of medical imaging informatics and PACS (Picture Archiving and Communication Systems)\n1990s: Development of telemedicine and teleradiology\n2000s: Emergence of electronic health records (EHRs) and health information exchanges (HIEs)\n2010s: Development of personalized medicine and precision health initiatives"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-the-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-the-z-transform",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Why the Z-Transform?",
    "text": "Why the Z-Transform?\n\nThe Fourier Transform assumes signals are stable and well-behaved\nBut some biosignals or systems may not be absolutely summable\nThe Z-Transform generalizes the Fourier Transform\nUseful for analyzing discrete-time systems, especially when stability and causality matter"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#definition",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#definition",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Definition",
    "text": "Definition\nLet \\(x[n]\\) be a discrete-time signal.\nThe Z-Transform is defined as:\n\\[X(z) = \\sum_{n=-\\infty}^{\\infty} x[n] z^{-n}\\]\nWhere: - \\(z \\in \\mathbb{C}\\) is a complex variable - \\(z = re^{j\\omega}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#region-of-convergence-roc",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#region-of-convergence-roc",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Region of Convergence (ROC)",
    "text": "Region of Convergence (ROC)\n\nThe Z-Transform converges only for certain values of \\(z\\)\nThe set of \\(z\\) for which the series converges is the ROC\nROC is critical for system stability and causality\n\n\n\nCausal Signals\nROC is outside outermost pole\nAnti-Causal Signals\nROC is inside innermost pole"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-plane-representation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-plane-representation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Z-Plane Representation",
    "text": "Z-Plane Representation\n\nPoles: values of \\(z\\) where \\(X(z) \\to \\infty\\)\nZeros: values where \\(X(z) = 0\\)\nVisualization of poles and zeros helps in understanding system behavior\n\n\nTransfer functionZPK (Zero-Pole-Kernel) Representation\n\n\n\\[H(z) = 1.00 \\cdot \\frac{(z - 0.50)}{(z - 0.90)}\\]\n\n\n\n\n(-1.5, 1.5)\n\n\n(-1.5, 1.5)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relationship-with-fourier-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relationship-with-fourier-transform",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Relationship with Fourier Transform",
    "text": "Relationship with Fourier Transform\nIf the ROC includes the unit circle, \\(|z| = 1\\), then:\n\\[X(e^{j\\omega}) = \\sum_{n=-\\infty}^{\\infty} x[n] e^{-j\\omega n}\\]\nSo the Fourier Transform is a special case of the Z-Transform."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-signal",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-signal",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example Signal",
    "text": "Example Signal\nLet:\n\\[x[n] = a^n u[n]\\]\nWhere: - \\(a \\in \\mathbb{R}\\) - \\(u[n]\\) is the unit step function (0 for \\(n&lt;0\\), 1 for \\(n\\geq 0\\))"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-z-transform",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 1: Z-Transform",
    "text": "Step 1: Z-Transform\nApply the definition:\n\\[X(z) = \\sum_{n=0}^{\\infty} a^n z^{-n}\n= \\sum_{n=0}^{\\infty} (az^{-1})^n\\]\nThis is a geometric series:\n\\[X(z) = \\frac{1}{1 - az^{-1}} = \\frac{z}{z - a}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#what-is-a-geometric-series",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#what-is-a-geometric-series",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "What is a Geometric Series?",
    "text": "What is a Geometric Series?\nA geometric series is a sum of terms where each term is multiplied by the same constant:\n\\[S = \\sum_{n=0}^{\\infty} r^n = 1 + r + r^2 + r^3 + \\cdots\\]\nThe value of \\(r\\) determines whether this sum converges (has a finite limit) or diverges."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#goal",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#goal",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Goal",
    "text": "Goal\nUnderstand why this series:\n\\[\\sum_{n=0}^{\\infty} r^n\\]\nconverges if and only if:\n\\[\\boxed{|r| &lt; 1}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#partial-sums",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#partial-sums",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Partial Sums",
    "text": "Partial Sums\nLet‚Äôs consider the sum up to the \\(N\\)-th term:\n\\[S_N = \\sum_{n=0}^{N} r^n = 1 + r + r^2 + \\cdots + r^N\\]\nThis has a closed-form expression:\n\\[S_N = \\frac{1 - r^{N+1}}{1 - r} \\quad \\text{for } r \\neq 1\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#taking-the-limit",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#taking-the-limit",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Taking the Limit",
    "text": "Taking the Limit\nTo find the sum of the infinite series, take the limit as \\(N \\to \\infty\\):\n\\[S = \\lim_{N \\to \\infty} S_N = \\lim_{N \\to \\infty} \\frac{1 - r^{N+1}}{1 - r}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-1-r-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-1-r-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Case 1: \\(|r| < 1\\)",
    "text": "Case 1: \\(|r| &lt; 1\\)\nIf \\(|r| &lt; 1\\), then:\n\\[r^{N+1} \\to 0 \\quad \\text{as } N \\to \\infty\\]\nSo the sum becomes:\n\\[S = \\frac{1}{1 - r}\\]\n‚úÖ The geometric series converges."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-2-r-geq-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-2-r-geq-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Case 2: \\(|r| \\geq 1\\)",
    "text": "Case 2: \\(|r| \\geq 1\\)\n\nIf \\(r = 1\\), then \\(S_N = N + 1 \\to \\infty\\)\nIf \\(r = -1\\), the sum oscillates: \\(1 - 1 + 1 - 1 + \\cdots\\)\nIf \\(|r| &gt; 1\\), then \\(r^{N+1} \\to \\infty\\)\n\n‚ùå In all cases: the series diverges"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#intuition",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#intuition",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Intuition",
    "text": "Intuition\n\nWhen \\(|r| &lt; 1\\), each term \\(r^n\\) gets smaller and smaller\nTheir total sum settles to a finite number\nWhen \\(|r| \\geq 1\\), the terms don‚Äôt vanish ‚Äî the sum keeps growing or oscillating"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-r-0.5",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-r-0.5",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example: \\(r = 0.5\\)",
    "text": "Example: \\(r = 0.5\\)\n\\[S = 1 + 0.5 + 0.25 + 0.125 + \\cdots = \\frac{1}{1 - 0.5} = 2\\]\nEvery term adds less. The sum ‚Äúflattens out.‚Äù"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-this-matters",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-this-matters",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Why This Matters",
    "text": "Why This Matters\nThe Z-Transform often gives us geometric series like:\n\\[\\sum_{n=0}^{\\infty} (az^{-1})^n\\]\nThis converges only if:\n\\[|az^{-1}| &lt; 1 \\Rightarrow |z| &gt; |a|\\]\nSo, understanding convergence of geometric series = understanding ROC in Z-transforms."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Summary",
    "text": "Summary\n\n\n\nCondition\nBehavior\nResult\n\n\n\n\n\\(|r| &lt; 1\\)\nTerms shrink\nSeries converges\n\n\n\\(|r| \\geq 1\\)\nTerms grow or oscillate\nDiverges\n\n\n\n\\[\\sum_{n=0}^{\\infty} r^n = \\frac{1}{1 - r} \\quad \\text{if } |r| &lt; 1\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-region-of-convergence-roc",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-region-of-convergence-roc",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 2: Region of Convergence (ROC)",
    "text": "Step 2: Region of Convergence (ROC)\nFor convergence of the geometric series:\n\\[|az^{-1}| &lt; 1 \\Rightarrow |z| &gt; |a|\\]\nTherefore, the ROC is:\n\\[\\boxed{|z| &gt; |a|}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#interpretation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#interpretation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Interpretation",
    "text": "Interpretation\n\nCausal signal (defined for \\(n \\geq 0\\))\nROC is outside the outermost pole\nStable system only if ROC includes the unit circle \\(|z| = 1\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-a-0.5",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-a-0.5",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example: \\(a = 0.5\\)",
    "text": "Example: \\(a = 0.5\\)\n\\[x[n] = (0.5)^n u[n]\\]\nZ-Transform:\n\\[X(z) = \\sum_{n=0}^{\\infty} (0.5)^n z^{-n} = \\frac{z}{z - 0.5}\\]\nRegion of Convergence:\n\\[\\boxed{|z| &gt; 0.5}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\nSignal\nZ-Transform\nROC\n\n\n\n\n\\(x[n] = a^n u[n]\\)\n\\(\\frac{z}{z - a}\\)\n\\(|z| &gt; |a|\\)\n\n\nExample: \\(a = 0.5\\)\n\\(\\frac{z}{z - 0.5}\\)\n\\(|z| &gt; 0.5\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#properties-of-the-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#properties-of-the-z-transform",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Properties of the Z-Transform",
    "text": "Properties of the Z-Transform\n\nLinearity: \\(a x[n] + b y[n] \\to aX(z) + bY(z)\\)\nTime shifting: \\(x[n - k] \\to z^{-k} X(z)\\)\nScaling in the z-domain: \\(a^n x[n] \\to X(z/a)\\)\nConvolution: \\(x[n] * h[n] \\to X(z)H(z)\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example",
    "text": "Example\nLet \\(x[n] = a^n u[n]\\), where \\(|a| &lt; 1\\)\n\\[X(z) = \\sum_{n=0}^{\\infty} a^n z^{-n} = \\frac{1}{1 - az^{-1}}, \\quad \\text{ROC: } |z| &gt; |a|\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#difference-equations-in-dsp",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#difference-equations-in-dsp",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Difference Equations in DSP",
    "text": "Difference Equations in DSP\nA difference equation relates input and output values at different time steps.\n\\[y[n] - a_1 y[n-1] - a_2 y[n-2] = b_0 x[n] + b_1 x[n-1]\\]\nCommon in: - Digital filters (FIR, IIR) - Signal models in ECG, EEG analysis - Implementation in real-time biosignal systems"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-transform-of-time-shifted-terms",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-transform-of-time-shifted-terms",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Z-Transform of Time-Shifted Terms",
    "text": "Z-Transform of Time-Shifted Terms\nThe Z-Transform turns time shifts into powers of \\(z^{-1}\\):\n\n\n\nTime Domain\nZ-Domain\n\n\n\n\n\\(x[n]\\)\n\\(X(z)\\)\n\n\n\\(x[n-k]\\)\n\\(z^{-k} X(z)\\)\n\n\n\\(y[n-k]\\)\n\\(z^{-k} Y(z)\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-apply-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-apply-z-transform",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 1: Apply Z-Transform",
    "text": "Step 1: Apply Z-Transform\nGiven:\n\\[y[n] - a_1 y[n-1] - a_2 y[n-2] = b_0 x[n] + b_1 x[n-1]\\]\nApply \\(\\mathcal{Z} \\{ \\cdot \\}\\):\n\\[Y(z) - a_1 z^{-1} Y(z) - a_2 z^{-2} Y(z) = b_0 X(z) + b_1 z^{-1} X(z)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-factor-and-solve-for-hz",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-factor-and-solve-for-hz",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 2: Factor and Solve for \\(H(z)\\)",
    "text": "Step 2: Factor and Solve for \\(H(z)\\)\nGroup:\n\\[Y(z)(1 - a_1 z^{-1} - a_2 z^{-2}) = X(z)(b_0 + b_1 z^{-1})\\]\nDivide both sides:\n\\[H(z) = \\frac{Y(z)}{X(z)} = \\frac{b_0 + b_1 z^{-1}}{1 - a_1 z^{-1} - a_2 z^{-2}}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example",
    "text": "Example\nGiven:\n\\[y[n] - 0.9 y[n-1] = x[n] - 0.5 x[n-1]\\]\nZ-Transform:\n\\[Y(z)(1 - 0.9 z^{-1}) = X(z)(1 - 0.5 z^{-1})\\]\nTransfer Function:\n\\[H(z) = \\frac{1 - 0.5 z^{-1}}{1 - 0.9 z^{-1}}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#poles-and-zeros",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#poles-and-zeros",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Poles and Zeros",
    "text": "Poles and Zeros\nLet‚Äôs analyze \\(H(z)\\):\n\nZeros: Roots of the numerator \\(\\Rightarrow z = 0.5\\)\nPoles: Roots of the denominator \\(\\Rightarrow z = 0.9\\)\n\n\n\nPole-Zero Plot\nVisualizes system behavior\nCheck for: - Stability (poles inside unit circle) - Frequency shaping"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#practice",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#practice",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Practice",
    "text": "Practice\nConvert this equation:\n\\[y[n] = 0.6 y[n-1] + x[n] + x[n-1]\\]\nFind: - \\(H(z)\\) - Poles and zeros - Plot them in the Z-plane"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#application-in-biosignal-processing",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#application-in-biosignal-processing",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Application in Biosignal Processing",
    "text": "Application in Biosignal Processing\n\nAnalysis of digital filters for ECG, EEG, etc.\nDesign of stable and causal filtering systems\nUseful in difference equation modeling of biosignals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-2",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-2",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Summary",
    "text": "Summary\n\nZ-Transform is a powerful tool for analyzing discrete systems\nProvides insight into stability, causality, and system behavior\nA generalization of the Fourier Transform\nCrucial in digital signal processing of biosignals\nZ-Transform converts difference equations into algebraic expressions\nTransfer function \\(H(z)\\) tells us how the system responds to inputs\nKey for digital filter design in biosignal processing"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#next-steps",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#next-steps",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Next Steps",
    "text": "Next Steps\n\nPractice Z-Transform computations\nPole-zero plotting exercises\nApplication to real biosignal filtering problems"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n\n\n\n\n\n\nNotch Filter\n\n\nA common issue in biosignal processing is removing power‚Äêline interference (50/60 Hz) from, for example, EEG or ECG signals. A simple digital filter to eliminate 60 Hz interference (assuming a sampling frequency \\(f_s = 5000\\) Hz) is to place complex‚Äêconjugate zeros at\n\\[\nz = e^{\\pm j 2\\pi\\frac{60}{5000}}.\n\\]\nThe resulting transfer function can be written as\n\\[\nH(z) = 1 \\;-\\; 2\\cos\\!\\Bigl(2\\pi\\frac{60}{5000}\\Bigr)\\,z^{-1} \\;+\\; z^{-2}.\n\\]\nThis \\(H(z)\\) has zeros at \\(e^{\\pm j2\\pi(60/5000)}\\) that precisely cancel the 60 Hz component, thereby implementing a notch filter. Moreover, it is a second‚Äêorder FIR filter with symmetric coefficients, which grants it linear phase (important to avoid waveform distortion)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\ndef design_filter(zeros=None, poles=None, gain=1.0):\n    \"\"\"\n    Dise√±a un filtro digital a partir de ceros y/o polos y una ganancia.\n\n    Par√°metros:\n    - zeros: lista de ceros (ra√≠ces del numerador), o None para no incluir\n    - poles: lista de polos (ra√≠ces del denominador), o None para no incluir\n    - gain: ganancia escalar del filtro\n\n    Devuelve:\n    - b: coeficientes del numerador\n    - a: coeficientes del denominador\n    \"\"\"\n    # Si no se pasan ceros, asumimos un FIR trivial (b = [gain])\n    if zeros:\n        b = gain * np.poly(zeros)\n    else:\n        b = np.array([gain], dtype=float)\n\n    # Si no se pasan polos, asumimos sistema FIR (a = [1])\n    if poles:\n        a = np.poly(poles)\n    else:\n        a = np.array([1.0], dtype=float)\n\n    return b, a"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-2",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-2",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\ndef gaussian(x, mu, sigma, A):\n    \"\"\"\n    Genera una funci√≥n gaussiana.\n\n    Par√°metros:\n    - x: array de tiempos\n    - mu: posici√≥n central de la gaussiana\n    - sigma: desviaci√≥n est√°ndar\n    - A: amplitud\n    \"\"\"\n    return A * np.exp(-((x - mu) ** 2) / (2 * sigma**2))"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-3",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-3",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\ndef simulate_ecg(duration=10.0, fs=500, heart_rate=60):\n    \"\"\"\n    Simula un ECG sint√©tico basado en la superposici√≥n de ondas gaussianas.\n\n    Par√°metros:\n    - duration: duraci√≥n de la se√±al en segundos\n    - fs: frecuencia de muestreo en Hz\n    - heart_rate: frecuencia cardiaca en latidos por minuto\n\n    Devuelve:\n    - t: vector de tiempos\n    - ecg: se√±al simulada de ECG en mV\n    \"\"\"\n    dt = 1 / fs\n    t = np.arange(0, duration, dt)\n    rr = 60 / heart_rate  # intervalo RR en segundos\n\n    # Inicializar se√±al\n    ecg = np.zeros_like(t)\n\n    # Par√°metros de las ondas (posiciones relativas en segundos)\n    # P wave\n    p_amp, p_dur, p_delay = 0.25, 0.09, 0.16\n    # Q wave\n    q_amp, q_dur, q_delay = -0.05, 0.066, 0.166\n    # R wave\n    r_amp, r_dur, r_delay = 1.6, 0.1, 0.166\n    # S wave\n    s_amp, s_dur, s_delay = -0.25, 0.066, 0.19\n    # T wave\n    t_amp, t_dur, t_delay = 0.35, 0.142, 0.36\n\n    # Generar cada latido\n    for beat_start in np.arange(0, duration, rr):\n        mask = (t &gt;= beat_start) & (t &lt; beat_start + rr)\n        tb = t[mask] - beat_start\n        ecg[mask] += gaussian(tb, p_delay, p_dur / 2, p_amp)\n        ecg[mask] += gaussian(tb, q_delay, q_dur / 2, q_amp)\n        ecg[mask] += gaussian(tb, r_delay, r_dur / 2, r_amp)\n        ecg[mask] += gaussian(tb, s_delay, s_dur / 2, s_amp)\n        ecg[mask] += gaussian(tb, t_delay, t_dur / 2, t_amp)\n\n    return t, ecg+0.1*np.cos(2*np.pi*60*t)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-4",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-4",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n# Par√°metros de simulaci√≥n\nDURATION = 10    # segundos\nFS = 500         # Hz\nHR = 70          # latidos por minuto\n\n# Generar se√±al\nt, ecg_signal = simulate_ecg(duration=DURATION, fs=FS, heart_rate=HR)\n\n# Graficar resultado\nplt.figure(figsize=(12, 4))\nplt.plot(t, ecg_signal, linewidth=1)\nplt.title(f'Se√±al de ECG sint√©tica ({HR} bpm)')\nplt.xlabel('Tiempo (s)')\nplt.ylabel('Amplitud (mV)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-5",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-5",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\nn = len(ecg_signal)\nyf = np.fft.fft(ecg_signal)\nxf = np.fft.fftfreq(n, 1/fs)[:n//2]\nplt.plot(xf, 2.0/n * np.abs(yf[0:n//2]))\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-6",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-6",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\nfc = 60\nb,a =design_filter(zeros=[np.exp(1j*2*np.pi*fc/fs), np.exp(-1j*2*np.pi*fc/fs)])\nprint(a)\nprint(b)\n\nw, h = sig.freqz(a, b, worN=8000)\nplt.plot(w/np.pi*fs/2, 20*np.log10(abs(h)))\nplt.grid()\nplt.xlabel('Frequency (Hz)')"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-7",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-7",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n\n\n\n\n\n\nFIR filters\n\n\nFIR filters (Finite Impulse Response) are widely used in biomedical processing because they can be designed to have linear phase response, avoiding phase distortion in the filtered signal (which is useful for preserving the morphology of ECG waves, for example)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-8",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-8",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n\n\n\n\n\n\nFilter Design Process\n\n\n\nDefining the desired ideal frequency response \\(H_d(e^{j\\omega})\\).\nObtaining the ideal impulse response \\(h_d[n]\\) as the inverse Fourier transform of \\(H_d\\).\nTruncating \\(h_d[n]\\) (which is usually infinite or very long) with a window function \\(w[n]\\) to obtain a realizable FIR filter\n\\[\nh[n] = h_d[n]\\,w[n].\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-9",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-9",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\nYou obtain \\(h_d[n]\\) as the inverse discrete‚Äìtime Fourier transform of your ideal frequency response \\(H_d(e^{j\\omega})\\). For a low-pass filter with cutoff \\(\\omega_c\\),\n\\[\nH_d(e^{j\\omega}) =\n\\begin{cases}\n1, & |\\omega|\\le\\omega_c,\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\]\nBy definition of the inverse DTFT,\n\\[\nh_d[n] \\;=\\; \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} H_d(e^{j\\omega})\\,e^{j\\omega n}\\,d\\omega\n\\;=\\;\\frac{1}{2\\pi}\\int_{-\\omega_c}^{\\omega_c} e^{j\\omega n}\\,d\\omega.\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-10",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-10",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\nCarry out the integral in two cases:\n\nFor \\(n\\neq 0\\):\n\\[\nh_d[n]\n=\\frac{1}{2\\pi}\\,\\frac{e^{j\\omega n}}{j\\,n}\\Biggr|_{-\\omega_c}^{\\omega_c}\n=\\frac{1}{2\\pi}\\,\\frac{e^{j\\omega_c n}-e^{-j\\omega_c n}}{j\\,n}\n=\\frac{\\sin(\\omega_c\\,n)}{\\pi\\,n}.\n\\]\nFor \\(n=0\\):\n\\[\nh_d[0]\n=\\frac{1}{2\\pi}\\int_{-\\omega_c}^{\\omega_c} 1\\,d\\omega\n=\\frac{2\\,\\omega_c}{2\\pi}\n=\\frac{\\omega_c}{\\pi}.\n\\]\n\nPutting both together,\n\\[\nh_d[n]\n=\\begin{cases}\n\\dfrac{\\sin(\\omega_c\\,n)}{\\pi\\,n}, & n\\neq 0,\\\\[1em]\n\\dfrac{\\omega_c}{\\pi},                & n=0.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relating-to-sampling-frequency",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relating-to-sampling-frequency",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Relating to sampling frequency",
    "text": "Relating to sampling frequency\nIf your cutoff is specified in Hz, \\(f_c\\), and sampling rate is \\(f_s\\), then\n\\[\n\\omega_c = 2\\pi\\,\\frac{f_c}{f_s},\n\\]\nso you can write\n\\[\nh_d[n]\n=\\frac{\\sin\\!\\bigl(2\\pi \\frac{f_c}{f_s}\\,n\\bigr)}{\\pi\\,n}\n=\\;2\\;\\frac{f_c}{f_s}\\;\\frac{\\sin\\!\\bigl(2\\pi \\frac{f_c}{f_s}\\,n\\bigr)}{2\\pi \\frac{f_c}{f_s}\\,n}\n=2\\frac{f_c}{f_s}\\,\\mathrm{sinc}\\!\\Bigl(2\\frac{f_c}{f_s}\\,n\\Bigr),\n\\]\nwhere we define the normalized sinc as \\(\\mathrm{sinc}(x)=\\frac{\\sin(\\pi x)}{\\pi x}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#key-takeaway",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#key-takeaway",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Key takeaway",
    "text": "Key takeaway\n\n\\(h_d[n]\\) is exactly the inverse‚ÄêDTFT of the ideal (‚Äúbrick‚Äêwall‚Äù) frequency specification.\nIt produces a sinc-shaped impulse response of infinite length.\nTruncation (with a window) makes it realizable as a finite-length FIR."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-11",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-11",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\nThe typical characteristics of classic windows are:\n\nRectangular: narrowest main lobe (width ‚âà 4œÄ/M rad) but highest sidelobes (first sidelobe ‚âà ‚Äì13 dB, stop-band attenuation ‚âà 21 dB). It gives the steepest transition for a given filter order, at the expense of poorer stop-band rejection.\nBartlett (triangular): somewhat wider main lobe (‚âà 8œÄ/M), sidelobes ‚âà ‚Äì25 dB.\nHann: main lobe ‚âà 8œÄ/M, sidelobes ‚âà ‚Äì31 dB (better rejection than rectangular but smoother transitions).\nHamming: main lobe ‚âà 8œÄ/M, sidelobes ‚âà ‚Äì41 dB (minimum stop-band attenuation ‚âà 53 dB). Very popular for its good compromise between transition width and stop-band attenuation.\nBlackman: wider main lobe (‚âà 12œÄ/M) but very low sidelobes (‚âà ‚Äì57 dB, attenuation ‚âà 74 dB).\nKaiser: allows selection of a parameter Œ≤ to control sidelobe attenuation, offering flexibility. Approximately, to achieve A dB of attenuation,\n\\[\n  \\beta \\approx 0.1102\\,(A - 8.7)\\quad(\\text{for }A&gt;50),\n\\]\nand the normalized transition width Œîœâ relates to the order M and Œ≤ by\n\\[\n  M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\n\\]\n\nThese formulas stem from Kaiser‚Äôs approximations and help in sizing the filter."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#windows-forms",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#windows-forms",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Windows Forms",
    "text": "Windows Forms\n\nTimeFrequencyCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(-100.0, 5.0)\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal.windows import (\n    boxcar,       # Rectangular\n    bartlett,    # Triangular\n    hann,        # Hann\n    hamming,     # Hamming\n    blackman,    # Blackman\n    kaiser       # Kaiser\n)\n\n# Parameters\nM = 64               # window length\nbeta = 8.6           # Kaiser parameter for moderate sidelobe attenuation\nnfft = 512           # FFT length for frequency response\nfs = 1.0             # normalized sampling rate\n\n# Generate windows\nwindows = {\n    'Rectangular': boxcar(M),\n    'Bartlett':    bartlett(M),\n    'Hann':        hann(M),\n    'Hamming':     hamming(M),\n    'Blackman':    blackman(M),\n    f'Kaiser (Œ≤={beta})': kaiser(M, beta)\n}\n\n# Time-domain plot\nplt.figure(figsize=(8, 4))\nfor name, w in windows.items():\n    plt.plot(np.arange(M), w, label=name)\nplt.title('Window Functions ‚Äî Time Domain')\nplt.xlabel('Sample index n')\nplt.ylabel('Amplitude')\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.tight_layout()\n\n# Frequency-domain plot\nplt.figure(figsize=(8, 4))\nfor name, w in windows.items():\n    # Compute normalized frequency response\n    W = np.fft.fft(w, nfft)\n    W_mag = 20 * np.log10(np.abs(W) / np.max(np.abs(W)))\n    freqs = np.fft.fftfreq(nfft, d=1/fs)\n    # Only plot 0 ‚â§ f ‚â§ 0.5 (normalized Nyquist)\n    idx = np.logical_and(freqs &gt;= 0, freqs &lt;= 0.5)\n    plt.plot(freqs[idx], W_mag[idx], label=name)\nplt.title('Window Functions ‚Äî Frequency Response')\nplt.xlabel('Normalized Frequency (cycles/sample)')\nplt.ylabel('Magnitude (dB)')\nplt.ylim(-100, 5)\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.tight_layout()\n\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-12",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-12",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Filter Design",
    "text": "Filter Design\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN = 101\nfc = 30\n\n# 2. Compute the ideal impulse response h_d[n] of a low-pass filter\nn = np.arange(N)\nM = (N - 1) / 2\n# Using the normalized sinc: sinc(x) = sin(pi*x)/(pi*x)\nh_d = (2 * fc / FS) * np.sinc(2 * fc * (n - M) / FS)\n\n# 3. Choose a window w[n] (here: Hamming) and truncate\nw = np.hamming(N)\nh = h_d * w\n\n# 4. Normalize to ensure unity gain at DC\nh /= np.sum(h)\n\n# 6. Filter it (only allowed library call)\ny = sig.lfilter(h, 1.0, ecg_signal)\n\n# 7. Plot input vs. output\nplt.figure(figsize=(8, 4))\nplt.plot(t, ecg_signal, label='Original signal')\nplt.plot(t, y, label='Filtered signal', linewidth=2)\nplt.xlabel('Time [s]')\nplt.ylabel('Amplitude')\nplt.title('Low-pass FIR (window method) ‚Äì Cutoff 100 Hz')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-iir-filter-design-strategy",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-iir-filter-design-strategy",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction: IIR Filter Design Strategy",
    "text": "Introduction: IIR Filter Design Strategy\n\nGoal: Design digital Infinite Impulse Response (IIR) filters.\nApproach: Leverage well-established theory and techniques from analog filter design.\nMethod:\n\nDesign a suitable analog filter prototype \\(H(s)\\).\nTransform this analog design into a digital filter \\(H(z)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---laplace-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---laplace-transform",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 0: The Analog Domain - Laplace Transform",
    "text": "Step 0: The Analog Domain - Laplace Transform\n\nContext: Continuous-time signals and Linear Time-Invariant (LTI) systems.\nTool: The Laplace Transform converts differential equations (time domain) to algebraic equations (s-domain).\nTransfer Function \\(H(s)\\): Represents the system in the s-domain. \\[H(s) = \\frac{Y(s)}{X(s)}\\] where \\(s = \\sigma + j\\Omega\\) is the complex frequency (\\(\\Omega\\) = analog angular frequency)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---s-plane-analysis",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---s-plane-analysis",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 0: The Analog Domain - s-Plane Analysis",
    "text": "Step 0: The Analog Domain - s-Plane Analysis\n\ns-Plane: Complex plane where \\(H(s)\\) is analyzed.\nPoles & Zeros: Roots of the denominator & numerator of \\(H(s)\\), respectively. Their locations determine filter behavior.\nFrequency Response: Determined by \\(H(j\\Omega)\\) (evaluating \\(H(s)\\) on the imaginary axis).\nStability: For a causal system to be stable, all poles must be in the Left-Half Plane (LHP), i.e., \\(\\text{Re}\\{s\\} &lt; 0\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---filter-prototypes",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---filter-prototypes",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 0: The Analog Domain - Filter Prototypes",
    "text": "Step 0: The Analog Domain - Filter Prototypes\n\nStandardized, well-understood analog filter approximations:\n\nButterworth: Maximally flat passband.\nChebyshev Type I: Equiripple passband, monotonic stopband.\nChebyshev Type II: Monotonic passband, equiripple stopband.\nElliptic (Cauer): Equiripple in both passband and stopband (sharpest transition for a given order).\n\nDesign usually starts with a normalized low-pass prototype."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#the-bridge-analog-to-digital-mapping",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#the-bridge-analog-to-digital-mapping",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "The Bridge: Analog-to-Digital Mapping",
    "text": "The Bridge: Analog-to-Digital Mapping\n\nCore Task: Convert the analog filter \\(H(s)\\) (s-plane) into a digital filter \\(H(z)\\) (z-plane).\nNeed a mapping that relates the continuous frequency \\(\\Omega\\) to the discrete frequency \\(\\omega\\).\nCrucially, the stable region (LHP in s-plane) should map to the stable region (inside the unit circle in z-plane)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 1: Digital Filter Specifications",
    "text": "Step 1: Digital Filter Specifications\n\nDefine the desired characteristics of the digital filter:\n\nCritical Frequencies:\n\nPassband edge: \\(\\omega_p\\)\nStopband edge: \\(\\omega_s\\)\n(Normalized digital angular frequencies, e.g., \\(0 \\le \\omega \\le \\pi\\))\n\nTolerances:\n\nMax. passband ripple/attenuation: \\(A_p\\) (dB) or \\(\\delta_p\\)\nMin. stopband attenuation: \\(A_s\\) (dB) or \\(\\delta_s\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-transformation-methods---overview",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-transformation-methods---overview",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 2: Transformation Methods - Overview",
    "text": "Step 2: Transformation Methods - Overview\n\nMathematical mappings from the s-plane to the z-plane.\nTwo primary methods:\n\nImpulse Invariance\nBilinear Transformation"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-1---impulse-invariance",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-1---impulse-invariance",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 2: Method 1 - Impulse Invariance",
    "text": "Step 2: Method 1 - Impulse Invariance\n\nConcept: Match the impulse response: \\(h_{digital}[n] \\approx T \\cdot h_{analog}(nT)\\).\nMapping: Maps s-plane pole \\(s_k\\) to z-plane pole \\(z_k = e^{s_k T}\\).\n\nUses partial fraction expansion of \\(H(s)\\).\n\nPros: Preserves impulse response shape.\nCons: Suffers from frequency aliasing if \\(H(j\\Omega)\\) is not bandlimited below Nyquist frequency (\\(F_s/2\\)). Best for low-pass/band-pass filters."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-2---bilinear-transformation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-2---bilinear-transformation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 2: Method 2 - Bilinear Transformation",
    "text": "Step 2: Method 2 - Bilinear Transformation\n\nConcept: An algebraic substitution mapping the \\(j\\Omega\\) axis onto the unit circle.\nMapping Formula: \\[s = \\frac{2}{T} \\frac{1 - z^{-1}}{1 + z^{-1}}\\] (T = sampling period, often set to 2 for simplicity during derivation).\nPros:\n\nNo aliasing: Maps entire \\(j\\Omega\\) axis to the unit circle (\\(-\\pi \\le \\omega \\le \\pi\\)).\nPreserves stability: Maps LHP (stable s-region) to inside the unit circle (stable z-region).\n\nCons: Introduces non-linear frequency warping."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#understanding-frequency-warping-bilinear",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#understanding-frequency-warping-bilinear",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Understanding Frequency Warping (Bilinear)",
    "text": "Understanding Frequency Warping (Bilinear)\n\nThe relationship between analog (\\(\\Omega\\)) and digital (\\(\\omega\\)) frequencies is non-linear: \\[\\Omega = \\frac{2}{T} \\tan\\left(\\frac{\\omega}{2}\\right)\\] or equivalently: \\[\\omega = 2 \\arctan\\left(\\frac{\\Omega T}{2}\\right)\\]\nThis compresses the infinite analog frequency axis onto the finite digital frequency range \\([-\\pi, \\pi]\\).\nThe mapping is non-uniform, most distorted near \\(\\omega = \\pm \\pi\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-3-frequency-pre-warping-bilinear-only",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-3-frequency-pre-warping-bilinear-only",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 3: Frequency Pre-warping (Bilinear Only)",
    "text": "Step 3: Frequency Pre-warping (Bilinear Only)\n\nProblem: Frequency warping distorts the locations of \\(\\omega_p\\) and \\(\\omega_s\\).\nSolution: Pre-warp the digital specifications (\\(\\omega_p, \\omega_s\\)) into corresponding analog frequencies (\\(\\Omega_p, \\Omega_s\\)) before designing the analog filter.\nFormula: Use the warping relationship: \\[\\Omega_p = \\frac{2}{T} \\tan\\left(\\frac{\\omega_p}{2}\\right)\\] \\[\\Omega_s = \\frac{2}{T} \\tan\\left(\\frac{\\omega_s}{2}\\right)\\]\nUse these \\(\\Omega_p, \\Omega_s\\) values for the analog design step."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-4-analog-prototype-design-workflow",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-4-analog-prototype-design-workflow",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 4: Analog Prototype Design Workflow",
    "text": "Step 4: Analog Prototype Design Workflow\n\nSelect Prototype: Choose Butterworth, Chebyshev, Elliptic based on specs (ripple, transition width) using the (pre-warped) \\(\\Omega_p, \\Omega_s, A_p, A_s\\).\nDetermine Order (N) & Cutoff (\\(\\Omega_c\\)): Calculate required analog filter order and cutoff frequency using prototype-specific formulas.\nFind Normalized LP \\(H_{LP}(s)\\): Obtain the transfer function for the normalized low-pass prototype.\nFrequency Transformation (Analog): If needed, transform \\(H_{LP}(s)\\) to target type (HP, BP, BS) using analog transformations.\n\nResult: The final analog filter transfer function \\(H_a(s)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#analog-filter-design-overview",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#analog-filter-design-overview",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Analog Filter Design: Overview",
    "text": "Analog Filter Design: Overview\nDesigning an analog filter translates desired signal filtering characteristics into a physical electronic circuit.\nKey Stages:\n\nDefine Specifications\nChoose an Approximation Method\nDetermine Filter Order\nFind Normalized Low-Pass Prototype (Conceptual)\nDenormalize & Transform (Conceptual)\nSynthesize the Circuit\nComponent Selection & Simulation\n\nWe‚Äôll illustrate steps 1, 3, and aspects of 4/5 using Python‚Äôs scipy.signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#define-filter-specifications",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#define-filter-specifications",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "1. Define Filter Specifications",
    "text": "1. Define Filter Specifications\nThis is the most crucial first step.\n\nType: Low-Pass (LPF), High-Pass (HPF), Band-Pass (BPF), Band-Stop (BSF).\nCritical Frequencies (Analog, \\(\\Omega\\) in rad/s or \\(f\\) in Hz):\n\nCutoff (\\(\\Omega_c, f_c\\))\nPassband Edge(s) (\\(\\Omega_p, f_p\\))\nStopband Edge(s) (\\(\\Omega_s, f_s\\))\n\nAttenuation Levels (dB):\n\nMax. Passband Attenuation/Ripple (\\(A_{max}\\) or gpass)\nMin. Stopband Attenuation (\\(A_{min}\\) or gstop)\n\nPhase Response: Linear phase (e.g., Bessel) or not critical.\nImpedance: Source/Load matching."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#specifications-python-example-low-pass",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#specifications-python-example-low-pass",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "1. Specifications: Python Example (Low-Pass)",
    "text": "1. Specifications: Python Example (Low-Pass)\nLet‚Äôs define specs for an analog low-pass filter. Frequencies for analog filters in scipy are typically in rad/s.\n\n\nPassband edge: 6283.19 rad/s (1000 Hz)\n\n\nStopband edge: 9424.78 rad/s (1500 Hz)\n\n\nMax Passband Loss: 1.0 dB\n\n\nMin Stopband Attenuation: 40.0 dB"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#choose-an-approximation-method-filter-family",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#choose-an-approximation-method-filter-family",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "2. Choose an Approximation Method (Filter Family)",
    "text": "2. Choose an Approximation Method (Filter Family)\nSelect based on trade-offs (roll-off, ripple, phase).\n\nButterworth: Maximally flat passband, smooth roll-off.\nChebyshev Type I: Steeper roll-off than Butterworth, passband ripple.\nChebyshev Type II: Steeper roll-off, stopband ripple, flat passband.\nElliptic (Cauer): Steepest roll-off, ripple in both bands.\nBessel-Thomson: Best phase linearity (constant group delay), slowest roll-off.\n\nFor our Python examples, we‚Äôll use Butterworth."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-filter-fundamentals",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-filter-fundamentals",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Butterworth Filter Fundamentals",
    "text": "Butterworth Filter Fundamentals\nThe Butterworth filter is maximally flat in the passband.\nThe normalized prototype has a cutoff frequency \\(\\omega_c = 1\\) rad/s.\nPoles are placed on the unit circle in the \\(s\\)-plane at angles: \\[s_k = e^{j\\pi\\frac{2k + n - 1}{2n}}, \\quad k = 1,2,\\ldots,n.\\]\nThe Butterworth polynomial of order \\(n\\) is: \\[B_n(s) = \\prod_{k=1}^{n} (s - s_k).\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-lp-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-lp-transfer-function",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Normalized Lowpass (LP) Transfer Function",
    "text": "Normalized Lowpass (LP) Transfer Function\nThe normalized \\(n\\)th-order lowpass prototype is: \\[H_{LP}(s) = \\frac{1}{B_n(s)} = \\frac{1}{\\prod_{k=1}^n (s - s_k)}.\\] This yields a cutoff at \\(|H_{LP}(j1)| = 1/\\sqrt{2}\\) (the ‚Äì3 dB point)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-highpass-hp-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-highpass-hp-transfer-function",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Normalized Highpass (HP) Transfer Function",
    "text": "Normalized Highpass (HP) Transfer Function\nApply the frequency transformation \\(s \\to 1/s\\) and multiply by \\(s^n\\): \\[H_{HP}(s) = H_{LP}(1/s)\\,s^n = \\frac{s^n}{B_n(1/s)} = \\frac{s^n}{\\prod_{k=1}^n (1/s - s_k)} = \\frac{\\prod_{k=1}^n(-s_k)\\;s^n}{\\prod_{k=1}^n(s - s_k^{-1})}.\\] This prototype has a normalized cutoff at \\(\\omega=1\\) rad/s in the highpass sense."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandpass-bp-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandpass-bp-transfer-function",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Normalized Bandpass (BP) Transfer Function",
    "text": "Normalized Bandpass (BP) Transfer Function\nUse the bandpass transformation: \\[s \\to \\frac{s^2 + \\Omega_0^2}{B\\,s},\\] where \\(\\Omega_0 = \\sqrt{\\omega_1\\omega_2}\\) and \\(B = \\omega_2 - \\omega_1\\).\nFor a normalized prototype, we set \\(\\Omega_0 = 1\\), \\(B = 1\\), giving: \\[H_{BP}(s) = H_{LP}\\left(\\frac{s^2 + 1}{s}\\right) = \\frac{(s)^n}{\\prod_{k=1}^n\\left(\\frac{s^2 + 1}{s} - s_k\\right)} = \\frac{s^n}{\\prod_{k=1}^n\\left(s^2 + 1 - s\\,s_k\\right)}.\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandstop-bs-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandstop-bs-transfer-function",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Normalized Bandstop (BS) Transfer Function",
    "text": "Normalized Bandstop (BS) Transfer Function\nUse the bandstop transformation: \\[s \\to \\frac{s}{\\frac{s^2 + 1}{s}} = \\frac{s^2}{s^2 + 1},\\] or equivalently \\(s \\to (B\\,s)/(s^2 + \\Omega_0^2)\\) with \\(B=1\\), \\(\\Omega_0=1\\). Then: \\[H_{BS}(s) = H_{LP}\\left(\\frac{s}{s^2 + 1}\\right) = \\frac{1}{B_n\\left(\\frac{s}{s^2+1}\\right)} = \\frac{1}{\\prod_{k=1}^n\\left(\\frac{s}{s^2+1} - s_k\\right)} = \\frac{(s^2+1)^n}{\\prod_{k=1}^n\\left(s - s_k(s^2+1)\\right)} = \\frac{(s^2+1)^n}{\\prod_{k=1}^n\\left(s - s_ks^2 - s_k\\right)}.\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "3. Determine the Filter Order (N)",
    "text": "3. Determine the Filter Order (N)\nEstimating the filter order (\\(N\\)) is a crucial first step in analog filter design after defining specifications. The order determines the filter‚Äôs complexity and steepness of its frequency response roll-off.\nThese equations are for Butterworth filters. The calculated \\(N\\) is a real number and must be rounded up to the next integer.\nCommon Variables: * \\(N\\): Filter order (integer, result of formula is rounded up). * \\(A_{min}\\): Minimum stopband attenuation (dB, positive value, e.g., 40 dB). * \\(A_{max}\\): Maximum passband attenuation/ripple (dB, positive value, e.g., 1 dB). * \\(\\log_{10}\\): Base-10 logarithm. * All \\(\\Omega\\) values are angular frequencies in rad/s."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-low-pass-lp-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-low-pass-lp-filter-order",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Butterworth Low-Pass (LP) Filter Order",
    "text": "Butterworth Low-Pass (LP) Filter Order\n\\[N \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\frac{\\Omega_s}{\\Omega_p}\\right)}\\]\nExplanation of LP-Specific Variables: * \\(\\Omega_p\\): Passband edge angular frequency. The frequency up to which signals pass with at most \\(A_{max}\\) attenuation. * \\(\\Omega_s\\): Stopband edge angular frequency. The frequency from which signals are attenuated by at least \\(A_{min}\\). * For a low-pass filter, \\(\\Omega_s &gt; \\Omega_p\\). The term \\(\\frac{\\Omega_s}{\\Omega_p}\\) is the transition ratio."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-high-pass-hp-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-high-pass-hp-filter-order",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Butterworth High-Pass (HP) Filter Order",
    "text": "Butterworth High-Pass (HP) Filter Order\n\\[N \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\frac{\\Omega_p}{\\Omega_s}\\right)}\\]\nExplanation of HP-Specific Variables: * \\(\\Omega_p\\): Passband edge angular frequency. The frequency from which signals pass with at most \\(A_{max}\\) attenuation. * \\(\\Omega_s\\): Stopband edge angular frequency. The frequency down to which signals are attenuated by at least \\(A_{min}\\). * For a high-pass filter, \\(\\Omega_p &gt; \\Omega_s\\). The term \\(\\frac{\\Omega_p}{\\Omega_s}\\) is the transition ratio (inverted compared to LP to keep it &gt;1 for the logarithm)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-pass-bp-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-pass-bp-filter-order",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Butterworth Band-Pass (BP) Filter Order",
    "text": "Butterworth Band-Pass (BP) Filter Order\nThe order \\(N_{BP}\\) is the same as an equivalent Low-Pass Prototype. \\[N_{BP} \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\Omega_{s,LP_equiv}\\right)}\\]\nExplanation of BP-Specific Variables: * \\(\\Omega_{p1}, \\Omega_{p2}\\): Passband edge angular frequencies (\\(\\Omega_{p1} &lt; \\Omega_{p2}\\)). * \\(\\Omega_{s1}, \\Omega_{s2}\\): Stopband edge angular frequencies (\\(\\Omega_{s1} &lt; \\Omega_{p1}\\) and \\(\\Omega_{s2} &gt; \\Omega_{p2}\\)). * \\(\\Omega_0 = \\sqrt{\\Omega_{p1}\\Omega_{p2}}\\): Geometric center frequency of the passband. * \\(B = \\Omega_{p2} - \\Omega_{p1}\\): Bandwidth of the passband. * \\(\\Omega_{s,LP_equiv} = \\min\\left( \\left| \\frac{\\Omega_{s1}^2 - \\Omega_0^2}{\\Omega_{s1} B} \\right|, \\left| \\frac{\\Omega_{s2}^2 - \\Omega_0^2}{\\Omega_{s2} B} \\right| \\right)\\) * This \\(\\Omega_{s,LP_equiv}\\) is the stopband edge of an equivalent low-pass prototype whose passband edge is normalized to 1 rad/s. It represents the more stringent of the two possible transitions from the passband edges to the stopband edges."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-stop-bs-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-stop-bs-filter-order",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Butterworth Band-Stop (BS) Filter Order",
    "text": "Butterworth Band-Stop (BS) Filter Order\nThe order \\(N_{BS}\\) is the same as an equivalent Low-Pass Prototype. \\[N_{BS} \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\Omega_{trans,LP_equiv}\\right)}\\]\nExplanation of BS-Specific Variables: * \\(\\Omega_{s1}, \\Omega_{s2}\\): Stopband edge angular frequencies defining the rejected band (\\(\\Omega_{s1} &lt; \\Omega_{s2}\\)). \\(A_{min}\\) is the attenuation in this band. * \\(\\Omega_{p1}, \\Omega_{p2}\\): Passband edge angular frequencies outside the stopband (\\(\\Omega_{p1} &lt; \\Omega_{s1}\\) and \\(\\Omega_{p2} &gt; \\Omega_{s2}\\)). \\(A_{max}\\) is the ripple in these passbands. * \\(\\Omega_0 = \\sqrt{\\Omega_{s1}\\Omega_{s2}}\\): Geometric center frequency of the stopband. * \\(B = \\Omega_{s2} - \\Omega_{s1}\\): Bandwidth of the stopband. * \\(\\Omega_{p,LP_i} = \\left| \\frac{\\Omega_{pi} B}{\\Omega_{pi}^2 - \\Omega_0^2} \\right|\\) for \\(i=1\\) (using \\(\\Omega_{p1}\\)) and \\(i=2\\) (using \\(\\Omega_{p2}\\)). * These are the passband edges of an equivalent low-pass prototype whose stopband edge is normalized to 1 rad/s. * \\(\\Omega_{trans,LP_equiv} = \\frac{1}{\\min(\\Omega_{p,LP1}, \\Omega_{p,LP2})}\\) * This is the effective transition ratio (stopband edge / passband edge) for the equivalent low-pass prototype."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "3. Determine the Filter Order (N) & Denormalization",
    "text": "3. Determine the Filter Order (N) & Denormalization\nCalculated based on specs and chosen filter type. scipy.signal.buttord (and similar for other types) can find this for analog filters.\n\n\n\nRequired Butterworth Filter Order (N): 14\n\n\nButterworth Natural Frequency (Wn_buttord): 6593.83 rad/s\n\n\n\nWn_buttord is the natural angular frequency (\\(\\Omega_n\\)) for the filter. For Butterworth, this is the -3dB cutoff frequency \\(\\Omega_c\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "3. Determine the Filter Order (N) & Denormalization",
    "text": "3. Determine the Filter Order (N) & Denormalization\nNormalized Lowpass to Denormalized Lowpass\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized LP with cutoff \\(\\Omega_c\\).\nTransformation: Replace \\(s_{norm}\\) with \\(s / \\Omega_c\\). \\[s_{norm} \\to \\frac{s}{\\Omega_c}\\]\nDenormalized Transfer Function: \\[H_{LP}(s) = H_{norm}\\left(\\frac{s}{\\Omega_c}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-highpass",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-highpass",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Normalized Lowpass to Denormalized Highpass",
    "text": "Normalized Lowpass to Denormalized Highpass\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized HP with cutoff \\(\\Omega_c\\).\nTransformation: Replace \\(s_{norm}\\) with \\(\\Omega_c / s\\). \\[s_{norm} \\to \\frac{\\Omega_c}{s}\\]\nDenormalized Transfer Function: \\[H_{HP}(s) = H_{norm}\\left(\\frac{\\Omega_c}{s}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandpass",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandpass",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Normalized Lowpass to Denormalized Bandpass",
    "text": "Normalized Lowpass to Denormalized Bandpass\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized BP with center frequency \\(\\Omega_0\\) and bandwidth \\(B\\).\nTransformation: Replace \\(s_{norm}\\) with \\(\\frac{s^2 + \\Omega_0^2}{B s}\\). \\[s_{norm} \\to \\frac{s^2 + \\Omega_0^2}{B s}\\]\nParameters:\n\n\\(\\Omega_0 = \\sqrt{\\Omega_1 \\Omega_2}\\) (geometric mean)\n\\(B = \\Omega_2 - \\Omega_1\\) (bandwidth) (\\(\\Omega_1, \\Omega_2\\) are the desired band edges in rad/s)\n\nDenormalized Transfer Function: \\[H_{BP}(s) = H_{norm}\\left(\\frac{s^2 + \\Omega_0^2}{B s}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandstop",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandstop",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Normalized Lowpass to Denormalized Bandstop",
    "text": "Normalized Lowpass to Denormalized Bandstop\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized BS with center frequency \\(\\Omega_0\\) and bandwidth \\(B\\).\nTransformation: Replace \\(s_{norm}\\) with \\(\\frac{B s}{s^2 + \\Omega_0^2}\\). \\[s_{norm} \\to \\frac{B s}{s^2 + \\Omega_0^2}\\]\nParameters:\n\n\\(\\Omega_0 = \\sqrt{\\Omega_1 \\Omega_2}\\)\n\\(B = \\Omega_2 - \\Omega_1\\)\n\nDenormalized Transfer Function: \\[H_{BS}(s) = H_{norm}\\left(\\frac{B s}{s^2 + \\Omega_0^2}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#obtain-analog-filter-transfer-function-h_as",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#obtain-analog-filter-transfer-function-h_as",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "4 & 5. Obtain Analog Filter Transfer Function \\(H_a(s)\\)",
    "text": "4 & 5. Obtain Analog Filter Transfer Function \\(H_a(s)\\)\nConceptually: Find normalized LP prototype \\(\\rightarrow\\) Denormalize \\(\\rightarrow\\) Transform.\nscipy.signal functions like butter, cheby1, etc., (with analog=True) perform these steps internally to give the final analog filter transfer function \\(H_a(s)\\).\n\\(H_a(s)\\) can be represented as: 1. Numerator (\\(b\\)) and Denominator (\\(a\\)) coefficients: \\(H_a(s) = \\frac{b_0 s^M + b_1 s^{M-1} + \\dots + b_M}{a_0 s^N + a_1 s^{N-1} + \\dots + a_N}\\) 2. Zeros (\\(z\\)), Poles (\\(p\\)), and Gain (\\(k\\)): \\(H_a(s) = k \\frac{\\prod (s-z_i)}{\\prod (s-p_j)}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#python-design-h_as-butterworth-lpf",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#python-design-h_as-butterworth-lpf",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "4 & 5. Python: Design \\(H_a(s)\\) (Butterworth LPF)",
    "text": "4 & 5. Python: Design \\(H_a(s)\\) (Butterworth LPF)\nUsing signal.butter with analog=True. The Wn parameter here should be the cutoff frequency \\(\\Omega_c\\). For buttord, the returned Wn_buttord is exactly this \\(\\Omega_c\\).\n\n\n\nAnalog Filter Coefficients (Numerator b, Denominator a):\n\n\nb_analog = [2.93718174e+53]\n\n\na_analog = [1.00000000e+00 5.88921844e+04 1.73414469e+09 3.37531810e+13\n 4.84169654e+17 5.40639098e+21 4.84125527e+25 3.52958830e+29\n 2.10491137e+33 1.02201934e+37 3.97946840e+40 1.20619642e+44\n 2.69441500e+47 3.97843852e+50 2.93718174e+53]\n\n\n\nAnalog Filter Zeros, Poles, Gain (ZPK):\n\n\nZeros (z_analog) = []\n\n\nPoles (p_analog) = [ -738.27500968+6552.37193897j -2177.8048373 +6223.80864963j\n -3508.13043664+5583.15760623j -4662.54372722+4662.54372722j\n -5583.15760623+3508.13043664j -6223.80864963+2177.8048373j\n -6552.37193897 +738.27500968j -6552.37193897 -738.27500968j\n -6223.80864963-2177.8048373j  -5583.15760623-3508.13043664j\n -4662.54372722-4662.54372722j -3508.13043664-5583.15760623j\n -2177.8048373 -6223.80864963j  -738.27500968-6552.37193897j]\n\n\nGain (k_analog) = 293718173729774468825490597908032846661500110135885824.00"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-analog-frequency-response-python",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-analog-frequency-response-python",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Visualizing Analog Frequency Response (Python)",
    "text": "Visualizing Analog Frequency Response (Python)\nUse scipy.signal.freqs to compute the frequency response of an analog filter given its \\(b,a\\) coefficients.\n\n\n(100.0, 7500)\n\n\n(-60.0, 5.0)\n\n\n(100.0, 7500)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#synthesize-the-circuit-realization",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#synthesize-the-circuit-realization",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "6. Synthesize the Circuit (Realization)",
    "text": "6. Synthesize the Circuit (Realization)\nConvert the mathematical \\(H_a(s)\\) into a physical electronic circuit. This step is not done by scipy.signal. It requires circuit design knowledge.\n\nPassive Filters:\n\nResistors (R), Inductors (L), Capacitors (C).\nCommonly ‚Äúladder‚Äù structures.\nInductors can be bulky/non-ideal, especially at low frequencies.\n\nActive Filters:\n\nOp-Amps, Resistors (R), Capacitors (C) (avoids inductors).\nCan provide gain, easy to cascade.\nRequires power. Limited by op-amp performance.\nCommon topologies: Sallen-Key, Multiple Feedback (MFB), State-Variable/Biquad.\nHigher-order filters are often cascaded 2nd-order sections."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#component-selection-and-simulation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#component-selection-and-simulation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "7. Component Selection and Simulation",
    "text": "7. Component Selection and Simulation\n\nComponent Values: Choose standard, available component values (R, C, L, Op-Amps) that are close to calculated ideals.\nTolerances: Account for component variations.\nNon-Idealities: Consider real-world behavior of components.\nCircuit Simulation (Essential):\n\nUse SPICE-based simulators (LTspice, QUCS, PSpice, etc.).\nVerify performance against specifications.\nIterate on design and component values as needed.\n\n\nThis is also outside the scope of scipy.signal but critical for hardware implementation."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#tools-for-analog-filter-design",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#tools-for-analog-filter-design",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Tools for Analog Filter Design",
    "text": "Tools for Analog Filter Design\n\nMathematical Software:\n\nPython with scipy.signal: Excellent for determining filter parameters (\\(N, \\Omega_c\\)) and transfer functions (\\(b,a\\) or \\(z,p,k\\)), and plotting responses.\nMATLAB (Signal Processing Toolbox), Octave.\n\nFilter Design Calculators/Software:\n\nTexas Instruments FilterPro‚Ñ¢, Analog Devices Filter Wizard¬Æ.\nOnline calculators and dedicated filter design suites.\n\nCircuit Simulators:\n\nLTspice, QUCS, PSpice, NI Multisim‚Ñ¢, Keysight ADS.\n\nFilter Design Handbooks:\n\nClassic texts (e.g., by Van Valkenburg, Zverev) provide theory, tables, and formulas."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#conclusion-for-analog-filter-design",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#conclusion-for-analog-filter-design",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Conclusion ‚Äì For Analog Filter Design",
    "text": "Conclusion ‚Äì For Analog Filter Design\nAnalog filter design is a multi-step process:\n\nSpecs \\(\\rightarrow\\) Theory \\(\\rightarrow\\) Math (\\(H_a(s)\\)) \\(\\rightarrow\\) Circuit \\(\\rightarrow\\) Verification.\nscipy.signal in Python is a powerful tool for the mathematical parts: determining order, calculating transfer function coefficients/poles/zeros, and analyzing frequency response for various analog filter prototypes.\nRealizing the physical circuit requires additional circuit design knowledge and simulation tools."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-apply-digital-transformation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-apply-digital-transformation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 5: Apply Digital Transformation",
    "text": "Step 5: Apply Digital Transformation\n\nConvert the designed analog filter \\(H_a(s)\\) to the digital domain \\(H(z)\\):\n\nIf Impulse Invariance: Use partial fractions and the \\(s_k \\rightarrow e^{s_k T}\\) mapping.\nIf Bilinear Transformation: Substitute \\(s = \\frac{2}{T} \\frac{1 - z^{-1}}{1 + z^{-1}}\\) into \\(H_a(s)\\) and simplify algebraically.\n\nResult: The digital filter transfer function: \\[H(z) = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{1 + \\sum_{k=1}^{N} a_k z^{-k}}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-implementation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-implementation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 6: Realization (Implementation)",
    "text": "Step 6: Realization (Implementation)\n\nThe transfer function \\(H(z)\\) corresponds directly to a difference equation: \\[y[n] = \\sum_{k=0}^{M} b_k x[n-k] - \\sum_{k=1}^{N} a_k y[n-k]\\]\n\\(x[n]\\): Input sequence\n\\(y[n]\\): Output sequence\n\\(b_k, a_k\\): Filter coefficients derived from \\(H(z)\\).\nThe feedback term (sum involving \\(y[n-k]\\)) makes the impulse response potentially infinite (IIR)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Summary: IIR Design Process",
    "text": "Summary: IIR Design Process\n\nDefine Digital Specs (\\(\\omega_p, \\omega_s, A_p, A_s\\)).\nSelect Transformation (e.g., Bilinear).\nPre-warp Frequencies (if Bilinear: \\(\\omega \\rightarrow \\Omega\\)).\nDesign Analog Filter \\(H_a(s)\\) (using prototypes & transformations).\nTransform to Digital \\(H(z)\\) (apply Bilinear or Impulse Invariance).\nRealize as Difference Equation for Implementation."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 1: Digital Filter Specifications",
    "text": "Step 1: Digital Filter Specifications\n\nDefine the desired characteristics of the digital filter:\n\nSampling Frequency: \\(F_s\\) (Hz)\nCritical Frequencies (Digital):\n\nPassband edge: \\(f_p\\) (Hz) \\(\\implies \\omega_p = 2\\pi f_p / F_s\\) (radians/sample)\nStopband edge: \\(f_s\\) (Hz) \\(\\implies \\omega_s = 2\\pi f_s / F_s\\) (radians/sample)\nNote: Scipy often uses frequencies normalized to Nyquist: \\(W_p = f_p / (F_s/2)\\), \\(W_s = f_s / (F_s/2)\\)\n\nTolerances:\n\nMax. passband ripple/attenuation: \\(A_p\\) or gpass (dB)\nMin. stopband attenuation: \\(A_s\\) or gstop (dB)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-example-specifications-python",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-example-specifications-python",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 1: Example Specifications (Python)",
    "text": "Step 1: Example Specifications (Python)\n\n\nSampling Frequency: 10000 Hz\n\n\nNormalized Passband Edge: 0.200 (pi rad/sample)\n\n\nNormalized Stopband Edge: 0.300 (pi rad/sample)\n\n\nMax Passband Loss: 1 dB\n\n\nMin Stopband Attenuation: 40 dB"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-designing-conceptual",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-designing-conceptual",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Steps 2-4: Finding Order & Designing (Conceptual)",
    "text": "Steps 2-4: Finding Order & Designing (Conceptual)\n\nTransformation: Bilinear Transform is implicitly used by many scipy.signal functions for IIR design.\nFrequency Pre-warping: Handled internally by Scipy when given digital frequency specs.\nAnalog Design: Scipy calculates the required analog prototype order and parameters based on the (internally pre-warped) specs.\nGoal: Find filter order \\(N\\) and digital cutoff frequency \\(W_n\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-wn-python---butterworth-example",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-wn-python---butterworth-example",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Steps 2-4: Finding Order & Wn (Python - Butterworth Example)",
    "text": "Steps 2-4: Finding Order & Wn (Python - Butterworth Example)\n\nUse scipy.signal.buttord to find the minimum order and cutoff frequency for a digital Butterworth filter meeting the specs.\n\n\n\n\nMinimum Filter Order (N): 12\n\n\nButterworth Natural Frequency (Wn): 0.211 (pi rad/sample)\n\n\n\nanalog=False specifies we want parameters for a digital filter.\nWn is the digital cutoff frequency (scalar for LP/HP, tuple for BP/BS) required by the butter function. It‚Äôs often close to wp."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-designing-the-digital-filter-python---butterworth",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-designing-the-digital-filter-python---butterworth",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 5: Designing the Digital Filter (Python - Butterworth)",
    "text": "Step 5: Designing the Digital Filter (Python - Butterworth)\n\nUse scipy.signal.butter (or cheby1, cheby2, ellip) to get the filter coefficients \\(b\\) (numerator) and \\(a\\) (denominator) of \\(H(z)\\).\n\n\n\n\nFilter Coefficients:\n\n\nNumerator (b): [0.0e+00 0.0e+00 1.0e-05 4.0e-05 1.0e-04 1.6e-04 1.9e-04 1.6e-04 1.0e-04\n 4.0e-05 1.0e-05 0.0e+00 0.0e+00]\n\n\nDenominator (a): [ 1.000000e+00 -6.930840e+00  2.271843e+01 -4.632962e+01  6.523097e+01\n -6.662310e+01  5.050575e+01 -2.858485e+01  1.197050e+01 -3.612930e+00\n  7.452400e-01 -9.424000e-02  5.520000e-03]\n\n\n\noutput='ba' gives numerator/denominator coefficients. Other options: 'sos' (second-order sections - numerically better), 'zpk' (zeros, poles, gain)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-frequency-response-python",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-frequency-response-python",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Visualizing Frequency Response (Python)",
    "text": "Visualizing Frequency Response (Python)\n\nCalculate the frequency response using scipy.signal.freqz.\nPlot magnitude (in dB) and phase.\n\n\n\n(0.0, 5000.0)\n\n\n(-60.0, 5.0)\n\n\n(0.0, 5000.0)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-filtering-python-example",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-filtering-python-example",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Step 6: Realization & Filtering (Python Example)",
    "text": "Step 6: Realization & Filtering (Python Example)\n\nThe coefficients b, a define the difference equation.\nUse scipy.signal.lfilter to apply the filter to a signal.\n\n\n\n(-1.5, 1.5)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process-with-scipy",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process-with-scipy",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Summary: IIR Design Process (with Scipy)",
    "text": "Summary: IIR Design Process (with Scipy)\n\nDefine Digital Specs (\\(f_p, f_s, gpass, gstop, F_s\\)). Normalize frequencies (\\(W_p, W_s\\)).\nSelect Filter Type (e.g., Butterworth) & find order/cutoff using buttord (digital).\nDesign Filter to get coefficients (\\(b, a\\)) using butter (digital).\nAnalyze Frequency Response using freqz.\nImplement/Apply Filter using lfilter (uses the difference equation implicitly).\n\n\nScipy handles the underlying analog prototype mapping, pre-warping, and bilinear transformation internally."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#qu√©-es-machine-learning-ml",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#qu√©-es-machine-learning-ml",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "¬øQu√© es Machine Learning (ML)?",
    "text": "¬øQu√© es Machine Learning (ML)?\n\nEl Machine Learning (Aprendizaje Autom√°tico) es un proceso automatizado que se encarga de extraer patrones a partir de los datos.\n\n\nEs un campo de conocimiento crucial y una tecnolog√≠a omnipresente.\n\n\nSu objetivo fundamental es ajustar modelos a los datos proporcionados para permitir la predicci√≥n y clasificaci√≥n."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-rol-de-la-predicci√≥n",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-rol-de-la-predicci√≥n",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "El Rol de la Predicci√≥n",
    "text": "El Rol de la Predicci√≥n\n\nEl ML busca aprender a predecir (estimar o aproximar) la etiqueta de un punto de datos bas√°ndose exclusivamente en sus caracter√≠sticas (features).\n\n\nImplementa el principio cient√≠fico de ‚Äúprueba y error‚Äù.\n\n\nEsto se logra refinando continuamente un modelo de forma iterativa, bas√°ndose en la p√©rdida incurrida por sus predicciones frente a los datos reales observados."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#componentes-esenciales",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#componentes-esenciales",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Componentes Esenciales",
    "text": "Componentes Esenciales\nLa teor√≠a del Machine Learning se presenta como la combinaci√≥n de tres componentes b√°sicos e interdependientes:\n\nDatos (Data): La materia prima a partir de la cual el sistema aprende.\nModelo (Model): La estructura matem√°tica que se ajusta a los datos (ej. red neuronal, √°rbol de decisi√≥n).\nFunci√≥n de P√©rdida (Loss Function): Mide la discrepancia entre las predicciones del modelo y los valores reales observados."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-machine-learning-ml-y-la-sanidad",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-machine-learning-ml-y-la-sanidad",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "El Machine Learning (ML) y la Sanidad",
    "text": "El Machine Learning (ML) y la Sanidad\nEl Machine Learning (ML) es un proceso automatizado que se dedica a extraer patrones complejos de los datos. En el sector salud, el objetivo es utilizar el ML para apoyar la toma de decisiones cl√≠nicas y operacionales.\nEl ML supervisado aprende un modelo a partir de un conjunto de caracter√≠sticas descriptivas y una caracter√≠stica objetivo, bas√°ndose en un conjunto de ejemplos hist√≥ricos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#tipos-de-modelos-de-ml",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#tipos-de-modelos-de-ml",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Tipos de Modelos de ML",
    "text": "Tipos de Modelos de ML\n\nModelos Predictivos: Permiten asignar un valor a cualquier variable desconocida, incluso si no tiene un aspecto temporal (como predecir un diagn√≥stico).\nRedes Neuronales Convolucionales (CNNs): Modelos de Deep Learning ideales para procesar datos con estructura de cuadr√≠cula, como las im√°genes, cruciales en el diagn√≥stico m√©dico.\nIA Causal: Utilizada para hacer inferencias sobre causa y efecto, lo cual es vital en la biolog√≠a, la medicina y el desarrollo de f√°rmacos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#casos-de-uso-en-el-diagn√≥stico-m√©dico",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#casos-de-uso-en-el-diagn√≥stico-m√©dico",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Casos de Uso en el Diagn√≥stico M√©dico",
    "text": "Casos de Uso en el Diagn√≥stico M√©dico\nLa anal√≠tica predictiva se utiliza para construir modelos que asisten en el diagn√≥stico, aprovechando grandes colecciones de ejemplos hist√≥ricos que superan lo que un solo individuo ver√≠a en su carrera.\n\nClasificaci√≥n de Im√°genes: Las CNNs son adecuadas para tareas que involucran datos con estructuras de cuadr√≠cula fija.\nDetecci√≥n de C√°ncer: Los modelos se pueden construir para la identificaci√≥n de especies bacterianas o la clasificaci√≥n de muestras de tejido para el c√°ncer de mama.\nPredicci√≥n de Riesgo Cardiovascular (CVD): Los modelos de regresi√≥n log√≠stica pueden predecir la probabilidad de que un paciente tenga una enfermedad.\nMedicina de Precisi√≥n: Las distribuciones de probabilidad se usan para modelar poblaciones y subpoblaciones, lo cual ayuda a dirigir tratamientos espec√≠ficos a grupos de pacientes que podr√≠an beneficiarse, por ejemplo, los que tienen diabetes."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#desaf√≠os-del-ml-en-el-sector-salud",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#desaf√≠os-del-ml-en-el-sector-salud",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Desaf√≠os del ML en el Sector Salud",
    "text": "Desaf√≠os del ML en el Sector Salud\nLa IA Causal es fundamental para ir m√°s all√° de la correlaci√≥n y estimar los efectos de una acci√≥n.\n\nOptimizaci√≥n de Dosis: Los modelos pueden predecir las dosis √≥ptimas de un medicamento bas√°ndose en datos hist√≥ricos de tratamientos y resultados asociados.\nCostos de I+D: El desarrollo de nuevos f√°rmacos es costoso (puede llegar a USD 2-3 mil millones) y tiene una alta tasa de fracaso (95% en ensayos cl√≠nicos).\nErrores de Atribuci√≥n: Una parte significativa de los fracasos en el desarrollo de medicamentos se atribuye a errores de atribuci√≥n causal, como la mala selecci√≥n de objetivos farmacol√≥gicos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#estimaci√≥n-de-efectos-y-robustez",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#estimaci√≥n-de-efectos-y-robustez",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Estimaci√≥n de Efectos y Robustez",
    "text": "Estimaci√≥n de Efectos y Robustez\n\nEfectos Heterog√©neos del Tratamiento (CATEs): Miden c√≥mo var√≠an los efectos de un tratamiento en diferentes segmentos de la poblaci√≥n.\nRobutsez Adversarial: En aplicaciones sensibles, la seguridad de los modelos debe ser evaluada frente a ataques, como la manipulaci√≥n de im√°genes m√©dicas."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#la-necesidad-de-modelos-interpretables",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#la-necesidad-de-modelos-interpretables",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "La Necesidad de Modelos Interpretables",
    "text": "La Necesidad de Modelos Interpretables\nLa interpretaci√≥n es esencial para garantizar que los modelos sean seguros, justos y fiables.\n\nTransparencia y Explicaci√≥n: La interpretabilidad reduce la brecha entre los complejos algoritmos y los usuarios humanos.\nDecisiones Cruciales: En √°mbitos como el diagn√≥stico de c√°ncer, la interpretaci√≥n del modelo es crucial para justificar las predicciones.\nEquidad y Rendici√≥n de Cuentas (FAT): La interpretaci√≥n ayuda a asegurar que las predicciones se hagan sin sesgos discernibles (equidad) y a explicar por qu√© se tomaron ciertas decisiones (rendici√≥n de cuentas).\nModelos de Caja Blanca: Modelos como la regresi√≥n log√≠stica son inherentemente interpretables (intr√≠nsecamente interpretables) porque su l√≥gica es transparente."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-problema-fundamental-b√∫squeda-y-bias",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-problema-fundamental-b√∫squeda-y-bias",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "El Problema Fundamental: B√∫squeda y Bias",
    "text": "El Problema Fundamental: B√∫squeda y Bias\nLos algoritmos de ML funcionan buscando entre un conjunto de modelos posibles para encontrar aquel que mejor se ajusta a los datos.\n\nProblema Mal Planteado (Ill-Posed Problem): La muestra de datos de entrenamiento es limitada. Como resultado, muchos modelos pueden ser consistentes con los datos, haciendo imposible elegir una soluci√≥n √∫nica solo por la consistencia.\nSin una gu√≠a, un modelo solo memorizar√≠a los datos (un extremo de sobreajuste)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#gu√≠a-para-la-selecci√≥n-del-modelo",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#gu√≠a-para-la-selecci√≥n-del-modelo",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Gu√≠a para la Selecci√≥n del Modelo",
    "text": "Gu√≠a para la Selecci√≥n del Modelo\nPara encontrar el modelo que mejor generaliza, los algoritmos utilizan un conjunto de suposiciones llamado Bias Inductivo.\nEste bias dirige la b√∫squeda del algoritmo hacia modelos espec√≠ficos que se asumen m√°s apropiados para el dominio.\n\n\nTipos de Bias\n\nBias de Restricci√≥n: Limita el conjunto de modelos posibles (ej. solo considerar modelos lineales).\nBias de Preferencia: Prefiere modelos con ciertas caracter√≠sticas (ej. preferir modelos m√°s simples o menos complejos).\n\n\nErrores Comunes\nSi el bias inductivo es inapropiado, el modelo cometer√° errores de generalizaci√≥n: - Underfitting (Subajuste): Modelo demasiado simplista que no captura la relaci√≥n subyacente. - Overfitting (Sobreajuste): Modelo demasiado complejo que se ajusta al ruido en los datos de entrenamiento."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-error",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-error",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Paradigmas de Aprendizaje: Modelos Basados en Error",
    "text": "Paradigmas de Aprendizaje: Modelos Basados en Error\nEstos modelos buscan un conjunto de par√°metros que minimice el error total en las predicciones con respecto al conjunto de entrenamiento.\n\nConcepto Central: Descenso de Gradiente (Gradient Descent). Es un algoritmo de b√∫squeda guiada que ajusta iterativamente los par√°metros del modelo (pesos) para moverse hacia el m√≠nimo global en una superficie de error.\nFunci√≥n de P√©rdida: T√≠picamente el Error Cuadr√°tico Sumado (\\(L2\\)) o la P√©rdida de Entrop√≠a Cruzada.\nEjemplo: Regresi√≥n Log√≠stica/Lineal. El modelo se define mediante una combinaci√≥n lineal de las caracter√≠sticas descriptivas multiplicadas por un conjunto de pesos.\nRegla de Actualizaci√≥n: El ajuste del peso (\\(\\Delta w\\)) es proporcional a la tasa de aprendizaje (\\(\\alpha\\)) y al gradiente de error."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-similitud",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-similitud",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Paradigmas de Aprendizaje: Modelos Basados en Similitud",
    "text": "Paradigmas de Aprendizaje: Modelos Basados en Similitud\nSe basan en la idea de que si una instancia es similar a instancias hist√≥ricas, tendr√° la misma etiqueta o valor objetivo.\n\nAlgoritmos: k-Vecinos M√°s Cercanos (k-NN).\nEspacio de Caracter√≠sticas: Las instancias se representan como puntos en un espacio de caracter√≠sticas, y la distancia entre ellas mide su disimilitud.\nFuncionamiento: Para una nueva consulta, el modelo identifica los \\(k\\) vecinos m√°s cercanos y predice la clase por voto mayoritario o el valor por promedio de sus vecinos.\nM√©tricas: Com√∫nmente se usa la Distancia Euclidiana o la Distancia Mahalanobis (que considera la covarianza entre caracter√≠sticas)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-informaci√≥n",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-informaci√≥n",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Paradigmas de Aprendizaje: Modelos Basados en Informaci√≥n",
    "text": "Paradigmas de Aprendizaje: Modelos Basados en Informaci√≥n\nEstos modelos determinan qu√© caracter√≠sticas son las m√°s informativas para realizar una secuencia de pruebas.\n\nAlgoritmos: √Årboles de Decisi√≥n (Decision Trees).\nEstructura: Se construye una estructura jer√°rquica donde los nodos internos representan pruebas de caracter√≠sticas y los nodos hoja representan la predicci√≥n.\nMedida Clave: La Ganancia de Informaci√≥n (Information Gain), calculada a partir de la Entrop√≠a, mide la reducci√≥n en la impureza del conjunto de datos al dividirlo por una caracter√≠stica.\nBias: Los algoritmos (como ID3) prefieren los √°rboles m√°s superficiales (menos complejos)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#qu√©-es-crisp-dm",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#qu√©-es-crisp-dm",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "¬øQu√© es CRISP-DM?",
    "text": "¬øQu√© es CRISP-DM?\n\nEst√°ndar de facto para proyectos anal√≠ticos.\n6 fases iterativas: Entendimiento del negocio, Entendimiento de los datos, Preparaci√≥n de los datos, Modelado, Evaluaci√≥n, Despliegue.\nCiclo no lineal; retroalimentaci√≥n entre fases."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#visi√≥n-general-diagrama",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#visi√≥n-general-diagrama",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Visi√≥n general (diagrama)",
    "text": "Visi√≥n general (diagrama)\n\n\n\n\n\n\n\nArtefactos\n\n\ncluster0\n\n1. Negocio\n\n\ncluster1\n\n2. Datos\n\n\ncluster2\n\n3. Preparaci√≥n\n\n\ncluster3\n\n4. Modelado\n\n\ncluster4\n\n5. Evaluaci√≥n\n\n\ncluster5\n\n6. Despliegue\n\n\n\nN1\n\n\n\nPICO/PECO\n\n\n\nD1\n\n\n\nInventario de fuentes\n\n\n\nN1-&gt;D1\n\n\nrequisitos\n de datos\n\n\n\nN2\n\n\n\nKPIs & Umbrales\n\n\n\nN3\n\n\n\nRiesgos & √âtica\n\n\n\nD2\n\n\n\nData Dictionary\n\n\n\nD3\n\n\n\nData Quality Report\n\n\n\nP1\n\n\n\nLimpieza/Imputaci√≥n\n\n\n\nD3-&gt;P1\n\n\ncalidad\n\n\n\nP1-&gt;D2\n\n\nmetadatos\n\n\n\nP2\n\n\n\nIngenier√≠a de features\n\n\n\nP3\n\n\n\nSplits anti-fuga\n\n\n\nM1\n\n\n\nBaselines\n\n\n\nP3-&gt;M1\n\n\ndataset\n modelable\n\n\n\nM1-&gt;P2\n\n\nfeatures\n\n\n\nM2\n\n\n\nTuning & CV\n\n\n\nM3\n\n\n\nArtefacto de inferencia\n\n\n\nE1\n\n\n\nROC/PR/Calibraci√≥n\n\n\n\nM3-&gt;E1\n\n\nmodelo\n\n\n\nE1-&gt;M1\n\n\najustes\n\n\n\nE2\n\n\n\nErrores cr√≠ticos\n\n\n\nE3\n\n\n\nAn√°lisis por subgrupos\n\n\n\nS1\n\n\n\nContenedor/Package\n\n\n\nE3-&gt;S1\n\n\ngo/no-go\n\n\n\nS2\n\n\n\nMonitoreo & Alertas\n\n\n\nS3\n\n\n\nPlan de retraining"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entendimiento del negocio",
    "text": "Entendimiento del negocio\n\nProblema cl√≠nico/laboral y poblaci√≥n objetivo.\nMetas anal√≠ticas: clasificaci√≥n, regresi√≥n, segmentaci√≥n, detecci√≥n.\nKPIs y restricciones: seguridad, costo, tiempo, privacidad.\nCriterio de √©xito: p.¬†ej., AUC ‚â• 0.90, sensibilidad ‚â• 0.95 en clase minoritaria.\nPlan del proyecto: roles, riesgos, cronograma y datos requeridos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 1)",
    "text": "Entregables (Fase 1)\n\nDeclaraci√≥n PICO/PECO del problema.\nMapa de stakeholders y requisitos.\nM√©tricas primarias/secundarias y umbrales m√≠nimos.\nProtocolos de √©tica y gobernanza de datos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#pico-ensayos-cl√≠nicos-intervenciones",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#pico-ensayos-cl√≠nicos-intervenciones",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "PICO (ensayos cl√≠nicos / intervenciones)",
    "text": "PICO (ensayos cl√≠nicos / intervenciones)\n\nPopulation (Poblaci√≥n): ¬øen qui√©nes? (pacientes, criterios de inclusi√≥n/exclusi√≥n).\nIntervention (Intervenci√≥n): ¬øqu√© intervenci√≥n/exposici√≥n activa? (tratamiento, protocolo, dispositivo).\nComparator (Comparador): ¬øcontra qu√© se compara? (placebo, est√°ndar de cuidado, otra intervenci√≥n).\nOutcome (Resultado): ¬øqu√© desenlaces medimos? (cl√≠nicos, funcionales, seguridad), con definici√≥n operacional y horizonte temporal.\n\nCu√°ndo usarlo: preguntas de efectividad/eficacia de una intervenci√≥n (t√≠pico en ECA o cuasi-experimentos).\nEjemplo (biom√©dico ‚Äì se√±ales)\n\nP: Adultos con sospecha de fibrilaci√≥n auricular en monitoreo Holter.\nI: Algoritmo de detecci√≥n basado en ECG de 1 derivaci√≥n con filtro adaptativo.\nC: Lectura por cardi√≥logo + algoritmo convencional validado.\nO: Sensibilidad ‚â• 0.95 y valor predictivo positivo ‚â• 0.90 para episodios ‚â• 30 s, en validaci√≥n ciega."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#peco-observacionales-exposiciones",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#peco-observacionales-exposiciones",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "PECO (observacionales / exposiciones)",
    "text": "PECO (observacionales / exposiciones)\n\nPopulation (Poblaci√≥n): ¬øen qui√©nes?\nExposure (Exposici√≥n): ¬øqu√© factor de exposici√≥n? (p.¬†ej., carga mec√°nica, turno nocturno, tabaquismo).\nComparator (Comparador): nivel de exposici√≥n de referencia (no expuestos / menos expuestos).\nOutcome (Resultado): desenlaces (incidencia, progresi√≥n, biomarcadores), con definici√≥n y ventana temporal.\n\nCu√°ndo usarlo: preguntas de asociaci√≥n causal o riesgo en estudios cohortes/casos y controles/transversales.\nEjemplo (biomec√°nica ‚Äì LCA)\n\nP: Deportistas amateur 18‚Äì35 a√±os post-reconstrucci√≥n de LCA.\nE: Asimetr√≠a de momento extensor de rodilla &gt; 15% durante salto con ca√≠da.\nC: Asimetr√≠a ‚â§ 15%.\nO: Re-lesi√≥n contralateral o ipsilateral a 12 meses."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#consejos-operativos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#consejos-operativos",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Consejos operativos",
    "text": "Consejos operativos\n\nDefinir Outcomes con m√©tricas, umbrales y ventana temporal (p.¬†ej., ‚Äú‚àÜIKDC ‚â• 10 puntos a 6 meses‚Äù).\nEn PECO, describir la medici√≥n de la exposici√≥n (instrumento, frecuencia, umbral) para minimizar sesgo de clasificaci√≥n.\nEspecificar a priori confusores y plan de ajuste (edad, sexo, dominio lateral, centro).\nEvitar outcomes compuestos mal justificados; priorizar uno primario y secundarios jer√°rquicos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#plantillas-r√°pidas",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#plantillas-r√°pidas",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Plantillas r√°pidas",
    "text": "Plantillas r√°pidas\n\nPICO: ‚ÄúEn P, ¬øla I comparada con C mejora O en T?‚Äù\nPECO: ‚ÄúEn P, ¬øla E frente a C se asocia con O en T, controlando por confusores?‚Äù"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entendimiento de los datos",
    "text": "Entendimiento de los datos\n\nInventario de fuentes: dispositivos, HIS/RIS, PACS, cuadernos de campo.\nExploraci√≥n: tipos de variables, distribuci√≥n, cardinalidad, valores faltantes.\nCalidad de datos: outliers, inconsistencias, sesgos de muestreo.\nPlan de calidad (qu√© corregir ahora vs.¬†m√°s adelante).\n\n\n\nRecomendaci√≥n: elaborar un Data Quality Report y un diccionario de datos versionado."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 2)",
    "text": "Entregables (Fase 2)\n\nData Quality Report (resumen estad√≠stico + visualizaciones clave).\nDiccionario de datos y esquema de metadatos.\nLista de riesgos de validez (fuga de datos, leakage temporal, etc.)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparaci√≥n-de-los-datos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparaci√≥n-de-los-datos",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Preparaci√≥n de los datos",
    "text": "Preparaci√≥n de los datos\n\nLimpieza: imputaci√≥n, manejo de at√≠picos, correcci√≥n de etiquetas.\nTransformaciones: normalizaci√≥n/estandarizaci√≥n, codificaci√≥n categ√≥rica.\nIngenier√≠a de caracter√≠sticas: ventanas temporales, espectro, texturas, ROI.\nParticiones: train/val/test con reglas anti-fuga (por paciente/centro).\n\n\n\nBiom√©dico: documente pipelines reproducibles con scripts y seed fijo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 3)",
    "text": "Entregables (Fase 3)\n\nABT (Analytical Base Table) o dataset modelable, con versi√≥n.\nPipelines de preproceso (c√≥digo + par√°metros + pruebas).\nEvidencia de no-fuga y balance/clase."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Modelado",
    "text": "Modelado\n\nBaselines robustos y trazables (p.¬†ej., regresi√≥n log√≠stica, NB, SVM).\nModelos avanzados: √°rboles/ensembles, deep learning si aplica.\nValidaci√≥n: K-fold estratificado por sujeto/centro; early stopping.\nTuning: b√∫squeda de hiperpar√°metros; ablation de features."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 4)",
    "text": "Entregables (Fase 4)\n\nReporte de experimentos (configuraciones, semillas, versiones).\nCurvas y tablas: ROC/PR, aprendizaje, calibraci√≥n, importancia de variables.\nModelo empaquetado (artefacto + inference script + schema de I/O)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluaci√≥n",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluaci√≥n",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Evaluaci√≥n",
    "text": "Evaluaci√≥n\n\nValidez t√©cnica: desempe√±o, incertidumbre, estabilidad temporal.\nValidez cl√≠nica/operacional: umbrales de decisi√≥n, impacto, costos.\nExplicabilidad: errores cr√≠ticos, an√°lisis por subgrupos (equidad).\nRevisi√≥n de riesgos: seguridad, privacidad, robustez, shift de dominio."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 5)",
    "text": "Entregables (Fase 5)\n\nInforme de evaluaci√≥n con estratificaci√≥n por subpoblaciones.\nMatriz de confusi√≥n, curvas ROC/PR, lift/gain si hay casos raros.\nDecisiones de go/no-go y plan de mitigaci√≥n de riesgos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Despliegue",
    "text": "Despliegue\n\nMVP en entorno controlado (sandbox/val cl√≠nica) con monitoreo.\nMLOps: versionado de datos/modelos, CI/CD, model registry.\nMonitoreo post-despliegue: drift, desempe√±o, alertas.\nCiclo de mantenimiento: retraining, gobernanza, auditor√≠a."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 6)",
    "text": "Entregables (Fase 6)\n\nPaquete de despliegue (contenedor o wheel), manual de integraci√≥n.\nTablero de monitoreo y protocolo de incidentes.\nPlan de actualizaci√≥n y retiro seguro del modelo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Checklist resumido",
    "text": "Checklist resumido\n\nProblema y m√©tricas claros.\nDatos caracterizados y limpios.\nParticiones sin fuga.\nBaseline y SOTA comparables.\nEvaluaci√≥n por subgrupos.\nPlan de despliegue y monitoreo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#qu√©-es-crisp-dm-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#qu√©-es-crisp-dm-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "¬øQu√© es CRISP-DM?",
    "text": "¬øQu√© es CRISP-DM?\n\nEst√°ndar de facto para proyectos anal√≠ticos.\n6 fases iterativas: Entendimiento del negocio, Entendimiento de los datos, Preparaci√≥n de los datos, Modelado, Evaluaci√≥n, Despliegue.\nCiclo no lineal; retroalimentaci√≥n entre fases.\n\n\n\nConsejo: marque expl√≠citamente supuestos, riesgos y decisiones en actas breves por fase."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#visi√≥n-general-diagrama-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#visi√≥n-general-diagrama-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Visi√≥n general (diagrama)",
    "text": "Visi√≥n general (diagrama)\n\n\n\n\n\n\n\nCRISPDM\n\n\n\nA\n\nEntendimiento\n del negocio\n\n\n\nB\n\nEntendimiento\n de los datos\n\n\n\nA-&gt;B\n\n\n\n\n\nC\n\nPreparaci√≥n\n de los datos\n\n\n\nB-&gt;C\n\n\n\n\n\nC-&gt;B\n\n\nretrabajo\n\n\n\nD\n\nModelado\n\n\n\nC-&gt;D\n\n\n\n\n\nD-&gt;B\n\n\ndiagn√≥sticos\n\n\n\nE\n\nEvaluaci√≥n\n\n\n\nD-&gt;E\n\n\n\n\n\nE-&gt;A\n\n\nredefinir metas\n\n\n\nF\n\nDespliegue\n\n\n\nE-&gt;F"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#visi√≥n-general-artefactos-por-fase",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#visi√≥n-general-artefactos-por-fase",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Visi√≥n general (artefactos por fase)",
    "text": "Visi√≥n general (artefactos por fase)\n\n\n\n\n\n\n\nArtefactos\n\n\ncluster0\n\n1. Negocio\n\n\ncluster1\n\n2. Datos\n\n\ncluster2\n\n3. Preparaci√≥n\n\n\ncluster3\n\n4. Modelado\n\n\ncluster4\n\n5. Evaluaci√≥n\n\n\ncluster5\n\n6. Despliegue\n\n\n\nN1\n\n\n\nPICO/PECO\n\n\n\nD1\n\n\n\nInventario de fuentes\n\n\n\nN1-&gt;D1\n\n\nrequisitos\n de datos\n\n\n\nN2\n\n\n\nKPIs & Umbrales\n\n\n\nN3\n\n\n\nRiesgos & √âtica\n\n\n\nD2\n\n\n\nData Dictionary\n\n\n\nD3\n\n\n\nData Quality Report\n\n\n\nP1\n\n\n\nLimpieza/Imputaci√≥n\n\n\n\nD3-&gt;P1\n\n\ncalidad\n\n\n\nP1-&gt;D2\n\n\nmetadatos\n\n\n\nP2\n\n\n\nIngenier√≠a de features\n\n\n\nP3\n\n\n\nSplits anti-fuga\n\n\n\nM1\n\n\n\nBaselines\n\n\n\nP3-&gt;M1\n\n\ndataset\n modelable\n\n\n\nM1-&gt;P2\n\n\nfeatures\n\n\n\nM2\n\n\n\nTuning & CV\n\n\n\nM3\n\n\n\nArtefacto de inferencia\n\n\n\nE1\n\n\n\nROC/PR/Calibraci√≥n\n\n\n\nM3-&gt;E1\n\n\nmodelo\n\n\n\nE1-&gt;M1\n\n\najustes\n\n\n\nE2\n\n\n\nErrores cr√≠ticos\n\n\n\nE3\n\n\n\nAn√°lisis por subgrupos\n\n\n\nS1\n\n\n\nContenedor/Package\n\n\n\nE3-&gt;S1\n\n\ngo/no-go\n\n\n\nS2\n\n\n\nMonitoreo & Alertas\n\n\n\nS3\n\n\n\nPlan de retraining"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "1) Entendimiento del negocio",
    "text": "1) Entendimiento del negocio\n\nProblema cl√≠nico/laboral y poblaci√≥n objetivo.\nMetas anal√≠ticas: clasificaci√≥n, regresi√≥n, segmentaci√≥n, detecci√≥n.\nKPIs y restricciones: seguridad, costo, tiempo, privacidad.\nCriterio de √©xito: p.¬†ej., AUC ‚â• 0.90, sensibilidad ‚â• 0.95 en clase minoritaria.\nPlan del proyecto: roles, riesgos, cronograma y datos requeridos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 1)",
    "text": "Entregables (Fase 1)\n\nDeclaraci√≥n PICO/PECO del problema.\nMapa de stakeholders y requisitos.\nM√©tricas primarias/secundarias y umbrales m√≠nimos.\nProtocolos de √©tica y gobernanza de datos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "2) Entendimiento de los datos",
    "text": "2) Entendimiento de los datos\n\nInventario de fuentes: dispositivos, HIS/RIS, PACS, cuadernos de campo.\nExploraci√≥n: tipos de variables, distribuci√≥n, cardinalidad, valores faltantes.\nCalidad de datos: outliers, inconsistencias, sesgos de muestreo.\nPlan de calidad (qu√© corregir ahora vs.¬†m√°s adelante).\n\n\n\nRecomendaci√≥n: elaborar un Data Quality Report y un diccionario de datos versionado."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 2)",
    "text": "Entregables (Fase 2)\n\nData Quality Report (resumen estad√≠stico + visualizaciones clave).\nDiccionario de datos y esquema de metadatos.\nLista de riesgos de validez (fuga de datos, leakage temporal, etc.)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparaci√≥n-de-los-datos-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparaci√≥n-de-los-datos-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "3) Preparaci√≥n de los datos",
    "text": "3) Preparaci√≥n de los datos\n\nLimpieza: imputaci√≥n, manejo de at√≠picos, correcci√≥n de etiquetas.\nTransformaciones: normalizaci√≥n/estandarizaci√≥n, codificaci√≥n categ√≥rica.\nIngenier√≠a de caracter√≠sticas: ventanas temporales, espectro, texturas, ROI.\nParticiones: train/val/test con reglas anti-fuga (por paciente/centro).\n\n\n\nBiom√©dico: documente pipelines reproducibles con scripts y seed fijo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 3)",
    "text": "Entregables (Fase 3)\n\nABT (Analytical Base Table) o dataset modelable, con versi√≥n.\nPipelines de preproceso (c√≥digo + par√°metros + pruebas).\nEvidencia de no-fuga y balance/clase."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "4) Modelado",
    "text": "4) Modelado\n\nBaselines robustos y trazables (p.¬†ej., regresi√≥n log√≠stica, NB, SVM).\nModelos avanzados: √°rboles/ensembles, deep learning si aplica.\nValidaci√≥n: K-fold estratificado por sujeto/centro; early stopping.\nTuning: b√∫squeda de hiperpar√°metros; ablation de features."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 4)",
    "text": "Entregables (Fase 4)\n\nReporte de experimentos (configuraciones, semillas, versiones).\nCurvas y tablas: ROC/PR, aprendizaje, calibraci√≥n, importancia de variables.\nModelo empaquetado (artefacto + inference script + schema de I/O)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluaci√≥n-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluaci√≥n-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "5) Evaluaci√≥n",
    "text": "5) Evaluaci√≥n\n\nValidez t√©cnica: desempe√±o, incertidumbre, estabilidad temporal.\nValidez cl√≠nica/operacional: umbrales de decisi√≥n, impacto, costos.\nExplicabilidad: errores cr√≠ticos, an√°lisis por subgrupos (equidad).\nRevisi√≥n de riesgos: seguridad, privacidad, robustez, shift de dominio."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 5)",
    "text": "Entregables (Fase 5)\n\nInforme de evaluaci√≥n con estratificaci√≥n por subpoblaciones.\nMatriz de confusi√≥n, curvas ROC/PR, lift/gain si hay casos raros.\nDecisiones de go/no-go y plan de mitigaci√≥n de riesgos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "6) Despliegue",
    "text": "6) Despliegue\n\nMVP en entorno controlado (sandbox/val cl√≠nica) con monitoreo.\nMLOps: versionado de datos/modelos, CI/CD, model registry.\nMonitoreo post-despliegue: drift, desempe√±o, alertas.\nCiclo de mantenimiento: retraining, gobernanza, auditor√≠a."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Entregables (Fase 6)",
    "text": "Entregables (Fase 6)\n\nPaquete de despliegue (contenedor o wheel), manual de integraci√≥n.\nTablero de monitoreo y protocolo de incidentes.\nPlan de actualizaci√≥n y retiro seguro del modelo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido-1",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Checklist resumido",
    "text": "Checklist resumido\n\nProblema y m√©tricas claros.\nDatos caracterizados y limpios.\nParticiones sin fuga.\nBaseline y SOTA comparables.\nEvaluaci√≥n por subgrupos.\nPlan de despliegue y monitoreo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-1-negocio",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-1-negocio",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Fase 1 ‚Äî Negocio",
    "text": "Fase 1 ‚Äî Negocio\n1.1 Declaraci√≥n PICO/PECO\n**Tipo**: PICO | PECO\n**Poblaci√≥n (P)**:\n**Intervenci√≥n/Exposici√≥n (I/E)**:\n**Comparador (C)**:\n**Outcomes (O)**:\n**Horizonte temporal (T)**:\n**Confusores a controlar**:\n**Criterio de √©xito** (umbral y justificaci√≥n):\n1.2 Mapa de stakeholders y requisitos\n**Stakeholders clave**: cl√≠nica, ingenier√≠a, TI, √©tica, pacientes.\n**Requisitos funcionales**:\n- RF1:\n- RF2:\n**Requisitos no funcionales** (seguridad, latencia, costo):\n- RNF1:\n- RNF2:\n**Riesgos y supuestos**:\n- R1:\n- S1:\n1.3 M√©tricas primarias/ secundarias\n**Tarea**: clasificaci√≥n | regresi√≥n | segmentaci√≥n | detecci√≥n\n**M√©trica primaria**: (p. ej., Sensibilidad@95% especificidad)\n**M√©tricas secundarias**: (AUC, F1, Brier, MAE, Dice/IoU)\n**Umbrales m√≠nimos**:\n**Justificaci√≥n cl√≠nica/operativa**:\n1.4 √âtica y gobernanza de datos\n**Base legal** (consentimiento/anonimizaci√≥n):\n**Evaluaci√≥n de riesgo** (privacidad, sesgo, seguridad):\n**Controles** (pseudonimizaci√≥n, control de acceso, auditor√≠a):\n**Plan de datos** (retenci√≥n, eliminaci√≥n, transferencia):"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-2-datos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-2-datos",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Fase 2 ‚Äî Datos",
    "text": "Fase 2 ‚Äî Datos\n2.1 Data Quality Report (DQR)\n**Origen de datos**: dispositivos/HIS/PACS/CSV/etc.\n**Cobertura temporal**:\n**Resumen por variable**:\n| Variable | Tipo | Unidades | % NA | √önicos | Min | Q1 | Mediana | Q3 | Max |\n|---|---|---|---:|---:|---:|---:|---:|---:|---:|\n| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n\n**Chequeos de reglas** (rangos plausibles, consistencia):\n- R1:\n- R2:\n**Outliers y tratamiento propuesto**:\n**Sesgos potenciales** (selecci√≥n, medici√≥n):\n2.2 Diccionario de datos\n| Nombre | Descripci√≥n | Tipo | Dominio/Unidades | Fuente | Notas |\n|---|---|---|---|---|---|\n| ... | ... | ... | ... | ... | ... |\n2.3 Riesgos de validez\n**Fugas potenciales**: por paciente, por tiempo, por sitio.\n**Dependencias**: variables derivadas del futuro.\n**Mitigaciones**: reglas de partici√≥n, ventanas estrictas."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-3-preparaci√≥n",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-3-preparaci√≥n",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Fase 3 ‚Äî Preparaci√≥n",
    "text": "Fase 3 ‚Äî Preparaci√≥n\n3.1 ABT / Dataset modelable (versi√≥n)\n**ID de versi√≥n**: abt_vYYYYMMDD\n**Clave de unidad anal√≠tica**: (p. ej., paciente, estudio, ventana)\n**Target**:\n**Features**: listado y fuente de cada una\n**Partici√≥n**: train/val/test con conteos por clase y por paciente\n3.2 Pipelines de preprocesamiento\n# pipeline_prepro.yaml\nversion: 1\nstages:\n  - name: limpieza\n    steps:\n      - imputacion: {estrategia: median, variables: [x1, x2]}\n      - winsorizacion: {p: 0.01}\n  - name: transformaciones\n    steps:\n      - estandarizacion: {m√©todo: zscore, by: train}\n      - pca: {var_explicada: 0.95}\nartifacts:\n  logs_dir: logs/\n  seed: 42\n3.3 Evidencia de no-fuga y balance\n**Regla anti-fuga**: split por paciente/centro/fecha.\n**Chequeo**: 0 pacientes compartidos entre train/val/test.\n**Distribuci√≥n de clases**:\n| Partici√≥n | n | Clase+ | Clase- | %+ |\n|---|---:|---:|---:|---:|\n| Train | | | | |\n| Val   | | | | |\n| Test  | | | | |"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-4-modelado",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-4-modelado",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Fase 4 ‚Äî Modelado",
    "text": "Fase 4 ‚Äî Modelado\n4.1 Reporte de experimentos\n**ID experimento**: exp_YYYYMMDD_hhmm\n**C√≥digo/commit**:\n**Semilla**: 42\n**Modelo**: (p. ej., LogisticRegression, ResNet18)\n**Features/inputs**:\n**Hiperpar√°metros**:\n**Esquema de validaci√≥n**: K-fold estratificado (por paciente)\n4.2 Resultados\n**Curvas**: ROC, PR, calibraci√≥n (con bandas de confianza)\n**Tablas**: m√©tricas por fold y promedio ¬± IC95%\n**Importancia de variables/atributos**: SHAP/coeficientes\n4.3 Artefacto de inferencia\n**Formato**: .pt | .onnx | .joblib | contenedor\n**Schema I/O**: tipos, unidades, validaciones\n**Script**: `inference.py` con prepro + postpro\n**Checksum y versi√≥n**:"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-5-evaluaci√≥n",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-5-evaluaci√≥n",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Fase 5 ‚Äî Evaluaci√≥n",
    "text": "Fase 5 ‚Äî Evaluaci√≥n\n5.1 Informe t√©cnico de evaluaci√≥n\n**Desempe√±o en test**: tabla principal de m√©tricas\n**Estratificaci√≥n**: por sexo/edad/centro/dispositivo\n**An√°lisis de errores**: casos representativos, costos\n**Equidad**: diferencias absolutas/relativas entre subgrupos\n5.2 Matrices y curvas\n**Matriz de confusi√≥n**: umbral √≥ptimo/operativo\n**Curvas**: ROC/PR; m√©tricas agregadas (AUC, AP)\n**Lift/Gain** (si prevalencia baja)\n5.3 Decisi√≥n y riesgos\n**Go/No-Go**: criterio y evidencia\n**Riesgos residuales**: lista y mitigaciones\n**Plan de validaci√≥n externa**: sitio/fecha/muestra"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-6-despliegue",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-6-despliegue",
    "title": "ML para Se√±ales e Im√°genes M√©dicas",
    "section": "Fase 6 ‚Äî Despliegue",
    "text": "Fase 6 ‚Äî Despliegue\n6.1 Paquete de despliegue\n**Estrategia**: contenedor | wheel | servicio\n**Infra**: CPU/GPU, RAM, almacenamiento\n**Integraci√≥n**: API/HL7/DICOM, autenticaci√≥n\n**Rollback**: versi√≥n estable y procedimiento\n6.2 Monitoreo y respuesta a incidentes\n**KPIs en producci√≥n**: latencia, tasa de error, drift, desempe√±o\n**Alertas**: umbrales y canal (email/ops)\n**Runbooks**: pasos ante fallo de modelo/datos/infra\n6.3 Mantenimiento y retiro\n**Retraining**: criterio de activaci√≥n, datos y frecuencia\n**Auditor√≠a**: trazabilidad de versiones y accesos\n**Retiro seguro**: plan de sustituci√≥n y archivo de modelos"
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Rol: Dise√±ador instruccional (AA en se√±ales e im√°genes m√©dicas)\nAudiencia: Pregrado (profundizaci√≥n, nivel avanzado)\nDuraci√≥n total: 24 horas (8 sesiones √ó 3 h)\nStack principal: Python 3.12, scikit-learn, PyTorch, MONAI, MNE (seg√∫n caso)\nPol√≠tica de validaci√≥n: subject-wise k-fold en todas las pr√°cticas\nEvaluaci√≥n sumativa: 7 mini-labs (70%) + quiz final (30%)\n√ânfasis cl√≠nico: Musculoesquel√©tico (EMG/RX/TC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n#\nT√≠tulo\nBloque\nHoras\nEntregable\n\n\n\n\n1\nFundamentos de AA en salud: tareas, m√©tricas y pipeline\nFundamentos\n3\nMini-lab 1: pipeline cl√°sico (sklearn)\n\n\n2\nValidaci√≥n rigurosa y reproducibilidad (subject-wise)\nFundamentos\n3\nMini-lab 2: split subject-wise + baseline\n\n\n3\nSe√±ales biom√©dicas I: preprocesado y features (ECG/EMG)\nSe√±ales\n3\nMini-lab 3: filtro ‚Üí features ‚Üí clasificaci√≥n\n\n\n4\nSe√±ales biom√©dicas II: ML cl√°sico vs CNN 1D\nSe√±ales\n3\nMini-lab 4: baseline vs CNN1D (comparativa)\n\n\n5\nSe√±ales biom√©dicas III: LSTM/GRU/Transformers 1D + explicabilidad\nSe√±ales\n3\nMini-lab 5: secuenciales + saliency/IG\n\n\n6\nIm√°genes m√©dicas I: DICOM, preprocesado y transfer learning\nIm√°genes\n3\nMini-lab 6: fine-tuning (MONAI)\n\n\n7\nIm√°genes m√©dicas II: U-Net/ResNet, m√©tricas y Grad-CAM\nIm√°genes\n3\nMini-lab 7: segmentaci√≥n + Grad-CAM\n\n\n8\nIntegraci√≥n, buenas pr√°cticas y quiz final\nIm√°genes (cierre)\n3\nQuiz final + repositorio reproducible\n\n\n\nBalance de horas por bloque (aprox.): Fundamentos 6 h (‚âà30%), Se√±ales 9 h (‚âà35%), Im√°genes 9 h (‚âà35%).\nEvaluaci√≥n (modelo 5B): 7 mini-labs √ó 10% c/u = 70%; Quiz final = 30%.\n\n\n\n\n\nResultados de aprendizaje:\nRA1. Diferenciar tareas (clasificaci√≥n, regresi√≥n, segmentaci√≥n).\nRA2. Seleccionar m√©tricas apropiadas por tarea (Acc, AUC, F1, MAE; Dice/IoU para segmentaci√≥n).\nRA3. Describir un pipeline reproducible de AA en salud.\nConceptos clave: problema/tarea, train/val/test, baseline, feature engineering, normalizaci√≥n, data leakage.\nActividad pr√°ctica (PhysioNet, sklearn):\nClasificar latidos ECG (e.g., MIT-BIH o PTB-XL de PhysioNet). Preproceso b√°sico, split estratificado por paciente (sin fuga), baseline con LogReg/SVM.\nStack: Python 3.12, scikit-learn, numpy, pandas, matplotlib.\nValidaci√≥n: subject-wise k-fold (k=5).\nEvaluaci√≥n: Mini-lab 1 (10%).\nReferencias sugeridas (verificar DOI/ISBN antes de publicar):\n\nBishop, Pattern Recognition and Machine Learning, 2006, ISBN 978-0387310732.\nPedregosa et al., Scikit-learn: Machine Learning in Python, JMLR 12:2825‚Äì2830, 2011.\n\nRiesgos comunes: fuga por segmentos del mismo paciente; m√©tricas inadecuadas por clase desbalanceada.\n\n\n\n\n\n\nResultados:\nRA1. Implementar subject-wise k-fold y reportes por clase.\nRA2. Configurar entorno reproducible y seeds.\nRA3. Documentar experimentos (versionado y data cards).\nConceptos: subject-wise vs aleatorio, nested CV, semillas, hojas de datos, readme de experimentos.\nActividad (PhysioNet, sklearn):\nRepetir baseline sesi√≥n 1 con particionamiento subject-wise k-fold y reporte de varianza entre folds.\nStack: scikit-learn, mlflow (opcional), pyproject.toml o conda env, control de versiones.\nValidaci√≥n: subject-wise k-fold con estratificaci√≥n si aplica.\nEvaluaci√≥n: Mini-lab 2 (10%).\nReferencias:\n\nG√©ron, Hands-On Machine Learning, 2¬™/3¬™ ed., O‚ÄôReilly, ISBN 978-1492032649.\n\nRiesgos: comparar m√©tricas de folds no hom√≥logos; no fijar semillas; no congelar versiones.\n\n\n\n\n\n\nResultados:\nRA1. Aplicar filtrado, resampling y normalizaci√≥n en ECG/EMG.\nRA2. Extraer features en tiempo/frecuencia (RMS, picos R, bandas).\nRA3. Entrenar un clasificador cl√°sico y evaluar robustez.\nConceptos: filtros pasa-banda, remoci√≥n de l√≠nea base, windowing, PSD, z-score.\nActividad (PhysioNet):\nECG MIT-BIH: detecci√≥n de picos R + features ‚Üí clasificaci√≥n de latidos con RandomForest vs LogReg.\nStack: scikit-learn, scipy, wfdb (lectura PhysioNet), matplotlib.\nValidaci√≥n: subject-wise k-fold; m√©tricas: F1 macro, sensibilidad por clase.\nEvaluaci√≥n: Mini-lab 3 (10%).\nReferencias:\n\nGoldberger et al., PhysioNet (portal oficial).\n\nRiesgos: overfitting por feature selection en todo el set; filtrado que distorsiona morfolog√≠a.\n\n\n\n\n\n\nResultados:\nRA1. Implementar una CNN 1D simple y compararla con ML cl√°sico.\nRA2. Seleccionar m√©tricas y early stopping.\nRA3. Analizar errores por sujeto.\nConceptos: convoluci√≥n 1D, receptive field, padding/stride, learning rate.\nActividad (PhysioNet):\nECG PTB-XL (multi-derivaci√≥n) o MIT-BIH re-muestreado: baseline SVM vs CNN1D en PyTorch.\nStack: PyTorch, scikit-learn.\nValidaci√≥n: subject-wise k-fold; confusion matrix por sujeto.\nEvaluaci√≥n: Mini-lab 4 (10%).\nReferencias:\n\nGoodfellow et al., Deep Learning, MIT Press, ISBN 978-0262035613.\n\nRiesgos: comparar modelos con splits distintos; no balancear clases.\n\n\n\n\n\n\nResultados:\nRA1. Implementar LSTM/GRU/Transformers 1D para detecci√≥n de eventos.\nRA2. Aplicar explicabilidad 1D (saliency, Integrated Gradients).\nRA3. Reportar variabilidad entre folds.\nConceptos: dependencias temporales, enmascaramiento, longitudes variables, atenci√≥n.\nActividad (PhysioNet):\nPTB-XL (o EEG PhysioNet para eventos): modelo secuencial + saliency/IG (Captum).\nStack: PyTorch, captum, mne (si EEG).\nValidaci√≥n: subject-wise k-fold; m√©tricas por evento.\nEvaluaci√≥n: Mini-lab 5 (10%).\nReferencias:\n\nHochreiter & Schmidhuber, LSTM (1997).\nVaswani et al., Attention Is All You Need (2017).\n\nRiesgos: secuencias truncadas sesgando etiquetas; explicaciones no estables entre folds.\n\n\n\n\n\n\nResultados:\nRA1. Cargar DICOM/series y normalizar intensidades.\nRA2. Ejecutar transfer learning con MONAI.\nRA3. Documentar data transforms y augmentations.\nConceptos: spacing, windowing, normalizaci√≥n, recortes, augment.\nActividad (TCIA):\nLIDC-IDRI (TCIA): clasificaci√≥n simple de n√≥dulos (benigno/sospechoso como etiqueta did√°ctica) con fine-tuning de ResNet.\nStack: MONAI, PyTorch, pydicom.\nValidaci√≥n: subject-wise k-fold por paciente.\nEvaluaci√≥n: Mini-lab 6 (10%).\nReferencias:\n\nMONAI (docs oficiales).\nArmato et al., LIDC-IDRI (descripci√≥n del dataset).\n\nRiesgos: fuga por cortes m√∫ltiples del mismo paciente en train/test; augment que altera anatom√≠a.\n\n\n\n\n\n\nResultados:\nRA1. Entrenar U-Net para segmentaci√≥n 2D.\nRA2. Evaluar con Dice/IoU y curvas de volumen.\nRA3. Aplicar Grad-CAM para inspecci√≥n de atenci√≥n.\nConceptos: U-Net (encoder-decoder), p√©rdida (Dice/BCE), tiling, posprocesado.\nActividad (TCIA):\nLIDC-IDRI: segmentaci√≥n de n√≥dulos con U-Net (MONAI) + Grad-CAM sobre cortes con ResNet para inspecci√≥n.\nStack: MONAI, PyTorch, captum.\nValidaci√≥n: subject-wise k-fold; reporte Dice por paciente.\nEvaluaci√≥n: Mini-lab 7 (10%).\nReferencias:\n\nRonneberger et al., U-Net, MICCAI 2015 (DOI disponible).\nHe et al., ResNet, CVPR 2016.\n\nRiesgos: entrenar/validar en cortes del mismo estudio; segmentaci√≥n con m√°scaras ruidosas.\n\n\n\n\n\n\nResultados:\nRA1. Integrar pipeline completo (datos ‚Üí modelo ‚Üí validaci√≥n ‚Üí reporte).\nRA2. Elaborar model card y data card resumidas.\nRA3. Defender decisiones de dise√±o con evidencia.\nConceptos: estructura de repositorio, model/data cards, checklist de reproducibilidad, trazabilidad de experimentos.\nActividad:\nIntegrar un caso se√±al (ECG) o imagen (TCIA) a elecci√≥n: notebook final con README y report de m√©tricas.\nStack: PyTorch, MONAI, scikit-learn, matplotlib.\nValidaci√≥n: subject-wise k-fold; reporte agregando media¬±DE.\nEvaluaci√≥n: Quiz final (30%).\nReferencias:\n\nMitchell et al., Model Cards for Model Reporting (FAccT).\n\nRiesgos: falta de seeds, rutas relativas no reproducibles, dependencias sin fijar versi√≥n.\n\n\n\n\n\n\nPython==3.12.*, seed fija (e.g., 42), requirements.txt o environment.yml, carpetas data/, notebooks/, models/, reports/.\nSubject-wise k-fold obligatorio; no mezclar cortes/derivaciones del mismo paciente entre splits.\nReportar media¬±DE por fold y por paciente cuando aplique.\n\n\n\n\n\n\nTextos:\n\nBishop (2006), PRML, ISBN 978-0387310732.\nGoodfellow, Bengio, Courville (2016), Deep Learning, ISBN 978-0262035613.\n\nSoftware:\n\nPedregosa et al.¬†(2011), Scikit-learn, JMLR 12.\nPaszke et al.¬†(2019), PyTorch (NeurIPS).\nMONAI (documentaci√≥n oficial).\n\nSe√±ales (PhysioNet): MIT-BIH, PTB-XL, EEG Motor/Imagery. (Usar portal oficial; a√±adir DOI/URL confirmados antes de publicar)\nIm√°genes (TCIA): LIDC-IDRI. (A√±adir DOI/URL confirmados antes de publicar)"
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#tabla-de-sesiones-24-h-8-sesiones-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#tabla-de-sesiones-24-h-8-sesiones-3-h",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "#\nT√≠tulo\nBloque\nHoras\nEntregable\n\n\n\n\n1\nFundamentos de AA en salud: tareas, m√©tricas y pipeline\nFundamentos\n3\nMini-lab 1: pipeline cl√°sico (sklearn)\n\n\n2\nValidaci√≥n rigurosa y reproducibilidad (subject-wise)\nFundamentos\n3\nMini-lab 2: split subject-wise + baseline\n\n\n3\nSe√±ales biom√©dicas I: preprocesado y features (ECG/EMG)\nSe√±ales\n3\nMini-lab 3: filtro ‚Üí features ‚Üí clasificaci√≥n\n\n\n4\nSe√±ales biom√©dicas II: ML cl√°sico vs CNN 1D\nSe√±ales\n3\nMini-lab 4: baseline vs CNN1D (comparativa)\n\n\n5\nSe√±ales biom√©dicas III: LSTM/GRU/Transformers 1D + explicabilidad\nSe√±ales\n3\nMini-lab 5: secuenciales + saliency/IG\n\n\n6\nIm√°genes m√©dicas I: DICOM, preprocesado y transfer learning\nIm√°genes\n3\nMini-lab 6: fine-tuning (MONAI)\n\n\n7\nIm√°genes m√©dicas II: U-Net/ResNet, m√©tricas y Grad-CAM\nIm√°genes\n3\nMini-lab 7: segmentaci√≥n + Grad-CAM\n\n\n8\nIntegraci√≥n, buenas pr√°cticas y quiz final\nIm√°genes (cierre)\n3\nQuiz final + repositorio reproducible\n\n\n\nBalance de horas por bloque (aprox.): Fundamentos 6 h (‚âà30%), Se√±ales 9 h (‚âà35%), Im√°genes 9 h (‚âà35%).\nEvaluaci√≥n (modelo 5B): 7 mini-labs √ó 10% c/u = 70%; Quiz final = 30%."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#fundamentos-de-aa-en-salud-tareas-m√©tricas-y-pipeline-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#fundamentos-de-aa-en-salud-tareas-m√©tricas-y-pipeline-3-h",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Resultados de aprendizaje:\nRA1. Diferenciar tareas (clasificaci√≥n, regresi√≥n, segmentaci√≥n).\nRA2. Seleccionar m√©tricas apropiadas por tarea (Acc, AUC, F1, MAE; Dice/IoU para segmentaci√≥n).\nRA3. Describir un pipeline reproducible de AA en salud.\nConceptos clave: problema/tarea, train/val/test, baseline, feature engineering, normalizaci√≥n, data leakage.\nActividad pr√°ctica (PhysioNet, sklearn):\nClasificar latidos ECG (e.g., MIT-BIH o PTB-XL de PhysioNet). Preproceso b√°sico, split estratificado por paciente (sin fuga), baseline con LogReg/SVM.\nStack: Python 3.12, scikit-learn, numpy, pandas, matplotlib.\nValidaci√≥n: subject-wise k-fold (k=5).\nEvaluaci√≥n: Mini-lab 1 (10%).\nReferencias sugeridas (verificar DOI/ISBN antes de publicar):\n\nBishop, Pattern Recognition and Machine Learning, 2006, ISBN 978-0387310732.\nPedregosa et al., Scikit-learn: Machine Learning in Python, JMLR 12:2825‚Äì2830, 2011.\n\nRiesgos comunes: fuga por segmentos del mismo paciente; m√©tricas inadecuadas por clase desbalanceada."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#validaci√≥n-rigurosa-y-reproducibilidad-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#validaci√≥n-rigurosa-y-reproducibilidad-3-h",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Implementar subject-wise k-fold y reportes por clase.\nRA2. Configurar entorno reproducible y seeds.\nRA3. Documentar experimentos (versionado y data cards).\nConceptos: subject-wise vs aleatorio, nested CV, semillas, hojas de datos, readme de experimentos.\nActividad (PhysioNet, sklearn):\nRepetir baseline sesi√≥n 1 con particionamiento subject-wise k-fold y reporte de varianza entre folds.\nStack: scikit-learn, mlflow (opcional), pyproject.toml o conda env, control de versiones.\nValidaci√≥n: subject-wise k-fold con estratificaci√≥n si aplica.\nEvaluaci√≥n: Mini-lab 2 (10%).\nReferencias:\n\nG√©ron, Hands-On Machine Learning, 2¬™/3¬™ ed., O‚ÄôReilly, ISBN 978-1492032649.\n\nRiesgos: comparar m√©tricas de folds no hom√≥logos; no fijar semillas; no congelar versiones."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#se√±ales-biom√©dicas-i-preprocesado-y-features-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#se√±ales-biom√©dicas-i-preprocesado-y-features-3-h",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Aplicar filtrado, resampling y normalizaci√≥n en ECG/EMG.\nRA2. Extraer features en tiempo/frecuencia (RMS, picos R, bandas).\nRA3. Entrenar un clasificador cl√°sico y evaluar robustez.\nConceptos: filtros pasa-banda, remoci√≥n de l√≠nea base, windowing, PSD, z-score.\nActividad (PhysioNet):\nECG MIT-BIH: detecci√≥n de picos R + features ‚Üí clasificaci√≥n de latidos con RandomForest vs LogReg.\nStack: scikit-learn, scipy, wfdb (lectura PhysioNet), matplotlib.\nValidaci√≥n: subject-wise k-fold; m√©tricas: F1 macro, sensibilidad por clase.\nEvaluaci√≥n: Mini-lab 3 (10%).\nReferencias:\n\nGoldberger et al., PhysioNet (portal oficial).\n\nRiesgos: overfitting por feature selection en todo el set; filtrado que distorsiona morfolog√≠a."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#se√±ales-biom√©dicas-ii-ml-cl√°sico-vs-cnn-1d-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#se√±ales-biom√©dicas-ii-ml-cl√°sico-vs-cnn-1d-3-h",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Implementar una CNN 1D simple y compararla con ML cl√°sico.\nRA2. Seleccionar m√©tricas y early stopping.\nRA3. Analizar errores por sujeto.\nConceptos: convoluci√≥n 1D, receptive field, padding/stride, learning rate.\nActividad (PhysioNet):\nECG PTB-XL (multi-derivaci√≥n) o MIT-BIH re-muestreado: baseline SVM vs CNN1D en PyTorch.\nStack: PyTorch, scikit-learn.\nValidaci√≥n: subject-wise k-fold; confusion matrix por sujeto.\nEvaluaci√≥n: Mini-lab 4 (10%).\nReferencias:\n\nGoodfellow et al., Deep Learning, MIT Press, ISBN 978-0262035613.\n\nRiesgos: comparar modelos con splits distintos; no balancear clases."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#se√±ales-biom√©dicas-iii-lstmgrutransformers-1d-explicabilidad-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#se√±ales-biom√©dicas-iii-lstmgrutransformers-1d-explicabilidad-3-h",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Implementar LSTM/GRU/Transformers 1D para detecci√≥n de eventos.\nRA2. Aplicar explicabilidad 1D (saliency, Integrated Gradients).\nRA3. Reportar variabilidad entre folds.\nConceptos: dependencias temporales, enmascaramiento, longitudes variables, atenci√≥n.\nActividad (PhysioNet):\nPTB-XL (o EEG PhysioNet para eventos): modelo secuencial + saliency/IG (Captum).\nStack: PyTorch, captum, mne (si EEG).\nValidaci√≥n: subject-wise k-fold; m√©tricas por evento.\nEvaluaci√≥n: Mini-lab 5 (10%).\nReferencias:\n\nHochreiter & Schmidhuber, LSTM (1997).\nVaswani et al., Attention Is All You Need (2017).\n\nRiesgos: secuencias truncadas sesgando etiquetas; explicaciones no estables entre folds."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#im√°genes-m√©dicas-i-dicom-preprocesado-y-transfer-learning-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#im√°genes-m√©dicas-i-dicom-preprocesado-y-transfer-learning-3-h",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Cargar DICOM/series y normalizar intensidades.\nRA2. Ejecutar transfer learning con MONAI.\nRA3. Documentar data transforms y augmentations.\nConceptos: spacing, windowing, normalizaci√≥n, recortes, augment.\nActividad (TCIA):\nLIDC-IDRI (TCIA): clasificaci√≥n simple de n√≥dulos (benigno/sospechoso como etiqueta did√°ctica) con fine-tuning de ResNet.\nStack: MONAI, PyTorch, pydicom.\nValidaci√≥n: subject-wise k-fold por paciente.\nEvaluaci√≥n: Mini-lab 6 (10%).\nReferencias:\n\nMONAI (docs oficiales).\nArmato et al., LIDC-IDRI (descripci√≥n del dataset).\n\nRiesgos: fuga por cortes m√∫ltiples del mismo paciente en train/test; augment que altera anatom√≠a."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#im√°genes-m√©dicas-ii-u-netresnet-m√©tricas-y-grad-cam-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#im√°genes-m√©dicas-ii-u-netresnet-m√©tricas-y-grad-cam-3-h",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Entrenar U-Net para segmentaci√≥n 2D.\nRA2. Evaluar con Dice/IoU y curvas de volumen.\nRA3. Aplicar Grad-CAM para inspecci√≥n de atenci√≥n.\nConceptos: U-Net (encoder-decoder), p√©rdida (Dice/BCE), tiling, posprocesado.\nActividad (TCIA):\nLIDC-IDRI: segmentaci√≥n de n√≥dulos con U-Net (MONAI) + Grad-CAM sobre cortes con ResNet para inspecci√≥n.\nStack: MONAI, PyTorch, captum.\nValidaci√≥n: subject-wise k-fold; reporte Dice por paciente.\nEvaluaci√≥n: Mini-lab 7 (10%).\nReferencias:\n\nRonneberger et al., U-Net, MICCAI 2015 (DOI disponible).\nHe et al., ResNet, CVPR 2016.\n\nRiesgos: entrenar/validar en cortes del mismo estudio; segmentaci√≥n con m√°scaras ruidosas."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#integraci√≥n-buenas-pr√°cticas-y-quiz-final-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#integraci√≥n-buenas-pr√°cticas-y-quiz-final-3-h",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Integrar pipeline completo (datos ‚Üí modelo ‚Üí validaci√≥n ‚Üí reporte).\nRA2. Elaborar model card y data card resumidas.\nRA3. Defender decisiones de dise√±o con evidencia.\nConceptos: estructura de repositorio, model/data cards, checklist de reproducibilidad, trazabilidad de experimentos.\nActividad:\nIntegrar un caso se√±al (ECG) o imagen (TCIA) a elecci√≥n: notebook final con README y report de m√©tricas.\nStack: PyTorch, MONAI, scikit-learn, matplotlib.\nValidaci√≥n: subject-wise k-fold; reporte agregando media¬±DE.\nEvaluaci√≥n: Quiz final (30%).\nReferencias:\n\nMitchell et al., Model Cards for Model Reporting (FAccT).\n\nRiesgos: falta de seeds, rutas relativas no reproducibles, dependencias sin fijar versi√≥n."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#requisitos-de-reproducibilidad",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#requisitos-de-reproducibilidad",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Python==3.12.*, seed fija (e.g., 42), requirements.txt o environment.yml, carpetas data/, notebooks/, models/, reports/.\nSubject-wise k-fold obligatorio; no mezclar cortes/derivaciones del mismo paciente entre splits.\nReportar media¬±DE por fold y por paciente cuando aplique."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#ap√©ndice-referencias-globales-y-datasets-portal-oficial",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#ap√©ndice-referencias-globales-y-datasets-portal-oficial",
    "title": "√çndice extendido ‚Äî Curso de Aprendizaje Autom√°tico para Se√±ales e Im√°genes M√©dicas (24 h)",
    "section": "",
    "text": "Textos:\n\nBishop (2006), PRML, ISBN 978-0387310732.\nGoodfellow, Bengio, Courville (2016), Deep Learning, ISBN 978-0262035613.\n\nSoftware:\n\nPedregosa et al.¬†(2011), Scikit-learn, JMLR 12.\nPaszke et al.¬†(2019), PyTorch (NeurIPS).\nMONAI (documentaci√≥n oficial).\n\nSe√±ales (PhysioNet): MIT-BIH, PTB-XL, EEG Motor/Imagery. (Usar portal oficial; a√±adir DOI/URL confirmados antes de publicar)\nIm√°genes (TCIA): LIDC-IDRI. (A√±adir DOI/URL confirmados antes de publicar)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nSuposse‚Ä¶\n\n\nA dataset of M tuples \\((\\mathbf{x}_i, \\mathbf{y}_i)\\) with i = 1, ‚Ä¶, M.\n\n\\(\\mathbf{x}_i\\): Inputs\n\\(\\mathbf{y}_i\\): Outputs\n\n\n\n\n\n\n\n\n\n\n\n\nWhat it is a neural network\n\n\nIs a mathematical function (sometimes called a network function) that takes some kind of input (typically multi-dimensional) called x iand generate some output."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nNetwork function\n\n\n\nThe output generated by the network function is called \\(\\hat{y}_i\\)\nThe network function normally depends on a certain number N of parameters, which we will indicate with \\(\\mathbf{\\theta}_k\\) \\[ \\mathbf{\\hat{y}}_i = f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), where, k=0,1,2,\\ldots,N \\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nImportante\n\n\nA neural network is nothing more than a mathematical function that depends on a set of parameters that are tuned, hopefully in some smart way, to make the network output as close as possible to some expected output.\n\n\n\n\n\n\n\n\\(\\mathbf{x}_i \\in \\mathbb{R}^n\\)\n\\(\\mathbf{y}_i \\in \\mathbb{R}^k\\)\n\\(i = 0,1,2,\\ldots,M\\)\n\\(\\mathbf{\\theta}_k \\in \\mathbb{R}^N\\)\n\\(k = 0,1,2,\\ldots,N\\)\n\n\n\nLoss function \\(L \\left( \\mathbf{\\hat{y}}_i, \\mathbf{y}_i \\right) = L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\)\nLoss function measures how close are \\(\\mathbf{\\hat{y}}_i\\) and \\(\\mathbf{y}_i\\)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nLearning\n\n\n\n$ _{_k ^N} L ( f ( _k, _i ), _i ) $\n\\(\\min_{\\mathbf{\\theta}_k \\in \\mathbb{R}^N} L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\) subject to \\(c_q, q=1,2,3,\\ldots,Q\\) with \\(Q \\in \\mathbb{N}\\)\nThe learning process is the search of a minima. However, most of the algorithms can search only a ‚Äúlocal‚Äù minima.\nIn principle, we want to find the global minimum or, in other words, the point for which the function value is the smallest between all possible points.\n\n\n\n\n\n\nIdentifying if the minimum is a local or a global minimum is impossible, due to the network function complexity.\nThis is one (albeit not the only one) of the reasons that training large neural networks is such a challenging numerical problem."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "A single neuron",
    "text": "A single neuron"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Neural Network",
    "text": "Neural Network"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Neural Network",
    "text": "Neural Network\n\nTaken from GeeksforGeeks"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Regularization",
    "text": "Regularization\nNeural Networks have a great number of internal parameters for learning; which varying in a vast range of values.\nThis number of parameters is fundamental for neural network knowledge representation\n\n\n\n\n\n\n\nProblem\n\n\nBut if this number increases too much the neural network is prone to overfitting"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Regularization",
    "text": "Regularization\n\n\n\n\n\n\n\nDefinition\n\n\nRegularization techniques reduce the possibility of a neural network overfitting by constraining the range of values that the weight values within the network hold.\n\n\n\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Regularization",
    "text": "Regularization\n\nRegularization works on assumption that smaller weights generate simpler model and thus helps avoid overfitting.\nThe simpler model is less prone to overfitting.\nAdding the regularization term to the sum of squared differences between the actual value and predicted value."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Regularization",
    "text": "Regularization\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k\n\\end{eqnarray}\\]\n\n\n\n\n\n\n\nNota\n\n\n\\(\\lambda\\) is the penalty term or regularization parameter which determines how much to penalizes the weights."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Types of Regularization",
    "text": "Types of Regularization\n\n\nL1 Regularization or Lasso or L1 norm\n\nL1 penalizes sum of absolute value of weights.\nL1 has a sparse solution.\nL1 has multiple solutions.\nL1 has built in feature selection.\nL1 is robust to outliers.\nL1 generates model that are simple and interpretable but cannot learn complex patterns.\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\lvert \\theta_k \\rvert\n\\end{eqnarray}\\]\n\nL2 Regularization or Ridge Regularization\n\nL2 regularization penalizes sum of square weights.\nL2 has a non sparse solution\nL2 has one solution\nL2 has no feature selection\nL2 is not robust to outliers\nL2 gives better prediction when output variable is a function of all input features\nL2 regularization is able to learn complex data patterns\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Evaluation",
    "text": "Evaluation\n\n\n\n\n\n\n\nRegression\n\n\n\n\\(R^2\\)\nResidual graph\nAutocorrelation analysis\n\n\n\n\n\n\n\n\n\n\n\n\nClassification\n\n\n\nConfusion Matrix(Matriz de Confusi√≥n)\nPrecision(Precisi√≥n)\nRecall(Exhaustividad)\nF1-score(Valor-F)\nAccuracy(Exactitud)\nTrue Positive(Positivos Verdaderos)\nTrue Negative(Negativos Verdaderos)\nFalse Positive(Positivos Falsos)\nFalse Negative(Negativos Falsos)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nConfusion Matrix\n\n\n‚ÄúAlso known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one.‚Äù"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nTrue Negative\n\n\nValues that being negative have been classified as negative\n\n\n\n\n\n\n\n\n\n\n\nTrue Positive\n\n\nValues that being positive have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Positive\n\n\nValues that being negative have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Negative\n\n\nValues that being negative have been classified as positive"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nSensitivity or Recall\n\n\nHow good is my classifier at detecting positive cases? \\[ \\frac{TP}{TP+FN} \\]\n\n\n\n\n\n\n\n\n\n\n\nSpecificity\n\n\nHow good is my classifier at avoiding negative cases? \\[ \\frac{TN}{TN+FP} \\]\n\n\n\n\n\n\n\n\n\n\n\n\nPrecision\n\n\nHow credible is my classifier when it detects a positive case? \\[\\frac{TP}{TP+FP}\\]\n\n\n\n\n\n\n\n\n\n\n\nAccuracy and Balance Accuracy\n\n\nHow many cases the classifier correctly identifies? \\[Accuracy = \\frac{TP+TN}{TP+FP+FN+TN}\\] \\[BalancedAccuracy = \\frac{Specificity+Sensitivity}{2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nPrevalence\n\n\nHow often does the positive condition actually occur in our sample? \\[\\frac{TP+FN}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nDetection Rate\n\n\nPercentage of true positives \\[\\frac{TP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nDetection Prevalence\n\n\nPercentage of positives \\[\\frac{TP+FP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nHarmonic mean of recall and precision.\n\n\n\\[2\\frac{\\left( Precision \\right) \\left( Sensitivity \\right)}{Precision+Sensitivity}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 1"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 2"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\n\n\nFor Class 3"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-gran-pregunta",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-gran-pregunta",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "La Gran Pregunta",
    "text": "La Gran Pregunta\n\n\n\n\n\n\nNota\n\n\n\n¬øY si tu celular pudiera detectar una enfermedad card√≠aca con solo tocarlo?\n¬øY si una computadora pudiera ver un tumor que el ojo humano m√°s experto a√∫n no distingue?\n\n\n\n\n\nImaginen por un momento‚Ä¶ ¬øY si su celular pudiera detectar una enfermedad card√≠aca con solo tocarlo? ¬øY si una computadora pudiera ver un tumor en una radiograf√≠a, incluso antes de que el ojo humano m√°s experto lo note? Esto no es ciencia ficci√≥n. Es lo que hacemos todos los d√≠as en este campo. La pregunta no es ‚Äòsi‚Äô es posible, sino ‚Äòc√≥mo‚Äô lo hacemos posible."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#bienvenida",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#bienvenida",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Bienvenida",
    "text": "Bienvenida\nProcesamiento de se√±ales e im√°genes\nDe los sonidos y las fotos a la salud y la tecnolog√≠a.\n\nGuion: Preguntar a los estudiantes: ¬øQu√© se√±ales usan sin darse cuenta? (Wi-Fi, m√∫sica, ritmo del coraz√≥n). Explicar que hoy aprender√°n a mirar c√≥mo las computadoras entienden esas se√±ales e im√°genes."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestro-viaje-de-hoy",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestro-viaje-de-hoy",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Nuestro Viaje de Hoy",
    "text": "Nuestro Viaje de Hoy\n\nLos Lenguajes Secretos del Cuerpo: Descubriremos las se√±ales el√©ctricas que nos mantienen vivos.\nUna Imagen Vale M√°s que Mil Pruebas: Veremos c√≥mo convertimos el interior del cuerpo en im√°genes.\nEl Truco de Magia: ‚ÄòProcesar‚Äô: Aprenderemos a limpiar y mejorar estos datos para encontrar pistas.\n¬°Tu Turno! Convi√©rtete en Ingeniero/a Biom√©dico/a: Realizar√°n an√°lisis reales en nuestro laboratorio digital.\n\n\nPara entender c√≥mo funciona esta ‚Äòmagia‚Äô, nuestro viaje de hoy tendr√° cuatro paradas. Primero, descifraremos los lenguajes secretos del cuerpo, las se√±ales el√©ctricas. Luego, veremos c√≥mo creamos im√°genes del interior de nuestro cuerpo. Despu√©s, revelaremos el truco de magia que llamamos ‚Äòprocesamiento‚Äô para limpiar y mejorar estos datos. Y finalmente, la parte m√°s emocionante: ustedes mismos se convertir√°n en ingenieros y realizar√°n an√°lisis en nuestro laboratorio digital."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#qu√©-es-una-se√±al-informaci√≥n-en-movimiento",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#qu√©-es-una-se√±al-informaci√≥n-en-movimiento",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "¬øQu√© es una Se√±al? Informaci√≥n en Movimiento",
    "text": "¬øQu√© es una Se√±al? Informaci√≥n en Movimiento\n\nUna se√±al es simplemente informaci√≥n que cambia con el tiempo.\nEmpecemos por lo b√°sico. ¬øQu√© es una se√±al? Es simplemente informaci√≥n que cambia con el tiempo. Piensen en la m√∫sica: las notas suben y bajan, creando una melod√≠a. Eso es una se√±al. O la temperatura a lo largo de un d√≠a: sube al mediod√≠a y baja por la noche. En el cuerpo, en lugar de notas o grados, medimos cosas como la actividad el√©ctrica, que sube y baja de formas muy espec√≠ficas."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-sinfon√≠a-el√©ctrica-del-cuerpo",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-sinfon√≠a-el√©ctrica-del-cuerpo",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "La Sinfon√≠a El√©ctrica del Cuerpo",
    "text": "La Sinfon√≠a El√©ctrica del Cuerpo\n\n\nEl Electrocardiograma (ECG) es el ritmo del coraz√≥n, nuestro tambor principal.\n\n\n\n\n\nSe√±al de ECG ideal, mostrando el patr√≥n r√≠tmico del coraz√≥n.\n\n\n\n\n\n¬øQu√© nos dice el ECG?\n\n¬øCu√°l es el ritmo card√≠aco?\n¬øEl coraz√≥n late muy r√°pido o muy lento?\n¬øHay alguna parte que no funciona en armon√≠a?\nPermite diagnosticar problemas y salvar vidas.\n\n\n\nNuestro cuerpo es como una orquesta el√©ctrica. El coraz√≥n es el tambor, marcando un ritmo constante y poderoso. La se√±al que produce se llama Electrocardiograma o ECG. El cerebro es como la secci√≥n de cuerdas, con miles de neuronas ‚Äòhablando‚Äô a la vez en una conversaci√≥n compleja. Esa se√±al es el Electroencefalograma o EEG. Escuchando estas ‚Äòmelod√≠as‚Äô, los m√©dicos pueden saber si todo funciona en armon√≠a."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desaf√≠o-encontrar-la-se√±al-en-el-ruido",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desaf√≠o-encontrar-la-se√±al-en-el-ruido",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "El Desaf√≠o: Encontrar la Se√±al en el Ruido",
    "text": "El Desaf√≠o: Encontrar la Se√±al en el Ruido\n\nUna se√±al de ECG real a menudo est√° contaminada con ruido.\nPero en el mundo real, estas se√±ales no son tan claras. Imaginen tratar de escuchar a un amigo en una fiesta muy ruidosa. El ‚Äòruido‚Äô es todo lo que interfiere: otros aparatos el√©ctricos, el movimiento del paciente, etc. Este ruido puede ocultar informaci√≥n vital que el m√©dico necesita ver. Como ven aqu√≠, el patr√≥n claro del latido casi ha desaparecido."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-soluci√≥n-cancelaci√≥n-de-ruido-digital",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-soluci√≥n-cancelaci√≥n-de-ruido-digital",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "La Soluci√≥n: Cancelaci√≥n de Ruido Digital",
    "text": "La Soluci√≥n: Cancelaci√≥n de Ruido Digital\n\n\nSe√±al Ruidosa (Original)\n\n\n\n\n\n\n\n\n\n\nSe√±al Filtrada (Limpia)\n\n\n\n\n\n\n\n\n\n\n\nAqu√≠ es donde entra nuestra ‚Äòmagia‚Äô. Usamos algoritmos de ‚Äòfiltrado‚Äô. Es como ponerse unos aud√≠fonos con cancelaci√≥n de ruido. La computadora mira cada punto de la se√±al y lo promedia con sus vecinos de una manera inteligente. El ruido, al ser aleatorio y r√°pido, se cancela, ¬°pero el patr√≥n real del latido, que es m√°s lento y repetitivo, se mantiene! As√≠ ‚Äòrescatamos‚Äô la informaci√≥n importante, como pueden ver en la gr√°fica de la derecha. Pasamos de algo ilegible a una se√±al clara y diagn√≥stica."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#qu√©-es-una-imagen-una-pintura-por-n√∫meros",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#qu√©-es-una-imagen-una-pintura-por-n√∫meros",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "¬øQu√© es una Imagen? Una Pintura por N√∫meros",
    "text": "¬øQu√© es una Imagen? Una Pintura por N√∫meros\n\n\nLos N√∫meros (P√≠xeles)\n\n\n\n\n\nMatriz de n√∫meros que representa una imagen simple.\n\n\n\n\n\nLa Imagen Resultante\n\n\n\n\n\nLa imagen en escala de grises generada por la matriz de n√∫meros.\n\n\n\n\n\n\nAhora hablemos de im√°genes. Para una computadora, una imagen no es una foto, es una cuadr√≠cula gigante de n√∫meros. ¬°Como un lienzo para pintar por n√∫meros! Cada n√∫mero representa el brillo de un puntito llamado ‚Äòp√≠xel‚Äô. Un n√∫mero bajo como 0 puede ser negro, un n√∫mero alto como 255 puede ser blanco, y los n√∫meros intermedios son todos los tonos de gris. A la izquierda ven los n√∫meros, y a la derecha, la imagen que la computadora crea a partir de ellos."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#una-ventana-hacia-el-cuerpo",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#una-ventana-hacia-el-cuerpo",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Una Ventana Hacia el Cuerpo",
    "text": "Una Ventana Hacia el Cuerpo\n\n\nRadiograf√≠a (Rayos X) Ideal para ver estructuras densas como los huesos.\n\n\n\n\n\nEjemplo de una radiograf√≠a de t√≥rax.\n\n\n\n\n\nResonancia Magn√©tica (MRI) Perfecta para ver tejidos blandos como el cerebro.\n\n\n\n\n\nEjemplo de una resonancia magn√©tica cerebral.\n\n\n\n\n\n\nCon esta idea, podemos crear ventanas incre√≠bles hacia el interior del cuerpo. Las Radiograf√≠as (Rayos X) son como la sombra del cuerpo; son excelentes para ver cosas densas como los huesos. Las Resonancias Magn√©ticas (MRI) son diferentes; crean un mapa detallado del agua en nuestro cuerpo, lo que las hace perfectas para ver tejidos blandos como el cerebro, los m√∫sculos o los √≥rganos."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desaf√≠o-hacer-visible-lo-invisible",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desaf√≠o-hacer-visible-lo-invisible",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "El Desaf√≠o: Hacer Visible lo Invisible",
    "text": "El Desaf√≠o: Hacer Visible lo Invisible\n\nUna imagen m√©dica con bajo contraste donde los detalles son dif√≠ciles de ver.\nA veces, la informaci√≥n que buscamos en una imagen m√©dica es muy sutil. Puede ser como tratar de encontrar a un amigo en una foto muy oscura o con mucha niebla. El contraste puede ser bajo, o los bordes entre un tejido sano y uno enfermo pueden ser borrosos. El ojo humano puede pasar por alto estos detalles cruciales."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-soluci√≥n-resaltadores-digitales",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-soluci√≥n-resaltadores-digitales",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "La Soluci√≥n: Resaltadores Digitales",
    "text": "La Soluci√≥n: Resaltadores Digitales\n\n\nImagen Original\n\n\n\n\n\n\n\n\n\n\nImagen Mejorada\n\n\n\n\n\n\n\n\n\n\n\n¬°De nuevo, el procesamiento viene al rescate! Podemos darle ‚Äòsuperpoderes‚Äô a la imagen. Con el ajuste de contraste, le decimos a la computadora: ‚Äòhaz que las partes oscuras sean m√°s oscuras y las claras m√°s claras‚Äô, ¬°como ajustar el brillo en Instagram! F√≠jense c√≥mo en la imagen de la derecha, los detalles que antes estaban ocultos ahora son perfectamente visibles. Otra t√©cnica es la detecci√≥n de bordes, que dibuja una l√≠nea donde hay un cambio brusco de brillo, ayudando a los m√©dicos a ver la forma exacta de los √≥rganos o tumores."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#√°reas-de-aplicaci√≥n-del-procesamiento-de-se√±ales-e-im√°genes",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#√°reas-de-aplicaci√≥n-del-procesamiento-de-se√±ales-e-im√°genes",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "√Åreas de aplicaci√≥n del procesamiento de se√±ales e im√°genes",
    "text": "√Åreas de aplicaci√≥n del procesamiento de se√±ales e im√°genes\n\n\n\nDiagn√≥stico automatizado\nIdentificaci√≥n de enfermedades en ECG, EEG o im√°genes m√©dicas.\nMonitoreo en tiempo real\nVigilancia en UCI con se√±ales continuas de coraz√≥n, respiraci√≥n y cerebro.\nTelemedicina\nTransmisi√≥n y compresi√≥n de se√±ales para consultas a distancia.\nRehabilitaci√≥n y pr√≥tesis inteligentes\nUso de se√±ales EMG para controlar pr√≥tesis y exoesqueletos.\n\n\n\nDetecci√≥n temprana de eventos cr√≠ticos\nAnticipaci√≥n de arritmias, crisis epil√©pticas o ca√≠das.\nBiometr√≠a y seguridad\nReconocimiento de voz, rostro o iris.\nImagenolog√≠a avanzada\nSegmentaci√≥n de √≥rganos o tumores en 3D para cirug√≠a o radioterapia.\nEntretenimiento y multimedia\nFiltros en fotos y videos, mejora de audio y realidad aumentada.\n\n\n\nGuion: resaltar que la mitad de las aplicaciones impacta directamente en salud y la otra mitad en la vida cotidiana. Pedir a los estudiantes que piensen en qu√© columna usan m√°s sin darse cuenta."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Plataforma para el monitoreo de salud de adultos mayores",
    "text": "Plataforma para el monitoreo de salud de adultos mayores\n\nDetecci√≥n ambulatoria de actividades diarias.\nDetecci√≥n ambulatoria de riesgo de ca√≠da.\nDetecci√≥n ambulatoria de riesgo neuronal.\nDetecci√≥n ambulatoria de riesgo psico-social.\nDetecci√≥n ambulatoria de riesgo card√≠aco\nMonitorizaci√≥n de terapias ambulatorias para la rehabilitaci√≥n de adultos mayores"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#creaci√≥n-de-ambientes-de-habitaci√≥n-saludables-usando-realimentaci√≥n-sensorial",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#creaci√≥n-de-ambientes-de-habitaci√≥n-saludables-usando-realimentaci√≥n-sensorial",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Creaci√≥n de ambientes de habitaci√≥n saludables usando realimentaci√≥n sensorial",
    "text": "Creaci√≥n de ambientes de habitaci√≥n saludables usando realimentaci√≥n sensorial\n\nNeurofeedback emocional usando m√∫sica.\nNeurofeedback de memoria procedimental.\nNeurofeedback en automotores.\nMonitorizaci√≥n ambulatoria de estado emocional.\nMonitorizaci√≥n ambulatoria de terapias emocionales"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#apoyo-tecnol√≥gico-mediante-ia-a-intervenciones-cl√≠nicas",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#apoyo-tecnol√≥gico-mediante-ia-a-intervenciones-cl√≠nicas",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Apoyo tecnol√≥gico mediante IA a intervenciones cl√≠nicas",
    "text": "Apoyo tecnol√≥gico mediante IA a intervenciones cl√≠nicas\n\nDetecci√≥n de anomal√≠as en im√°genes mediante segmentaci√≥n heur√≠stica.\nPlaneaci√≥n pre-operatoria mediante el uso de inteligencia artificial.\nEvaluaci√≥n de espasticidad mediante el uso tecnolog√≠a."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#detecci√≥n-de-informaci√≥n-en-terapias-y-proyectos-de-rehabilitaci√≥n",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#detecci√≥n-de-informaci√≥n-en-terapias-y-proyectos-de-rehabilitaci√≥n",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Detecci√≥n de informaci√≥n en terapias y proyectos de rehabilitaci√≥n",
    "text": "Detecci√≥n de informaci√≥n en terapias y proyectos de rehabilitaci√≥n\n\nGeneraci√≥n de interfaces cerebro-computador\nGeneraci√≥n de algoritmos de clasificaci√≥n de intenci√≥n de movimiento\nMonitorizaci√≥n de terapias de rehabilitaci√≥n."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#invitaci√≥n",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#invitaci√≥n",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Invitaci√≥n",
    "text": "Invitaci√≥n\n\nInvitaci√≥n"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestras-herramientas",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestras-herramientas",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Nuestras Herramientas",
    "text": "Nuestras Herramientas\nVamos a usar este mismo documento como nuestro cuaderno de laboratorio digital.\n\nVer√°n bloques de c√≥digo en Python.\nNo necesitan ser expertos. El c√≥digo ya est√° escrito.\nSu misi√≥n: ejecutarlo (con el bot√≥n de play ‚ñ∫), observar los resultados e incluso experimentar cambiando algunos valores.\n\n¬°Vamos a hacer ciencia de verdad!\n\n¬°Suficiente teor√≠a! Es hora de que se pongan la bata de laboratorio. Vamos a usar este mismo documento como nuestro ‚Äòcuaderno de laboratorio digital‚Äô. Ver√°n bloques de c√≥digo en Python. No se asusten, no necesitan ser expertos. El c√≥digo ya est√° escrito. Su misi√≥n es ejecutarlo, observar los resultados e incluso experimentar cambiando algunas cosas. ¬°Vamos a hacer ciencia de verdad!"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misi√≥n-1-de-n√∫meros-a-dibujos",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misi√≥n-1-de-n√∫meros-a-dibujos",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Misi√≥n 1: ¬°De N√∫meros a Dibujos! üìù",
    "text": "Misi√≥n 1: ¬°De N√∫meros a Dibujos! üìù\nObjetivo: Comprender que las im√°genes son, en el fondo, solo listas de n√∫meros e instrucciones.\nMateriales: Una hoja de papel cuadriculado y un l√°piz.\nInstrucciones (Parte A - La Imagen Misteriosa):\nEn una hoja resalta los n√∫meros pares y los primos permitiendo ver el mensaje secreto."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misi√≥n-2-de-n√∫meros-a-dibujos",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misi√≥n-2-de-n√∫meros-a-dibujos",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Misi√≥n 2: ¬°De N√∫meros a Dibujos! üìù",
    "text": "Misi√≥n 2: ¬°De N√∫meros a Dibujos! üìù\nObjetivo: Comprender que las se√±ales e im√°genes son, en el fondo, solo listas de n√∫meros e instrucciones.\nMateriales: Una hoja de papel cuadriculado y un l√°piz.\nInstrucciones (Parte A - La Se√±al Misteriosa):\n\nEn tu hoja, dibuja un eje: el horizontal se llama ‚ÄúTiempo‚Äù (de 1 a 10) y el vertical ‚ÄúValor‚Äù (de 1 a 10).\nTe dar√© pares de n√∫meros (Tiempo, Valor). Dibuja un punto en cada coordenada.\nCoordenadas: (1, 2), (2, 4), (3, 6), (4, 8), (5, 6), (6, 4), (7, 2), (8, 4), (9, 6), (10, 8).\nUne los puntos en orden. ¬øQu√© letra o forma simple has dibujado?\n\nInstrucciones (Parte B - La Imagen Secreta):\n\nEn otra parte de tu hoja, dibuja una cuadr√≠cula de 8x8.\nTe dar√© coordenadas (fila, columna) que debes rellenar o colorear. La fila 1 es la de arriba, la columna 1 es la de la izquierda.\nP√≠xeles a colorear:\n\nFila 2: Columnas 3, 4, 5, 6\nFila 3: Columnas 2, 7\nFila 4: Columnas 2, 4, 5, 7\nFila 5: Columnas 2, 7\nFila 6: Columnas 3, 6\nFila 7: Columnas 4, 5\n\nAl√©jate un poco‚Ä¶ ¬øQu√© imagen has creado?"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misi√≥n-3-rescatar-un-latido",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misi√≥n-3-rescatar-un-latido",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Misi√≥n 3: Rescatar un Latido",
    "text": "Misi√≥n 3: Rescatar un Latido\nEl Reto: Hemos recibido la se√±al de ECG de un paciente, pero est√° llena de ruido. Es imposible para un m√©dico leerla as√≠.\nTu Tarea: Ejecuta el c√≥digo de abajo para aplicar un filtro digital y limpiar la se√±al. ¬°El diagn√≥stico del paciente depende de ti!\n\n\nMostrando la se√±al original recibida del paciente...\n\n\n\n\n\n\n\n\n\n\n¬°Filtro aplicado! Mostrando la se√±al recuperada..."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misi√≥n-4-mapear-el-cerebro",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misi√≥n-4-mapear-el-cerebro",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Misi√≥n 4: Mapear el Cerebro",
    "text": "Misi√≥n 4: Mapear el Cerebro\nEl Reto: Tenemos una imagen de resonancia magn√©tica. Para estudiarla, un neur√≥logo necesita ver claramente los contornos de las diferentes estructuras.\nTu Tarea: Ejecuta el c√≥digo para aplicar un filtro de ‚Äòdetecci√≥n de bordes‚Äô y crear un mapa de los contornos del cerebro.\n\n\nCargando imagen de resonancia magn√©tica...\n¬°Filtro de bordes aplicado! Mostrando comparaci√≥n..."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#preguntas",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#preguntas",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "¬øPreguntas?",
    "text": "¬øPreguntas?\n¬°Gracias!\n\nGracias por su atenci√≥n y su excelente trabajo como ingenieros. Ahora, me encantar√≠a responder a cualquier pregunta que tengan."
  },
  {
    "objectID": "codigo/preparing_slides.html",
    "href": "codigo/preparing_slides.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport pywt\nimport matplotlib.pyplot as plt\nimport imageio\nfrom scipy import signal\n\nplt.rcParams.update(\n    {\n        \"text.usetex\": True,  # usar LaTeX real\n        \"font.family\": \"Fira Code\",       # familia general\n        \"mathtext.fontset\": \"custom\",     # fuente personalizada para f√≥rmulas\n        \"mathtext.rm\": \"Fira Code\",       # texto ‚Äúroman‚Äù\n        \"mathtext.it\": \"Fira Code:italic\",# texto it√°lico\n        \"mathtext.bf\": \"Fira Code:bold\",   # texto en negrita\n        \"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n    }\n)\n\n# Time vector\nt = np.linspace(-3, 3, 500)\n\n# Define the original function and its components\nf_t = np.exp(t)  # Original function: e^t\nf_even = (np.exp(t) + np.exp(-t)) / 2  # Even part: cosh(t)\nf_odd = (np.exp(t) - np.exp(-t)) / 2  # Odd part: sinh(t)\n\n# Create the subplots\nfig, axs = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n\n# Plot the original function\naxs[0].plot(t, f_t, label=r\"$f(t) = e^t$\", color=\"blue\", linewidth=2)\naxs[0].set_title(\"Original Function\", fontsize=14)\naxs[0].set_ylabel(\"Amplitude\", fontsize=12)\naxs[0].legend(fontsize=12)\naxs[0].grid(True)\n\n# Plot the even part\naxs[1].plot(\n    t, f_even, label=r\"$f_{\\text{even}}(t) = \\cosh(t)$\", color=\"green\", linewidth=2\n)\naxs[1].set_title(\"Even Part of the Function\", fontsize=14)\naxs[1].set_ylabel(\"Amplitude\", fontsize=12)\naxs[1].legend(fontsize=12)\naxs[1].grid(True)\n\n# Plot the odd part\naxs[2].plot(t, f_odd, label=r\"$f_{\\text{odd}}(t) = \\sinh(t)$\", color=\"red\", linewidth=2)\naxs[2].set_title(\"Odd Part of the Function\", fontsize=14)\naxs[2].set_xlabel(\"Time (s)\", fontsize=12)\naxs[2].set_ylabel(\"Amplitude\", fontsize=12)\naxs[2].legend(fontsize=12)\naxs[2].grid(True)\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time base\nnp.random.seed(7)\nfs = 500  # Hz\nT = 2.0  # s\nt = np.linspace(0, T, int(fs * T), endpoint=False)\n\n# Deterministic signal: sinusoid\nA, f0, phi = 1.0, 5.0, np.pi / 6\nx_det = A * np.cos(2 * np.pi * f0 * t + phi)\n\n# Random signal: zero-mean Gaussian sequence, smoothed to be signal-like\nnoise = np.random.randn(t.size)\nM = 25  # moving-average window length (odd)\nkernel = np.ones(M) / M\nx_rand = np.convolve(noise, kernel, mode=\"same\") * 0.8  # scaled for visibility\n\n# Plot (two panels on a single slide)\nfig, axes = plt.subplots(2, 1, figsize=(9, 5), sharex=True)\n\naxes[0].plot(t, x_det, lw=1.4)\naxes[0].set_title(r\"Deterministic signal: $x_d(t)=A\\cos(2\\pi f_0 t+\\phi)$\")\naxes[0].set_ylabel(\"Amplitude\")\naxes[0].grid(alpha=0.3)\n\naxes[1].plot(t, x_rand, lw=1.2)\naxes[1].set_title(r\"Random signal (one realization): $X(t)$ with $\\mathbb{E}[X(t)]=0$\")\naxes[1].set_xlabel(r\"Time $t$ [s]\")\naxes[1].set_ylabel(\"Amplitude\")\naxes[1].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/PSIM/cod003_FourierImage.html",
    "href": "codigo/PSIM/cod003_FourierImage.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Step 1: Load the Ultrasound Image\nimage = cv2.imread(\n    \"../../data/malignant_breast_cancer.png\", \n    cv2.IMREAD_GRAYSCALE\n)\n\n\nsharpening_kernel1 = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\nsharpening_kernel2 = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n\nsharpened_image1 = cv2.filter2D(image, -1, sharpening_kernel1)\nsharpened_image2 = cv2.filter2D(image, -1, sharpening_kernel2)\n\n\n# Step 4: Display the Original and Sharpened Images Side-by-Side\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 3, 1)\nplt.title(\"Original Ultrasound Image\")\nplt.imshow(image, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 2)\nplt.title(\"Sharpened Ultrasound Image Kernel1\")\nplt.imshow(sharpened_image1, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 3)\nplt.title(\"Sharpened Ultrasound Image Kernel2\")\nplt.imshow(sharpened_image2, cmap=\"gray\")\nplt.axis(\"off\")\n\n\n\n\n\n\n\n\n\ndft1 = cv2.dft(np.float32(image), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift1 = np.fft.fftshift(dft1)\nmagnitude_spectrum1 = 20 * np.log(cv2.magnitude(dft_shift1[:, :, 0], dft_shift1[:, :, 1]))\n\ndft2 = cv2.dft(np.float32(sharpened_image1), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift2 = np.fft.fftshift(dft2)\nmagnitude_spectrum2 = 20 * np.log(\n    cv2.magnitude(dft_shift2[:, :, 0], dft_shift2[:, :, 1])\n)\n\ndft3 = cv2.dft(np.float32(sharpened_image2), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift3 = np.fft.fftshift(dft3)\nmagnitude_spectrum3 = 20 * np.log(\n    cv2.magnitude(dft_shift3[:, :, 0], dft_shift3[:, :, 1])\n)\n\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(3, 1, 1)\nplt.title(\"Magnitude Spectrum of initial image in log scale\")\nplt.imshow(magnitude_spectrum1, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(3, 1, 2)\nplt.title(\"Magnitude Spectrum of the first sharpended image in log scale\")\nplt.imshow(magnitude_spectrum2, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(3, 1, 3)\nplt.title(\"Magnitude Spectrum of the second sharpended image in log scale\")\nplt.imshow(magnitude_spectrum3, cmap=\"gray\")\nplt.axis(\"off\")\n\n\n\n\n\n\n\n\n\nrows, cols = image.shape\ncrow, ccol = rows // 2, cols // 2  # Coordenadas del centro\n\n# Crear una m√°scara pasa-altas\n# Empezamos con una matriz de unos\nmask = np.ones((rows, cols, 2), np.uint8)\n\n# Crear una regi√≥n cuadrada en el centro de la m√°scara que representa las bajas frecuencias\nr = 10  # Radio de la regi√≥n de bajas frecuencias que queremos eliminar\nmask[crow - r : crow + r, ccol - r : ccol + r] = (\n    0  # Zona central donde eliminamos las bajas frecuencias\n)\n\nplt.imshow(mask[:,:,1])\n\n\n\n\n\n\n\n\n\n# Aplicar la m√°scara pasa-altas al espectro DFT\nfshift = dft_shift1 * mask\n\n# Desplazar de vuelta las frecuencias (inverso de fftshift)\nf_ishift = np.fft.ifftshift(fshift)\n\n# Aplicar la transformada inversa de Fourier (IDFT)\nimg_back = cv2.idft(f_ishift)\n\n# Calcular la magnitud para obtener la imagen final filtrada\nimg_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n\n# Mostrar las im√°genes original y filtrada\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.imshow(image, cmap=\"gray\")\nplt.title(\"Imagen Original\")\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(img_back, cmap=\"gray\")\nplt.title(\"Imagen Filtrada (Pasa-Altas)\")\nplt.axis(\"off\")\n\nplt.show()"
  },
  {
    "objectID": "codigo/PSIM/cod004_wavelet_explain.html",
    "href": "codigo/PSIM/cod004_wavelet_explain.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nFs = 100\nt = np.arange(0,8, 1/Fs)\nx1 = np.exp(-t)\nx1[np.uint(2/0.01)]=0.8\nplt.plot(t,x1)\nplt.show()\n\n\n\n\n\n\n\n\n\ndef EspectroMagnitudFourier(t, x):\n    N = len(t)\n    Fs = 1/np.mean(np.diff(t))\n    x_fft = np.fft.fftshift(np.fft.fft(x))\n    f = np.fft.fftshift(np.fft.fftfreq(N, 1/Fs))\n    plt.plot(f, np.abs(x_fft))\n\n\nEspectroMagnitudFourier(t,x1)\n\n\n\n\n\n\n\n\n\nfrom scipy.signal import chirp\n\n\nx2 = np.sin(2*np.pi*2*t)+np.sin(2*np.pi*5*t)+np.sin(2*np.pi*10*t)\nEspectroMagnitudFourier(t,x2)\n\n\n\n\n\n\n\n\n\nx3 = np.zeros(t.shape)\nt1 = np.uint(3/0.01)\nt2 = np.uint(5/0.01)\nx3[0:t1] = np.sin(2*np.pi*2*t[0:t1])\n\nx3[t1:t2] = np.sin(2*np.pi*5*t[t1:t2])\nx3[t2:] = np.sin(2*np.pi*10*t[t2:])\nplt.plot(t,x3)\nplt.show()\n\n\n\nEspectroMagnitudFourier(t,x3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport scaleogram as scg  # Assuming you have `scaleogram` installed.\nimport pywt\n\n\n# Define the scales (`scales`)\nnum_points = x3.shape[0]\nmax_scale2 = 50  # You can adjust this based on your requirements\nscales = np.arange(1, max_scale2 + 1)  # Proper definition of scales\n\n# Define the wavelet to be used for the CWT\nwavelet_name = \"cmor0.5-1.0\"  \n\n# Compute the Continuous Wavelet Transform (CWT)\ncoef, freqs = pywt.cwt(x3, scales, wavelet=wavelet_name)\n\n# Plot the scalogram\nplt.figure(figsize=(10, 6))\nplt.imshow(\n    np.abs(coef),\n    aspect=\"auto\",\n    extent=[0, num_points, scales[-1], scales[0]],\n    cmap=\"viridis\",\n)\nplt.colorbar(label=\"Magnitude\")\nplt.ylabel(\"Scales\")\nplt.xlabel(\"Time\")\nplt.title(f\"Continuous Wavelet Transform (Scalogram) using {wavelet_name} wavelet\")\nplt.gca().invert_yaxis()  # Invert y-axis to have larger scales at the bottom\nplt.show()\n\n# Plot the mother wavelet function\nwavelet = pywt.ContinuousWavelet(wavelet_name)\n\n# Get the wavelet function (psi) and time points (x)\npsi, x = wavelet.wavefun(level=10)  # Level determines the resolution\n\n# Plotting the wavelet function (psi)\nplt.figure(figsize=(10, 6))\nplt.plot(x, psi, label=f\"{wavelet_name} wavelet\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.title(f\"Wavelet Function: {wavelet_name}\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport pywt\nimport scaleogram as scg\nimport scipy.io as sio\n\nanchos = np.uint(np.arange(1,np.log2(x3.shape[0])))\n\ncoef, freqs = pywt.cwt(x3,anchos,\"gaus1\") \nplt.matshow(coef)\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\ndata = sio.loadmat(\"../../data/JS00001.mat\")\necg001 = data[\"val\"][9, :]\nt = np.linspace(0,10, 5000)\nplt.plot(t,ecg001)\n\n\n\n\n\n\n\n\n\nimport scipy.signal as sig\nt_decimate=sig.decimate(t, 2)\n\n\ncoef_lvl1 = pywt.dwt(ecg001, wavelet=\"db1\")\nplt.plot(t_decimate, coef_lvl1[0]/np.max(coef_lvl1[0]))\nplt.plot(t_decimate, coef_lvl1[1]/np.max(coef_lvl1[1]))\nplt.show()\n\nplt.plot(t_decimate, coef_lvl1[0])\nplt.plot(t, ecg001)\nplt.show()\n\nplt.plot(t_decimate, coef_lvl1[1]/np.max(coef_lvl1[1]))\nplt.plot(t,ecg001/np.max(ecg001))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Descomposici√≥n con la Transformada Wavelet Discreta\nwavelet = \"db4\"  # Elegimos la wavelet Daubechies de nivel 4\nmax_level = pywt.dwt_max_level(len(ecg001), wavelet)\ncoeffs = pywt.wavedec(ecg001, wavelet, level=max_level)\n\n\n# Apply soft thresholding to detail coefficients\ncoeffs_thresh = [coeffs[0]]  # Keep approximation coefficients unchanged\ncoeffs_thresh.extend(\n    pywt.threshold(detail, 2000, mode=\"soft\") for detail in coeffs[1:]\n)\n\n\n# Reconstrucci√≥n de la se√±al desde los coeficientes\nreconstructed_signal = pywt.waverec(coeffs_thresh, wavelet)\n\n# Visualizaci√≥n de la se√±al original, ruidosa y reconstruida\nplt.figure(figsize=(12, 8))\n\n# Se√±al image\nplt.plot(t, ecg001, label=\"Se√±al Ruidosa\", color=\"orange\")\nplt.plot(t, reconstructed_signal, label=\"Se√±al Reconstruida\", color=\"green\")\n\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport cv2\nfrom scipy.signal import convolve2d\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pywt\nimport pywt.data\n\noriginal = cv2.imread(\"../../data/female-chest-x-ray.jpg\", cv2.IMREAD_GRAYSCALE)\n\n\nfrom scipy.signal import convolve2d\n\n# Filtros de paso bajo y paso alto para la wavelet Haar\nlow_pass = np.array([1, 1]) / np.sqrt(2)\nhigh_pass = np.array([1, -1]) / np.sqrt(2)\n\nprint(low_pass[:, None])\n\n# Convoluci√≥n en las filas\nLL_rows = convolve2d(original, low_pass[:, None], mode=\"same\")  # Paso bajo en filas\nHL_rows = convolve2d(original, high_pass[:, None], mode=\"same\")  # Paso alto en filas\n\n# Convoluci√≥n en las columnas\nLL_scratch = convolve2d(LL_rows, low_pass[None, :], mode=\"same\")  # Paso bajo en columnas\nLH_scratch = convolve2d(LL_rows, high_pass[None, :], mode=\"same\")  # Paso alto en columnas\nHL_scratch = convolve2d(\n    HL_rows, low_pass[None, :], mode=\"same\"\n)  # Paso bajo en columnas\nHH_scratch = convolve2d(\n    HL_rows, high_pass[None, :], mode=\"same\"\n)  # Paso alto en columnas\n\n# Visualizaci√≥n de las subbandas\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 3, 1)\nplt.title(\"Imagen Original\")\nplt.imshow(original, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 2)\nplt.title(\"Subbanda LL (Low-Low)\")\nplt.imshow(LL_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 3)\nplt.title(\"Subbanda LH (Low-High)\")\nplt.imshow(LH_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 5)\nplt.title(\"Subbanda HL (High-Low)\")\nplt.imshow(HL_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 6)\nplt.title(\"Subbanda HH (High-High)\")\nplt.imshow(HH_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\n[[0.70710678]\n [0.70710678]]\nfloat32\n\n\n\n\n\n\n\n\n\n\nimagen_oscura = np.uint8(cv2.normalize(LL_scratch, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX))\nhistograma = cv2.calcHist([imagen_oscura], [0], None, [256], [0, 256])\nplt.plot(histograma)\n\n\n\n\n\n\n\n\n\n\n# Load image\n#original = pywt.data.camera()\n\n# Wavelet transform of image, and plot approximation and details\ntitles = ['Approximation', ' Horizontal detail',\n          'Vertical detail', 'Diagonal detail']\ncoeffs2 = pywt.dwt2(original, 'haar')\nLL, (LH, HL, HH) = coeffs2\nfig = plt.figure(figsize=(12, 3))\nfor i, a in enumerate([LL, LH, HL, HH]):\n    ax = fig.add_subplot(1, 4, i + 1)\n    ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n    ax.set_title(titles[i], fontsize=10)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfig.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nth1 = 0.7*np.max([LL,HL,LH,HH])\nLL[LL&lt;th1]=0\nHL[HL&lt;th1]=0\nLH[LH&lt;th1]=0\nHH[HH&lt;th1]=0\ncoeffs2_denoise = (LL, (LH, HL, HH))\nimagen_recons=pywt.idwt2(coeffs2_denoise, wavelet=\"haar\")\nplt.imshow(np.hstack((original, imagen_recons)), cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(original-imagen_recons, cmap=\"gray\")"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html",
    "href": "codigo/PSIM/cod001_signal_conditioning.html",
    "title": "Paginas importantes",
    "section": "",
    "text": "https://www.nature.com/articles/s41597-020-0386-x\nhttps://physionet.org/content/ecg-arrhythmia/1.0.0/"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librer√≠as",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librer√≠as",
    "title": "Paginas importantes",
    "section": "Carga de librer√≠as",
    "text": "Carga de librer√≠as\n\nnumpy: Para manipulaci√≥n num√©rica y funciones estad√≠sticas b√°sicas\nmatplotlib.pyplot: Para generaci√≥n de gr√°ficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\nscipy.signal: Para an√°lisis de se√±ales de la librer√≠a SCIPY\nscipy.optimize: Para realizar el ajuste de curva\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.signal as signal\nfrom scipy.signal import freqz, butter, cheby1, firwin\nfrom scipy.optimize import curve_fit"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#configuraci√≥n-de-carpetas",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#configuraci√≥n-de-carpetas",
    "title": "Paginas importantes",
    "section": "Configuraci√≥n de carpetas",
    "text": "Configuraci√≥n de carpetas\n\ndata_path = \"/content/drive/MyDrive/ECG_Dataset/\""
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "title": "Paginas importantes",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\nplt.plot(f_vect1, mag_ecg_fft1**2)\nplt.grid()\n\n\n\n\n\n\n\n\n\nfs = 500\nfcut = 50\norder = 4\n\nf_corte = fcut/(fs/2)\n\nb, a = signal.butter(order, f_corte, \"lowpass\")\n\n\ndef plot_filter_response(b, a=1, fs=1.0):\n    \"\"\"Grafica la respuesta en frecuencia de un filtro dado.\"\"\"\n    w, h = freqz(b, a, worN=2048, fs=fs)  # Calcula la respuesta en frecuencia\n\n    # Magnitud de la respuesta en frecuencia\n    plt.figure(figsize=(10, 6))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(w, 20 * np.log10(abs(h)), \"b\")\n    plt.title(\"Respuesta en Frecuencia del Filtro\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Magnitud [dB]\")\n    plt.grid()\n\n    # Fase de la respuesta en frecuencia\n    plt.subplot(2, 1, 2)\n    plt.plot(w, np.angle(h), \"g\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Fase [radianes]\")\n    plt.grid()\n\n    plt.tight_layout()\n    plt.show()\n\n\n# Par√°metros del filtro\nfs = 1000  # Frecuencia de muestreo en Hz\ncutoff = 200  # Frecuencia de corte en Hz\norder = 4  # Orden del filtro\n\n# Filtro IIR Butterworth\nb_iir, a_iir = butter(order, cutoff, fs=fs, btype=\"low\", analog=False)\nprint(\"Filtro IIR Butterworth\")\nplot_filter_response(b_iir, a_iir, fs=fs)\n\n# Filtro FIR (ventana de Hamming)\nnumtaps = 50  # N√∫mero de coeficientes del FIR\nb_fir = firwin(numtaps, cutoff, fs=fs, window=\"hamming\")\nprint(\"Filtro FIR (Ventana de Hamming)\")\nplot_filter_response(b_fir, fs=fs)\n\n\necg_filt_1 = signal.lfilter(b, a, lead_10)\necg_filt_2 = signal.filtfilt(b, a, lead_10) # No causal.\n\n\nplt.plot(t, ecg_filt_1)\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nmag_ecg_filt = np.abs(np.fft.fft(ecg_filt_2))[:np.uint(N/2)]\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.plot(f_vect1, mag_ecg_filt)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\ndef modelo_artefacto(time, p0, p1, p2, p3, p4):\n  return p0+p1*np.sin(p2*time)+p3*np.cos(p4*time)\n\n\npopt, pcov = curve_fit(modelo_artefacto, t, ecg_filt_2)\n\n\npopt[1]\n\n152.2437794044702\n\n\n\nplt.plot(t, modelo_artefacto(t, *popt))\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2-modelo_artefacto(t, *popt))"
  },
  {
    "objectID": "codigo/Preparaciones/python_01_01.html",
    "href": "codigo/Preparaciones/python_01_01.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "\"\"\"\nMatrix 15x15 with two letters:\n- \"I\" drawn using EVEN numbers.\n- \"B\" drawn using PRIME numbers.\n- Background filled with ODD COMPOSITE numbers to visually \"hide\" the letters.\n\nReproducible and self-contained.\n\"\"\"\n\nimport numpy as np\n\nrng = np.random.default_rng(42)\n\n\n# --- helpers ---\ndef is_prime(n: int) -&gt; bool:\n    if n &lt; 2:\n        return False\n    if n % 2 == 0:\n        return n == 2\n    d = 3\n    while d * d &lt;= n:\n        if n % d == 0:\n            return False\n        d += 2\n    return True\n\n\n# pools\neven_pool = np.array([n for n in range(2, 100) if n % 2 == 0])\nprime_pool = np.array([n for n in range(2, 100) if is_prime(n)])\n# odd composite numbers (not prime, not even, &gt;1)\noddcomp_pool = np.array([n for n in range(3, 100, 2) if not is_prime(n)])\n\n# --- canvas ---\nH, W = 15, 15\nM = rng.choice(oddcomp_pool, size=(H, W))  # background: odd composite\n\n\n# Coordinate helper (row, col) with 0-based indexing\ndef put(vals, coords):\n    \"\"\"Place random values from `vals` at integer coordinates `coords`.\"\"\"\n    rr, cc = zip(*coords)\n    M[tuple(rr), tuple(cc)] = rng.choice(vals, size=len(coords))\n\n\n# --- draw \"I\" with even numbers (left side) ---\n# Use a simple blocky \"I\": top bar, vertical stem, bottom bar\ntop_row, bottom_row = 2, 12  # keep margins\nleft_col, right_col = 1, 3\nstem_col = 2\n\nI_coords = []\n# top bar\nI_coords += [(top_row, c) for c in range(left_col, right_col + 1)]\n# bottom bar\nI_coords += [(bottom_row, c) for c in range(left_col, right_col + 1)]\n# vertical stem\nI_coords += [(r, stem_col) for r in range(top_row, bottom_row + 1)]\n\nput(even_pool, I_coords)\n\n# --- draw \"B\" with primes (right side) ---\n# Spine + two bowls (top and bottom) approximated with block pixels\nspine_col = 10\nright_edge = 12\ntop, mid, bot = 2, 7, 12\n\nB_coords = []\n# vertical spine\nB_coords += [(r, spine_col) for r in range(top, bot + 1)]\n# top horizontal\nB_coords += [(top, c) for c in range(spine_col, right_edge + 1)]\n# mid horizontal (waist)\nB_coords += [(mid, c) for c in range(spine_col, right_edge)]\n# bottom horizontal\nB_coords += [(bot, c) for c in range(spine_col, right_edge + 1)]\n# right edges of bowls\nB_coords += [(r, right_edge) for r in range(top + 1, mid)]\nB_coords += [(r, right_edge) for r in range(mid + 1, bot)]\n\nput(prime_pool, B_coords)\n\n\n# --- sanity checks (optional) ---\ndef all_in_pool(vals, coords):\n    rr, cc = zip(*coords)\n    flat = M[tuple(rr), tuple(cc)].ravel().tolist()\n    return all(v in vals for v in flat)\n\n\nassert all_in_pool(set(even_pool.tolist()), I_coords), \"I must be even numbers\"\nassert all_in_pool(set(prime_pool.tolist()), B_coords), \"B must be primes\"\n\n# Background should be odd composite (not even, not prime)\nfor r in range(H):\n    for c in range(W):\n        if (r, c) in I_coords or (r, c) in B_coords:\n            continue\n        v = M[r, c]\n        assert v % 2 == 1 and not is_prime(v), \"Background must be odd composite\"\n\n# --- pretty print ---\nnp.set_printoptions(linewidth=200, formatter={\"int\": lambda x: f\"{x:02d}\"})\nprint(M)\n\n[[21 85 75 51 51 91 21 77 33 21 63 99 81 85 77]\n [85 57 25 87 55 57 49 27 95 85 75 51 87 63 55]\n [55 30 84 58 93 15 91 87 35 69 23 59 07 45 15]\n [99 55 02 75 85 81 27 49 55 57 59 63 11 81 77]\n [95 81 76 99 51 45 93 49 15 55 53 27 19 25 77]\n [55 45 50 65 75 95 51 27 87 69 05 21 89 85 87]\n [51 87 72 49 93 39 33 77 69 25 67 27 97 09 85]\n [85 85 66 55 77 35 85 63 55 57 59 05 25 35 21]\n [51 75 44 55 91 65 15 85 65 69 71 63 47 63 85]\n [39 69 32 45 51 99 33 35 51 99 03 09 37 87 15]\n [91 39 62 39 51 75 25 63 57 85 11 75 23 51 51]\n [87 45 14 45 09 21 21 85 81 77 41 77 53 93 57]\n [95 54 58 46 57 55 27 49 33 39 11 47 71 49 95]\n [21 45 21 45 99 49 93 57 77 55 35 85 99 35 85]\n [35 77 85 55 81 35 15 21 55 93 25 55 77 33 81]]\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# --- Funci√≥n para identificar primos ---\ndef is_prime(n: int) -&gt; bool:\n    if n &lt; 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    for i in range(3, int(n**0.5) + 1, 2):\n        if n % i == 0:\n            return False\n    return True\n\n\n# # Crear matriz aleatoria 15x15 con n√∫meros entre 1 y 100\n# np.random.seed(42)\n# M = np.random.randint(1, 100, (15, 5))\n\n# M√°scaras l√≥gicas\nmask_even = M % 2 == 0  # pares\nmask_prime = np.vectorize(is_prime)(M)  # primos\n\n# --- Visualizaci√≥n ---\nfig, ax = plt.subplots(figsize=(10, 6.7))\nax.matshow(np.ones_like(M), cmap=\"gray_r\")  # fondo gris claro\n\n# Mostrar n√∫meros\nfor i in range(M.shape[0]):\n    for j in range(M.shape[1]):\n        val = M[i, j]\n        color = \"black\"\n        weight = \"normal\"\n        if mask_even[i, j]:\n            color = \"black\"\n            weight = \"normal\"\n        if mask_prime[i, j]:\n            color = \"black\"\n            weight = \"normal\"\n        ax.text(\n            j, i, f\"{val:2d}\", va=\"center\", ha=\"center\", color=color, fontweight=weight\n        )\n\nax.set_xticks([])\nax.set_yticks([])\nax.set_title(\"Matriz 15x15\", fontsize=18)\n\nplt.savefig(\"mision01.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# --- Funci√≥n para identificar primos ---\ndef is_prime(n: int) -&gt; bool:\n    if n &lt; 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    for i in range(3, int(n**0.5) + 1, 2):\n        if n % i == 0:\n            return False\n    return True\n\n\n# # Crear matriz aleatoria 15x15 con n√∫meros entre 1 y 100\n# np.random.seed(42)\n# M = np.random.randint(1, 100, (15, 15))\n\n# M√°scaras l√≥gicas\nmask_even = M % 2 == 0  # pares\nmask_prime = np.vectorize(is_prime)(M)  # primos\n\n# --- Visualizaci√≥n ---\nfig, ax = plt.subplots(figsize=(8, 8))\nax.matshow(np.ones_like(M), cmap=\"gray_r\")  # fondo gris claro\n\n# Mostrar n√∫meros\nfor i in range(M.shape[0]):\n    for j in range(M.shape[1]):\n        val = M[i, j]\n        color = \"black\"\n        weight = \"normal\"\n        if mask_even[i, j]:\n            color = \"blue\"\n            weight = \"bold\"\n        if mask_prime[i, j]:\n            color = \"red\"\n            weight = \"bold\"\n        ax.text(\n            j, i, f\"{val:2d}\", va=\"center\", ha=\"center\", color=color, fontweight=weight\n        )\n\nax.set_xticks([])\nax.set_yticks([])\nax.set_title(\"Matriz 15x15 con pares (azul) y primos (rojo)\", fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Plotting the polyline defined by the coordinates\nimport matplotlib.pyplot as plt\n\n# Data\nt = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nv = [2, 4, 6, 8, 6, 4, 2, 4, 6, 8]\n\n# Figure\nplt.figure(figsize=(7, 4.5))  # one figure only; fast to render\nplt.plot(t, v, marker=\"o\", linewidth=2)\nplt.xticks(range(1, 11))\nplt.yticks(range(1, 11))\nplt.xlim(1, 10)\nplt.ylim(1, 10)\nplt.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.6)\nplt.xlabel(\"Tiempo\")\nplt.ylabel(\"Valor\")\nplt.title(\"Puntos conectados en el plano (Tiempo vs. Valor)\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/SYSB/remuestreo.html",
    "href": "codigo/SYSB/remuestreo.html",
    "title": "Par√°metros Iniciales de la se√±al",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\\[x\\left(t\\right) = 10\\sin\\left(2\\pi3t\\right)\\]\n\\[t\\in\\left[0, 5\\right]\\]\n\\[f_{s_1} = 20Hz\\]\n\\[f_{s_2} = 100Hz\\]\nt0 = 0\ntf = 1"
  },
  {
    "objectID": "codigo/SYSB/remuestreo.html#gr√°ficas-iniciales",
    "href": "codigo/SYSB/remuestreo.html#gr√°ficas-iniciales",
    "title": "Par√°metros Iniciales de la se√±al",
    "section": "Gr√°ficas iniciales",
    "text": "Gr√°ficas iniciales\n\nt_graph = np.linspace(t0, tf, 1000)\nx = 10*np.sin(2*np.pi*3*t_graph)\nplt.figure(figsize=(10,6))\nplt.plot(t_graph, x)\n\n\n\n\n\n\n\n\n\nfs1 = 20\nt_1 = np.linspace(t0, tf, fs1*(tf-t0), endpoint=False)\nx_1 = 10 * np.sin(2 * np.pi * 3 * t_1)\nplt.figure(figsize=(10, 6))\nplt.plot(t_graph, x)\nplt.plot(t_1, x_1, 'r*')\nplt.grid()\n\n\n\n\n\n\n\n\n\nt_oversample = [t0]\nx_1_over = [x_1[0]]\n\ndelta_t1 = np.mean(np.diff(t_1))\n\nt_oversample = np.empty(len(t_1)+len(t_1))\nt_oversample[0::2] = t_1\nt_oversample[1::2] = t_1 + (delta_t1/2)\n\nx_1_over = np.empty(len(t_1) + len(t_1))\nx_1_over[0::2] = x_1\nx_1_over[1::2] = (x_1+np.roll(x_1,-1))/2\n\nplt.figure(figsize=(10, 6))\nplt.plot(t_graph, x, \"k\")\nplt.plot(t_oversample, x_1_over, \"g*\")\nplt.plot(t_1, x_1, \"r*\")\nplt.grid()\n\n\n\n\n\n\n\n\n\n4//2\n\n2\n\n\n\n4%3\n\n1"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp.¬†261‚Äì265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp.¬†261‚Äì265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\ndata = pd.read_csv(\"../../data/diabetes.csv\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values\n\ndata.describe()\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n\n\n\ncol_entradas = [\n    \"Pregnancies\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"BMI\",\n    \"DiabetesPedigreeFunction\",\n    \"Age\"\n]\ncol_salidas = [\n    \"Outcome\"\n]\n\n\ndata[col_salidas].head()\n\n\n\n\n\n\n\n\nOutcome\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n2\n1\n\n\n3\n0\n\n\n4\n1"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship\n\nsns.countplot(data=data, x=\"Outcome\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data\n\nstandarScaler_features = StandardScaler().fit(data[col_entradas])\nentradas_norm = standarScaler_features.transform(data[col_entradas])\nsalida_norm = data[col_salidas].values"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#create-neural-network-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#create-neural-network-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network data",
    "text": "Create neural network data\n\nCreate Dataset\n\nclass TabularDataset(Dataset):\n    def __init__(self, ent, sal):\n        self.inputs = torch.tensor(ent, dtype=torch.float32)\n        self.outputs = torch.tensor(sal, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return self.inputs[idx], self.outputs[idx]\n\n\nconjuntoDatos = TabularDataset(ent=entradas_norm, sal=salida_norm)\n\ntrain_ds, val_ds, test_ds = random_split(conjuntoDatos, [0.7, 0.15, 0.15])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=True)\n\n\nfor batch in train_loader:\n    X_batch, y_batch = batch\n    print(X_batch.shape, y_batch.shape)\n\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([26, 8]) torch.Size([26, 1])"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model\n\nclass RedNeuronal(nn.Module):\n    def __init__(self, ent, sal):\n        super(RedNeuronal, self).__init__()\n        self.num_caract = ent\n        self.num_salidas = sal\n        self.fc1 = nn.Linear(self.num_caract, 10)  # Capa oculta 1\n        self.act1 = nn.ReLU()\n        self.fc2 = nn.Linear(10, 12) # Capa oculta 2\n        self.act2 = nn.ReLU()\n        self.fc3 = nn.Linear(12, 13)  # Capa oculta 3\n        self.act3 = nn.ReLU()\n        self.fc4 = nn.Linear(13, self.num_salidas)  # Capa de salida\n        self.act4 = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.act1(self.fc1(x))\n        x = self.act2(self.fc2(x))\n        x = self.act3(self.fc3(x))\n        x = self.act4(self.fc4(x))\n        return x\n\n\nepocas = 1000  # N√∫mero de √©pocas de entrenamiento\nbatch_size = 32  # Tama√±o del lote\n\n\nred = RedNeuronal(8, 1)\nred = red.to(device=device1)\n\n\nprint(red.parameters())\n\n&lt;generator object Module.parameters at 0x7f7ae23a5ee0&gt;\n\n\n\ncriterio = nn.BCELoss()\noptimizador = optim.Adam(red.parameters(), lr=0.001)\n\n\n# Entrenar la red neuronal\nfor epoca in range(epocas):\n    perdida_entrenamiento = 0\n    for X_batch, y_batch in train_loader:\n        # Pasar los datos por la red neuronal\n        salida = red(X_batch.to(device=device1))\n\n        # Calcular la p√©rdida\n        perdida = criterio(salida, y_batch.to(device=device1))\n\n        # Actualizar los pesos\n        optimizador.zero_grad()\n        perdida.backward()\n        optimizador.step()\n        perdida_entrenamiento += perdida.item()\n\n    # Imprimir la p√©rdida en cada √©poca\n    #print(f\"√âpoca {epoca+1}, p√©rdida: {perdida.item():.8f}\")\n    perdida_validacion = 0\n    con_exactitud = 0\n    total = 0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            # Pasar los datos por la red neuronal\n            salida = red(X_batch.to(device=device1))\n\n            # Calcular la p√©rdida\n            perdida = criterio(salida, y_batch.to(device=device1))\n\n            perdida_validacion += perdida.item()\n\n            # Calcular la exactitud\n            _, predicciones = torch.max(salida, 1)\n            con_exactitud += (predicciones.cpu().numpy() == y_batch.cpu().numpy()).sum().item()\n            total += y_batch.shape[0]\n\n    # Imprimir los resultados\n    print(f\"√âpoca {epoca+1}\")\n    print(f\"Perdida entrenamiento: {perdida_entrenamiento/len(train_loader)}\")\n    print(f\"Perdida validaci√≥n: {perdida_validacion/len(val_loader)}\")\n    print(f\"Exactitud validaci√≥n: {con_exactitud/total:.4f}\")\n\n√âpoca 1\nPerdida entrenamiento: 0.6791575761402354\nPerdida validaci√≥n: 0.6788250803947449\nExactitud validaci√≥n: 18.0609\n√âpoca 2\nPerdida entrenamiento: 0.672294301145217\nPerdida validaci√≥n: 0.6751690059900284\nExactitud validaci√≥n: 18.4000\n√âpoca 3\nPerdida entrenamiento: 0.6647399173063391\nPerdida validaci√≥n: 0.6713864207267761\nExactitud validaci√≥n: 18.7391\n√âpoca 4\nPerdida entrenamiento: 0.6535137961892521\nPerdida validaci√≥n: 0.6575797200202942\nExactitud validaci√≥n: 18.4000\n√âpoca 5\nPerdida entrenamiento: 0.6389946797314812\nPerdida validaci√≥n: 0.6436730623245239\nExactitud validaci√≥n: 18.2870\n√âpoca 6\nPerdida entrenamiento: 0.6213853324160856\nPerdida validaci√≥n: 0.6348690390586853\nExactitud validaci√≥n: 18.6261\n√âpoca 7\nPerdida entrenamiento: 0.5960922311334049\nPerdida validaci√≥n: 0.6058164685964584\nExactitud validaci√≥n: 18.5130\n√âpoca 8\nPerdida entrenamiento: 0.5712940009201274\nPerdida validaci√≥n: 0.5880416631698608\nExactitud validaci√≥n: 18.7391\n√âpoca 9\nPerdida entrenamiento: 0.5457583104862886\nPerdida validaci√≥n: 0.5503197610378265\nExactitud validaci√≥n: 18.4000\n√âpoca 10\nPerdida entrenamiento: 0.5210335955900305\nPerdida validaci√≥n: 0.5285529047250748\nExactitud validaci√≥n: 18.4000\n√âpoca 11\nPerdida entrenamiento: 0.4988165813333848\nPerdida validaci√≥n: 0.5061830580234528\nExactitud validaci√≥n: 18.2870\n√âpoca 12\nPerdida entrenamiento: 0.48283538572928486\nPerdida validaci√≥n: 0.5024331212043762\nExactitud validaci√≥n: 18.5130\n√âpoca 13\nPerdida entrenamiento: 0.4708527694730198\nPerdida validaci√≥n: 0.5093462020158768\nExactitud validaci√≥n: 18.4000\n√âpoca 14\nPerdida entrenamiento: 0.4619144955102135\nPerdida validaci√≥n: 0.4764373451471329\nExactitud validaci√≥n: 18.4000\n√âpoca 15\nPerdida entrenamiento: 0.4541836258243112\nPerdida validaci√≥n: 0.4746478497982025\nExactitud validaci√≥n: 17.9478\n√âpoca 16\nPerdida entrenamiento: 0.4520234956460841\nPerdida validaci√≥n: 0.48348189145326614\nExactitud validaci√≥n: 18.5130\n√âpoca 17\nPerdida entrenamiento: 0.44661900751730976\nPerdida validaci√≥n: 0.47032642364501953\nExactitud validaci√≥n: 18.0609\n√âpoca 18\nPerdida entrenamiento: 0.44420213033171263\nPerdida validaci√≥n: 0.4675467982888222\nExactitud validaci√≥n: 18.4000\n√âpoca 19\nPerdida entrenamiento: 0.44500470512053547\nPerdida validaci√≥n: 0.46534235775470734\nExactitud validaci√≥n: 18.5130\n√âpoca 20\nPerdida entrenamiento: 0.44122909447726083\nPerdida validaci√≥n: 0.49303658306598663\nExactitud validaci√≥n: 18.4000\n√âpoca 21\nPerdida entrenamiento: 0.439960497267106\nPerdida validaci√≥n: 0.4710696116089821\nExactitud validaci√≥n: 18.0609\n√âpoca 22\nPerdida entrenamiento: 0.43822164395276236\nPerdida validaci√≥n: 0.4644882157444954\nExactitud validaci√≥n: 18.4000\n√âpoca 23\nPerdida entrenamiento: 0.43539681855370016\nPerdida validaci√≥n: 0.48128364980220795\nExactitud validaci√≥n: 18.4000\n√âpoca 24\nPerdida entrenamiento: 0.43452516373466044\nPerdida validaci√≥n: 0.49383869767189026\nExactitud validaci√≥n: 18.5130\n√âpoca 25\nPerdida entrenamiento: 0.4337502367356244\nPerdida validaci√≥n: 0.461711123585701\nExactitud validaci√≥n: 18.1739\n√âpoca 26\nPerdida entrenamiento: 0.4328044530223398\nPerdida validaci√≥n: 0.4867813438177109\nExactitud validaci√≥n: 18.6261\n√âpoca 27\nPerdida entrenamiento: 0.4315945961896111\nPerdida validaci√≥n: 0.49709317088127136\nExactitud validaci√≥n: 18.8522\n√âpoca 28\nPerdida entrenamiento: 0.43218792361371655\nPerdida validaci√≥n: 0.4762030094861984\nExactitud validaci√≥n: 18.6261\n√âpoca 29\nPerdida entrenamiento: 0.42929310570744905\nPerdida validaci√≥n: 0.4678042158484459\nExactitud validaci√≥n: 18.4000\n√âpoca 30\nPerdida entrenamiento: 0.42652833286453695\nPerdida validaci√≥n: 0.4651280418038368\nExactitud validaci√≥n: 18.6261\n√âpoca 31\nPerdida entrenamiento: 0.4259583511773278\nPerdida validaci√≥n: 0.48188481479883194\nExactitud validaci√≥n: 18.6261\n√âpoca 32\nPerdida entrenamiento: 0.4245906016405891\nPerdida validaci√≥n: 0.48621364682912827\nExactitud validaci√≥n: 18.1739\n√âpoca 33\nPerdida entrenamiento: 0.4256867608603309\nPerdida validaci√≥n: 0.5174973607063293\nExactitud validaci√≥n: 18.6261\n√âpoca 34\nPerdida entrenamiento: 0.4248025277081658\nPerdida validaci√≥n: 0.4981654956936836\nExactitud validaci√≥n: 18.7391\n√âpoca 35\nPerdida entrenamiento: 0.42286987865672393\nPerdida validaci√≥n: 0.4870433583855629\nExactitud validaci√≥n: 18.7391\n√âpoca 36\nPerdida entrenamiento: 0.42132503057227416\nPerdida validaci√≥n: 0.48050128668546677\nExactitud validaci√≥n: 18.6261\n√âpoca 37\nPerdida entrenamiento: 0.422717108446009\nPerdida validaci√≥n: 0.4715006574988365\nExactitud validaci√≥n: 18.2870\n√âpoca 38\nPerdida entrenamiento: 0.41828276742907133\nPerdida validaci√≥n: 0.4957212060689926\nExactitud validaci√≥n: 18.4000\n√âpoca 39\nPerdida entrenamiento: 0.41759711153366985\nPerdida validaci√≥n: 0.4781687557697296\nExactitud validaci√≥n: 18.1739\n√âpoca 40\nPerdida entrenamiento: 0.4186316009830026\nPerdida validaci√≥n: 0.467018261551857\nExactitud validaci√≥n: 18.7391\n√âpoca 41\nPerdida entrenamiento: 0.41757552763995004\nPerdida validaci√≥n: 0.47248195111751556\nExactitud validaci√≥n: 18.5130\n√âpoca 42\nPerdida entrenamiento: 0.41657427479239073\nPerdida validaci√≥n: 0.5107008069753647\nExactitud validaci√≥n: 18.9652\n√âpoca 43\nPerdida entrenamiento: 0.41385892559500304\nPerdida validaci√≥n: 0.48618149757385254\nExactitud validaci√≥n: 18.6261\n√âpoca 44\nPerdida entrenamiento: 0.4130455264273812\nPerdida validaci√≥n: 0.48718027025461197\nExactitud validaci√≥n: 18.1739\n√âpoca 45\nPerdida entrenamiento: 0.4121672230608323\nPerdida validaci√≥n: 0.49359724670648575\nExactitud validaci√≥n: 18.4000\n√âpoca 46\nPerdida entrenamiento: 0.4103984973009895\nPerdida validaci√≥n: 0.5008325800299644\nExactitud validaci√≥n: 18.6261\n√âpoca 47\nPerdida entrenamiento: 0.40746283005265627\nPerdida validaci√≥n: 0.5021576881408691\nExactitud validaci√≥n: 18.4000\n√âpoca 48\nPerdida entrenamiento: 0.4073647067827337\nPerdida validaci√≥n: 0.4890240281820297\nExactitud validaci√≥n: 18.5130\n√âpoca 49\nPerdida entrenamiento: 0.40921850765452666\nPerdida validaci√≥n: 0.5141201466321945\nExactitud validaci√≥n: 18.4000\n√âpoca 50\nPerdida entrenamiento: 0.40371377503170686\nPerdida validaci√≥n: 0.5138585902750492\nExactitud validaci√≥n: 18.4000\n√âpoca 51\nPerdida entrenamiento: 0.40545569798525644\nPerdida validaci√≥n: 0.49403806775808334\nExactitud validaci√≥n: 18.7391\n√âpoca 52\nPerdida entrenamiento: 0.4029516472535975\nPerdida validaci√≥n: 0.4981403201818466\nExactitud validaci√≥n: 18.4000\n√âpoca 53\nPerdida entrenamiento: 0.40148040301659527\nPerdida validaci√≥n: 0.470258504152298\nExactitud validaci√≥n: 18.1739\n√âpoca 54\nPerdida entrenamiento: 0.4014539648504818\nPerdida validaci√≥n: 0.5071394890546799\nExactitud validaci√≥n: 18.5130\n√âpoca 55\nPerdida entrenamiento: 0.4001041352748871\nPerdida validaci√≥n: 0.5059882402420044\nExactitud validaci√≥n: 18.7391\n√âpoca 56\nPerdida entrenamiento: 0.398499013746486\nPerdida validaci√≥n: 0.465816680341959\nExactitud validaci√≥n: 18.1739\n√âpoca 57\nPerdida entrenamiento: 0.39581065318163705\nPerdida validaci√≥n: 0.4719567634165287\nExactitud validaci√≥n: 18.4000\n√âpoca 58\nPerdida entrenamiento: 0.3962685343097238\nPerdida validaci√≥n: 0.49108629673719406\nExactitud validaci√≥n: 17.9478\n√âpoca 59\nPerdida entrenamiento: 0.3972399699337342\nPerdida validaci√≥n: 0.5343546643853188\nExactitud validaci√≥n: 18.4000\n√âpoca 60\nPerdida entrenamiento: 0.39424481111414295\nPerdida validaci√≥n: 0.5204134956002235\nExactitud validaci√≥n: 18.0609\n√âpoca 61\nPerdida entrenamiento: 0.3933473562493044\nPerdida validaci√≥n: 0.48885199427604675\nExactitud validaci√≥n: 18.2870\n√âpoca 62\nPerdida entrenamiento: 0.39581848593319163\nPerdida validaci√≥n: 0.5045148134231567\nExactitud validaci√≥n: 18.6261\n√âpoca 63\nPerdida entrenamiento: 0.39225762381273155\nPerdida validaci√≥n: 0.49928755313158035\nExactitud validaci√≥n: 18.5130\n√âpoca 64\nPerdida entrenamiento: 0.39095135120784535\nPerdida validaci√≥n: 0.49818097054958344\nExactitud validaci√≥n: 18.4000\n√âpoca 65\nPerdida entrenamiento: 0.39278412917081046\nPerdida validaci√≥n: 0.51187414675951\nExactitud validaci√≥n: 18.4000\n√âpoca 66\nPerdida entrenamiento: 0.3880087408949347\nPerdida validaci√≥n: 0.5048925578594208\nExactitud validaci√≥n: 18.4000\n√âpoca 67\nPerdida entrenamiento: 0.3891824781894684\nPerdida validaci√≥n: 0.49526503682136536\nExactitud validaci√≥n: 18.6261\n√âpoca 68\nPerdida entrenamiento: 0.38694337185691385\nPerdida validaci√≥n: 0.520538330078125\nExactitud validaci√≥n: 18.7391\n√âpoca 69\nPerdida entrenamiento: 0.3850225508213043\nPerdida validaci√≥n: 0.4962310940027237\nExactitud validaci√≥n: 18.1739\n√âpoca 70\nPerdida entrenamiento: 0.3856160588124219\nPerdida validaci√≥n: 0.5117396265268326\nExactitud validaci√≥n: 18.6261\n√âpoca 71\nPerdida entrenamiento: 0.38290825836798725\nPerdida validaci√≥n: 0.48271531239151955\nExactitud validaci√≥n: 18.7391\n√âpoca 72\nPerdida entrenamiento: 0.3842119478127536\nPerdida validaci√≥n: 0.5159867852926254\nExactitud validaci√≥n: 18.1739\n√âpoca 73\nPerdida entrenamiento: 0.38493889570236206\nPerdida validaci√≥n: 0.5417948067188263\nExactitud validaci√≥n: 18.5130\n√âpoca 74\nPerdida entrenamiento: 0.38206734727410707\nPerdida validaci√≥n: 0.4967944473028183\nExactitud validaci√≥n: 18.4000\n√âpoca 75\nPerdida entrenamiento: 0.3789928336353863\nPerdida validaci√≥n: 0.518608808517456\nExactitud validaci√≥n: 18.5130\n√âpoca 76\nPerdida entrenamiento: 0.3797504796701319\nPerdida validaci√≥n: 0.5038291662931442\nExactitud validaci√≥n: 18.2870\n√âpoca 77\nPerdida entrenamiento: 0.3783522914437687\nPerdida validaci√≥n: 0.5356133580207825\nExactitud validaci√≥n: 18.1739\n√âpoca 78\nPerdida entrenamiento: 0.37765972754534555\nPerdida validaci√≥n: 0.5259551480412483\nExactitud validaci√≥n: 18.4000\n√âpoca 79\nPerdida entrenamiento: 0.3763415795915267\nPerdida validaci√≥n: 0.5199824124574661\nExactitud validaci√≥n: 18.0609\n√âpoca 80\nPerdida entrenamiento: 0.3773508159553303\nPerdida validaci√≥n: 0.49937019497156143\nExactitud validaci√≥n: 18.2870\n√âpoca 81\nPerdida entrenamiento: 0.37419071442940655\nPerdida validaci√≥n: 0.5143114551901817\nExactitud validaci√≥n: 18.6261\n√âpoca 82\nPerdida entrenamiento: 0.37580522544243755\nPerdida validaci√≥n: 0.5341081693768501\nExactitud validaci√≥n: 18.4000\n√âpoca 83\nPerdida entrenamiento: 0.3732707009595983\nPerdida validaci√≥n: 0.5355776324868202\nExactitud validaci√≥n: 18.6261\n√âpoca 84\nPerdida entrenamiento: 0.37286416923298554\nPerdida validaci√≥n: 0.5186856985092163\nExactitud validaci√≥n: 18.4000\n√âpoca 85\nPerdida entrenamiento: 0.3705448946532081\nPerdida validaci√≥n: 0.5483004599809647\nExactitud validaci√≥n: 18.4000\n√âpoca 86\nPerdida entrenamiento: 0.3727482636185253\nPerdida validaci√≥n: 0.5254365280270576\nExactitud validaci√≥n: 18.2870\n√âpoca 87\nPerdida entrenamiento: 0.3692259718390072\nPerdida validaci√≥n: 0.5111869126558304\nExactitud validaci√≥n: 18.5130\n√âpoca 88\nPerdida entrenamiento: 0.37127525315565224\nPerdida validaci√≥n: 0.5337236076593399\nExactitud validaci√≥n: 18.4000\n√âpoca 89\nPerdida entrenamiento: 0.37246738461887136\nPerdida validaci√≥n: 0.5206818729639053\nExactitud validaci√≥n: 18.1739\n√âpoca 90\nPerdida entrenamiento: 0.3690295158063664\nPerdida validaci√≥n: 0.5593036413192749\nExactitud validaci√≥n: 18.5130\n√âpoca 91\nPerdida entrenamiento: 0.369259593241355\nPerdida validaci√≥n: 0.5117775499820709\nExactitud validaci√≥n: 18.2870\n√âpoca 92\nPerdida entrenamiento: 0.3679639767198002\nPerdida validaci√≥n: 0.5290718674659729\nExactitud validaci√≥n: 18.4000\n√âpoca 93\nPerdida entrenamiento: 0.36736031928483176\nPerdida validaci√≥n: 0.5078761726617813\nExactitud validaci√≥n: 18.4000\n√âpoca 94\nPerdida entrenamiento: 0.3644753282561022\nPerdida validaci√≥n: 0.5632258951663971\nExactitud validaci√≥n: 18.7391\n√âpoca 95\nPerdida entrenamiento: 0.36306865776286407\nPerdida validaci√≥n: 0.5218587443232536\nExactitud validaci√≥n: 18.2870\n√âpoca 96\nPerdida entrenamiento: 0.3643888498053831\nPerdida validaci√≥n: 0.5354526937007904\nExactitud validaci√≥n: 18.2870\n√âpoca 97\nPerdida entrenamiento: 0.3653539445470361\nPerdida validaci√≥n: 0.51034265011549\nExactitud validaci√≥n: 18.4000\n√âpoca 98\nPerdida entrenamiento: 0.36249710707103505\nPerdida validaci√≥n: 0.5734138116240501\nExactitud validaci√≥n: 18.6261\n√âpoca 99\nPerdida entrenamiento: 0.36265045316780314\nPerdida validaci√≥n: 0.5656266584992409\nExactitud validaci√≥n: 18.7391\n√âpoca 100\nPerdida entrenamiento: 0.3610046874074375\nPerdida validaci√≥n: 0.521674856543541\nExactitud validaci√≥n: 18.2870\n√âpoca 101\nPerdida entrenamiento: 0.35992640081573934\nPerdida validaci√≥n: 0.5487679094076157\nExactitud validaci√≥n: 18.2870\n√âpoca 102\nPerdida entrenamiento: 0.3585259414771024\nPerdida validaci√≥n: 0.548629879951477\nExactitud validaci√≥n: 18.5130\n√âpoca 103\nPerdida entrenamiento: 0.35833654684178967\nPerdida validaci√≥n: 0.5379441231489182\nExactitud validaci√≥n: 18.4000\n√âpoca 104\nPerdida entrenamiento: 0.3592461680664736\nPerdida validaci√≥n: 0.543404832482338\nExactitud validaci√≥n: 18.4000\n√âpoca 105\nPerdida entrenamiento: 0.3567296178901897\nPerdida validaci√≥n: 0.5594352409243584\nExactitud validaci√≥n: 18.2870\n√âpoca 106\nPerdida entrenamiento: 0.3556781069320791\nPerdida validaci√≥n: 0.5586513355374336\nExactitud validaci√≥n: 18.4000\n√âpoca 107\nPerdida entrenamiento: 0.35517681609181795\nPerdida validaci√≥n: 0.5655415803194046\nExactitud validaci√≥n: 18.4000\n√âpoca 108\nPerdida entrenamiento: 0.35475079189328584\nPerdida validaci√≥n: 0.5609813407063484\nExactitud validaci√≥n: 18.8522\n√âpoca 109\nPerdida entrenamiento: 0.3557695606175591\nPerdida validaci√≥n: 0.5627079755067825\nExactitud validaci√≥n: 18.2870\n√âpoca 110\nPerdida entrenamiento: 0.3561686961089863\nPerdida validaci√≥n: 0.5387836992740631\nExactitud validaci√≥n: 18.4000\n√âpoca 111\nPerdida entrenamiento: 0.35163088756449085\nPerdida validaci√≥n: 0.5590721815824509\nExactitud validaci√≥n: 18.1739\n√âpoca 112\nPerdida entrenamiento: 0.35371597812456246\nPerdida validaci√≥n: 0.5587764009833336\nExactitud validaci√≥n: 18.2870\n√âpoca 113\nPerdida entrenamiento: 0.3535332837525536\nPerdida validaci√≥n: 0.5312048122286797\nExactitud validaci√≥n: 18.5130\n√âpoca 114\nPerdida entrenamiento: 0.35189832834636464\nPerdida validaci√≥n: 0.6044761911034584\nExactitud validaci√≥n: 18.8522\n√âpoca 115\nPerdida entrenamiento: 0.3514702092198765\nPerdida validaci√≥n: 0.5321017280220985\nExactitud validaci√≥n: 18.6261\n√âpoca 116\nPerdida entrenamiento: 0.351543351131327\nPerdida validaci√≥n: 0.5573963150382042\nExactitud validaci√≥n: 18.6261\n√âpoca 117\nPerdida entrenamiento: 0.3497464911026113\nPerdida validaci√≥n: 0.5573238208889961\nExactitud validaci√≥n: 18.4000\n√âpoca 118\nPerdida entrenamiento: 0.3498367386705735\nPerdida validaci√≥n: 0.5645684897899628\nExactitud validaci√≥n: 18.2870\n√âpoca 119\nPerdida entrenamiento: 0.35061120899284587\nPerdida validaci√≥n: 0.5626191198825836\nExactitud validaci√≥n: 18.5130\n√âpoca 120\nPerdida entrenamiento: 0.34882452558068666\nPerdida validaci√≥n: 0.5745996534824371\nExactitud validaci√≥n: 18.2870\n√âpoca 121\nPerdida entrenamiento: 0.3476862302597831\nPerdida validaci√≥n: 0.5468194410204887\nExactitud validaci√≥n: 18.4000\n√âpoca 122\nPerdida entrenamiento: 0.34637948432389426\nPerdida validaci√≥n: 0.533638957887888\nExactitud validaci√≥n: 17.9478\n√âpoca 123\nPerdida entrenamiento: 0.34753450838958516\nPerdida validaci√≥n: 0.5294349901378155\nExactitud validaci√≥n: 18.1739\n√âpoca 124\nPerdida entrenamiento: 0.3470301829716739\nPerdida validaci√≥n: 0.5638434365391731\nExactitud validaci√≥n: 18.4000\n√âpoca 125\nPerdida entrenamiento: 0.3439143107217901\nPerdida validaci√≥n: 0.5707154497504234\nExactitud validaci√≥n: 18.8522\n√âpoca 126\nPerdida entrenamiento: 0.34399966369656954\nPerdida validaci√≥n: 0.5750905275344849\nExactitud validaci√≥n: 18.5130\n√âpoca 127\nPerdida entrenamiento: 0.3459861094460768\nPerdida validaci√≥n: 0.5637594535946846\nExactitud validaci√≥n: 18.2870\n√âpoca 128\nPerdida entrenamiento: 0.3425804122405894\nPerdida validaci√≥n: 0.5966473817825317\nExactitud validaci√≥n: 18.7391\n√âpoca 129\nPerdida entrenamiento: 0.34382107065004464\nPerdida validaci√≥n: 0.5452658385038376\nExactitud validaci√≥n: 18.4000\n√âpoca 130\nPerdida entrenamiento: 0.3432043326251647\nPerdida validaci√≥n: 0.568010963499546\nExactitud validaci√≥n: 18.5130\n√âpoca 131\nPerdida entrenamiento: 0.34486333587590384\nPerdida validaci√≥n: 0.5764288678765297\nExactitud validaci√≥n: 18.4000\n√âpoca 132\nPerdida entrenamiento: 0.3452732370180242\nPerdida validaci√≥n: 0.5937597900629044\nExactitud validaci√≥n: 18.5130\n√âpoca 133\nPerdida entrenamiento: 0.343221268233131\nPerdida validaci√≥n: 0.6223113089799881\nExactitud validaci√≥n: 18.7391\n√âpoca 134\nPerdida entrenamiento: 0.3406377662630642\nPerdida validaci√≥n: 0.6121482476592064\nExactitud validaci√≥n: 18.7391\n√âpoca 135\nPerdida entrenamiento: 0.34228555770481334\nPerdida validaci√≥n: 0.5532180443406105\nExactitud validaci√≥n: 18.1739\n√âpoca 136\nPerdida entrenamiento: 0.3407059855320874\nPerdida validaci√≥n: 0.6256612241268158\nExactitud validaci√≥n: 18.6261\n√âpoca 137\nPerdida entrenamiento: 0.33841385210261626\nPerdida validaci√≥n: 0.6118277311325073\nExactitud validaci√≥n: 18.7391\n√âpoca 138\nPerdida entrenamiento: 0.3379518126740175\nPerdida validaci√≥n: 0.5608039274811745\nExactitud validaci√≥n: 18.4000\n√âpoca 139\nPerdida entrenamiento: 0.33698144818053527\nPerdida validaci√≥n: 0.6184676513075829\nExactitud validaci√≥n: 18.6261\n√âpoca 140\nPerdida entrenamiento: 0.3397687033695333\nPerdida validaci√≥n: 0.6316100880503654\nExactitud validaci√≥n: 18.5130\n√âpoca 141\nPerdida entrenamiento: 0.33633708515587973\nPerdida validaci√≥n: 0.5819898918271065\nExactitud validaci√≥n: 18.6261\n√âpoca 142\nPerdida entrenamiento: 0.33748694290133086\nPerdida validaci√≥n: 0.6265446171164513\nExactitud validaci√≥n: 18.1739\n√âpoca 143\nPerdida entrenamiento: 0.3356994197649114\nPerdida validaci√≥n: 0.6239243969321251\nExactitud validaci√≥n: 18.4000\n√âpoca 144\nPerdida entrenamiento: 0.33472176159129424\nPerdida validaci√≥n: 0.6359140202403069\nExactitud validaci√≥n: 18.4000\n√âpoca 145\nPerdida entrenamiento: 0.3353544543771183\nPerdida validaci√≥n: 0.623450018465519\nExactitud validaci√≥n: 18.4000\n√âpoca 146\nPerdida entrenamiento: 0.33618306412416343\nPerdida validaci√≥n: 0.5927932560443878\nExactitud validaci√≥n: 18.0609\n√âpoca 147\nPerdida entrenamiento: 0.3340167955440633\nPerdida validaci√≥n: 0.6286558359861374\nExactitud validaci√≥n: 18.6261\n√âpoca 148\nPerdida entrenamiento: 0.33400292519260855\nPerdida validaci√≥n: 0.6745086014270782\nExactitud validaci√≥n: 18.1739\n√âpoca 149\nPerdida entrenamiento: 0.3350304067134857\nPerdida validaci√≥n: 0.6481637880206108\nExactitud validaci√≥n: 18.5130\n√âpoca 150\nPerdida entrenamiento: 0.3336921281674329\nPerdida validaci√≥n: 0.6298792809247971\nExactitud validaci√≥n: 18.7391\n√âpoca 151\nPerdida entrenamiento: 0.3350611933890511\nPerdida validaci√≥n: 0.5883950218558311\nExactitud validaci√≥n: 18.0609\n√âpoca 152\nPerdida entrenamiento: 0.3336448108448702\nPerdida validaci√≥n: 0.6367370784282684\nExactitud validaci√≥n: 18.5130\n√âpoca 153\nPerdida entrenamiento: 0.3326067302156897\nPerdida validaci√≥n: 0.6520734950900078\nExactitud validaci√≥n: 18.2870\n√âpoca 154\nPerdida entrenamiento: 0.3309824501766878\nPerdida validaci√≥n: 0.6116059124469757\nExactitud validaci√≥n: 18.2870\n√âpoca 155\nPerdida entrenamiento: 0.3331507540800992\nPerdida validaci√≥n: 0.590815544128418\nExactitud validaci√≥n: 18.5130\n√âpoca 156\nPerdida entrenamiento: 0.33216743872446175\nPerdida validaci√≥n: 0.6476473957300186\nExactitud validaci√≥n: 18.2870\n√âpoca 157\nPerdida entrenamiento: 0.3311873867231257\nPerdida validaci√≥n: 0.6468140035867691\nExactitud validaci√≥n: 18.0609\n√âpoca 158\nPerdida entrenamiento: 0.32796593273387237\nPerdida validaci√≥n: 0.6146449446678162\nExactitud validaci√≥n: 18.1739\n√âpoca 159\nPerdida entrenamiento: 0.33034057389287386\nPerdida validaci√≥n: 0.6230598539113998\nExactitud validaci√≥n: 18.5130\n√âpoca 160\nPerdida entrenamiento: 0.3273730260484359\nPerdida validaci√≥n: 0.6443871557712555\nExactitud validaci√≥n: 18.4000\n√âpoca 161\nPerdida entrenamiento: 0.330964570536333\nPerdida validaci√≥n: 0.6126606613397598\nExactitud validaci√≥n: 18.6261\n√âpoca 162\nPerdida entrenamiento: 0.33085155487060547\nPerdida validaci√≥n: 0.6176680326461792\nExactitud validaci√≥n: 18.5130\n√âpoca 163\nPerdida entrenamiento: 0.32789769067483787\nPerdida validaci√≥n: 0.5946464017033577\nExactitud validaci√≥n: 18.5130\n√âpoca 164\nPerdida entrenamiento: 0.3267712610609391\nPerdida validaci√≥n: 0.6227770447731018\nExactitud validaci√≥n: 18.2870\n√âpoca 165\nPerdida entrenamiento: 0.3263696502236759\nPerdida validaci√≥n: 0.6890445426106453\nExactitud validaci√≥n: 18.2870\n√âpoca 166\nPerdida entrenamiento: 0.3250192473916447\nPerdida validaci√≥n: 0.6499665081501007\nExactitud validaci√≥n: 18.5130\n√âpoca 167\nPerdida entrenamiento: 0.3261696854058434\nPerdida validaci√≥n: 0.6132025644183159\nExactitud validaci√≥n: 18.2870\n√âpoca 168\nPerdida entrenamiento: 0.3261833287337247\nPerdida validaci√≥n: 0.6634091883897781\nExactitud validaci√≥n: 18.5130\n√âpoca 169\nPerdida entrenamiento: 0.32349429411046643\nPerdida validaci√≥n: 0.6630931124091148\nExactitud validaci√≥n: 18.6261\n√âpoca 170\nPerdida entrenamiento: 0.3271436393260956\nPerdida validaci√≥n: 0.612961657345295\nExactitud validaci√≥n: 18.5130\n√âpoca 171\nPerdida entrenamiento: 0.32476263098856983\nPerdida validaci√≥n: 0.6598226502537727\nExactitud validaci√≥n: 18.2870\n√âpoca 172\nPerdida entrenamiento: 0.324515997486956\nPerdida validaci√≥n: 0.6418932229280472\nExactitud validaci√≥n: 18.4000\n√âpoca 173\nPerdida entrenamiento: 0.32433526919168587\nPerdida validaci√≥n: 0.7335801050066948\nExactitud validaci√≥n: 18.2870\n√âpoca 174\nPerdida entrenamiento: 0.3219207516487907\nPerdida validaci√≥n: 0.653811901807785\nExactitud validaci√≥n: 18.2870\n√âpoca 175\nPerdida entrenamiento: 0.3205060888739193\nPerdida validaci√≥n: 0.6664783358573914\nExactitud validaci√≥n: 18.5130\n√âpoca 176\nPerdida entrenamiento: 0.3207370875512852\nPerdida validaci√≥n: 0.6229857131838799\nExactitud validaci√≥n: 18.0609\n√âpoca 177\nPerdida entrenamiento: 0.3227768680628608\nPerdida validaci√≥n: 0.6437440887093544\nExactitud validaci√≥n: 18.2870\n√âpoca 178\nPerdida entrenamiento: 0.3209051349583794\nPerdida validaci√≥n: 0.6665943264961243\nExactitud validaci√≥n: 18.4000\n√âpoca 179\nPerdida entrenamiento: 0.32111615643781777\nPerdida validaci√≥n: 0.6589837148785591\nExactitud validaci√≥n: 18.5130\n√âpoca 180\nPerdida entrenamiento: 0.3208710200646344\nPerdida validaci√≥n: 0.6451635211706161\nExactitud validaci√≥n: 18.4000\n√âpoca 181\nPerdida entrenamiento: 0.3188728216816397\nPerdida validaci√≥n: 0.6509027481079102\nExactitud validaci√≥n: 18.4000\n√âpoca 182\nPerdida entrenamiento: 0.3178029682706384\nPerdida validaci√≥n: 0.6660331636667252\nExactitud validaci√≥n: 18.2870\n√âpoca 183\nPerdida entrenamiento: 0.31673886320170236\nPerdida validaci√≥n: 0.6581268012523651\nExactitud validaci√≥n: 18.2870\n√âpoca 184\nPerdida entrenamiento: 0.31750109002870675\nPerdida validaci√≥n: 0.6372020319104195\nExactitud validaci√≥n: 18.5130\n√âpoca 185\nPerdida entrenamiento: 0.31816011930213256\nPerdida validaci√≥n: 0.7313763499259949\nExactitud validaci√≥n: 18.4000\n√âpoca 186\nPerdida entrenamiento: 0.3156069096396951\nPerdida validaci√≥n: 0.6771089732646942\nExactitud validaci√≥n: 18.4000\n√âpoca 187\nPerdida entrenamiento: 0.31772204532342796\nPerdida validaci√≥n: 0.6511183455586433\nExactitud validaci√≥n: 18.4000\n√âpoca 188\nPerdida entrenamiento: 0.31324949685265036\nPerdida validaci√≥n: 0.6433937773108482\nExactitud validaci√≥n: 18.1739\n√âpoca 189\nPerdida entrenamiento: 0.31725497894427357\nPerdida validaci√≥n: 0.68333500623703\nExactitud validaci√≥n: 18.1739\n√âpoca 190\nPerdida entrenamiento: 0.3123554464648752\nPerdida validaci√≥n: 0.6660071387887001\nExactitud validaci√≥n: 18.8522\n√âpoca 191\nPerdida entrenamiento: 0.3153311452444862\nPerdida validaci√≥n: 0.7063699811697006\nExactitud validaci√≥n: 18.7391\n√âpoca 192\nPerdida entrenamiento: 0.31404705433284535\nPerdida validaci√≥n: 0.6741388291120529\nExactitud validaci√≥n: 18.7391\n√âpoca 193\nPerdida entrenamiento: 0.31402675632168264\nPerdida validaci√≥n: 0.6543318554759026\nExactitud validaci√≥n: 18.1739\n√âpoca 194\nPerdida entrenamiento: 0.3119946630562053\nPerdida validaci√≥n: 0.6574038416147232\nExactitud validaci√≥n: 18.5130\n√âpoca 195\nPerdida entrenamiento: 0.3136322226594476\nPerdida validaci√≥n: 0.7180648446083069\nExactitud validaci√≥n: 18.2870\n√âpoca 196\nPerdida entrenamiento: 0.3097478344159968\nPerdida validaci√≥n: 0.6812009885907173\nExactitud validaci√≥n: 18.2870\n√âpoca 197\nPerdida entrenamiento: 0.3116472389768152\nPerdida validaci√≥n: 0.6507846117019653\nExactitud validaci√≥n: 18.4000\n√âpoca 198\nPerdida entrenamiento: 0.31110472188276406\nPerdida validaci√≥n: 0.6414782479405403\nExactitud validaci√≥n: 18.2870\n√âpoca 199\nPerdida entrenamiento: 0.3103514997398152\nPerdida validaci√≥n: 0.6524050757288933\nExactitud validaci√≥n: 18.4000\n√âpoca 200\nPerdida entrenamiento: 0.31179756802671094\nPerdida validaci√≥n: 0.6920239329338074\nExactitud validaci√≥n: 18.7391\n√âpoca 201\nPerdida entrenamiento: 0.3084581047296524\nPerdida validaci√≥n: 0.764978215098381\nExactitud validaci√≥n: 18.0609\n√âpoca 202\nPerdida entrenamiento: 0.30916617986033945\nPerdida validaci√≥n: 0.7176909744739532\nExactitud validaci√≥n: 18.4000\n√âpoca 203\nPerdida entrenamiento: 0.3087397515773773\nPerdida validaci√≥n: 0.7063323929905891\nExactitud validaci√≥n: 18.2870\n√âpoca 204\nPerdida entrenamiento: 0.3106594672974418\nPerdida validaci√≥n: 0.6954813897609711\nExactitud validaci√≥n: 18.4000\n√âpoca 205\nPerdida entrenamiento: 0.30759740226409016\nPerdida validaci√≥n: 0.7038579732179642\nExactitud validaci√≥n: 18.1739\n√âpoca 206\nPerdida entrenamiento: 0.3062534963383394\nPerdida validaci√≥n: 0.7156248390674591\nExactitud validaci√≥n: 18.2870\n√âpoca 207\nPerdida entrenamiento: 0.30647197278106914\nPerdida validaci√≥n: 0.688948281109333\nExactitud validaci√≥n: 18.5130\n√âpoca 208\nPerdida entrenamiento: 0.3078196758733076\nPerdida validaci√≥n: 0.692335918545723\nExactitud validaci√≥n: 18.6261\n√âpoca 209\nPerdida entrenamiento: 0.30704403011237874\nPerdida validaci√≥n: 0.6741050034761429\nExactitud validaci√≥n: 17.9478\n√âpoca 210\nPerdida entrenamiento: 0.30527643508770885\nPerdida validaci√≥n: 0.6659369245171547\nExactitud validaci√≥n: 18.5130\n√âpoca 211\nPerdida entrenamiento: 0.3071153356748469\nPerdida validaci√≥n: 0.7391846030950546\nExactitud validaci√≥n: 18.6261\n√âpoca 212\nPerdida entrenamiento: 0.30531730371363025\nPerdida validaci√≥n: 0.7998167648911476\nExactitud validaci√≥n: 18.5130\n√âpoca 213\nPerdida entrenamiento: 0.3038189893259722\nPerdida validaci√≥n: 0.7052174434065819\nExactitud validaci√≥n: 17.9478\n√âpoca 214\nPerdida entrenamiento: 0.30341966976137724\nPerdida validaci√≥n: 0.7350720167160034\nExactitud validaci√≥n: 18.5130\n√âpoca 215\nPerdida entrenamiento: 0.30246863645665784\nPerdida validaci√≥n: 0.7088495343923569\nExactitud validaci√≥n: 18.5130\n√âpoca 216\nPerdida entrenamiento: 0.30353131013758045\nPerdida validaci√≥n: 0.6834466755390167\nExactitud validaci√≥n: 18.6261\n√âpoca 217\nPerdida entrenamiento: 0.30161605074125175\nPerdida validaci√≥n: 0.7241852506995201\nExactitud validaci√≥n: 17.9478\n√âpoca 218\nPerdida entrenamiento: 0.3025359528906205\nPerdida validaci√≥n: 0.6786011755466461\nExactitud validaci√≥n: 18.1739\n√âpoca 219\nPerdida entrenamiento: 0.3013206886894563\nPerdida validaci√≥n: 0.679993025958538\nExactitud validaci√≥n: 18.5130\n√âpoca 220\nPerdida entrenamiento: 0.3010849926401587\nPerdida validaci√≥n: 0.8055609986186028\nExactitud validaci√≥n: 18.7391\n√âpoca 221\nPerdida entrenamiento: 0.299965525374693\nPerdida validaci√≥n: 0.6772769540548325\nExactitud validaci√≥n: 18.4000\n√âpoca 222\nPerdida entrenamiento: 0.3033907431013444\nPerdida validaci√≥n: 0.736585833132267\nExactitud validaci√≥n: 18.5130\n√âpoca 223\nPerdida entrenamiento: 0.3007599991910598\nPerdida validaci√≥n: 0.7596707493066788\nExactitud validaci√≥n: 18.2870\n√âpoca 224\nPerdida entrenamiento: 0.30001555558513193\nPerdida validaci√≥n: 0.6992309913039207\nExactitud validaci√≥n: 18.2870\n√âpoca 225\nPerdida entrenamiento: 0.2969650775194168\nPerdida validaci√≥n: 0.7044773250818253\nExactitud validaci√≥n: 18.2870\n√âpoca 226\nPerdida entrenamiento: 0.29871873557567596\nPerdida validaci√≥n: 0.6746115535497665\nExactitud validaci√≥n: 18.5130\n√âpoca 227\nPerdida entrenamiento: 0.2973190230481765\nPerdida validaci√≥n: 0.684038981795311\nExactitud validaci√≥n: 18.4000\n√âpoca 228\nPerdida entrenamiento: 0.2981330340399462\nPerdida validaci√≥n: 0.7490448206663132\nExactitud validaci√≥n: 18.8522\n√âpoca 229\nPerdida entrenamiento: 0.29559924935593324\nPerdida validaci√≥n: 0.694603718817234\nExactitud validaci√≥n: 18.4000\n√âpoca 230\nPerdida entrenamiento: 0.2944230069132412\nPerdida validaci√≥n: 0.7294625043869019\nExactitud validaci√≥n: 18.5130\n√âpoca 231\nPerdida entrenamiento: 0.29362457640030803\nPerdida validaci√≥n: 0.7362787425518036\nExactitud validaci√≥n: 18.6261\n√âpoca 232\nPerdida entrenamiento: 0.294377674074734\nPerdida validaci√≥n: 0.7065712809562683\nExactitud validaci√≥n: 18.5130\n√âpoca 233\nPerdida entrenamiento: 0.29613833129405975\nPerdida validaci√≥n: 0.7128828167915344\nExactitud validaci√≥n: 18.2870\n√âpoca 234\nPerdida entrenamiento: 0.29697078904684854\nPerdida validaci√≥n: 0.7355586439371109\nExactitud validaci√≥n: 18.2870\n√âpoca 235\nPerdida entrenamiento: 0.2928716233547996\nPerdida validaci√≥n: 0.8148213103413582\nExactitud validaci√≥n: 18.7391\n√âpoca 236\nPerdida entrenamiento: 0.2956160175449708\nPerdida validaci√≥n: 0.7032250016927719\nExactitud validaci√≥n: 18.5130\n√âpoca 237\nPerdida entrenamiento: 0.29322683942668576\nPerdida validaci√≥n: 0.7366586253046989\nExactitud validaci√≥n: 18.6261\n√âpoca 238\nPerdida entrenamiento: 0.29531940730179057\nPerdida validaci√≥n: 0.716269001364708\nExactitud validaci√≥n: 18.2870\n√âpoca 239\nPerdida entrenamiento: 0.29456058582838845\nPerdida validaci√≥n: 0.8046405576169491\nExactitud validaci√≥n: 18.6261\n√âpoca 240\nPerdida entrenamiento: 0.2919597485486199\nPerdida validaci√≥n: 0.7698554992675781\nExactitud validaci√≥n: 18.1739\n√âpoca 241\nPerdida entrenamiento: 0.2926513622788822\nPerdida validaci√≥n: 0.6973117738962173\nExactitud validaci√≥n: 18.7391\n√âpoca 242\nPerdida entrenamiento: 0.2892984853071325\nPerdida validaci√≥n: 0.7638273388147354\nExactitud validaci√≥n: 18.4000\n√âpoca 243\nPerdida entrenamiento: 0.29051580937469706\nPerdida validaci√≥n: 0.7815098166465759\nExactitud validaci√≥n: 18.7391\n√âpoca 244\nPerdida entrenamiento: 0.2899246417424258\nPerdida validaci√≥n: 0.7704179286956787\nExactitud validaci√≥n: 18.1739\n√âpoca 245\nPerdida entrenamiento: 0.28837614375002246\nPerdida validaci√≥n: 0.7450488656759262\nExactitud validaci√≥n: 18.4000\n√âpoca 246\nPerdida entrenamiento: 0.29001492174232707\nPerdida validaci√≥n: 0.7398979514837265\nExactitud validaci√≥n: 18.1739\n√âpoca 247\nPerdida entrenamiento: 0.28900785919497995\nPerdida validaci√≥n: 0.7784785479307175\nExactitud validaci√≥n: 18.0609\n√âpoca 248\nPerdida entrenamiento: 0.28841665474807515\nPerdida validaci√≥n: 0.7403790205717087\nExactitud validaci√≥n: 18.5130\n√âpoca 249\nPerdida entrenamiento: 0.2894595230326933\nPerdida validaci√≥n: 0.7213053703308105\nExactitud validaci√≥n: 18.2870\n√âpoca 250\nPerdida entrenamiento: 0.2888253462665221\nPerdida validaci√≥n: 0.766401544213295\nExactitud validaci√≥n: 18.2870\n√âpoca 251\nPerdida entrenamiento: 0.2866971107090221\nPerdida validaci√≥n: 0.7406387180089951\nExactitud validaci√≥n: 18.5130\n√âpoca 252\nPerdida entrenamiento: 0.2872468583724078\nPerdida validaci√≥n: 0.7808045633137226\nExactitud validaci√≥n: 18.5130\n√âpoca 253\nPerdida entrenamiento: 0.2877846333910437\nPerdida validaci√≥n: 0.7809512466192245\nExactitud validaci√≥n: 18.4000\n√âpoca 254\nPerdida entrenamiento: 0.2867770826115328\nPerdida validaci√≥n: 0.7319426983594894\nExactitud validaci√≥n: 18.1739\n√âpoca 255\nPerdida entrenamiento: 0.28648798080051646\nPerdida validaci√≥n: 0.7230148687958717\nExactitud validaci√≥n: 18.4000\n√âpoca 256\nPerdida entrenamiento: 0.2846994154593524\nPerdida validaci√≥n: 0.7592649683356285\nExactitud validaci√≥n: 18.4000\n√âpoca 257\nPerdida entrenamiento: 0.2864809036254883\nPerdida validaci√≥n: 0.7423518821597099\nExactitud validaci√≥n: 18.2870\n√âpoca 258\nPerdida entrenamiento: 0.2850097224992864\nPerdida validaci√≥n: 0.8285829573869705\nExactitud validaci√≥n: 18.2870\n√âpoca 259\nPerdida entrenamiento: 0.2860611309023464\nPerdida validaci√≥n: 0.7817785143852234\nExactitud validaci√≥n: 18.5130\n√âpoca 260\nPerdida entrenamiento: 0.28397778027197895\nPerdida validaci√≥n: 0.7759557962417603\nExactitud validaci√≥n: 18.1739\n√âpoca 261\nPerdida entrenamiento: 0.2851453958188786\nPerdida validaci√≥n: 0.773240715265274\nExactitud validaci√≥n: 18.1739\n√âpoca 262\nPerdida entrenamiento: 0.28346505322877097\nPerdida validaci√≥n: 0.8145815879106522\nExactitud validaci√≥n: 18.4000\n√âpoca 263\nPerdida entrenamiento: 0.2839648855083129\nPerdida validaci√≥n: 0.8247283324599266\nExactitud validaci√≥n: 18.2870\n√âpoca 264\nPerdida entrenamiento: 0.2820875758633894\nPerdida validaci√≥n: 0.7470234334468842\nExactitud validaci√≥n: 18.1739\n√âpoca 265\nPerdida entrenamiento: 0.2828727487255545\nPerdida validaci√≥n: 0.7517593279480934\nExactitud validaci√≥n: 18.4000\n√âpoca 266\nPerdida entrenamiento: 0.28342335364397836\nPerdida validaci√≥n: 0.745085820555687\nExactitud validaci√≥n: 18.0609\n√âpoca 267\nPerdida entrenamiento: 0.28173114271724925\nPerdida validaci√≥n: 0.8318959027528763\nExactitud validaci√≥n: 18.5130\n√âpoca 268\nPerdida entrenamiento: 0.28258827241028056\nPerdida validaci√≥n: 0.7550449594855309\nExactitud validaci√≥n: 18.5130\n√âpoca 269\nPerdida entrenamiento: 0.2806198824854458\nPerdida validaci√≥n: 0.815860778093338\nExactitud validaci√≥n: 17.9478\n√âpoca 270\nPerdida entrenamiento: 0.2798441560829387\nPerdida validaci√≥n: 0.8292346000671387\nExactitud validaci√≥n: 18.7391\n√âpoca 271\nPerdida entrenamiento: 0.28328849813517404\nPerdida validaci√≥n: 0.84027498960495\nExactitud validaci√≥n: 17.9478\n√âpoca 272\nPerdida entrenamiento: 0.27925308399340687\nPerdida validaci√≥n: 0.8446707427501678\nExactitud validaci√≥n: 18.5130\n√âpoca 273\nPerdida entrenamiento: 0.279740308137501\nPerdida validaci√≥n: 0.7891214042901993\nExactitud validaci√≥n: 18.4000\n√âpoca 274\nPerdida entrenamiento: 0.2804296621504952\nPerdida validaci√≥n: 0.7523273676633835\nExactitud validaci√≥n: 18.6261\n√âpoca 275\nPerdida entrenamiento: 0.2786500278641196\nPerdida validaci√≥n: 0.8763114959001541\nExactitud validaci√≥n: 18.5130\n√âpoca 276\nPerdida entrenamiento: 0.2789465942803551\nPerdida validaci√≥n: 0.7518940791487694\nExactitud validaci√≥n: 18.4000\n√âpoca 277\nPerdida entrenamiento: 0.2798019025255652\nPerdida validaci√≥n: 0.8489273488521576\nExactitud validaci√≥n: 18.7391\n√âpoca 278\nPerdida entrenamiento: 0.280226955519003\nPerdida validaci√≥n: 0.766749732196331\nExactitud validaci√≥n: 18.5130\n√âpoca 279\nPerdida entrenamiento: 0.2779183343929403\nPerdida validaci√≥n: 0.7820227146148682\nExactitud validaci√≥n: 18.4000\n√âpoca 280\nPerdida entrenamiento: 0.2765612396247247\nPerdida validaci√≥n: 0.7857282161712646\nExactitud validaci√≥n: 18.4000\n√âpoca 281\nPerdida entrenamiento: 0.27886566169121685\nPerdida validaci√≥n: 0.8160237297415733\nExactitud validaci√≥n: 18.6261\n√âpoca 282\nPerdida entrenamiento: 0.2769961637609145\nPerdida validaci√≥n: 0.8009995818138123\nExactitud validaci√≥n: 18.5130\n√âpoca 283\nPerdida entrenamiento: 0.2754744019578485\nPerdida validaci√≥n: 0.8242090195417404\nExactitud validaci√≥n: 18.2870\n√âpoca 284\nPerdida entrenamiento: 0.27566534894354205\nPerdida validaci√≥n: 0.8263423070311546\nExactitud validaci√≥n: 18.4000\n√âpoca 285\nPerdida entrenamiento: 0.275710387264981\nPerdida validaci√≥n: 0.7984395027160645\nExactitud validaci√≥n: 18.7391\n√âpoca 286\nPerdida entrenamiento: 0.2722511160023072\nPerdida validaci√≥n: 0.7776636183261871\nExactitud validaci√≥n: 18.7391\n√âpoca 287\nPerdida entrenamiento: 0.2785680565763922\nPerdida validaci√≥n: 0.8693821281194687\nExactitud validaci√≥n: 18.1739\n√âpoca 288\nPerdida entrenamiento: 0.2776385243324673\nPerdida validaci√≥n: 0.8111721277236938\nExactitud validaci√≥n: 18.5130\n√âpoca 289\nPerdida entrenamiento: 0.2753101648653255\nPerdida validaci√≥n: 0.7979157716035843\nExactitud validaci√≥n: 18.6261\n√âpoca 290\nPerdida entrenamiento: 0.2721212304690305\nPerdida validaci√≥n: 0.8984339684247971\nExactitud validaci√≥n: 18.1739\n√âpoca 291\nPerdida entrenamiento: 0.27208081150756164\nPerdida validaci√≥n: 0.8066085278987885\nExactitud validaci√≥n: 18.0609\n√âpoca 292\nPerdida entrenamiento: 0.2724810707218507\nPerdida validaci√≥n: 0.858610674738884\nExactitud validaci√≥n: 18.1739\n√âpoca 293\nPerdida entrenamiento: 0.2749691465321709\nPerdida validaci√≥n: 0.8009930029511452\nExactitud validaci√≥n: 18.4000\n√âpoca 294\nPerdida entrenamiento: 0.2745845510679133\nPerdida validaci√≥n: 0.8322249576449394\nExactitud validaci√≥n: 18.6261\n√âpoca 295\nPerdida entrenamiento: 0.27191179903114543\nPerdida validaci√≥n: 0.8544426411390305\nExactitud validaci√≥n: 18.5130\n√âpoca 296\nPerdida entrenamiento: 0.2718319112763685\nPerdida validaci√≥n: 0.7973638772964478\nExactitud validaci√≥n: 18.2870\n√âpoca 297\nPerdida entrenamiento: 0.27322857257197886\nPerdida validaci√≥n: 0.8390850126743317\nExactitud validaci√≥n: 18.2870\n√âpoca 298\nPerdida entrenamiento: 0.2706087967928718\nPerdida validaci√≥n: 0.8332074135541916\nExactitud validaci√≥n: 18.2870\n√âpoca 299\nPerdida entrenamiento: 0.27064647394068103\nPerdida validaci√≥n: 0.7855604067444801\nExactitud validaci√≥n: 18.6261\n√âpoca 300\nPerdida entrenamiento: 0.27028607620912437\nPerdida validaci√≥n: 0.844075620174408\nExactitud validaci√≥n: 18.5130\n√âpoca 301\nPerdida entrenamiento: 0.27047083395368915\nPerdida validaci√≥n: 0.7950586900115013\nExactitud validaci√≥n: 18.7391\n√âpoca 302\nPerdida entrenamiento: 0.2688707393758437\nPerdida validaci√≥n: 0.8446274772286415\nExactitud validaci√≥n: 18.4000\n√âpoca 303\nPerdida entrenamiento: 0.27010226337348714\nPerdida validaci√≥n: 0.8923372030258179\nExactitud validaci√≥n: 18.1739\n√âpoca 304\nPerdida entrenamiento: 0.26951658988700194\nPerdida validaci√≥n: 0.8144352659583092\nExactitud validaci√≥n: 18.7391\n√âpoca 305\nPerdida entrenamiento: 0.2690744391259025\nPerdida validaci√≥n: 0.9116105735301971\nExactitud validaci√≥n: 18.4000\n√âpoca 306\nPerdida entrenamiento: 0.26870520588229685\nPerdida validaci√≥n: 0.8943951576948166\nExactitud validaci√≥n: 18.6261\n√âpoca 307\nPerdida entrenamiento: 0.27256863783387575\nPerdida validaci√≥n: 0.9162701666355133\nExactitud validaci√≥n: 18.2870\n√âpoca 308\nPerdida entrenamiento: 0.26849985648604\nPerdida validaci√≥n: 0.8575167655944824\nExactitud validaci√≥n: 18.1739\n√âpoca 309\nPerdida entrenamiento: 0.2659115265397465\nPerdida validaci√≥n: 0.8369210362434387\nExactitud validaci√≥n: 18.9652\n√âpoca 310\nPerdida entrenamiento: 0.26523913004819083\nPerdida validaci√≥n: 0.8102370351552963\nExactitud validaci√≥n: 18.5130\n√âpoca 311\nPerdida entrenamiento: 0.26695583322468924\nPerdida validaci√≥n: 0.8106616139411926\nExactitud validaci√≥n: 18.5130\n√âpoca 312\nPerdida entrenamiento: 0.26486619518083687\nPerdida validaci√≥n: 0.862990252673626\nExactitud validaci√≥n: 18.7391\n√âpoca 313\nPerdida entrenamiento: 0.2670781770173241\nPerdida validaci√≥n: 0.9409219324588776\nExactitud validaci√≥n: 18.2870\n√âpoca 314\nPerdida entrenamiento: 0.26387015773969535\nPerdida validaci√≥n: 0.8297825679183006\nExactitud validaci√≥n: 18.5130\n√âpoca 315\nPerdida entrenamiento: 0.2630258443600991\nPerdida validaci√≥n: 0.8401200473308563\nExactitud validaci√≥n: 18.6261\n√âpoca 316\nPerdida entrenamiento: 0.26609305248540993\nPerdida validaci√≥n: 0.8802365660667419\nExactitud validaci√≥n: 18.4000\n√âpoca 317\nPerdida entrenamiento: 0.26455171406269073\nPerdida validaci√≥n: 0.85386922955513\nExactitud validaci√≥n: 18.7391\n√âpoca 318\nPerdida entrenamiento: 0.2650342899210313\nPerdida validaci√≥n: 0.913348600268364\nExactitud validaci√≥n: 18.6261\n√âpoca 319\nPerdida entrenamiento: 0.2632635078009437\nPerdida validaci√≥n: 0.8332754224538803\nExactitud validaci√≥n: 18.6261\n√âpoca 320\nPerdida entrenamiento: 0.2620505313662922\nPerdida validaci√≥n: 0.8459868878126144\nExactitud validaci√≥n: 18.1739\n√âpoca 321\nPerdida entrenamiento: 0.2629975974559784\nPerdida validaci√≥n: 0.96159228682518\nExactitud validaci√≥n: 18.8522\n√âpoca 322\nPerdida entrenamiento: 0.26157911384806914\nPerdida validaci√≥n: 0.8396739363670349\nExactitud validaci√≥n: 18.6261\n√âpoca 323\nPerdida entrenamiento: 0.2618062881862416\nPerdida validaci√≥n: 0.8706338852643967\nExactitud validaci√≥n: 18.1739\n√âpoca 324\nPerdida entrenamiento: 0.26290398397866416\nPerdida validaci√≥n: 0.9644896686077118\nExactitud validaci√≥n: 18.6261\n√âpoca 325\nPerdida entrenamiento: 0.2609732878558776\nPerdida validaci√≥n: 0.9126636236906052\nExactitud validaci√≥n: 18.0609\n√âpoca 326\nPerdida entrenamiento: 0.26105780110639687\nPerdida validaci√≥n: 0.9232337772846222\nExactitud validaci√≥n: 18.1739\n√âpoca 327\nPerdida entrenamiento: 0.26264332410167246\nPerdida validaci√≥n: 0.8974900245666504\nExactitud validaci√≥n: 18.4000\n√âpoca 328\nPerdida entrenamiento: 0.2613668257699293\nPerdida validaci√≥n: 0.8862783759832382\nExactitud validaci√≥n: 18.4000\n√âpoca 329\nPerdida entrenamiento: 0.25836709930616264\nPerdida validaci√≥n: 0.8626670092344284\nExactitud validaci√≥n: 18.5130\n√âpoca 330\nPerdida entrenamiento: 0.25922364522429076\nPerdida validaci√≥n: 0.8830067962408066\nExactitud validaci√≥n: 18.4000\n√âpoca 331\nPerdida entrenamiento: 0.26386993597535524\nPerdida validaci√≥n: 0.8540544435381889\nExactitud validaci√≥n: 18.2870\n√âpoca 332\nPerdida entrenamiento: 0.2593020134988953\nPerdida validaci√≥n: 0.9039890021085739\nExactitud validaci√≥n: 18.6261\n√âpoca 333\nPerdida entrenamiento: 0.2595018516568577\nPerdida validaci√≥n: 0.8899291157722473\nExactitud validaci√≥n: 17.9478\n√âpoca 334\nPerdida entrenamiento: 0.25665878986611085\nPerdida validaci√≥n: 0.8394737765192986\nExactitud validaci√≥n: 18.5130\n√âpoca 335\nPerdida entrenamiento: 0.25748301604214835\nPerdida validaci√≥n: 0.9290647059679031\nExactitud validaci√≥n: 18.7391\n√âpoca 336\nPerdida entrenamiento: 0.2590382677667281\nPerdida validaci√≥n: 0.8649090602993965\nExactitud validaci√≥n: 18.2870\n√âpoca 337\nPerdida entrenamiento: 0.2554243496235679\nPerdida validaci√≥n: 0.9593407809734344\nExactitud validaci√≥n: 18.7391\n√âpoca 338\nPerdida entrenamiento: 0.25691094906891093\nPerdida validaci√≥n: 0.9706677794456482\nExactitud validaci√≥n: 18.2870\n√âpoca 339\nPerdida entrenamiento: 0.25731626678915587\nPerdida validaci√≥n: 0.9453080892562866\nExactitud validaci√≥n: 18.6261\n√âpoca 340\nPerdida entrenamiento: 0.25507257659645644\nPerdida validaci√≥n: 1.0293856039643288\nExactitud validaci√≥n: 18.1739\n√âpoca 341\nPerdida entrenamiento: 0.25653984616784486\nPerdida validaci√≥n: 0.9515304788947105\nExactitud validaci√≥n: 18.6261\n√âpoca 342\nPerdida entrenamiento: 0.2530783467433032\nPerdida validaci√≥n: 0.9056045934557915\nExactitud validaci√≥n: 18.5130\n√âpoca 343\nPerdida entrenamiento: 0.25274669072207284\nPerdida validaci√≥n: 0.918601781129837\nExactitud validaci√≥n: 18.5130\n√âpoca 344\nPerdida entrenamiento: 0.25438859269899483\nPerdida validaci√≥n: 0.8851798251271248\nExactitud validaci√≥n: 18.6261\n√âpoca 345\nPerdida entrenamiento: 0.25582583599230824\nPerdida validaci√≥n: 0.8939363956451416\nExactitud validaci√≥n: 18.5130\n√âpoca 346\nPerdida entrenamiento: 0.25355858443414464\nPerdida validaci√≥n: 0.9068932980298996\nExactitud validaci√≥n: 18.5130\n√âpoca 347\nPerdida entrenamiento: 0.2524866067311343\nPerdida validaci√≥n: 0.8788146674633026\nExactitud validaci√≥n: 18.1739\n√âpoca 348\nPerdida entrenamiento: 0.2536166170064141\nPerdida validaci√≥n: 0.9186953902244568\nExactitud validaci√≥n: 18.5130\n√âpoca 349\nPerdida entrenamiento: 0.25076256341793957\nPerdida validaci√≥n: 0.9136313498020172\nExactitud validaci√≥n: 18.1739\n√âpoca 350\nPerdida entrenamiento: 0.2505396744784187\nPerdida validaci√≥n: 0.8769859820604324\nExactitud validaci√≥n: 18.1739\n√âpoca 351\nPerdida entrenamiento: 0.2476857444819282\nPerdida validaci√≥n: 0.9611544162034988\nExactitud validaci√≥n: 18.1739\n√âpoca 352\nPerdida entrenamiento: 0.2510046801146339\nPerdida validaci√≥n: 0.8769300132989883\nExactitud validaci√≥n: 18.7391\n√âpoca 353\nPerdida entrenamiento: 0.2519538367495817\nPerdida validaci√≥n: 1.009942501783371\nExactitud validaci√≥n: 18.6261\n√âpoca 354\nPerdida entrenamiento: 0.25590333780821634\nPerdida validaci√≥n: 1.0110169053077698\nExactitud validaci√≥n: 18.4000\n√âpoca 355\nPerdida entrenamiento: 0.24665287882089615\nPerdida validaci√≥n: 0.963760256767273\nExactitud validaci√≥n: 18.4000\n√âpoca 356\nPerdida entrenamiento: 0.24831677973270416\nPerdida validaci√≥n: 0.9520362615585327\nExactitud validaci√≥n: 18.4000\n√âpoca 357\nPerdida entrenamiento: 0.25036969605614157\nPerdida validaci√≥n: 0.9705468714237213\nExactitud validaci√≥n: 18.1739\n√âpoca 358\nPerdida entrenamiento: 0.2493774198433932\nPerdida validaci√≥n: 0.9390139281749725\nExactitud validaci√≥n: 18.2870\n√âpoca 359\nPerdida entrenamiento: 0.24896152755793402\nPerdida validaci√≥n: 0.9668420851230621\nExactitud validaci√≥n: 18.8522\n√âpoca 360\nPerdida entrenamiento: 0.24545341993079467\nPerdida validaci√≥n: 0.9598726183176041\nExactitud validaci√≥n: 18.4000\n√âpoca 361\nPerdida entrenamiento: 0.2458833907456959\nPerdida validaci√≥n: 0.9334637522697449\nExactitud validaci√≥n: 18.1739\n√âpoca 362\nPerdida entrenamiento: 0.24675725137486176\nPerdida validaci√≥n: 0.9621522575616837\nExactitud validaci√≥n: 18.0609\n√âpoca 363\nPerdida entrenamiento: 0.24821498946231954\nPerdida validaci√≥n: 0.9556918889284134\nExactitud validaci√≥n: 18.7391\n√âpoca 364\nPerdida entrenamiento: 0.24909637824577444\nPerdida validaci√≥n: 0.8772937767207623\nExactitud validaci√≥n: 18.4000\n√âpoca 365\nPerdida entrenamiento: 0.2441341666614308\nPerdida validaci√≥n: 0.9345356523990631\nExactitud validaci√≥n: 18.6261\n√âpoca 366\nPerdida entrenamiento: 0.2470776263405295\nPerdida validaci√≥n: 1.1278765723109245\nExactitud validaci√≥n: 18.4000\n√âpoca 367\nPerdida entrenamiento: 0.24338742038782904\nPerdida validaci√≥n: 0.9173186719417572\nExactitud validaci√≥n: 18.7391\n√âpoca 368\nPerdida entrenamiento: 0.24587972418350332\nPerdida validaci√≥n: 0.9912368655204773\nExactitud validaci√≥n: 18.0609\n√âpoca 369\nPerdida entrenamiento: 0.2427884471767089\nPerdida validaci√≥n: 0.9538993611931801\nExactitud validaci√≥n: 18.7391\n√âpoca 370\nPerdida entrenamiento: 0.243407864780987\nPerdida validaci√≥n: 1.0761137753725052\nExactitud validaci√≥n: 18.4000\n√âpoca 371\nPerdida entrenamiento: 0.24230772344505086\nPerdida validaci√≥n: 0.968388170003891\nExactitud validaci√≥n: 18.6261\n√âpoca 372\nPerdida entrenamiento: 0.2439663826542742\nPerdida validaci√≥n: 0.9714508131146431\nExactitud validaci√≥n: 18.6261\n√âpoca 373\nPerdida entrenamiento: 0.24384574592113495\nPerdida validaci√≥n: 0.9771965891122818\nExactitud validaci√≥n: 18.4000\n√âpoca 374\nPerdida entrenamiento: 0.24184141614857843\nPerdida validaci√≥n: 0.9964085817337036\nExactitud validaci√≥n: 18.4000\n√âpoca 375\nPerdida entrenamiento: 0.24101467518245473\nPerdida validaci√≥n: 0.9356465041637421\nExactitud validaci√≥n: 17.9478\n√âpoca 376\nPerdida entrenamiento: 0.24006997969220667\nPerdida validaci√≥n: 0.9156605526804924\nExactitud validaci√≥n: 18.0609\n√âpoca 377\nPerdida entrenamiento: 0.23987779985455907\nPerdida validaci√≥n: 1.0531059503555298\nExactitud validaci√≥n: 18.2870\n√âpoca 378\nPerdida entrenamiento: 0.24004541951067307\nPerdida validaci√≥n: 1.0218062326312065\nExactitud validaci√≥n: 18.6261\n√âpoca 379\nPerdida entrenamiento: 0.23972525666741765\nPerdida validaci√≥n: 1.0781173408031464\nExactitud validaci√≥n: 18.4000\n√âpoca 380\nPerdida entrenamiento: 0.23826756415998235\nPerdida validaci√≥n: 1.0114049911499023\nExactitud validaci√≥n: 18.2870\n√âpoca 381\nPerdida entrenamiento: 0.24126425473129048\nPerdida validaci√≥n: 0.9385729283094406\nExactitud validaci√≥n: 18.2870\n√âpoca 382\nPerdida entrenamiento: 0.23986119557829463\nPerdida validaci√≥n: 1.0387549847364426\nExactitud validaci√≥n: 18.5130\n√âpoca 383\nPerdida entrenamiento: 0.2385270192342646\nPerdida validaci√≥n: 0.9609201848506927\nExactitud validaci√≥n: 18.6261\n√âpoca 384\nPerdida entrenamiento: 0.23623030238291798\nPerdida validaci√≥n: 0.9485830962657928\nExactitud validaci√≥n: 18.9652\n√âpoca 385\nPerdida entrenamiento: 0.2384230853880153\nPerdida validaci√≥n: 0.9416188150644302\nExactitud validaci√≥n: 18.4000\n√âpoca 386\nPerdida entrenamiento: 0.23678378015756607\nPerdida validaci√≥n: 0.9777514040470123\nExactitud validaci√≥n: 18.5130\n√âpoca 387\nPerdida entrenamiento: 0.2363624467569239\nPerdida validaci√≥n: 1.0215286016464233\nExactitud validaci√≥n: 18.7391\n√âpoca 388\nPerdida entrenamiento: 0.23862669660764582\nPerdida validaci√≥n: 0.9029609151184559\nExactitud validaci√≥n: 18.1739\n√âpoca 389\nPerdida entrenamiento: 0.23591116070747375\nPerdida validaci√≥n: 0.981246717274189\nExactitud validaci√≥n: 18.6261\n√âpoca 390\nPerdida entrenamiento: 0.23835155718466816\nPerdida validaci√≥n: 1.0086095109581947\nExactitud validaci√≥n: 18.2870\n√âpoca 391\nPerdida entrenamiento: 0.2371460374663858\nPerdida validaci√≥n: 1.0065960884094238\nExactitud validaci√≥n: 18.1739\n√âpoca 392\nPerdida entrenamiento: 0.23677723285029917\nPerdida validaci√≥n: 0.9826027452945709\nExactitud validaci√≥n: 18.5130\n√âpoca 393\nPerdida entrenamiento: 0.23566791196079814\nPerdida validaci√≥n: 1.0341725945472717\nExactitud validaci√≥n: 18.7391\n√âpoca 394\nPerdida entrenamiento: 0.23627526444547317\nPerdida validaci√≥n: 1.0409796610474586\nExactitud validaci√≥n: 18.6261\n√âpoca 395\nPerdida entrenamiento: 0.23617835518191843\nPerdida validaci√≥n: 1.6217666417360306\nExactitud validaci√≥n: 18.5130\n√âpoca 396\nPerdida entrenamiento: 0.233415008029517\nPerdida validaci√≥n: 0.9137831814587116\nExactitud validaci√≥n: 18.4000\n√âpoca 397\nPerdida entrenamiento: 0.2343826009070172\nPerdida validaci√≥n: 1.7579079121351242\nExactitud validaci√≥n: 18.7391\n√âpoca 398\nPerdida entrenamiento: 0.23368020224220612\nPerdida validaci√≥n: 1.0100515186786652\nExactitud validaci√≥n: 18.7391\n√âpoca 399\nPerdida entrenamiento: 0.2321076200288885\nPerdida validaci√≥n: 1.6793339550495148\nExactitud validaci√≥n: 18.6261\n√âpoca 400\nPerdida entrenamiento: 0.23293223012896144\nPerdida validaci√≥n: 1.610338568687439\nExactitud validaci√≥n: 18.6261\n√âpoca 401\nPerdida entrenamiento: 0.23105231278082905\nPerdida validaci√≥n: 1.6416560858488083\nExactitud validaci√≥n: 18.4000\n√âpoca 402\nPerdida entrenamiento: 0.23033762372591915\nPerdida validaci√≥n: 1.66363063454628\nExactitud validaci√≥n: 18.4000\n√âpoca 403\nPerdida entrenamiento: 0.23017951057237737\nPerdida validaci√≥n: 1.6514071226119995\nExactitud validaci√≥n: 18.4000\n√âpoca 404\nPerdida entrenamiento: 0.23135478268651402\nPerdida validaci√≥n: 1.703551098704338\nExactitud validaci√≥n: 18.6261\n√âpoca 405\nPerdida entrenamiento: 0.23199564174694173\nPerdida validaci√≥n: 1.6757195889949799\nExactitud validaci√≥n: 18.2870\n√âpoca 406\nPerdida entrenamiento: 0.23011183563400717\nPerdida validaci√≥n: 2.195468708872795\nExactitud validaci√≥n: 18.5130\n√âpoca 407\nPerdida entrenamiento: 0.2305179115603952\nPerdida validaci√≥n: 2.174595355987549\nExactitud validaci√≥n: 18.7391\n√âpoca 408\nPerdida entrenamiento: 0.23433966364930658\nPerdida validaci√≥n: 1.7009802162647247\nExactitud validaci√≥n: 18.5130\n√âpoca 409\nPerdida entrenamiento: 0.23122593146913192\nPerdida validaci√≥n: 1.6614426672458649\nExactitud validaci√≥n: 18.9652\n√âpoca 410\nPerdida entrenamiento: 0.22980902212507584\nPerdida validaci√≥n: 1.6923879534006119\nExactitud validaci√≥n: 18.5130\n√âpoca 411\nPerdida entrenamiento: 0.2278544008731842\nPerdida validaci√≥n: 1.6532950922846794\nExactitud validaci√≥n: 18.4000\n√âpoca 412\nPerdida entrenamiento: 0.22777951815549066\nPerdida validaci√≥n: 1.680533990263939\nExactitud validaci√≥n: 18.6261\n√âpoca 413\nPerdida entrenamiento: 0.22783642744316773\nPerdida validaci√≥n: 1.6505683958530426\nExactitud validaci√≥n: 18.4000\n√âpoca 414\nPerdida entrenamiento: 0.22797440430697272\nPerdida validaci√≥n: 1.6364076286554337\nExactitud validaci√≥n: 18.2870\n√âpoca 415\nPerdida entrenamiento: 0.22762182880850398\nPerdida validaci√≥n: 1.630989708006382\nExactitud validaci√≥n: 18.2870\n√âpoca 416\nPerdida entrenamiento: 0.227926942793762\nPerdida validaci√≥n: 1.6618505418300629\nExactitud validaci√≥n: 18.6261\n√âpoca 417\nPerdida entrenamiento: 0.22629480239223032\nPerdida validaci√≥n: 1.6968141943216324\nExactitud validaci√≥n: 18.4000\n√âpoca 418\nPerdida entrenamiento: 0.22488318559001474\nPerdida validaci√≥n: 1.7578092515468597\nExactitud validaci√≥n: 18.2870\n√âpoca 419\nPerdida entrenamiento: 0.2263673219610663\nPerdida validaci√≥n: 1.6131335943937302\nExactitud validaci√≥n: 18.1739\n√âpoca 420\nPerdida entrenamiento: 0.22987113630070405\nPerdida validaci√≥n: 1.7163729965686798\nExactitud validaci√≥n: 18.1739\n√âpoca 421\nPerdida entrenamiento: 0.22674175527165918\nPerdida validaci√≥n: 1.6752920597791672\nExactitud validaci√≥n: 18.8522\n√âpoca 422\nPerdida entrenamiento: 0.22827263702364528\nPerdida validaci√≥n: 1.7154240310192108\nExactitud validaci√≥n: 18.5130\n√âpoca 423\nPerdida entrenamiento: 0.2220915402559673\nPerdida validaci√≥n: 1.6310960724949837\nExactitud validaci√≥n: 18.1739\n√âpoca 424\nPerdida entrenamiento: 0.22505173613043392\nPerdida validaci√≥n: 1.6115675866603851\nExactitud validaci√≥n: 18.1739\n√âpoca 425\nPerdida entrenamiento: 0.22220089418046615\nPerdida validaci√≥n: 2.214143306016922\nExactitud validaci√≥n: 18.1739\n√âpoca 426\nPerdida entrenamiento: 0.2250201561871697\nPerdida validaci√≥n: 1.64544016122818\nExactitud validaci√≥n: 18.1739\n√âpoca 427\nPerdida entrenamiento: 0.22550559876596227\nPerdida validaci√≥n: 1.6851514726877213\nExactitud validaci√≥n: 18.7391\n√âpoca 428\nPerdida entrenamiento: 0.22317052457262487\nPerdida validaci√≥n: 1.7038426101207733\nExactitud validaci√≥n: 18.7391\n√âpoca 429\nPerdida entrenamiento: 0.22356641993803136\nPerdida validaci√≥n: 1.710338070988655\nExactitud validaci√≥n: 18.4000\n√âpoca 430\nPerdida entrenamiento: 0.22142810199190588\nPerdida validaci√≥n: 1.7483271360397339\nExactitud validaci√≥n: 18.7391\n√âpoca 431\nPerdida entrenamiento: 0.22034293062546673\nPerdida validaci√≥n: 1.6430785655975342\nExactitud validaci√≥n: 18.7391\n√âpoca 432\nPerdida entrenamiento: 0.22316901824053595\nPerdida validaci√≥n: 1.7672994136810303\nExactitud validaci√≥n: 18.4000\n√âpoca 433\nPerdida entrenamiento: 0.22463338383856943\nPerdida validaci√≥n: 1.6433425098657608\nExactitud validaci√≥n: 18.4000\n√âpoca 434\nPerdida entrenamiento: 0.22231091646587148\nPerdida validaci√≥n: 1.6801955252885818\nExactitud validaci√≥n: 18.5130\n√âpoca 435\nPerdida entrenamiento: 0.2208845168352127\nPerdida validaci√≥n: 1.6813064217567444\nExactitud validaci√≥n: 18.2870\n√âpoca 436\nPerdida entrenamiento: 0.22095614584053264\nPerdida validaci√≥n: 1.6760065108537674\nExactitud validaci√≥n: 18.6261\n√âpoca 437\nPerdida entrenamiento: 0.22033456712961197\nPerdida validaci√≥n: 1.678830772638321\nExactitud validaci√≥n: 18.7391\n√âpoca 438\nPerdida entrenamiento: 0.22007577559527228\nPerdida validaci√≥n: 1.6954376250505447\nExactitud validaci√≥n: 18.6261\n√âpoca 439\nPerdida entrenamiento: 0.22003603507490718\nPerdida validaci√≥n: 1.725928619503975\nExactitud validaci√≥n: 18.8522\n√âpoca 440\nPerdida entrenamiento: 0.22195249708259807\nPerdida validaci√≥n: 1.8037448972463608\nExactitud validaci√≥n: 18.5130\n√âpoca 441\nPerdida entrenamiento: 0.21979504736030803\nPerdida validaci√≥n: 1.6947238594293594\nExactitud validaci√≥n: 18.1739\n√âpoca 442\nPerdida entrenamiento: 0.21700231205014622\nPerdida validaci√≥n: 1.7131413221359253\nExactitud validaci√≥n: 18.5130\n√âpoca 443\nPerdida entrenamiento: 0.21716881061301513\nPerdida validaci√≥n: 1.7016572207212448\nExactitud validaci√≥n: 18.2870\n√âpoca 444\nPerdida entrenamiento: 0.21755946778199253\nPerdida validaci√≥n: 2.2080706506967545\nExactitud validaci√≥n: 18.4000\n√âpoca 445\nPerdida entrenamiento: 0.21960881308597677\nPerdida validaci√≥n: 2.2232966125011444\nExactitud validaci√≥n: 18.2870\n√âpoca 446\nPerdida entrenamiento: 0.2177817536627545\nPerdida validaci√≥n: 1.674214854836464\nExactitud validaci√≥n: 18.2870\n√âpoca 447\nPerdida entrenamiento: 0.22076668239691677\nPerdida validaci√≥n: 1.6826488673686981\nExactitud validaci√≥n: 18.4000\n√âpoca 448\nPerdida entrenamiento: 0.2175587897791582\nPerdida validaci√≥n: 1.684437245130539\nExactitud validaci√≥n: 18.4000\n√âpoca 449\nPerdida entrenamiento: 0.21597974396803798\nPerdida validaci√≥n: 1.7088166177272797\nExactitud validaci√≥n: 18.2870\n√âpoca 450\nPerdida entrenamiento: 0.21813132044147043\nPerdida validaci√≥n: 1.733146995306015\nExactitud validaci√≥n: 18.1739\n√âpoca 451\nPerdida entrenamiento: 0.21773759976905935\nPerdida validaci√≥n: 1.6941641122102737\nExactitud validaci√≥n: 18.2870\n√âpoca 452\nPerdida entrenamiento: 0.21535080583656535\nPerdida validaci√≥n: 1.76713265478611\nExactitud validaci√≥n: 18.4000\n√âpoca 453\nPerdida entrenamiento: 0.21499554462292614\nPerdida validaci√≥n: 1.725937306880951\nExactitud validaci√≥n: 18.4000\n√âpoca 454\nPerdida entrenamiento: 0.21762167399420457\nPerdida validaci√≥n: 1.745834544301033\nExactitud validaci√≥n: 18.4000\n√âpoca 455\nPerdida entrenamiento: 0.21529359852566438\nPerdida validaci√≥n: 1.7183891236782074\nExactitud validaci√≥n: 18.6261\n√âpoca 456\nPerdida entrenamiento: 0.21322160959243774\nPerdida validaci√≥n: 1.665738008916378\nExactitud validaci√≥n: 18.5130\n√âpoca 457\nPerdida entrenamiento: 0.21297074021661982\nPerdida validaci√≥n: 1.6415093056857586\nExactitud validaci√≥n: 18.1739\n√âpoca 458\nPerdida entrenamiento: 0.2120342228342505\nPerdida validaci√≥n: 1.6675629317760468\nExactitud validaci√≥n: 18.5130\n√âpoca 459\nPerdida entrenamiento: 0.21290872377507827\nPerdida validaci√≥n: 1.7062142491340637\nExactitud validaci√≥n: 18.1739\n√âpoca 460\nPerdida entrenamiento: 0.2155881883466945\nPerdida validaci√≥n: 1.6664244383573532\nExactitud validaci√≥n: 18.6261\n√âpoca 461\nPerdida entrenamiento: 0.2123072870513972\nPerdida validaci√≥n: 1.6892398595809937\nExactitud validaci√≥n: 18.1739\n√âpoca 462\nPerdida entrenamiento: 0.21215057285392985\nPerdida validaci√≥n: 1.71298286318779\nExactitud validaci√≥n: 18.5130\n√âpoca 463\nPerdida entrenamiento: 0.2131307668545667\nPerdida validaci√≥n: 2.3371381908655167\nExactitud validaci√≥n: 18.4000\n√âpoca 464\nPerdida entrenamiento: 0.21063883252003612\nPerdida validaci√≥n: 1.6871272176504135\nExactitud validaci√≥n: 18.4000\n√âpoca 465\nPerdida entrenamiento: 0.21041779746027553\nPerdida validaci√≥n: 1.7584034204483032\nExactitud validaci√≥n: 18.8522\n√âpoca 466\nPerdida entrenamiento: 0.20908518573817084\nPerdida validaci√≥n: 1.7399623692035675\nExactitud validaci√≥n: 18.2870\n√âpoca 467\nPerdida entrenamiento: 0.20974228049025817\nPerdida validaci√≥n: 1.7392813563346863\nExactitud validaci√≥n: 18.0609\n√âpoca 468\nPerdida entrenamiento: 0.20860017222516677\nPerdida validaci√≥n: 1.7459359467029572\nExactitud validaci√≥n: 18.6261\n√âpoca 469\nPerdida entrenamiento: 0.20901529490947723\nPerdida validaci√≥n: 1.6576770320534706\nExactitud validaci√≥n: 18.2870\n√âpoca 470\nPerdida entrenamiento: 0.20985684850636652\nPerdida validaci√≥n: 1.6809408068656921\nExactitud validaci√≥n: 17.8348\n√âpoca 471\nPerdida entrenamiento: 0.20888636611840306\nPerdida validaci√≥n: 1.7095791101455688\nExactitud validaci√≥n: 18.4000\n√âpoca 472\nPerdida entrenamiento: 0.20915422983029308\nPerdida validaci√≥n: 1.735638752579689\nExactitud validaci√≥n: 18.6261\n√âpoca 473\nPerdida entrenamiento: 0.21087617295629837\nPerdida validaci√≥n: 2.223282590508461\nExactitud validaci√≥n: 18.8522\n√âpoca 474\nPerdida entrenamiento: 0.21059176501105814\nPerdida validaci√≥n: 2.2696365863084793\nExactitud validaci√≥n: 18.4000\n√âpoca 475\nPerdida entrenamiento: 0.20993135518887462\nPerdida validaci√≥n: 2.3144669383764267\nExactitud validaci√≥n: 18.4000\n√âpoca 476\nPerdida entrenamiento: 0.2069975641720435\nPerdida validaci√≥n: 1.7147362232208252\nExactitud validaci√≥n: 17.9478\n√âpoca 477\nPerdida entrenamiento: 0.20739179674316854\nPerdida validaci√≥n: 1.7762307822704315\nExactitud validaci√≥n: 18.4000\n√âpoca 478\nPerdida entrenamiento: 0.20736681187854095\nPerdida validaci√≥n: 1.7321285605430603\nExactitud validaci√≥n: 18.7391\n√âpoca 479\nPerdida entrenamiento: 0.20850269627921722\nPerdida validaci√≥n: 1.7248305529356003\nExactitud validaci√≥n: 18.5130\n√âpoca 480\nPerdida entrenamiento: 0.20808968561537125\nPerdida validaci√≥n: 1.6793062910437584\nExactitud validaci√≥n: 18.5130\n√âpoca 481\nPerdida entrenamiento: 0.2063585151644314\nPerdida validaci√≥n: 2.3160250037908554\nExactitud validaci√≥n: 18.4000\n√âpoca 482\nPerdida entrenamiento: 0.20922441298470779\nPerdida validaci√≥n: 1.7382783144712448\nExactitud validaci√≥n: 18.7391\n√âpoca 483\nPerdida entrenamiento: 0.2089783260050942\nPerdida validaci√≥n: 1.675756473094225\nExactitud validaci√≥n: 18.2870\n√âpoca 484\nPerdida entrenamiento: 0.20955036317600922\nPerdida validaci√≥n: 1.7968875467777252\nExactitud validaci√≥n: 18.5130\n√âpoca 485\nPerdida entrenamiento: 0.20719658802537358\nPerdida validaci√≥n: 2.281432792544365\nExactitud validaci√≥n: 18.2870\n√âpoca 486\nPerdida entrenamiento: 0.20671694988713546\nPerdida validaci√≥n: 2.290306895971298\nExactitud validaci√≥n: 18.5130\n√âpoca 487\nPerdida entrenamiento: 0.20706017490695505\nPerdida validaci√≥n: 1.7116160094738007\nExactitud validaci√≥n: 18.4000\n√âpoca 488\nPerdida entrenamiento: 0.20524413971339955\nPerdida validaci√≥n: 1.8093033283948898\nExactitud validaci√≥n: 18.5130\n√âpoca 489\nPerdida entrenamiento: 0.2051747401847559\nPerdida validaci√≥n: 1.7765755355358124\nExactitud validaci√≥n: 18.6261\n√âpoca 490\nPerdida entrenamiento: 0.20630764128530726\nPerdida validaci√≥n: 1.7870673686265945\nExactitud validaci√≥n: 18.2870\n√âpoca 491\nPerdida entrenamiento: 0.20644442780929453\nPerdida validaci√≥n: 2.2809912860393524\nExactitud validaci√≥n: 18.5130\n√âpoca 492\nPerdida entrenamiento: 0.2057285668218837\nPerdida validaci√≥n: 2.258572533726692\nExactitud validaci√≥n: 17.8348\n√âpoca 493\nPerdida entrenamiento: 0.2029068154447219\nPerdida validaci√≥n: 1.6803431659936905\nExactitud validaci√≥n: 18.7391\n√âpoca 494\nPerdida entrenamiento: 0.2028874272809309\nPerdida validaci√≥n: 1.8127751350402832\nExactitud validaci√≥n: 18.7391\n√âpoca 495\nPerdida entrenamiento: 0.2052424208206289\nPerdida validaci√≥n: 1.7849414199590683\nExactitud validaci√≥n: 18.7391\n√âpoca 496\nPerdida entrenamiento: 0.20392162791069815\nPerdida validaci√≥n: 1.7237890660762787\nExactitud validaci√≥n: 18.4000\n√âpoca 497\nPerdida entrenamiento: 0.20092843429130666\nPerdida validaci√≥n: 2.2871531173586845\nExactitud validaci√≥n: 18.6261\n√âpoca 498\nPerdida entrenamiento: 0.20234436278834061\nPerdida validaci√≥n: 2.2854884639382362\nExactitud validaci√≥n: 18.2870\n√âpoca 499\nPerdida entrenamiento: 0.20332733541727066\nPerdida validaci√≥n: 1.7827043235301971\nExactitud validaci√≥n: 18.6261\n√âpoca 500\nPerdida entrenamiento: 0.20469026092220755\nPerdida validaci√≥n: 2.3745395615696907\nExactitud validaci√≥n: 18.5130\n√âpoca 501\nPerdida entrenamiento: 0.20449996783452876\nPerdida validaci√≥n: 1.7906746417284012\nExactitud validaci√≥n: 18.6261\n√âpoca 502\nPerdida entrenamiento: 0.20517864034456365\nPerdida validaci√≥n: 1.732749417424202\nExactitud validaci√≥n: 18.5130\n√âpoca 503\nPerdida entrenamiento: 0.20195804273380952\nPerdida validaci√≥n: 2.2683166712522507\nExactitud validaci√≥n: 18.5130\n√âpoca 504\nPerdida entrenamiento: 0.2007514510084601\nPerdida validaci√≥n: 1.7528420686721802\nExactitud validaci√≥n: 18.4000\n√âpoca 505\nPerdida entrenamiento: 0.2026394693290486\nPerdida validaci√≥n: 1.7850606441497803\nExactitud validaci√≥n: 18.4000\n√âpoca 506\nPerdida entrenamiento: 0.20051894775208304\nPerdida validaci√≥n: 1.7376345694065094\nExactitud validaci√≥n: 18.5130\n√âpoca 507\nPerdida entrenamiento: 0.1994068114196553\nPerdida validaci√≥n: 1.813426986336708\nExactitud validaci√≥n: 18.2870\n√âpoca 508\nPerdida entrenamiento: 0.20079496415222392\nPerdida validaci√≥n: 2.327720493078232\nExactitud validaci√≥n: 18.2870\n√âpoca 509\nPerdida entrenamiento: 0.20256532158921747\nPerdida validaci√≥n: 1.7458709627389908\nExactitud validaci√≥n: 18.4000\n√âpoca 510\nPerdida entrenamiento: 0.20124467067858753\nPerdida validaci√≥n: 1.7705589160323143\nExactitud validaci√≥n: 18.5130\n√âpoca 511\nPerdida entrenamiento: 0.19941148468676737\nPerdida validaci√≥n: 1.796208769083023\nExactitud validaci√≥n: 18.4000\n√âpoca 512\nPerdida entrenamiento: 0.19882883394465728\nPerdida validaci√≥n: 1.749910831451416\nExactitud validaci√≥n: 18.4000\n√âpoca 513\nPerdida entrenamiento: 0.2000570288475822\nPerdida validaci√≥n: 1.796690434217453\nExactitud validaci√≥n: 18.5130\n√âpoca 514\nPerdida entrenamiento: 0.19875034295460758\nPerdida validaci√≥n: 1.7634713500738144\nExactitud validaci√≥n: 18.4000\n√âpoca 515\nPerdida entrenamiento: 0.19847256471129024\nPerdida validaci√≥n: 1.7303752601146698\nExactitud validaci√≥n: 18.2870\n√âpoca 516\nPerdida entrenamiento: 0.19714518767945907\nPerdida validaci√≥n: 1.7873051464557648\nExactitud validaci√≥n: 18.7391\n√âpoca 517\nPerdida entrenamiento: 0.19987665379748626\nPerdida validaci√≥n: 2.3726578801870346\nExactitud validaci√≥n: 18.0609\n√âpoca 518\nPerdida entrenamiento: 0.19713971062618144\nPerdida validaci√≥n: 1.8600481450557709\nExactitud validaci√≥n: 18.6261\n√âpoca 519\nPerdida entrenamiento: 0.19719707089311936\nPerdida validaci√≥n: 1.7947774976491928\nExactitud validaci√≥n: 18.5130\n√âpoca 520\nPerdida entrenamiento: 0.19800057525143905\nPerdida validaci√≥n: 1.8386373445391655\nExactitud validaci√≥n: 18.4000\n√âpoca 521\nPerdida entrenamiento: 0.19503561845597098\nPerdida validaci√≥n: 1.86511692404747\nExactitud validaci√≥n: 18.0609\n√âpoca 522\nPerdida entrenamiento: 0.19703502164167516\nPerdida validaci√≥n: 2.2786576449871063\nExactitud validaci√≥n: 18.7391\n√âpoca 523\nPerdida entrenamiento: 0.1965047695180949\nPerdida validaci√≥n: 1.7550715208053589\nExactitud validaci√≥n: 18.5130\n√âpoca 524\nPerdida entrenamiento: 0.19743618281448588\nPerdida validaci√≥n: 1.7788794338703156\nExactitud validaci√≥n: 18.4000\n√âpoca 525\nPerdida entrenamiento: 0.19581336571889765\nPerdida validaci√≥n: 2.3412183597683907\nExactitud validaci√≥n: 18.6261\n√âpoca 526\nPerdida entrenamiento: 0.19735115065294154\nPerdida validaci√≥n: 1.7944573611021042\nExactitud validaci√≥n: 18.5130\n√âpoca 527\nPerdida entrenamiento: 0.1972572623806841\nPerdida validaci√≥n: 1.7847600281238556\nExactitud validaci√≥n: 18.4000\n√âpoca 528\nPerdida entrenamiento: 0.19613027397324057\nPerdida validaci√≥n: 1.8530294448137283\nExactitud validaci√≥n: 18.2870\n√âpoca 529\nPerdida entrenamiento: 0.19604966395041523\nPerdida validaci√≥n: 1.8482124507427216\nExactitud validaci√≥n: 18.6261\n√âpoca 530\nPerdida entrenamiento: 0.19563549099599614\nPerdida validaci√≥n: 1.7713856101036072\nExactitud validaci√≥n: 18.6261\n√âpoca 531\nPerdida entrenamiento: 0.1955263259656289\nPerdida validaci√≥n: 1.8069935888051987\nExactitud validaci√≥n: 17.9478\n√âpoca 532\nPerdida entrenamiento: 0.19411977774956646\nPerdida validaci√≥n: 1.8041860908269882\nExactitud validaci√≥n: 18.6261\n√âpoca 533\nPerdida entrenamiento: 0.1945977715008399\nPerdida validaci√≥n: 1.825106680393219\nExactitud validaci√≥n: 18.2870\n√âpoca 534\nPerdida entrenamiento: 0.1952920450883753\nPerdida validaci√≥n: 2.3135114312171936\nExactitud validaci√≥n: 18.6261\n√âpoca 535\nPerdida entrenamiento: 0.19248855683733435\nPerdida validaci√≥n: 1.8990767300128937\nExactitud validaci√≥n: 18.4000\n√âpoca 536\nPerdida entrenamiento: 0.19831059960757985\nPerdida validaci√≥n: 1.80620726197958\nExactitud validaci√≥n: 18.2870\n√âpoca 537\nPerdida entrenamiento: 0.1929608224069371\nPerdida validaci√≥n: 1.7912742048501968\nExactitud validaci√≥n: 18.4000\n√âpoca 538\nPerdida entrenamiento: 0.19296798898893244\nPerdida validaci√≥n: 1.7543442994356155\nExactitud validaci√≥n: 18.1739\n√âpoca 539\nPerdida entrenamiento: 0.1950954786118339\nPerdida validaci√≥n: 1.8118992149829865\nExactitud validaci√≥n: 18.4000\n√âpoca 540\nPerdida entrenamiento: 0.1945850323228275\nPerdida validaci√≥n: 1.8098999336361885\nExactitud validaci√≥n: 18.2870\n√âpoca 541\nPerdida entrenamiento: 0.19389351413530462\nPerdida validaci√≥n: 2.289820373058319\nExactitud validaci√≥n: 18.2870\n√âpoca 542\nPerdida entrenamiento: 0.19105484468095443\nPerdida validaci√≥n: 1.794912725687027\nExactitud validaci√≥n: 18.0609\n√âpoca 543\nPerdida entrenamiento: 0.19384890005869024\nPerdida validaci√≥n: 1.875189632177353\nExactitud validaci√≥n: 18.1739\n√âpoca 544\nPerdida entrenamiento: 0.19117492963286006\nPerdida validaci√≥n: 1.809283822774887\nExactitud validaci√≥n: 18.4000\n√âpoca 545\nPerdida entrenamiento: 0.19236618893987992\nPerdida validaci√≥n: 2.2911151945590973\nExactitud validaci√≥n: 18.6261\n√âpoca 546\nPerdida entrenamiento: 0.19125396495356278\nPerdida validaci√≥n: 1.7524409666657448\nExactitud validaci√≥n: 18.5130\n√âpoca 547\nPerdida entrenamiento: 0.19026901047019398\nPerdida validaci√≥n: 1.8327823728322983\nExactitud validaci√≥n: 18.4000\n√âpoca 548\nPerdida entrenamiento: 0.1921607873895589\nPerdida validaci√≥n: 2.307979680597782\nExactitud validaci√≥n: 18.2870\n√âpoca 549\nPerdida entrenamiento: 0.19157351816401763\nPerdida validaci√≥n: 1.8872595876455307\nExactitud validaci√≥n: 18.4000\n√âpoca 550\nPerdida entrenamiento: 0.19094288480632446\nPerdida validaci√≥n: 1.9153790324926376\nExactitud validaci√≥n: 18.6261\n√âpoca 551\nPerdida entrenamiento: 0.19048834592103958\nPerdida validaci√≥n: 1.7659415304660797\nExactitud validaci√≥n: 18.5130\n√âpoca 552\nPerdida entrenamiento: 0.19038300785948248\nPerdida validaci√≥n: 1.7611987218260765\nExactitud validaci√≥n: 18.4000\n√âpoca 553\nPerdida entrenamiento: 0.18965064383604946\nPerdida validaci√≥n: 1.871100902557373\nExactitud validaci√≥n: 18.2870\n√âpoca 554\nPerdida entrenamiento: 0.19062230779844172\nPerdida validaci√≥n: 1.8860596120357513\nExactitud validaci√≥n: 18.2870\n√âpoca 555\nPerdida entrenamiento: 0.18969056185554056\nPerdida validaci√≥n: 2.3548885583877563\nExactitud validaci√≥n: 18.0609\n√âpoca 556\nPerdida entrenamiento: 0.18985140696167946\nPerdida validaci√≥n: 2.386777237057686\nExactitud validaci√≥n: 18.5130\n√âpoca 557\nPerdida entrenamiento: 0.19206796192071018\nPerdida validaci√≥n: 1.804469645023346\nExactitud validaci√≥n: 18.2870\n√âpoca 558\nPerdida entrenamiento: 0.1930651068687439\nPerdida validaci√≥n: 1.8630142956972122\nExactitud validaci√≥n: 18.4000\n√âpoca 559\nPerdida entrenamiento: 0.1930370124823907\nPerdida validaci√≥n: 1.7798155397176743\nExactitud validaci√≥n: 18.4000\n√âpoca 560\nPerdida entrenamiento: 0.1902738498414264\nPerdida validaci√≥n: 1.8318945318460464\nExactitud validaci√≥n: 18.4000\n√âpoca 561\nPerdida entrenamiento: 0.19049055655212963\nPerdida validaci√≥n: 1.7881848067045212\nExactitud validaci√≥n: 18.4000\n√âpoca 562\nPerdida entrenamiento: 0.18791185231769786\nPerdida validaci√≥n: 1.8009058833122253\nExactitud validaci√≥n: 18.7391\n√âpoca 563\nPerdida entrenamiento: 0.18878159409060197\nPerdida validaci√≥n: 2.3612941056489944\nExactitud validaci√≥n: 18.2870\n√âpoca 564\nPerdida entrenamiento: 0.18708483611836152\nPerdida validaci√≥n: 1.795827567577362\nExactitud validaci√≥n: 18.6261\n√âpoca 565\nPerdida entrenamiento: 0.18627881477860844\nPerdida validaci√≥n: 1.8481564670801163\nExactitud validaci√≥n: 18.5130\n√âpoca 566\nPerdida entrenamiento: 0.18686316863578908\nPerdida validaci√≥n: 1.8827480152249336\nExactitud validaci√≥n: 18.5130\n√âpoca 567\nPerdida entrenamiento: 0.18734496525105307\nPerdida validaci√≥n: 2.437557488679886\nExactitud validaci√≥n: 18.6261\n√âpoca 568\nPerdida entrenamiento: 0.18700052578659618\nPerdida validaci√≥n: 1.8809164464473724\nExactitud validaci√≥n: 18.6261\n√âpoca 569\nPerdida entrenamiento: 0.1859943498583401\nPerdida validaci√≥n: 2.3979000598192215\nExactitud validaci√≥n: 18.5130\n√âpoca 570\nPerdida entrenamiento: 0.1867598135243444\nPerdida validaci√≥n: 2.401433676481247\nExactitud validaci√≥n: 18.4000\n√âpoca 571\nPerdida entrenamiento: 0.18641008743468454\nPerdida validaci√≥n: 1.8099213689565659\nExactitud validaci√≥n: 18.4000\n√âpoca 572\nPerdida entrenamiento: 0.1878149176345152\nPerdida validaci√≥n: 1.8095275163650513\nExactitud validaci√≥n: 18.7391\n√âpoca 573\nPerdida entrenamiento: 0.1844573288279421\nPerdida validaci√≥n: 1.815418690443039\nExactitud validaci√≥n: 18.4000\n√âpoca 574\nPerdida entrenamiento: 0.18568310711313696\nPerdida validaci√≥n: 1.7979236990213394\nExactitud validaci√≥n: 18.5130\n√âpoca 575\nPerdida entrenamiento: 0.1849901847103063\nPerdida validaci√≥n: 1.8825554847717285\nExactitud validaci√≥n: 18.4000\n√âpoca 576\nPerdida entrenamiento: 0.18612053245306015\nPerdida validaci√≥n: 1.80270117521286\nExactitud validaci√≥n: 18.4000\n√âpoca 577\nPerdida entrenamiento: 0.1876081745414173\nPerdida validaci√≥n: 1.8711232542991638\nExactitud validaci√≥n: 18.2870\n√âpoca 578\nPerdida entrenamiento: 0.18576577305793762\nPerdida validaci√≥n: 1.908687710762024\nExactitud validaci√≥n: 18.2870\n√âpoca 579\nPerdida entrenamiento: 0.18641850834383683\nPerdida validaci√≥n: 1.86570705473423\nExactitud validaci√≥n: 17.9478\n√âpoca 580\nPerdida entrenamiento: 0.1835003499599064\nPerdida validaci√≥n: 1.8697331100702286\nExactitud validaci√≥n: 18.6261\n√âpoca 581\nPerdida entrenamiento: 0.18529456985347412\nPerdida validaci√≥n: 1.7919117659330368\nExactitud validaci√≥n: 18.2870\n√âpoca 582\nPerdida entrenamiento: 0.1841503298457931\nPerdida validaci√≥n: 2.4412302374839783\nExactitud validaci√≥n: 18.7391\n√âpoca 583\nPerdida entrenamiento: 0.18371729158303318\nPerdida validaci√≥n: 1.8544679284095764\nExactitud validaci√≥n: 18.8522\n√âpoca 584\nPerdida entrenamiento: 0.18499108140959458\nPerdida validaci√≥n: 1.8232229053974152\nExactitud validaci√≥n: 18.5130\n√âpoca 585\nPerdida entrenamiento: 0.1860760952181676\nPerdida validaci√≥n: 1.841095194220543\nExactitud validaci√≥n: 18.5130\n√âpoca 586\nPerdida entrenamiento: 0.18593923703712575\nPerdida validaci√≥n: 1.8760543167591095\nExactitud validaci√≥n: 18.5130\n√âpoca 587\nPerdida entrenamiento: 0.18209941509891958\nPerdida validaci√≥n: 1.9005913734436035\nExactitud validaci√≥n: 18.5130\n√âpoca 588\nPerdida entrenamiento: 0.18258259160553708\nPerdida validaci√≥n: 1.858061134815216\nExactitud validaci√≥n: 18.6261\n√âpoca 589\nPerdida entrenamiento: 0.18598782183492885\nPerdida validaci√≥n: 2.420540153980255\nExactitud validaci√≥n: 18.2870\n√âpoca 590\nPerdida entrenamiento: 0.1828598489656168\nPerdida validaci√≥n: 1.8328881710767746\nExactitud validaci√≥n: 18.6261\n√âpoca 591\nPerdida entrenamiento: 0.1841830584932776\nPerdida validaci√≥n: 1.8384827971458435\nExactitud validaci√≥n: 18.5130\n√âpoca 592\nPerdida entrenamiento: 0.1838392247171963\nPerdida validaci√≥n: 2.3826200664043427\nExactitud validaci√≥n: 18.6261\n√âpoca 593\nPerdida entrenamiento: 0.18054470770499287\nPerdida validaci√≥n: 2.3773992508649826\nExactitud validaci√≥n: 18.7391\n√âpoca 594\nPerdida entrenamiento: 0.18052921707139297\nPerdida validaci√≥n: 1.9906710982322693\nExactitud validaci√≥n: 18.0609\n√âpoca 595\nPerdida entrenamiento: 0.18146830621887655\nPerdida validaci√≥n: 2.434752732515335\nExactitud validaci√≥n: 18.5130\n√âpoca 596\nPerdida entrenamiento: 0.17948470089365454\nPerdida validaci√≥n: 1.852248728275299\nExactitud validaci√≥n: 18.7391\n√âpoca 597\nPerdida entrenamiento: 0.17860462297411525\nPerdida validaci√≥n: 2.346190959215164\nExactitud validaci√≥n: 18.5130\n√âpoca 598\nPerdida entrenamiento: 0.18151379288995967\nPerdida validaci√≥n: 1.9093308448791504\nExactitud validaci√≥n: 18.5130\n√âpoca 599\nPerdida entrenamiento: 0.17953513781814015\nPerdida validaci√≥n: 1.927807793021202\nExactitud validaci√≥n: 18.6261\n√âpoca 600\nPerdida entrenamiento: 0.18134287832414403\nPerdida validaci√≥n: 1.8202008605003357\nExactitud validaci√≥n: 17.9478\n√âpoca 601\nPerdida entrenamiento: 0.18065105510108612\nPerdida validaci√≥n: 2.4191258996725082\nExactitud validaci√≥n: 18.0609\n√âpoca 602\nPerdida entrenamiento: 0.17909427337786732\nPerdida validaci√≥n: 2.3444060534238815\nExactitud validaci√≥n: 17.9478\n√âpoca 603\nPerdida entrenamiento: 0.1807249688050326\nPerdida validaci√≥n: 1.859527364373207\nExactitud validaci√≥n: 18.6261\n√âpoca 604\nPerdida entrenamiento: 0.17981747581678278\nPerdida validaci√≥n: 1.8991383910179138\nExactitud validaci√≥n: 18.4000\n√âpoca 605\nPerdida entrenamiento: 0.18046181123046315\nPerdida validaci√≥n: 1.9196833372116089\nExactitud validaci√≥n: 18.2870\n√âpoca 606\nPerdida entrenamiento: 0.17735964761060827\nPerdida validaci√≥n: 1.8872027397155762\nExactitud validaci√≥n: 18.4000\n√âpoca 607\nPerdida entrenamiento: 0.17956263265189001\nPerdida validaci√≥n: 1.8883287459611893\nExactitud validaci√≥n: 18.2870\n√âpoca 608\nPerdida entrenamiento: 0.17843612239641302\nPerdida validaci√≥n: 2.382715880870819\nExactitud validaci√≥n: 18.2870\n√âpoca 609\nPerdida entrenamiento: 0.17757347269969828\nPerdida validaci√≥n: 1.932212918996811\nExactitud validaci√≥n: 18.6261\n√âpoca 610\nPerdida entrenamiento: 0.1786287356825436\nPerdida validaci√≥n: 1.9283054769039154\nExactitud validaci√≥n: 18.4000\n√âpoca 611\nPerdida entrenamiento: 0.17991680958691766\nPerdida validaci√≥n: 2.5501490607857704\nExactitud validaci√≥n: 18.2870\n√âpoca 612\nPerdida entrenamiento: 0.18011304056819746\nPerdida validaci√≥n: 1.7971415668725967\nExactitud validaci√≥n: 18.4000\n√âpoca 613\nPerdida entrenamiento: 0.17593874650843003\nPerdida validaci√≥n: 2.426175683736801\nExactitud validaci√≥n: 18.4000\n√âpoca 614\nPerdida entrenamiento: 0.17618215829133987\nPerdida validaci√≥n: 2.452900141477585\nExactitud validaci√≥n: 18.5130\n√âpoca 615\nPerdida entrenamiento: 0.17730087129508748\nPerdida validaci√≥n: 1.8392793536186218\nExactitud validaci√≥n: 18.5130\n√âpoca 616\nPerdida entrenamiento: 0.1800769615699263\nPerdida validaci√≥n: 1.9838367700576782\nExactitud validaci√≥n: 18.8522\n√âpoca 617\nPerdida entrenamiento: 0.17642011405790553\nPerdida validaci√≥n: 1.9059662222862244\nExactitud validaci√≥n: 18.7391\n√âpoca 618\nPerdida entrenamiento: 0.17710689542924657\nPerdida validaci√≥n: 1.862879142165184\nExactitud validaci√≥n: 18.5130\n√âpoca 619\nPerdida entrenamiento: 0.17686956814106772\nPerdida validaci√≥n: 1.8814306408166885\nExactitud validaci√≥n: 18.4000\n√âpoca 620\nPerdida entrenamiento: 0.17600232581881917\nPerdida validaci√≥n: 1.8020828627049923\nExactitud validaci√≥n: 18.1739\n√âpoca 621\nPerdida entrenamiento: 0.17544799276134548\nPerdida validaci√≥n: 1.811521127820015\nExactitud validaci√≥n: 18.6261\n√âpoca 622\nPerdida entrenamiento: 0.17697353485752554\nPerdida validaci√≥n: 1.877358078956604\nExactitud validaci√≥n: 18.5130\n√âpoca 623\nPerdida entrenamiento: 0.17406106301966837\nPerdida validaci√≥n: 1.8654315024614334\nExactitud validaci√≥n: 18.1739\n√âpoca 624\nPerdida entrenamiento: 0.17648298687794628\nPerdida validaci√≥n: 1.8686436414718628\nExactitud validaci√≥n: 18.5130\n√âpoca 625\nPerdida entrenamiento: 0.17434970179901405\nPerdida validaci√≥n: 1.919616162776947\nExactitud validaci√≥n: 18.9652\n√âpoca 626\nPerdida entrenamiento: 0.17567084598190644\nPerdida validaci√≥n: 1.9153682887554169\nExactitud validaci√≥n: 18.0609\n√âpoca 627\nPerdida entrenamiento: 0.17896952392423854\nPerdida validaci√≥n: 1.8582693189382553\nExactitud validaci√≥n: 18.0609\n√âpoca 628\nPerdida entrenamiento: 0.17745003915008375\nPerdida validaci√≥n: 1.9257307648658752\nExactitud validaci√≥n: 18.5130\n√âpoca 629\nPerdida entrenamiento: 0.1788088896257036\nPerdida validaci√≥n: 1.931223213672638\nExactitud validaci√≥n: 18.5130\n√âpoca 630\nPerdida entrenamiento: 0.17631110548973083\nPerdida validaci√≥n: 2.3573699593544006\nExactitud validaci√≥n: 18.6261\n√âpoca 631\nPerdida entrenamiento: 0.17479468860170422\nPerdida validaci√≥n: 1.9445046782493591\nExactitud validaci√≥n: 18.6261\n√âpoca 632\nPerdida entrenamiento: 0.1756579818971017\nPerdida validaci√≥n: 1.973215788602829\nExactitud validaci√≥n: 18.1739\n√âpoca 633\nPerdida entrenamiento: 0.17561784189413576\nPerdida validaci√≥n: 1.9100207686424255\nExactitud validaci√≥n: 18.8522\n√âpoca 634\nPerdida entrenamiento: 0.1757204962127349\nPerdida validaci√≥n: 1.939280390739441\nExactitud validaci√≥n: 18.1739\n√âpoca 635\nPerdida entrenamiento: 0.17755503207445145\nPerdida validaci√≥n: 1.981196641921997\nExactitud validaci√≥n: 18.5130\n√âpoca 636\nPerdida entrenamiento: 0.17460980178678737\nPerdida validaci√≥n: 1.9405174255371094\nExactitud validaci√≥n: 18.4000\n√âpoca 637\nPerdida entrenamiento: 0.17348291571525967\nPerdida validaci√≥n: 1.8273062705993652\nExactitud validaci√≥n: 18.4000\n√âpoca 638\nPerdida entrenamiento: 0.1731029485954958\nPerdida validaci√≥n: 2.380571126937866\nExactitud validaci√≥n: 18.0609\n√âpoca 639\nPerdida entrenamiento: 0.17311051268787944\nPerdida validaci√≥n: 2.059565246105194\nExactitud validaci√≥n: 18.4000\n√âpoca 640\nPerdida entrenamiento: 0.17420342915198384\nPerdida validaci√≥n: 1.9567348062992096\nExactitud validaci√≥n: 18.6261\n√âpoca 641\nPerdida entrenamiento: 0.17315113938906612\nPerdida validaci√≥n: 1.9034782350063324\nExactitud validaci√≥n: 18.5130\n√âpoca 642\nPerdida entrenamiento: 0.1723686158657074\nPerdida validaci√≥n: 1.9813492596149445\nExactitud validaci√≥n: 18.5130\n√âpoca 643\nPerdida entrenamiento: 0.1716386500526877\nPerdida validaci√≥n: 1.9668281972408295\nExactitud validaci√≥n: 18.4000\n√âpoca 644\nPerdida entrenamiento: 0.17454188360887415\nPerdida validaci√≥n: 2.3830559104681015\nExactitud validaci√≥n: 18.2870\n√âpoca 645\nPerdida entrenamiento: 0.17409280687570572\nPerdida validaci√≥n: 1.8761438131332397\nExactitud validaci√≥n: 18.1739\n√âpoca 646\nPerdida entrenamiento: 0.17281085559550455\nPerdida validaci√≥n: 1.8756016343832016\nExactitud validaci√≥n: 18.4000\n√âpoca 647\nPerdida entrenamiento: 0.17153984615031412\nPerdida validaci√≥n: 1.9308282732963562\nExactitud validaci√≥n: 18.7391\n√âpoca 648\nPerdida entrenamiento: 0.17411951852195404\nPerdida validaci√≥n: 1.8359106853604317\nExactitud validaci√≥n: 17.8348\n√âpoca 649\nPerdida entrenamiento: 0.17255713790655136\nPerdida validaci√≥n: 1.8988316506147385\nExactitud validaci√≥n: 18.5130\n√âpoca 650\nPerdida entrenamiento: 0.17018533541875727\nPerdida validaci√≥n: 1.949387177824974\nExactitud validaci√≥n: 18.6261\n√âpoca 651\nPerdida entrenamiento: 0.17180895630051107\nPerdida validaci√≥n: 1.9061071127653122\nExactitud validaci√≥n: 18.5130\n√âpoca 652\nPerdida entrenamiento: 0.1712561582817751\nPerdida validaci√≥n: 1.9416884183883667\nExactitud validaci√≥n: 18.9652\n√âpoca 653\nPerdida entrenamiento: 0.17215262353420258\nPerdida validaci√≥n: 1.8685024976730347\nExactitud validaci√≥n: 18.8522\n√âpoca 654\nPerdida entrenamiento: 0.16887790841214798\nPerdida validaci√≥n: 1.8882263749837875\nExactitud validaci√≥n: 18.2870\n√âpoca 655\nPerdida entrenamiento: 0.17128623868612683\nPerdida validaci√≥n: 2.458386555314064\nExactitud validaci√≥n: 18.1739\n√âpoca 656\nPerdida entrenamiento: 0.170212522149086\nPerdida validaci√≥n: 1.954999327659607\nExactitud validaci√≥n: 18.5130\n√âpoca 657\nPerdida entrenamiento: 0.1741621494293213\nPerdida validaci√≥n: 1.9523300230503082\nExactitud validaci√≥n: 18.5130\n√âpoca 658\nPerdida entrenamiento: 0.17083424548892415\nPerdida validaci√≥n: 1.959117352962494\nExactitud validaci√≥n: 18.7391\n√âpoca 659\nPerdida entrenamiento: 0.16970867137698567\nPerdida validaci√≥n: 1.8965559303760529\nExactitud validaci√≥n: 18.4000\n√âpoca 660\nPerdida entrenamiento: 0.16913258941734538\nPerdida validaci√≥n: 1.9195391535758972\nExactitud validaci√≥n: 18.2870\n√âpoca 661\nPerdida entrenamiento: 0.16958869686898062\nPerdida validaci√≥n: 2.4342183619737625\nExactitud validaci√≥n: 17.7217\n√âpoca 662\nPerdida entrenamiento: 0.1689609788796481\nPerdida validaci√≥n: 1.990819126367569\nExactitud validaci√≥n: 18.6261\n√âpoca 663\nPerdida entrenamiento: 0.17155426433857748\nPerdida validaci√≥n: 2.4798940420150757\nExactitud validaci√≥n: 18.6261\n√âpoca 664\nPerdida entrenamiento: 0.17054487940143137\nPerdida validaci√≥n: 1.982157289981842\nExactitud validaci√≥n: 18.5130\n√âpoca 665\nPerdida entrenamiento: 0.16904305841992884\nPerdida validaci√≥n: 1.8254309445619583\nExactitud validaci√≥n: 18.4000\n√âpoca 666\nPerdida entrenamiento: 0.16776984053499558\nPerdida validaci√≥n: 1.9470479041337967\nExactitud validaci√≥n: 18.6261\n√âpoca 667\nPerdida entrenamiento: 0.16710532982559764\nPerdida validaci√≥n: 2.491328239440918\nExactitud validaci√≥n: 18.8522\n√âpoca 668\nPerdida entrenamiento: 0.16992384808904984\nPerdida validaci√≥n: 1.9949734210968018\nExactitud validaci√≥n: 18.7391\n√âpoca 669\nPerdida entrenamiento: 0.16685624595950632\nPerdida validaci√≥n: 1.8857195228338242\nExactitud validaci√≥n: 18.4000\n√âpoca 670\nPerdida entrenamiento: 0.16876719979678884\nPerdida validaci√≥n: 1.880652368068695\nExactitud validaci√≥n: 18.8522\n√âpoca 671\nPerdida entrenamiento: 0.1676985665279276\nPerdida validaci√≥n: 1.9278014451265335\nExactitud validaci√≥n: 18.0609\n√âpoca 672\nPerdida entrenamiento: 0.1676903353894458\nPerdida validaci√≥n: 1.950418546795845\nExactitud validaci√≥n: 18.6261\n√âpoca 673\nPerdida entrenamiento: 0.1701295621254865\nPerdida validaci√≥n: 1.8648300468921661\nExactitud validaci√≥n: 17.9478\n√âpoca 674\nPerdida entrenamiento: 0.17001822459347107\nPerdida validaci√≥n: 1.8509264029562473\nExactitud validaci√≥n: 18.1739\n√âpoca 675\nPerdida entrenamiento: 0.16711394970907884\nPerdida validaci√≥n: 1.954179808497429\nExactitud validaci√≥n: 18.5130\n√âpoca 676\nPerdida entrenamiento: 0.16708773023941936\nPerdida validaci√≥n: 1.924515724182129\nExactitud validaci√≥n: 18.2870\n√âpoca 677\nPerdida entrenamiento: 0.16858496648423812\nPerdida validaci√≥n: 2.000500962138176\nExactitud validaci√≥n: 18.4000\n√âpoca 678\nPerdida entrenamiento: 0.16450631793807535\nPerdida validaci√≥n: 2.566338747739792\nExactitud validaci√≥n: 18.2870\n√âpoca 679\nPerdida entrenamiento: 0.16761167566565907\nPerdida validaci√≥n: 2.0148858428001404\nExactitud validaci√≥n: 18.4000\n√âpoca 680\nPerdida entrenamiento: 0.16833147757193623\nPerdida validaci√≥n: 2.074228048324585\nExactitud validaci√≥n: 18.6261\n√âpoca 681\nPerdida entrenamiento: 0.16532384385080898\nPerdida validaci√≥n: 1.9695260673761368\nExactitud validaci√≥n: 18.6261\n√âpoca 682\nPerdida entrenamiento: 0.16553058124640407\nPerdida validaci√≥n: 1.9510675370693207\nExactitud validaci√≥n: 18.4000\n√âpoca 683\nPerdida entrenamiento: 0.16487656051621719\nPerdida validaci√≥n: 2.4368354082107544\nExactitud validaci√≥n: 18.0609\n√âpoca 684\nPerdida entrenamiento: 0.1665136836030904\nPerdida validaci√≥n: 1.9446289241313934\nExactitud validaci√≥n: 18.6261\n√âpoca 685\nPerdida entrenamiento: 0.16706801074392655\nPerdida validaci√≥n: 2.0074078142642975\nExactitud validaci√≥n: 18.2870\n√âpoca 686\nPerdida entrenamiento: 0.16774573746849508\nPerdida validaci√≥n: 1.9531133472919464\nExactitud validaci√≥n: 18.2870\n√âpoca 687\nPerdida entrenamiento: 0.1662634378846954\nPerdida validaci√≥n: 1.9650149643421173\nExactitud validaci√≥n: 18.1739\n√âpoca 688\nPerdida entrenamiento: 0.165897518834647\nPerdida validaci√≥n: 1.9263443648815155\nExactitud validaci√≥n: 18.5130\n√âpoca 689\nPerdida entrenamiento: 0.16783844898728764\nPerdida validaci√≥n: 2.5158949941396713\nExactitud validaci√≥n: 18.1739\n√âpoca 690\nPerdida entrenamiento: 0.1632937078966814\nPerdida validaci√≥n: 2.1293532699346542\nExactitud validaci√≥n: 18.4000\n√âpoca 691\nPerdida entrenamiento: 0.16604621116729343\nPerdida validaci√≥n: 1.994159609079361\nExactitud validaci√≥n: 18.2870\n√âpoca 692\nPerdida entrenamiento: 0.16435301785959916\nPerdida validaci√≥n: 1.955128014087677\nExactitud validaci√≥n: 18.5130\n√âpoca 693\nPerdida entrenamiento: 0.16429974248304086\nPerdida validaci√≥n: 1.9711505323648453\nExactitud validaci√≥n: 18.4000\n√âpoca 694\nPerdida entrenamiento: 0.1655895092031535\nPerdida validaci√≥n: 1.929766833782196\nExactitud validaci√≥n: 18.4000\n√âpoca 695\nPerdida entrenamiento: 0.16631515455596588\nPerdida validaci√≥n: 2.5120222568511963\nExactitud validaci√≥n: 18.6261\n√âpoca 696\nPerdida entrenamiento: 0.16254296022302964\nPerdida validaci√≥n: 2.6067320108413696\nExactitud validaci√≥n: 18.5130\n√âpoca 697\nPerdida entrenamiento: 0.16614514501655803\nPerdida validaci√≥n: 1.9055406600236893\nExactitud validaci√≥n: 18.2870\n√âpoca 698\nPerdida entrenamiento: 0.16295288327862234\nPerdida validaci√≥n: 2.6316159069538116\nExactitud validaci√≥n: 18.4000\n√âpoca 699\nPerdida entrenamiento: 0.16373521878438838\nPerdida validaci√≥n: 1.9525791704654694\nExactitud validaci√≥n: 18.4000\n√âpoca 700\nPerdida entrenamiento: 0.16521619216484182\nPerdida validaci√≥n: 2.574406772851944\nExactitud validaci√≥n: 18.4000\n√âpoca 701\nPerdida entrenamiento: 0.1622587906963685\nPerdida validaci√≥n: 2.044219732284546\nExactitud validaci√≥n: 18.5130\n√âpoca 702\nPerdida entrenamiento: 0.16276384846252553\nPerdida validaci√≥n: 2.4917390048503876\nExactitud validaci√≥n: 18.2870\n√âpoca 703\nPerdida entrenamiento: 0.16085231830092037\nPerdida validaci√≥n: 2.0034276843070984\nExactitud validaci√≥n: 18.7391\n√âpoca 704\nPerdida entrenamiento: 0.1621255900929956\nPerdida validaci√≥n: 1.8788238018751144\nExactitud validaci√≥n: 18.0609\n√âpoca 705\nPerdida entrenamiento: 0.16276478811221964\nPerdida validaci√≥n: 2.609136253595352\nExactitud validaci√≥n: 18.7391\n√âpoca 706\nPerdida entrenamiento: 0.16290473981815226\nPerdida validaci√≥n: 2.039955824613571\nExactitud validaci√≥n: 18.1739\n√âpoca 707\nPerdida entrenamiento: 0.1612090832170318\nPerdida validaci√≥n: 2.555538982152939\nExactitud validaci√≥n: 18.6261\n√âpoca 708\nPerdida entrenamiento: 0.16272959770525203\nPerdida validaci√≥n: 2.6732825934886932\nExactitud validaci√≥n: 18.6261\n√âpoca 709\nPerdida entrenamiento: 0.16046422807609334\nPerdida validaci√≥n: 2.65529066324234\nExactitud validaci√≥n: 18.2870\n√âpoca 710\nPerdida entrenamiento: 0.1593300660743433\nPerdida validaci√≥n: 2.6579330414533615\nExactitud validaci√≥n: 18.1739\n√âpoca 711\nPerdida entrenamiento: 0.16260490128222635\nPerdida validaci√≥n: 3.1879926919937134\nExactitud validaci√≥n: 18.2870\n√âpoca 712\nPerdida entrenamiento: 0.1639710743637646\nPerdida validaci√≥n: 2.5582952350378036\nExactitud validaci√≥n: 18.1739\n√âpoca 713\nPerdida entrenamiento: 0.16152114859398672\nPerdida validaci√≥n: 3.1042632460594177\nExactitud validaci√≥n: 18.0609\n√âpoca 714\nPerdida entrenamiento: 0.16002430547686183\nPerdida validaci√≥n: 2.019172251224518\nExactitud validaci√≥n: 18.5130\n√âpoca 715\nPerdida entrenamiento: 0.162712872685755\nPerdida validaci√≥n: 2.5908713340759277\nExactitud validaci√≥n: 18.2870\n√âpoca 716\nPerdida entrenamiento: 0.16232478969237385\nPerdida validaci√≥n: 3.1466260999441147\nExactitud validaci√≥n: 18.6261\n√âpoca 717\nPerdida entrenamiento: 0.15897689803558238\nPerdida validaci√≥n: 2.5849307030439377\nExactitud validaci√≥n: 18.1739\n√âpoca 718\nPerdida entrenamiento: 0.16153902823434158\nPerdida validaci√≥n: 2.647393435239792\nExactitud validaci√≥n: 18.1739\n√âpoca 719\nPerdida entrenamiento: 0.16119855642318726\nPerdida validaci√≥n: 2.612269088625908\nExactitud validaci√≥n: 18.5130\n√âpoca 720\nPerdida entrenamiento: 0.15967204334104762\nPerdida validaci√≥n: 2.601207673549652\nExactitud validaci√≥n: 18.0609\n√âpoca 721\nPerdida entrenamiento: 0.15950890805791407\nPerdida validaci√≥n: 2.5986678898334503\nExactitud validaci√≥n: 18.4000\n√âpoca 722\nPerdida entrenamiento: 0.1589717917582568\nPerdida validaci√≥n: 2.7100989818573\nExactitud validaci√≥n: 18.5130\n√âpoca 723\nPerdida entrenamiento: 0.16081694338251562\nPerdida validaci√≥n: 3.600108325481415\nExactitud validaci√≥n: 18.2870\n√âpoca 724\nPerdida entrenamiento: 0.16270827458185308\nPerdida validaci√≥n: 2.6002797037363052\nExactitud validaci√≥n: 18.2870\n√âpoca 725\nPerdida entrenamiento: 0.1581830897313707\nPerdida validaci√≥n: 2.6805626302957535\nExactitud validaci√≥n: 18.4000\n√âpoca 726\nPerdida entrenamiento: 0.1591141451807583\nPerdida validaci√≥n: 2.6532941460609436\nExactitud validaci√≥n: 18.9652\n√âpoca 727\nPerdida entrenamiento: 0.157598956981126\nPerdida validaci√≥n: 2.572138734161854\nExactitud validaci√≥n: 18.2870\n√âpoca 728\nPerdida entrenamiento: 0.15787621149245432\nPerdida validaci√≥n: 2.6060239374637604\nExactitud validaci√≥n: 18.1739\n√âpoca 729\nPerdida entrenamiento: 0.15959105903611465\nPerdida validaci√≥n: 2.6934962272644043\nExactitud validaci√≥n: 18.2870\n√âpoca 730\nPerdida entrenamiento: 0.1582015459151829\nPerdida validaci√≥n: 2.60768923163414\nExactitud validaci√≥n: 18.5130\n√âpoca 731\nPerdida entrenamiento: 0.157621492357815\nPerdida validaci√≥n: 3.6954606622457504\nExactitud validaci√≥n: 18.6261\n√âpoca 732\nPerdida entrenamiento: 0.15893621874206207\nPerdida validaci√≥n: 2.7011904567480087\nExactitud validaci√≥n: 18.6261\n√âpoca 733\nPerdida entrenamiento: 0.15736218322725856\nPerdida validaci√≥n: 2.8146928548812866\nExactitud validaci√≥n: 18.6261\n√âpoca 734\nPerdida entrenamiento: 0.1576247026815134\nPerdida validaci√≥n: 3.218151092529297\nExactitud validaci√≥n: 18.4000\n√âpoca 735\nPerdida entrenamiento: 0.15623568064149687\nPerdida validaci√≥n: 2.5988488644361496\nExactitud validaci√≥n: 18.2870\n√âpoca 736\nPerdida entrenamiento: 0.1571689445306273\nPerdida validaci√≥n: 2.706854522228241\nExactitud validaci√≥n: 18.2870\n√âpoca 737\nPerdida entrenamiento: 0.15617569579797633\nPerdida validaci√≥n: 2.713013231754303\nExactitud validaci√≥n: 18.8522\n√âpoca 738\nPerdida entrenamiento: 0.15783894587965572\nPerdida validaci√≥n: 2.7247913777828217\nExactitud validaci√≥n: 18.4000\n√âpoca 739\nPerdida entrenamiento: 0.15578018676708727\nPerdida validaci√≥n: 2.6655010879039764\nExactitud validaci√≥n: 18.5130\n√âpoca 740\nPerdida entrenamiento: 0.15636154088903875\nPerdida validaci√≥n: 3.165435329079628\nExactitud validaci√≥n: 18.2870\n√âpoca 741\nPerdida entrenamiento: 0.15926396539982626\nPerdida validaci√≥n: 2.5721025094389915\nExactitud validaci√≥n: 18.0609\n√âpoca 742\nPerdida entrenamiento: 0.156381642774624\nPerdida validaci√≥n: 2.6201601326465607\nExactitud validaci√≥n: 18.2870\n√âpoca 743\nPerdida entrenamiento: 0.15768505413742626\nPerdida validaci√≥n: 2.618269592523575\nExactitud validaci√≥n: 18.5130\n√âpoca 744\nPerdida entrenamiento: 0.1584767182083691\nPerdida validaci√≥n: 2.642210215330124\nExactitud validaci√≥n: 18.2870\n√âpoca 745\nPerdida entrenamiento: 0.1547083705663681\nPerdida validaci√≥n: 2.74025359749794\nExactitud validaci√≥n: 18.2870\n√âpoca 746\nPerdida entrenamiento: 0.15429270661929073\nPerdida validaci√≥n: 2.722310483455658\nExactitud validaci√≥n: 18.9652\n√âpoca 747\nPerdida entrenamiento: 0.15567336516345248\nPerdida validaci√≥n: 2.602600187063217\nExactitud validaci√≥n: 18.4000\n√âpoca 748\nPerdida entrenamiento: 0.15859329021152327\nPerdida validaci√≥n: 2.6595190167427063\nExactitud validaci√≥n: 18.4000\n√âpoca 749\nPerdida entrenamiento: 0.1617139963542714\nPerdida validaci√≥n: 2.670899897813797\nExactitud validaci√≥n: 18.2870\n√âpoca 750\nPerdida entrenamiento: 0.1628905837150181\nPerdida validaci√≥n: 3.219875618815422\nExactitud validaci√≥n: 18.6261\n√âpoca 751\nPerdida entrenamiento: 0.16012920132454703\nPerdida validaci√≥n: 3.225644052028656\nExactitud validaci√≥n: 18.2870\n√âpoca 752\nPerdida entrenamiento: 0.15868979188449242\nPerdida validaci√≥n: 2.67586637288332\nExactitud validaci√≥n: 18.4000\n√âpoca 753\nPerdida entrenamiento: 0.1629258720752071\nPerdida validaci√≥n: 2.6681269705295563\nExactitud validaci√≥n: 18.4000\n√âpoca 754\nPerdida entrenamiento: 0.15711017215953155\nPerdida validaci√≥n: 3.1297914385795593\nExactitud validaci√≥n: 17.8348\n√âpoca 755\nPerdida entrenamiento: 0.1531862835673725\nPerdida validaci√≥n: 2.726800709962845\nExactitud validaci√≥n: 18.6261\n√âpoca 756\nPerdida entrenamiento: 0.15572210028767586\nPerdida validaci√≥n: 2.682586520910263\nExactitud validaci√≥n: 18.4000\n√âpoca 757\nPerdida entrenamiento: 0.15500885072876425\nPerdida validaci√≥n: 2.609253168106079\nExactitud validaci√≥n: 18.6261\n√âpoca 758\nPerdida entrenamiento: 0.1528870090842247\nPerdida validaci√≥n: 2.7033819258213043\nExactitud validaci√≥n: 18.4000\n√âpoca 759\nPerdida entrenamiento: 0.15350659870926073\nPerdida validaci√≥n: 3.182022213935852\nExactitud validaci√≥n: 18.2870\n√âpoca 760\nPerdida entrenamiento: 0.15298916180344188\nPerdida validaci√≥n: 2.600184068083763\nExactitud validaci√≥n: 18.4000\n√âpoca 761\nPerdida entrenamiento: 0.1532105700496365\nPerdida validaci√≥n: 2.6323400884866714\nExactitud validaci√≥n: 18.2870\n√âpoca 762\nPerdida entrenamiento: 0.15355657391688404\nPerdida validaci√≥n: 2.684819757938385\nExactitud validaci√≥n: 18.7391\n√âpoca 763\nPerdida entrenamiento: 0.15543739366180756\nPerdida validaci√≥n: 3.7091951966285706\nExactitud validaci√≥n: 18.4000\n√âpoca 764\nPerdida entrenamiento: 0.15140601116068222\nPerdida validaci√≥n: 3.2474584877490997\nExactitud validaci√≥n: 18.1739\n√âpoca 765\nPerdida entrenamiento: 0.1533643844373086\nPerdida validaci√≥n: 2.633063405752182\nExactitud validaci√≥n: 18.5130\n√âpoca 766\nPerdida entrenamiento: 0.15192966732908697\nPerdida validaci√≥n: 3.1432758569717407\nExactitud validaci√≥n: 18.1739\n√âpoca 767\nPerdida entrenamiento: 0.15253492926850037\nPerdida validaci√≥n: 3.246622011065483\nExactitud validaci√≥n: 18.5130\n√âpoca 768\nPerdida entrenamiento: 0.15309041738510132\nPerdida validaci√≥n: 2.62382273375988\nExactitud validaci√≥n: 18.6261\n√âpoca 769\nPerdida entrenamiento: 0.15307236353264136\nPerdida validaci√≥n: 3.6945867389440536\nExactitud validaci√≥n: 17.9478\n√âpoca 770\nPerdida entrenamiento: 0.15285500949796507\nPerdida validaci√≥n: 2.6508836895227432\nExactitud validaci√≥n: 18.2870\n√âpoca 771\nPerdida entrenamiento: 0.15295826271176338\nPerdida validaci√≥n: 2.6306875497102737\nExactitud validaci√≥n: 17.8348\n√âpoca 772\nPerdida entrenamiento: 0.15547319151022854\nPerdida validaci√≥n: 2.6264542788267136\nExactitud validaci√≥n: 18.2870\n√âpoca 773\nPerdida entrenamiento: 0.1503035711014972\nPerdida validaci√≥n: 2.7056295573711395\nExactitud validaci√≥n: 18.4000\n√âpoca 774\nPerdida entrenamiento: 0.15113376037162893\nPerdida validaci√≥n: 3.1897840797901154\nExactitud validaci√≥n: 18.2870\n√âpoca 775\nPerdida entrenamiento: 0.15134701746351578\nPerdida validaci√≥n: 2.728394031524658\nExactitud validaci√≥n: 18.4000\n√âpoca 776\nPerdida entrenamiento: 0.1525684919427423\nPerdida validaci√≥n: 2.6042723059654236\nExactitud validaci√≥n: 18.1739\n√âpoca 777\nPerdida entrenamiento: 0.1504207696108257\nPerdida validaci√≥n: 2.600286602973938\nExactitud validaci√≥n: 18.0609\n√âpoca 778\nPerdida entrenamiento: 0.14879275551613638\nPerdida validaci√≥n: 3.278126984834671\nExactitud validaci√≥n: 18.6261\n√âpoca 779\nPerdida entrenamiento: 0.1492233626982745\nPerdida validaci√≥n: 3.162637710571289\nExactitud validaci√≥n: 17.9478\n√âpoca 780\nPerdida entrenamiento: 0.15052652950672543\nPerdida validaci√≥n: 3.2997718304395676\nExactitud validaci√≥n: 18.5130\n√âpoca 781\nPerdida entrenamiento: 0.1493004634976387\nPerdida validaci√≥n: 2.6290631741285324\nExactitud validaci√≥n: 18.4000\n√âpoca 782\nPerdida entrenamiento: 0.15232405197971008\nPerdida validaci√≥n: 2.6413462162017822\nExactitud validaci√≥n: 18.1739\n√âpoca 783\nPerdida entrenamiento: 0.149240040603806\nPerdida validaci√≥n: 3.256709098815918\nExactitud validaci√≥n: 18.6261\n√âpoca 784\nPerdida entrenamiento: 0.15085110112148173\nPerdida validaci√≥n: 3.1722599267959595\nExactitud validaci√≥n: 18.4000\n√âpoca 785\nPerdida entrenamiento: 0.151833686101086\nPerdida validaci√≥n: 2.7989502251148224\nExactitud validaci√≥n: 18.6261\n√âpoca 786\nPerdida entrenamiento: 0.1522596204543815\nPerdida validaci√≥n: 3.242053836584091\nExactitud validaci√≥n: 18.2870\n√âpoca 787\nPerdida entrenamiento: 0.14921585799140089\nPerdida validaci√≥n: 2.6283081024885178\nExactitud validaci√≥n: 18.0609\n√âpoca 788\nPerdida entrenamiento: 0.14916231044951608\nPerdida validaci√≥n: 2.6112345829606056\nExactitud validaci√≥n: 18.5130\n√âpoca 789\nPerdida entrenamiento: 0.14993023477932987\nPerdida validaci√≥n: 2.7713897675275803\nExactitud validaci√≥n: 18.5130\n√âpoca 790\nPerdida entrenamiento: 0.14652396913836985\nPerdida validaci√≥n: 2.666732057929039\nExactitud validaci√≥n: 18.2870\n√âpoca 791\nPerdida entrenamiento: 0.14829734318396626\nPerdida validaci√≥n: 2.7664362490177155\nExactitud validaci√≥n: 18.5130\n√âpoca 792\nPerdida entrenamiento: 0.14896368410657435\nPerdida validaci√≥n: 2.713522434234619\nExactitud validaci√≥n: 18.1739\n√âpoca 793\nPerdida entrenamiento: 0.1503126388963531\nPerdida validaci√≥n: 2.7845799028873444\nExactitud validaci√≥n: 18.4000\n√âpoca 794\nPerdida entrenamiento: 0.1479355679715381\nPerdida validaci√≥n: 3.245860606431961\nExactitud validaci√≥n: 18.2870\n√âpoca 795\nPerdida entrenamiento: 0.14547785524936283\nPerdida validaci√≥n: 3.1711438596248627\nExactitud validaci√≥n: 17.9478\n√âpoca 796\nPerdida entrenamiento: 0.14639997482299805\nPerdida validaci√≥n: 2.6832973659038544\nExactitud validaci√≥n: 18.0609\n√âpoca 797\nPerdida entrenamiento: 0.14787339857395956\nPerdida validaci√≥n: 3.2161754816770554\nExactitud validaci√≥n: 18.8522\n√âpoca 798\nPerdida entrenamiento: 0.14859987883006825\nPerdida validaci√≥n: 2.6865431666374207\nExactitud validaci√≥n: 18.4000\n√âpoca 799\nPerdida entrenamiento: 0.1477495445048108\nPerdida validaci√≥n: 2.63492251932621\nExactitud validaci√≥n: 18.2870\n√âpoca 800\nPerdida entrenamiento: 0.14877094437970834\nPerdida validaci√≥n: 2.6738118827342987\nExactitud validaci√≥n: 18.1739\n√âpoca 801\nPerdida entrenamiento: 0.1459410251939998\nPerdida validaci√≥n: 2.6356877088546753\nExactitud validaci√≥n: 18.2870\n√âpoca 802\nPerdida entrenamiento: 0.14662704945487134\nPerdida validaci√≥n: 2.6701188534498215\nExactitud validaci√≥n: 18.0609\n√âpoca 803\nPerdida entrenamiento: 0.14530917300897486\nPerdida validaci√≥n: 2.6025548111647367\nExactitud validaci√≥n: 18.0609\n√âpoca 804\nPerdida entrenamiento: 0.14726974793216763\nPerdida validaci√≥n: 2.7442044615745544\nExactitud validaci√≥n: 18.6261\n√âpoca 805\nPerdida entrenamiento: 0.14796733768547282\nPerdida validaci√≥n: 2.7691594064235687\nExactitud validaci√≥n: 18.4000\n√âpoca 806\nPerdida entrenamiento: 0.144820795777966\nPerdida validaci√≥n: 2.7950679063796997\nExactitud validaci√≥n: 18.1739\n√âpoca 807\nPerdida entrenamiento: 0.1451437639839509\nPerdida validaci√≥n: 2.794357866048813\nExactitud validaci√≥n: 18.4000\n√âpoca 808\nPerdida entrenamiento: 0.14519775439711177\nPerdida validaci√≥n: 3.242251545190811\nExactitud validaci√≥n: 18.5130\n√âpoca 809\nPerdida entrenamiento: 0.14527228825232563\nPerdida validaci√≥n: 3.215233623981476\nExactitud validaci√≥n: 18.4000\n√âpoca 810\nPerdida entrenamiento: 0.14561747715753667\nPerdida validaci√≥n: 2.7339600920677185\nExactitud validaci√≥n: 18.1739\n√âpoca 811\nPerdida entrenamiento: 0.1456113238545025\nPerdida validaci√≥n: 2.7056923508644104\nExactitud validaci√≥n: 18.6261\n√âpoca 812\nPerdida entrenamiento: 0.14788693189620972\nPerdida validaci√≥n: 2.826267398893833\nExactitud validaci√≥n: 18.6261\n√âpoca 813\nPerdida entrenamiento: 0.14552707049776525\nPerdida validaci√≥n: 2.6988613605499268\nExactitud validaci√≥n: 18.2870\n√âpoca 814\nPerdida entrenamiento: 0.14622166621334412\nPerdida validaci√≥n: 2.7413794100284576\nExactitud validaci√≥n: 18.6261\n√âpoca 815\nPerdida entrenamiento: 0.143801851745914\nPerdida validaci√≥n: 2.6483813747763634\nExactitud validaci√≥n: 18.6261\n√âpoca 816\nPerdida entrenamiento: 0.14336932428619442\nPerdida validaci√≥n: 2.7818442583084106\nExactitud validaci√≥n: 18.7391\n√âpoca 817\nPerdida entrenamiento: 0.14512714743614197\nPerdida validaci√≥n: 3.2018503546714783\nExactitud validaci√≥n: 18.1739\n√âpoca 818\nPerdida entrenamiento: 0.14359367025249145\nPerdida validaci√≥n: 3.8155419528484344\nExactitud validaci√≥n: 18.4000\n√âpoca 819\nPerdida entrenamiento: 0.14185754341237686\nPerdida validaci√≥n: 2.6466083750128746\nExactitud validaci√≥n: 18.7391\n√âpoca 820\nPerdida entrenamiento: 0.14415400869706096\nPerdida validaci√≥n: 2.8113376051187515\nExactitud validaci√≥n: 18.7391\n√âpoca 821\nPerdida entrenamiento: 0.14479920443366556\nPerdida validaci√≥n: 2.733074575662613\nExactitud validaci√≥n: 18.2870\n√âpoca 822\nPerdida entrenamiento: 0.14300062858006535\nPerdida validaci√≥n: 2.66407323628664\nExactitud validaci√≥n: 17.9478\n√âpoca 823\nPerdida entrenamiento: 0.14438624636215322\nPerdida validaci√≥n: 2.725124940276146\nExactitud validaci√≥n: 18.6261\n√âpoca 824\nPerdida entrenamiento: 0.14179060323273435\nPerdida validaci√≥n: 3.7919468730688095\nExactitud validaci√≥n: 18.7391\n√âpoca 825\nPerdida entrenamiento: 0.14401953755056157\nPerdida validaci√≥n: 2.940170705318451\nExactitud validaci√≥n: 18.8522\n√âpoca 826\nPerdida entrenamiento: 0.14078793148784077\nPerdida validaci√≥n: 2.730820268392563\nExactitud validaci√≥n: 18.6261\n√âpoca 827\nPerdida entrenamiento: 0.14310375184697263\nPerdida validaci√≥n: 2.7902650237083435\nExactitud validaci√≥n: 18.8522\n√âpoca 828\nPerdida entrenamiento: 0.1415631906951175\nPerdida validaci√≥n: 2.798295736312866\nExactitud validaci√≥n: 18.5130\n√âpoca 829\nPerdida entrenamiento: 0.1424680740079459\nPerdida validaci√≥n: 2.751399964094162\nExactitud validaci√≥n: 18.4000\n√âpoca 830\nPerdida entrenamiento: 0.1435266877798473\nPerdida validaci√≥n: 2.73421211540699\nExactitud validaci√≥n: 18.1739\n√âpoca 831\nPerdida entrenamiento: 0.14105699036051245\nPerdida validaci√≥n: 2.752659022808075\nExactitud validaci√≥n: 18.1739\n√âpoca 832\nPerdida entrenamiento: 0.1436002629206461\nPerdida validaci√≥n: 2.6599045991897583\nExactitud validaci√≥n: 18.5130\n√âpoca 833\nPerdida entrenamiento: 0.14401213079690933\nPerdida validaci√≥n: 2.719948261976242\nExactitud validaci√≥n: 18.2870\n√âpoca 834\nPerdida entrenamiento: 0.14162796144099796\nPerdida validaci√≥n: 3.2921559512615204\nExactitud validaci√≥n: 18.2870\n√âpoca 835\nPerdida entrenamiento: 0.14128982319551356\nPerdida validaci√≥n: 2.6709438040852547\nExactitud validaci√≥n: 18.4000\n√âpoca 836\nPerdida entrenamiento: 0.14059947935097358\nPerdida validaci√≥n: 2.7341255843639374\nExactitud validaci√≥n: 18.4000\n√âpoca 837\nPerdida entrenamiento: 0.1398994068012518\nPerdida validaci√≥n: 2.786491632461548\nExactitud validaci√≥n: 18.5130\n√âpoca 838\nPerdida entrenamiento: 0.14133495618315303\nPerdida validaci√≥n: 2.690669760107994\nExactitud validaci√≥n: 18.2870\n√âpoca 839\nPerdida entrenamiento: 0.1424069856019581\nPerdida validaci√≥n: 3.295660972595215\nExactitud validaci√≥n: 18.4000\n√âpoca 840\nPerdida entrenamiento: 0.1393086116980104\nPerdida validaci√≥n: 2.660525068640709\nExactitud validaci√≥n: 18.5130\n√âpoca 841\nPerdida entrenamiento: 0.14105064158930497\nPerdida validaci√≥n: 2.737117111682892\nExactitud validaci√≥n: 18.4000\n√âpoca 842\nPerdida entrenamiento: 0.13984821671072176\nPerdida validaci√≥n: 2.802027255296707\nExactitud validaci√≥n: 18.5130\n√âpoca 843\nPerdida entrenamiento: 0.14101365844116492\nPerdida validaci√≥n: 2.8786006718873978\nExactitud validaci√≥n: 18.6261\n√âpoca 844\nPerdida entrenamiento: 0.14051969480865142\nPerdida validaci√≥n: 2.7385316342115402\nExactitud validaci√≥n: 18.6261\n√âpoca 845\nPerdida entrenamiento: 0.14059160868911183\nPerdida validaci√≥n: 3.7438178658485413\nExactitud validaci√≥n: 18.4000\n√âpoca 846\nPerdida entrenamiento: 0.1408574015778654\nPerdida validaci√≥n: 3.268863081932068\nExactitud validaci√≥n: 18.2870\n√âpoca 847\nPerdida entrenamiento: 0.14002320258056417\nPerdida validaci√≥n: 3.4570556730031967\nExactitud validaci√≥n: 18.5130\n√âpoca 848\nPerdida entrenamiento: 0.14203892955008676\nPerdida validaci√≥n: 2.8030443489551544\nExactitud validaci√≥n: 18.4000\n√âpoca 849\nPerdida entrenamiento: 0.14011239435742884\nPerdida validaci√≥n: 2.820237874984741\nExactitud validaci√≥n: 18.2870\n√âpoca 850\nPerdida entrenamiento: 0.1396850124001503\nPerdida validaci√≥n: 3.243169218301773\nExactitud validaci√≥n: 18.5130\n√âpoca 851\nPerdida entrenamiento: 0.13872243946089463\nPerdida validaci√≥n: 2.7179784178733826\nExactitud validaci√≥n: 18.5130\n√âpoca 852\nPerdida entrenamiento: 0.13912279465619257\nPerdida validaci√≥n: 2.7133824974298477\nExactitud validaci√≥n: 18.1739\n√âpoca 853\nPerdida entrenamiento: 0.13690624988692648\nPerdida validaci√≥n: 2.8744891583919525\nExactitud validaci√≥n: 18.1739\n√âpoca 854\nPerdida entrenamiento: 0.1364170865100973\nPerdida validaci√≥n: 2.780077964067459\nExactitud validaci√≥n: 18.4000\n√âpoca 855\nPerdida entrenamiento: 0.13848148680785122\nPerdida validaci√≥n: 2.732403054833412\nExactitud validaci√≥n: 18.4000\n√âpoca 856\nPerdida entrenamiento: 0.13774363828056\nPerdida validaci√≥n: 2.748747408390045\nExactitud validaci√≥n: 18.1739\n√âpoca 857\nPerdida entrenamiento: 0.13970747677718892\nPerdida validaci√≥n: 2.7384248077869415\nExactitud validaci√≥n: 18.7391\n√âpoca 858\nPerdida entrenamiento: 0.13931907012182124\nPerdida validaci√≥n: 2.7981139421463013\nExactitud validaci√≥n: 18.5130\n√âpoca 859\nPerdida entrenamiento: 0.13711956625475602\nPerdida validaci√≥n: 2.746776044368744\nExactitud validaci√≥n: 18.4000\n√âpoca 860\nPerdida entrenamiento: 0.14136996602310853\nPerdida validaci√≥n: 2.961911305785179\nExactitud validaci√≥n: 18.8522\n√âpoca 861\nPerdida entrenamiento: 0.1371486279017785\nPerdida validaci√≥n: 2.920855939388275\nExactitud validaci√≥n: 18.9652\n√âpoca 862\nPerdida entrenamiento: 0.1369148339418804\nPerdida validaci√≥n: 3.3346258997917175\nExactitud validaci√≥n: 17.9478\n√âpoca 863\nPerdida entrenamiento: 0.1381302679724553\nPerdida validaci√≥n: 2.696602389216423\nExactitud validaci√≥n: 18.1739\n√âpoca 864\nPerdida entrenamiento: 0.13654666306341395\nPerdida validaci√≥n: 2.7097426876425743\nExactitud validaci√≥n: 18.5130\n√âpoca 865\nPerdida entrenamiento: 0.1373768339262289\nPerdida validaci√≥n: 2.822031795978546\nExactitud validaci√≥n: 17.8348\n√âpoca 866\nPerdida entrenamiento: 0.1341216191649437\nPerdida validaci√≥n: 2.705332897603512\nExactitud validaci√≥n: 18.1739\n√âpoca 867\nPerdida entrenamiento: 0.1376872159102384\nPerdida validaci√≥n: 2.7694733440876007\nExactitud validaci√≥n: 18.0609\n√âpoca 868\nPerdida entrenamiento: 0.13436881759587457\nPerdida validaci√≥n: 2.782355934381485\nExactitud validaci√≥n: 18.6261\n√âpoca 869\nPerdida entrenamiento: 0.13662084586480083\nPerdida validaci√≥n: 2.75421804189682\nExactitud validaci√≥n: 18.1739\n√âpoca 870\nPerdida entrenamiento: 0.1360327185076826\nPerdida validaci√≥n: 2.8113476634025574\nExactitud validaci√≥n: 18.7391\n√âpoca 871\nPerdida entrenamiento: 0.13782303298220916\nPerdida validaci√≥n: 2.779130682349205\nExactitud validaci√≥n: 18.5130\n√âpoca 872\nPerdida entrenamiento: 0.13344334416529713\nPerdida validaci√≥n: 2.784419059753418\nExactitud validaci√≥n: 18.2870\n√âpoca 873\nPerdida entrenamiento: 0.13555954462465117\nPerdida validaci√≥n: 2.7529250234365463\nExactitud validaci√≥n: 18.2870\n√âpoca 874\nPerdida entrenamiento: 0.1355480694157236\nPerdida validaci√≥n: 3.300339162349701\nExactitud validaci√≥n: 18.4000\n√âpoca 875\nPerdida entrenamiento: 0.13865461638745138\nPerdida validaci√≥n: 2.9780090004205704\nExactitud validaci√≥n: 18.7391\n√âpoca 876\nPerdida entrenamiento: 0.1376051098546561\nPerdida validaci√≥n: 2.8903158009052277\nExactitud validaci√≥n: 18.2870\n√âpoca 877\nPerdida entrenamiento: 0.13494748030515277\nPerdida validaci√≥n: 2.7917942702770233\nExactitud validaci√≥n: 18.6261\n√âpoca 878\nPerdida entrenamiento: 0.1352824815275038\nPerdida validaci√≥n: 3.3168766498565674\nExactitud validaci√≥n: 18.6261\n√âpoca 879\nPerdida entrenamiento: 0.1324736436500269\nPerdida validaci√≥n: 2.7636314928531647\nExactitud validaci√≥n: 18.4000\n√âpoca 880\nPerdida entrenamiento: 0.13348486493615544\nPerdida validaci√≥n: 2.871694028377533\nExactitud validaci√≥n: 18.5130\n√âpoca 881\nPerdida entrenamiento: 0.13614112927633173\nPerdida validaci√≥n: 2.82409131526947\nExactitud validaci√≥n: 18.7391\n√âpoca 882\nPerdida entrenamiento: 0.13355802678886583\nPerdida validaci√≥n: 2.7636439353227615\nExactitud validaci√≥n: 18.4000\n√âpoca 883\nPerdida entrenamiento: 0.1327956191757146\nPerdida validaci√≥n: 2.812580853700638\nExactitud validaci√≥n: 18.1739\n√âpoca 884\nPerdida entrenamiento: 0.13378482684493065\nPerdida validaci√≥n: 2.7658906280994415\nExactitud validaci√≥n: 18.2870\n√âpoca 885\nPerdida entrenamiento: 0.1324151684256161\nPerdida validaci√≥n: 2.857463538646698\nExactitud validaci√≥n: 18.4000\n√âpoca 886\nPerdida entrenamiento: 0.1337796228335184\nPerdida validaci√≥n: 3.4032358527183533\nExactitud validaci√≥n: 18.4000\n√âpoca 887\nPerdida entrenamiento: 0.13265221697442672\nPerdida validaci√≥n: 3.3464408963918686\nExactitud validaci√≥n: 18.2870\n√âpoca 888\nPerdida entrenamiento: 0.13283191577476613\nPerdida validaci√≥n: 2.790514573454857\nExactitud validaci√≥n: 18.5130\n√âpoca 889\nPerdida entrenamiento: 0.13208355623133042\nPerdida validaci√≥n: 2.8009232729673386\nExactitud validaci√≥n: 18.5130\n√âpoca 890\nPerdida entrenamiento: 0.13509997550178976\nPerdida validaci√≥n: 2.8039220198988914\nExactitud validaci√≥n: 18.5130\n√âpoca 891\nPerdida entrenamiento: 0.13466739829848795\nPerdida validaci√≥n: 2.90687495470047\nExactitud validaci√≥n: 18.2870\n√âpoca 892\nPerdida entrenamiento: 0.1318563308347674\nPerdida validaci√≥n: 2.8616604059934616\nExactitud validaci√≥n: 18.6261\n√âpoca 893\nPerdida entrenamiento: 0.13101407315801172\nPerdida validaci√≥n: 2.96872079372406\nExactitud validaci√≥n: 18.6261\n√âpoca 894\nPerdida entrenamiento: 0.13524135245996363\nPerdida validaci√≥n: 2.829436719417572\nExactitud validaci√≥n: 18.5130\n√âpoca 895\nPerdida entrenamiento: 0.13446547616930568\nPerdida validaci√≥n: 2.8921854197978973\nExactitud validaci√≥n: 18.4000\n√âpoca 896\nPerdida entrenamiento: 0.13377005256274166\nPerdida validaci√≥n: 2.9073114544153214\nExactitud validaci√≥n: 18.5130\n√âpoca 897\nPerdida entrenamiento: 0.13366495949380539\nPerdida validaci√≥n: 2.869605004787445\nExactitud validaci√≥n: 18.4000\n√âpoca 898\nPerdida entrenamiento: 0.13367976116783478\nPerdida validaci√≥n: 2.8357715904712677\nExactitud validaci√≥n: 18.2870\n√âpoca 899\nPerdida entrenamiento: 0.13272172037292929\nPerdida validaci√≥n: 3.323453515768051\nExactitud validaci√≥n: 18.2870\n√âpoca 900\nPerdida entrenamiento: 0.132703357759644\nPerdida validaci√≥n: 2.9263442158699036\nExactitud validaci√≥n: 18.6261\n√âpoca 901\nPerdida entrenamiento: 0.13167799373759942\nPerdida validaci√≥n: 3.4298669397830963\nExactitud validaci√≥n: 18.0609\n√âpoca 902\nPerdida entrenamiento: 0.1339989497381098\nPerdida validaci√≥n: 2.8030209839344025\nExactitud validaci√≥n: 18.2870\n√âpoca 903\nPerdida entrenamiento: 0.1287992243819377\nPerdida validaci√≥n: 2.8654688000679016\nExactitud validaci√≥n: 18.7391\n√âpoca 904\nPerdida entrenamiento: 0.13100341444506364\nPerdida validaci√≥n: 3.4879584312438965\nExactitud validaci√≥n: 18.4000\n√âpoca 905\nPerdida entrenamiento: 0.1310742236673832\nPerdida validaci√≥n: 2.7952137142419815\nExactitud validaci√≥n: 18.2870\n√âpoca 906\nPerdida entrenamiento: 0.12950651961214402\nPerdida validaci√≥n: 2.8933157920837402\nExactitud validaci√≥n: 18.5130\n√âpoca 907\nPerdida entrenamiento: 0.12948743275859775\nPerdida validaci√≥n: 2.920369252562523\nExactitud validaci√≥n: 18.9652\n√âpoca 908\nPerdida entrenamiento: 0.12981591811951468\nPerdida validaci√≥n: 2.874404937028885\nExactitud validaci√≥n: 18.2870\n√âpoca 909\nPerdida entrenamiento: 0.1289715587216265\nPerdida validaci√≥n: 3.2992987632751465\nExactitud validaci√≥n: 18.7391\n√âpoca 910\nPerdida entrenamiento: 0.1300869676120141\nPerdida validaci√≥n: 3.415118455886841\nExactitud validaci√≥n: 18.1739\n√âpoca 911\nPerdida entrenamiento: 0.1314496520687552\nPerdida validaci√≥n: 2.855779469013214\nExactitud validaci√≥n: 18.4000\n√âpoca 912\nPerdida entrenamiento: 0.13039520207573385\nPerdida validaci√≥n: 2.863826960325241\nExactitud validaci√≥n: 18.2870\n√âpoca 913\nPerdida entrenamiento: 0.12854845580809257\nPerdida validaci√≥n: 3.4703205823898315\nExactitud validaci√≥n: 18.5130\n√âpoca 914\nPerdida entrenamiento: 0.1311737588223289\nPerdida validaci√≥n: 2.8276840299367905\nExactitud validaci√≥n: 18.1739\n√âpoca 915\nPerdida entrenamiento: 0.12898599926163168\nPerdida validaci√≥n: 2.808225929737091\nExactitud validaci√≥n: 18.2870\n√âpoca 916\nPerdida entrenamiento: 0.12826384625890674\nPerdida validaci√≥n: 2.954753652215004\nExactitud validaci√≥n: 18.0609\n√âpoca 917\nPerdida entrenamiento: 0.1291312752839397\nPerdida validaci√≥n: 3.455663487315178\nExactitud validaci√≥n: 18.2870\n√âpoca 918\nPerdida entrenamiento: 0.1272546608439263\nPerdida validaci√≥n: 2.840626373887062\nExactitud validaci√≥n: 18.6261\n√âpoca 919\nPerdida entrenamiento: 0.12807583589764202\nPerdida validaci√≥n: 2.908486932516098\nExactitud validaci√≥n: 18.7391\n√âpoca 920\nPerdida entrenamiento: 0.12984531920622377\nPerdida validaci√≥n: 2.949549823999405\nExactitud validaci√≥n: 18.1739\n√âpoca 921\nPerdida entrenamiento: 0.12714826140333624\nPerdida validaci√≥n: 2.9026261270046234\nExactitud validaci√≥n: 18.0609\n√âpoca 922\nPerdida entrenamiento: 0.12683334858978496\nPerdida validaci√≥n: 3.4384027123451233\nExactitud validaci√≥n: 18.4000\n√âpoca 923\nPerdida entrenamiento: 0.12668604359907262\nPerdida validaci√≥n: 3.4019243717193604\nExactitud validaci√≥n: 17.9478\n√âpoca 924\nPerdida entrenamiento: 0.1273968097041635\nPerdida validaci√≥n: 3.4543668031692505\nExactitud validaci√≥n: 18.0609\n√âpoca 925\nPerdida entrenamiento: 0.1270380519768771\nPerdida validaci√≥n: 2.9080685824155807\nExactitud validaci√≥n: 18.4000\n√âpoca 926\nPerdida entrenamiento: 0.12678182059351137\nPerdida validaci√≥n: 2.854278191924095\nExactitud validaci√≥n: 18.6261\n√âpoca 927\nPerdida entrenamiento: 0.1272417313474066\nPerdida validaci√≥n: 3.409367948770523\nExactitud validaci√≥n: 18.5130\n√âpoca 928\nPerdida entrenamiento: 0.12685667372801723\nPerdida validaci√≥n: 4.08304163813591\nExactitud validaci√≥n: 18.4000\n√âpoca 929\nPerdida entrenamiento: 0.12677246003466494\nPerdida validaci√≥n: 2.8712600469589233\nExactitud validaci√≥n: 18.4000\n√âpoca 930\nPerdida entrenamiento: 0.12664389434982748\nPerdida validaci√≥n: 2.9682075679302216\nExactitud validaci√≥n: 18.5130\n√âpoca 931\nPerdida entrenamiento: 0.12917877909015207\nPerdida validaci√≥n: 2.8417866826057434\nExactitud validaci√≥n: 18.1739\n√âpoca 932\nPerdida entrenamiento: 0.12731395530350068\nPerdida validaci√≥n: 2.898645430803299\nExactitud validaci√≥n: 18.4000\n√âpoca 933\nPerdida entrenamiento: 0.12507441157803817\nPerdida validaci√≥n: 2.914635419845581\nExactitud validaci√≥n: 18.5130\n√âpoca 934\nPerdida entrenamiento: 0.12594195674447453\nPerdida validaci√≥n: 2.912827104330063\nExactitud validaci√≥n: 18.4000\n√âpoca 935\nPerdida entrenamiento: 0.1251837317557896\nPerdida validaci√≥n: 3.5243859738111496\nExactitud validaci√≥n: 18.4000\n√âpoca 936\nPerdida entrenamiento: 0.12473153717377607\nPerdida validaci√≥n: 2.9899864494800568\nExactitud validaci√≥n: 18.6261\n√âpoca 937\nPerdida entrenamiento: 0.12627896666526794\nPerdida validaci√≥n: 2.940245568752289\nExactitud validaci√≥n: 17.9478\n√âpoca 938\nPerdida entrenamiento: 0.12539050552774877\nPerdida validaci√≥n: 3.506003439426422\nExactitud validaci√≥n: 18.6261\n√âpoca 939\nPerdida entrenamiento: 0.12461071943535525\nPerdida validaci√≥n: 2.9693265557289124\nExactitud validaci√≥n: 18.8522\n√âpoca 940\nPerdida entrenamiento: 0.12703695104402654\nPerdida validaci√≥n: 3.0138815343379974\nExactitud validaci√≥n: 18.6261\n√âpoca 941\nPerdida entrenamiento: 0.12593218640369527\nPerdida validaci√≥n: 3.412371516227722\nExactitud validaci√≥n: 18.8522\n√âpoca 942\nPerdida entrenamiento: 0.12484191182781668\nPerdida validaci√≥n: 2.875510886311531\nExactitud validaci√≥n: 18.4000\n√âpoca 943\nPerdida entrenamiento: 0.12549839157830267\nPerdida validaci√≥n: 3.0640504956245422\nExactitud validaci√≥n: 18.2870\n√âpoca 944\nPerdida entrenamiento: 0.1243065052172717\nPerdida validaci√≥n: 3.010021924972534\nExactitud validaci√≥n: 18.5130\n√âpoca 945\nPerdida entrenamiento: 0.12402418606421527\nPerdida validaci√≥n: 2.888392746448517\nExactitud validaci√≥n: 18.6261\n√âpoca 946\nPerdida entrenamiento: 0.12377885378458921\nPerdida validaci√≥n: 2.8283270969986916\nExactitud validaci√≥n: 18.1739\n√âpoca 947\nPerdida entrenamiento: 0.12332157023689326\nPerdida validaci√≥n: 3.4357332587242126\nExactitud validaci√≥n: 18.1739\n√âpoca 948\nPerdida entrenamiento: 0.12415540525141884\nPerdida validaci√≥n: 2.9335389137268066\nExactitud validaci√≥n: 18.7391\n√âpoca 949\nPerdida entrenamiento: 0.12486725640209283\nPerdida validaci√≥n: 2.931018203496933\nExactitud validaci√≥n: 18.6261\n√âpoca 950\nPerdida entrenamiento: 0.12408434424330206\nPerdida validaci√≥n: 3.054698035120964\nExactitud validaci√≥n: 18.6261\n√âpoca 951\nPerdida entrenamiento: 0.12574190032832763\nPerdida validaci√≥n: 3.0038841366767883\nExactitud validaci√≥n: 18.2870\n√âpoca 952\nPerdida entrenamiento: 0.12242736294865608\nPerdida validaci√≥n: 4.074982047080994\nExactitud validaci√≥n: 18.4000\n√âpoca 953\nPerdida entrenamiento: 0.12435674601617981\nPerdida validaci√≥n: 2.973332405090332\nExactitud validaci√≥n: 18.5130\n√âpoca 954\nPerdida entrenamiento: 0.12533021915484877\nPerdida validaci√≥n: 3.4903931617736816\nExactitud validaci√≥n: 18.5130\n√âpoca 955\nPerdida entrenamiento: 0.12362913436749402\nPerdida validaci√≥n: 2.894077181816101\nExactitud validaci√≥n: 18.0609\n√âpoca 956\nPerdida entrenamiento: 0.1241259554072338\nPerdida validaci√≥n: 3.5641388595104218\nExactitud validaci√≥n: 18.8522\n√âpoca 957\nPerdida entrenamiento: 0.12326250049997778\nPerdida validaci√≥n: 2.894750624895096\nExactitud validaci√≥n: 18.7391\n√âpoca 958\nPerdida entrenamiento: 0.12201590529259514\nPerdida validaci√≥n: 3.554157704114914\nExactitud validaci√≥n: 18.7391\n√âpoca 959\nPerdida entrenamiento: 0.12234444193103734\nPerdida validaci√≥n: 3.0658498108386993\nExactitud validaci√≥n: 18.7391\n√âpoca 960\nPerdida entrenamiento: 0.1225890420815524\nPerdida validaci√≥n: 2.9639132916927338\nExactitud validaci√≥n: 18.2870\n√âpoca 961\nPerdida entrenamiento: 0.12655563323813326\nPerdida validaci√≥n: 3.4610494822263718\nExactitud validaci√≥n: 18.2870\n√âpoca 962\nPerdida entrenamiento: 0.12557828514014974\nPerdida validaci√≥n: 3.0472725331783295\nExactitud validaci√≥n: 18.7391\n√âpoca 963\nPerdida entrenamiento: 0.12406371117514722\nPerdida validaci√≥n: 3.4296689927577972\nExactitud validaci√≥n: 18.5130\n√âpoca 964\nPerdida entrenamiento: 0.12306797109982547\nPerdida validaci√≥n: 2.8831294775009155\nExactitud validaci√≥n: 18.6261\n√âpoca 965\nPerdida entrenamiento: 0.12154533823623377\nPerdida validaci√≥n: 3.0393559336662292\nExactitud validaci√≥n: 18.0609\n√âpoca 966\nPerdida entrenamiento: 0.12231333071694654\nPerdida validaci√≥n: 2.893571987748146\nExactitud validaci√≥n: 18.2870\n√âpoca 967\nPerdida entrenamiento: 0.12442432300132863\nPerdida validaci√≥n: 2.8784404695034027\nExactitud validaci√≥n: 18.8522\n√âpoca 968\nPerdida entrenamiento: 0.12219117998200305\nPerdida validaci√≥n: 3.0569884181022644\nExactitud validaci√≥n: 18.5130\n√âpoca 969\nPerdida entrenamiento: 0.1204835956587511\nPerdida validaci√≥n: 3.0531783998012543\nExactitud validaci√≥n: 18.1739\n√âpoca 970\nPerdida entrenamiento: 0.12147321595865138\nPerdida validaci√≥n: 3.105465844273567\nExactitud validaci√≥n: 18.5130\n√âpoca 971\nPerdida entrenamiento: 0.11965199538013514\nPerdida validaci√≥n: 2.9067180305719376\nExactitud validaci√≥n: 18.2870\n√âpoca 972\nPerdida entrenamiento: 0.1203617955393651\nPerdida validaci√≥n: 2.853972941637039\nExactitud validaci√≥n: 18.2870\n√âpoca 973\nPerdida entrenamiento: 0.12197020540342611\nPerdida validaci√≥n: 2.951186329126358\nExactitud validaci√≥n: 18.6261\n√âpoca 974\nPerdida entrenamiento: 0.12436810749418595\nPerdida validaci√≥n: 3.067672148346901\nExactitud validaci√≥n: 18.6261\n√âpoca 975\nPerdida entrenamiento: 0.12134960271856364\nPerdida validaci√≥n: 3.5442528426647186\nExactitud validaci√≥n: 18.2870\n√âpoca 976\nPerdida entrenamiento: 0.1222062270869227\nPerdida validaci√≥n: 3.071064904332161\nExactitud validaci√≥n: 18.7391\n√âpoca 977\nPerdida entrenamiento: 0.12381410642581828\nPerdida validaci√≥n: 2.9515878558158875\nExactitud validaci√≥n: 18.1739\n√âpoca 978\nPerdida entrenamiento: 0.11919486478847616\nPerdida validaci√≥n: 2.987251326441765\nExactitud validaci√≥n: 18.8522\n√âpoca 979\nPerdida entrenamiento: 0.12118908982066547\nPerdida validaci√≥n: 2.964499592781067\nExactitud validaci√≥n: 18.2870\n√âpoca 980\nPerdida entrenamiento: 0.11982706517857664\nPerdida validaci√≥n: 2.884852759540081\nExactitud validaci√≥n: 18.2870\n√âpoca 981\nPerdida entrenamiento: 0.12243366482503273\nPerdida validaci√≥n: 2.9526966214179993\nExactitud validaci√≥n: 18.5130\n√âpoca 982\nPerdida entrenamiento: 0.12023616615025436\nPerdida validaci√≥n: 2.892222762107849\nExactitud validaci√≥n: 18.5130\n√âpoca 983\nPerdida entrenamiento: 0.11949533388456877\nPerdida validaci√≥n: 3.0738677978515625\nExactitud validaci√≥n: 18.5130\n√âpoca 984\nPerdida entrenamiento: 0.11815058308489182\nPerdida validaci√≥n: 2.943865194916725\nExactitud validaci√≥n: 18.1739\n√âpoca 985\nPerdida entrenamiento: 0.12010063581606921\nPerdida validaci√≥n: 3.0461696088314056\nExactitud validaci√≥n: 18.2870\n√âpoca 986\nPerdida entrenamiento: 0.1200608185985509\nPerdida validaci√≥n: 4.0663831532001495\nExactitud validaci√≥n: 18.4000\n√âpoca 987\nPerdida entrenamiento: 0.11974002442815725\nPerdida validaci√≥n: 3.468088820576668\nExactitud validaci√≥n: 18.1739\n√âpoca 988\nPerdida entrenamiento: 0.11906973097254248\nPerdida validaci√≥n: 2.943978175520897\nExactitud validaci√≥n: 18.0609\n√âpoca 989\nPerdida entrenamiento: 0.12085146150168251\nPerdida validaci√≥n: 3.0875197649002075\nExactitud validaci√≥n: 18.4000\n√âpoca 990\nPerdida entrenamiento: 0.11931220442056656\nPerdida validaci√≥n: 3.4530164301395416\nExactitud validaci√≥n: 18.2870\n√âpoca 991\nPerdida entrenamiento: 0.1200842373073101\nPerdida validaci√≥n: 3.108154445886612\nExactitud validaci√≥n: 18.4000\n√âpoca 992\nPerdida entrenamiento: 0.11944863528889768\nPerdida validaci√≥n: 3.4121116399765015\nExactitud validaci√≥n: 18.2870\n√âpoca 993\nPerdida entrenamiento: 0.11968237862867467\nPerdida validaci√≥n: 2.9360441118478775\nExactitud validaci√≥n: 18.2870\n√âpoca 994\nPerdida entrenamiento: 0.11799231237348388\nPerdida validaci√≥n: 3.036650687456131\nExactitud validaci√≥n: 18.4000\n√âpoca 995\nPerdida entrenamiento: 0.11872703187605914\nPerdida validaci√≥n: 2.939451888203621\nExactitud validaci√≥n: 18.4000\n√âpoca 996\nPerdida entrenamiento: 0.1186886644538711\nPerdida validaci√≥n: 3.0029216408729553\nExactitud validaci√≥n: 18.4000\n√âpoca 997\nPerdida entrenamiento: 0.11697329558870372\nPerdida validaci√≥n: 2.912400111556053\nExactitud validaci√≥n: 18.1739\n√âpoca 998\nPerdida entrenamiento: 0.11653838547713616\nPerdida validaci√≥n: 3.0047235190868378\nExactitud validaci√≥n: 18.1739\n√âpoca 999\nPerdida entrenamiento: 0.11792571338660576\nPerdida validaci√≥n: 4.158627465367317\nExactitud validaci√≥n: 18.5130\n√âpoca 1000\nPerdida entrenamiento: 0.11670456804773387\nPerdida validaci√≥n: 2.9439720809459686\nExactitud validaci√≥n: 18.1739"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‚ÄòMachine Learning with R‚Äô by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book‚Äôs specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book‚Äôs examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary‚Äôs residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution\n\ndata_path = \"../../data/\""
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load\n\ndata = pd.read_csv(data_path+\"insurance_2.csv\")\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\nNumber of GPUs available: 1\nGPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   salary    1338 non-null   float64\n 6   region    1338 non-null   object \n 7   charges   1338 non-null   float64\ndtypes: float64(3), int64(2), object(3)\nmemory usage: 83.8+ KB\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\ncount\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n\n\nmean\n39.207025\n30.663397\n1.094918\n159064.411451\n13270.422265\n\n\nstd\n14.049960\n6.098187\n1.205493\n41741.994963\n12110.011237\n\n\nmin\n18.000000\n15.960000\n0.000000\n104622.922023\n1121.873900\n\n\n25%\n27.000000\n26.296250\n0.000000\n130087.161933\n4740.287150\n\n\n50%\n39.000000\n30.400000\n1.000000\n146740.897257\n9382.033000\n\n\n75%\n51.000000\n34.693750\n2.000000\n171897.191284\n16639.912515\n\n\nmax\n64.000000\n53.130000\n5.000000\n338460.517246\n63770.428010\n\n\n\n\n\n\n\n\ndata.select_dtypes(\"object\")\n\n\n\n\n\n\n\n\nsex\nsmoker\nregion\n\n\n\n\n0\nfemale\nyes\nsouthwest\n\n\n1\nmale\nno\nsoutheast\n\n\n2\nmale\nno\nsoutheast\n\n\n3\nmale\nno\nnorthwest\n\n\n4\nmale\nno\nnorthwest\n\n\n...\n...\n...\n...\n\n\n1333\nmale\nno\nnorthwest\n\n\n1334\nfemale\nno\nnortheast\n\n\n1335\nfemale\nno\nsoutheast\n\n\n1336\nfemale\nno\nsouthwest\n\n\n1337\nfemale\nyes\nnorthwest\n\n\n\n\n1338 rows √ó 3 columns\n\n\n\n\ndata[\"sex\"] = data[\"sex\"].astype(\"category\")\ndata[\"smoker\"] = data[\"smoker\"].astype(\"category\")\ndata[\"region\"] = data[\"region\"].astype(\"category\")\n\n\ndata.select_dtypes(\"number\")\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\n0\n19\n27.900\n0\n159272.812482\n16884.92400\n\n\n1\n18\n33.770\n1\n117088.625944\n1725.55230\n\n\n2\n28\n33.000\n3\n129043.852213\n4449.46200\n\n\n3\n33\n22.705\n0\n194635.486180\n21984.47061\n\n\n4\n32\n28.880\n0\n113585.904592\n3866.85520\n\n\n...\n...\n...\n...\n...\n...\n\n\n1333\n50\n30.970\n3\n145933.927725\n10600.54830\n\n\n1334\n18\n31.920\n0\n117665.917758\n2205.98080\n\n\n1335\n18\n36.850\n0\n133402.353115\n1629.83350\n\n\n1336\n21\n25.800\n0\n133975.682996\n2007.94500\n\n\n1337\n61\n29.070\n0\n216658.755628\n29141.36030\n\n\n\n\n1338 rows √ó 5 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   age       1338 non-null   int64   \n 1   sex       1338 non-null   category\n 2   bmi       1338 non-null   float64 \n 3   children  1338 non-null   int64   \n 4   smoker    1338 non-null   category\n 5   salary    1338 non-null   float64 \n 6   region    1338 non-null   category\n 7   charges   1338 non-null   float64 \ndtypes: category(3), float64(3), int64(2)\nmemory usage: 56.8 KB\n\n\n\n\n2. Visualizing distributions\n\nsns.histplot(data[\"bmi\"], stat=\"probability\")\n\n\n\n\n\n\n\n\n\n\n3. Exploring relationships between variables\n\nsns.scatterplot(data=data, x=\"bmi\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\n\n4. Analyzing categorical variables\n\nsns.countplot(data=data, x=\"smoker\", stat=\"probability\")\n\n\n\n\n\n\n\n\n\nsns.boxplot(data=data, y=\"charges\", x=\"smoker\")\n\n\n\n\n\n\n\n\n\nsns.pointplot(data=data, x=\"sex\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\ng001 = sns.FacetGrid(data=data, col=\"smoker\", row=\"sex\")\ng001.map(plt.scatter, \"bmi\", \"charges\")\n\n\n\n\n\n\n\n\n\nsns.regplot(data=data, x=\"salary\", y=\"charges\",\n            scatter_kws={\"color\": \"blue\"},  # Color de los puntos\n            line_kws={\"color\": \"red\"})"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "title": "Health Care Cost Predictor",
    "section": "5. Checking availability of GPU",
    "text": "5. Checking availability of GPU\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\ndevice1\n\nUsing device: cuda:0\n\n\ndevice(type='cuda', index=0)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "title": "Health Care Cost Predictor",
    "section": "6. Splitting data",
    "text": "6. Splitting data\n\nentrada = data[\"salary\"].to_numpy().reshape(-1, 1)\nsalida = data[\"charges\"].to_numpy().reshape(-1, 1)\n\n\nstandarScaler_features = StandardScaler().fit(entrada)\nstandarScaler_output = StandardScaler().fit(salida)\n\n\nsalary_train, salary_test, charges_train, charges_test = train_test_split(\n    standarScaler_features.transform(entrada),\n    standarScaler_output.transform(salida),\n    train_size=0.7,\n    shuffle=True,\n)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "title": "Health Care Cost Predictor",
    "section": "7. Converting Data To Tensor",
    "text": "7. Converting Data To Tensor\n\nt_salary_train = torch.tensor(salary_train, dtype=torch.float32, device=device1)\nt_salary_test = torch.tensor(salary_test, dtype=torch.float32, device=device1)\nt_charges_train = torch.tensor(charges_train, dtype=torch.float32, device=device1)\nt_charges_test = torch.tensor(charges_test, dtype=torch.float32, device=device1)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "8. Model Implementation",
    "text": "8. Model Implementation\n\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\nmodel = LinearRegression().to(device1)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "10. Train Model",
    "text": "10. Train Model\n\nnum_epochs = 1000\nfor epoch in range(num_epochs):\n\n     # Fordward Pass and loss\n\n     charges_predicted = model(t_salary_train)\n     loss = criterion(charges_predicted, t_charges_train)\n\n     # Backward pass\n     loss.backward()\n\n     #wweights update\n     optimizer.step()\n     optimizer.zero_grad()\n\n     # Progress tracking\n\n     if (epoch+1)%10 ==0:\n          print(f\"Epoch: {epoch+1}, loss={loss.item():.4f}\")\n\nEpoch: 10, loss=1.2763\nEpoch: 20, loss=0.8460\nEpoch: 30, loss=0.5655\nEpoch: 40, loss=0.3828\nEpoch: 50, loss=0.2637\nEpoch: 60, loss=0.1861\nEpoch: 70, loss=0.1355\nEpoch: 80, loss=0.1026\nEpoch: 90, loss=0.0811\nEpoch: 100, loss=0.0671\nEpoch: 110, loss=0.0579\nEpoch: 120, loss=0.0520\nEpoch: 130, loss=0.0481\nEpoch: 140, loss=0.0456\nEpoch: 150, loss=0.0439\nEpoch: 160, loss=0.0428\nEpoch: 170, loss=0.0421\nEpoch: 180, loss=0.0417\nEpoch: 190, loss=0.0414\nEpoch: 200, loss=0.0412\nEpoch: 210, loss=0.0411\nEpoch: 220, loss=0.0410\nEpoch: 230, loss=0.0409\nEpoch: 240, loss=0.0409\nEpoch: 250, loss=0.0409\nEpoch: 260, loss=0.0408\nEpoch: 270, loss=0.0408\nEpoch: 280, loss=0.0408\nEpoch: 290, loss=0.0408\nEpoch: 300, loss=0.0408\nEpoch: 310, loss=0.0408\nEpoch: 320, loss=0.0408\nEpoch: 330, loss=0.0408\nEpoch: 340, loss=0.0408\nEpoch: 350, loss=0.0408\nEpoch: 360, loss=0.0408\nEpoch: 370, loss=0.0408\nEpoch: 380, loss=0.0408\nEpoch: 390, loss=0.0408\nEpoch: 400, loss=0.0408\nEpoch: 410, loss=0.0408\nEpoch: 420, loss=0.0408\nEpoch: 430, loss=0.0408\nEpoch: 440, loss=0.0408\nEpoch: 450, loss=0.0408\nEpoch: 460, loss=0.0408\nEpoch: 470, loss=0.0408\nEpoch: 480, loss=0.0408\nEpoch: 490, loss=0.0408\nEpoch: 500, loss=0.0408\nEpoch: 510, loss=0.0408\nEpoch: 520, loss=0.0408\nEpoch: 530, loss=0.0408\nEpoch: 540, loss=0.0408\nEpoch: 550, loss=0.0408\nEpoch: 560, loss=0.0408\nEpoch: 570, loss=0.0408\nEpoch: 580, loss=0.0408\nEpoch: 590, loss=0.0408\nEpoch: 600, loss=0.0408\nEpoch: 610, loss=0.0408\nEpoch: 620, loss=0.0408\nEpoch: 630, loss=0.0408\nEpoch: 640, loss=0.0408\nEpoch: 650, loss=0.0408\nEpoch: 660, loss=0.0408\nEpoch: 670, loss=0.0408\nEpoch: 680, loss=0.0408\nEpoch: 690, loss=0.0408\nEpoch: 700, loss=0.0408\nEpoch: 710, loss=0.0408\nEpoch: 720, loss=0.0408\nEpoch: 730, loss=0.0408\nEpoch: 740, loss=0.0408\nEpoch: 750, loss=0.0408\nEpoch: 760, loss=0.0408\nEpoch: 770, loss=0.0408\nEpoch: 780, loss=0.0408\nEpoch: 790, loss=0.0408\nEpoch: 800, loss=0.0408\nEpoch: 810, loss=0.0408\nEpoch: 820, loss=0.0408\nEpoch: 830, loss=0.0408\nEpoch: 840, loss=0.0408\nEpoch: 850, loss=0.0408\nEpoch: 860, loss=0.0408\nEpoch: 870, loss=0.0408\nEpoch: 880, loss=0.0408\nEpoch: 890, loss=0.0408\nEpoch: 900, loss=0.0408\nEpoch: 910, loss=0.0408\nEpoch: 920, loss=0.0408\nEpoch: 930, loss=0.0408\nEpoch: 940, loss=0.0408\nEpoch: 950, loss=0.0408\nEpoch: 960, loss=0.0408\nEpoch: 970, loss=0.0408\nEpoch: 980, loss=0.0408\nEpoch: 990, loss=0.0408\nEpoch: 1000, loss=0.0408\n\n\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )\n\n\n\n\n\n\n\n\n\ns_predicha = standarScaler_output.inverse_transform(prediction.cpu().numpy())\ns_real = standarScaler_output.inverse_transform(charges_test)\n\nresiduos = s_real- s_predicha\n\nsm.graphics.tsa.plot_acf(residuos, lags=100)"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp.¬†261‚Äì265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp.¬†261‚Äì265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\n#data = pd.read_csv(\"drive/MyDrive/ASIM/diabetes.csv\")\ndata = pd.read_csv(\"../../data/diabetes.csv\")\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\ncount\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n\n\nmean\n3.845052\n120.894531\n69.105469\n20.536458\n79.799479\n31.992578\n0.471876\n33.240885\n0.348958\n\n\nstd\n3.369578\n31.972618\n19.355807\n15.952218\n115.244002\n7.884160\n0.331329\n11.760232\n0.476951\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.078000\n21.000000\n0.000000\n\n\n25%\n1.000000\n99.000000\n62.000000\n0.000000\n0.000000\n27.300000\n0.243750\n24.000000\n0.000000\n\n\n50%\n3.000000\n117.000000\n72.000000\n23.000000\n30.500000\n32.000000\n0.372500\n29.000000\n0.000000\n\n\n75%\n6.000000\n140.250000\n80.000000\n32.000000\n127.250000\n36.600000\n0.626250\n41.000000\n1.000000\n\n\nmax\n17.000000\n199.000000\n122.000000\n99.000000\n846.000000\n67.100000\n2.420000\n81.000000\n1.000000"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values\n\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship\n\nsns.histplot(data=data, x=\"BloodPressure\", kde=True)\n\n\n\n\n\n\n\n\n\nsns.countplot(data=data, x=\"Outcome\")\n\n\n\n\n\n\n\n\n\ndata.drop(data[data[\"BloodPressure\"]==0].index, inplace=True)\n\n\nsns.countplot(data=data, x=\"Outcome\")\n\n\n\n\n\n\n\n\n\nfeatures = [\n    \"Pregnancies\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"BMI\",\n    \"DiabetesPedigreeFunction\",\n    \"Age\"\n]\n\noutput = [\n    \"Outcome\"\n]"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data\n\nstandardScaler_features = StandardScaler().fit(data[features])\nstandardScaler_output = StandardScaler().fit(data[output])\n\nstandard_features = standardScaler_features.transform(data[features])\nstandard_output = data[output].values.reshape(-1,1)\n\n\nclass ConjuntoDatosTabulares(Dataset):\n  def __init__(self, ent, sal):\n    self.inputs = torch.tensor(ent, dtype=torch.float32)\n    self.outputs = torch.tensor(sal, dtype=torch.float32)\n\n  def __len__(self):\n    return len(self.inputs)\n\n  def __getitem__(self, idx):\n    return self.inputs[idx], self.outputs[idx]\n\n\n\nbs = 32  # Tama√±o del lote\n\n\ntotal_data = ConjuntoDatosTabulares(ent=standard_features, sal=standard_output)\ntotal_data_dataloader = DataLoader(total_data, batch_size = 32, shuffle=True)\n\n\ntrain_ds, val_ds, test_ds = random_split(total_data, [0.56, 0.14, 0.3])\n\ntrain_loader = DataLoader(train_ds, batch_size = bs, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size = bs, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size = bs, shuffle=True)\n\n\na = next(iter(total_data_dataloader))\nx, y = a"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#create-neural-network",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#create-neural-network",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network",
    "text": "Create neural network\n\nclass RedNeuronal(nn.Module):\n  def __init__(self, num_caract, num_salidas):\n    super(RedNeuronal, self).__init__()\n    self.num_inputs = num_caract\n    self.num_outputs = num_salidas\n    self.hidden1 = nn.Linear(self.num_inputs, 10)\n    self.fact1 = nn.ReLU()\n    self.hidden2 = nn.Linear(10, 12)\n    self.fact2 = nn.ReLU()\n    self.hidden3 = nn.Linear(12, 13)\n    self.fact3 = nn.ReLU()\n    self.hidden4 = nn.Linear(13, self.num_outputs)\n    self.fact4 = nn.Sigmoid()\n\n  def forward(self, x):\n    x = self.fact1(self.hidden1(x))\n    x = self.fact2(self.hidden2(x))\n    x = self.fact3(self.hidden3(x))\n    x = self.fact4(self.hidden4(x))\n    return x"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model\n\nepocas = 1000  # N√∫mero de √©pocas de entrenamiento\n\n\nred = RedNeuronal(8, 1)\nred = red.to(device=device1)\n\n\nprint(red.parameters())\n\n&lt;generator object Module.parameters at 0x7fcf6518c190&gt;\n\n\n\ncriterio = nn.BCELoss()\noptimizador = optim.Adam(red.parameters(), lr=0.001)\n\n\n# Entrenar la red neuronal\nfor epoca in range(epocas):\n    perdida_entrenamiento = 0\n    for X_batch, y_batch in train_loader:\n        # Pasar los datos por la red neuronal\n        salida = red(X_batch.to(device=device1))\n\n        # Calcular la p√©rdida\n        perdida = criterio(salida, y_batch.to(device=device1))\n\n        # Actualizar los pesos\n        optimizador.zero_grad()\n        perdida.backward()\n        optimizador.step()\n        perdida_entrenamiento += perdida.item()\n\n    # Imprimir la p√©rdida en cada √©poca\n    # print(f\"√âpoca {epoca+1}, p√©rdida: {perdida.item():.8f}\")\n    perdida_validacion = 0\n    con_exactitud = 0\n    total = 0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            # Pasar los datos por la red neuronal\n            salida = red(X_batch.to(device=device1))\n\n            # Calcular la p√©rdida\n            perdida = criterio(salida, y_batch.to(device=device1))\n\n            perdida_validacion += perdida.item()\n\n    # Imprimir los resultados\n    print(f\"√âpoca {epoca+1}\")\n    print(f\"Perdida entrenamiento: {perdida_entrenamiento/len(train_loader)}\")\n    print(f\"Perdida validaci√≥n: {perdida_validacion/len(val_loader)}\")\n\n√âpoca 1\nPerdida entrenamiento: 0.7267978053826553\nPerdida validaci√≥n: 0.7159790992736816\n√âpoca 2\nPerdida entrenamiento: 0.7182281980147729\nPerdida validaci√≥n: 0.7118411660194397\n√âpoca 3\nPerdida entrenamiento: 0.7104145655265222\nPerdida validaci√≥n: 0.7019551694393158\n√âpoca 4\nPerdida entrenamiento: 0.7015121854268588\nPerdida validaci√≥n: 0.6946617513895035\n√âpoca 5\nPerdida entrenamiento: 0.6905638575553894\nPerdida validaci√≥n: 0.6804916262626648\n√âpoca 6\nPerdida entrenamiento: 0.6800636832530682\nPerdida validaci√≥n: 0.6584434807300568\n√âpoca 7\nPerdida entrenamiento: 0.6666435966124902\nPerdida validaci√≥n: 0.6408872753381729\n√âpoca 8\nPerdida entrenamiento: 0.6524532116376437\nPerdida validaci√≥n: 0.6386194676160812\n√âpoca 9\nPerdida entrenamiento: 0.6351055273642907\nPerdida validaci√≥n: 0.602764829993248\n√âpoca 10\nPerdida entrenamiento: 0.6161944040885339\nPerdida validaci√≥n: 0.5701538622379303\n√âpoca 11\nPerdida entrenamiento: 0.5947254254267766\nPerdida validaci√≥n: 0.5622555166482925\n√âpoca 12\nPerdida entrenamiento: 0.5704072484603295\nPerdida validaci√≥n: 0.5211050510406494\n√âpoca 13\nPerdida entrenamiento: 0.548466084095148\nPerdida validaci√≥n: 0.480282261967659\n√âpoca 14\nPerdida entrenamiento: 0.5316605155284588\nPerdida validaci√≥n: 0.4288185238838196\n√âpoca 15\nPerdida entrenamiento: 0.5179111269804147\nPerdida validaci√≥n: 0.4584948718547821\n√âpoca 16\nPerdida entrenamiento: 0.5062230687875015\nPerdida validaci√≥n: 0.4407348707318306\n√âpoca 17\nPerdida entrenamiento: 0.49960110966975874\nPerdida validaci√≥n: 0.4830065444111824\n√âpoca 18\nPerdida entrenamiento: 0.49942563359554\nPerdida validaci√≥n: 0.3943897932767868\n√âpoca 19\nPerdida entrenamiento: 0.48894316875017607\nPerdida validaci√≥n: 0.4019322246313095\n√âpoca 20\nPerdida entrenamiento: 0.4884497339908893\nPerdida validaci√≥n: 0.37546899914741516\n√âpoca 21\nPerdida entrenamiento: 0.4813868930706611\nPerdida validaci√≥n: 0.39141348749399185\n√âpoca 22\nPerdida entrenamiento: 0.4776655458486997\nPerdida validaci√≥n: 0.3661811575293541\n√âpoca 23\nPerdida entrenamiento: 0.47272541660528916\nPerdida validaci√≥n: 0.45798082649707794\n√âpoca 24\nPerdida entrenamiento: 0.4703685755913074\nPerdida validaci√≥n: 0.44551635533571243\n√âpoca 25\nPerdida entrenamiento: 0.46607735523810756\nPerdida validaci√≥n: 0.4059871584177017\n√âpoca 26\nPerdida entrenamiento: 0.4660418469172258\nPerdida validaci√≥n: 0.38415608555078506\n√âpoca 27\nPerdida entrenamiento: 0.4620107962534978\nPerdida validaci√≥n: 0.4321253150701523\n√âpoca 28\nPerdida entrenamiento: 0.45929738879203796\nPerdida validaci√≥n: 0.3779127597808838\n√âpoca 29\nPerdida entrenamiento: 0.4604421624770531\nPerdida validaci√≥n: 0.39340754598379135\n√âpoca 30\nPerdida entrenamiento: 0.45797420465029204\nPerdida validaci√≥n: 0.41168972104787827\n√âpoca 31\nPerdida entrenamiento: 0.453733898126162\nPerdida validaci√≥n: 0.3659657798707485\n√âpoca 32\nPerdida entrenamiento: 0.4509870432890378\nPerdida validaci√≥n: 0.35692010819911957\n√âpoca 33\nPerdida entrenamiento: 0.4491236439118019\nPerdida validaci√≥n: 0.39127306640148163\n√âpoca 34\nPerdida entrenamiento: 0.44821084233430714\nPerdida validaci√≥n: 0.4903676062822342\n√âpoca 35\nPerdida entrenamiento: 0.4483366654469417\nPerdida validaci√≥n: 0.41949494183063507\n√âpoca 36\nPerdida entrenamiento: 0.4433157375225654\nPerdida validaci√≥n: 0.3596146032214165\n√âpoca 37\nPerdida entrenamiento: 0.44532549610504735\nPerdida validaci√≥n: 0.4067723825573921\n√âpoca 38\nPerdida entrenamiento: 0.441569637793761\nPerdida validaci√≥n: 0.3658885098993778\n√âpoca 39\nPerdida entrenamiento: 0.4414483675589928\nPerdida validaci√≥n: 0.36617711186408997\n√âpoca 40\nPerdida entrenamiento: 0.442814643566425\nPerdida validaci√≥n: 0.43410953134298325\n√âpoca 41\nPerdida entrenamiento: 0.44105668709828305\nPerdida validaci√≥n: 0.41927940398454666\n√âpoca 42\nPerdida entrenamiento: 0.4365276006551889\nPerdida validaci√≥n: 0.4514813870191574\n√âpoca 43\nPerdida entrenamiento: 0.4371137320995331\nPerdida validaci√≥n: 0.40512615442276\n√âpoca 44\nPerdida entrenamiento: 0.4338447176493131\nPerdida validaci√≥n: 0.3971825987100601\n√âpoca 45\nPerdida entrenamiento: 0.4321022881911351\nPerdida validaci√≥n: 0.4355890303850174\n√âpoca 46\nPerdida entrenamiento: 0.43205584012545073\nPerdida validaci√≥n: 0.41393060982227325\n√âpoca 47\nPerdida entrenamiento: 0.4316117866681172\nPerdida validaci√≥n: 0.3700167201459408\n√âpoca 48\nPerdida entrenamiento: 0.4322385054368239\nPerdida validaci√≥n: 0.5200365260243416\n√âpoca 49\nPerdida entrenamiento: 0.4290507435798645\nPerdida validaci√≥n: 0.4920997768640518\n√âpoca 50\nPerdida entrenamiento: 0.4292399768645947\nPerdida validaci√≥n: 0.36969228461384773\n√âpoca 51\nPerdida entrenamiento: 0.42718150180119735\nPerdida validaci√≥n: 0.4156232178211212\n√âpoca 52\nPerdida entrenamiento: 0.424829540344385\nPerdida validaci√≥n: 0.4026588648557663\n√âpoca 53\nPerdida entrenamiento: 0.42635376636798566\nPerdida validaci√≥n: 0.5363039597868919\n√âpoca 54\nPerdida entrenamiento: 0.42566425525225127\nPerdida validaci√≥n: 0.3764454163610935\n√âpoca 55\nPerdida entrenamiento: 0.4237565237742204\nPerdida validaci√≥n: 0.3808739259839058\n√âpoca 56\nPerdida entrenamiento: 0.4219471537149869\nPerdida validaci√≥n: 0.4832487851381302\n√âpoca 57\nPerdida entrenamiento: 0.4212725300055284\nPerdida validaci√≥n: 0.41617023199796677\n√âpoca 58\nPerdida entrenamiento: 0.4186098369268271\nPerdida validaci√≥n: 0.3641137257218361\n√âpoca 59\nPerdida entrenamiento: 0.42065096359986526\nPerdida validaci√≥n: 0.4038226157426834\n√âpoca 60\nPerdida entrenamiento: 0.41977634911353773\nPerdida validaci√≥n: 0.38351573422551155\n√âpoca 61\nPerdida entrenamiento: 0.42114768578455997\nPerdida validaci√≥n: 0.4520387575030327\n√âpoca 62\nPerdida entrenamiento: 0.4161078998675713\nPerdida validaci√≥n: 0.393571600317955\n√âpoca 63\nPerdida entrenamiento: 0.4192577485854809\nPerdida validaci√≥n: 0.41231170296669006\n√âpoca 64\nPerdida entrenamiento: 0.4160077480169443\nPerdida validaci√≥n: 0.3934858366847038\n√âpoca 65\nPerdida entrenamiento: 0.41279572592331815\nPerdida validaci√≥n: 0.3768220767378807\n√âpoca 66\nPerdida entrenamiento: 0.41775457904889035\nPerdida validaci√≥n: 0.4513847976922989\n√âpoca 67\nPerdida entrenamiento: 0.4163452753653893\nPerdida validaci√≥n: 0.4106815755367279\n√âpoca 68\nPerdida entrenamiento: 0.41231613205029416\nPerdida validaci√≥n: 0.47492188960313797\n√âpoca 69\nPerdida entrenamiento: 0.41317373743424046\nPerdida validaci√≥n: 0.3622148148715496\n√âpoca 70\nPerdida entrenamiento: 0.41339464027148026\nPerdida validaci√≥n: 0.39243172109127045\n√âpoca 71\nPerdida entrenamiento: 0.41166099447470444\nPerdida validaci√≥n: 0.4348529800772667\n√âpoca 72\nPerdida entrenamiento: 0.41057429634607756\nPerdida validaci√≥n: 0.45380373299121857\n√âpoca 73\nPerdida entrenamiento: 0.40971608803822446\nPerdida validaci√≥n: 0.43138349056243896\n√âpoca 74\nPerdida entrenamiento: 0.4103902509579292\nPerdida validaci√≥n: 0.3543439395725727\n√âpoca 75\nPerdida entrenamiento: 0.41078854409547955\nPerdida validaci√≥n: 0.4501536637544632\n√âpoca 76\nPerdida entrenamiento: 0.40908563137054443\nPerdida validaci√≥n: 0.4332057163119316\n√âpoca 77\nPerdida entrenamiento: 0.40671666998129624\nPerdida validaci√≥n: 0.47097714990377426\n√âpoca 78\nPerdida entrenamiento: 0.4092497917322012\nPerdida validaci√≥n: 0.3809227794408798\n√âpoca 79\nPerdida entrenamiento: 0.40779951214790344\nPerdida validaci√≥n: 0.39128022640943527\n√âpoca 80\nPerdida entrenamiento: 0.40222956010928523\nPerdida validaci√≥n: 0.38470108062028885\n√âpoca 81\nPerdida entrenamiento: 0.40348539444116444\nPerdida validaci√≥n: 0.3810441344976425\n√âpoca 82\nPerdida entrenamiento: 0.402382846062\nPerdida validaci√≥n: 0.42453859001398087\n√âpoca 83\nPerdida entrenamiento: 0.4035201118542598\nPerdida validaci√≥n: 0.42277510464191437\n√âpoca 84\nPerdida entrenamiento: 0.40302718602694\nPerdida validaci√≥n: 0.4245646893978119\n√âpoca 85\nPerdida entrenamiento: 0.40186390509972203\nPerdida validaci√≥n: 0.4499344155192375\n√âpoca 86\nPerdida entrenamiento: 0.40172262031298417\nPerdida validaci√≥n: 0.49974845349788666\n√âpoca 87\nPerdida entrenamiento: 0.400823359306042\nPerdida validaci√≥n: 0.425841860473156\n√âpoca 88\nPerdida entrenamiento: 0.39879807142110973\nPerdida validaci√≥n: 0.3989344537258148\n√âpoca 89\nPerdida entrenamiento: 0.3981326176570012\nPerdida validaci√≥n: 0.4065830484032631\n√âpoca 90\nPerdida entrenamiento: 0.3998530392463391\nPerdida validaci√≥n: 0.39869045466184616\n√âpoca 91\nPerdida entrenamiento: 0.39560900972439694\nPerdida validaci√≥n: 0.37907231599092484\n√âpoca 92\nPerdida entrenamiento: 0.3956319529276628\nPerdida validaci√≥n: 0.3895183838903904\n√âpoca 93\nPerdida entrenamiento: 0.3948855010362772\nPerdida validaci√≥n: 0.40453095734119415\n√âpoca 94\nPerdida entrenamiento: 0.3942739229935866\nPerdida validaci√≥n: 0.42533183097839355\n√âpoca 95\nPerdida entrenamiento: 0.39367732405662537\nPerdida validaci√≥n: 0.49657849967479706\n√âpoca 96\nPerdida entrenamiento: 0.39477550295683056\nPerdida validaci√≥n: 0.42017025500535965\n√âpoca 97\nPerdida entrenamiento: 0.39310317773085374\nPerdida validaci√≥n: 0.38999152556061745\n√âpoca 98\nPerdida entrenamiento: 0.3917583009371391\nPerdida validaci√≥n: 0.43369147926568985\n√âpoca 99\nPerdida entrenamiento: 0.38949758960650516\nPerdida validaci√≥n: 0.4349787309765816\n√âpoca 100\nPerdida entrenamiento: 0.39008616025631243\nPerdida validaci√≥n: 0.395715843886137\n√âpoca 101\nPerdida entrenamiento: 0.38877419783518863\nPerdida validaci√≥n: 0.36947037652134895\n√âpoca 102\nPerdida entrenamiento: 0.39078972202080947\nPerdida validaci√≥n: 0.4100741744041443\n√âpoca 103\nPerdida entrenamiento: 0.39032559669934785\nPerdida validaci√≥n: 0.42708979547023773\n√âpoca 104\nPerdida entrenamiento: 0.3895266938668031\nPerdida validaci√≥n: 0.4977172240614891\n√âpoca 105\nPerdida entrenamiento: 0.3862973955961374\nPerdida validaci√≥n: 0.4343803748488426\n√âpoca 106\nPerdida entrenamiento: 0.38772000716282773\nPerdida validaci√≥n: 0.4120924770832062\n√âpoca 107\nPerdida entrenamiento: 0.387257273380573\nPerdida validaci√≥n: 0.46935633569955826\n√âpoca 108\nPerdida entrenamiento: 0.3854876779592954\nPerdida validaci√≥n: 0.4736231788992882\n√âpoca 109\nPerdida entrenamiento: 0.3852063004787152\nPerdida validaci√≥n: 0.4230464696884155\n√âpoca 110\nPerdida entrenamiento: 0.3828760408438169\nPerdida validaci√≥n: 0.5397054925560951\n√âpoca 111\nPerdida entrenamiento: 0.3831189355024925\nPerdida validaci√≥n: 0.43693213164806366\n√âpoca 112\nPerdida entrenamiento: 0.3818291677878453\nPerdida validaci√≥n: 0.39886316657066345\n√âpoca 113\nPerdida entrenamiento: 0.38133204671052784\nPerdida validaci√≥n: 0.4186994433403015\n√âpoca 114\nPerdida entrenamiento: 0.38088562855353725\nPerdida validaci√≥n: 0.39437006786465645\n√âpoca 115\nPerdida entrenamiento: 0.38014946763332075\nPerdida validaci√≥n: 0.42200181633234024\n√âpoca 116\nPerdida entrenamiento: 0.3776790407987741\nPerdida validaci√≥n: 0.3852379620075226\n√âpoca 117\nPerdida entrenamiento: 0.37825816640487087\nPerdida validaci√≥n: 0.4611133188009262\n√âpoca 118\nPerdida entrenamiento: 0.3772958150276771\nPerdida validaci√≥n: 0.38224026188254356\n√âpoca 119\nPerdida entrenamiento: 0.3778039331619556\nPerdida validaci√≥n: 0.4286082088947296\n√âpoca 120\nPerdida entrenamiento: 0.3743162567798908\nPerdida validaci√≥n: 0.39137063175439835\n√âpoca 121\nPerdida entrenamiento: 0.3749724511916821\nPerdida validaci√≥n: 0.4739982336759567\n√âpoca 122\nPerdida entrenamiento: 0.37313790504749006\nPerdida validaci√≥n: 0.39009249955415726\n√âpoca 123\nPerdida entrenamiento: 0.3736418072993939\nPerdida validaci√≥n: 0.48800554871559143\n√âpoca 124\nPerdida entrenamiento: 0.3741052127801455\nPerdida validaci√≥n: 0.4744153171777725\n√âpoca 125\nPerdida entrenamiento: 0.37422877779373753\nPerdida validaci√≥n: 0.43327439576387405\n√âpoca 126\nPerdida entrenamiento: 0.371814754146796\nPerdida validaci√≥n: 0.4883398041129112\n√âpoca 127\nPerdida entrenamiento: 0.3707105219364166\nPerdida validaci√≥n: 0.4257439374923706\n√âpoca 128\nPerdida entrenamiento: 0.3705435876662915\nPerdida validaci√≥n: 0.4996122717857361\n√âpoca 129\nPerdida entrenamiento: 0.36863908630151015\nPerdida validaci√≥n: 0.44596949219703674\n√âpoca 130\nPerdida entrenamiento: 0.36837688088417053\nPerdida validaci√≥n: 0.5108792632818222\n√âpoca 131\nPerdida entrenamiento: 0.3644952911597032\nPerdida validaci√≥n: 0.4148697182536125\n√âpoca 132\nPerdida entrenamiento: 0.3676655269586123\nPerdida validaci√≥n: 0.4180637337267399\n√âpoca 133\nPerdida entrenamiento: 0.36441197762122524\nPerdida validaci√≥n: 0.4463004618883133\n√âpoca 134\nPerdida entrenamiento: 0.364000148498095\nPerdida validaci√≥n: 0.45392312854528427\n√âpoca 135\nPerdida entrenamiento: 0.3633742378308223\nPerdida validaci√≥n: 0.5120198130607605\n√âpoca 136\nPerdida entrenamiento: 0.36356962414888233\nPerdida validaci√≥n: 0.5091618970036507\n√âpoca 137\nPerdida entrenamiento: 0.3639798118517949\nPerdida validaci√≥n: 0.4719684571027756\n√âpoca 138\nPerdida entrenamiento: 0.3627295471154727\nPerdida validaci√≥n: 0.44826727360486984\n√âpoca 139\nPerdida entrenamiento: 0.3609895293529217\nPerdida validaci√≥n: 0.4631754010915756\n√âpoca 140\nPerdida entrenamiento: 0.3619653765971844\nPerdida validaci√≥n: 0.5464806333184242\n√âpoca 141\nPerdida entrenamiento: 0.3585687061915031\nPerdida validaci√≥n: 0.5189626067876816\n√âpoca 142\nPerdida entrenamiento: 0.3566366388247563\nPerdida validaci√≥n: 0.46764953434467316\n√âpoca 143\nPerdida entrenamiento: 0.36353538128045887\nPerdida validaci√≥n: 0.46592652797698975\n√âpoca 144\nPerdida entrenamiento: 0.35643438536387223\nPerdida validaci√≥n: 0.43039967119693756\n√âpoca 145\nPerdida entrenamiento: 0.35604520256702715\nPerdida validaci√≥n: 0.5149550661444664\n√âpoca 146\nPerdida entrenamiento: 0.35637769676171815\nPerdida validaci√≥n: 0.4144183583557606\n√âpoca 147\nPerdida entrenamiento: 0.355108747115502\nPerdida validaci√≥n: 0.4768465459346771\n√âpoca 148\nPerdida entrenamiento: 0.35542476864961475\nPerdida validaci√≥n: 0.4844294711947441\n√âpoca 149\nPerdida entrenamiento: 0.3519860024635608\nPerdida validaci√≥n: 0.4547104239463806\n√âpoca 150\nPerdida entrenamiento: 0.3521421987276811\nPerdida validaci√≥n: 0.466669999063015\n√âpoca 151\nPerdida entrenamiento: 0.3548166167277556\nPerdida validaci√≥n: 0.5513210147619247\n√âpoca 152\nPerdida entrenamiento: 0.35027686334573305\nPerdida validaci√≥n: 0.5020348504185677\n√âpoca 153\nPerdida entrenamiento: 0.34959811774583965\nPerdida validaci√≥n: 0.5455379039049149\n√âpoca 154\nPerdida entrenamiento: 0.3523002461745189\nPerdida validaci√≥n: 0.47232835739851\n√âpoca 155\nPerdida entrenamiento: 0.35344558495741624\nPerdida validaci√≥n: 0.5145654082298279\n√âpoca 156\nPerdida entrenamiento: 0.3485158762106529\nPerdida validaci√≥n: 0.486834391951561\n√âpoca 157\nPerdida entrenamiento: 0.34897099549953753\nPerdida validaci√≥n: 0.5043940991163254\n√âpoca 158\nPerdida entrenamiento: 0.34723360263384306\nPerdida validaci√≥n: 0.5066465809941292\n√âpoca 159\nPerdida entrenamiento: 0.34640762439140904\nPerdida validaci√≥n: 0.5473715737462044\n√âpoca 160\nPerdida entrenamiento: 0.34859538536805373\nPerdida validaci√≥n: 0.4481390565633774\n√âpoca 161\nPerdida entrenamiento: 0.3447049787411323\nPerdida validaci√≥n: 0.424229035153985\n√âpoca 162\nPerdida entrenamiento: 0.34568210060779864\nPerdida validaci√≥n: 0.4851425141096115\n√âpoca 163\nPerdida entrenamiento: 0.3433854981110646\nPerdida validaci√≥n: 0.48836609721183777\n√âpoca 164\nPerdida entrenamiento: 0.3420627174469141\nPerdida validaci√≥n: 0.509034663438797\n√âpoca 165\nPerdida entrenamiento: 0.34017568826675415\nPerdida validaci√≥n: 0.6002066135406494\n√âpoca 166\nPerdida entrenamiento: 0.34276773035526276\nPerdida validaci√≥n: 0.52107934653759\n√âpoca 167\nPerdida entrenamiento: 0.34077843106709993\nPerdida validaci√≥n: 0.48411911725997925\n√âpoca 168\nPerdida entrenamiento: 0.3387271555570456\nPerdida validaci√≥n: 0.446561835706234\n√âpoca 169\nPerdida entrenamiento: 0.34064857547099775\nPerdida validaci√≥n: 0.4455733299255371\n√âpoca 170\nPerdida entrenamiento: 0.3393576191021846\nPerdida validaci√≥n: 0.4353795200586319\n√âpoca 171\nPerdida entrenamiento: 0.34231315094691056\nPerdida validaci√≥n: 0.4627293348312378\n√âpoca 172\nPerdida entrenamiento: 0.3361229976782432\nPerdida validaci√≥n: 0.5688041225075722\n√âpoca 173\nPerdida entrenamiento: 0.33672307087824893\nPerdida validaci√≥n: 0.45936134085059166\n√âpoca 174\nPerdida entrenamiento: 0.33723970445302814\nPerdida validaci√≥n: 0.5437187701463699\n√âpoca 175\nPerdida entrenamiento: 0.3378218343624702\nPerdida validaci√≥n: 0.6265709698200226\n√âpoca 176\nPerdida entrenamiento: 0.3348902968259958\nPerdida validaci√≥n: 0.4678940027952194\n√âpoca 177\nPerdida entrenamiento: 0.33359681299099553\nPerdida validaci√≥n: 0.49202893674373627\n√âpoca 178\nPerdida entrenamiento: 0.3337265390616197\nPerdida validaci√≥n: 0.46057265624403954\n√âpoca 179\nPerdida entrenamiento: 0.33145728134191954\nPerdida validaci√≥n: 0.5372823402285576\n√âpoca 180\nPerdida entrenamiento: 0.33341708091589123\nPerdida validaci√≥n: 0.4422183372080326\n√âpoca 181\nPerdida entrenamiento: 0.3310887057047624\nPerdida validaci√≥n: 0.7397722750902176\n√âpoca 182\nPerdida entrenamiento: 0.32945447243176973\nPerdida validaci√≥n: 0.4633013419806957\n√âpoca 183\nPerdida entrenamiento: 0.32728753983974457\nPerdida validaci√≥n: 0.4701136499643326\n√âpoca 184\nPerdida entrenamiento: 0.3269531589287978\nPerdida validaci√≥n: 0.5811994299292564\n√âpoca 185\nPerdida entrenamiento: 0.3289144921761293\nPerdida validaci√≥n: 0.6501174867153168\n√âpoca 186\nPerdida entrenamiento: 0.3250019389849443\nPerdida validaci√≥n: 0.48658087104558945\n√âpoca 187\nPerdida entrenamiento: 0.3252809208173018\nPerdida validaci√≥n: 0.5948077514767647\n√âpoca 188\nPerdida entrenamiento: 0.32456459448887753\nPerdida validaci√≥n: 0.5170600488781929\n√âpoca 189\nPerdida entrenamiento: 0.3248377591371536\nPerdida validaci√≥n: 0.5801271125674248\n√âpoca 190\nPerdida entrenamiento: 0.3258056640625\nPerdida validaci√≥n: 0.5002523139119148\n√âpoca 191\nPerdida entrenamiento: 0.3205260726121756\nPerdida validaci√≥n: 0.7138897553086281\n√âpoca 192\nPerdida entrenamiento: 0.3199167068188007\nPerdida validaci√≥n: 0.5612407624721527\n√âpoca 193\nPerdida entrenamiento: 0.31928349229005665\nPerdida validaci√≥n: 0.6081007793545723\n√âpoca 194\nPerdida entrenamiento: 0.3201474203513219\nPerdida validaci√≥n: 0.5727706551551819\n√âpoca 195\nPerdida entrenamiento: 0.3193618678129636\nPerdida validaci√≥n: 0.47843847796320915\n√âpoca 196\nPerdida entrenamiento: 0.3186295720247122\nPerdida validaci√≥n: 0.5062254294753075\n√âpoca 197\nPerdida entrenamiento: 0.3170779118171105\nPerdida validaci√≥n: 0.6240173578262329\n√âpoca 198\nPerdida entrenamiento: 0.31651219954857457\nPerdida validaci√≥n: 0.733600378036499\n√âpoca 199\nPerdida entrenamiento: 0.31591541492022\nPerdida validaci√≥n: 0.5893783569335938\n√âpoca 200\nPerdida entrenamiento: 0.31407135954269993\nPerdida validaci√≥n: 0.672258049249649\n√âpoca 201\nPerdida entrenamiento: 0.3167167156934738\nPerdida validaci√≥n: 0.5906193181872368\n√âpoca 202\nPerdida entrenamiento: 0.31775486125395846\nPerdida validaci√≥n: 0.6703383028507233\n√âpoca 203\nPerdida entrenamiento: 0.3142982469155238\nPerdida validaci√≥n: 0.493832191452384\n√âpoca 204\nPerdida entrenamiento: 0.3143202100808804\nPerdida validaci√≥n: 0.6293051838874817\n√âpoca 205\nPerdida entrenamiento: 0.3154367025081928\nPerdida validaci√≥n: 0.5778104141354561\n√âpoca 206\nPerdida entrenamiento: 0.312066729252155\nPerdida validaci√≥n: 0.5893872007727623\n√âpoca 207\nPerdida entrenamiento: 0.3136929445541822\nPerdida validaci√≥n: 0.516918983310461\n√âpoca 208\nPerdida entrenamiento: 0.30938355510051435\nPerdida validaci√≥n: 0.582847073674202\n√âpoca 209\nPerdida entrenamiento: 0.3098432135123473\nPerdida validaci√≥n: 0.5286299884319305\n√âpoca 210\nPerdida entrenamiento: 0.3081144358103092\nPerdida validaci√≥n: 0.5873531252145767\n√âpoca 211\nPerdida entrenamiento: 0.3083389034638038\nPerdida validaci√≥n: 0.602348081767559\n√âpoca 212\nPerdida entrenamiento: 0.3055564474601012\nPerdida validaci√≥n: 0.6705131381750107\n√âpoca 213\nPerdida entrenamiento: 0.30720986884373885\nPerdida validaci√≥n: 0.6529285907745361\n√âpoca 214\nPerdida entrenamiento: 0.3054585216137079\nPerdida validaci√≥n: 0.6688360720872879\n√âpoca 215\nPerdida entrenamiento: 0.30763639509677887\nPerdida validaci√≥n: 0.5135140027850866\n√âpoca 216\nPerdida entrenamiento: 0.303421927186159\nPerdida validaci√≥n: 0.5739713087677956\n√âpoca 217\nPerdida entrenamiento: 0.3031972520626508\nPerdida validaci√≥n: 0.5670073255896568\n√âpoca 218\nPerdida entrenamiento: 0.30217409363159764\nPerdida validaci√≥n: 0.592064693570137\n√âpoca 219\nPerdida entrenamiento: 0.30135699533499205\nPerdida validaci√≥n: 0.636160098016262\n√âpoca 220\nPerdida entrenamiento: 0.3016016884491994\nPerdida validaci√≥n: 0.5606770887970924\n√âpoca 221\nPerdida entrenamiento: 0.3024453268601344\nPerdida validaci√≥n: 0.5745292976498604\n√âpoca 222\nPerdida entrenamiento: 0.3018904064710324\nPerdida validaci√≥n: 0.7433184385299683\n√âpoca 223\nPerdida entrenamiento: 0.2971323464925473\nPerdida validaci√≥n: 0.740757018327713\n√âpoca 224\nPerdida entrenamiento: 0.2984556464048532\nPerdida validaci√≥n: 0.5652462765574455\n√âpoca 225\nPerdida entrenamiento: 0.29587332101968616\nPerdida validaci√≥n: 0.5960354954004288\n√âpoca 226\nPerdida entrenamiento: 0.298045168702419\nPerdida validaci√≥n: 0.6095506846904755\n√âpoca 227\nPerdida entrenamiento: 0.2962602503024615\nPerdida validaci√≥n: 0.8097492754459381\n√âpoca 228\nPerdida entrenamiento: 0.29590065891926104\nPerdida validaci√≥n: 0.642509862780571\n√âpoca 229\nPerdida entrenamiento: 0.29353805115589726\nPerdida validaci√≥n: 0.6805313527584076\n√âpoca 230\nPerdida entrenamiento: 0.2950842518072862\nPerdida validaci√≥n: 0.5805027037858963\n√âpoca 231\nPerdida entrenamiento: 0.2943579313846735\nPerdida validaci√≥n: 0.5456069093197584\n√âpoca 232\nPerdida entrenamiento: 0.293004646897316\nPerdida validaci√≥n: 0.5370007765013725\n√âpoca 233\nPerdida entrenamiento: 0.2904043530042355\nPerdida validaci√≥n: 0.627612516283989\n√âpoca 234\nPerdida entrenamiento: 0.2912729737850336\nPerdida validaci√≥n: 0.7116727158427238\n√âpoca 235\nPerdida entrenamiento: 0.28903550253464627\nPerdida validaci√≥n: 0.660587415099144\n√âpoca 236\nPerdida entrenamiento: 0.28757661695663744\nPerdida validaci√≥n: 0.5772789008915424\n√âpoca 237\nPerdida entrenamiento: 0.28811851946207195\nPerdida validaci√≥n: 0.7320586889982224\n√âpoca 238\nPerdida entrenamiento: 0.28815625779903853\nPerdida validaci√≥n: 0.7152724415063858\n√âpoca 239\nPerdida entrenamiento: 0.28606483340263367\nPerdida validaci√≥n: 0.6598239541053772\n√âpoca 240\nPerdida entrenamiento: 0.285346840436642\nPerdida validaci√≥n: 0.6209026128053665\n√âpoca 241\nPerdida entrenamiento: 0.2845807350598849\nPerdida validaci√≥n: 0.7468656450510025\n√âpoca 242\nPerdida entrenamiento: 0.2821243279255353\nPerdida validaci√≥n: 0.7041357904672623\n√âpoca 243\nPerdida entrenamiento: 0.28611129178450656\nPerdida validaci√≥n: 0.6743378043174744\n√âpoca 244\nPerdida entrenamiento: 0.284884695823376\nPerdida validaci√≥n: 0.6707199811935425\n√âpoca 245\nPerdida entrenamiento: 0.2815088893358524\nPerdida validaci√≥n: 0.5728727634996176\n√âpoca 246\nPerdida entrenamiento: 0.28080847744758314\nPerdida validaci√≥n: 0.6702363193035126\n√âpoca 247\nPerdida entrenamiento: 0.2867404520511627\nPerdida validaci√≥n: 0.5843783281743526\n√âpoca 248\nPerdida entrenamiento: 0.2806525001159081\nPerdida validaci√≥n: 0.7861420884728432\n√âpoca 249\nPerdida entrenamiento: 0.27863137194743526\nPerdida validaci√≥n: 0.6410687640309334\n√âpoca 250\nPerdida entrenamiento: 0.2770683398613563\nPerdida validaci√≥n: 0.5936639066785574\n√âpoca 251\nPerdida entrenamiento: 0.2768169263234505\nPerdida validaci√≥n: 0.6833072006702423\n√âpoca 252\nPerdida entrenamiento: 0.2748305465166385\nPerdida validaci√≥n: 0.6042004376649857\n√âpoca 253\nPerdida entrenamiento: 0.2757860215810629\nPerdida validaci√≥n: 0.7947159111499786\n√âpoca 254\nPerdida entrenamiento: 0.2751406201949486\nPerdida validaci√≥n: 0.6367254927754402\n√âpoca 255\nPerdida entrenamiento: 0.2708621449195422\nPerdida validaci√≥n: 0.7180898785591125\n√âpoca 256\nPerdida entrenamiento: 0.275149221603687\nPerdida validaci√≥n: 0.7423695474863052\n√âpoca 257\nPerdida entrenamiento: 0.2727271203811352\nPerdida validaci√≥n: 0.9060819447040558\n√âpoca 258\nPerdida entrenamiento: 0.2681584942799348\nPerdida validaci√≥n: 0.5963035766035318\n√âpoca 259\nPerdida entrenamiento: 0.27062331025417036\nPerdida validaci√≥n: 0.873478040099144\n√âpoca 260\nPerdida entrenamiento: 0.2674179868056224\nPerdida validaci√≥n: 0.8986184149980545\n√âpoca 261\nPerdida entrenamiento: 0.2690170338520637\nPerdida validaci√≥n: 0.6592900529503822\n√âpoca 262\nPerdida entrenamiento: 0.26846447587013245\nPerdida validaci√≥n: 0.9479366093873978\n√âpoca 263\nPerdida entrenamiento: 0.26402759552001953\nPerdida validaci√≥n: 0.9008272737264633\n√âpoca 264\nPerdida entrenamiento: 0.2652583489051232\nPerdida validaci√≥n: 0.6301005408167839\n√âpoca 265\nPerdida entrenamiento: 0.2668720644253951\nPerdida validaci√≥n: 0.6739533171057701\n√âpoca 266\nPerdida entrenamiento: 0.261234122973222\nPerdida validaci√≥n: 0.8646781742572784\n√âpoca 267\nPerdida entrenamiento: 0.26453658250662\nPerdida validaci√≥n: 0.6588940024375916\n√âpoca 268\nPerdida entrenamiento: 0.2624517106092893\nPerdida validaci√≥n: 0.6618993282318115\n√âpoca 269\nPerdida entrenamiento: 0.26085009712439317\nPerdida validaci√≥n: 0.8263240605592728\n√âpoca 270\nPerdida entrenamiento: 0.2599637359380722\nPerdida validaci√≥n: 0.6784602850675583\n√âpoca 271\nPerdida entrenamiento: 0.257305567081158\nPerdida validaci√≥n: 0.6983089298009872\n√âpoca 272\nPerdida entrenamiento: 0.25707618319071257\nPerdida validaci√≥n: 0.7596462219953537\n√âpoca 273\nPerdida entrenamiento: 0.25479228565326106\nPerdida validaci√≥n: 0.8516096025705338\n√âpoca 274\nPerdida entrenamiento: 0.2555289314343379\nPerdida validaci√≥n: 0.6697004027664661\n√âpoca 275\nPerdida entrenamiento: 0.25535631752931154\nPerdida validaci√≥n: 0.7662394493818283\n√âpoca 276\nPerdida entrenamiento: 0.25399595499038696\nPerdida validaci√≥n: 0.6714568100869656\n√âpoca 277\nPerdida entrenamiento: 0.2534373849630356\nPerdida validaci√≥n: 0.8177104741334915\n√âpoca 278\nPerdida entrenamiento: 0.2528454798918504\nPerdida validaci√≥n: 0.6949421167373657\n√âpoca 279\nPerdida entrenamiento: 0.2524537363877663\nPerdida validaci√≥n: 0.6863048002123833\n√âpoca 280\nPerdida entrenamiento: 0.2513547700185042\nPerdida validaci√≥n: 0.9646367728710175\n√âpoca 281\nPerdida entrenamiento: 0.25098807078141433\nPerdida validaci√≥n: 0.8969951719045639\n√âpoca 282\nPerdida entrenamiento: 0.2472042705004032\nPerdida validaci√≥n: 0.8082799464464188\n√âpoca 283\nPerdida entrenamiento: 0.24754732789901587\nPerdida validaci√≥n: 0.7941425144672394\n√âpoca 284\nPerdida entrenamiento: 0.24609676003456116\nPerdida validaci√≥n: 0.684365876019001\n√âpoca 285\nPerdida entrenamiento: 0.2511652432955228\nPerdida validaci√≥n: 0.8623279631137848\n√âpoca 286\nPerdida entrenamiento: 0.24547406687186316\nPerdida validaci√≥n: 0.6912081725895405\n√âpoca 287\nPerdida entrenamiento: 0.2429599383702645\nPerdida validaci√≥n: 0.9732776954770088\n√âpoca 288\nPerdida entrenamiento: 0.2432185262441635\nPerdida validaci√≥n: 1.0060452669858932\n√âpoca 289\nPerdida entrenamiento: 0.24023229227616236\nPerdida validaci√≥n: 0.8277311474084854\n√âpoca 290\nPerdida entrenamiento: 0.23955060427005476\nPerdida validaci√≥n: 0.786811426281929\n√âpoca 291\nPerdida entrenamiento: 0.23958009022932786\nPerdida validaci√≥n: 0.7557588405907154\n√âpoca 292\nPerdida entrenamiento: 0.23640594402184853\nPerdida validaci√≥n: 0.8277218341827393\n√âpoca 293\nPerdida entrenamiento: 0.242647141791307\nPerdida validaci√≥n: 0.7543492093682289\n√âpoca 294\nPerdida entrenamiento: 0.23744144004124862\nPerdida validaci√≥n: 0.9005269259214401\n√âpoca 295\nPerdida entrenamiento: 0.23505891057161185\nPerdida validaci√≥n: 1.0138403475284576\n√âpoca 296\nPerdida entrenamiento: 0.23421819106890604\nPerdida validaci√≥n: 0.8683191686868668\n√âpoca 297\nPerdida entrenamiento: 0.2318978040264203\nPerdida validaci√≥n: 0.8101358413696289\n√âpoca 298\nPerdida entrenamiento: 0.23346705046983865\nPerdida validaci√≥n: 0.7712786123156548\n√âpoca 299\nPerdida entrenamiento: 0.23196385686214155\nPerdida validaci√≥n: 0.7931528687477112\n√âpoca 300\nPerdida entrenamiento: 0.23038125955141509\nPerdida validaci√≥n: 0.9017031192779541\n√âpoca 301\nPerdida entrenamiento: 0.2300905608213865\nPerdida validaci√≥n: 0.8927458971738815\n√âpoca 302\nPerdida entrenamiento: 0.22902650099534255\nPerdida validaci√≥n: 0.7802269160747528\n√âpoca 303\nPerdida entrenamiento: 0.22824548184871674\nPerdida validaci√≥n: 0.7526897303760052\n√âpoca 304\nPerdida entrenamiento: 0.22763773340445298\nPerdida validaci√≥n: 0.8381522595882416\n√âpoca 305\nPerdida entrenamiento: 0.22718356033930412\nPerdida validaci√≥n: 0.8254359364509583\n√âpoca 306\nPerdida entrenamiento: 0.22468459835419288\nPerdida validaci√≥n: 1.0651862174272537\n√âpoca 307\nPerdida entrenamiento: 0.2252236008644104\nPerdida validaci√≥n: 0.7800127901136875\n√âpoca 308\nPerdida entrenamiento: 0.22522478034863105\nPerdida validaci√≥n: 0.7735980823636055\n√âpoca 309\nPerdida entrenamiento: 0.22313766926527023\nPerdida validaci√≥n: 0.9621244966983795\n√âpoca 310\nPerdida entrenamiento: 0.22204241729699647\nPerdida validaci√≥n: 1.0749974250793457\n√âpoca 311\nPerdida entrenamiento: 0.22262436610001785\nPerdida validaci√≥n: 1.3250411748886108\n√âpoca 312\nPerdida entrenamiento: 0.21946634925328767\nPerdida validaci√≥n: 1.220914050936699\n√âpoca 313\nPerdida entrenamiento: 0.2192572527206861\nPerdida validaci√≥n: 1.041431501507759\n√âpoca 314\nPerdida entrenamiento: 0.22139415374168983\nPerdida validaci√≥n: 0.8025665357708931\n√âpoca 315\nPerdida entrenamiento: 0.21974669626125923\nPerdida validaci√≥n: 0.8422096148133278\n√âpoca 316\nPerdida entrenamiento: 0.21913381665945053\nPerdida validaci√≥n: 0.8897643834352493\n√âpoca 317\nPerdida entrenamiento: 0.21626591223936814\nPerdida validaci√≥n: 1.055869460105896\n√âpoca 318\nPerdida entrenamiento: 0.21514099263227904\nPerdida validaci√≥n: 1.1917777508497238\n√âpoca 319\nPerdida entrenamiento: 0.21370321741470924\nPerdida validaci√≥n: 1.0201979875564575\n√âpoca 320\nPerdida entrenamiento: 0.21699885450876677\nPerdida validaci√≥n: 0.8245937786996365\n√âpoca 321\nPerdida entrenamiento: 0.21201098309113428\nPerdida validaci√≥n: 1.1265588402748108\n√âpoca 322\nPerdida entrenamiento: 0.21394624962256506\nPerdida validaci√≥n: 0.962070643901825\n√âpoca 323\nPerdida entrenamiento: 0.20957350157774413\nPerdida validaci√≥n: 0.9868338853120804\n√âpoca 324\nPerdida entrenamiento: 0.21265120231188261\nPerdida validaci√≥n: 0.8874924257397652\n√âpoca 325\nPerdida entrenamiento: 0.2091066837310791\nPerdida validaci√≥n: 1.0081952214241028\n√âpoca 326\nPerdida entrenamiento: 0.21077775267454293\nPerdida validaci√≥n: 0.8385808542370796\n√âpoca 327\nPerdida entrenamiento: 0.20795948058366776\nPerdida validaci√≥n: 0.8538511730730534\n√âpoca 328\nPerdida entrenamiento: 0.20780498018631569\nPerdida validaci√≥n: 0.9103939160704613\n√âpoca 329\nPerdida entrenamiento: 0.20708075280372912\nPerdida validaci√≥n: 1.1897397637367249\n√âpoca 330\nPerdida entrenamiento: 0.20662683363144213\nPerdida validaci√≥n: 0.885913148522377\n√âpoca 331\nPerdida entrenamiento: 0.20712659450677726\nPerdida validaci√≥n: 1.0818254053592682\n√âpoca 332\nPerdida entrenamiento: 0.20439559909013602\nPerdida validaci√≥n: 1.0768046230077744\n√âpoca 333\nPerdida entrenamiento: 0.20461885745708758\nPerdida validaci√≥n: 0.9814814329147339\n√âpoca 334\nPerdida entrenamiento: 0.20301808130282623\nPerdida validaci√≥n: 1.1490432769060135\n√âpoca 335\nPerdida entrenamiento: 0.2035538857946029\nPerdida validaci√≥n: 1.178459957242012\n√âpoca 336\nPerdida entrenamiento: 0.20196825036635765\nPerdida validaci√≥n: 1.0208635181188583\n√âpoca 337\nPerdida entrenamiento: 0.20007529854774475\nPerdida validaci√≥n: 0.8982732370495796\n√âpoca 338\nPerdida entrenamiento: 0.20441429087748894\nPerdida validaci√≥n: 1.2766572535037994\n√âpoca 339\nPerdida entrenamiento: 0.19922098345481432\nPerdida validaci√≥n: 1.2669693678617477\n√âpoca 340\nPerdida entrenamiento: 0.20049226914460844\nPerdida validaci√≥n: 1.1927863359451294\n√âpoca 341\nPerdida entrenamiento: 0.19930510165599677\nPerdida validaci√≥n: 1.1106315851211548\n√âpoca 342\nPerdida entrenamiento: 0.1986603576403398\nPerdida validaci√≥n: 0.9161171913146973\n√âpoca 343\nPerdida entrenamiento: 0.1980497338450872\nPerdida validaci√≥n: 0.8788779089227319\n√âpoca 344\nPerdida entrenamiento: 0.19675294711039618\nPerdida validaci√≥n: 0.926335796713829\n√âpoca 345\nPerdida entrenamiento: 0.1941346635039036\nPerdida validaci√≥n: 1.0945035070180893\n√âpoca 346\nPerdida entrenamiento: 0.1936252420911422\nPerdida validaci√≥n: 1.0377127081155777\n√âpoca 347\nPerdida entrenamiento: 0.19242666776363665\nPerdida validaci√≥n: 1.2945685386657715\n√âpoca 348\nPerdida entrenamiento: 0.19187256120718443\nPerdida validaci√≥n: 1.0255257040262222\n√âpoca 349\nPerdida entrenamiento: 0.19146961661485526\nPerdida validaci√≥n: 1.3043287247419357\n√âpoca 350\nPerdida entrenamiento: 0.19094201062734312\nPerdida validaci√≥n: 0.9868040531873703\n√âpoca 351\nPerdida entrenamiento: 0.1926536777844796\nPerdida validaci√≥n: 0.9217413030564785\n√âpoca 352\nPerdida entrenamiento: 0.1905878747885044\nPerdida validaci√≥n: 0.9125046692788601\n√âpoca 353\nPerdida entrenamiento: 0.187868713759459\nPerdida validaci√≥n: 0.9345213063061237\n√âpoca 354\nPerdida entrenamiento: 0.18901339631814223\nPerdida validaci√≥n: 0.9942605942487717\n√âpoca 355\nPerdida entrenamiento: 0.18814368947194174\nPerdida validaci√≥n: 0.9075269959867001\n√âpoca 356\nPerdida entrenamiento: 0.18838231953290793\nPerdida validaci√≥n: 1.0101798176765442\n√âpoca 357\nPerdida entrenamiento: 0.1871264118414659\nPerdida validaci√≥n: 1.3163970857858658\n√âpoca 358\nPerdida entrenamiento: 0.18556923533861452\nPerdida validaci√≥n: 1.1430521309375763\n√âpoca 359\nPerdida entrenamiento: 0.18438442624532259\nPerdida validaci√≥n: 1.0945535898208618\n√âpoca 360\nPerdida entrenamiento: 0.18359505041287497\nPerdida validaci√≥n: 1.1046949326992035\n√âpoca 361\nPerdida entrenamiento: 0.18347960653213355\nPerdida validaci√≥n: 1.0777917206287384\n√âpoca 362\nPerdida entrenamiento: 0.18606625038843888\nPerdida validaci√≥n: 1.039321780204773\n√âpoca 363\nPerdida entrenamiento: 0.1835288187632194\nPerdida validaci√≥n: 1.8219835758209229\n√âpoca 364\nPerdida entrenamiento: 0.1832315560716849\nPerdida validaci√≥n: 0.9855913817882538\n√âpoca 365\nPerdida entrenamiento: 0.18345200499662986\nPerdida validaci√≥n: 1.3815755248069763\n√âpoca 366\nPerdida entrenamiento: 0.18204493877979425\nPerdida validaci√≥n: 1.3143933415412903\n√âpoca 367\nPerdida entrenamiento: 0.18039714430387205\nPerdida validaci√≥n: 1.1001662760972977\n√âpoca 368\nPerdida entrenamiento: 0.1790039367400683\nPerdida validaci√≥n: 1.1200962960720062\n√âpoca 369\nPerdida entrenamiento: 0.17842322817215553\nPerdida validaci√≥n: 1.248393177986145\n√âpoca 370\nPerdida entrenamiento: 0.17733524567805803\nPerdida validaci√≥n: 1.1019806116819382\n√âpoca 371\nPerdida entrenamiento: 0.18092230707406998\nPerdida validaci√≥n: 1.0071088895201683\n√âpoca 372\nPerdida entrenamiento: 0.1787138833449437\nPerdida validaci√≥n: 0.9970914125442505\n√âpoca 373\nPerdida entrenamiento: 0.17536774850808656\nPerdida validaci√≥n: 1.2062337547540665\n√âpoca 374\nPerdida entrenamiento: 0.1755595069665175\nPerdida validaci√≥n: 1.2552458047866821\n√âpoca 375\nPerdida entrenamiento: 0.17521371291233942\nPerdida validaci√≥n: 1.3755380511283875\n√âpoca 376\nPerdida entrenamiento: 0.17484821493809038\nPerdida validaci√≥n: 0.9694990161806345\n√âpoca 377\nPerdida entrenamiento: 0.16993199575405854\nPerdida validaci√≥n: 1.2601993381977081\n√âpoca 378\nPerdida entrenamiento: 0.17217573007711998\nPerdida validaci√≥n: 1.0045286491513252\n√âpoca 379\nPerdida entrenamiento: 0.16950746167164582\nPerdida validaci√≥n: 1.0718081295490265\n√âpoca 380\nPerdida entrenamiento: 0.17159914741149315\nPerdida validaci√≥n: 1.4655284881591797\n√âpoca 381\nPerdida entrenamiento: 0.16838658973574638\nPerdida validaci√≥n: 1.1533843874931335\n√âpoca 382\nPerdida entrenamiento: 0.17031876341654703\nPerdida validaci√≥n: 0.9962851293385029\n√âpoca 383\nPerdida entrenamiento: 0.16913885737840945\nPerdida validaci√≥n: 1.7159227132797241\n√âpoca 384\nPerdida entrenamiento: 0.16765954746649817\nPerdida validaci√≥n: 1.159842073917389\n√âpoca 385\nPerdida entrenamiento: 0.1671962749499541\nPerdida validaci√≥n: 1.4913894534111023\n√âpoca 386\nPerdida entrenamiento: 0.1681254764015858\nPerdida validaci√≥n: 1.122810274362564\n√âpoca 387\nPerdida entrenamiento: 0.165319480575048\nPerdida validaci√≥n: 1.54014253616333\n√âpoca 388\nPerdida entrenamiento: 0.16413759382871482\nPerdida validaci√≥n: 1.1817348301410675\n√âpoca 389\nPerdida entrenamiento: 0.1640704136628371\nPerdida validaci√≥n: 1.2460854202508926\n√âpoca 390\nPerdida entrenamiento: 0.16306643531872675\nPerdida validaci√≥n: 1.609892874956131\n√âpoca 391\nPerdida entrenamiento: 0.16301732109143183\nPerdida validaci√≥n: 1.4515731483697891\n√âpoca 392\nPerdida entrenamiento: 0.16136908989686233\nPerdida validaci√≥n: 1.096735492348671\n√âpoca 393\nPerdida entrenamiento: 0.16398021177603647\nPerdida validaci√≥n: 1.068606436252594\n√âpoca 394\nPerdida entrenamiento: 0.15940716748054212\nPerdida validaci√≥n: 1.2023451328277588\n√âpoca 395\nPerdida entrenamiento: 0.16102972282813147\nPerdida validaci√≥n: 1.3458791375160217\n√âpoca 396\nPerdida entrenamiento: 0.15895120684917158\nPerdida validaci√≥n: 1.1531001776456833\n√âpoca 397\nPerdida entrenamiento: 0.16065807869801155\nPerdida validaci√≥n: 1.4515523314476013\n√âpoca 398\nPerdida entrenamiento: 0.16089507135061118\nPerdida validaci√≥n: 1.0475106053054333\n√âpoca 399\nPerdida entrenamiento: 0.1607217674071972\nPerdida validaci√≥n: 1.0925526916980743\n√âpoca 400\nPerdida entrenamiento: 0.15985893744688767\nPerdida validaci√≥n: 1.1263118088245392\n√âpoca 401\nPerdida entrenamiento: 0.15693163986389452\nPerdida validaci√≥n: 1.5815104246139526\n√âpoca 402\nPerdida entrenamiento: 0.15736779341330895\nPerdida validaci√≥n: 1.3613525032997131\n√âpoca 403\nPerdida entrenamiento: 0.15994859314881837\nPerdida validaci√≥n: 1.3299525380134583\n√âpoca 404\nPerdida entrenamiento: 0.15524562992728674\nPerdida validaci√≥n: 1.129160463809967\n√âpoca 405\nPerdida entrenamiento: 0.15532630681991577\nPerdida validaci√≥n: 1.2196290791034698\n√âpoca 406\nPerdida entrenamiento: 0.15297087396566683\nPerdida validaci√≥n: 2.013798788189888\n√âpoca 407\nPerdida entrenamiento: 0.15678289418037122\nPerdida validaci√≥n: 1.579893410205841\n√âpoca 408\nPerdida entrenamiento: 0.15148546947882727\nPerdida validaci√≥n: 1.1102407947182655\n√âpoca 409\nPerdida entrenamiento: 0.15315252427871412\nPerdida validaci√≥n: 1.093673411756754\n√âpoca 410\nPerdida entrenamiento: 0.15141890599177435\nPerdida validaci√≥n: 1.3287800699472427\n√âpoca 411\nPerdida entrenamiento: 0.15180933131621435\nPerdida validaci√≥n: 1.3786164820194244\n√âpoca 412\nPerdida entrenamiento: 0.1497001200914383\nPerdida validaci√≥n: 1.5654205977916718\n√âpoca 413\nPerdida entrenamiento: 0.1539385886146472\nPerdida validaci√≥n: 1.0817826110869646\n√âpoca 414\nPerdida entrenamiento: 0.1514056955392544\nPerdida validaci√≥n: 1.9382396638393402\n√âpoca 415\nPerdida entrenamiento: 0.15173272100778726\nPerdida validaci√≥n: 1.3418876677751541\n√âpoca 416\nPerdida entrenamiento: 0.14910465880082205\nPerdida validaci√≥n: 1.8640508651733398\n√âpoca 417\nPerdida entrenamiento: 0.14727372017044288\nPerdida validaci√≥n: 1.1653900444507599\n√âpoca 418\nPerdida entrenamiento: 0.1486102778177995\nPerdida validaci√≥n: 1.4865805208683014\n√âpoca 419\nPerdida entrenamiento: 0.1470818628485386\nPerdida validaci√≥n: 1.8298079371452332\n√âpoca 420\nPerdida entrenamiento: 0.14542641719946495\nPerdida validaci√≥n: 1.8267624229192734\n√âpoca 421\nPerdida entrenamiento: 0.1465584973876293\nPerdida validaci√≥n: 1.7401020023971796\n√âpoca 422\nPerdida entrenamiento: 0.1459429063476049\nPerdida validaci√≥n: 1.8647668659687042\n√âpoca 423\nPerdida entrenamiento: 0.14751056438455215\nPerdida validaci√≥n: 1.853477194905281\n√âpoca 424\nPerdida entrenamiento: 0.14484965801239014\nPerdida validaci√≥n: 1.9142803102731705\n√âpoca 425\nPerdida entrenamiento: 0.14378211962488982\nPerdida validaci√≥n: 1.9636558592319489\n√âpoca 426\nPerdida entrenamiento: 0.14685687107535508\nPerdida validaci√≥n: 2.342496156692505\n√âpoca 427\nPerdida entrenamiento: 0.1424619727409803\nPerdida validaci√≥n: 4.561129406094551\n√âpoca 428\nPerdida entrenamiento: 0.14290866886193937\nPerdida validaci√≥n: 4.768705457448959\n√âpoca 429\nPerdida entrenamiento: 0.1421340394478578\nPerdida validaci√≥n: 2.390932723879814\n√âpoca 430\nPerdida entrenamiento: 0.14333476355442634\nPerdida validaci√≥n: 1.9665760695934296\n√âpoca 431\nPerdida entrenamiento: 0.14370077475905418\nPerdida validaci√≥n: 4.5777967274188995\n√âpoca 432\nPerdida entrenamiento: 0.1428644536779477\nPerdida validaci√≥n: 1.915467545390129\n√âpoca 433\nPerdida entrenamiento: 0.1437031918993363\nPerdida validaci√≥n: 1.8353270888328552\n√âpoca 434\nPerdida entrenamiento: 0.1391112907574727\nPerdida validaci√≥n: 1.8254324793815613\n√âpoca 435\nPerdida entrenamiento: 0.14128816758210844\nPerdida validaci√≥n: 2.2376081943511963\n√âpoca 436\nPerdida entrenamiento: 0.13954832634100547\nPerdida validaci√≥n: 4.6626335978508\n√âpoca 437\nPerdida entrenamiento: 0.138767588023956\nPerdida validaci√≥n: 1.7955627366900444\n√âpoca 438\nPerdida entrenamiento: 0.140621029986785\nPerdida validaci√≥n: 1.9822211861610413\n√âpoca 439\nPerdida entrenamiento: 0.13871822305596793\nPerdida validaci√≥n: 1.8298685476183891\n√âpoca 440\nPerdida entrenamiento: 0.13960186392068863\nPerdida validaci√≥n: 2.2689503729343414\n√âpoca 441\nPerdida entrenamiento: 0.1384184412085093\nPerdida validaci√≥n: 1.978897362947464\n√âpoca 442\nPerdida entrenamiento: 0.1393213366659788\nPerdida validaci√≥n: 1.796176865696907\n√âpoca 443\nPerdida entrenamiento: 0.1366216018795967\nPerdida validaci√≥n: 1.8592241257429123\n√âpoca 444\nPerdida entrenamiento: 0.13682998573550811\nPerdida validaci√≥n: 1.7595698600634933\n√âpoca 445\nPerdida entrenamiento: 0.13522964973862356\nPerdida validaci√≥n: 1.9084278345108032\n√âpoca 446\nPerdida entrenamiento: 0.13606802832621795\nPerdida validaci√≥n: 2.1424740850925446\n√âpoca 447\nPerdida entrenamiento: 0.13595753048474973\nPerdida validaci√≥n: 1.9501730501651764\n√âpoca 448\nPerdida entrenamiento: 0.13536394158234963\nPerdida validaci√≥n: 1.7681202897801995\n√âpoca 449\nPerdida entrenamiento: 0.13383748439642099\nPerdida validaci√≥n: 1.776937936898321\n√âpoca 450\nPerdida entrenamiento: 0.134520024061203\nPerdida validaci√≥n: 2.3689710795879364\n√âpoca 451\nPerdida entrenamiento: 0.13803439873915452\nPerdida validaci√≥n: 2.100162461400032\n√âpoca 452\nPerdida entrenamiento: 0.1336829622204487\nPerdida validaci√≥n: 2.2752034962177277\n√âpoca 453\nPerdida entrenamiento: 0.13292249807944664\nPerdida validaci√≥n: 1.995318591594696\n√âpoca 454\nPerdida entrenamiento: 0.13514817792635697\nPerdida validaci√≥n: 1.9861263036727905\n√âpoca 455\nPerdida entrenamiento: 0.1320819346090922\nPerdida validaci√≥n: 1.9134028553962708\n√âpoca 456\nPerdida entrenamiento: 0.13178949975050414\nPerdida validaci√≥n: 2.345687836408615\n√âpoca 457\nPerdida entrenamiento: 0.13060673899375475\nPerdida validaci√≥n: 1.7884992298204452\n√âpoca 458\nPerdida entrenamiento: 0.13102037072754824\nPerdida validaci√≥n: 2.0062188506126404\n√âpoca 459\nPerdida entrenamiento: 0.13201026274607733\nPerdida validaci√≥n: 2.2236380875110626\n√âpoca 460\nPerdida entrenamiento: 0.13188833112900072\nPerdida validaci√≥n: 1.913369283080101\n√âpoca 461\nPerdida entrenamiento: 0.13061570146909127\nPerdida validaci√≥n: 2.1135205924510956\n√âpoca 462\nPerdida entrenamiento: 0.12994415083756813\nPerdida validaci√≥n: 2.502940058708191\n√âpoca 463\nPerdida entrenamiento: 0.13231988767018685\nPerdida validaci√≥n: 2.2688323259353638\n√âpoca 464\nPerdida entrenamiento: 0.132278629220449\nPerdida validaci√≥n: 1.9339222609996796\n√âpoca 465\nPerdida entrenamiento: 0.1299718085389871\nPerdida validaci√≥n: 1.854475636035204\n√âpoca 466\nPerdida entrenamiento: 0.13145282578009826\nPerdida validaci√≥n: 2.1876435577869415\n√âpoca 467\nPerdida entrenamiento: 0.1313119169611197\nPerdida validaci√≥n: 2.0629679560661316\n√âpoca 468\nPerdida entrenamiento: 0.12963297819862\nPerdida validaci√≥n: 1.8632949441671371\n√âpoca 469\nPerdida entrenamiento: 0.13173786350167715\nPerdida validaci√≥n: 2.3062230050563812\n√âpoca 470\nPerdida entrenamiento: 0.12814507748071963\nPerdida validaci√≥n: 1.8778863623738289\n√âpoca 471\nPerdida entrenamiento: 0.1295533965413387\nPerdida validaci√≥n: 2.0298818349838257\n√âpoca 472\nPerdida entrenamiento: 0.12830456117024788\nPerdida validaci√≥n: 1.8326761359348893\n√âpoca 473\nPerdida entrenamiento: 0.13108183042361185\nPerdida validaci√≥n: 1.8978855609893799\n√âpoca 474\nPerdida entrenamiento: 0.12631277166880095\nPerdida validaci√≥n: 1.8579567857086658\n√âpoca 475\nPerdida entrenamiento: 0.1265657704610091\nPerdida validaci√≥n: 1.8173991988878697\n√âpoca 476\nPerdida entrenamiento: 0.1263832891216645\nPerdida validaci√≥n: 2.03189879655838\n√âpoca 477\nPerdida entrenamiento: 0.1271198460688958\nPerdida validaci√≥n: 2.035249412059784\n√âpoca 478\nPerdida entrenamiento: 0.12515214171547157\nPerdida validaci√≥n: 2.3506749868392944\n√âpoca 479\nPerdida entrenamiento: 0.1258234651042865\nPerdida validaci√≥n: 2.0357569456100464\n√âpoca 480\nPerdida entrenamiento: 0.12334210511583549\nPerdida validaci√≥n: 2.3931768983602524\n√âpoca 481\nPerdida entrenamiento: 0.12442116553966816\nPerdida validaci√≥n: 1.8402148545719683\n√âpoca 482\nPerdida entrenamiento: 0.12398571349107303\nPerdida validaci√≥n: 1.8500240058638155\n√âpoca 483\nPerdida entrenamiento: 0.12187421866334401\nPerdida validaci√≥n: 2.4725755900144577\n√âpoca 484\nPerdida entrenamiento: 0.12302208233338136\nPerdida validaci√≥n: 2.2796106934547424\n√âpoca 485\nPerdida entrenamiento: 0.12683135729569656\nPerdida validaci√≥n: 1.8626185692846775\n√âpoca 486\nPerdida entrenamiento: 0.12531459446136767\nPerdida validaci√≥n: 2.2455354630947113\n√âpoca 487\nPerdida entrenamiento: 0.12518665194511414\nPerdida validaci√≥n: 2.294196218252182\n√âpoca 488\nPerdida entrenamiento: 0.12416661272828396\nPerdida validaci√≥n: 5.504393815994263\n√âpoca 489\nPerdida entrenamiento: 0.12151235857835183\nPerdida validaci√≥n: 4.765833288431168\n√âpoca 490\nPerdida entrenamiento: 0.12303080123204452\nPerdida validaci√≥n: 2.5530178621411324\n√âpoca 491\nPerdida entrenamiento: 0.1221739208469024\nPerdida validaci√≥n: 2.623643547296524\n√âpoca 492\nPerdida entrenamiento: 0.12077710233055629\nPerdida validaci√≥n: 2.641333118081093\n√âpoca 493\nPerdida entrenamiento: 0.12215936126617286\nPerdida validaci√≥n: 2.523965746164322\n√âpoca 494\nPerdida entrenamiento: 0.12131250764314945\nPerdida validaci√≥n: 2.86473748087883\n√âpoca 495\nPerdida entrenamiento: 0.11971759996735133\nPerdida validaci√≥n: 2.8849087059497833\n√âpoca 496\nPerdida entrenamiento: 0.11921405147474545\nPerdida validaci√≥n: 3.088648520410061\n√âpoca 497\nPerdida entrenamiento: 0.11881179362535477\nPerdida validaci√≥n: 2.7041009813547134\n√âpoca 498\nPerdida entrenamiento: 0.12069269728202087\nPerdida validaci√≥n: 2.701828509569168\n√âpoca 499\nPerdida entrenamiento: 0.11688872054219246\nPerdida validaci√≥n: 2.6526040136814117\n√âpoca 500\nPerdida entrenamiento: 0.12055957403320533\nPerdida validaci√≥n: 2.768251270055771\n√âpoca 501\nPerdida entrenamiento: 0.1185041986978971\nPerdida validaci√≥n: 2.610110007226467\n√âpoca 502\nPerdida entrenamiento: 0.11842981869211563\nPerdida validaci√≥n: 2.783321276307106\n√âpoca 503\nPerdida entrenamiento: 0.11740847648336337\nPerdida validaci√≥n: 5.701580911874771\n√âpoca 504\nPerdida entrenamiento: 0.11811252511464633\nPerdida validaci√≥n: 5.549773216247559\n√âpoca 505\nPerdida entrenamiento: 0.11450959799381402\nPerdida validaci√≥n: 2.8138828575611115\n√âpoca 506\nPerdida entrenamiento: 0.1174502051793612\nPerdida validaci√≥n: 2.615239202976227\n√âpoca 507\nPerdida entrenamiento: 0.11577433175765552\nPerdida validaci√≥n: 2.584429509937763\n√âpoca 508\nPerdida entrenamiento: 0.11714056907938077\nPerdida validaci√≥n: 2.5579630389111117\n√âpoca 509\nPerdida entrenamiento: 0.11275060732777302\nPerdida validaci√≥n: 2.8419259935617447\n√âpoca 510\nPerdida entrenamiento: 0.11713154499347393\nPerdida validaci√≥n: 3.056575983762741\n√âpoca 511\nPerdida entrenamiento: 0.11541045027283522\nPerdida validaci√≥n: 2.8400514125823975\n√âpoca 512\nPerdida entrenamiento: 0.11325491334383304\nPerdida validaci√≥n: 2.6306902319192886\n√âpoca 513\nPerdida entrenamiento: 0.11358885925549728\nPerdida validaci√≥n: 2.571716500679031\n√âpoca 514\nPerdida entrenamiento: 0.11338759013093434\nPerdida validaci√≥n: 2.9470843076705933\n√âpoca 515\nPerdida entrenamiento: 0.11455664554467568\nPerdida validaci√≥n: 2.9394672214984894\n√âpoca 516\nPerdida entrenamiento: 0.11280371965124057\nPerdida validaci√≥n: 5.647374600172043\n√âpoca 517\nPerdida entrenamiento: 0.11306084377261308\nPerdida validaci√≥n: 2.619787771254778\n√âpoca 518\nPerdida entrenamiento: 0.1135869212448597\nPerdida validaci√≥n: 2.853236883878708\n√âpoca 519\nPerdida entrenamiento: 0.11409064611563316\nPerdida validaci√≥n: 5.546691715717316\n√âpoca 520\nPerdida entrenamiento: 0.1118229848261063\nPerdida validaci√≥n: 2.745006173849106\n√âpoca 521\nPerdida entrenamiento: 0.11278153583407402\nPerdida validaci√≥n: 3.1580388844013214\n√âpoca 522\nPerdida entrenamiento: 0.11320935247036126\nPerdida validaci√≥n: 2.7071564495563507\n√âpoca 523\nPerdida entrenamiento: 0.11237332626030995\nPerdida validaci√≥n: 2.6988750621676445\n√âpoca 524\nPerdida entrenamiento: 0.10959484084294392\nPerdida validaci√≥n: 3.124171957373619\n√âpoca 525\nPerdida entrenamiento: 0.11166479524511558\nPerdida validaci√≥n: 5.45481139421463\n√âpoca 526\nPerdida entrenamiento: 0.11054900173957531\nPerdida validaci√≥n: 3.007249414920807\n√âpoca 527\nPerdida entrenamiento: 0.11383987246797635\nPerdida validaci√≥n: 2.8005631417036057\n√âpoca 528\nPerdida entrenamiento: 0.10905527896606006\nPerdida validaci√≥n: 3.0521177500486374\n√âpoca 529\nPerdida entrenamiento: 0.11215656551604088\nPerdida validaci√≥n: 2.909767299890518\n√âpoca 530\nPerdida entrenamiento: 0.11102713014070804\nPerdida validaci√≥n: 2.6694091595709324\n√âpoca 531\nPerdida entrenamiento: 0.10923272371292114\nPerdida validaci√≥n: 2.6914474070072174\n√âpoca 532\nPerdida entrenamiento: 0.10927552013443066\nPerdida validaci√≥n: 2.8471918255090714\n√âpoca 533\nPerdida entrenamiento: 0.11039042931336623\nPerdida validaci√≥n: 5.58680272102356\n√âpoca 534\nPerdida entrenamiento: 0.11040670768572734\nPerdida validaci√≥n: 5.831094592809677\n√âpoca 535\nPerdida entrenamiento: 0.10797414355553113\nPerdida validaci√≥n: 2.8358536660671234\n√âpoca 536\nPerdida entrenamiento: 0.10849945705670577\nPerdida validaci√≥n: 2.847647100687027\n√âpoca 537\nPerdida entrenamiento: 0.10771226997558887\nPerdida validaci√≥n: 2.6895657889544964\n√âpoca 538\nPerdida entrenamiento: 0.10608476199782811\nPerdida validaci√≥n: 2.9265541434288025\n√âpoca 539\nPerdida entrenamiento: 0.10907147738796014\nPerdida validaci√≥n: 3.472039520740509\n√âpoca 540\nPerdida entrenamiento: 0.10541577493915191\nPerdida validaci√≥n: 2.654316759100766\n√âpoca 541\nPerdida entrenamiento: 0.10745507736618702\nPerdida validaci√≥n: 5.496880441904068\n√âpoca 542\nPerdida entrenamiento: 0.10491894815976803\nPerdida validaci√≥n: 2.7173368334770203\n√âpoca 543\nPerdida entrenamiento: 0.1082516282510299\nPerdida validaci√≥n: 5.47006168961525\n√âpoca 544\nPerdida entrenamiento: 0.10422761451739532\nPerdida validaci√≥n: 2.749433569610119\n√âpoca 545\nPerdida entrenamiento: 0.1062567073565263\nPerdida validaci√≥n: 2.848259523510933\n√âpoca 546\nPerdida entrenamiento: 0.10411920971595325\nPerdida validaci√≥n: 3.7098141610622406\n√âpoca 547\nPerdida entrenamiento: 0.10428597262272468\nPerdida validaci√≥n: 2.771275945007801\n√âpoca 548\nPerdida entrenamiento: 0.10482547260247745\nPerdida validaci√≥n: 2.740638144314289\n√âpoca 549\nPerdida entrenamiento: 0.10570188955618785\nPerdida validaci√≥n: 3.0091414153575897\n√âpoca 550\nPerdida entrenamiento: 0.10292766644404484\nPerdida validaci√≥n: 3.15601310133934\n√âpoca 551\nPerdida entrenamiento: 0.10313611305676974\nPerdida validaci√≥n: 3.4876405000686646\n√âpoca 552\nPerdida entrenamiento: 0.102155673962373\nPerdida validaci√≥n: 2.9055378437042236\n√âpoca 553\nPerdida entrenamiento: 0.10382852617364663\nPerdida validaci√≥n: 2.723412472754717\n√âpoca 554\nPerdida entrenamiento: 0.10259475057514814\nPerdida validaci√≥n: 5.492315292358398\n√âpoca 555\nPerdida entrenamiento: 0.10145168722822116\nPerdida validaci√≥n: 2.754060558974743\n√âpoca 556\nPerdida entrenamiento: 0.10143737294352971\nPerdida validaci√≥n: 3.07767117023468\n√âpoca 557\nPerdida entrenamiento: 0.1056364316206712\nPerdida validaci√≥n: 2.9746521413326263\n√âpoca 558\nPerdida entrenamiento: 0.10130224491541202\nPerdida validaci√≥n: 3.025153934955597\n√âpoca 559\nPerdida entrenamiento: 0.10119306353422311\nPerdida validaci√≥n: 3.1392782032489777\n√âpoca 560\nPerdida entrenamiento: 0.10136075776356918\nPerdida validaci√≥n: 3.2021331638097763\n√âpoca 561\nPerdida entrenamiento: 0.10253067285968707\nPerdida validaci√≥n: 3.076074779033661\n√âpoca 562\nPerdida entrenamiento: 0.10206653034457794\nPerdida validaci√≥n: 5.530216574668884\n√âpoca 563\nPerdida entrenamiento: 0.10454103207358947\nPerdida validaci√≥n: 3.2058138102293015\n√âpoca 564\nPerdida entrenamiento: 0.10343335053095451\nPerdida validaci√≥n: 3.1237970888614655\n√âpoca 565\nPerdida entrenamiento: 0.09964850559257545\nPerdida validaci√≥n: 3.4429604411125183\n√âpoca 566\nPerdida entrenamiento: 0.10099474125756668\nPerdida validaci√≥n: 3.31308913230896\n√âpoca 567\nPerdida entrenamiento: 0.09864685397881728\nPerdida validaci√≥n: 2.990403264760971\n√âpoca 568\nPerdida entrenamiento: 0.10084413794370797\nPerdida validaci√≥n: 3.0305745601654053\n√âpoca 569\nPerdida entrenamiento: 0.09896215968407117\nPerdida validaci√≥n: 2.773144192993641\n√âpoca 570\nPerdida entrenamiento: 0.09875178738282277\nPerdida validaci√≥n: 3.2597747147083282\n√âpoca 571\nPerdida entrenamiento: 0.09714520020553699\nPerdida validaci√≥n: 2.7881274856626987\n√âpoca 572\nPerdida entrenamiento: 0.09834642221148197\nPerdida validaci√≥n: 2.897169277071953\n√âpoca 573\nPerdida entrenamiento: 0.09885117368629345\nPerdida validaci√≥n: 3.086055040359497\n√âpoca 574\nPerdida entrenamiento: 0.09760436788201332\nPerdida validaci√≥n: 2.9079464077949524\n√âpoca 575\nPerdida entrenamiento: 0.09912287873717454\nPerdida validaci√≥n: 3.261339485645294\n√âpoca 576\nPerdida entrenamiento: 0.09698486127532445\nPerdida validaci√≥n: 2.9379115402698517\n√âpoca 577\nPerdida entrenamiento: 0.0979744757597263\nPerdida validaci√≥n: 3.2120234966278076\n√âpoca 578\nPerdida entrenamiento: 0.0980399100539776\nPerdida validaci√≥n: 2.905558556318283\n√âpoca 579\nPerdida entrenamiento: 0.09601865737484051\nPerdida validaci√≥n: 3.2893512845039368\n√âpoca 580\nPerdida entrenamiento: 0.09636882950480168\nPerdida validaci√≥n: 5.822457730770111\n√âpoca 581\nPerdida entrenamiento: 0.09623523285755745\nPerdida validaci√≥n: 2.9834419786930084\n√âpoca 582\nPerdida entrenamiento: 0.09567874211531419\nPerdida validaci√≥n: 2.834209755063057\n√âpoca 583\nPerdida entrenamiento: 0.09520710431612454\nPerdida validaci√≥n: 3.457405775785446\n√âpoca 584\nPerdida entrenamiento: 0.09503164486243175\nPerdida validaci√≥n: 2.783683327026665\n√âpoca 585\nPerdida entrenamiento: 0.09478533927064675\nPerdida validaci√≥n: 3.208044409751892\n√âpoca 586\nPerdida entrenamiento: 0.09366065492996803\nPerdida validaci√≥n: 2.8148815520107746\n√âpoca 587\nPerdida entrenamiento: 0.09470219050462429\nPerdida validaci√≥n: 3.1014271676540375\n√âpoca 588\nPerdida entrenamiento: 0.09309046171032466\nPerdida validaci√≥n: 3.2367973625659943\n√âpoca 589\nPerdida entrenamiento: 0.09493592811318544\nPerdida validaci√≥n: 3.512310117483139\n√âpoca 590\nPerdida entrenamiento: 0.09326716999594982\nPerdida validaci√≥n: 3.0231358408927917\n√âpoca 591\nPerdida entrenamiento: 0.09341454792481202\nPerdida validaci√≥n: 3.043340712785721\n√âpoca 592\nPerdida entrenamiento: 0.09278626940571345\nPerdida validaci√≥n: 5.691175103187561\n√âpoca 593\nPerdida entrenamiento: 0.09466937327614197\nPerdida validaci√≥n: 3.352739989757538\n√âpoca 594\nPerdida entrenamiento: 0.09303238815986194\nPerdida validaci√≥n: 3.332100570201874\n√âpoca 595\nPerdida entrenamiento: 0.0932160415328466\nPerdida validaci√≥n: 3.2494913041591644\n√âpoca 596\nPerdida entrenamiento: 0.09378410044770974\nPerdida validaci√≥n: 3.2207201719284058\n√âpoca 597\nPerdida entrenamiento: 0.09273648376648243\nPerdida validaci√≥n: 2.8693348169326782\n√âpoca 598\nPerdida entrenamiento: 0.09436917047087963\nPerdida validaci√≥n: 2.8971500992774963\n√âpoca 599\nPerdida entrenamiento: 0.09192508573715504\nPerdida validaci√≥n: 3.5734232664108276\n√âpoca 600\nPerdida entrenamiento: 0.0922428432565469\nPerdida validaci√≥n: 3.286315381526947\n√âpoca 601\nPerdida entrenamiento: 0.090951818972826\nPerdida validaci√≥n: 2.839483904186636\n√âpoca 602\nPerdida entrenamiento: 0.09206941953072181\nPerdida validaci√≥n: 6.175304114818573\n√âpoca 603\nPerdida entrenamiento: 0.0930221310028663\nPerdida validaci√≥n: 3.414512574672699\n√âpoca 604\nPerdida entrenamiento: 0.09010667654757316\nPerdida validaci√≥n: 2.8338278711307794\n√âpoca 605\nPerdida entrenamiento: 0.09371261155376068\nPerdida validaci√≥n: 3.4049655497074127\n√âpoca 606\nPerdida entrenamiento: 0.09388583640639599\nPerdida validaci√≥n: 3.5773722529411316\n√âpoca 607\nPerdida entrenamiento: 0.09048281996869124\nPerdida validaci√≥n: 3.2947387397289276\n√âpoca 608\nPerdida entrenamiento: 0.09159044520213054\nPerdida validaci√≥n: 2.9430512189865112\n√âpoca 609\nPerdida entrenamiento: 0.08964369574991557\nPerdida validaci√≥n: 3.3014421463012695\n√âpoca 610\nPerdida entrenamiento: 0.08908333887274449\nPerdida validaci√≥n: 2.998455196619034\n√âpoca 611\nPerdida entrenamiento: 0.09090320049570157\nPerdida validaci√≥n: 5.645829796791077\n√âpoca 612\nPerdida entrenamiento: 0.08766440416757877\nPerdida validaci√≥n: 2.9032982736825943\n√âpoca 613\nPerdida entrenamiento: 0.08854922107779063\nPerdida validaci√≥n: 3.060891628265381\n√âpoca 614\nPerdida entrenamiento: 0.08976021638283363\nPerdida validaci√≥n: 3.0479705929756165\n√âpoca 615\nPerdida entrenamiento: 0.08961896913555953\nPerdida validaci√≥n: 4.045959830284119\n√âpoca 616\nPerdida entrenamiento: 0.08848642328610787\nPerdida validaci√≥n: 5.979500740766525\n√âpoca 617\nPerdida entrenamiento: 0.08795142374359645\nPerdida validaci√≥n: 3.2142326831817627\n√âpoca 618\nPerdida entrenamiento: 0.08949532818335754\nPerdida validaci√≥n: 3.4921406507492065\n√âpoca 619\nPerdida entrenamiento: 0.08757467159571555\nPerdida validaci√≥n: 2.9816556125879288\n√âpoca 620\nPerdida entrenamiento: 0.0879586089688998\nPerdida validaci√≥n: 3.0630840808153152\n√âpoca 621\nPerdida entrenamiento: 0.08634372141498786\nPerdida validaci√≥n: 4.073459208011627\n√âpoca 622\nPerdida entrenamiento: 0.08796885366050097\nPerdida validaci√≥n: 2.9151867516338825\n√âpoca 623\nPerdida entrenamiento: 0.08707575729260078\nPerdida validaci√≥n: 3.223273813724518\n√âpoca 624\nPerdida entrenamiento: 0.08563883115465824\nPerdida validaci√≥n: 3.0873585641384125\n√âpoca 625\nPerdida entrenamiento: 0.08584944187448575\nPerdida validaci√≥n: 2.9525046534836292\n√âpoca 626\nPerdida entrenamiento: 0.08701738285330626\nPerdida validaci√≥n: 3.099105030298233\n√âpoca 627\nPerdida entrenamiento: 0.08607068084753476\nPerdida validaci√≥n: 5.73407855629921\n√âpoca 628\nPerdida entrenamiento: 0.08767787438745682\nPerdida validaci√≥n: 2.8967090360820293\n√âpoca 629\nPerdida entrenamiento: 0.08825744960743648\nPerdida validaci√≥n: 3.380082130432129\n√âpoca 630\nPerdida entrenamiento: 0.0873606692139919\nPerdida validaci√≥n: 3.1084282398223877\n√âpoca 631\nPerdida entrenamiento: 0.08586964011192322\nPerdida validaci√≥n: 3.7326546162366867\n√âpoca 632\nPerdida entrenamiento: 0.08663071577365582\nPerdida validaci√≥n: 5.914897799491882\n√âpoca 633\nPerdida entrenamiento: 0.08718680790983714\nPerdida validaci√≥n: 2.9612930342555046\n√âpoca 634\nPerdida entrenamiento: 0.085944925649808\nPerdida validaci√≥n: 3.224094897508621\n√âpoca 635\nPerdida entrenamiento: 0.0844750301196025\nPerdida validaci√≥n: 3.0974116921424866\n√âpoca 636\nPerdida entrenamiento: 0.08396346781116265\nPerdida validaci√≥n: 3.4633867144584656\n√âpoca 637\nPerdida entrenamiento: 0.08545709831210282\nPerdida validaci√≥n: 2.9578521959483624\n√âpoca 638\nPerdida entrenamiento: 0.08674065195597135\nPerdida validaci√≥n: 2.949578620493412\n√âpoca 639\nPerdida entrenamiento: 0.08519237488508224\nPerdida validaci√≥n: 3.2103909254074097\n√âpoca 640\nPerdida entrenamiento: 0.08840005414990279\nPerdida validaci√≥n: 3.0627825558185577\n√âpoca 641\nPerdida entrenamiento: 0.0849433932453394\nPerdida validaci√≥n: 3.172268331050873\n√âpoca 642\nPerdida entrenamiento: 0.08262179534022625\nPerdida validaci√≥n: 3.236430197954178\n√âpoca 643\nPerdida entrenamiento: 0.08367389583816895\nPerdida validaci√≥n: 2.942924888804555\n√âpoca 644\nPerdida entrenamiento: 0.08231127118835083\nPerdida validaci√≥n: 3.27776700258255\n√âpoca 645\nPerdida entrenamiento: 0.08604721839611347\nPerdida validaci√≥n: 2.9394181985408068\n√âpoca 646\nPerdida entrenamiento: 0.08392453394257106\nPerdida validaci√≥n: 3.0016921162605286\n√âpoca 647\nPerdida entrenamiento: 0.08415115481385818\nPerdida validaci√≥n: 3.1223526895046234\n√âpoca 648\nPerdida entrenamiento: 0.08276968549650449\nPerdida validaci√≥n: 2.978962305933237\n√âpoca 649\nPerdida entrenamiento: 0.08537436477266826\nPerdida validaci√≥n: 3.432997077703476\n√âpoca 650\nPerdida entrenamiento: 0.0837293887654176\nPerdida validaci√≥n: 3.4656736850738525\n√âpoca 651\nPerdida entrenamiento: 0.08413175550790933\nPerdida validaci√≥n: 3.3202735409140587\n√âpoca 652\nPerdida entrenamiento: 0.08189639592399964\nPerdida validaci√≥n: 3.8872807025909424\n√âpoca 653\nPerdida entrenamiento: 0.08280348534194323\nPerdida validaci√≥n: 6.082957550883293\n√âpoca 654\nPerdida entrenamiento: 0.08127718963302098\nPerdida validaci√≥n: 3.207852452993393\n√âpoca 655\nPerdida entrenamiento: 0.08102134758463272\nPerdida validaci√≥n: 3.252897948026657\n√âpoca 656\nPerdida entrenamiento: 0.08139984109080754\nPerdida validaci√≥n: 2.9737558010965586\n√âpoca 657\nPerdida entrenamiento: 0.08038559813912098\nPerdida validaci√≥n: 3.310336619615555\n√âpoca 658\nPerdida entrenamiento: 0.07984856028969471\nPerdida validaci√≥n: 3.006955109536648\n√âpoca 659\nPerdida entrenamiento: 0.08055987037145175\nPerdida validaci√≥n: 3.5304589942097664\n√âpoca 660\nPerdida entrenamiento: 0.08210009408111756\nPerdida validaci√≥n: 3.9923764169216156\n√âpoca 661\nPerdida entrenamiento: 0.08106890879571438\nPerdida validaci√≥n: 3.647656798362732\n√âpoca 662\nPerdida entrenamiento: 0.0803337491189058\nPerdida validaci√≥n: 3.0062214881181717\n√âpoca 663\nPerdida entrenamiento: 0.08178974587756854\nPerdida validaci√≥n: 3.8203519582748413\n√âpoca 664\nPerdida entrenamiento: 0.07993544179659623\nPerdida validaci√≥n: 5.766702353954315\n√âpoca 665\nPerdida entrenamiento: 0.07951982949788754\nPerdida validaci√≥n: 3.537745386362076\n√âpoca 666\nPerdida entrenamiento: 0.07966543834369916\nPerdida validaci√≥n: 3.3440269827842712\n√âpoca 667\nPerdida entrenamiento: 0.07974013012762253\nPerdida validaci√≥n: 3.4005532264709473\n√âpoca 668\nPerdida entrenamiento: 0.08048110283338107\nPerdida validaci√≥n: 6.076398730278015\n√âpoca 669\nPerdida entrenamiento: 0.07910338760568546\nPerdida validaci√≥n: 3.1290396749973297\n√âpoca 670\nPerdida entrenamiento: 0.07919158643254867\nPerdida validaci√≥n: 3.0483686476945877\n√âpoca 671\nPerdida entrenamiento: 0.07788696125722848\nPerdida validaci√≥n: 6.258003294467926\n√âpoca 672\nPerdida entrenamiento: 0.08138983582074825\nPerdida validaci√≥n: 3.043996773660183\n√âpoca 673\nPerdida entrenamiento: 0.08381304632012661\nPerdida validaci√≥n: 2.9912613732740283\n√âpoca 674\nPerdida entrenamiento: 0.08171401430781071\nPerdida validaci√≥n: 3.2535914480686188\n√âpoca 675\nPerdida entrenamiento: 0.07973616025768794\nPerdida validaci√≥n: 3.008113071322441\n√âpoca 676\nPerdida entrenamiento: 0.08049123103802021\nPerdida validaci√≥n: 3.3409511744976044\n√âpoca 677\nPerdida entrenamiento: 0.0830245754466607\nPerdida validaci√≥n: 6.382318615913391\n√âpoca 678\nPerdida entrenamiento: 0.0790841830177949\nPerdida validaci√≥n: 3.5300813168287277\n√âpoca 679\nPerdida entrenamiento: 0.07988710758777764\nPerdida validaci√≥n: 3.441707044839859\n√âpoca 680\nPerdida entrenamiento: 0.07954001054167747\nPerdida validaci√≥n: 3.0263784900307655\n√âpoca 681\nPerdida entrenamiento: 0.08027764732161394\nPerdida validaci√≥n: 3.698488086462021\n√âpoca 682\nPerdida entrenamiento: 0.07939692701284702\nPerdida validaci√≥n: 6.145058274269104\n√âpoca 683\nPerdida entrenamiento: 0.07660764312514892\nPerdida validaci√≥n: 4.3174373507499695\n√âpoca 684\nPerdida entrenamiento: 0.07766298620173565\nPerdida validaci√≥n: 6.3749352395534515\n√âpoca 685\nPerdida entrenamiento: 0.07970923471909303\nPerdida validaci√≥n: 4.056097626686096\n√âpoca 686\nPerdida entrenamiento: 0.07719844278807823\nPerdida validaci√≥n: 3.051921732723713\n√âpoca 687\nPerdida entrenamiento: 0.0781680206553294\nPerdida validaci√≥n: 3.4439048767089844\n√âpoca 688\nPerdida entrenamiento: 0.07667693667686902\nPerdida validaci√≥n: 3.182342290878296\n√âpoca 689\nPerdida entrenamiento: 0.0783315381178489\nPerdida validaci√≥n: 3.228578358888626\n√âpoca 690\nPerdida entrenamiento: 0.07471121217195804\nPerdida validaci√≥n: 3.2710892260074615\n√âpoca 691\nPerdida entrenamiento: 0.07603253968633138\nPerdida validaci√≥n: 3.523540109395981\n√âpoca 692\nPerdida entrenamiento: 0.07471496525865334\nPerdida validaci√≥n: 3.411119043827057\n√âpoca 693\nPerdida entrenamiento: 0.0752135177071278\nPerdida validaci√≥n: 3.4445889592170715\n√âpoca 694\nPerdida entrenamiento: 0.07611862613031498\nPerdida validaci√≥n: 3.559295654296875\n√âpoca 695\nPerdida entrenamiento: 0.0759881936873381\nPerdida validaci√≥n: 3.5824018120765686\n√âpoca 696\nPerdida entrenamiento: 0.07466840600738159\nPerdida validaci√≥n: 3.9484466910362244\n√âpoca 697\nPerdida entrenamiento: 0.0735154255078389\nPerdida validaci√≥n: 3.0945662409067154\n√âpoca 698\nPerdida entrenamiento: 0.07556946203112602\nPerdida validaci√≥n: 3.3838585913181305\n√âpoca 699\nPerdida entrenamiento: 0.075852148521405\nPerdida validaci√≥n: 3.9069823026657104\n√âpoca 700\nPerdida entrenamiento: 0.07505714750060669\nPerdida validaci√≥n: 3.286153644323349\n√âpoca 701\nPerdida entrenamiento: 0.07513145830195683\nPerdida validaci√≥n: 3.0753321163356304\n√âpoca 702\nPerdida entrenamiento: 0.07591709723839393\nPerdida validaci√≥n: 3.383682131767273\n√âpoca 703\nPerdida entrenamiento: 0.07662103439752872\nPerdida validaci√≥n: 6.287557303905487\n√âpoca 704\nPerdida entrenamiento: 0.074071651038069\nPerdida validaci√≥n: 3.51538348197937\n√âpoca 705\nPerdida entrenamiento: 0.07326486592109387\nPerdida validaci√≥n: 3.647996246814728\n√âpoca 706\nPerdida entrenamiento: 0.07368115650919768\nPerdida validaci√≥n: 3.0932504013180733\n√âpoca 707\nPerdida entrenamiento: 0.0751225554312651\nPerdida validaci√≥n: 5.895449340343475\n√âpoca 708\nPerdida entrenamiento: 0.07395617950421113\nPerdida validaci√≥n: 5.860315516591072\n√âpoca 709\nPerdida entrenamiento: 0.07535010304015416\nPerdida validaci√≥n: 3.0919011384248734\n√âpoca 710\nPerdida entrenamiento: 0.07465821561905053\nPerdida validaci√≥n: 5.954198464751244\n√âpoca 711\nPerdida entrenamiento: 0.07308040587947918\nPerdida validaci√≥n: 3.787451297044754\n√âpoca 712\nPerdida entrenamiento: 0.07293918241675083\nPerdida validaci√≥n: 3.5140918493270874\n√âpoca 713\nPerdida entrenamiento: 0.07424381232032409\nPerdida validaci√≥n: 3.5032528042793274\n√âpoca 714\nPerdida entrenamiento: 0.07196107234519261\nPerdida validaci√≥n: 3.103741290047765\n√âpoca 715\nPerdida entrenamiento: 0.07321044630729236\nPerdida validaci√≥n: 3.2048414945602417\n√âpoca 716\nPerdida entrenamiento: 0.07338270552169818\nPerdida validaci√≥n: 3.4842203855514526\n√âpoca 717\nPerdida entrenamiento: 0.07320698207387558\nPerdida validaci√≥n: 3.547133982181549\n√âpoca 718\nPerdida entrenamiento: 0.07335239849411525\nPerdida validaci√≥n: 3.3462226688861847\n√âpoca 719\nPerdida entrenamiento: 0.07362754786243805\nPerdida validaci√≥n: 3.0637363731259484\n√âpoca 720\nPerdida entrenamiento: 0.07329921933034292\nPerdida validaci√≥n: 3.5014507174491882\n√âpoca 721\nPerdida entrenamiento: 0.07308094232128216\nPerdida validaci√≥n: 3.600960463285446\n√âpoca 722\nPerdida entrenamiento: 0.07359824429910916\nPerdida validaci√≥n: 3.6419607996940613\n√âpoca 723\nPerdida entrenamiento: 0.0702361033942837\nPerdida validaci√≥n: 3.3048584163188934\n√âpoca 724\nPerdida entrenamiento: 0.07198195188091351\nPerdida validaci√≥n: 3.635326474905014\n√âpoca 725\nPerdida entrenamiento: 0.07143456402879494\nPerdida validaci√≥n: 3.1239943015389144\n√âpoca 726\nPerdida entrenamiento: 0.07296538524902783\nPerdida validaci√≥n: 3.9761489629745483\n√âpoca 727\nPerdida entrenamiento: 0.06996076797636655\nPerdida validaci√≥n: 3.673790752887726\n√âpoca 728\nPerdida entrenamiento: 0.07061829260335518\nPerdida validaci√≥n: 3.527384489774704\n√âpoca 729\nPerdida entrenamiento: 0.07066990879292671\nPerdida validaci√≥n: 3.565238893032074\n√âpoca 730\nPerdida entrenamiento: 0.06986354305767097\nPerdida validaci√≥n: 3.1452227979898453\n√âpoca 731\nPerdida entrenamiento: 0.07251900878663246\nPerdida validaci√≥n: 3.676050305366516\n√âpoca 732\nPerdida entrenamiento: 0.07029389106453611\nPerdida validaci√≥n: 6.303750157356262\n√âpoca 733\nPerdida entrenamiento: 0.07063901882905227\nPerdida validaci√≥n: 3.6955054998397827\n√âpoca 734\nPerdida entrenamiento: 0.07026771971812615\nPerdida validaci√≥n: 3.6877950727939606\n√âpoca 735\nPerdida entrenamiento: 0.07010470860852645\nPerdida validaci√≥n: 3.8105451464653015\n√âpoca 736\nPerdida entrenamiento: 0.07092373674878708\nPerdida validaci√≥n: 6.272245496511459\n√âpoca 737\nPerdida entrenamiento: 0.06938746227667882\nPerdida validaci√≥n: 4.11859667301178\n√âpoca 738\nPerdida entrenamiento: 0.07033284137455317\nPerdida validaci√≥n: 3.489028960466385\n√âpoca 739\nPerdida entrenamiento: 0.07005046737881807\nPerdida validaci√≥n: 3.9497650265693665\n√âpoca 740\nPerdida entrenamiento: 0.06991838477551937\nPerdida validaci√≥n: 3.5906466245651245\n√âpoca 741\nPerdida entrenamiento: 0.07006746086363609\nPerdida validaci√≥n: 4.010214567184448\n√âpoca 742\nPerdida entrenamiento: 0.06976071902765678\nPerdida validaci√≥n: 3.903961181640625\n√âpoca 743\nPerdida entrenamiento: 0.07007302042956536\nPerdida validaci√≥n: 3.373776465654373\n√âpoca 744\nPerdida entrenamiento: 0.06779414845200685\nPerdida validaci√≥n: 3.4710806906223297\n√âpoca 745\nPerdida entrenamiento: 0.06950925863706149\nPerdida validaci√≥n: 3.2723368108272552\n√âpoca 746\nPerdida entrenamiento: 0.06822979550522107\nPerdida validaci√≥n: 3.880464196205139\n√âpoca 747\nPerdida entrenamiento: 0.06774935606293954\nPerdida validaci√≥n: 4.389346688985825\n√âpoca 748\nPerdida entrenamiento: 0.06761566936396636\nPerdida validaci√≥n: 3.15746596394456\n√âpoca 749\nPerdida entrenamiento: 0.06839605879325134\nPerdida validaci√≥n: 3.3875818252563477\n√âpoca 750\nPerdida entrenamiento: 0.06772242185588066\nPerdida validaci√≥n: 3.1746858982369304\n√âpoca 751\nPerdida entrenamiento: 0.06843308130135903\nPerdida validaci√≥n: 3.2046142797917128\n√âpoca 752\nPerdida entrenamiento: 0.06832610113689533\nPerdida validaci√≥n: 3.952906757593155\n√âpoca 753\nPerdida entrenamiento: 0.0690260434953066\nPerdida validaci√≥n: 3.7516192197799683\n√âpoca 754\nPerdida entrenamiento: 0.06749802698882726\nPerdida validaci√≥n: 3.1946978587657213\n√âpoca 755\nPerdida entrenamiento: 0.06692473447093597\nPerdida validaci√≥n: 3.173951795324683\n√âpoca 756\nPerdida entrenamiento: 0.06698934733867645\nPerdida validaci√≥n: 3.6998668909072876\n√âpoca 757\nPerdida entrenamiento: 0.06710446482667556\nPerdida validaci√≥n: 6.106452941894531\n√âpoca 758\nPerdida entrenamiento: 0.06671396270394325\nPerdida validaci√≥n: 3.59967178106308\n√âpoca 759\nPerdida entrenamiento: 0.0667688400986103\nPerdida validaci√≥n: 4.006033331155777\n√âpoca 760\nPerdida entrenamiento: 0.06433771564983405\nPerdida validaci√≥n: 9.396792531013489\n√âpoca 761\nPerdida entrenamiento: 0.0658060577339851\nPerdida validaci√≥n: 3.6313920319080353\n√âpoca 762\nPerdida entrenamiento: 0.06626230678879298\nPerdida validaci√≥n: 3.1925170212052763\n√âpoca 763\nPerdida entrenamiento: 0.06445745751261711\nPerdida validaci√≥n: 3.2214292294811457\n√âpoca 764\nPerdida entrenamiento: 0.0656591676748716\nPerdida validaci√≥n: 3.7026621997356415\n√âpoca 765\nPerdida entrenamiento: 0.06652211283261959\nPerdida validaci√≥n: 4.019250392913818\n√âpoca 766\nPerdida entrenamiento: 0.0645568874449684\nPerdida validaci√≥n: 3.2478851601481438\n√âpoca 767\nPerdida entrenamiento: 0.0645436357993346\nPerdida validaci√≥n: 3.634760797023773\n√âpoca 768\nPerdida entrenamiento: 0.06626242198623143\nPerdida validaci√≥n: 3.2138933995738626\n√âpoca 769\nPerdida entrenamiento: 0.06454834657219741\nPerdida validaci√≥n: 3.4520061314105988\n√âpoca 770\nPerdida entrenamiento: 0.06424231254137479\nPerdida validaci√≥n: 6.513358294963837\n√âpoca 771\nPerdida entrenamiento: 0.0674513099858394\nPerdida validaci√≥n: 3.208299418911338\n√âpoca 772\nPerdida entrenamiento: 0.06449403012028107\nPerdida validaci√≥n: 3.4559914767742157\n√âpoca 773\nPerdida entrenamiento: 0.06507012119086888\nPerdida validaci√≥n: 3.4043886959552765\n√âpoca 774\nPerdida entrenamiento: 0.06500616096533261\nPerdida validaci√≥n: 3.7424195408821106\n√âpoca 775\nPerdida entrenamiento: 0.06445603316219953\nPerdida validaci√≥n: 3.2316817604005337\n√âpoca 776\nPerdida entrenamiento: 0.06395076867192984\nPerdida validaci√≥n: 3.3793974220752716\n√âpoca 777\nPerdida entrenamiento: 0.06544297073896115\nPerdida validaci√≥n: 3.6280748546123505\n√âpoca 778\nPerdida entrenamiento: 0.06932021118700504\nPerdida validaci√≥n: 3.5138529241085052\n√âpoca 779\nPerdida entrenamiento: 0.07144579004782897\nPerdida validaci√≥n: 3.281018428504467\n√âpoca 780\nPerdida entrenamiento: 0.06321389299745743\nPerdida validaci√≥n: 4.2752964198589325\n√âpoca 781\nPerdida entrenamiento: 0.06387096292410906\nPerdida validaci√≥n: 6.191157042980194\n√âpoca 782\nPerdida entrenamiento: 0.06328819821087214\nPerdida validaci√≥n: 4.009998798370361\n√âpoca 783\nPerdida entrenamiento: 0.06345390198895565\nPerdida validaci√≥n: 3.5408129692077637\n√âpoca 784\nPerdida entrenamiento: 0.06154564581811428\nPerdida validaci√≥n: 3.728050410747528\n√âpoca 785\nPerdida entrenamiento: 0.06283387785347608\nPerdida validaci√≥n: 3.271757125854492\n√âpoca 786\nPerdida entrenamiento: 0.06242528486137207\nPerdida validaci√≥n: 3.5932647585868835\n√âpoca 787\nPerdida entrenamiento: 0.0626249214491019\nPerdida validaci√≥n: 6.087800234556198\n√âpoca 788\nPerdida entrenamiento: 0.06314485878325425\nPerdida validaci√≥n: 3.6031576097011566\n√âpoca 789\nPerdida entrenamiento: 0.0641820035301722\nPerdida validaci√≥n: 3.6429638266563416\n√âpoca 790\nPerdida entrenamiento: 0.06248174120600407\nPerdida validaci√≥n: 4.228351831436157\n√âpoca 791\nPerdida entrenamiento: 0.06177817901166586\nPerdida validaci√≥n: 4.137951165437698\n√âpoca 792\nPerdida entrenamiento: 0.0609730864660098\nPerdida validaci√≥n: 3.5382475554943085\n√âpoca 793\nPerdida entrenamiento: 0.0613269078043791\nPerdida validaci√≥n: 3.2661752179265022\n√âpoca 794\nPerdida entrenamiento: 0.06030727149202274\nPerdida validaci√≥n: 6.637757331132889\n√âpoca 795\nPerdida entrenamiento: 0.06137405077998455\nPerdida validaci√≥n: 3.8624553084373474\n√âpoca 796\nPerdida entrenamiento: 0.0609011253198752\nPerdida validaci√≥n: 3.3248483315110207\n√âpoca 797\nPerdida entrenamiento: 0.06208982662512706\nPerdida validaci√≥n: 3.9522294402122498\n√âpoca 798\nPerdida entrenamiento: 0.060166037999666654\nPerdida validaci√≥n: 3.2770682722330093\n√âpoca 799\nPerdida entrenamiento: 0.06056450558109926\nPerdida validaci√≥n: 3.343050740659237\n√âpoca 800\nPerdida entrenamiento: 0.06177033111453056\nPerdida validaci√≥n: 3.580229103565216\n√âpoca 801\nPerdida entrenamiento: 0.060246036746180974\nPerdida validaci√≥n: 3.505081385374069\n√âpoca 802\nPerdida entrenamiento: 0.061356705326873526\nPerdida validaci√≥n: 4.062293261289597\n√âpoca 803\nPerdida entrenamiento: 0.05942604003044275\nPerdida validaci√≥n: 4.110773056745529\n√âpoca 804\nPerdida entrenamiento: 0.060502128245738834\nPerdida validaci√≥n: 3.8822240233421326\n√âpoca 805\nPerdida entrenamiento: 0.05999588966369629\nPerdida validaci√≥n: 6.7766527235507965\n√âpoca 806\nPerdida entrenamiento: 0.059047887495790534\nPerdida validaci√≥n: 4.154969960451126\n√âpoca 807\nPerdida entrenamiento: 0.058758083587655656\nPerdida validaci√≥n: 4.048469461500645\n√âpoca 808\nPerdida entrenamiento: 0.059343369104541265\nPerdida validaci√≥n: 3.914748638868332\n√âpoca 809\nPerdida entrenamiento: 0.06124117999122693\nPerdida validaci√≥n: 3.564255177974701\n√âpoca 810\nPerdida entrenamiento: 0.05879233297533714\nPerdida validaci√≥n: 3.761751651763916\n√âpoca 811\nPerdida entrenamiento: 0.059525275316375956\nPerdida validaci√≥n: 3.518033117055893\n√âpoca 812\nPerdida entrenamiento: 0.058720690986284844\nPerdida validaci√≥n: 3.7310802340507507\n√âpoca 813\nPerdida entrenamiento: 0.059426360118847624\nPerdida validaci√≥n: 3.907933384180069\n√âpoca 814\nPerdida entrenamiento: 0.05819435217059576\nPerdida validaci√≥n: 3.6875914335250854\n√âpoca 815\nPerdida entrenamiento: 0.058877732748022445\nPerdida validaci√≥n: 3.6664465963840485\n√âpoca 816\nPerdida entrenamiento: 0.05832370979568133\nPerdida validaci√≥n: 3.8303341567516327\n√âpoca 817\nPerdida entrenamiento: 0.05997598550927181\nPerdida validaci√≥n: 4.546199798583984\n√âpoca 818\nPerdida entrenamiento: 0.06107013658262216\nPerdida validaci√≥n: 4.69145804643631\n√âpoca 819\nPerdida entrenamiento: 0.056150777981831476\nPerdida validaci√≥n: 3.3038771846331656\n√âpoca 820\nPerdida entrenamiento: 0.058985657416857205\nPerdida validaci√≥n: 3.8559694290161133\n√âpoca 821\nPerdida entrenamiento: 0.05928831898535673\nPerdida validaci√≥n: 4.11640003323555\n√âpoca 822\nPerdida entrenamiento: 0.05734322563960002\nPerdida validaci√≥n: 4.668489754199982\n√âpoca 823\nPerdida entrenamiento: 0.056264102745514646\nPerdida validaci√≥n: 3.920742154121399\n√âpoca 824\nPerdida entrenamiento: 0.05873554816039709\nPerdida validaci√≥n: 3.493961662054062\n√âpoca 825\nPerdida entrenamiento: 0.05683453810902742\nPerdida validaci√≥n: 6.510374307632446\n√âpoca 826\nPerdida entrenamiento: 0.055070443222155936\nPerdida validaci√≥n: 4.398071765899658\n√âpoca 827\nPerdida entrenamiento: 0.05675230762706353\nPerdida validaci√≥n: 4.375220954418182\n√âpoca 828\nPerdida entrenamiento: 0.055023180607419744\nPerdida validaci√≥n: 6.8428884744644165\n√âpoca 829\nPerdida entrenamiento: 0.05631783174780699\nPerdida validaci√≥n: 4.441886872053146\n√âpoca 830\nPerdida entrenamiento: 0.05498757557227062\nPerdida validaci√≥n: 4.170099914073944\n√âpoca 831\nPerdida entrenamiento: 0.05439775250852108\nPerdida validaci√≥n: 4.17107766866684\n√âpoca 832\nPerdida entrenamiento: 0.05483622884807678\nPerdida validaci√≥n: 4.0521272122859955\n√âpoca 833\nPerdida entrenamiento: 0.054396349363602124\nPerdida validaci√≥n: 4.2378314435482025\n√âpoca 834\nPerdida entrenamiento: 0.0537837570389876\nPerdida validaci√≥n: 6.800297603011131\n√âpoca 835\nPerdida entrenamiento: 0.05468137791523567\nPerdida validaci√≥n: 4.214636117219925\n√âpoca 836\nPerdida entrenamiento: 0.05472402432217048\nPerdida validaci√≥n: 4.283179759979248\n√âpoca 837\nPerdida entrenamiento: 0.054236042886399306\nPerdida validaci√≥n: 4.970643877983093\n√âpoca 838\nPerdida entrenamiento: 0.053958216395515665\nPerdida validaci√≥n: 4.149262264370918\n√âpoca 839\nPerdida entrenamiento: 0.05368467112286733\nPerdida validaci√≥n: 4.775151491165161\n√âpoca 840\nPerdida entrenamiento: 0.05479082651436329\nPerdida validaci√≥n: 4.5180723667144775\n√âpoca 841\nPerdida entrenamiento: 0.05527265548992615\nPerdida validaci√≥n: 4.143805742263794\n√âpoca 842\nPerdida entrenamiento: 0.05225516497515715\nPerdida validaci√≥n: 4.767333805561066\n√âpoca 843\nPerdida entrenamiento: 0.05295462655619933\nPerdida validaci√≥n: 4.054084673523903\n√âpoca 844\nPerdida entrenamiento: 0.052490573591337755\nPerdida validaci√≥n: 4.043152339756489\n√âpoca 845\nPerdida entrenamiento: 0.05167995869683532\nPerdida validaci√≥n: 4.035788454610156\n√âpoca 846\nPerdida entrenamiento: 0.05253026355057955\nPerdida validaci√≥n: 4.491959989070892\n√âpoca 847\nPerdida entrenamiento: 0.05272071479031673\nPerdida validaci√≥n: 4.08733955770731\n√âpoca 848\nPerdida entrenamiento: 0.051107910461723804\nPerdida validaci√≥n: 4.299175828695297\n√âpoca 849\nPerdida entrenamiento: 0.05270489319585837\nPerdida validaci√≥n: 4.7589231133461\n√âpoca 850\nPerdida entrenamiento: 0.05218249845963258\nPerdida validaci√≥n: 4.42910698056221\n√âpoca 851\nPerdida entrenamiento: 0.0517392076838475\nPerdida validaci√≥n: 4.063683340325952\n√âpoca 852\nPerdida entrenamiento: 0.05056576960935043\nPerdida validaci√≥n: 4.544508397579193\n√âpoca 853\nPerdida entrenamiento: 0.050385619298769876\nPerdida validaci√≥n: 7.497417986392975\n√âpoca 854\nPerdida entrenamiento: 0.051967507729736656\nPerdida validaci√≥n: 4.558947831392288\n√âpoca 855\nPerdida entrenamiento: 0.050523535993236765\nPerdida validaci√≥n: 7.215233594179153\n√âpoca 856\nPerdida entrenamiento: 0.05060775463397686\nPerdida validaci√≥n: 4.495422422885895\n√âpoca 857\nPerdida entrenamiento: 0.05093105721215789\nPerdida validaci√≥n: 7.129923522472382\n√âpoca 858\nPerdida entrenamiento: 0.05117681049383604\nPerdida validaci√≥n: 4.351238787174225\n√âpoca 859\nPerdida entrenamiento: 0.05049055363409794\nPerdida validaci√≥n: 4.08912917599082\n√âpoca 860\nPerdida entrenamiento: 0.05090016857362711\nPerdida validaci√≥n: 4.626007974147797\n√âpoca 861\nPerdida entrenamiento: 0.0504580932454421\nPerdida validaci√≥n: 4.207754582166672\n√âpoca 862\nPerdida entrenamiento: 0.050872162414284855\nPerdida validaci√≥n: 4.572880119085312\n√âpoca 863\nPerdida entrenamiento: 0.05100252135441853\nPerdida validaci√≥n: 7.2558281272649765\n√âpoca 864\nPerdida entrenamiento: 0.04953286008766064\nPerdida validaci√≥n: 4.496209770441055\n√âpoca 865\nPerdida entrenamiento: 0.05012407168172873\nPerdida validaci√≥n: 4.0990868136286736\n√âpoca 866\nPerdida entrenamiento: 0.048918719618366316\nPerdida validaci√≥n: 4.131444938480854\n√âpoca 867\nPerdida entrenamiento: 0.04928459671254341\nPerdida validaci√≥n: 5.020654857158661\n√âpoca 868\nPerdida entrenamiento: 0.04903019620822026\nPerdida validaci√≥n: 4.551450133323669\n√âpoca 869\nPerdida entrenamiento: 0.04945437524181146\nPerdida validaci√≥n: 4.500010818243027\n√âpoca 870\nPerdida entrenamiento: 0.04856425581070093\nPerdida validaci√≥n: 4.7949676513671875\n√âpoca 871\nPerdida entrenamiento: 0.04902963899075985\nPerdida validaci√≥n: 7.995621174573898\n√âpoca 872\nPerdida entrenamiento: 0.04977420273308571\nPerdida validaci√≥n: 7.18223363161087\n√âpoca 873\nPerdida entrenamiento: 0.04900971413231813\nPerdida validaci√≥n: 5.231534659862518\n√âpoca 874\nPerdida entrenamiento: 0.049250427060402356\nPerdida validaci√≥n: 4.179678939282894\n√âpoca 875\nPerdida entrenamiento: 0.048545404337346554\nPerdida validaci√≥n: 7.5138179659843445\n√âpoca 876\nPerdida entrenamiento: 0.04902011091605975\nPerdida validaci√≥n: 7.690000653266907\n√âpoca 877\nPerdida entrenamiento: 0.049634022459101215\nPerdida validaci√≥n: 4.181770049035549\n√âpoca 878\nPerdida entrenamiento: 0.04979390636659586\nPerdida validaci√≥n: 4.789144668728113\n√âpoca 879\nPerdida entrenamiento: 0.04782095207617833\nPerdida validaci√≥n: 7.752316355705261\n√âpoca 880\nPerdida entrenamiento: 0.047524592480980433\nPerdida validaci√≥n: 4.361296311020851\n√âpoca 881\nPerdida entrenamiento: 0.04772741806048613\nPerdida validaci√≥n: 5.283886909484863\n√âpoca 882\nPerdida entrenamiento: 0.049345526414421886\nPerdida validaci√≥n: 5.229241371154785\n√âpoca 883\nPerdida entrenamiento: 0.04679644315575178\nPerdida validaci√≥n: 7.914421200752258\n√âpoca 884\nPerdida entrenamiento: 0.04703991981939627\nPerdida validaci√≥n: 5.433315575122833\n√âpoca 885\nPerdida entrenamiento: 0.049513145278279595\nPerdida validaci√≥n: 7.677872061729431\n√âpoca 886\nPerdida entrenamiento: 0.04793915123893665\nPerdida validaci√≥n: 5.197003066539764\n√âpoca 887\nPerdida entrenamiento: 0.04776551424024197\nPerdida validaci√≥n: 5.358761668205261\n√âpoca 888\nPerdida entrenamiento: 0.0485514304958857\nPerdida validaci√≥n: 4.744048622378614\n√âpoca 889\nPerdida entrenamiento: 0.049604152114345476\nPerdida validaci√≥n: 8.026496231555939\n√âpoca 890\nPerdida entrenamiento: 0.04807417854093588\nPerdida validaci√≥n: 5.384512186050415\n√âpoca 891\nPerdida entrenamiento: 0.04864290915429592\nPerdida validaci√≥n: 5.179917335510254\n√âpoca 892\nPerdida entrenamiento: 0.04812890613594881\nPerdida validaci√≥n: 5.456477701663971\n√âpoca 893\nPerdida entrenamiento: 0.04833104031590315\nPerdida validaci√≥n: 8.13897693157196\n√âpoca 894\nPerdida entrenamiento: 0.04785565258218692\nPerdida validaci√≥n: 7.886135160923004\n√âpoca 895\nPerdida entrenamiento: 0.049369161805281274\nPerdida validaci√≥n: 7.536204218864441\n√âpoca 896\nPerdida entrenamiento: 0.05050841332055055\nPerdida validaci√≥n: 5.33561635017395\n√âpoca 897\nPerdida entrenamiento: 0.04976207891908976\nPerdida validaci√≥n: 7.572638392448425\n√âpoca 898\nPerdida entrenamiento: 0.048271565626447015\nPerdida validaci√≥n: 5.2607505321502686\n√âpoca 899\nPerdida entrenamiento: 0.0469307591422246\nPerdida validaci√≥n: 4.9310347735881805\n√âpoca 900\nPerdida entrenamiento: 0.046212898853879705\nPerdida validaci√≥n: 10.429802477359772\n√âpoca 901\nPerdida entrenamiento: 0.04607743311386842\nPerdida validaci√≥n: 8.391501128673553\n√âpoca 902\nPerdida entrenamiento: 0.0450165058987645\nPerdida validaci√≥n: 7.945931136608124\n√âpoca 903\nPerdida entrenamiento: 0.04573409936319177\nPerdida validaci√≥n: 6.206254571676254\n√âpoca 904\nPerdida entrenamiento: 0.046273574662896305\nPerdida validaci√≥n: 4.837220882647671\n√âpoca 905\nPerdida entrenamiento: 0.04536168943517483\nPerdida validaci√≥n: 5.7693856954574585\n√âpoca 906\nPerdida entrenamiento: 0.04983616161804933\nPerdida validaci√≥n: 4.874648252502084\n√âpoca 907\nPerdida entrenamiento: 0.048089443491055414\nPerdida validaci√≥n: 4.867903176695108\n√âpoca 908\nPerdida entrenamiento: 0.04482537740841508\nPerdida validaci√≥n: 5.361008048057556\n√âpoca 909\nPerdida entrenamiento: 0.04441759233864454\nPerdida validaci√≥n: 8.161953628063202\n√âpoca 910\nPerdida entrenamiento: 0.04429550490413721\nPerdida validaci√≥n: 5.4278759360313416\n√âpoca 911\nPerdida entrenamiento: 0.04375691038484757\nPerdida validaci√≥n: 5.562376141548157\n√âpoca 912\nPerdida entrenamiento: 0.04385505602336847\nPerdida validaci√≥n: 5.063310891389847\n√âpoca 913\nPerdida entrenamiento: 0.04419422715615768\nPerdida validaci√≥n: 5.079816937446594\n√âpoca 914\nPerdida entrenamiento: 0.043570125833726846\nPerdida validaci√≥n: 5.188879191875458\n√âpoca 915\nPerdida entrenamiento: 0.043833284853742674\nPerdida validaci√≥n: 4.941752478480339\n√âpoca 916\nPerdida entrenamiento: 0.04390216339379549\nPerdida validaci√≥n: 4.89091937802732\n√âpoca 917\nPerdida entrenamiento: 0.04507616391548744\nPerdida validaci√≥n: 5.422266781330109\n√âpoca 918\nPerdida entrenamiento: 0.043265287119608656\nPerdida validaci√≥n: 5.867627322673798\n√âpoca 919\nPerdida entrenamiento: 0.04298393084452702\nPerdida validaci√≥n: 7.655619859695435\n√âpoca 920\nPerdida entrenamiento: 0.04295176403740278\nPerdida validaci√≥n: 10.454034566879272\n√âpoca 921\nPerdida entrenamiento: 0.04356664985131759\nPerdida validaci√≥n: 5.592731535434723\n√âpoca 922\nPerdida entrenamiento: 0.042768083369502656\nPerdida validaci√≥n: 4.900315457955003\n√âpoca 923\nPerdida entrenamiento: 0.045229774326659165\nPerdida validaci√≥n: 5.696951985359192\n√âpoca 924\nPerdida entrenamiento: 0.04300991954425207\nPerdida validaci√≥n: 4.877590395510197\n√âpoca 925\nPerdida entrenamiento: 0.04320732837256331\nPerdida validaci√≥n: 5.988415837287903\n√âpoca 926\nPerdida entrenamiento: 0.04337704124358984\nPerdida validaci√≥n: 8.132118225097656\n√âpoca 927\nPerdida entrenamiento: 0.043636782381397024\nPerdida validaci√≥n: 5.575676202774048\n√âpoca 928\nPerdida entrenamiento: 0.043071469435325034\nPerdida validaci√≥n: 7.69149649143219\n√âpoca 929\nPerdida entrenamiento: 0.04279871220485522\nPerdida validaci√≥n: 8.94551944732666\n√âpoca 930\nPerdida entrenamiento: 0.04158741343193329\nPerdida validaci√≥n: 5.9363309144973755\n√âpoca 931\nPerdida entrenamiento: 0.042360139437592946\nPerdida validaci√≥n: 5.669342577457428\n√âpoca 932\nPerdida entrenamiento: 0.04308424804073114\nPerdida validaci√≥n: 7.684343189001083\n√âpoca 933\nPerdida entrenamiento: 0.042666685265990406\nPerdida validaci√≥n: 11.007444053888321\n√âpoca 934\nPerdida entrenamiento: 0.04146604684109871\nPerdida validaci√≥n: 5.555517554283142\n√âpoca 935\nPerdida entrenamiento: 0.04259964572982146\nPerdida validaci√≥n: 5.175597250461578\n√âpoca 936\nPerdida entrenamiento: 0.04205227105949934\nPerdida validaci√≥n: 5.40211808681488\n√âpoca 937\nPerdida entrenamiento: 0.04228109278931068\nPerdida validaci√≥n: 6.1808552742004395\n√âpoca 938\nPerdida entrenamiento: 0.04311830536104166\nPerdida validaci√≥n: 10.741185247898102\n√âpoca 939\nPerdida entrenamiento: 0.043163470637339815\nPerdida validaci√≥n: 5.921260833740234\n√âpoca 940\nPerdida entrenamiento: 0.04055054041628654\nPerdida validaci√≥n: 5.262785702943802\n√âpoca 941\nPerdida entrenamiento: 0.04157177903331243\nPerdida validaci√≥n: 5.35451865196228\n√âpoca 942\nPerdida entrenamiento: 0.0415198694771299\nPerdida validaci√≥n: 7.973495125770569\n√âpoca 943\nPerdida entrenamiento: 0.040533507314439006\nPerdida validaci√≥n: 4.92364627122879\n√âpoca 944\nPerdida entrenamiento: 0.04062959207938267\nPerdida validaci√≥n: 5.073706194758415\n√âpoca 945\nPerdida entrenamiento: 0.040624873067897097\nPerdida validaci√≥n: 8.072493553161621\n√âpoca 946\nPerdida entrenamiento: 0.040667824447155\nPerdida validaci√≥n: 5.12357422709465\n√âpoca 947\nPerdida entrenamiento: 0.04132207554693405\nPerdida validaci√≥n: 4.931139972992241\n√âpoca 948\nPerdida entrenamiento: 0.041251580589092694\nPerdida validaci√≥n: 6.213336825370789\n√âpoca 949\nPerdida entrenamiento: 0.03960881582819498\nPerdida validaci√≥n: 5.1579442620277405\n√âpoca 950\nPerdida entrenamiento: 0.04065688083378168\nPerdida validaci√≥n: 5.068708926439285\n√âpoca 951\nPerdida entrenamiento: 0.041666437370272785\nPerdida validaci√≥n: 5.178554832935333\n√âpoca 952\nPerdida entrenamiento: 0.04248258535965131\nPerdida validaci√≥n: 7.714734971523285\n√âpoca 953\nPerdida entrenamiento: 0.03928559345121567\nPerdida validaci√≥n: 4.913980485871434\n√âpoca 954\nPerdida entrenamiento: 0.041722226314819776\nPerdida validaci√≥n: 5.258084446191788\n√âpoca 955\nPerdida entrenamiento: 0.04159032173741322\nPerdida validaci√≥n: 5.252501457929611\n√âpoca 956\nPerdida entrenamiento: 0.04170346489319435\nPerdida validaci√≥n: 4.984535411000252\n√âpoca 957\nPerdida entrenamiento: 0.04048321252832046\nPerdida validaci√≥n: 8.03850769996643\n√âpoca 958\nPerdida entrenamiento: 0.04004818967615183\nPerdida validaci√≥n: 8.282288789749146\n√âpoca 959\nPerdida entrenamiento: 0.04017204476090578\nPerdida validaci√≥n: 8.028823256492615\n√âpoca 960\nPerdida entrenamiento: 0.03906387448883974\nPerdida validaci√≥n: 5.145549774169922\n√âpoca 961\nPerdida entrenamiento: 0.041092993978124395\nPerdida validaci√≥n: 5.181346893310547\n√âpoca 962\nPerdida entrenamiento: 0.03917228444837607\nPerdida validaci√≥n: 5.263754636049271\n√âpoca 963\nPerdida entrenamiento: 0.03960341867059469\nPerdida validaci√≥n: 5.101293057203293\n√âpoca 964\nPerdida entrenamiento: 0.03922462800087837\nPerdida validaci√≥n: 5.038782596588135\n√âpoca 965\nPerdida entrenamiento: 0.03790095942811324\nPerdida validaci√≥n: 4.954838437348371\n√âpoca 966\nPerdida entrenamiento: 0.03930759118296779\nPerdida validaci√≥n: 5.001334883272648\n√âpoca 967\nPerdida entrenamiento: 0.03813998795186098\nPerdida validaci√≥n: 6.026365399360657\n√âpoca 968\nPerdida entrenamiento: 0.038181327283382416\nPerdida validaci√≥n: 5.887161493301392\n√âpoca 969\nPerdida entrenamiento: 0.03895379753353504\nPerdida validaci√≥n: 5.548644781112671\n√âpoca 970\nPerdida entrenamiento: 0.03912664047227456\nPerdida validaci√≥n: 5.311693072319031\n√âpoca 971\nPerdida entrenamiento: 0.03870617698591489\nPerdida validaci√≥n: 5.490020513534546\n√âpoca 972\nPerdida entrenamiento: 0.03748865955724166\nPerdida validaci√≥n: 10.62033686041832\n√âpoca 973\nPerdida entrenamiento: 0.03864966748425594\nPerdida validaci√≥n: 5.311264842748642\n√âpoca 974\nPerdida entrenamiento: 0.03776480472431733\nPerdida validaci√≥n: 6.198935285210609\n√âpoca 975\nPerdida entrenamiento: 0.03823253541038586\nPerdida validaci√≥n: 6.116997182369232\n√âpoca 976\nPerdida entrenamiento: 0.037811676756693766\nPerdida validaci√≥n: 5.664330780506134\n√âpoca 977\nPerdida entrenamiento: 0.038681479170918465\nPerdida validaci√≥n: 5.71380490064621\n√âpoca 978\nPerdida entrenamiento: 0.03898881017588652\nPerdida validaci√≥n: 5.0552245527505875\n√âpoca 979\nPerdida entrenamiento: 0.0369387546984049\nPerdida validaci√≥n: 5.013122085481882\n√âpoca 980\nPerdida entrenamiento: 0.03696431670911037\nPerdida validaci√≥n: 5.435646593570709\n√âpoca 981\nPerdida entrenamiento: 0.0377054988191678\nPerdida validaci√≥n: 7.99576997756958\n√âpoca 982\nPerdida entrenamiento: 0.03688380738290457\nPerdida validaci√≥n: 5.6264747977256775\n√âpoca 983\nPerdida entrenamiento: 0.03905959971822225\nPerdida validaci√≥n: 5.130975678563118\n√âpoca 984\nPerdida entrenamiento: 0.03906594059215142\nPerdida validaci√≥n: 5.282015740871429\n√âpoca 985\nPerdida entrenamiento: 0.040465183269519076\nPerdida validaci√≥n: 5.062030218541622\n√âpoca 986\nPerdida entrenamiento: 0.039131697912055716\nPerdida validaci√≥n: 5.825139343738556\n√âpoca 987\nPerdida entrenamiento: 0.03985199138808709\nPerdida validaci√≥n: 4.996991615742445\n√âpoca 988\nPerdida entrenamiento: 0.03810182027518749\nPerdida validaci√≥n: 5.061925791203976\n√âpoca 989\nPerdida entrenamiento: 0.03756197885825084\nPerdida validaci√≥n: 6.193111687898636\n√âpoca 990\nPerdida entrenamiento: 0.037496679104291476\nPerdida validaci√≥n: 5.766824841499329\n√âpoca 991\nPerdida entrenamiento: 0.037181258703080505\nPerdida validaci√≥n: 5.420461535453796\n√âpoca 992\nPerdida entrenamiento: 0.03704871022357391\nPerdida validaci√≥n: 8.288544058799744\n√âpoca 993\nPerdida entrenamiento: 0.03609542168963414\nPerdida validaci√≥n: 5.090890198945999\n√âpoca 994\nPerdida entrenamiento: 0.03537790541752027\nPerdida validaci√≥n: 7.8367608189582825\n√âpoca 995\nPerdida entrenamiento: 0.036478488777692504\nPerdida validaci√≥n: 8.35268884897232\n√âpoca 996\nPerdida entrenamiento: 0.03573003110404198\nPerdida validaci√≥n: 8.260665535926819\n√âpoca 997\nPerdida entrenamiento: 0.0378370895408667\nPerdida validaci√≥n: 5.0253689478267916\n√âpoca 998\nPerdida entrenamiento: 0.03472784552006768\nPerdida validaci√≥n: 7.795221388339996\n√âpoca 999\nPerdida entrenamiento: 0.035625782007208236\nPerdida validaci√≥n: 5.025393606225407\n√âpoca 1000\nPerdida entrenamiento: 0.034889969401634656\nPerdida validaci√≥n: 6.157822489738464\n\n\nComo se puede observar la p√©rdida de validaci√≥n empieza a ser mucho mayor que la p√©rdida de entrenamiento, esto es un claro indicador de Overfitting"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "",
    "text": "Profesor Asociado en la Universidad Escuela Colombiana de Ingenieria, Analista de Datos con un s√≥lido trasfondo como Ingeniero en Electr√≥nica y Telecomunicaciones y Doctor en Ciencias de la Electr√≥nica. Cuento con 20 a√±os de experiencia en Educaci√≥n Universitaria y una destacada participaci√≥n en proyectos de investigaci√≥n en el campo de la Ciencia de los Datos aplicada a las organizaciones, el aprendizaje y la ciencia. Mi enfoque se centra en utilizar mis habilidades t√©cnicas y experiencia para analizar grandes conjuntos de datos y extraer conocimientos valiosos que impulsen la toma de decisiones informadas."
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "2016",
    "text": "2016\n- P. E. Caicedo-Rodr√≠guez, Rengifo-Rodas, Carlos Felipe, y Rodr√≠guez-Cheu, Luis Eduardo, ¬´Contributions of electronic sciences to the problem of falls of old age population¬ª, 2016, doi: 10.17488/RMIB.37.3.6."
  },
  {
    "objectID": "about.html#section-1",
    "href": "about.html#section-1",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "2017",
    "text": "2017\n- P. E. Caicedo-Rodr√≠guez, C. F. Rengifo-Rodas, y L. E. Rodr√≠guez-Cheu, ¬´A human gait temporal parameters calculation algorithm¬ª, en VII Latin American Congress on Biomedical Engineering CLAIB 2016, Bucaramanga, Santander, Colombia, October 26th -28th, 2016, vol. 60, I. Torres, J. Bustamante, y D. A. Sierra, Eds., en IFMBE Proceedings, vol. 60. , Singapore: Springer Singapore, 2017, pp. 285-288. doi: 10.1007/978-981-10-4086-3_72."
  },
  {
    "objectID": "about.html#section-2",
    "href": "about.html#section-2",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "2018",
    "text": "2018\n-  S. P. Castillo-Land√≠nez y P. E. Caicedo-Rodr√≠guez, ¬´EL BLOG COMO HERRAMIENTA DE ENSE√ëANZA EN LOS CURSOS DE INVESTIGACI√ìN¬ª, presentado en Encuentro Internacional de Educaci√≥n en Ingenier√≠a ACOFI, Cartagena, Colombia, 2018."
  },
  {
    "objectID": "about.html#section-3",
    "href": "about.html#section-3",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "2019",
    "text": "2019\n- N. Valencia-Jimenez et¬†al., ¬´A Comparative Study of Markerless Systems Based on Color-Depth Cameras, Polymer Optical Fiber Curvature Sensors, and Inertial Measurement Units: Towards Increasing the Accuracy in Joint Angle Estimation¬ª, Electronics, vol. 8, n.¬∫ 2, p. 173, feb. 2019, doi: 10.3390/electronics8020173.\n- S. P. Castillo-Landinez, P. E. Caicedo-Rodr√≠guez, y D. F. S√°nchez-G√≥mez, ¬´Dise√±o e implementaci√≥n de un software para la trazabilidad del proceso de beneficio del caf√©¬ª, CTA, vol. 20, n.¬∫ 3, sep. 2019, doi: 10.21930/rcta.vol20_num3_art:1588.\n- P. E. Caicedo-Rodriguez, C. F. Rengifo-Rodas, L. E. Rodr√≠guez-Cheu, y W. A. Sierra-Arevalo, ¬´Gait Phase Detection for Lower Limb Prosthetic Devices¬ª, en Wearable Robotics: Challenges and Trends, vol. 22, M. C. Carrozza, S. Micera, y J. L. Pons, Eds., en Biosystems & Biorobotics, vol. 22. , Cham: Springer International Publishing, 2019, pp. 201-205. doi: 10.1007/978-3-030-01887-0_39.\n- S. P. Castillo-Land√≠nez y P. E. Caicedo-Rodr√≠guez, ¬´AN√ÅLISIS DE SENTIMIENTOS, UNA HERRAMIENTA PARA VALORAR LA ACTITUD DEL ESTUDIANTE FRENTE A UN CURSO¬ª, presentado en Encuentro internacional de educaci√≥n en ingenier√≠a, Cartagena, Colombia, 2019.\nP. E. Caicedo-Rodr√≠guez, C. F. Rengifo-Rodas, y L. E. Rodriguez-Cheu, ¬´LA VELOCIDAD DE MARCHA COMO FACTOR DISCRIMINATORIO DEL RIESGO DE CA√çDA EN ADULTOS MAYORES¬ª, presentado en Encuentro internacional de educaci√≥n en ingenier√≠a, Cartagena, Colombia, 2019. doi: 10.26507/ponencia.282."
  },
  {
    "objectID": "about.html#section-4",
    "href": "about.html#section-4",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "2020",
    "text": "2020\n- P. E. Caicedo-Rodr√≠guez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. G√≥mez-Guevara, ¬´Dataset for gait analysis and assessment of fall risk for older adults¬ª, Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- P. E. Caicedo-Rodr√≠guez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. G√≥mez-Guevara, ¬´Dataset for gait analysis and assessment of fall risk for older adults¬ª, Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- Y. H. Bola√±os-Mu√±oz, C. F. Rengifo-Rodas, P. E. Caicedo-Rodr√≠guez, L. E. Rodriguez-Cheu, y W. A. Sierra-Arevalo, ¬´Electronic system for step width estimation using programmable system-on-chip technology and time of flight cameras¬ª, HardwareX, vol. 8, p. e00126, oct. 2020, doi: 10.1016/j.ohx.2020.e00126.\n- S. P. Castillo Land√≠nez, P. E. Caicedo Rodr√≠guez, y S. A. Mu√±oz De La Rosa, ¬´LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA CUARENTENA A TRAV√âS DEL AN√ÅLISIS DE SENTIMIENTOS. UN CASO DE ESTUDIO EN LA UNIAUT√ìNOMA DEL CAUCA¬ª, en Encuentro Internacional de Educaci√≥n en Ingenier√≠a ACOFI 2020, Asociacion Colombiana de Facultades de Ingenier√≠a - ACOFI, ago. 2020, pp. 1-8. doi: 10.26507/ponencia.820.\n- J. P. Henao-Pereira, A. E. Tovar-Leon, S. P. Castillo-Land√≠nez, y P. E. Caicedo-Rodr√≠guez, ¬´Los accidentes de tr√°nsito desde la perspectiva de la miner√≠a de datos. Una revisi√≥n de la literatura¬ª, Aibi revista investig. adm. ing., pp. 133-141, ago. 2020, doi: 10.15649/2346030X.743."
  },
  {
    "objectID": "about.html#section-5",
    "href": "about.html#section-5",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "2021",
    "text": "2021\n- P. E. Caicedo-Rodr√≠guez, Incidencia de los sistemas electr√≥nicos de medici√≥n de variables biomec√°nicas en la concordancia intra e inter evaluador del examen POMA de funci√≥n motora, Primera. Popay√°n, Colombia: Sello Editorial Uniaut√≥noma del Cauca, 2021.\n- S. Castillo Land√≠nez, P. E. Caicedo Rodr√≠guez, S. A. Mu√±oz De La Rosa, y J. P. Sandoval Paz, ¬´LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA PANDEMIA, UN A√ëO DESPU√âS¬ª, en Encuentro Internacional de Educaci√≥n en Ingenier√≠a ACOFI 2021, Asociacion Colombiana de Facultades de Ingenier√≠a - ACOFI, sep. 2021, pp. 1-9. doi: 10.26507/ponencia.2005.\n- L. S. Vargas-Valencia et¬†al., ¬´Sleeve for Knee Angle Monitoring: An IMU-POF Sensor Fusion System¬ª, IEEE J. Biomed. Health Inform., vol. 25, n.¬∫ 2, pp. 465-474, feb. 2021, doi: 10.1109/JBHI.2020.2988360.\n- C. R. Malaver-Flor y M. Y. Astorquiza-Velasco, ¬´T√©cnicas de Procesamiento Para Variables Posturales Enfocadas en Detecci√≥n Temprana Del Microtraumatismo Tisular de un Ciclista¬ª, PROSPECTIVA, vol. 19, n.¬∫ 2, 2021."
  },
  {
    "objectID": "about.html#section-6",
    "href": "about.html#section-6",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "2022",
    "text": "2022\n- S. Castillo Land√≠nez, P. E. Caicedo Rodr√≠guez, y J. A. Mosquera Bola√±os, ¬´Los adolescentes y el uso de las redes sociales. Un an√°lisis desde la √≥ptica de la ciencia de datos y el procesamiento de lenguaje natural¬ª, presentado en Nuevas realidades para la educaci√≥n en ingenier√≠a: curr√≠culo, tecnolog√≠a, medio ambiente y desarrollo, sep. 2022, pp. 1-8. doi: 10.26507/paper.2693.\n- V. Cer√≥n Monje, C. E. Z√∫√±iga Mu√±oz, S. P. Castillo Land√≠nez, y P. E. Caicedo Rodr√≠guez, ¬´An√°lisis de sentimientos aplicado a la evaluaci√≥n docente de la Corporaci√≥n Universitaria Aut√≥noma del Cauca¬ª, presentado en Nuevas realidades para la educaci√≥n en ingenier√≠a: curr√≠culo, tecnolog√≠a, medio ambiente y desarrollo, sep. 2022, pp. 1-10. doi: 10.26507/paper.2308."
  },
  {
    "objectID": "about.html#section-7",
    "href": "about.html#section-7",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "2023",
    "text": "2023\n- J. M. Cabrera √Ångel, P. E. Caicedo-Rodr√≠guez, y S. Castillo-Land√≠nez, ¬´As√≠ nos vemos¬ª, Uniautonoma del Cauca, Popay√°n, 2023.\n- S. Castillo Land√≠nez y P. E. Caicedo Rodr√≠guez, ¬´¬°¬°¬°Ahora s√≠ toc√≥ poner atenci√≥n porque hay que evaluar!!!¬ª, presentado en Ingenier√≠a para transformar territorios, sep. 2023, pp. 1-10. doi: 10.26507/paper.2941."
  },
  {
    "objectID": "about.html#section-8",
    "href": "about.html#section-8",
    "title": "Ph.D.¬†Pablo Eduardo Caicedo R",
    "section": "2024",
    "text": "2024"
  },
  {
    "objectID": "laboratorios/APSB/lab01_IniciandoJetsonNano.html",
    "href": "laboratorios/APSB/lab01_IniciandoJetsonNano.html",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Download the Jetson Nano 2GB Developer Kit SD Card Image and note where it was saved on the computer.\nDownload, install, and launchSD Memory Card Formatter for Windows\nDownload, install, and launch Etcher."
  },
  {
    "objectID": "laboratorios/APSB/lab01_IniciandoJetsonNano.html#requiered-downloads",
    "href": "laboratorios/APSB/lab01_IniciandoJetsonNano.html#requiered-downloads",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Download the Jetson Nano 2GB Developer Kit SD Card Image and note where it was saved on the computer.\nDownload, install, and launchSD Memory Card Formatter for Windows\nDownload, install, and launch Etcher."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "title": "Lab√≥ratorio 002. ‚ÄúDesarrollo de soluciones innovadoras en procesamiento de se√±ales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible‚Äù",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen t√©cnicas de procesamiento de se√±ales (1D) para abordar problemas de salud, contribuyendo as√≠ a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#descripci√≥n-de-la-actividad",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#descripci√≥n-de-la-actividad",
    "title": "Lab√≥ratorio 002. ‚ÄúDesarrollo de soluciones innovadoras en procesamiento de se√±ales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible‚Äù",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen t√©cnicas de procesamiento de se√±ales (1D) para abordar problemas de salud, contribuyendo as√≠ a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "title": "Lab√≥ratorio 002. ‚ÄúDesarrollo de soluciones innovadoras en procesamiento de se√±ales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible‚Äù",
    "section": "Requisitos:",
    "text": "Requisitos:\n\nIdentificar un problema de salud espec√≠fico y relevante, relacionado con los ODS.\nJustificar la importancia del problema y la necesidad de una soluci√≥n innovadora.\nEstablecer objetivos claros y medibles para el proyecto.\nElegir un dataset apropiado de se√±ales (1D).\nDesarrollar una soluci√≥n t√©cnica que satisfaga los indicadores de soluci√≥n de problema, con descripci√≥n matem√°tica, f√≠sica y/o estad√≠stica.\nImplementar la soluci√≥n en Python."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#r√∫brica-de-evaluaci√≥n",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#r√∫brica-de-evaluaci√≥n",
    "title": "Lab√≥ratorio 002. ‚ÄúDesarrollo de soluciones innovadoras en procesamiento de se√±ales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible‚Äù",
    "section": "R√∫brica de evaluaci√≥n",
    "text": "R√∫brica de evaluaci√≥n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPuntos\nBueno\nRegular\nMalo\n\n\n\n\nProblema de salud identificado\n15\nProblema claro, relevante y bien justificado (15puntos)\nProblema claro, pero justificaci√≥n d√©bil (7puntos)\nProblema no claro o no relevante (0puntos)\n\n\nJustificaci√≥n y objetivos\n15\nJustificaci√≥n s√≥lida y objetivos claros y medibles (15puntos)\nJustificaci√≥n d√©bil y objetivos poco claros (7puntos)\nJustificaci√≥n y objetivos no claros (0puntos)\n\n\nSoluci√≥n t√©cnica\n20\nSoluci√≥n innovadora, bien fundamentada y correctamente implementada en Python (20puntos)\nSoluci√≥n adecuada, pero con errores en la implementaci√≥n (10puntos)\nSoluci√≥n no innovadora o con errores graves (0puntos)\n\n\nDise√±o de indicadores\n20\nIndicadores bien definidos, con descripci√≥n matem√°tica, m√©dica y estad√≠stica clara y precisa (20puntos)\nIndicadores bien definidos, pero con descripci√≥n no clara o incompleta (10puntos)\nIndicadores no bien definidos o sin descripci√≥n (0puntos)\n\n\nContribuci√≥n a los ODS\n10\nContribuci√≥n clara y significativa a los ODS (10puntos)\nContribuci√≥n moderada a los ODS (7puntos)\nContribuci√≥n no clara o nula a los ODS (0puntos)\n\n\nImpacto potencial en la salud\n10\nImpacto potencial alto y bien justificado (10puntos)\nImpacto potencial moderado y justificaci√≥n d√©bil (7puntos)\nImpacto potencial bajo o no justificado (0puntos)\n\n\nPresentaci√≥n y documentaci√≥n\n10\nPresentaci√≥n clara y documentaci√≥n precisa y completa (10puntos)\nPresentaci√≥n clara, pero documentaci√≥n no precisa (7puntos)\nPresentaci√≥n no clara o documentaci√≥n no est√° presente (0puntos)"
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "Al finalizar, el estudiante ser√° capaz de:\n1. Explicar la relaci√≥n entre la profundidad de bit \\(b\\), los niveles representables \\(L=2^{b}\\) y el paso de cuantizaci√≥n \\(\\Delta\\) en una imagen digital.\n2. Adquirir y documentar im√°genes bajo condiciones controladas para analizar rango din√°mico, histogramas y artefactos de cuantizaci√≥n (banding, posterizaci√≥n).\n3. Convertir im√°genes RGB a espacios HSV, CIE L*a*b* y Y‚ÄôCrCb (formato OpenCV) e interpretar la sem√°ntica de canales e histogramas.\n4. Cuantizar im√°genes a distintas profundidades de bit y evaluar distorsi√≥n con \\(\\mathrm{MSE}\\); discutir perceptualmente los cambios.\n5. Justificar la elecci√≥n de espacio de color seg√∫n la tarea (robustez a iluminaci√≥n, segmentaci√≥n, compresi√≥n) con evidencia cualitativa y cuantitativa.\n\n\n\n\n\nCuantizaci√≥n. Para una se√±al \\(x\\in[X_{\\min},X_{\\max}]\\), la cuantizaci√≥n uniforme escalar con \\(b\\) bits tiene \\(L=2^{b}\\) niveles y paso \\(\\Delta=\\dfrac{X_{\\max}-X_{\\min}}{L}\\). El error de cuantizaci√≥n \\(e=x-\\hat{x}\\in[-\\Delta/2,\\Delta/2]\\) (mid-tread).\nRango din√°mico. En \\(b\\) bits sin signo: \\([0,\\,2^{b}-1]\\) (en 8 bits: \\([0,255]\\)).\nEspacios de color (OpenCV).\n\nBGR (lectura por defecto en OpenCV).\n\nHSV: cv2.COLOR_BGR2HSV (H en [0,179] para uint8).\n\nLab: cv2.COLOR_BGR2LAB (uint8: \\(L^\\*\\in[0,255]\\), \\(a^\\*,b^\\*\\approx[0,255]\\) con 128 ‚âà neutro).\n\nYCrCb: cv2.COLOR_BGR2YCrCb (orden de cromas: Y, Cr, Cb).\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nOpenCV trabaja en BGR (no RGB) cuando lee/escribe im√°genes con cv2.imread y cv2.imwrite. Para mostrar correctamente en archivos guardados, no es necesario convertir a RGB; sin embargo, documente siempre el orden de canales.\n\n\n\n\n\n\n\n\nC√°mara de tel√©fono u ordenador. Fijar ISO, tiempo de exposici√≥n y balance de blancos. Preferir PNG/TIFF (sin p√©rdidas); si es posible, capturar RAW+JPEG.\nEscena est√°tica con colores saturados y neutros (p.¬†ej., cuadr√≠cula de color y rampa en escala de grises en un monitor). Iluminaci√≥n difusa y estable.\nPython 3.12 con: opencv-python y numpy. No use otras librer√≠as de imagen/visualizaci√≥n.\n\n\n\n\n\n\nMontaje de escena (iluminaci√≥n constante). Fondo neutro; evitar brillos especulares.\n\nConjunto A (referencia, 8 bits sin p√©rdidas). Guardar una imagen n√≠tida y bien expuesta en PNG/TIFF.\n\nConjunto B (bracketing de exposici√≥n). ¬±1 y ¬±2 EV respecto a la referencia para discutir recorte (clipping) vs.¬†cuantizaci√≥n.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nMantenga fijos los par√°metros de c√°mara entre capturas. Cambios en ISO o WB confunden los an√°lisis de profundidad de bit y espacio de color.\n\n\n\n\n\n\n\nCargar la imagen de referencia. Inspeccionar forma, dtype, m√≠nimos/m√°ximos usando √∫nicamente OpenCV.\n\nEstimar el uso efectivo de bits contando valores distintos por canal.\nCuente cuantos pixeles hay, por cada canal y nivel del canal\n\n\n\n\n\n-Explique que es el error cuadr√°tico medio (MSE, por sus siglas en ingl√©s) y la relaci√≥n se√±al a rudio pico (PSNR, por sus siglas en ingl√©s), Cuantice la imagen BGR de referencia a \\(b\\in\\{1,2,\\dots,7\\}\\) bits (por canal). Para cada \\(b\\):\n\nCalcule \\(\\mathrm{MSE}\\) y \\(\\mathrm{PSNR}\\) respecto a la referencia ($b=8).\nGenere y guarde la imagen cuantizada y un mapa de error visual (colormap).\n\n\n\n\n\n\nConvertir la imagen de referencia a HSV, Lab y YCrCb (OpenCV).\n\nCuantizar solo un canal a \\(b\\in\\{2,4\\}\\) (mantener los otros en 8 bits), revertir a BGR y guardar resultados.\n\nComparar perceptualmente artefactos entre cuantizar luminancia (Y) y crominancias (Cr/Cb), y entre canales de HSV/Lab.\n\n\n\n\n\n\nInforme Latex (PDF) con:\n\nProtocolo de adquisici√≥n, metadatos y fotos de la escena.\n\nResultados de Actividades 1‚Äì3 (figuras, histogramas, tablas).\n\nTabla que resuma qu√© espacio/canal soporta mayor cuantizaci√≥n con artefactos m√≠nimos (justifique).\n\nTabla con MSE vs.¬†\\(b\\) (sin PSNR).\n\n\nCarpeta reproducible con c√≥digo e im√°genes originales (preferir PNG/TIFF).\n\n\n\n\n\nFormato: 10 minutos de presentaci√≥n + 2‚Äì3 minutos de preguntas. Puntuaci√≥n total: 100 puntos.\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPeso\nExcelente (A) (7puntos)\nBueno (B) (5puntos)\nA mejorar (C) (3puntos)\nInsuficiente (D/E) (0puntos)\n\n\n\n\nEstructura y narrativa\n15\nObjetivo, m√©todo y resultados se articulan con coherencia; introducci√≥n y cierre precisos en tiempo.\nSecuencia mayormente clara con leves transiciones d√©biles.\nOrden irregular; faltan transiciones clave.\nDesorganizada; prop√≥sito no se comprende.\n\n\nRigor t√©cnico\n25\nDefiniciones y ecuaciones (\\(L=2^{b}\\), \\(\\Delta\\), \\(\\mathrm{MSE}\\)) correctas; supuestos declarados y validados.\nMenores imprecisiones sin afectar conclusiones.\nVarias imprecisiones o supuestos no justificados.\nErrores conceptuales graves o confusi√≥n sostenida.\n\n\nMetodolog√≠a y adquisici√≥n\n15\nPar√°metros de c√°mara controlados; protocolo replicable; evidencia fotogr√°fica clara.\nControl adecuado con una omisi√≥n menor.\nControl parcial; documentaci√≥n incompleta.\nSin control de variables; documentaci√≥n escasa.\n\n\nAn√°lisis y resultados\n20\nComparaciones entre espacios (HSV/Lab/YCrCb) con figuras pertinentes; conclusiones sustentadas.\nAn√°lisis correcto pero poco profundo o con pocas figuras.\nAn√°lisis superficial; conclusiones poco justificadas.\nSin an√°lisis; afirmaciones sin evidencia.\n\n\nVisualizaci√≥n\n10\nFiguras legibles, ejes/leyendas correctas (en im√°genes generadas con OpenCV); mapas de error bien presentados.\nVisualizaci√≥n adecuada con detalles mejorables.\nGr√°ficos confusos o mal rotulados.\nVisualizaciones ausentes o incorrectas.\n\n\nGesti√≥n del tiempo\n10\nCulmina en 9‚Äì10 min; distribuye tiempo equilibradamente.\nLeve desviaci√≥n (¬±1 min).\nDesviaci√≥n moderada (¬±2 min).\nDesviaci√≥n severa (&gt;¬±2 min) o no concluye.\n\n\nClaridad y comunicaci√≥n\n5\nLenguaje t√©cnico claro, voz y ritmo adecuados, contacto visual.\nGeneralmente claro con momentos de ambig√ºedad.\nDificultades frecuentes de expresi√≥n.\nIncomprensible o lectura de diapositivas.\n\n\n\nRecomendaciones de preparaci√≥n (no evaluadas, pero sugeridas):\n- Ensayar con cron√≥metro (marcas en 3‚Äì6‚Äì9 min).\n- Limitar texto por diapositiva; priorizar comparativas claras (antes/despu√©s, por espacio y por \\(b\\)).\n- Anticipar dos preguntas t√©cnicas (supuestos y limitaciones)."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#resultados-de-aprendizaje",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#resultados-de-aprendizaje",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "Al finalizar, el estudiante ser√° capaz de:\n1. Explicar la relaci√≥n entre la profundidad de bit \\(b\\), los niveles representables \\(L=2^{b}\\) y el paso de cuantizaci√≥n \\(\\Delta\\) en una imagen digital.\n2. Adquirir y documentar im√°genes bajo condiciones controladas para analizar rango din√°mico, histogramas y artefactos de cuantizaci√≥n (banding, posterizaci√≥n).\n3. Convertir im√°genes RGB a espacios HSV, CIE L*a*b* y Y‚ÄôCrCb (formato OpenCV) e interpretar la sem√°ntica de canales e histogramas.\n4. Cuantizar im√°genes a distintas profundidades de bit y evaluar distorsi√≥n con \\(\\mathrm{MSE}\\); discutir perceptualmente los cambios.\n5. Justificar la elecci√≥n de espacio de color seg√∫n la tarea (robustez a iluminaci√≥n, segmentaci√≥n, compresi√≥n) con evidencia cualitativa y cuantitativa."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#conceptos-clave-conciso",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#conceptos-clave-conciso",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "Cuantizaci√≥n. Para una se√±al \\(x\\in[X_{\\min},X_{\\max}]\\), la cuantizaci√≥n uniforme escalar con \\(b\\) bits tiene \\(L=2^{b}\\) niveles y paso \\(\\Delta=\\dfrac{X_{\\max}-X_{\\min}}{L}\\). El error de cuantizaci√≥n \\(e=x-\\hat{x}\\in[-\\Delta/2,\\Delta/2]\\) (mid-tread).\nRango din√°mico. En \\(b\\) bits sin signo: \\([0,\\,2^{b}-1]\\) (en 8 bits: \\([0,255]\\)).\nEspacios de color (OpenCV).\n\nBGR (lectura por defecto en OpenCV).\n\nHSV: cv2.COLOR_BGR2HSV (H en [0,179] para uint8).\n\nLab: cv2.COLOR_BGR2LAB (uint8: \\(L^\\*\\in[0,255]\\), \\(a^\\*,b^\\*\\approx[0,255]\\) con 128 ‚âà neutro).\n\nYCrCb: cv2.COLOR_BGR2YCrCb (orden de cromas: Y, Cr, Cb).\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nOpenCV trabaja en BGR (no RGB) cuando lee/escribe im√°genes con cv2.imread y cv2.imwrite. Para mostrar correctamente en archivos guardados, no es necesario convertir a RGB; sin embargo, documente siempre el orden de canales."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#materiales",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#materiales",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "C√°mara de tel√©fono u ordenador. Fijar ISO, tiempo de exposici√≥n y balance de blancos. Preferir PNG/TIFF (sin p√©rdidas); si es posible, capturar RAW+JPEG.\nEscena est√°tica con colores saturados y neutros (p.¬†ej., cuadr√≠cula de color y rampa en escala de grises en un monitor). Iluminaci√≥n difusa y estable.\nPython 3.12 con: opencv-python y numpy. No use otras librer√≠as de imagen/visualizaci√≥n."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#protocolo-de-adquisici√≥n-documentar-en-el-informe",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#protocolo-de-adquisici√≥n-documentar-en-el-informe",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "Montaje de escena (iluminaci√≥n constante). Fondo neutro; evitar brillos especulares.\n\nConjunto A (referencia, 8 bits sin p√©rdidas). Guardar una imagen n√≠tida y bien expuesta en PNG/TIFF.\n\nConjunto B (bracketing de exposici√≥n). ¬±1 y ¬±2 EV respecto a la referencia para discutir recorte (clipping) vs.¬†cuantizaci√≥n.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nMantenga fijos los par√°metros de c√°mara entre capturas. Cambios en ISO o WB confunden los an√°lisis de profundidad de bit y espacio de color."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-1-exploraci√≥n-inicial-y-chequeos",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-1-exploraci√≥n-inicial-y-chequeos",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "Cargar la imagen de referencia. Inspeccionar forma, dtype, m√≠nimos/m√°ximos usando √∫nicamente OpenCV.\n\nEstimar el uso efectivo de bits contando valores distintos por canal.\nCuente cuantos pixeles hay, por cada canal y nivel del canal"
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-2-reducci√≥n-de-profundidad-de-bit-y-calidad-mse",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-2-reducci√≥n-de-profundidad-de-bit-y-calidad-mse",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "-Explique que es el error cuadr√°tico medio (MSE, por sus siglas en ingl√©s) y la relaci√≥n se√±al a rudio pico (PSNR, por sus siglas en ingl√©s), Cuantice la imagen BGR de referencia a \\(b\\in\\{1,2,\\dots,7\\}\\) bits (por canal). Para cada \\(b\\):\n\nCalcule \\(\\mathrm{MSE}\\) y \\(\\mathrm{PSNR}\\) respecto a la referencia ($b=8).\nGenere y guarde la imagen cuantizada y un mapa de error visual (colormap)."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-3-transformaciones-de-espacio-de-color-y-sem√°ntica-de-canales",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-3-transformaciones-de-espacio-de-color-y-sem√°ntica-de-canales",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "Convertir la imagen de referencia a HSV, Lab y YCrCb (OpenCV).\n\nCuantizar solo un canal a \\(b\\in\\{2,4\\}\\) (mantener los otros en 8 bits), revertir a BGR y guardar resultados.\n\nComparar perceptualmente artefactos entre cuantizar luminancia (Y) y crominancias (Cr/Cb), y entre canales de HSV/Lab."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#entregables",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#entregables",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "Informe Latex (PDF) con:\n\nProtocolo de adquisici√≥n, metadatos y fotos de la escena.\n\nResultados de Actividades 1‚Äì3 (figuras, histogramas, tablas).\n\nTabla que resuma qu√© espacio/canal soporta mayor cuantizaci√≥n con artefactos m√≠nimos (justifique).\n\nTabla con MSE vs.¬†\\(b\\) (sin PSNR).\n\n\nCarpeta reproducible con c√≥digo e im√°genes originales (preferir PNG/TIFF)."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#r√∫brica-de-evaluaci√≥n-para-exposiciones-orales-10-minutos",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#r√∫brica-de-evaluaci√≥n-para-exposiciones-orales-10-minutos",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "",
    "text": "Formato: 10 minutos de presentaci√≥n + 2‚Äì3 minutos de preguntas. Puntuaci√≥n total: 100 puntos.\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPeso\nExcelente (A) (7puntos)\nBueno (B) (5puntos)\nA mejorar (C) (3puntos)\nInsuficiente (D/E) (0puntos)\n\n\n\n\nEstructura y narrativa\n15\nObjetivo, m√©todo y resultados se articulan con coherencia; introducci√≥n y cierre precisos en tiempo.\nSecuencia mayormente clara con leves transiciones d√©biles.\nOrden irregular; faltan transiciones clave.\nDesorganizada; prop√≥sito no se comprende.\n\n\nRigor t√©cnico\n25\nDefiniciones y ecuaciones (\\(L=2^{b}\\), \\(\\Delta\\), \\(\\mathrm{MSE}\\)) correctas; supuestos declarados y validados.\nMenores imprecisiones sin afectar conclusiones.\nVarias imprecisiones o supuestos no justificados.\nErrores conceptuales graves o confusi√≥n sostenida.\n\n\nMetodolog√≠a y adquisici√≥n\n15\nPar√°metros de c√°mara controlados; protocolo replicable; evidencia fotogr√°fica clara.\nControl adecuado con una omisi√≥n menor.\nControl parcial; documentaci√≥n incompleta.\nSin control de variables; documentaci√≥n escasa.\n\n\nAn√°lisis y resultados\n20\nComparaciones entre espacios (HSV/Lab/YCrCb) con figuras pertinentes; conclusiones sustentadas.\nAn√°lisis correcto pero poco profundo o con pocas figuras.\nAn√°lisis superficial; conclusiones poco justificadas.\nSin an√°lisis; afirmaciones sin evidencia.\n\n\nVisualizaci√≥n\n10\nFiguras legibles, ejes/leyendas correctas (en im√°genes generadas con OpenCV); mapas de error bien presentados.\nVisualizaci√≥n adecuada con detalles mejorables.\nGr√°ficos confusos o mal rotulados.\nVisualizaciones ausentes o incorrectas.\n\n\nGesti√≥n del tiempo\n10\nCulmina en 9‚Äì10 min; distribuye tiempo equilibradamente.\nLeve desviaci√≥n (¬±1 min).\nDesviaci√≥n moderada (¬±2 min).\nDesviaci√≥n severa (&gt;¬±2 min) o no concluye.\n\n\nClaridad y comunicaci√≥n\n5\nLenguaje t√©cnico claro, voz y ritmo adecuados, contacto visual.\nGeneralmente claro con momentos de ambig√ºedad.\nDificultades frecuentes de expresi√≥n.\nIncomprensible o lectura de diapositivas.\n\n\n\nRecomendaciones de preparaci√≥n (no evaluadas, pero sugeridas):\n- Ensayar con cron√≥metro (marcas en 3‚Äì6‚Äì9 min).\n- Limitar texto por diapositiva; priorizar comparativas claras (antes/despu√©s, por espacio y por \\(b\\)).\n- Anticipar dos preguntas t√©cnicas (supuestos y limitaciones)."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach\n\ndef f_hat(x):\n    return 4*(x**3) - 8*x\n\ndef shift(xs, n):\n    if n &gt;= 0:\n        return np.concatenate((np.full(n, xs[0]), xs[:-n]))\n    else:\n        return np.concatenate((xs[-n:], np.full(-n, xs[-1])))\n\ndef f_hat_num(x,t):\n    delta = shift(t, -1) - t\n    salida = (shift(x, -1) - x) / np.mean(delta[:-1])\n    return np.concatenate((salida[:-1], [salida[-2]]))\n\n\ntemp = np.array([0,1,2,3,4,5,6])\nnp.concatenate([temp, [temp[-1]]])\n\narray([0, 1, 2, 3, 4, 5, 6, 6])\n\n\n\nplt.plot(t, f_hat(t))\nplt.plot(t, f_hat_num(f(t), t))"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach\n\nimport sympy as sp\n\n# Define the variable and the expression\nx1 = sp.symbols(\"x1\")\nexpr = x1**4 - 4 * x1**2 + 4\n\nresult = sp.integrate(expr, (x1, -10, 10)).evalf()\n\n# Print the LaTeX representation\nprint(sp.latex(expr))\nprint(result)\n\nx_{1}^{4} - 4 x_{1}^{2} + 4\n37413.3333333333\n\n\n\n# Define the limits of integration\na = -10\nb = 10\n\n# Define the number of subintervals\nn = 100\n\n# Calculate the width of each subinterval\nh = (b - a) / n\n\n# Initialize the sum\nsum = 0.5 * (f(a) + f(b))\n\n# Apply the Trapezoid Rule\nfor i in range(1, n):\n    sum += f(a + i * h)\n\n# Calculate the integral\nintegral = h * sum\n\nprint(\"Approximate integral:\", integral)\n\nApproximate integral: 37439.465599999996"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler‚Äôs Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)\n\n# Define the derivative function\ndef f1(x, y):\n    return 2 * x - 3 * y\n\n\n# Initial condition\nx0 = 0\ny0 = 1\n\n# Step size\nh = 0.1\n\n# Total steps\nn = int(10 / h)\n\n# Create arrays to store x and y values\nx = [0] * (n + 1)\ny = [0] * (n + 1)\n\n# Initialize x and y arrays\nx[0] = x0\ny[0] = y0\n\n# Euler's Method\nfor i in range(n):\n    x[i + 1] = x[i] + h\n    y[i + 1] = y[i] + h * f1(x[i], y[i])"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent.\n\nt1= np.linspace(-2,2,1000)\nplt.plot(t1, f(t1))\n\n\n\n\n\n\n\n\n\n# Initial guess\nx0 = 10 * (np.random.rand() - 0.5)\n\n# Learning rate\nalpha = 0.01\n\n# Number of iterations\nn_iter = 1000\n\n# Gradient Descent\nxg = x0\nfor i in range(n_iter):\n    xg = xg - alpha * f_hat(xg)\n\n# Print the minimum\nprint(\"Time of the minimum:\", xg)\nprint(\"Function value at minimum:\", f(xg))\n\nTime of the minimum: -1.4142135623730956\nFunction value at minimum: 8.881784197001252e-16"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab04_sol_ImagProc02.html",
    "href": "laboratorios/PSIM/Previous/lab04_sol_ImagProc02.html",
    "title": "Algoritmos b√°sicos de procesamiento de im√°genes",
    "section": "",
    "text": "Usando la imagen fresas.png la cual fue tomada de la p√°gina Geeks for geeks resuelva las siguientes cuestiones.\n\nAplique las siguientes transformaciones y describa el efecto de cada transformaci√≥n:\n\nTransformaci√≥n n-potencial con \\(1&lt;n&lt;2\\)\nTransformaci√≥n n-potencial con \\(0.5&lt;n&lt;1\\)\nTransformaci√≥n LOG (Logaritmo Natural)\nTransformaci√≥n exponencial\nDescriba en un diagrama de bloques el algoritmo necesario para realizar este tipo de transformaciones.\nInvestigue y desarrolle el algoritmo de la transformaci√≥n \\(\\Gamma\\). La informaci√≥n b√°sica la puede encontrar aqui\n\n\nRecuerde: Si una imagen queda completamente blanca o completamente negra, es probable que sea por mal manejo de rangos de intensidad\n\nimport pydicom as pyimag1\nimport cv2 as pyimag2\nimport matplotlib.pyplot as pyimag3\nimport numpy as pyimag4\n\nruta = \"../../data/imagen_dicom.dcm\"\n\n\ndata_imagen = pyimag1.dcmread(ruta)\nimage = data_imagen.pixel_array\npyimag3.imshow(image, cmap=\"gray\")\npyimag3.axis(\"off\")\n\npatient_name= data_imagen.PatientID\nprint(f\"Nombre del paciente: {patient_name}\")\n\nNombre del paciente: 239\n\n\n\n\n\n\n\n\n\n\nSea los siguientes kernels de convoluci√≥n:\n\n\\(\\begin{bmatrix}\n1 & 1 & 1 \\\\\n1 & -8 & 1 \\\\\n1 & 1 & 1\n\\end{bmatrix}\\)\n\\(\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n-1 & 8 & -1 \\\\\n-1 & -1 & -1\n\\end{bmatrix}\\)\n\n\nExplique las siguientes cuestiones:\n\nInvestigue las formas de realizar la convoluci√≥n con opencv.\nAplique cada uno de los kernels de convoluci√≥n y compare los resultados.\nExplique cuales son las respectivas resoluci√≥nes de pixel de las imagenes resultantes as√≠ como su m√°ximo y su m√≠nimo.\n\n\nkernel1 = (1 / 9) * pyimag4.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\nkernel2 = pyimag4.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\nconv1 = pyimag2.filter2D(image, ddepth=-1, kernel=kernel1)\nconv1_normalized = pyimag2.normalize(conv1, None, 0, 255, pyimag2.NORM_MINMAX)\nconv2 = pyimag2.filter2D(image, ddepth=-1, kernel=kernel2)\nconv2_normalized = pyimag2.normalize(conv2, None, 0, 255, pyimag2.NORM_MINMAX)\npyimag3.imshow(pyimag4.concatenate(\n    (conv1_normalized, conv2_normalized), \n    axis=1), \n    cmap=\"gray\")\npyimag3.axis(\"off\")\n\n\n\n\n\n\n\n\n\nrows, cols = image.shape\nangle = 45\nM = pyimag2.getRotationMatrix2D((cols//2, rows//2), angle, 1)\ntransformed_image = pyimag2.warpAffine(image, M, (cols, rows))\npyimag3.imshow(transformed_image, cmap=\"gray\")\npyimag3.axis(\"off\")\n\n\n\n\n\n\n\n\n\nUtilizando la imagen radiograf√≠a, aplique cada tipo de matriz afine presente en las diapositivas de clase\nDeterminar proyecto final para PSIM.\n\nDeterminar el problema a resolver.\nDeterminar el objetivo a alcanzar\nDeterminar el dataset\n\n\nRecuerde, en su proyecto final, NO podr√° hacer uso de algoritmos de machine learning."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/Proyecto_Final_2024-2.html",
    "href": "laboratorios/PSIM/Previous/Proyecto_Final_2024-2.html",
    "title": "Proyecto Final: PSIM 2024-1",
    "section": "",
    "text": "Horarios de Sustentaci√≥n\n\n\nMonitor√≠a del Curso\nKevin Mart√≠nez\n\n\nR√∫brica\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (100%)\nBueno (80%)\nRegular (60%)\nInsuficiente (40%)\nNo presentado (0%)\n\n\n\n\nUso de t√©cnicas de procesamiento de im√°genes o se√±ales\nDemuestra un dominio profundo y una aplicaci√≥n adecuada de t√©cnicas de procesamiento de im√°genes o se√±ales para lograr los objetivos del proyecto.\nDemuestra una comprensi√≥n s√≥lida y una aplicaci√≥n adecuada de t√©cnicas de procesamiento de im√°genes o se√±ales para lograr los objetivos del proyecto.\nDemuestra una comprensi√≥n b√°sica y una aplicaci√≥n limitada de t√©cnicas de procesamiento de im√°genes o se√±ales para lograr los objetivos del proyecto.\nDemuestra una comprensi√≥n deficiente y una aplicaci√≥n inadecuada de t√©cnicas de procesamiento de im√°genes o se√±ales para lograr los objetivos del proyecto.\nNo se evidencia la aplicaci√≥n de t√©cnicas de procesamiento de im√°genes o se√±ales.\n\n\nCoherencia entre objetivos y resultados\nLos objetivos del proyecto est√°n claramente definidos y alineados con los resultados obtenidos.\nLos objetivos del proyecto est√°n definidos y alineados en gran medida con los resultados obtenidos.\nLos objetivos del proyecto est√°n definidos, pero no se alinean completamente con los resultados obtenidos.\nLos objetivos del proyecto est√°n poco definidos y no se alinean con los resultados obtenidos.\nNo se definen objetivos para el proyecto.\n\n\nTiempo de exposici√≥n\nLa exposici√≥n del proyecto es clara, concisa y organizada, permitiendo una comprensi√≥n completa del trabajo realizado.\nLa exposici√≥n del proyecto es clara y organizada, permitiendo una buena comprensi√≥n del trabajo realizado.\nLa exposici√≥n del proyecto es clara, pero con algunas deficiencias en la organizaci√≥n, lo que dificulta la comprensi√≥n completa del trabajo realizado.\nLa exposici√≥n del proyecto es poco clara y desorganizada, lo que dificulta la comprensi√≥n del trabajo realizado.\nNo se realiza una exposici√≥n del proyecto.\n\n\nPresentaci√≥n\nLa presentaci√≥n del proyecto es visualmente atractiva, profesional y utiliza recursos multimedia de manera efectiva para comunicar los resultados.\nLa presentaci√≥n del proyecto es visualmente atractiva y profesional, utilizando algunos recursos multimedia para comunicar los resultados.\nLa presentaci√≥n del proyecto es visualmente aceptable, pero con algunos errores o falta de recursos multimedia para comunicar los resultados.\nLa presentaci√≥n del proyecto es poco visualmente atractiva, con errores y falta de recursos multimedia para comunicar los resultados.\nNo se realiza una presentaci√≥n del proyecto.\n\n\nNivel de la codificaci√≥n\nEl c√≥digo est√° bien escrito, documentado, organizado y utiliza las mejores pr√°cticas de programaci√≥n.\nEl c√≥digo est√° bien escrito, documentado y organizado.\nEl c√≥digo est√° escrito, pero con algunas deficiencias en la documentaci√≥n y organizaci√≥n.\nEl c√≥digo est√° escrito de manera deficiente, con mala documentaci√≥n y organizaci√≥n.\nEl c√≥digo no est√° escrito o est√° escrito de manera no funcional.\n\n\nCreatividad en el algoritmo\nEl algoritmo utilizado en el proyecto es novedoso, original y efectivo para resolver el problema planteado.\nEl algoritmo utilizado en el proyecto es creativo, original y efectivo para resolver el problema planteado.\nEl algoritmo utilizado en el proyecto es creativo, pero con algunas limitaciones en su originalidad o efectividad.\nEl algoritmo utilizado en el proyecto es poco creativo, con limitaciones en su originalidad y efectividad.\nEl algoritmo utilizado en el proyecto no es creativo ni efectivo para resolver el problema planteado.\n\n\nTrabajo en equipo\nSe evidencia un trabajo en equipo efectivo, con una clara divisi√≥n de roles, comunicaci√≥n constante y colaboraci√≥n entre los miembros del equipo.\nSe evidencia un trabajo en equipo colaborativo, con una clara divisi√≥n de roles y comunicaci√≥n entre los miembros del equipo.\nSe evidencia un trabajo en equipo con algunas dificultades en la colaboraci√≥n o comunicaci√≥n entre los miembros del equipo.\nSe evidencia un trabajo en equipo deficiente, con falta de colaboraci√≥n y comunicaci√≥n entre los miembros del equipo.\nNo se evidencia un trabajo en equipo.\n\n\nTrabajo individual\nCada miembro del equipo demuestra un alto nivel de compromiso, responsabilidad y contribuci√≥n individual al proyecto.\nCada miembro del equipo demuestra un buen nivel de compromiso, responsabilidad y contribuci√≥n individual al proyecto.\nCada miembro del equipo demuestra un nivel aceptable de compromiso, responsabilidad y contribuci√≥n individual al proyecto.\nCada miembro del equipo demuestra un bajo nivel de compromiso, responsabilidad y contribuci√≥n individual al proyecto.\nNo se evidencia el trabajo individual de los miembros del equipo."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "",
    "text": "Prop√≥sito: formular 2‚Äì3 objetivos SMART para el proyecto final de la asignatura, alineados con ODS 3: Salud y bienestar (y secundarios ODS 9/10/11 si aplica) y con necesidades de salud p√∫blica en Colombia.\nRestricci√≥n metodol√≥gica (obligatoria): evitar machine learning general. √önicos algoritmos de decisi√≥n permitidos: K‚Äëmeans, regresi√≥n lineal m√∫ltiple y regresi√≥n log√≠stica m√∫ltiple. Prohibidos: redes neuronales, SVM, √°rboles/ensembles, m√©todos bayesianos avanzados, etc."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#resultados-de-aprendizaje",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#resultados-de-aprendizaje",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "Resultados de aprendizaje",
    "text": "Resultados de aprendizaje\nAl finalizar, cada equipo:\n\nConecta un problema cl√≠nico-prioritario en Colombia con al menos un objetivo ODS y una meta/indicador verificable.\nRedacta 2‚Äì3 objetivos SMART (impacto cl√≠nico, t√©cnico, implementaci√≥n) con m√©tricas y umbrales.\nDefine fuentes de datos (abiertos o locales con cumplimiento √©tico) y un plan de validaci√≥n reproducible.\nDescribe riesgos de sesgo/√©tica y medidas de mitigaci√≥n acordes con normativa colombiana de protecci√≥n de datos."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#opciones-de-reto-elige-uno",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#opciones-de-reto-elige-uno",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "Opciones de reto (elige uno)",
    "text": "Opciones de reto (elige uno)\nLas siguientes opciones se enfocan en tareas de detecci√≥n, medici√≥n o soporte a decisi√≥n usando √∫nicamente K‚Äëmeans y/o regresi√≥n m√∫ltiple.\n\n1) Tuberculosis en radiograf√≠a de t√≥rax (soporte a triage)\n\nTarea: puntaje de riesgo por paciente a partir de descriptores de imagen cl√°sicos (textura, intensidades, morfolog√≠a).\nAlgoritmos permitidos: segmentaci√≥n de regiones sospechosas (heur√≠stica), K‚Äëmeans para agrupar patrones de textura, regresi√≥n log√≠stica m√∫ltiple para estimar probabilidad de TB.\nM√©trica primaria: sensibilidad y especificidad; curva ROC/AUC para el modelo log√≠stico; tiempo de lectura por estudio.\n\n\n\n2) Retinopat√≠a diab√©tica (fondo de ojo)\n\nTarea: detecci√≥n de lesiones (exudados, microaneurismas) mediante filtros cl√°sicos; conteos y √°reas como predictores.\nAlgoritmos: K‚Äëmeans sobre espacios de color; regresi√≥n log√≠stica m√∫ltiple para riesgo de RD referible.\nM√©trica primaria: F1 para lesi√≥n referible; exactitud por estratos de calidad de imagen.\n\n\n\n3) Ultrasonido obst√©trico (biometr√≠a cef√°lica)\n\nTarea: estimar circunferencia cef√°lica (HC) con ajuste geom√©trico; usar regresi√≥n lineal m√∫ltiple para corregir sesgos por √°ngulo/ganancia.\nM√©trica primaria: error absoluto medio (MAE) en mm frente a anotador experto.\n\n\n\n4) Lesiones cut√°neas (dermatoscopia/imagen macro)\n\nTarea: segmentaci√≥n cl√°sica de la lesi√≥n; extracci√≥n de color/forma/asimetr√≠a; regresi√≥n log√≠stica m√∫ltiple para riesgo de malignidad (prototipo educativo, no cl√≠nico).\nM√©trica primaria: AUC; an√°lisis de errores por fototipo.\n\n\n\n5) Extracci√≥n de signos vitales con c√°mara web (rPPG) sin ML\n\nObjetivo: estimar frecuencia cardiaca (FC) y frecuencia respiratoria (FR) desde video RGB facial capturado con webcam est√°ndar (‚â• 30 fps) sin redes neuronales.\nPipeline sugerido: detecci√≥n de rostro (cl√°sica), definici√≥n de ROI (frente/p√≥mulos), promediado espacial por canal, detrend y banda pasante; c√°lculo espectral.\nC√°lculos:\n\nSe√±al rPPG por canal: \\(s_c(t) = \\frac{1}{|\\Omega|}\\sum_{(i,j)\\in \\Omega} I_c(i,j,t)\\).\nPreamplificaci√≥n crom√°tica tipo POS/CHROM (implementaci√≥n determinista sin entrenamiento).\nHR (bpm) desde pico espectral: \\(\\mathrm{HR} = 60, f_{\\text{peak}}\\).\nSNR: \\(\\mathrm{SNR} = 10\\log_{10}\\left( \\frac{P\\{\\text{se√±al}}\\}{P\\{\\text{ruido}}\\} \\right)\\).\n\nAlgoritmos de decisi√≥n permitidos:\n\nK‚Äëmeans para estabilidad de ROI (agrupar p√≠xeles por coherencia temporal) o clusterizar condiciones de iluminaci√≥n.\nRegresi√≥n lineal m√∫ltiple para correcci√≥n de artefactos (p.¬†ej., modelar FC estimada como funci√≥n de variables de captura: luminancia media, varianza, amplitud de movimiento): \\(\\widehat{\\mathrm{FC}} = \\beta_0 + \\sum_{j=1}^p \\beta_j x_j\\).\nRegresi√≥n log√≠stica m√∫ltiple para calidad binaria del segmento (v√°lido/no v√°lido) a partir de predictores como SNR, varianza, energ√≠a de banda: \\(\\Pr(\\text{v√°lido}=1\\mid x)=\\sigma!\\left( \\beta_0 + \\sum_{j=1}^p \\beta_j x_j \\right),\\ \\ \\sigma(z)=\\frac{1}{1+e^{-z}}\\).\n\nM√©tricas: MAE de FC (bpm), MAE de FR (rpm), proporci√≥n de segmentos v√°lidos, latencia."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#recordatorio-de-ecuaciones-uso-en-los-tres-algoritmos-permitidos",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#recordatorio-de-ecuaciones-uso-en-los-tres-algoritmos-permitidos",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "Recordatorio de ecuaciones (uso en los tres algoritmos permitidos)",
    "text": "Recordatorio de ecuaciones (uso en los tres algoritmos permitidos)\nK‚Äëmeans (criterio WCSS): minimizar\n\\(J = \\sum_{i=1}^k \\sum_{x\\in C_i} \\lVert x - \\mu_i \\rVert^2\\).\nRegresi√≥n lineal m√∫ltiple:\n\\(\\hat{y} = \\beta_0 + \\sum_{j=1}^p \\beta_j x_j\\), con ajuste por m√≠nimos cuadrados: \\(\\min_\\beta \\lVert y - X\\beta \\rVert_2^2\\).\nRegresi√≥n log√≠stica m√∫ltiple:\n\\(\\Pr(Y=1\\mid x) = \\sigma!\\left( \\beta_0 + \\sum_{j=1}^p \\beta_j x_j \\right)\\), donde \\(\\sigma(z)=\\frac{1}{1+e^{-z}}\\)."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#plantilla-lienzo-de-objetivos-1-p√°gina",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#plantilla-lienzo-de-objetivos-1-p√°gina",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "Plantilla: Lienzo de Objetivos (1 p√°gina)",
    "text": "Plantilla: Lienzo de Objetivos (1 p√°gina)\nComplete y entregue una p√°gina por equipo. En la plantilla del curso\n\nT√≠tulo del proyecto:\nODS principal (meta/indicador):\nODS secundario (opcional):\nProblema en Colombia (fuente breve):\nPoblaci√≥n objetivo y escenario de uso:\nModalidad de imagen y tarea:\nDatos/datasets (licencia y tama√±o):\nObjetivo SMART 1 (impacto):\nObjetivo SMART 2 (t√©cnico):\nObjetivo SMART 3 (implementaci√≥n):\nM√©trica(s) primaria(s) y umbrales:\nRiesgos/sesgos y cumplimiento (privacidad y √©tica):\nPlan de validaci√≥n:\nHitos/tiempos:"
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#ejemplos-de-objetivos-smart-adaptar-al-caso",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#ejemplos-de-objetivos-smart-adaptar-al-caso",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "Ejemplos de objetivos SMART (adaptar al caso)",
    "text": "Ejemplos de objetivos SMART (adaptar al caso)\n\nImpacto cl√≠nico (ODS 3): ‚ÄúEn 10 semanas, demostrar en n=40 participantes que el prototipo de rPPG logra MAE(FC) ‚â§ 5 bpm frente a pulsiox√≠metro de referencia, en condiciones de luz ambiental de consultorio.‚Äù\nT√©cnico‚Äëalgor√≠tmico: ‚ÄúImplementar pipeline determinista de rPPG con banda 0.7‚Äì4 Hz para FC y 0.1‚Äì0.5 Hz para FR; usar K‚Äëmeans para seleccionar ROI estable y regresi√≥n lineal m√∫ltiple para correcci√≥n por iluminaci√≥n; alcanzar proporci√≥n de segmentos v√°lidos ‚â• 0.9.‚Äù\nImplementaci√≥n/uso responsable: ‚ÄúEntregar una app on‚Äëdevice que procese 60 s de video en ‚â§ 3 s y exporte solo series temporales y m√©tricas (sin video). Incluir aviso y consentimiento informado.‚Äù\n\n\nPara otras opciones de reto, formule un objetivo an√°logo con m√©trica primaria clara (p.¬†ej., AUC ‚â• 0.85 para log√≠stica m√∫ltiple o MAE ‚â§ umbral en lineal m√∫ltiple) y justificativo ODS."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#sugerencias-de-m√©tricas-y-validaci√≥n",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#sugerencias-de-m√©tricas-y-validaci√≥n",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "Sugerencias de m√©tricas y validaci√≥n",
    "text": "Sugerencias de m√©tricas y validaci√≥n\n\nClasificaci√≥n (log√≠stica m√∫ltiple): AUC, sensibilidad, especificidad, F1, calibraci√≥n (revisar curva de confiabilidad).\nRegresi√≥n (lineal m√∫ltiple): MAE, RMSE, \\(R^2\\), an√°lisis de residuos.\nClustering (K‚Äëmeans): inercia (WCSS), silhouette (solo para diagn√≥stico; no usar como criterio de decisi√≥n cl√≠nica).\nValidaci√≥n: partici√≥n entrenamiento/validaci√≥n, estratificaci√≥n por subgrupos (edad/sexo/calidad de imagen), IC por bootstrap si el tama√±o lo permite."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#riesgos-y-mitigaciones-√©tica-y-sesgo",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#riesgos-y-mitigaciones-√©tica-y-sesgo",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "Riesgos y mitigaciones (√©tica y sesgo)",
    "text": "Riesgos y mitigaciones (√©tica y sesgo)\n\nPrivacidad: evitar almacenar datos identificables; anonimizar; limitar finalidades; consentimiento informado cuando aplique.\nSesgo de dominio: evaluar por dispositivo, iluminaci√≥n, fototipo, instituci√≥n; reportar desempe√±o estratificado.\nSeguridad: indicar que los prototipos son con fines educativos y no cl√≠nicos."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#entregables-de-la-sesi√≥n",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#entregables-de-la-sesi√≥n",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "Entregables de la sesi√≥n",
    "text": "Entregables de la sesi√≥n\n\nLienzo de Objetivos (1 p√°gina) completado.\nPitch de 60 s leyendo objetivo principal y m√©trica clave.\nArchivo breve (m√°x. 1 p√°gina) con las ecuaciones que usa su proyecto (de entre las listadas) y la m√©trica primaria con definici√≥n formal."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#r√∫brica-de-evaluaci√≥n-actividad-de-hoy",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#r√∫brica-de-evaluaci√≥n-actividad-de-hoy",
    "title": "Objetivos de Proyecto Final en Procesamiento de Im√°genes Biom√©dicas (ODS‚ÄìColombia)",
    "section": "R√∫brica de evaluaci√≥n (actividad de hoy)",
    "text": "R√∫brica de evaluaci√≥n (actividad de hoy)\nPuntaje total: 100. Aprobaci√≥n sugerida: ‚â• 70 y sin criterios en nivel Insuficiente.\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPeso\nExcelente (4)\nBueno (3)\nB√°sico (2)\nInsuficiente (1)\n\n\n\n\nAlineaci√≥n con ODS\n20\nODS principal correcto y meta/indicador expl√≠cito y pertinente\nODS correcto sin indicador concreto\nODS gen√©rico\nSin ODS o incorrecto\n\n\nRelevancia pa√≠s/poblaci√≥n\n15\nContexto Colombia claro (poblaci√≥n, nivel de atenci√≥n, brecha)\nContexto parcial\nContexto vago\nSin contexto\n\n\nCalidad de objetivos SMART\n20\n2‚Äì3 objetivos con m√©tricas, umbrales y tiempos; separados en impacto/t√©cnico/implementaci√≥n\nObjetivos claros pero incompletos\nFaltan m√©tricas o tiempos\nConfusos o no medibles\n\n\nViabilidad t√©cnica (solo K‚Äëmeans / reg. m√∫ltiple)\n15\nElecci√≥n y justificaci√≥n rigurosa; ecuaciones y variables definidas\nElecci√≥n adecuada con ligeras lagunas\nUso dudoso o variables mal definidas\nIncumple restricciones o inviable\n\n\n√âtica y cumplimiento\n10\nRiesgos/sesgos y medidas; privacidad correctamente abordada\nMenciona √©tica sin detalle\nSuperficial\nNo aborda\n\n\nM√©tricas de √©xito\n10\nIndicadores cl√≠nicos/operativos claros y umbrales\nIndicadores presentes sin umbrales\nIndicadores vagos\nNo hay\n\n\nClaridad de la entrega (1 p√°g + pitch)\n10\nS√≠ntesis excelente, visual limpio, pitch preciso\nClaro con leves omisiones\nDenso o poco legible\nIncompleto"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "El procesamiento de se√±ales de origen fisiol√≥gico ‚Äîcomo las provenientes de sistemas cardiovasculares, neuromusculares o musculoesquel√©ticos‚Äî constituye un √°rea clave dentro de la ingenier√≠a biom√©dica y las ciencias de la salud. Su correcta interpretaci√≥n requiere no solo conocimientos t√©cnicos avanzados, sino tambi√©n una capacidad cr√≠tica para integrar informaci√≥n multidisciplinar.\nLos objetivos de esta actividad son:\n\nAnalizar y comparar diferentes enfoques te√≥ricos sobre el procesamiento de se√±ales fisiol√≥gicas (ECG, EMG, PPG, etc.).\nEvaluar la calidad y rigurosidad t√©cnica de fuentes bibliogr√°ficas cient√≠ficas.\nFomentar el pensamiento cr√≠tico y la capacidad de s√≠ntesis de los estudiantes.\nDesarrollar habilidades de lectura t√©cnica y argumentaci√≥n cient√≠fica en contextos biom√©dicos.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al.¬†A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al.¬†Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7\nM. A. Mart√≠nez Gonz√°lez, A. S√°nchez-Villegas, E. A. Toledo Atucha, y J. Faulin Fajardo, Bioestad√≠stica amigable, Third. Madrid, Espa√±a: Elsevier, 2020."
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#duraci√≥n",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#duraci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#materiales",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#materiales",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al.¬†A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al.¬†Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7\nM. A. Mart√≠nez Gonz√°lez, A. S√°nchez-Villegas, E. A. Toledo Atucha, y J. Faulin Fajardo, Bioestad√≠stica amigable, Third. Madrid, Espa√±a: Elsevier, 2020."
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-1-carga-y-visualizaci√≥n-entrega-22-de-abril-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-1-carga-y-visualizaci√≥n-entrega-22-de-abril-de-2025",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Fase 1 ‚Äì Carga y visualizaci√≥n (Entrega: 22 de abril de 2025)",
    "text": "Fase 1 ‚Äì Carga y visualizaci√≥n (Entrega: 22 de abril de 2025)\n\nCargar una se√±al electrocardiogr√°fica aleatoria del dataset.\nVisualizar la se√±al cruda.\nIdentificar ruido de l√≠nea base y artefactos. Explique que tipos de artefactos pueden aparecen en esta se√±al. Haga uso de diferentes art√≠culos de naturaleza acad√©mica, por su puesto referencielos."
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-2-preprocesamiento-entrega-6-de-mayo-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-2-preprocesamiento-entrega-6-de-mayo-de-2025",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Fase 2 ‚Äì Preprocesamiento (Entrega 6 de mayo de 2025)",
    "text": "Fase 2 ‚Äì Preprocesamiento (Entrega 6 de mayo de 2025)\n\nRealice un Filtrado paso banda (0.5‚Äì40 Hz). Porque se utiliza este rango de frecuencia? Se aplica un filtro FIR o IIR, porque?\nAplicar una normalizaci√≥n de escala a la se√±al. ¬øPor qu√©\nAplicar un corte de ruido de l√≠nea base a la se√±al. ¬øQue t√©cnicas existen para tal fin?\nAplicar un corte de artefactos a la se√±al. ¬øQu√© t√©cnicas existen para tal fin?"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-3-detecci√≥n-de-picos-r-y-segmentaci√≥n-entrega-semana-del-19-de-mayo-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-3-detecci√≥n-de-picos-r-y-segmentaci√≥n-entrega-semana-del-19-de-mayo-de-2025",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Fase 3 ‚Äì Detecci√≥n de picos R y segmentaci√≥n (Entrega Semana del 19 de mayo de 2025)",
    "text": "Fase 3 ‚Äì Detecci√≥n de picos R y segmentaci√≥n (Entrega Semana del 19 de mayo de 2025)\n\nRealice una detecci√≥n de picos R utilizando un algoritmo espec√≠fico. ¬øQu√© algoritmo se ha utilizado? ¬øPor qu√©? ¬øQu√© ventajas y desventajas tiene? Que tecnicas matematicas se han utilizado para el algoritmo?\nCalcular intervalos RR y frecuencia card√≠aca instant√°nea. Que es una frecuencia card√≠aca instant√°nea? ¬øPor qu√© es importante?\nSegmentar la se√±al en intervalos de tiempo correspondientes a cada complejo QRS. ¬øQue t√©cnica utiliz√≥ y cual es la base matem√°tica en la que se bas√≥?"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-4-extracci√≥n-de-caracter√≠sticas-entrega-semana-del-19-de-mayo-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-4-extracci√≥n-de-caracter√≠sticas-entrega-semana-del-19-de-mayo-de-2025",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Fase 4 ‚Äì Extracci√≥n de caracter√≠sticas (Entrega Semana del 19 de mayo de 2025)",
    "text": "Fase 4 ‚Äì Extracci√≥n de caracter√≠sticas (Entrega Semana del 19 de mayo de 2025)\n\nPara cada sujeto del conjunto de datos, calcule las siguientes caracter√≠sticas:\n\nFrecuencia card√≠aca promedio.\nFrecuencia card√≠aca m√°xima.\nFrecuencia card√≠aca m√≠nima.\nIntervalo RR promedio.\nIntervalo RR m√°ximo.\nIntervalo RR m√≠nimo.\nCoeficiente de variaci√≥n de la frecuencia card√≠aca.\nN√∫mero de latidos\n\nExisten otras caracter√≠sticas que se pueden calcular, ¬øcu√°les son? Referencie al menos 3 art√≠culos de naturaleza acad√©mica.\nForme una tabla con las caracter√≠sticas calculadas para cada sujeto. Cada fila corresponde a un sujeto y cada columna corresponde a una caracter√≠stica.\nDetermine si cada caracter√≠stica es param√©trica o no. Se recomienda utilizar t√©cnicas estad√≠sticas para determinar si una caracter√≠stica es param√©trica o no.\nCon la informaci√≥n de parametricidad de la variable, determine si esta tiene diferencias estad√≠sticamente para las personas con arritmias y las personas sin arritmias.\nUtilizando un algoritmo de regresi√≥n log√≠stica, plantee un __modelo estad√≠stico de clasificaci√≥__n.¬†¬øQu√© es una regresi√≥n log√≠stica? ¬øComo se puede calcular? Que es un modelo estad√≠stico de clasificaci√≥n?"
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 4, 2025. The defense will be carried out by one of the team members chosen at random.\nThe python libraries allow for this laboratory are: matplotlib and random"
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 1: Mean and Median",
    "text": "Exercise 1: Mean and Median\nWrite a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g.¬†normal, binomial)."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes‚Äô Theorem",
    "text": "Exercise 6: Bayes‚Äô Theorem\nWrite a Python program that applies Bayes‚Äô theorem to update the probability of a hypothesis given new evidence."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g.¬†normal, uniform)."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10:Function visualization - I",
    "text": "Exercise 10:Function visualization - I\nGenerate a python code that allows the visualization (in one figure) of the real (blue) part and the imaginary (red) part, magnitude (green) and phase of the following signals:\n\\[f\\left(t\\right) = e^{-j10 \\pi t}\\]\n\\[g\\left(t\\right) = 10cos\\left(2 \\pi t\\right) + j10sin\\left(2 \\pi t\\right)\\]\nThe visualization mus be in the range \\(\\left[-10, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/ASIM/lab002_CNN.html",
    "href": "laboratorios/ASIM/lab002_CNN.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torchvision\n\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader\n\nimport torch.nn as nn\n\nfrom torch import utils\nfrom torch import optim\nfrom torch import device\nfrom torch import inference_mode\n\nimport tqdm\n\nfrom timeit import default_timer as timer\nfrom tqdm.auto import tqdm\n\nfrom torchmetrics import ConfusionMatrix\nimport mlxtend\nfrom mlxtend.plotting import plot_confusion_matrix\nimport numpy\nfrom torchvision.transforms.v2 import (\n    ConvertImageDtype,\n    Normalize,\n    Resize,\n    CenterCrop,\n    ToTensor,\n    ToImage,\n    Compose\n)\n\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0\n\n\n\ntransformacion = Compose([\n    ToTensor(), \n    Normalize(mean=[0.5], std=[0.5])\n    ])\n\n/home/pablo/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n\n\n\ndata_flag = \"pathmnist\"\ninfo = INFO[data_flag]\nDataClass = getattr(medmnist, info[\"python_class\"])\n\n# Load the training and testing datasets\ntrain_data = DataClass(split=\"train\", transform=transformacion, download=True)\nval_data = DataClass(split=\"val\", transform=transformacion, download=True)\ntest_data = DataClass(split=\"test\", transform=transformacion, download=True)\n\nDownloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /home/pablo/.medmnist/pathmnist.npz\n\n\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 205615438/205615438 [00:20&lt;00:00, 10059790.46it/s]\n\n\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\n\n\n\n# check data properties\nimg = train_data[0][0]\nlabel = train_data[0][1]\n\nprint(f\"Image:\\n {img}\")\nprint(f\"Label:\\n {label}\")\n\nprint(f\"Image shape: {img.shape}\")\nprint(f\"Label: {label}\")\n\nImage:\n tensor([[[0.7255, 0.7176, 0.7255,  ..., 0.7255, 0.7176, 0.7333],\n         [0.7098, 0.7255, 0.7176,  ..., 0.5451, 0.5059, 0.4902],\n         [0.7255, 0.7255, 0.7176,  ..., 0.6314, 0.6235, 0.6392],\n         ...,\n         [0.7098, 0.7020, 0.7333,  ..., 0.7333, 0.7255, 0.7333],\n         [0.6706, 0.7020, 0.7333,  ..., 0.7333, 0.7333, 0.7333],\n         [0.6863, 0.7255, 0.7333,  ..., 0.7255, 0.7333, 0.7412]],\n\n        [[0.6314, 0.6235, 0.6235,  ..., 0.6314, 0.6235, 0.6314],\n         [0.6157, 0.6235, 0.6157,  ..., 0.3882, 0.3490, 0.3176],\n         [0.6314, 0.6235, 0.6078,  ..., 0.4980, 0.5059, 0.5216],\n         ...,\n         [0.6078, 0.5765, 0.6314,  ..., 0.6314, 0.6314, 0.6392],\n         [0.5059, 0.5686, 0.6314,  ..., 0.6314, 0.6392, 0.6314],\n         [0.5294, 0.6235, 0.6314,  ..., 0.6314, 0.6314, 0.6392]],\n\n        [[0.7804, 0.7804, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7725, 0.7725, 0.7725,  ..., 0.5843, 0.5451, 0.5294],\n         [0.7725, 0.7725, 0.7647,  ..., 0.6706, 0.6706, 0.6941],\n         ...,\n         [0.7647, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7098, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7255, 0.7725, 0.7804,  ..., 0.7804, 0.7804, 0.7882]]])\nLabel:\n [0]\nImage shape: torch.Size([3, 28, 28])\nLabel: [0]\n\n\n\n# Number of image channels\nn_channels = info[\"n_channels\"]\nprint(f\"number of channels: {n_channels}\")\n\n# Number of classes\nn_classes = len(info[\"label\"])\nprint(f\"number of classes: {n_classes}\")\n\n# Get the class names from the dataset\nclass_names = info[\"label\"]\nprint(f\"class names: {class_names}\")\n\nnumber of channels: 3\nnumber of classes: 9\nclass names: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n\n\n\nfor i in range(3):\n    img = train_data[i][0]\n    label = train_data[i][1]\n    plt.figure(figsize=(3, 3))\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(label)\n    plt.axis(False)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.6313726..0.84313726].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.372549..0.85882354].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# change data into dataloader form\nBATCH_SIZE = 128\ntrain_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n\n\n# check dataloader\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")\n\nDataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53cd0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53490&gt;)\nLength of train dataloader: 704 batches of 128\nLength of test dataloader: 57 batches of 128\nLength of val dataloader: 79 batches of 128\n\n\n\n# define training loop functions\ndef train_step(\n    model: torch.nn.Module,\n    data_loader: torch.utils.data.DataLoader,\n    loss_fn: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    train_loss, train_acc = 0, 0\n    model.to(device)\n\n    for batch, (X, y) in enumerate(data_loader):\n        # need to change target shape for this medmnist data\n        y = y.squeeze().long()\n\n        # Send data to selected device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. loss and accuracy\n        loss = loss_fn(y_pred, y)\n        train_loss += loss\n        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n    # Calculate loss and accuracy per epoch\n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n\n    return train_loss, train_acc\n\n\ndef test_step(\n    data_loader: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    test_loss, test_acc = 0, 0\n    model.to(device)\n\n    model.eval()  # eval mode for testing\n    with torch.inference_mode():  # Inference context manager\n        for X, y in data_loader:\n            # need to change target shape for this medmnist data\n            y = y.squeeze().long()\n\n            # Send data to selected device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred = model(X)\n\n            # 2. Calculate loss and accuracy\n            test_loss += loss_fn(test_pred, y)\n            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n\n        # Adjust metrics and print out\n        test_loss /= len(data_loader)\n        test_acc /= len(data_loader)\n\n        return test_loss, test_acc\n\n\ndef eval_func(\n    data_loader: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    eval_loss, eval_acc = 0, 0\n    model.to(device)\n\n    model.eval()\n    y_preds = []\n    y_targets = []\n    with torch.inference_mode():\n        for batch, (X, y) in tqdm(enumerate(data_loader)):\n            # need to change target shape for this medmnist data\n            y = y.squeeze().long()\n\n            # Send data to selected device\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass\n            eval_pred = model(X)\n\n            # Find loss and accuracy\n            eval_loss += loss_fn(eval_pred, y)\n            eval_acc += accuracy_fn(y_true=y, y_pred=eval_pred.argmax(dim=1))\n\n            # Add prediction and target labels to list\n            eval_labels = torch.argmax(torch.softmax(eval_pred, dim=1), dim=1)\n            y_preds.append(eval_labels)\n            y_targets.append(y)\n\n        # Scale loss and acc\n        eval_loss /= len(data_loader)\n        eval_acc /= len(data_loader)\n\n        # Put predictions on CPU for evaluation\n        y_preds = torch.cat(y_preds).cpu()\n        y_targets = torch.cat(y_targets).cpu()\n\n        return {\n            \"model_name\": model.__class__.__name__,\n            \"loss\": eval_loss.item(),\n            \"accuracy\": eval_acc,\n            \"predictions\": y_preds,\n            \"targets\": y_targets,\n        }\n\n\ndef print_train_time(start: float, end: float, device: torch.device = None):\n    total_time = end - start\n    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n    return total_time\n\n\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct / len(y_pred)) * 100\n    return acc\n\n\nclass cnn(torch.nn.Module):\n    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n        super().__init__()\n\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=input_shape, out_channels=hidden_units, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n        )\n\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units, out_channels=hidden_units, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units, out_channels=hidden_units * 4, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n        )\n\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units * 4,\n                out_channels=hidden_units * 4,\n                kernel_size=3,\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n        )\n\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units * 4,\n                out_channels=hidden_units * 4,\n                kernel_size=3,\n                padding=1,\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_units * 4 * 4 * 4, hidden_units * 8),\n            nn.ReLU(),\n            nn.Linear(hidden_units * 8, hidden_units * 8),\n            nn.ReLU(),\n            nn.Linear(hidden_units * 8, n_classes),\n        )\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\n# Define Model\nmodel = cnn(input_shape=n_channels, hidden_units=16, output_shape=n_classes).to(device)\n\n\n# Setup loss and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# View Model\nmodel\n\ncnn(\n  (layer1): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer2): Sequential(\n    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (layer3): Sequential(\n    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer4): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer5): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=1024, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=128, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=128, out_features=9, bias=True)\n  )\n)\n\n\n\ntorch.manual_seed(42)\n\n# Measure Time\n\ntrain_time_start_model = timer()\n\niteration_loss_list = []\niteration_accuracy_list = []\n\n# set parameters\nepochs = 10\nbest_loss = 10\n\n# call train and test function\nfor epoch in tqdm(range(epochs)):\n    train_loss, train_acc = train_step(\n        data_loader=train_dataloader,\n        model=model,\n        loss_fn=loss_fn,\n        optimizer=optimizer,\n        accuracy_fn=accuracy_fn,\n        device=device1,\n    )\n\n    test_loss, test_acc = test_step(\n        data_loader=test_dataloader,\n        model=model,\n        loss_fn=loss_fn,\n        accuracy_fn=accuracy_fn,\n        device=device1,\n    )\n\n    for iteration, (x, y) in enumerate(train_dataloader):\n        iteration_loss_list.append(train_loss.item())\n        iteration_accuracy_list.append(train_acc)\n\n    print(\n        f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\"\n    )\n\n    # save best model instance\n\n    if test_loss &lt; best_loss:\n        best_loss = test_loss\n        print(f\"Saving best model for epoch: {epoch}\")\n        torch.save(obj=model.state_dict(), f=\"./model.pth\")\n\n\ntrain_time_end_model = timer()\ntotal_train_time_model = print_train_time(\n    start=train_time_start_model, end=train_time_end_model, device=device1\n)\n\n\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[17], line 33\n     16 train_loss, train_acc = train_step(\n     17     data_loader=train_dataloader,\n     18     model=model,\n   (...)\n     22     device=device1,\n     23 )\n     25 test_loss, test_acc = test_step(\n     26     data_loader=test_dataloader,\n     27     model=model,\n   (...)\n     30     device=device1,\n     31 )\n---&gt; 33 for iteration, (x, y) in enumerate(train_dataloader):\n     34     iteration_loss_list.append(train_loss.item())\n     35     iteration_accuracy_list.append(train_acc)\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630, in _BaseDataLoaderIter.__next__(self)\n    627 if self._sampler_iter is None:\n    628     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    629     self._reset()  # type: ignore[call-arg]\n--&gt; 630 data = self._next_data()\n    631 self._num_yielded += 1\n    632 if self._dataset_kind == _DatasetKind.Iterable and \\\n    633         self._IterableDataset_len_called is not None and \\\n    634         self._num_yielded &gt; self._IterableDataset_len_called:\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673, in _SingleProcessDataLoaderIter._next_data(self)\n    671 def _next_data(self):\n    672     index = self._next_index()  # may raise StopIteration\n--&gt; 673     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    674     if self._pin_memory:\n    675         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52, in _MapDatasetFetcher.fetch(self, possibly_batched_index)\n     50         data = self.dataset.__getitems__(possibly_batched_index)\n     51     else:\n---&gt; 52         data = [self.dataset[idx] for idx in possibly_batched_index]\n     53 else:\n     54     data = self.dataset[possibly_batched_index]\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52, in &lt;listcomp&gt;(.0)\n     50         data = self.dataset.__getitems__(possibly_batched_index)\n     51     else:\n---&gt; 52         data = [self.dataset[idx] for idx in possibly_batched_index]\n     53 else:\n     54     data = self.dataset[possibly_batched_index]\n\nFile ~/.local/lib/python3.10/site-packages/medmnist/dataset.py:138, in MedMNIST2D.__getitem__(self, index)\n    132 \"\"\"\n    133 return: (without transform/target_transofrm)\n    134     img: PIL.Image\n    135     target: np.array of `L` (L=1 for single-label)\n    136 \"\"\"\n    137 img, target = self.imgs[index], self.labels[index].astype(int)\n--&gt; 138 img = Image.fromarray(img)\n    140 if self.as_rgb:\n    141     img = img.convert(\"RGB\")\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3304, in fromarray(obj, mode)\n   3301         msg = \"'strides' requires either tobytes() or tostring()\"\n   3302         raise ValueError(msg)\n-&gt; 3304 return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3206, in frombuffer(mode, size, data, decoder_name, *args)\n   3203         im.readonly = 1\n   3204         return im\n-&gt; 3206 return frombytes(mode, size, data, decoder_name, args)\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3138, in frombytes(mode, size, data, decoder_name, *args)\n   3135 _check_size(size)\n   3137 im = new(mode, size)\n-&gt; 3138 if im.width != 0 and im.height != 0:\n   3139     decoder_args: Any = args\n   3140     if len(decoder_args) == 1 and isinstance(decoder_args[0], tuple):\n   3141         # may pass tuple instead of argument list\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:559, in Image.height(self)\n    555 @property\n    556 def width(self) -&gt; int:\n    557     return self.size[0]\n--&gt; 559 @property\n    560 def height(self) -&gt; int:\n    561     return self.size[1]\n    563 @property\n    564 def size(self) -&gt; tuple[int, int]:\n\nKeyboardInterrupt: \n\n\n\n\n# Load model\nloaded_model = cnn(input_shape=n_channels, hidden_units=16, output_shape=n_classes).to(\n    device\n)\n\nloaded_model.load_state_dict(torch.load(f=\"./model.pth\"))\n\n# get results\nmodel_results = eval_func(\n    data_loader=val_dataloader,\n    model=loaded_model,\n    loss_fn=loss_fn,\n    accuracy_fn=accuracy_fn,\n    device=device,\n)\n\nmodel_results\n\n\n# Get Model predictions and true targets\ny_targets = model_results[\"targets\"]\ny_preds = model_results[\"predictions\"]\n\n# Setup confusion matrix\nconfmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\nconfmat_tensor = confmat(preds=y_preds, target=y_targets)\n\n# Plot the confusion matrix\nfix, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), class_names=class_names, figsize=(10, 7)\n)\n\n\n# Get Model predictions and true targets\ny_targets = model_results[\"targets\"]\ny_preds = model_results[\"predictions\"]\n\n# Setup confusion matrix\nconfmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\nconfmat_tensor = confmat(preds=y_preds, target=y_targets)\n\n# Plot the confusion matrix\nfix, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), class_names=class_names, figsize=(10, 7)\n)"
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html",
    "href": "laboratorios/ASIM/lab001_OOP.html",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "href": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "href": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Encapsulation",
    "text": "Encapsulation\n\nEncapsulation is the concept of bundling data and methods that operate on that data within a single unit (class).\nIt helps to hide the implementation details and expose only the necessary information to the outside world."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "href": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Inheritance",
    "text": "Inheritance\n\nInheritance is the mechanism by which one class can inherit the attributes and methods of another class.\nIt promotes code reuse and facilitates the creation of a hierarchy of classes."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "href": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Polymorphism",
    "text": "Polymorphism\n\nPolymorphism is the ability of an object to take on multiple forms.\nIt can be achieved through method overriding (where a subclass provides a different implementation of a method) or method overloading (where multiple methods with the same name can be defined with different parameters)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "href": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Abstraction",
    "text": "Abstraction\n\nAbstraction is the concept of showing only the necessary information to the outside world while hiding the implementation details.\nIt helps to reduce complexity and improve code readability.\n\n\nclass BankAccount:\n    def __init__(self, account_number, account_name, balance):\n        self.account_number = account_number\n        self.account_name = account_name\n        self.balance = balance\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance:\n            print(\"Insufficient funds\")\n        else:\n            self.balance -= amount\n\n    def display_details(self):\n        print(f\"Account Number: {self.account_number}\")\n        print(f\"Account Name: {self.account_name}\")\n        print(f\"Balance: {self.balance}\")\n\n\nThe BankAccount class encapsulates the account_number, account_name, and balance attributes, as well as the deposit, withdraw, and display_details methods.\nThe __init__ method is a special method that is called when an object is created, and it initializes the attributes.\nThe deposit and withdraw methods modify the balance attribute, demonstrating encapsulation.\nThe display_details method provides a way to access the attributes without exposing them directly, demonstrating abstraction.\n\n\nclass SavingsAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, interest_rate):\n        super().__init__(account_number, account_name, balance)\n        self.interest_rate = interest_rate\n\n    def add_interest(self):\n        interest = self.balance * self.interest_rate\n        self.deposit(interest)\n\n\nThe SavingsAccount class inherits the attributes and methods of BankAccount using the super() function.\nIt adds an additional attribute interest_rate and a method add_interest that calculates and deposits interest.\n\n\nclass CurrentAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, overdraft_limit):\n        super().__init__(account_number, account_name, balance)\n        self.overdraft_limit = overdraft_limit\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance + self.overdraft_limit:\n            print(\"Transaction declined\")\n        else:\n            super().withdraw(amount)\n\n\n\n\nimage.png\n\n\n\n‚ÄúDesigning a Comprehensive Hospital Management System in Python‚Äù\n\nIntroduction\nIn this task, we aim to develop a straightforward hospital management system that efficiently manages patients, doctors, and appointments. Leveraging Python‚Äôs object-oriented programming capabilities, we will create a robust framework to streamline hospital operations.\n\n\nSystem Components\nThe hospital management system comprises four primary classes: Person, Patient, Doctor, Appointment, and Hospital.\n\n\nPerson Class\nThe Person class serves as the foundation for both Patient and Doctor classes, encapsulating essential attributes:\n\nname\nage\ngender\n\n\n\nPatient Class\nInheriting from Person, the Patient class introduces additional attributes:\n\npatient_id\nillness\n\n\n\nDoctor Class\nSimilarly, the Doctor class inherits from Person and includes:\n\ndoctor_id\nspecialization\n\n\n\nAppointment Class\nThe Appointment class encompasses:\n\nappointment_id\npatient (a Patient object)\ndoctor (a Doctor object)\ndate\ntime\n\n\n\nHospital Class\nThe Hospital class is the central hub, managing:\n\npatients (a list of Patient objects)\ndoctors (a list of Doctor objects)\nappointments (a list of Appointment objects)\nHospital Class Methods: The Hospital class features the following methods:\n\nadd_patient(name, age, gender, patient_id, illness): Adds a new patient to the hospital.\nadd_doctor(name, age, gender, doctor_id, specialization): Adds a new doctor to the hospital.\nschedule_appointment(appointment_id, patient_id, doctor_id, date, time): Schedules a new appointment.\nlist_appointments(): Lists all appointments.\n\n\n\n\nImplementation\nBy utilizing these classes and methods, the hospital management system provides a structured approach to managing patients, doctors, and appointments, ensuring efficient and organized hospital operations."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 6, 2025. The defense will be carried out by one of the team members chosen at random."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 1: Mean and Median",
    "text": "Exercise 1: Mean and Median\nWrite a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g.¬†normal, binomial)."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes‚Äô Theorem",
    "text": "Exercise 6: Bayes‚Äô Theorem\nWrite a Python program that applies Bayes‚Äô theorem to update the probability of a hypothesis given new evidence."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g.¬†normal, uniform)."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10:Function visualization - I",
    "text": "Exercise 10:Function visualization - I\nGenerate a python code that allows the visualization (in one figure) of the real (blue) part and the imaginary (red) part, magnitude (green) and phase of the following signals:\n\\[f\\left(t\\right) = e^{-j10 \\pi t}\\]\n\\[g\\left(t\\right) = 10cos\\left(2 \\pi t\\right) + j10sin\\left(2 \\pi t\\right)\\]\nThe visualization must be in the range of t \\(\\left[-10, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/ASIM/lab002_CNN_cap.html",
    "href": "laboratorios/ASIM/lab002_CNN_cap.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torchvision\n\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader\n\nimport torch.nn as nn\n\nfrom torch import utils\nfrom torch import optim\nfrom torch import device\nfrom torch import inference_mode\n\nimport tqdm\n\nfrom timeit import default_timer as timer\nfrom tqdm.auto import tqdm\n\nfrom torchmetrics import ConfusionMatrix\nimport mlxtend\nfrom mlxtend.plotting import plot_confusion_matrix\nimport numpy\nfrom torchvision.transforms.v2 import (\n    ConvertImageDtype,\n    Normalize,\n    Resize,\n    CenterCrop,\n    ToTensor,\n    ToImage,\n    Compose\n)\n\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0\n\n\n\ntransformacion = Compose([\n    ToTensor(), \n    Normalize(mean=[0.5], std=[0.5])\n    ])\n\n/home/pablo/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n\n\n\ndata_flag = \"pathmnist\"\ninfo = INFO[data_flag]\nDataClass = getattr(medmnist, info[\"python_class\"])\n\n# Load the training and testing datasets\ntrain_data = DataClass(split=\"train\", transform=transformacion, download=True)\nval_data = DataClass(split=\"val\", transform=transformacion, download=True)\ntest_data = DataClass(split=\"test\", transform=transformacion, download=True)\n\nDownloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /home/pablo/.medmnist/pathmnist.npz\n\n\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 205615438/205615438 [00:20&lt;00:00, 10059790.46it/s]\n\n\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\n\n\n\n# check data properties\nimg = train_data[0][0]\nlabel = train_data[0][1]\n\nprint(f\"Image:\\n {img}\")\nprint(f\"Label:\\n {label}\")\n\nprint(f\"Image shape: {img.shape}\")\nprint(f\"Label: {label}\")\n\nImage:\n tensor([[[0.7255, 0.7176, 0.7255,  ..., 0.7255, 0.7176, 0.7333],\n         [0.7098, 0.7255, 0.7176,  ..., 0.5451, 0.5059, 0.4902],\n         [0.7255, 0.7255, 0.7176,  ..., 0.6314, 0.6235, 0.6392],\n         ...,\n         [0.7098, 0.7020, 0.7333,  ..., 0.7333, 0.7255, 0.7333],\n         [0.6706, 0.7020, 0.7333,  ..., 0.7333, 0.7333, 0.7333],\n         [0.6863, 0.7255, 0.7333,  ..., 0.7255, 0.7333, 0.7412]],\n\n        [[0.6314, 0.6235, 0.6235,  ..., 0.6314, 0.6235, 0.6314],\n         [0.6157, 0.6235, 0.6157,  ..., 0.3882, 0.3490, 0.3176],\n         [0.6314, 0.6235, 0.6078,  ..., 0.4980, 0.5059, 0.5216],\n         ...,\n         [0.6078, 0.5765, 0.6314,  ..., 0.6314, 0.6314, 0.6392],\n         [0.5059, 0.5686, 0.6314,  ..., 0.6314, 0.6392, 0.6314],\n         [0.5294, 0.6235, 0.6314,  ..., 0.6314, 0.6314, 0.6392]],\n\n        [[0.7804, 0.7804, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7725, 0.7725, 0.7725,  ..., 0.5843, 0.5451, 0.5294],\n         [0.7725, 0.7725, 0.7647,  ..., 0.6706, 0.6706, 0.6941],\n         ...,\n         [0.7647, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7098, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7255, 0.7725, 0.7804,  ..., 0.7804, 0.7804, 0.7882]]])\nLabel:\n [0]\nImage shape: torch.Size([3, 28, 28])\nLabel: [0]\n\n\n\n# Number of image channels\nn_channels = info[\"n_channels\"]\nprint(f\"number of channels: {n_channels}\")\n\n# Number of classes\nn_classes = len(info[\"label\"])\nprint(f\"number of classes: {n_classes}\")\n\n# Get the class names from the dataset\nclass_names = info[\"label\"]\nprint(f\"class names: {class_names}\")\n\nnumber of channels: 3\nnumber of classes: 9\nclass names: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n\n\n\nfor i in range(3):\n    img = train_data[i][0]\n    label = train_data[i][1]\n    plt.figure(figsize=(3, 3))\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(label)\n    plt.axis(False)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.6313726..0.84313726].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.372549..0.85882354].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# change data into dataloader form\nBATCH_SIZE = 128\ntrain_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n\n\n# check dataloader\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")\n\nDataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53cd0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53490&gt;)\nLength of train dataloader: 704 batches of 128\nLength of test dataloader: 57 batches of 128\nLength of val dataloader: 79 batches of 128"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "El electrocardiograma (ECG o EKG) es una grabaci√≥n de la actividad el√©ctrica card√≠aca en la superficie de la piel, durante un per√≠odo de tiempo determinado. En cada ciclo card√≠aco, un coraz√≥n sano presenta una secuencia de se√±ales el√©ctricas que se generan en el nodo sinoauricular y se distribuyen en el coraz√≥n hasta alcanzar los ventr√≠culos. Estas se√±ales tienen una forma caracter√≠stica que se muestra en la figura 1.\n\n\n\nFigura 1. ECG durante un ciclo card√≠aco normal\n\n\nA trav√©s de un ECG, un profesional de la salud entrenado es capaz de obtener informaci√≥n relevante sobre el funcionamiento del coraz√≥n; por ejemplo, se puede determinar la frecuencia card√≠aca, la presencia de da√±o en el m√∫sculo card√≠aco, los efectos de medicamentos y la funci√≥n de marcapasos implantados.\n\n\nLos estudiantes conocer√°n las principales teor√≠as concernientes a la generaci√≥n del electrocardiograma y su relaci√≥n con el funcionamiento del coraz√≥n.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al.¬†A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al.¬†Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#objetivo-de-aprendizaje",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Los estudiantes conocer√°n las principales teor√≠as concernientes a la generaci√≥n del electrocardiograma y su relaci√≥n con el funcionamiento del coraz√≥n."
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#duraci√≥n",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#duraci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#materiales",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#materiales",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al.¬†A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al.¬†Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-1-revisi√≥n-al-electrocardiograms",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-1-revisi√≥n-al-electrocardiograms",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Actividad 1: Revisi√≥n al electrocardiograms",
    "text": "Actividad 1: Revisi√≥n al electrocardiograms\n\n¬øQu√© es un electrocardiograma (ECG) y cu√°l es su importancia en el diagn√≥stico cl√≠nico?\n¬øQu√© informaci√≥n electrofisiol√≥gica proporciona un ECG y c√≥mo se relaciona con la actividad del coraz√≥n?\n¬øQu√© es una derivaci√≥n (lead) en el contexto de un ECG y cu√°l es su funci√≥n?\n¬øCu√°ntas derivaciones existen en un ECG est√°ndar y c√≥mo se clasifican?\nObserve la Figura 1 proporcionada y determine a qu√© derivaci√≥n corresponde el diagrama mostrado. Justifique su respuesta.\n¬øQu√© es una arritmia y qu√© tipos existen? Describa las caracter√≠sticas de cada tipo de arritmia."
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-2-an√°lisis-del-articulo",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-2-an√°lisis-del-articulo",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Actividad 2: An√°lisis del articulo",
    "text": "Actividad 2: An√°lisis del articulo\n\n¬øCu√°les son las principales clases de arritmias que el art√≠culo estudia y c√≥mo se agrupan?\n¬øQu√© impacto tienen las arritmias en la salud p√∫blica seg√∫n el art√≠culo? Mencione datos estad√≠sticos relevantes.\n¬øPor qu√© es importante mejorar la precisi√≥n en la clasificaci√≥n autom√°tica de arritmias?\n¬øCu√°les son las principales fuentes de ruido en una se√±al de ECG y qu√© t√©cnicas se utilizaron en el art√≠culo para reducirlas?\n¬øPor qu√© se aplic√≥ normalizaci√≥n a las se√±ales ECG? ¬øQu√© impacto tuvo en la clasificaci√≥n? Explique el m√©todo de normalizaci√≥n.\n¬øCu√°les son las principales caracter√≠sticas extra√≠das de la se√±al ECG en este estudio?\n¬øPor qu√© es importante la selecci√≥n de caracter√≠sticas para el entrenamiento de un algoritmo de clasificaci√≥n?"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-3-an√°lisis-de-la-base-de-datos",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-3-an√°lisis-de-la-base-de-datos",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Actividad 3: An√°lisis de la base de datos",
    "text": "Actividad 3: An√°lisis de la base de datos\n\n¬øCu√°les fueron los criterios de selecci√≥n de los pacientes?\n¬øCu√°ntos registros de ECG se recopilaron en total y qu√© duraci√≥n tienen las se√±ales analizadas?\n¬øC√≥mo se realiz√≥ la toma de datos del ECG? Especifique el n√∫mero de derivaciones, la duraci√≥n del registro y la frecuencia de muestreo.\n¬øCu√°les fueron las caracter√≠sticas demogr√°ficas de la poblaci√≥n estudiada? Describa la distribuci√≥n por edad y g√©nero.\n¬øCu√°l fue la prevalencia de cada tipo de arritmia en la base de datos? ¬øQu√© arritmias fueron las m√°s frecuentes y cu√°les fueron las menos comunes?"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#criterios-de-evaluaci√≥n",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#criterios-de-evaluaci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Criterios de Evaluaci√≥n",
    "text": "Criterios de Evaluaci√≥n\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nNivel Excelente (5.0 - 4.5)\nNivel Satisfactorio (4.4 - 3.5)\nNivel Aceptable (3.4 - 2.5)\nNivel Deficiente (&lt;2.5)\nPeso (%)\n\n\n\n\nComprensi√≥n te√≥rica del ECG y su relevancia cl√≠nica\nExplica de manera clara y detallada la importancia del ECG, su funci√≥n diagn√≥stica y la informaci√≥n electrofisiol√≥gica que proporciona. Responde con precisi√≥n todas las preguntas te√≥ricas.\nResponde la mayor√≠a de las preguntas con claridad, pero algunas respuestas pueden carecer de profundidad o detalles.\nResponde las preguntas de manera parcial o con imprecisiones conceptuales. Falta claridad en algunos conceptos.\nRespuestas incompletas o con errores fundamentales en la comprensi√≥n del ECG y su relevancia.\n20%\n\n\nAn√°lisis del art√≠culo de Zheng et al.\nIdentifica y sintetiza correctamente las clases de arritmias, impacto en salud p√∫blica, t√©cnicas de reducci√≥n de ruido y normalizaci√≥n. Argumenta con evidencia del art√≠culo.\nPresenta un buen an√°lisis, aunque algunas respuestas carecen de profundidad o precisi√≥n. Uso adecuado pero limitado de la evidencia.\nMuestra dificultad en identificar o explicar correctamente algunos conceptos clave del art√≠culo.\nAn√°lisis deficiente, respuestas vagas o incorrectas, falta de relaci√≥n con el art√≠culo.\n20%\n\n\nAn√°lisis de la base de datos de ECG\nDescribe con precisi√≥n los criterios de selecci√≥n, n√∫mero de registros, condiciones de adquisici√≥n y caracter√≠sticas demogr√°ficas. Utiliza correctamente los datos del art√≠culo.\nExplica la mayor√≠a de los aspectos, aunque con algunas omisiones o falta de precisi√≥n en los datos.\nResponde parcialmente, con confusi√≥n en algunos aspectos metodol√≥gicos o demogr√°ficos.\nNo logra describir correctamente los criterios de la base de datos o presenta errores graves en su interpretaci√≥n.\n20%\n\n\nJustificaci√≥n y an√°lisis de derivaciones\nIdentifica correctamente la derivaci√≥n del ECG mostrado en la Figura 1, justificando con base en conocimientos te√≥ricos.\nIdentifica la derivaci√≥n con una justificaci√≥n aceptable, aunque podr√≠a ser m√°s clara.\nPresenta una identificaci√≥n incorrecta o incompleta con una justificaci√≥n d√©bil.\nNo justifica o identifica err√≥neamente la derivaci√≥n.\n15%\n\n\nPresentaci√≥n y redacci√≥n del informe\nInforme bien estructurado, sin errores gramaticales o de formato. Uso adecuado de referencias. Argumentaci√≥n clara y precisa.\nInforme organizado, aunque con algunos errores menores de gram√°tica o formato. Argumentaci√≥n adecuada.\nPresentaci√≥n con errores de redacci√≥n y formato. Explicaciones poco estructuradas.\nInforme desorganizado, con errores graves de gram√°tica y sin referencias adecuadas.\n15%\n\n\nParticipaci√≥n y trabajo en equipo\nDemuestra alto compromiso y participaci√≥n en la sesi√≥n de laboratorio. Contribuye activamente al desarrollo del informe.\nParticipa en la mayor√≠a de las actividades, aunque con algunas intervenciones limitadas.\nParticipa de forma espor√°dica o depende en exceso del grupo para completar las actividades.\nNo participa o su aporte al equipo es m√≠nimo.\n10%\n\n\n\nTotal: 100% puntos."
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Antes de realizar el procesamiento de se√±ales en estudios biom√©dicos, es fundamental llevar a cabo un an√°lisis descriptivo de los participantes. Este paso permite contextualizar los datos y asegurar que cualquier resultado obtenido sea v√°lido, representativo y adecuado para su interpretaci√≥n cl√≠nica y cient√≠fica. A continuaci√≥n, se detallan las razones clave para realizar este an√°lisis previo:\n\nCaracterizaci√≥n de la Poblaci√≥n Estudiada: El an√°lisis descriptivo permite conocer la distribuci√≥n de variables clave.\nIdentificaci√≥n de Posibles Sesgos en los Datos: Un estudio bien dise√±ado debe asegurarse de que los datos sean representativos de la poblaci√≥n objetivo.\nEvaluaci√≥n de la Calidad de los Datos: El an√°lisis descriptivo ayuda a detectar inconsistencias en los datos antes de aplicar t√©cnicas de procesamiento de se√±ales.\nJustificaci√≥n del Preprocesamiento de Se√±ales: Al conocer las caracter√≠sticas de los participantes, se pueden tomar decisiones informadas sobre qu√© t√©cnicas de procesamiento aplicar.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al.¬†A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al.¬†Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#duraci√≥n",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#duraci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#materiales",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#materiales",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al.¬†A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al.¬†Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-generaci√≥n-de-la-informaci√≥n-base",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-generaci√≥n-de-la-informaci√≥n-base",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Actividad 1: Generaci√≥n de la informaci√≥n base",
    "text": "Actividad 1: Generaci√≥n de la informaci√≥n base\nUtilizando el dataset, realice las siguiente tareas:\n\nEnumere todos los posibles diagn√≥sticos que los pacientes pueden tener.\nPara todos los pacientes genere una tabla que debe tener la siguiente informaci√≥n:\n\nID: Identificador del paciente.\nEdad: Edad del paciente.\nSexo: Sexo del paciente.\nDiagnosticos: A partir de aqu√≠ se genera una columna por cada diagn√≥stico posible de un paciente. En cada paciente se registrar√° un 1 si este fue diagn√≥sticado con la dolencia respectiva. Recomendaci√≥n: Use los archivos .hea adjuntos en el dataset."
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-an√°lisis-de-la-informaci√≥n",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-an√°lisis-de-la-informaci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Actividad 2: An√°lisis de la informaci√≥n",
    "text": "Actividad 2: An√°lisis de la informaci√≥n\nA partir de la tabla generado en la actividad anterior responda de forma clara y concisa las siguientes preguntas:\n\n¬øCu√°l es la frecuencia y el porcentaje de casos de Bradicardia Sinusal (SB) en la muestra?\n¬øCu√°l es la edad promedio y su desviaci√≥n est√°ndar para los pacientes con Bradicardia #. Sinusal (SB)?\n¬øCu√°l es el porcentaje de hombres en la categor√≠a de Bradicardia Sinusal (SB)?\n¬øCu√°ntos pacientes fueron diagnosticados con Ritmo Sinusal (SR) y qu√© porcentaje representa del total?\n¬øCu√°l es la edad promedio y la desviaci√≥n est√°ndar de los pacientes con Ritmo Sinusal (SR)?\n¬øQu√© porcentaje de los pacientes con Ritmo Sinusal (SR) son hombres?\n¬øCu√°ntos casos de Fibrilaci√≥n Auricular (AFIB) se reportaron y qu√© porcentaje representa?\n¬øCu√°l es la edad promedio y la desviaci√≥n est√°ndar de los pacientes con Fibrilaci√≥n Auricular (AFIB)?\n¬øQu√© porcentaje de los pacientes con Fibrilaci√≥n Auricular (AFIB) son hombres?\n¬øCu√°ntos pacientes presentan Taquicardia Sinusal (ST) y qu√© porcentaje del total representa?\n¬øCu√°l es la edad promedio y la desviaci√≥n est√°ndar de los pacientes con Taquicardia Sinusal (ST)?\n¬øQu√© porcentaje de los pacientes con Taquicardia Sinusal (ST) son hombres?\n¬øCu√°l es la frecuencia y el porcentaje de casos de Flutter Auricular (AF) en la muestra?\n¬øCu√°l es la edad promedio y su desviaci√≥n est√°ndar para los pacientes con Flutter Auricular (AF)?\n¬øCu√°l es el porcentaje de hombres en la categor√≠a de Flutter Auricular (AF)?\n¬øCu√°ntos pacientes presentan Irregularidad Sinusal (SI) y qu√© porcentaje del total representa?\n¬øCu√°l es la edad promedio y la desviaci√≥n est√°ndar de los pacientes con Irregularidad Sinusal (SI)?\n¬øQu√© porcentaje de los pacientes con Irregularidad Sinusal (SI) son hombres?\n¬øCu√°l es la frecuencia y el porcentaje de casos de Taquicardia Supraventricular (SVT) en la muestra?\n¬øCu√°l es la edad promedio y su desviaci√≥n est√°ndar para los pacientes con Taquicardia Supraventricular (SVT)?\n¬øCu√°l es el porcentaje de hombres en la categor√≠a de Taquicardia Supraventricular (SVT)?\n¬øCu√°ntos casos de Taquicardia Auricular (AT) se registraron y qu√© porcentaje del total representa?\n¬øCu√°l es la edad promedio y la desviaci√≥n est√°ndar de los pacientes con Taquicardia Auricular (AT)?\n¬øQu√© porcentaje de los pacientes con Taquicardia Auricular (AT) son hombres?\n¬øCu√°ntos casos de Taquicardia por Reentrada en el Nodo AV (AVNRT) se reportaron y qu√© porcentaje representan?\n¬øCu√°l es la edad promedio y la desviaci√≥n est√°ndar de los pacientes con Taquicardia por Reentrada en el Nodo AV (AVNRT)?\n¬øQu√© porcentaje de los pacientes con Taquicardia por Reentrada en el Nodo AV (AVNRT) son hombres?\n¬øCu√°ntos pacientes fueron diagnosticados con Taquicardia por Reentrada Auriculoventricular (AVRT) y qu√© porcentaje representan?\n¬øCu√°l es la edad promedio y la desviaci√≥n est√°ndar de los pacientes con Taquicardia por Reentrada Auriculoventricular (AVRT)?\n¬øQu√© porcentaje de los pacientes con Taquicardia por Reentrada Auriculoventricular (AVRT) son hombres?\n¬øCu√°ntos casos de Ritmo de deambulamiento auricular sinusal a auricular (SAAWR) se registraron y qu√© porcentaje representan?\n¬øCu√°l es la edad promedio y la desviaci√≥n est√°ndar de los pacientes con Ritmo de deambulamiento auricular sinusal a auricular (SAAWR)?\n¬øQu√© porcentaje de los pacientes con Ritmo de deambulamiento auricular sinusal a auricular (SAAWR) son hombres?\n¬øCu√°l es el n√∫mero total de pacientes en la muestra y su edad promedio?\n¬øCu√°l es el porcentaje total de hombres en la muestra?"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#criterios-de-evaluaci√≥n",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#criterios-de-evaluaci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Criterios de Evaluaci√≥n",
    "text": "Criterios de Evaluaci√≥n\nSustentaci√≥n del trabajo. Cada equipo deber√° responder tres preguntas:\n\nPregunta aleatoria basada en la actividad 2.\nPregunta basada en estad√≠sticas que se obtienen a partir de la tabla de la actividad 1\nPregunta sobre el c√≥digo utilizado para realizar el laboratorio."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab03_ImagProc.html",
    "href": "laboratorios/PSIM/Previous/lab03_ImagProc.html",
    "title": "Laboratorio 3: Carga de datos e Histograma",
    "section": "",
    "text": "Cargar el archivo imagen_dicom.dcm y almacenarlo en la variable var01.\nCargar el archivo imagen_nii.nii y almacenarlo en la variable var02.\nCargar el archivo covid-4.png y almacenarlo en la variable var03.\nMostrar las variables: var01, var02, var03.\nDescribir las dimensiones de cada una de las imagenes.\nTomar la var03 y si tiene m√°s de una dimensi√≥n, convertirla a imagen en escala de grises, con profundidad de intensidad de pixel de 8bits.\nContar cuantos pixeles hay para cada valor de intensidad posible en la conversi√≥n en escala de grises de la variable var03. Mostrar estos valores en una gr√°fica de barras.\nPara el punto 7 solo puede utilizar la librer√≠a numpy.\nPara el punto 8 solo puede utilizar la librer√≠a matplotlib."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab04_ImagProc02.html",
    "href": "laboratorios/PSIM/Previous/lab04_ImagProc02.html",
    "title": "Algoritmos b√°sicos de procesamiento de im√°genes",
    "section": "",
    "text": "Usando la imagen fresas.png la cual fue tomada de la p√°gina Geeks for geeks resuelva las siguientes cuestiones.\n\nAplique las siguientes transformaciones y describa el efecto de cada transformaci√≥n:\n\nTransformaci√≥n n-potencial con \\(1&lt;n&lt;2\\)\nTransformaci√≥n n-potencial con \\(0.5&lt;n&lt;1\\)\nTransformaci√≥n LOG (Logaritmo Natural)\nTransformaci√≥n exponencial\nDescriba en un diagrama de bloques el algoritmo necesario para realizar este tipo de transformaciones.\nInvestigue y desarrolle el algoritmo de la transformaci√≥n \\(\\Gamma\\). La informaci√≥n b√°sica la puede encontrar aqui\n\n\nRecuerde: Si una imagen queda completamente blanca o completamente negra, es probable que sea por mal manejo de rangos de intensidad\n\nSea los siguientes kernels de convoluci√≥n:\n\n\\(\\begin{bmatrix}\n1 & 1 & 1 \\\\\n1 & -8 & 1 \\\\\n1 & 1 & 1\n\\end{bmatrix}\\)\n\\(\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n-1 & 8 & -1 \\\\\n-1 & -1 & -1\n\\end{bmatrix}\\)\n\n\nExplique las siguientes cuestiones:\n\nInvestigue las formas de realizar la convoluci√≥n con opencv.\nAplique cada uno de los kernels de convoluci√≥n y compare los resultados.\nExplique cuales son las respectivas resoluci√≥nes de pixel de las imagenes resultantes as√≠ como su m√°ximo y su m√≠nimo.\n\n\nUtilizando la imagen radiograf√≠a, aplique cada tipo de matriz afine presente en las diapositivas de clase\nDeterminar proyecto final para PSIM.\n\nDeterminar el problema a resolver.\nDeterminar el objetivo a alcanzar\nDeterminar el dataset\n\n\nRecuerde, en su proyecto final, NO podr√° hacer uso de algoritmos de machine learning."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler‚Äôs Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 6, 2025. The defense will be carried out by one of the team members chosen at random.\n\nExercise 0: Matrix Manipulation\nWrite a program that (after an initial solo design) prompts from the keyboard three integers \\(N\\), \\(M\\), and \\(K\\); validates that \\(N \\ge 1\\), \\(M \\ge 1\\), and \\(K \\ge 0\\); and constructs an \\(N \\times M\\) matrix whose entries are uniformly sampled integers from the closed interval \\([0, K]\\). The algorithm must classify every entry and extract the sets of even numbers, odd numbers, and prime numbers, where \\(0\\) and \\(1\\) are treated as non-prime and primality is decided via trial division up to \\(\\lfloor \\sqrt{x} \\rfloor\\) with early termination. For each category, report both (a) the total count over all matrix positions and (b) the sorted set of unique values; handle duplicates correctly, and note that if \\(K &lt; 2\\) the prime set is empty by definition. Structure the solution modularly (separate input handling, matrix generation, and classification), include basic input-error recovery, and optionally expose a random-seed parameter to ensure reproducibility. After independently drafting pseudocode, engage a peer as a ‚Äúmore knowledgeable other‚Äù to critique modularity and efficiency, then implement the revised design, test it on at least two contrasting cases (e.g., small matrices and edge \\(K\\) values), and submit a concise analytical note that justifies your validation choices and discusses time complexity; conclude with a brief reflection explaining how the peer interaction scaffolded your final solution.\n\n\nExercise 1: Numerical Diferentation\nDetermine the numerical derivative of the function h, represented as \\(\\left(\\frac{dh}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach\n\n\nExercise 2: Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{h(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach\n\n\nExercise 3: Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler‚Äôs Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)\n\n\nExercise 4: Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent.\n\n\n\n0.5585873704668033"
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html",
    "title": "Laboratorio 004: Manipulacion de Im√°genes",
    "section": "",
    "text": "Comprender la estructura digital de una imagen como matriz de p√≠xeles.\nAplicar t√©cnicas b√°sicas de manipulaci√≥n de im√°genes usando Python.\nDesarrollar funciones para codificar y decodificar informaci√≥n textual en im√°genes.\nReflexionar sobre la importancia del procesamiento de im√°genes en aplicaciones biom√©dicas.\n\n\n\n\n\nLenguaje: Python 3\nLibrer√≠as: opencv-python (cv2), numpy, matplotlib, pydicom.\n\n\n\n\n\nCarga y visualizaci√≥n de im√°genes dicom\nConversi√≥n de texto a binario\nCodificaci√≥n de bits en el canal de color\nRecuperaci√≥n del mensaje codificado\nGeneraci√≥n de la imagen dicom\n\n\n\n\nCada grupo trabajar√° una variante distinta del laboratorio base. Esto garantiza diversidad de enfoques y evita el plagio entre equipos.\n\n\n\n\n\n\n\n\nGrupo\nVariante asignada\nDescripci√≥n\n\n\n\n\nA\nCanal rojo\nSolo puede usar el canal rojo para codificar.\n\n\nB\nOrden inverso\nEl mensaje se codifica recorriendo los p√≠xeles en orden inverso.\n\n\nC\nDos mensajes\nCodifica dos mensajes distintos: uno en azul y otro en verde.\n\n\nD\nCompresi√≥n b√°sica\nComprime el mensaje antes de insertarlo.\n\n\nE\nEscala de grises\nUtiliza im√°genes en escala de grises para codificaci√≥n.\n\n\nF\nAlto contraste\nSolo se permite codificar en p√≠xeles con alto contraste respecto a sus vecinos.\n\n\nG\nPatr√≥n de ajedrez\nEl mensaje se codifica en p√≠xeles alternos como patr√≥n de ajedrez.\n\n\nH\nTres bits\nSe usan los tres bits menos significativos para codificar cada car√°cter.\n\n\nI\nBaja variabilidad local\nEl mensaje solo se codifica en zonas donde los valores de p√≠xel son muy similares entre vecinos.\n\n\n\n\n\n\nCodifica el siguiente mensaje dentro de una imagen asignada por el docente:\n\"Paciente Juan P√©rez, ID: 203911, ECG normal, sin antecedentes\"\nCada grupo deber√°:\n\nEntregar el c√≥digo Python funcional.\nComparar la imagen original y la modificada.\nRecuperar correctamente el mensaje.\nEntregar un informe breve explicando el proceso y los retos del grupo.\n\n\n\n\n\n\n\nCriterio\nPuntaje\n\n\n\n\nManipulaci√≥n b√°sica de im√°genes\n20 pts\n\n\nCodificaci√≥n y recuperaci√≥n funcional\n40 pts\n\n\nAdaptaci√≥n a la variante del grupo\n30 pts\n\n\nInforme t√©cnico claro y bien escrito\n10 pt\n\n\nTotal\n100 pts\n\n\n\n\n\n\n\n¬øQu√© aplicaciones biom√©dicas podr√≠an beneficiarse del ocultamiento de datos en im√°genes? Explica una situaci√≥n cl√≠nica concreta donde esta t√©cnica ser√≠a √∫til."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#objetivos-del-laboratorio",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#objetivos-del-laboratorio",
    "title": "Laboratorio 004: Manipulacion de Im√°genes",
    "section": "",
    "text": "Comprender la estructura digital de una imagen como matriz de p√≠xeles.\nAplicar t√©cnicas b√°sicas de manipulaci√≥n de im√°genes usando Python.\nDesarrollar funciones para codificar y decodificar informaci√≥n textual en im√°genes.\nReflexionar sobre la importancia del procesamiento de im√°genes en aplicaciones biom√©dicas."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#herramientas",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#herramientas",
    "title": "Laboratorio 004: Manipulacion de Im√°genes",
    "section": "",
    "text": "Lenguaje: Python 3\nLibrer√≠as: opencv-python (cv2), numpy, matplotlib, pydicom."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#actividades-comunes-a-todos-los-grupos",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#actividades-comunes-a-todos-los-grupos",
    "title": "Laboratorio 004: Manipulacion de Im√°genes",
    "section": "",
    "text": "Carga y visualizaci√≥n de im√°genes dicom\nConversi√≥n de texto a binario\nCodificaci√≥n de bits en el canal de color\nRecuperaci√≥n del mensaje codificado\nGeneraci√≥n de la imagen dicom"
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#variantes-del-laboratorio-por-grupo",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#variantes-del-laboratorio-por-grupo",
    "title": "Laboratorio 004: Manipulacion de Im√°genes",
    "section": "",
    "text": "Cada grupo trabajar√° una variante distinta del laboratorio base. Esto garantiza diversidad de enfoques y evita el plagio entre equipos.\n\n\n\n\n\n\n\n\nGrupo\nVariante asignada\nDescripci√≥n\n\n\n\n\nA\nCanal rojo\nSolo puede usar el canal rojo para codificar.\n\n\nB\nOrden inverso\nEl mensaje se codifica recorriendo los p√≠xeles en orden inverso.\n\n\nC\nDos mensajes\nCodifica dos mensajes distintos: uno en azul y otro en verde.\n\n\nD\nCompresi√≥n b√°sica\nComprime el mensaje antes de insertarlo.\n\n\nE\nEscala de grises\nUtiliza im√°genes en escala de grises para codificaci√≥n.\n\n\nF\nAlto contraste\nSolo se permite codificar en p√≠xeles con alto contraste respecto a sus vecinos.\n\n\nG\nPatr√≥n de ajedrez\nEl mensaje se codifica en p√≠xeles alternos como patr√≥n de ajedrez.\n\n\nH\nTres bits\nSe usan los tres bits menos significativos para codificar cada car√°cter.\n\n\nI\nBaja variabilidad local\nEl mensaje solo se codifica en zonas donde los valores de p√≠xel son muy similares entre vecinos."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#ejercicio-integrador",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#ejercicio-integrador",
    "title": "Laboratorio 004: Manipulacion de Im√°genes",
    "section": "",
    "text": "Codifica el siguiente mensaje dentro de una imagen asignada por el docente:\n\"Paciente Juan P√©rez, ID: 203911, ECG normal, sin antecedentes\"\nCada grupo deber√°:\n\nEntregar el c√≥digo Python funcional.\nComparar la imagen original y la modificada.\nRecuperar correctamente el mensaje.\nEntregar un informe breve explicando el proceso y los retos del grupo."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#evaluaci√≥n",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#evaluaci√≥n",
    "title": "Laboratorio 004: Manipulacion de Im√°genes",
    "section": "",
    "text": "Criterio\nPuntaje\n\n\n\n\nManipulaci√≥n b√°sica de im√°genes\n20 pts\n\n\nCodificaci√≥n y recuperaci√≥n funcional\n40 pts\n\n\nAdaptaci√≥n a la variante del grupo\n30 pts\n\n\nInforme t√©cnico claro y bien escrito\n10 pt\n\n\nTotal\n100 pts"
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#pregunta-de-reflexi√≥n",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#pregunta-de-reflexi√≥n",
    "title": "Laboratorio 004: Manipulacion de Im√°genes",
    "section": "",
    "text": "¬øQu√© aplicaciones biom√©dicas podr√≠an beneficiarse del ocultamiento de datos en im√°genes? Explica una situaci√≥n cl√≠nica concreta donde esta t√©cnica ser√≠a √∫til."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html",
    "href": "laboratorios/APSB/lab01_Linux.html",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Los estudiantes ser√°n capaces de aplicar comandos esenciales de Linux para la manipulaci√≥n de archivos, gesti√≥n de procesos y an√°lisis de datos biom√©dicos.\n\n\n\n1.5 horas\n\n\n\n\nComputador con Linux (instalado o m√°quina virtual), WSL2 con Ubuntu, o emulado.\nHoja de trucos de Linux.\nArchivo de datos biom√©dicos en formato .csv (proporcionado).\n\n\n\n\n\n\n\n\nExplora los archivos y directorios disponibles en el sistema.\nCrea una estructura de directorios organizada para almacenar datos biom√©dicos.\nMueve y organiza el archivo de datos de pacientes dentro de la estructura creada.\nModifica los permisos del archivo para restringir o permitir accesos seg√∫n corresponda.\n\nPreguntas de reflexi√≥n:\n- ¬øPor qu√© es importante organizar archivos en un entorno de trabajo biom√©dico?\n- ¬øC√≥mo podr√≠as utilizar permisos de archivos para proteger datos de pacientes en un hospital?\n\n\n\n\n\n\n\n\nExamina las primeras l√≠neas del archivo de pacientes para entender su estructura.\nCuenta la cantidad total de registros para determinar el n√∫mero de pacientes.\nFiltra los registros de pacientes con presi√≥n arterial alta.\nOrdena los pacientes por edad para identificar a los de mayor edad.\nExtrae informaci√≥n relevante, como edad y frecuencia card√≠aca, y gu√°rdala en un nuevo archivo.\n\nPreguntas de an√°lisis:\n- ¬øC√≥mo podr√≠amos automatizar estos an√°lisis para realizarlos diariamente en un hospital?\n- ¬øQu√© otros patrones en los datos podr√≠amos detectar utilizando solo comandos de Linux?\n\n\n\n\n\n\n\n\nEscribe un script en python que realice los an√°lisis anteriores y guarde los resultados en un archivo de reporte.\nAsigna los permisos adecuados al script para poder ejecutarlo.\nEjecuta el script y verifica el contenido del reporte generado.\n\nReflexi√≥n final:\n- ¬øC√≥mo podr√≠amos modificar el script para hacerlo m√°s interactivo?\n- ¬øC√≥mo podr√≠amos programarlo para que se ejecute autom√°ticamente cada cierto tiempo?\n\n\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nDescripci√≥n\nPuntos\n\n\n\n\nUso de comandos b√°sicos\nAplicaci√≥n correcta de comandos de navegaci√≥n y manipulaci√≥n de archivos\n20\n\n\nProcesamiento de datos\nUso adecuado de herramientas para an√°lisis de datos\n30\n\n\nAutomatizaci√≥n con scripts\nCreaci√≥n y ejecuci√≥n correcta de un script funcional\n30\n\n\nReflexi√≥n y an√°lisis\nRespuestas argumentadas a preguntas de reflexi√≥n\n20\n\n\n\nTotal: 100 puntos.\n\nEsta actividad permite a los estudiantes desarrollar habilidades pr√°cticas en Linux con aplicaciones directas en bioinform√°tica y an√°lisis de datos biom√©dicos."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#objetivo-de-aprendizaje",
    "href": "laboratorios/APSB/lab01_Linux.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Los estudiantes ser√°n capaces de aplicar comandos esenciales de Linux para la manipulaci√≥n de archivos, gesti√≥n de procesos y an√°lisis de datos biom√©dicos."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#duraci√≥n",
    "href": "laboratorios/APSB/lab01_Linux.html#duraci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "1.5 horas"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#materiales",
    "href": "laboratorios/APSB/lab01_Linux.html#materiales",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Computador con Linux (instalado o m√°quina virtual), WSL2 con Ubuntu, o emulado.\nHoja de trucos de Linux.\nArchivo de datos biom√©dicos en formato .csv (proporcionado)."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-1-exploraci√≥n-y-gesti√≥n-de-archivos-30-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-1-exploraci√≥n-y-gesti√≥n-de-archivos-30-min",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Explora los archivos y directorios disponibles en el sistema.\nCrea una estructura de directorios organizada para almacenar datos biom√©dicos.\nMueve y organiza el archivo de datos de pacientes dentro de la estructura creada.\nModifica los permisos del archivo para restringir o permitir accesos seg√∫n corresponda.\n\nPreguntas de reflexi√≥n:\n- ¬øPor qu√© es importante organizar archivos en un entorno de trabajo biom√©dico?\n- ¬øC√≥mo podr√≠as utilizar permisos de archivos para proteger datos de pacientes en un hospital?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-2-procesamiento-de-datos-biom√©dicos-en-la-terminal-40-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-2-procesamiento-de-datos-biom√©dicos-en-la-terminal-40-min",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Examina las primeras l√≠neas del archivo de pacientes para entender su estructura.\nCuenta la cantidad total de registros para determinar el n√∫mero de pacientes.\nFiltra los registros de pacientes con presi√≥n arterial alta.\nOrdena los pacientes por edad para identificar a los de mayor edad.\nExtrae informaci√≥n relevante, como edad y frecuencia card√≠aca, y gu√°rdala en un nuevo archivo.\n\nPreguntas de an√°lisis:\n- ¬øC√≥mo podr√≠amos automatizar estos an√°lisis para realizarlos diariamente en un hospital?\n- ¬øQu√© otros patrones en los datos podr√≠amos detectar utilizando solo comandos de Linux?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-3-automatizaci√≥n-con-scripts-20-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-3-automatizaci√≥n-con-scripts-20-min",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Escribe un script en python que realice los an√°lisis anteriores y guarde los resultados en un archivo de reporte.\nAsigna los permisos adecuados al script para poder ejecutarlo.\nEjecuta el script y verifica el contenido del reporte generado.\n\nReflexi√≥n final:\n- ¬øC√≥mo podr√≠amos modificar el script para hacerlo m√°s interactivo?\n- ¬øC√≥mo podr√≠amos programarlo para que se ejecute autom√°ticamente cada cierto tiempo?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#criterios-de-evaluaci√≥n",
    "href": "laboratorios/APSB/lab01_Linux.html#criterios-de-evaluaci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "Criterio\nDescripci√≥n\nPuntos\n\n\n\n\nUso de comandos b√°sicos\nAplicaci√≥n correcta de comandos de navegaci√≥n y manipulaci√≥n de archivos\n20\n\n\nProcesamiento de datos\nUso adecuado de herramientas para an√°lisis de datos\n30\n\n\nAutomatizaci√≥n con scripts\nCreaci√≥n y ejecuci√≥n correcta de un script funcional\n30\n\n\nReflexi√≥n y an√°lisis\nRespuestas argumentadas a preguntas de reflexi√≥n\n20\n\n\n\nTotal: 100 puntos.\n\nEsta actividad permite a los estudiantes desarrollar habilidades pr√°cticas en Linux con aplicaciones directas en bioinform√°tica y an√°lisis de datos biom√©dicos."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html",
    "href": "laboratorios/APSB/lab02_EDA.html",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "Construir un conjunto de datos a partir de se√±ales e im√°genes biom√©dicas.\nAplicar t√©cnicas de preprocesamiento y limpieza de datos.\nRealizar un an√°lisis exploratorio de datos (EDA).\nExtraer relaciones matem√°ticas mediante modelos de regresi√≥n y regresi√≥n log√≠stica.\nComparar el desempe√±o de m√∫ltiples modelos y seleccionar el m√°s adecuado.\n\n\n\n\n\n\n\nCada estudiante debe elegir un conjunto de datos biom√©dicos, que puede provenir de:\n\nSe√±ales fisiol√≥gicas: ECG, EEG, PPG, EMG.\nIm√°genes m√©dicas: Radiograf√≠as, resonancias, tomograf√≠as, postura, etc.\nBases de datos p√∫blicas: PhysioNet, Kaggle, NIH, entre otras.\n\n\n\n\nDependiendo del tipo de datos, se deben aplicar las siguientes t√©cnicas:\n\n\n\nCarga de archivos (.csv, .edf, .mat).\nFiltrado de ruido y artefactos con t√©cnicas adecuadas.\n\n\n\n\n\nCarga de im√°genes (.png, .jpg, .dicom).\nConversi√≥n a escala de grises, realce de contraste o segmentaci√≥n si es necesario.\n\n\n\n\n\n\n\n\n\nLos estudiantes deben:\n\nAnalizar la estructura del conjunto de datos.\nIdentificar posibles valores at√≠picos o datos faltantes.\n\n\n\n\n\nGr√°ficos de se√±ales en el dominio del tiempo y la frecuencia.\nHistogramas de intensidades en im√°genes m√©dicas.\n\n\n\n\n\n\n\n\nCada estudiante debe seleccionar una o m√°s variables independientes y una variable dependiente con la que se intentar√° encontrar una relaci√≥n matem√°tica.\nEjemplos de relaciones a explorar:\n\nSe√±ales: ¬øC√≥mo se relaciona la variabilidad del ECG con la edad?\nIm√°genes: ¬øExiste una correlaci√≥n entre el √°rea de una lesi√≥n y la presencia de patolog√≠a?\n\n\n\n\nSe entrenar√°n y comparar√°n distintos modelos:\n\n\nPara analizar relaciones entre variables num√©ricas.\n\nSeparar el conjunto de datos en entrenamiento y prueba.\nAjustar un modelo de regresi√≥n lineal.\nEvaluar el desempe√±o con m√©tricas como el error cuadr√°tico medio (MSE).\nGenerar una gr√°fica que muestre la relaci√≥n encontrada.\n\n\n\n\nPara predecir una variable categ√≥rica, como la presencia o ausencia de una condici√≥n m√©dica.\n\nSeleccionar variables predictoras y la variable objetivo.\nDividir los datos en conjunto de entrenamiento y prueba.\nEntrenar un modelo de regresi√≥n log√≠stica.\nEvaluar el desempe√±o utilizando la precisi√≥n y la matriz de confusi√≥n.\n\n\n\n\n\n\n\nCada estudiante debe probar m√∫ltiples modelos y justificar su elecci√≥n con base en:\n\nRegresi√≥n lineal vs.¬†Regresi√≥n polin√≥mica (para variables continuas).\nRegresi√≥n log√≠stica vs.¬†√Årboles de decisi√≥n (para clasificaci√≥n binaria).\n\nCriterios de evaluaci√≥n:\n\nError cuadr√°tico medio (MSE) para regresi√≥n.\nPrecisi√≥n y matriz de confusi√≥n para clasificaci√≥n.\n\nSe espera que cada estudiante explique:\n\n¬øCu√°l fue el modelo m√°s adecuado?\n¬øPor qu√© eligieron ese modelo y no otro?\n¬øC√≥mo pueden mejorarlo?\n\n\n\n\n\nLos estudiantes deben responder:\n\n¬øQu√© relaci√≥n matem√°tica encontraron en los datos?\n¬øCu√°l fue el modelo m√°s adecuado y por qu√©?\n¬øC√≥mo podr√≠an mejorar la predicci√≥n o ajustar mejor el modelo?\n\n\n\n\n\n\nEntrega: Un informe en Jupyter Notebook con c√≥digo, visualizaciones y an√°lisis.\nCriterios: Correcta implementaci√≥n de modelos, an√°lisis de resultados y justificaci√≥n del mejor modelo.\n\n\n\n\n\nLa calificaci√≥n total ser√° de 100 puntos, distribuidos de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (20 pts)\nAceptable (10 pts)\nDeficiente (5 pts)\nPuntos\n\n\n\n\nSelecci√≥n y Construcci√≥n del Dataset\nSe elige un conjunto de datos relevante y se preprocesa adecuadamente.\nSe elige un conjunto de datos adecuado pero con preprocesamiento incompleto.\nEl conjunto de datos no es adecuado o carece de preprocesamiento.\n\n\n\nExploraci√≥n y Visualizaci√≥n\nSe realizan estad√≠sticas descriptivas y gr√°ficos claros y relevantes.\nSe presentan estad√≠sticas b√°sicas y gr√°ficos, pero con poca interpretaci√≥n.\nNo se incluyen estad√≠sticas ni gr√°ficos relevantes.\n\n\n\nEntrenamiento de Modelos\nSe implementan correctamente al menos dos modelos y se comparan sus resultados.\nSe implementa un modelo correctamente pero sin comparaci√≥n.\nLa implementaci√≥n de los modelos es incompleta o incorrecta.\n\n\n\nEvaluaci√≥n y Selecci√≥n del Mejor Modelo\nSe justifican las m√©tricas y se elige el mejor modelo con base en evidencia.\nSe elige un modelo, pero sin un an√°lisis detallado de m√©tricas.\nNo hay justificaci√≥n clara para la elecci√≥n del modelo.\n\n\n\nInterpretaci√≥n y Conclusiones\nSe explican claramente los hallazgos y posibles aplicaciones cl√≠nicas.\nSe presentan hallazgos, pero sin mucha profundidad.\nNo se presentan hallazgos o la explicaci√≥n es insuficiente.\n\n\n\nCalidad del C√≥digo y Presentaci√≥n\nEl c√≥digo es claro, bien documentado y correctamente estructurado.\nEl c√≥digo tiene errores menores o falta de documentaci√≥n.\nEl c√≥digo es desordenado, con errores o sin documentaci√≥n.\n\n\n\n\n\n\n\n90 - 100 puntos: Sobresaliente.\n75 - 89 puntos: Bueno.\n50 - 74 puntos: Necesita mejora.\n0 - 49 puntos: Deficiente.\n\n\nNotas adicionales: Se recomienda el uso de bibliotecas como pandas, numpy, matplotlib, statsmodels y seaborn para an√°lisis y visualizaci√≥n."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#objetivos",
    "href": "laboratorios/APSB/lab02_EDA.html#objetivos",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "Construir un conjunto de datos a partir de se√±ales e im√°genes biom√©dicas.\nAplicar t√©cnicas de preprocesamiento y limpieza de datos.\nRealizar un an√°lisis exploratorio de datos (EDA).\nExtraer relaciones matem√°ticas mediante modelos de regresi√≥n y regresi√≥n log√≠stica.\nComparar el desempe√±o de m√∫ltiples modelos y seleccionar el m√°s adecuado."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-1-construcci√≥n-del-conjunto-de-datos",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-1-construcci√≥n-del-conjunto-de-datos",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "Cada estudiante debe elegir un conjunto de datos biom√©dicos, que puede provenir de:\n\nSe√±ales fisiol√≥gicas: ECG, EEG, PPG, EMG.\nIm√°genes m√©dicas: Radiograf√≠as, resonancias, tomograf√≠as, postura, etc.\nBases de datos p√∫blicas: PhysioNet, Kaggle, NIH, entre otras.\n\n\n\n\nDependiendo del tipo de datos, se deben aplicar las siguientes t√©cnicas:\n\n\n\nCarga de archivos (.csv, .edf, .mat).\nFiltrado de ruido y artefactos con t√©cnicas adecuadas.\n\n\n\n\n\nCarga de im√°genes (.png, .jpg, .dicom).\nConversi√≥n a escala de grises, realce de contraste o segmentaci√≥n si es necesario."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-2-an√°lisis-exploratorio-de-datos-eda",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-2-an√°lisis-exploratorio-de-datos-eda",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "Los estudiantes deben:\n\nAnalizar la estructura del conjunto de datos.\nIdentificar posibles valores at√≠picos o datos faltantes.\n\n\n\n\n\nGr√°ficos de se√±ales en el dominio del tiempo y la frecuencia.\nHistogramas de intensidades en im√°genes m√©dicas."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-3-extracci√≥n-de-relaciones-matem√°ticas-con-modelos-predictivos",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-3-extracci√≥n-de-relaciones-matem√°ticas-con-modelos-predictivos",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "Cada estudiante debe seleccionar una o m√°s variables independientes y una variable dependiente con la que se intentar√° encontrar una relaci√≥n matem√°tica.\nEjemplos de relaciones a explorar:\n\nSe√±ales: ¬øC√≥mo se relaciona la variabilidad del ECG con la edad?\nIm√°genes: ¬øExiste una correlaci√≥n entre el √°rea de una lesi√≥n y la presencia de patolog√≠a?\n\n\n\n\nSe entrenar√°n y comparar√°n distintos modelos:\n\n\nPara analizar relaciones entre variables num√©ricas.\n\nSeparar el conjunto de datos en entrenamiento y prueba.\nAjustar un modelo de regresi√≥n lineal.\nEvaluar el desempe√±o con m√©tricas como el error cuadr√°tico medio (MSE).\nGenerar una gr√°fica que muestre la relaci√≥n encontrada.\n\n\n\n\nPara predecir una variable categ√≥rica, como la presencia o ausencia de una condici√≥n m√©dica.\n\nSeleccionar variables predictoras y la variable objetivo.\nDividir los datos en conjunto de entrenamiento y prueba.\nEntrenar un modelo de regresi√≥n log√≠stica.\nEvaluar el desempe√±o utilizando la precisi√≥n y la matriz de confusi√≥n."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-4-comparaci√≥n-y-selecci√≥n-del-mejor-modelo",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-4-comparaci√≥n-y-selecci√≥n-del-mejor-modelo",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "Cada estudiante debe probar m√∫ltiples modelos y justificar su elecci√≥n con base en:\n\nRegresi√≥n lineal vs.¬†Regresi√≥n polin√≥mica (para variables continuas).\nRegresi√≥n log√≠stica vs.¬†√Årboles de decisi√≥n (para clasificaci√≥n binaria).\n\nCriterios de evaluaci√≥n:\n\nError cuadr√°tico medio (MSE) para regresi√≥n.\nPrecisi√≥n y matriz de confusi√≥n para clasificaci√≥n.\n\nSe espera que cada estudiante explique:\n\n¬øCu√°l fue el modelo m√°s adecuado?\n¬øPor qu√© eligieron ese modelo y no otro?\n¬øC√≥mo pueden mejorarlo?"
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-5-interpretaci√≥n-y-discusi√≥n",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-5-interpretaci√≥n-y-discusi√≥n",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "Los estudiantes deben responder:\n\n¬øQu√© relaci√≥n matem√°tica encontraron en los datos?\n¬øCu√°l fue el modelo m√°s adecuado y por qu√©?\n¬øC√≥mo podr√≠an mejorar la predicci√≥n o ajustar mejor el modelo?"
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#evaluaci√≥n",
    "href": "laboratorios/APSB/lab02_EDA.html#evaluaci√≥n",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "Entrega: Un informe en Jupyter Notebook con c√≥digo, visualizaciones y an√°lisis.\nCriterios: Correcta implementaci√≥n de modelos, an√°lisis de resultados y justificaci√≥n del mejor modelo."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#r√∫brica-de-evaluaci√≥n",
    "href": "laboratorios/APSB/lab02_EDA.html#r√∫brica-de-evaluaci√≥n",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "La calificaci√≥n total ser√° de 100 puntos, distribuidos de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (20 pts)\nAceptable (10 pts)\nDeficiente (5 pts)\nPuntos\n\n\n\n\nSelecci√≥n y Construcci√≥n del Dataset\nSe elige un conjunto de datos relevante y se preprocesa adecuadamente.\nSe elige un conjunto de datos adecuado pero con preprocesamiento incompleto.\nEl conjunto de datos no es adecuado o carece de preprocesamiento.\n\n\n\nExploraci√≥n y Visualizaci√≥n\nSe realizan estad√≠sticas descriptivas y gr√°ficos claros y relevantes.\nSe presentan estad√≠sticas b√°sicas y gr√°ficos, pero con poca interpretaci√≥n.\nNo se incluyen estad√≠sticas ni gr√°ficos relevantes.\n\n\n\nEntrenamiento de Modelos\nSe implementan correctamente al menos dos modelos y se comparan sus resultados.\nSe implementa un modelo correctamente pero sin comparaci√≥n.\nLa implementaci√≥n de los modelos es incompleta o incorrecta.\n\n\n\nEvaluaci√≥n y Selecci√≥n del Mejor Modelo\nSe justifican las m√©tricas y se elige el mejor modelo con base en evidencia.\nSe elige un modelo, pero sin un an√°lisis detallado de m√©tricas.\nNo hay justificaci√≥n clara para la elecci√≥n del modelo.\n\n\n\nInterpretaci√≥n y Conclusiones\nSe explican claramente los hallazgos y posibles aplicaciones cl√≠nicas.\nSe presentan hallazgos, pero sin mucha profundidad.\nNo se presentan hallazgos o la explicaci√≥n es insuficiente.\n\n\n\nCalidad del C√≥digo y Presentaci√≥n\nEl c√≥digo es claro, bien documentado y correctamente estructurado.\nEl c√≥digo tiene errores menores o falta de documentaci√≥n.\nEl c√≥digo es desordenado, con errores o sin documentaci√≥n.\n\n\n\n\n\n\n\n90 - 100 puntos: Sobresaliente.\n75 - 89 puntos: Bueno.\n50 - 74 puntos: Necesita mejora.\n0 - 49 puntos: Deficiente.\n\n\nNotas adicionales: Se recomienda el uso de bibliotecas como pandas, numpy, matplotlib, statsmodels y seaborn para an√°lisis y visualizaci√≥n."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp.¬†261‚Äì265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp.¬†261‚Äì265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\ndata = pd.read_csv(\"../../data/diabetes.csv\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network data",
    "text": "Create neural network data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‚ÄòMachine Learning with R‚Äô by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book‚Äôs specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book‚Äôs examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary‚Äôs residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\n\n2. Visualizing distributions\n\n\n3. Exploring relationships between variables\n\n\n4. Analyzing categorical variables"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "Model Implementation",
    "text": "Model Implementation"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "Train Model",
    "text": "Train Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance"
  },
  {
    "objectID": "codigo/ASIM/cod002_LinearRegression.html",
    "href": "codigo/ASIM/cod002_LinearRegression.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport numpy as np\n\n# Generate some random data\nnp.random.seed(0)\nX = np.random.rand(100,1)\ny = 3 + 2 * X + np.random.randn(100,1) / 1.5\nX\n\narray([[0.5488135 ],\n       [0.71518937],\n       [0.60276338],\n       [0.54488318],\n       [0.4236548 ],\n       [0.64589411],\n       [0.43758721],\n       [0.891773  ],\n       [0.96366276],\n       [0.38344152],\n       [0.79172504],\n       [0.52889492],\n       [0.56804456],\n       [0.92559664],\n       [0.07103606],\n       [0.0871293 ],\n       [0.0202184 ],\n       [0.83261985],\n       [0.77815675],\n       [0.87001215],\n       [0.97861834],\n       [0.79915856],\n       [0.46147936],\n       [0.78052918],\n       [0.11827443],\n       [0.63992102],\n       [0.14335329],\n       [0.94466892],\n       [0.52184832],\n       [0.41466194],\n       [0.26455561],\n       [0.77423369],\n       [0.45615033],\n       [0.56843395],\n       [0.0187898 ],\n       [0.6176355 ],\n       [0.61209572],\n       [0.616934  ],\n       [0.94374808],\n       [0.6818203 ],\n       [0.3595079 ],\n       [0.43703195],\n       [0.6976312 ],\n       [0.06022547],\n       [0.66676672],\n       [0.67063787],\n       [0.21038256],\n       [0.1289263 ],\n       [0.31542835],\n       [0.36371077],\n       [0.57019677],\n       [0.43860151],\n       [0.98837384],\n       [0.10204481],\n       [0.20887676],\n       [0.16130952],\n       [0.65310833],\n       [0.2532916 ],\n       [0.46631077],\n       [0.24442559],\n       [0.15896958],\n       [0.11037514],\n       [0.65632959],\n       [0.13818295],\n       [0.19658236],\n       [0.36872517],\n       [0.82099323],\n       [0.09710128],\n       [0.83794491],\n       [0.09609841],\n       [0.97645947],\n       [0.4686512 ],\n       [0.97676109],\n       [0.60484552],\n       [0.73926358],\n       [0.03918779],\n       [0.28280696],\n       [0.12019656],\n       [0.2961402 ],\n       [0.11872772],\n       [0.31798318],\n       [0.41426299],\n       [0.0641475 ],\n       [0.69247212],\n       [0.56660145],\n       [0.26538949],\n       [0.52324805],\n       [0.09394051],\n       [0.5759465 ],\n       [0.9292962 ],\n       [0.31856895],\n       [0.66741038],\n       [0.13179786],\n       [0.7163272 ],\n       [0.28940609],\n       [0.18319136],\n       [0.58651293],\n       [0.02010755],\n       [0.82894003],\n       [0.00469548]])\n\n\n\n\n# Convert data to PyTorch tensors\nX_tensor = torch.from_numpy(X.astype(np.float32))\ny_tensor = torch.from_numpy(y.astype(np.float32))\n\n\n# Define the linear regression model\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Initialize the model, loss function, and optimizer\nmodel = LinearRegression()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# Train the model\nfor epoch in range(1000):\n    optimizer.zero_grad()\n    outputs = model(X_tensor)\n    loss = criterion(outputs, y_tensor)\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 100 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n# Print the learned parameters\n\nm = model.linear.weight.item()\nb = model.linear.bias.item()\n\nprint(\"Learned parameters:\")\nprint(\"Weight:\", m)\nprint(\"Bias:\", b )\n\nEpoch 1, Loss: 17.11027717590332\nEpoch 101, Loss: 0.5529825687408447\nEpoch 201, Loss: 0.4432789981365204\nEpoch 301, Loss: 0.44221213459968567\nEpoch 401, Loss: 0.4419429302215576\nEpoch 501, Loss: 0.4417407214641571\nEpoch 601, Loss: 0.44158604741096497\nEpoch 701, Loss: 0.44146785140037537\nEpoch 801, Loss: 0.4413774013519287\nEpoch 901, Loss: 0.4413083791732788\nLearned parameters:\nWeight: 1.91282320022583\nBias: 3.170973062515259\n\n\n\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0 , 1, 200)\nfig001 = plt.figure()\nplt.plot(t, m*t+b)\nplt.plot(X, y, 'r*')"
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html",
    "href": "codigo/ASIM/cod001_Kaggle.html",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "href": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/SYSB/DisennoFiltros.html",
    "href": "codigo/SYSB/DisennoFiltros.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\nimport ast\n\n\ndef design_filter(zeros=None, poles=None, gain=1.0):\n    \"\"\"\n    Dise√±a un filtro digital a partir de ceros y/o polos y una ganancia.\n\n    Par√°metros:\n    - zeros: lista de ceros (ra√≠ces del numerador), o None para no incluir\n    - poles: lista de polos (ra√≠ces del denominador), o None para no incluir\n    - gain: ganancia escalar del filtro\n\n    Devuelve:\n    - b: coeficientes del numerador\n    - a: coeficientes del denominador\n    \"\"\"\n    # Si no se pasan ceros, asumimos un FIR trivial (b = [gain])\n    if zeros:\n        b = gain * np.poly(zeros)\n    else:\n        b = np.array([gain], dtype=float)\n\n    # Si no se pasan polos, asumimos sistema FIR (a = [1])\n    if poles:\n        a = np.poly(poles)\n    else:\n        a = np.array([1.0], dtype=float)\n\n    return b, a\n\n\ndef gaussian(x, mu, sigma, A):\n    \"\"\"\n    Genera una funci√≥n gaussiana.\n\n    Par√°metros:\n    - x: array de tiempos\n    - mu: posici√≥n central de la gaussiana\n    - sigma: desviaci√≥n est√°ndar\n    - A: amplitud\n    \"\"\"\n    return A * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n\n\n\ndef simulate_ecg(duration=10.0, fs=500, heart_rate=60):\n    \"\"\"\n    Simula un ECG sint√©tico basado en la superposici√≥n de ondas gaussianas.\n\n    Par√°metros:\n    - duration: duraci√≥n de la se√±al en segundos\n    - fs: frecuencia de muestreo en Hz\n    - heart_rate: frecuencia cardiaca en latidos por minuto\n\n    Devuelve:\n    - t: vector de tiempos\n    - ecg: se√±al simulada de ECG en mV\n    \"\"\"\n    dt = 1 / fs\n    t = np.arange(0, duration, dt)\n    rr = 60 / heart_rate  # intervalo RR en segundos\n\n    # Inicializar se√±al\n    ecg = np.zeros_like(t)\n\n    # Par√°metros de las ondas (posiciones relativas en segundos)\n    # P wave\n    p_amp, p_dur, p_delay = 0.25, 0.09, 0.16\n    # Q wave\n    q_amp, q_dur, q_delay = -0.05, 0.066, 0.166\n    # R wave\n    r_amp, r_dur, r_delay = 1.6, 0.1, 0.166\n    # S wave\n    s_amp, s_dur, s_delay = -0.25, 0.066, 0.19\n    # T wave\n    t_amp, t_dur, t_delay = 0.35, 0.142, 0.36\n\n    # Generar cada latido\n    for beat_start in np.arange(0, duration, rr):\n        mask = (t &gt;= beat_start) & (t &lt; beat_start + rr)\n        tb = t[mask] - beat_start\n        ecg[mask] += gaussian(tb, p_delay, p_dur / 2, p_amp)\n        ecg[mask] += gaussian(tb, q_delay, q_dur / 2, q_amp)\n        ecg[mask] += gaussian(tb, r_delay, r_dur / 2, r_amp)\n        ecg[mask] += gaussian(tb, s_delay, s_dur / 2, s_amp)\n        ecg[mask] += gaussian(tb, t_delay, t_dur / 2, t_amp)\n\n    return t, ecg+0.1*np.cos(2*np.pi*60*t)\n\n\n    # Par√°metros de simulaci√≥n\n    DURATION = 10    # segundos\n    FS = 500         # Hz\n    HR = 70          # latidos por minuto\n\n    # Generar se√±al\n    t, ecg_signal = simulate_ecg(duration=DURATION, fs=FS, heart_rate=HR)\n\n    # Graficar resultado\n    plt.figure(figsize=(12, 4))\n    plt.plot(t, ecg_signal, linewidth=1)\n    plt.title(f'Se√±al de ECG sint√©tica ({HR} bpm)')\n    plt.xlabel('Tiempo (s)')\n    plt.ylabel('Amplitud (mV)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy import signal\n\n\nn = len(ecg_signal)\nyf = np.fft.rfft(ecg_signal)\nxf = np.fft.rfftfreq(n, d=1/FS)\nmagnitude = np.abs(yf) / n\n\n\nplt.figure()\nplt.plot(xf, magnitude)\nplt.title(\"Espectro de frecuencia de la se√±al ECG\")\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.xlim(0, FS/2)\nplt.grid(True)\n\n\n\n\n\n\n\n\n\nb,a = design_filter(zeros=[np.exp(1j*2*np.pi*60/500), np.exp(-1j*2*np.pi*60/500)])\nw, h = signal.freqz(b, a, worN=1024)\n\n\n    mag_db = 20 * np.log10(np.abs(h))\n    phase = np.unwrap(np.angle(h))\n\n    # Gr√°ficos\n    plt.figure(figsize=(8, 6))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(250*(w/np.pi), mag_db)\n    plt.title(\"Respuesta en frecuencia\")\n    plt.ylabel(\"Magnitud (dB)\")\n    plt.grid(True)\n\n    plt.subplot(2, 1, 2)\n    plt.plot(250*(w/np.pi), phase)\n    plt.xlabel(\"Frecuencia normalizada (√óœÄ rad/muestra)\")\n    plt.ylabel(\"Fase (rad)\")\n    plt.grid(True)\n\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "codigo/preparing_slides_002.html",
    "href": "codigo/preparing_slides_002.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport cv2\n\n\ndef generate_striped_image(N, M, K, orientation=\"vertical\"):\n    \"\"\"\n    Genera una imagen de N√óM pixeles con bandas alternas (blanco/negro)\n    de ancho K, en orientaci√≥n vertical u horizontal.\n\n    Par√°metros\n    ----------\n    N : int\n        Altura de la imagen en pixeles.\n    M : int\n        Anchura de la imagen en pixeles.\n    K : int\n        Ancho de cada banda en pixeles.\n    orientation : {'vertical', 'horizontal'}\n        Orientaci√≥n de las bandas. 'vertical' crea franjas verticales;\n        'horizontal' crea franjas horizontales.\n\n    Devuelve\n    -------\n    img : np.ndarray\n        Imagen en escala de grises (dtype uint8) con valores 0 o 255.\n    \"\"\"\n    # Crear imagen en negro\n    img = np.zeros((N, M), dtype=np.uint8)\n\n    # Alternar franjas\n    if orientation == \"vertical\":\n        for start in range(0, M, K):\n            # Determinar color de la franja (0 o 255)\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[:, start : start + K] = color\n\n    elif orientation == \"horizontal\":\n        for start in range(0, N, K):\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[start : start + K, :] = color\n\n    else:\n        raise ValueError(\"orientation debe ser 'vertical' o 'horizontal'\")\n\n    return img\n\n\nif __name__ == \"__main__\":\n    # Par√°metros de ejemplo\n    altura = 400  # N\n    anchura = 400  # M\n    ancho_banda = 50  # K\n\n    # Generar imagen con franjas verticales\n    img_vertical = generate_striped_image(\n        altura, anchura, ancho_banda, orientation=\"vertical\"\n    )\n    cv2.imwrite(\"stripes_vertical.png\", img_vertical)\n    print(\"Guardado stripes_vertical.png\")\n\n    # Generar imagen con franjas horizontales\n    img_horizontal = generate_striped_image(\n        altura, anchura, ancho_banda, orientation=\"horizontal\"\n    )\n    cv2.imwrite(\"stripes_horizontal.png\", img_horizontal)\n    print(\"Guardado stripes_horizontal.png\")\n\nGuardado stripes_vertical.png\nGuardado stripes_horizontal.png\n\n\n\nimport numpy as np\nimport cv2\n\n\ndef generate_pattern_image(N, M, K, pattern=\"vertical\"):\n    \"\"\"\n    Genera una imagen de N√óM p√≠xeles con:\n      - 'vertical': franjas verticales de ancho K\n      - 'horizontal': franjas horizontales de alto K\n      - 'squares': cuadrados alternos de tama√±o K√óK (patr√≥n ajedrez)\n\n    Par√°metros\n    ----------\n    N : int\n        Altura de la imagen en p√≠xeles.\n    M : int\n        Anchura de la imagen en p√≠xeles.\n    K : int\n        Dimensi√≥n de la franja o del cuadrado en p√≠xeles.\n    pattern : {'vertical', 'horizontal', 'squares'}\n        Tipo de patr√≥n a generar.\n\n    Devuelve\n    -------\n    img : np.ndarray\n        Imagen en escala de grises (dtype uint8) con valores 0 o 255.\n    \"\"\"\n    img = np.zeros((N, M), dtype=np.uint8)\n\n    if pattern == \"vertical\":\n        for start in range(0, M, K):\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[:, start : start + K] = color\n\n    elif pattern == \"horizontal\":\n        for start in range(0, N, K):\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[start : start + K, :] = color\n\n    elif pattern == \"squares\":\n        for i in range(0, N, K):\n            for j in range(0, M, K):\n                # alterna color en funci√≥n de la suma de √≠ndices de bloque\n                color = 255 if (((i // K) + (j // K)) % 2) == 0 else 0\n                img[i : i + K, j : j + K] = color\n\n    else:\n        raise ValueError(\"pattern debe ser 'vertical', 'horizontal' o 'squares'\")\n\n    return img\n\n\nif __name__ == \"__main__\":\n    # Par√°metros de ejemplo\n    altura = 400  # N\n    anchura = 600  # M\n    K = 50  # tama√±o de banda o cuadrado\n\n    # Generar y guardar cada patr√≥n\n    for pat in [\"vertical\", \"horizontal\", \"squares\"]:\n        img = generate_pattern_image(altura, anchura, K, pattern=pat)\n        filename = f\"pattern_{pat}.png\"\n        cv2.imwrite(filename, img)\n        print(f\"Guardado {filename}\")\n\nGuardado pattern_vertical.png\nGuardado pattern_horizontal.png\nGuardado pattern_squares.png\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a periodic discrete signal\nN = 8  # Period of the signal\nn = np.arange(N)\nx_n = np.array([1, 2, 3, 4, 3, 2, 1, 0])  # Example discrete signal\n\n# Compute DTFS coefficients\nC_k = np.fft.fft(x_n) / N  # Normalized Discrete Fourier Transform\n\n# Reconstruct the signal using DTFS\nx_reconstructed = np.zeros(N, dtype=complex)\nfor k in range(N):\n    x_reconstructed += C_k[k] * np.exp(1j * 2 * np.pi * k * n / N)\n\n# Plot original and reconstructed signals\nplt.figure(figsize=(10, 4))\nplt.stem(n, x_n, linefmt='b-', markerfmt='bo', basefmt='r-', label='Original Signal')\nplt.stem(n, np.real(x_reconstructed), linefmt='r--', markerfmt='go', basefmt='r-', label='Reconstructed Signal')\nplt.xlabel(\"n\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"DTFS: Original vs Reconstructed Signal\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Print DTFS Coefficients\nprint(\"DTFS Coefficients:\")\nfor k in range(N):\n    print(f\"C[{k}] = {C_k[k]:.4f}\")\n\n\n\n\n\n\n\n\nDTFS Coefficients:\nC[0] = 2.0000+0.0000j\nC[1] = -0.6036-0.6036j\nC[2] = 0.0000+0.0000j\nC[3] = 0.1036-0.1036j\nC[4] = 0.0000+0.0000j\nC[5] = 0.1036+0.1036j\nC[6] = 0.0000+0.0000j\nC[7] = -0.6036+0.6036j\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a periodic discrete signal\nN = 8  # Period of the signal\nn = np.arange(N)\nx_n = np.array([1, 2, 3, 4, 3, 2, 1, 0])  # Example discrete signal\n\n# Compute DTFS coefficients\nC_k = np.fft.fft(x_n) / N  # Normalized Discrete Fourier Transform\n\n# Verify periodicity property: C[k] repeats every N\nC_k_extended = np.tile(C_k, 2)  # Extend coefficients to see repetition\nk_extended = np.arange(2 * N)\n\n# Plot DTFS coefficients and their periodic repetition\nplt.figure(figsize=(10, 4))\nplt.stem(\n    k_extended,\n    np.real(C_k_extended),\n    linefmt=\"b-\",\n    markerfmt=\"bo\",\n    basefmt=\"r-\",\n    label=\"Real Part\",\n)\nplt.stem(\n    k_extended,\n    np.imag(C_k_extended),\n    linefmt=\"g--\",\n    markerfmt=\"go\",\n    basefmt=\"r-\",\n    label=\"Imaginary Part\",\n)\nplt.xlabel(\"n\")\nplt.ylabel(\"Magnitude\")\nplt.title(\"DTFS Periodicity: Coefficients Repeat Every N Samples\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Print DTFS Coefficients to observe periodicity\nprint(\"DTFS Coefficients (showing periodicity):\")\nfor k in range(2 * N):\n    print(f\"C[{k}] = {C_k_extended[k]:.4f}\")\n\n\n\n\n\n\n\n\nDTFS Coefficients (showing periodicity):\nC[0] = 2.0000+0.0000j\nC[1] = -0.6036-0.6036j\nC[2] = 0.0000+0.0000j\nC[3] = 0.1036-0.1036j\nC[4] = 0.0000+0.0000j\nC[5] = 0.1036+0.1036j\nC[6] = 0.0000+0.0000j\nC[7] = -0.6036+0.6036j\nC[8] = 2.0000+0.0000j\nC[9] = -0.6036-0.6036j\nC[10] = 0.0000+0.0000j\nC[11] = 0.1036-0.1036j\nC[12] = 0.0000+0.0000j\nC[13] = 0.1036+0.1036j\nC[14] = 0.0000+0.0000j\nC[15] = -0.6036+0.6036j\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Par√°metros\nfs_cont = 5000  # Frecuencia de muestreo \"continua\" (muy alta)\nfs_sampled = 1000  # Frecuencia de muestreo baja\nT = 1  # Duraci√≥n de la se√±al en segundos\nf_signal = 30  # Frecuencia de la se√±al\n\n# Se√±al continua\nt_cont = np.linspace(0, T, fs_cont * T, endpoint=False)\nsignal_cont = np.sin(2 * np.pi * f_signal * t_cont)\n\n# Se√±al muestreada\nt_sampled = np.linspace(0, T, fs_sampled * T, endpoint=False)\nsignal_sampled = np.sin(2 * np.pi * f_signal * t_sampled)\n\n# FFT continua\nfft_cont = np.fft.fft(signal_cont)\nfreqs_cont = np.fft.fftfreq(len(signal_cont), d=1 / fs_cont)\n\n# FFT muestreada\nfft_sampled = np.fft.fft(signal_sampled)\nfreqs_sampled = np.fft.fftfreq(len(signal_sampled), d=1 / fs_sampled)\n\n# Graficar espectro original y espectro muestreado\nplt.figure(figsize=(12, 6))\n\nplt.subplot(3, 1, 1)\nplt.plot(\n    t_cont, signal_cont\n)\nplt.subplot(3, 1, 2)\nplt.plot(\n    freqs_cont[: len(freqs_cont) // 2],\n    np.abs(fft_cont[: len(freqs_cont) // 2]),\n    label=\"Espectro original\",\n)\nplt.title(\"Espectro de la se√±al continua\")\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.legend()\n\nplt.subplot(3, 1, 3)\nplt.plot(\n    freqs_sampled[: len(freqs_sampled) // 2],\n    np.abs(fft_sampled[: len(freqs_sampled) // 2]),\n    label=\"Espectro muestreado\",\n)\nplt.title(\"Espectro despu√©s del muestreo (repeticiones cada f_s)\")\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import tf2zpk\n\n# Define numerator (zeros) and denominator (poles) coefficients of the transfer function\n# Example: H(z) = (1 - 0.5z^-1) / (1 - 0.9z^-1)\nb = [1, -0.5]  # Numerator coefficients (zeros)\na = [1, -0.9]  # Denominator coefficients (poles)\n\n# Get zeros, poles, and gain\nz, p, k = tf2zpk(b, a)\n\n# Plot settings\nfig, ax = plt.subplots()\nax.set_title(\"Pole-Zero Plot in the Z-Plane\")\n\n# Draw unit circle\nunit_circle = plt.Circle((0, 0), 1, color=\"black\", fill=False, linestyle=\"dashed\")\nax.add_artist(unit_circle)\n\n# Plot zeros and poles\nax.plot(np.real(z), np.imag(z), \"go\", label=\"Zeros\")  # green circles\nax.plot(np.real(p), np.imag(p), \"rx\", label=\"Poles\")  # red Xs\n\n# Axes and formatting\nax.set_xlabel(\"Re\")\nax.set_ylabel(\"Im\")\nax.axhline(0, color=\"gray\", linewidth=0.5)\nax.axvline(0, color=\"gray\", linewidth=0.5)\nax.set_aspect(\"equal\")\nax.grid(True, linestyle=\"--\", alpha=0.5)\nax.legend()\nax.set_xlim(-1.5, 1.5)\nax.set_ylim(-1.5, 1.5)\n\nplt.show()\n\n\n\n\n\n\n\n\n\ndef zpk_to_latex(z, p, k):\n    def format_factor(value):\n        sign = \"+\" if np.real(value) &lt; 0 else \"-\"\n        return f\"(z {sign} {abs(np.real(value)):.2f})\"\n\n    num = \" \".join([format_factor(zero) for zero in z]) if len(z) &gt; 0 else \"1\"\n    den = \" \".join([format_factor(pole) for pole in p]) if len(p) &gt; 0 else \"1\"\n\n    latex_str = r\"H(z) = \" + f\"{k:.2f} \\\\cdot \\\\frac{{{num}}}{{{den}}}\"\n    return latex_str\n\n\nzpk_to_latex(z,p,k)\n\n'H(z) = 1.00 \\\\cdot \\\\frac{(z - 0.50)}{(z - 0.90)}'"
  },
  {
    "objectID": "codigo/PSIM/cod005_eda_images.html",
    "href": "codigo/PSIM/cod005_eda_images.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nimagen = cv2.imread(\"../../data/female-chest-x-ray.jpg\")\n\n\niBlue = imagen[:,:,0]\niGreen = imagen[:, :, 1]\niRed = imagen[:, :, 2]\n\n\nb = 8\ninp01 = iBlue\n\nfor k in range(256)\n\n800000"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html",
    "title": "Estudio de arritmia card√≠aca",
    "section": "",
    "text": "#from google.colab import drive\n#drive.mount('/content/drive')"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librer√≠as",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librer√≠as",
    "title": "Estudio de arritmia card√≠aca",
    "section": "Carga de librer√≠as",
    "text": "Carga de librer√≠as\n\nnumpy: Para manipulaci√≥n num√©rica y funciones estad√≠sticas b√°sicas\nmatplotlib.pyplot: Para generaci√≥n de gr√°ficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.signal as sig"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#configuraci√≥n-de-carpetas",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#configuraci√≥n-de-carpetas",
    "title": "Estudio de arritmia card√≠aca",
    "section": "Configuraci√≥n de carpetas",
    "text": "Configuraci√≥n de carpetas\n\n# data_path = \"/content/drive/MyDrive/ECG_Dataset/\"#Datapath de colab\ndata_path = \"../../data/\""
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "title": "Estudio de arritmia card√≠aca",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\n\n\n\n\n\n\n\n\n\nfs =  500\n\nfc1 = 0.5\nfc2 = 50\norder_fir = 51\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import freqz, windows\n\n\n# Definir el vector de frecuencias\nf_vect = np.linspace(-fs//2, fs//2, order_fir)\n\n# Definir la respuesta en frecuencia deseada\nH1 = np.zeros(len(f_vect))\nH1[(((f_vect &gt;= 0.5) & (f_vect &lt;= 50)) | ((f_vect &lt;= -0.5) & (f_vect &gt;= -50)))] =  1  # Banda de paso entre 0.5 y 50 Hz\n\nplt.figure(figsize=(10,6))\nplt.plot(f_vect, H1)\n\n# Normalizar las frecuencias con respecto a Nyquist (fs/2)\nnormalized_frequencies = f_vect / (fs / 2)\n\n# Interpolaci√≥n de la respuesta deseada\nH_interp = np.interp(np.linspace(0, 1, order_fir), normalized_frequencies, H1)\n\n# Transformada Inversa de Fourier para obtener la respuesta al impulso\nh = np.fft.ifft(H_interp, order_fir).real  # Solo tomamos la parte real\n\n# Aplicar ventana de Hamming\nwindow = windows.hamming(order_fir)\nh_windowed = h * window\n\n# Normalizar la energ√≠a del filtro\nh_windowed /= np.sum(h_windowed)\n\n# Calcular la respuesta en frecuencia\nw, H_fir = freqz(h_windowed, worN=2048, fs=fs)\n\n# Graficar la respuesta al impulso\nplt.figure(figsize=(12, 5))\nplt.stem(h_windowed, basefmt=\"C0\")\nplt.title(\"Respuesta al Impulso del Filtro FIR con Especificaci√≥n en Frecuencia\")\nplt.xlabel(\"n (muestras)\")\nplt.ylabel(\"h[n]\")\nplt.grid()\nplt.show()\n\n# Graficar la respuesta en frecuencia\nplt.figure(figsize=(12, 6))\nplt.subplot(2, 1, 1)\nplt.plot(w, 20 * np.log10(abs(H_fir)), \"b\")\nplt.title(\"Respuesta en Frecuencia - Magnitud\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Magnitud [dB]\")\nplt.grid()\n\nplt.subplot(2, 1, 2)\nplt.plot(w, np.angle(H_fir), \"g\")\nplt.title(\"Respuesta en Frecuencia - Fase\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Fase [radianes]\")\nplt.grid()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import firls, freqz\n\n# Par√°metros del filtro\nfs = 500  # Frecuencia de muestreo en Hz\nN = 51  # N√∫mero de coeficientes del filtro (impar para centrar en cero)\n\n# Definir las bandas y la respuesta deseada\nbands = [0, 0.5, 50, fs / 2]  # Frecuencias en Hz\ndesired = [0, 10, 10, 0]  # Pasa-banda de 0.5 Hz a 50 Hz\n\n# Dise√±ar el filtro FIR con firls\nh_firls = firls(N, bands, desired, fs=fs)\n\n# Calcular la respuesta en frecuencia\nw, H_fir = freqz(h_firls, worN=2048, fs=fs)\n\n# Graficar la respuesta al impulso\nplt.figure(figsize=(12, 5))\nplt.stem(h_firls, basefmt=\"C0\")\nplt.title(\"Respuesta al Impulso del Filtro FIR con firls\")\nplt.xlabel(\"n (muestras)\")\nplt.ylabel(\"h[n]\")\nplt.grid()\nplt.show()\n\n# Graficar la respuesta en frecuencia\nplt.figure(figsize=(12, 6))\nplt.subplot(2, 1, 1)\nplt.plot(w, 20 * np.log10(abs(H_fir)), \"b\")\nplt.title(\"Respuesta en Frecuencia - Magnitud\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Magnitud [dB]\")\nplt.grid()\n\nplt.subplot(2, 1, 2)\nplt.plot(w, np.angle(H_fir), \"g\")\nplt.title(\"Respuesta en Frecuencia - Fase\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Fase [radianes]\")\nplt.grid()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html",
    "title": "DETECCI√ìN DE LA LEUCEMIA LINFOBL√ÅSTICA AGUDA",
    "section": "",
    "text": "La leucemia linfobl√°stica aguda (LLA) es un tipo de c√°ncer hematol√≥gico caracterizado por la proliferaci√≥n descontrolada de linfoblastos inmaduros en la m√©dula √≥sea, la sangre y otros √≥rganos. Este trastorno impide la producci√≥n adecuada de c√©lulas sangu√≠neas normales, lo que provoca s√≠ntomas como anemia, infecciones recurrentes y sangrados anormales. [1]\nEl c√°ncer es una de las principales causas de mortalidad entre ni√±os y adolescentes en todo el mundo; cada a√±o se diagnostica c√°ncer a aproximadamente 274.000 ni√±os de entre 0 y 19 a√±os. [2]\nEn Am√©rica Latina y el Caribe, se estima que alrededor de 30.000 ni√±as, ni√±os y adolescentes menores de 19 a√±os resultar√°n afectados por el c√°ncer anualmente. De ellos, casi 10.000 fallecer√°n a causa de esta enfermedad.\nEn los pa√≠ses de ingresos altos, m√°s del 80% de los ni√±os afectados de c√°ncer se curan, pero en muchos pa√≠ses de ingresos medianos y bajos la tasa de curaci√≥n es de aproximadamente el 20%.[3]\nLas defunciones evitables debidas a los c√°nceres infantiles en los pa√≠ses de ingresos medianos y bajos se producen a consecuencia de la falta de diagn√≥stico, los diagn√≥sticos incorrectos o tard√≠os, las dificultades para acceder a la atenci√≥n sanitaria, el abandono del tratamiento, la muerte por toxicidad y las mayores tasas de recidivas. [3]"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#significado-en-el-contexto-del-modelo",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#significado-en-el-contexto-del-modelo",
    "title": "DETECCI√ìN DE LA LEUCEMIA LINFOBL√ÅSTICA AGUDA",
    "section": "Significado en el Contexto del Modelo",
    "text": "Significado en el Contexto del Modelo\n\nCombinaci√≥n Lineal\n\nCada caracter√≠stica \\(x_i\\) se pondera por su importancia relativa \\(\\theta_i\\)\nEl t√©rmino independiente \\(\\theta_0\\) a√±ade un sesgo base\n\nInterpretaci√≥n de los Coeficientes\n\n\\(\\theta_i &gt; 0\\): La caracter√≠stica aumenta la probabilidad de leucemia\n\\(\\theta_i &lt; 0\\): La caracter√≠stica disminuye la probabilidad de leucemia\n\\(|\\theta_i|\\): Magnitud del impacto de la caracter√≠stica\n\nFlujo del Modelo\n\\[\nX\\theta \\xrightarrow{\\text{producto punto}} z \\xrightarrow{\\text{sigmoide}} h_\\theta(x) = \\frac{1}{1 + e^{-z}}\n\\]\nResultado\n\n\\(z\\): Puntuaci√≥n lineal (puede ser cualquier n√∫mero real)\n\\(h_\\theta(x)\\): Probabilidad entre 0 y 1 despu√©s de aplicar la sigmoide\n\n\nLa regularizaci√≥n L1 (tambi√©n conocida como LASSO - Least Absolute Shrinkage and Selection Operator) es una t√©cnica para prevenir el sobreajuste (overfitting).\n\n¬øQu√© es la regularizaci√≥n L1?\nEs un t√©rmino que se a√±ade a la funci√≥n de costo:\n\\[\n\\frac{\\lambda}{m} \\sum_{j=1}^{n} |\\theta_j|\n\\]\nDonde:\n- Œª (lambda) es el par√°metro que controla la fuerza de la regularizaci√≥n\n- m es el n√∫mero de muestras\n- Œ∏j son los par√°metros del modelo\n- |Œ∏j| es el valor absoluto de cada par√°metro\n\n\n¬øPor qu√© se implementa?\n\nPrevenci√≥n de sobreajuste:\n\nPenaliza coeficientes muy grandes que podr√≠an hacer que el modelo se ajuste demasiado a los datos de entrenamiento\nAyuda al modelo a generalizar mejor con nuevos datos\n\nSelecci√≥n de caracter√≠sticas:\n\nLa regularizaci√≥n L1 tiende a producir coeficientes exactamente iguales a cero\nEsto efectivamente selecciona las caracter√≠sticas m√°s importantes y descarta las menos relevantes\n\n\n\n\nEfectos pr√°cticos:\n\nCon lambda_reg = 0:\n\nNo hay regularizaci√≥n\nEl modelo puede sobreajustarse\n\nCon lambda_reg peque√±o (ej: 0.1):\n\nRegularizaci√≥n suave\nBalance entre ajuste y generalizaci√≥n\n\nCon lambda_reg grande (ej: 10):\n\nRegularizaci√≥n fuerte\nM√°s coeficientes se vuelven cero\nModelo m√°s simple pero puede subajustarse (underfitting)\n\n\n\n\nVentajas:\n\nSelecci√≥n autom√°tica de caracter√≠sticas m√°s relevantes para detectar leucemia\nReducci√≥n del ruido en las mediciones de c√©lulas\nModelo m√°s robusto y generalizable a nuevas muestras\nInterpretabilidad mejorada al identificar las caracter√≠sticas m√°s importantes"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#√°rea-del-contorno",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#√°rea-del-contorno",
    "title": "DETECCI√ìN DE LA LEUCEMIA LINFOBL√ÅSTICA AGUDA",
    "section": "1. √Årea del Contorno",
    "text": "1. √Årea del Contorno\nEl √°rea de un contorno cerrado se calcula utilizando la f√≥rmula del √°rea de un pol√≠gono mediante coordenadas:\n\\[\n\\text{√Årea} = \\frac{1}{2} \\sum_{i=1}^{n} (x_i y_{i+1} - y_i x_{i+1})\n\\]\nDonde:\n- \\(n\\) : N√∫mero total de puntos en el contorno\n- \\((x_i, y_i)\\) : Coordenadas del punto \\(i\\) del contorno\n- \\((x_{i+1}, y_{i+1})\\) : Coordenadas del siguiente punto en el contorno\n- El punto \\(n+1\\) se considera igual al punto 1, cerrando el pol√≠gono\nEsta f√≥rmula:\n- Utiliza el m√©todo de triangulaci√≥n para calcular el √°rea\n- Funciona para cualquier pol√≠gono cerrado, sea c√≥ncavo o convexo\n- El resultado es positivo si los puntos est√°n ordenados en sentido antihorario\n- El valor absoluto del resultado da el √°rea real"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#per√≠metro-del-contorno",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#per√≠metro-del-contorno",
    "title": "DETECCI√ìN DE LA LEUCEMIA LINFOBL√ÅSTICA AGUDA",
    "section": "2. Per√≠metro del Contorno",
    "text": "2. Per√≠metro del Contorno\nEl per√≠metro se calcula sumando las distancias entre todos los puntos consecutivos del contorno:\n\\[\n\\text{Per√≠metro} = \\sum_{i=1}^{n} \\sqrt{(x_{i+1} - x_i)^2 + (y_{i+1} - y_i)^2}\n\\]\nDonde:\n- \\(n\\) : N√∫mero total de puntos en el contorno\n- \\((x_i, y_i)\\) : Coordenadas del punto actual\n- \\((x_{i+1}, y_{i+1})\\) : Coordenadas del siguiente punto\n- El √∫ltimo punto se conecta con el primero para cerrar el contorno\nEsta f√≥rmula:\n- Utiliza la distancia euclidiana entre puntos consecutivos\n- La suma total representa la longitud del contorno completo\n- Es independiente de la orientaci√≥n del contorno"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#circularidad",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#circularidad",
    "title": "DETECCI√ìN DE LA LEUCEMIA LINFOBL√ÅSTICA AGUDA",
    "section": "3. Circularidad",
    "text": "3. Circularidad\nLa circularidad es una medida adimensional que cuantifica qu√© tan similar es una forma a un c√≠rculo perfecto:\n\\[\n\\text{Circularidad} = \\frac{4\\pi \\times \\text{√Årea}}{\\text{Per√≠metro}^2}\n\\]\nDonde:\n- \\(\\text{√Årea}\\) : √Årea del contorno calculada con la primera f√≥rmula\n- \\(\\text{Per√≠metro}\\) : Per√≠metro del contorno calculado con la segunda f√≥rmula\n- \\(\\pi\\) : Constante matem√°tica pi (‚âà 3.14159)\nInterpretaci√≥n de los valores:\n- \\(\\text{Circularidad} = 1\\) : C√≠rculo perfecto\n- \\(0 &lt; \\text{Circularidad} &lt; 1\\) : Formas no circulares\n- Valores cercanos a 1: Formas casi circulares\n- Valores cercanos a 0: Formas muy alargadas o irregulares\nPropiedades importantes:\n1. Es invariante a la escala (el tama√±o no afecta el resultado)\n2. Es adimensional (no tiene unidades)\n3. Siempre es menor o igual a 1 (la igualdad solo se da en c√≠rculos perfectos)\n4. Es sensible a irregularidades en el contorno\nEjemplo de interpretaci√≥n:\n- Circularidad = 0.95: Forma muy circular\n- Circularidad = 0.7: Forma moderadamente circular\n- Circularidad = 0.3: Forma muy irregular o alargadas"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#funci√≥n-log√≠stica",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#funci√≥n-log√≠stica",
    "title": "DETECCI√ìN DE LA LEUCEMIA LINFOBL√ÅSTICA AGUDA",
    "section": "Funci√≥n Log√≠stica",
    "text": "Funci√≥n Log√≠stica\nLa funci√≥n log√≠stica, o funci√≥n sigmoide, se define como:\n\\[\nP(y = 1|x) = \\frac{1}{1 + e^{-(w^T x + b)}}\n\\]\nDonde:\n- ( P(y = 1|x) ) es la probabilidad de que la clase sea 1 dado un vector de caracter√≠sticas ( x ).\n- ( w ) es el vector de pesos del modelo.\n- ( b ) es el sesgo o t√©rmino independiente.\n- ( x ) es el vector de caracter√≠sticas de entrada.\nLa funci√≥n sigmoide convierte la salida lineal ( w^T x + b ) en un valor entre 0 y 1, que puede interpretarse como una probabilidad."
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#funci√≥n-de-costo",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#funci√≥n-de-costo",
    "title": "DETECCI√ìN DE LA LEUCEMIA LINFOBL√ÅSTICA AGUDA",
    "section": "Funci√≥n de Costo",
    "text": "Funci√≥n de Costo\nPara entrenar el modelo, se utiliza la funci√≥n de costo de entrop√≠a cruzada:\n\\[\nJ(w, b) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(P(y^{(i)}|x^{(i)})) + (1 - y^{(i)}) \\log(1 - P(y^{(i)}|x^{(i)})) \\right]\n\\]\nDonde:\n- ( m ) es el n√∫mero total de ejemplos en el conjunto de datos.\n- ( y^{(i)} ) es la etiqueta verdadera para el i-√©simo ejemplo.\n- ( P(y{(i)}|x{(i)}) ) es la probabilidad predicha para el i-√©simo ejemplo."
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#gradientes-y-actualizaci√≥n",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#gradientes-y-actualizaci√≥n",
    "title": "DETECCI√ìN DE LA LEUCEMIA LINFOBL√ÅSTICA AGUDA",
    "section": "Gradientes y Actualizaci√≥n",
    "text": "Gradientes y Actualizaci√≥n\nLos gradientes de la funci√≥n de costo con respecto a los par√°metros ( w ) y ( b ) se utilizan para actualizar los pesos y el sesgo mediante descenso por gradiente:\n\nGradiente del peso ( w ):\n\n\\[\n\\frac{\\partial J(w, b)}{\\partial w} = \\frac{1}{m} \\sum_{i=1}^{m} (P(y^{(i)}|x^{(i)}) - y^{(i)}) x^{(i)}\n\\]\n\nGradiente del sesgo ( b ):\n\n\\[\n\\frac{\\partial J(w, b)}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (P(y^{(i)}|x^{(i)}) - y^{(i)})\n\\]\nLos par√°metros se actualizan de la siguiente manera:\n\nActualizaci√≥n del peso ( w ):\n\n\\[\nw := w - \\alpha \\frac{\\partial J(w, b)}{\\partial w}\n\\]\n\nActualizaci√≥n del sesgo ( b ):\n\n\\[\nb := b - \\alpha \\frac{\\partial J(w, b)}{\\partial b}\n\\]\nDonde ( ) es la tasa de aprendizaje.\nLa precisi√≥n del modelo se eval√∫a comparando las predicciones con las etiquetas verdaderas en el conjunto de prueba, utilizando m√©tricas como la precisi√≥n (accuracy), precisi√≥n (precision), sensibilidad (recall), y especificidad."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#√°reas-de-aplicaci√≥n-del-procesamiento-de-se√±ales-e-im√°genes",
    "href": "presentaciones/TALLERES/Promise.html#√°reas-de-aplicaci√≥n-del-procesamiento-de-se√±ales-e-im√°genes",
    "title": "Semillero en Procesamiento de Se√±ales e Imagenes",
    "section": "√Åreas de aplicaci√≥n del procesamiento de se√±ales e im√°genes",
    "text": "√Åreas de aplicaci√≥n del procesamiento de se√±ales e im√°genes\n\n\n\nDiagn√≥stico automatizado\nIdentificaci√≥n de enfermedades en ECG, EEG o im√°genes m√©dicas.\nMonitoreo en tiempo real\nVigilancia en UCI con se√±ales continuas de coraz√≥n, respiraci√≥n y cerebro.\nTelemedicina\nTransmisi√≥n y compresi√≥n de se√±ales para consultas a distancia.\nRehabilitaci√≥n y pr√≥tesis inteligentes\nUso de se√±ales EMG para controlar pr√≥tesis y exoesqueletos.\n\n\n\nDetecci√≥n temprana de eventos cr√≠ticos\nAnticipaci√≥n de arritmias, crisis epil√©pticas o ca√≠das.\nBiometr√≠a y seguridad\nReconocimiento de voz, rostro o iris.\nImagenolog√≠a avanzada\nSegmentaci√≥n de √≥rganos o tumores en 3D para cirug√≠a o radioterapia.\nEntretenimiento y multimedia\nFiltros en fotos y videos, mejora de audio y realidad aumentada."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "href": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "title": "Semillero en Procesamiento de Se√±ales e Imagenes",
    "section": "Plataforma para el monitoreo de salud de adultos mayores",
    "text": "Plataforma para el monitoreo de salud de adultos mayores\n\n\n\nDetecci√≥n ambulatoria de actividades diarias.\nDetecci√≥n ambulatoria de riesgo de ca√≠da.\nDetecci√≥n ambulatoria de riesgo neuronal.\n\n\n\n\n\n\n\n\n\n\nProfesora Auxiliar\n\n\nPh.D.¬†Jenny Carolina Castiblanco S."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores-1",
    "href": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores-1",
    "title": "Semillero en Procesamiento de Se√±ales e Imagenes",
    "section": "Plataforma para el monitoreo de salud de adultos mayores",
    "text": "Plataforma para el monitoreo de salud de adultos mayores\n\n\n\nDetecci√≥n ambulatoria de riesgo psico-social.\nDetecci√≥n ambulatoria de riesgo card√≠aco\nMonitorizaci√≥n de terapias ambulatorias para la rehabilitaci√≥n de adultos mayores\n\n\n\n\n\n\n\n\n\n\nProfesora Auxiliar\n\n\nPh.D.¬†Jenny Carolina Castiblanco S."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#creaci√≥n-de-ambientes-de-habitaci√≥n-saludables-usando-realimentaci√≥n-sensorial",
    "href": "presentaciones/TALLERES/Promise.html#creaci√≥n-de-ambientes-de-habitaci√≥n-saludables-usando-realimentaci√≥n-sensorial",
    "title": "Semillero en Procesamiento de Se√±ales e Imagenes",
    "section": "Creaci√≥n de ambientes de habitaci√≥n saludables usando realimentaci√≥n sensorial",
    "text": "Creaci√≥n de ambientes de habitaci√≥n saludables usando realimentaci√≥n sensorial\n\n\n\n\n\nNeurofeedback emocional usando m√∫sica.\nNeurofeedback de memoria procedimental.\nNeurofeedback en automotores.\nMonitorizaci√≥n ambulatoria de estado emocional.\nMonitorizaci√≥n ambulatoria de terapias emocionales"
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#apoyo-tecnol√≥gico-mediante-ia-a-intervenciones-cl√≠nicas",
    "href": "presentaciones/TALLERES/Promise.html#apoyo-tecnol√≥gico-mediante-ia-a-intervenciones-cl√≠nicas",
    "title": "Semillero en Procesamiento de Se√±ales e Imagenes",
    "section": "Apoyo tecnol√≥gico mediante IA a intervenciones cl√≠nicas",
    "text": "Apoyo tecnol√≥gico mediante IA a intervenciones cl√≠nicas\n\n\n\nDetecci√≥n de anomal√≠as en im√°genes mediante segmentaci√≥n heur√≠stica.\nPlaneaci√≥n pre-operatoria mediante el uso de inteligencia artificial.\nPlanificaci√≥n operatoria de sistemas rob√≥ticos.\nEvaluaci√≥n de espasticidad mediante el uso tecnolog√≠a."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#rehabilitaci√≥n-y-pr√≥tesis-inteligentes",
    "href": "presentaciones/TALLERES/Promise.html#rehabilitaci√≥n-y-pr√≥tesis-inteligentes",
    "title": "Semillero en Procesamiento de Se√±ales e Imagenes",
    "section": "Rehabilitaci√≥n y pr√≥tesis inteligentes",
    "text": "Rehabilitaci√≥n y pr√≥tesis inteligentes\n\n\n\n\n\n\n\n\n\n\nProfesora Auxiliar\n\n\nPh.D.¬†Jenny Carolina Castiblanco S.\n\n\n\n\n\n\nGeneraci√≥n de interfaces cerebro-computador\nGeneraci√≥n de algoritmos de clasificaci√≥n de intenci√≥n de movimiento\nMonitorizaci√≥n de terapias de rehabilitaci√≥n.\nUso de se√±ales DE origen biol√≥gico para controlar pr√≥tesis y exoesqueletos."
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant ‚Äúfree‚Äù sources of data\n\n\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Linear Regression",
    "text": "Linear Regression"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Linear Regression",
    "text": "Linear Regression\nIn the example, in previous slide, data was modelled as a linear function. The difference (error) between the modelled data \\(\\left( \\hat{y}_n \\right)\\) and actual data \\(\\left( y_n \\right)\\) can be written as\n\n\n\n\n\n\n\nCost function\n\n\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Some other examples of cost function",
    "text": "Some other examples of cost function\n\\[E = \\sqrt{\\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}}\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left| \\hat{y}_n - y_n \\right| }\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nLooking the cost surface, we notices that this surface has a global minimum. If we could have an algorithm which automatically finds it.\n\nCost Surface"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nIndeed, there are multiples algorithms for minima searching. The most famous is the one named as least squares but in this course we will use the gradient descent algorithm.\nAssuming that the data model is a function \\(f\\left(\\theta_i, x_n, y_n\\right)\\), where \\(\\theta\\) is known as model parameter.\n\n\n\n\n\n\n\nThe gradient descent algorithm\n\n\n\\[\\boldsymbol{\\theta}_{i,j+1} =  \\boldsymbol{\\theta}_{i,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{i}}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\nAssumptions\n\n\n\nLinear model for the Regression\nMean square error as cost function\n\\(\\eta = 1\\)\n\n\n\n\n\n\\[\\boldsymbol{\\theta}_i = \\left[ \\theta_1, \\theta_0 \\right]^T\\]\n\\[\\hat{y}_n  = \\theta_1 x_n + \\theta_0\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_1\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{1,j+1} = \\boldsymbol{\\theta}_{1,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right) x_n}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_0\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{0,j+1} = \\boldsymbol{\\theta}_{0,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  E & = & \\frac{1}{N} \\sqrt{u}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{1}{2 N \\sqrt{u}} \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}}\\\\\n  \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}} &=& 2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{2 N \\sqrt{u}}\n\\end{eqnarray}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} &=& \\frac{\\sum_{n=1}^{N}{x_n \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{2}} &=& \\frac{\\sum_{n=1}^{N}{x_n^2 \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\n\\end{eqnarray}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#what-is-convolution",
    "href": "presentaciones/ASIM/lect005_CNN.html#what-is-convolution",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "What is Convolution?",
    "text": "What is Convolution?\n\nConvolution: A mathematical operation used to extract features from input data.\nFilter/Kernels:\n\nA small matrix (e.g., 3x3) that slides over the input.\nDetects patterns such as edges, textures, and colors.\n\nStride: Number of pixels by which the filter moves at each step.\nPadding: Adds extra pixels around the border of the input, preserving spatial dimensions."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#convolution-in-action",
    "href": "presentaciones/ASIM/lect005_CNN.html#convolution-in-action",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Convolution in Action",
    "text": "Convolution in Action\n\nInput: A matrix of pixel values (e.g., an image).\nOutput (Feature Map): A matrix where each value represents the result of applying the filter over a region of the input."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#what-are-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#what-are-cnns",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "What are CNNs?",
    "text": "What are CNNs?\n\nDefinition: CNNs are deep learning models primarily used for visual recognition tasks.\nKey Concept: CNNs learn and detect hierarchical patterns in image data (e.g., edges, shapes, textures).\nImportance: Automatically extract features, reducing the need for manual feature engineering."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#why-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#why-cnns",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Why CNNs?",
    "text": "Why CNNs?\n\nFully Connected Networks struggle with large images due to high dimensionality.\nCNNs reduce the number of parameters by using local connectivity (convolutions) and weight sharing.\nEfficient in Learning: They exploit spatial hierarchies in images."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#cnn-architecture-overview",
    "href": "presentaciones/ASIM/lect005_CNN.html#cnn-architecture-overview",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "CNN Architecture Overview",
    "text": "CNN Architecture Overview\n\nInput Layer: Raw image data (e.g., 28x28 pixels for MNIST).\nConvolutional Layer: Detects features from input images using filters.\nActivation Function: Typically ReLU to introduce non-linearity.\nPooling Layer: Reduces the spatial dimensions (downsampling).\nFully Connected Layer: Performs classification based on extracted features."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#activation-function-relu",
    "href": "presentaciones/ASIM/lect005_CNN.html#activation-function-relu",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Activation Function (ReLU)",
    "text": "Activation Function (ReLU)\n\nPurpose: Introduce non-linearity into the network, allowing CNNs to learn complex patterns.\nReLU Formula: ( f(x) = (0, x) )\nWhy ReLU?:\n\nFaster convergence compared to sigmoid or tanh.\nAvoids the vanishing gradient problem."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#pooling-layers",
    "href": "presentaciones/ASIM/lect005_CNN.html#pooling-layers",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Pooling Layers",
    "text": "Pooling Layers\n\nPurpose: Reduce the spatial dimensions of feature maps, decrease computational load, and control overfitting.\nTypes of Pooling:\n\nMax Pooling: Selects the maximum value within a specified window.\nAverage Pooling: Calculates the average value within a specified window.\n\nBenefits:\n\nRetains the most important features (Max Pooling).\nSmooths the feature maps (Average Pooling).\n\nCommon Parameters:\n\nKernel Size: Size of the window (e.g., 2x2).\nStride: Step size for moving the window."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#fully-connected-layers",
    "href": "presentaciones/ASIM/lect005_CNN.html#fully-connected-layers",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Fully Connected Layers",
    "text": "Fully Connected Layers\n\nFlattening: Converts the 2D feature maps into a 1D vector for input into fully connected layers.\nFully Connected (Dense) Layers: Every neuron in the previous layer is connected to every neuron in the next layer.\nRole: Performs classification based on features learned from convolution and pooling layers."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#training-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#training-cnns",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Training CNNs",
    "text": "Training CNNs\n\nLoss Function: Cross-entropy loss is commonly used for classification tasks.\nOptimization: Backpropagation combined with optimizers like stochastic gradient descent (SGD) or Adam.\nTraining Concepts:\n\nEpochs: Number of complete passes over the dataset.\nMini-batches: Small subsets of the dataset used in each iteration."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#challenges",
    "href": "presentaciones/ASIM/lect005_CNN.html#challenges",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Challenges",
    "text": "Challenges\n\nComputational Resources: CNNs require powerful hardware (e.g., GPUs) for training large models.\nLarge Datasets: CNNs often need vast amounts of labeled data to perform well.\nOverfitting: Common problem in CNNs when trained on small datasets. Solutions include:\n\nData augmentation (rotating, flipping, or zooming images).\nDropout layers to randomly drop neurons during training."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#future-of-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#future-of-cnns",
    "title": "Aprendizaje autom√°tico para el procesamiento de se√±ales e im√°genes m√©dicas",
    "section": "Future of CNNs",
    "text": "Future of CNNs\n\nAdvanced Architectures:\n\nResidual Networks (ResNet):\n\nDeeper networks can be trained by using skip connections to bypass layers and avoid the vanishing gradient problem.\n\nInception Networks:\n\nUtilize multiple filters of different sizes in parallel to capture features at different scales.\n\nEfficientNet:\n\nBalances network depth, width, and resolution, creating more efficient models with fewer parameters while maintaining accuracy."
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#el-profesor",
    "title": "Sistemas y Se√±ales Biom√©dicas",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducaci√≥n\nDoctor en Ciencias de la Electr√≥nica. Magister en Ingenier√≠a Electr√≥nica y Telecomunicaciones Ingeniero en Electr√≥nica y Telecomunicaciones\nIntereses\nProcesamiento de Im√°genes, Dispositivos para el an√°lisis de movimiento humano, ciencia de los datos, IA.\n\nDesempe√±o\nProfesor del Centro de Estudios en Biom√©dica y Biotecnog√≠a\nProfesor en la l√≠nea de Procesmiento de Se√±ales e Im√°genes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Sistemas y Se√±ales Biom√©dicas",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducci√≥n al procesado de se√±ales.\nConceptos de se√±ales cont√≠nuas & discretas.\nMuestreo.\nExtracci√≥n de caracter√≠sticas de una se√±al.\nFiltraje de se√±ales."
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#estrateg√≠as-de-aprendizaje",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#estrateg√≠as-de-aprendizaje",
    "title": "Sistemas y Se√±ales Biom√©dicas",
    "section": "Estrateg√≠as de Aprendizaje",
    "text": "Estrateg√≠as de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluaci√≥n final\nPr√°cticas de laboratorio, donde se utilizar√°n herramientas computacionales y se aplicar√°n conocimientos y destrezas adquiridas en otros cursos\nLecturas de la tem√°tica a tratar, previas a las clases magistrales\nLecturas de art√≠culos cient√≠ficos de inter√©s para el √°rea de procesamiento de se√±ales e im√°genes\nDesarrollo de talleres fuera de la clase\nProyecto pr√°ctico de fin de curso"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#evaluaci√≥n",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#evaluaci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicas",
    "section": "Evaluaci√≥n",
    "text": "Evaluaci√≥n\n\n\n\nExamen parcial 1 (15%)\nExamen parcial 2 (15%)\nExamen final (20%)\nLaboratorios (30%)\nProyecto Final (20%)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#evaluaci√≥n-1",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#evaluaci√≥n-1",
    "title": "Sistemas y Se√±ales Biom√©dicas",
    "section": "Evaluaci√≥n",
    "text": "Evaluaci√≥n\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (15%)\nLaboratorios (15%)\nProyecto final (20%)\n\n\nExamen Parcial 1 (15%)\nExamen Parcial 2 (15%)\nExamen final (20%)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#recursos",
    "title": "Sistemas y Se√±ales Biom√©dicas",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nLunes 10:00am-11:30am F-204. Jueves 10:00am-11:30am F-206.\nLaboratorio\nMartes 10:00am-11:30am. I1-308\n\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#bibliograf√≠a",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#bibliograf√≠a",
    "title": "Sistemas y Se√±ales Biom√©dicas",
    "section": "Bibliograf√≠a",
    "text": "Bibliograf√≠a\n[1] ¬´Medical Image Analysis and Informatics¬ª.\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.¬™ ed.¬†Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. Ant√≥nio, C. Mora, y S. Jardim, ¬´Developments in Image Processing Using Deep Learning and Reinforcement Learning¬ª, J. Imaging, vol.¬†9, n.¬∫ 10, p.¬†207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, ¬´Biomedical Signal and Image Processing, Second Edition¬ª.\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.¬™ ed.¬†Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press‚ÄØ; CRC Press, 2022.\n[14] R. Raut, ¬´Intelligent Systems for Rehabilitation Engineering¬ª.\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, ¬´Biomedical Signal Analysis¬ª.\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et¬†al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et¬†al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.¬™ ed.¬†Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, ¬´Artificial Intelligence, Robots, and Philosophy¬ª.\n[23] L. N. McKinnis, ¬´Fundamentals of Musculoskeletal Imaging, Fifth Edition¬ª.\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et¬†al., ¬´Advances in Deep Learning-Based Medical Image Analysis¬ª, Health Data Sci, vol.¬†2021, p.¬†8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol.¬†228. en Intelligent Systems Reference Library, vol.¬†228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK‚ÄØ: Hoboken, NJ: ISTE‚ÄØ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, ¬´A review of the application of deep learning in medical image classification and segmentation¬ª, Ann Transl Med, vol.¬†8, n.¬∫ 11, pp.¬†713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed.¬†en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.¬™ ed.¬†NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#what-is-a-signal",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#what-is-a-signal",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "What is a signal?",
    "text": "What is a signal?\n\nA signal is a function that conveys information by mapping an independent variable (or variables) to measurable quantities.\nFormally, a signal is a mapping \\(x:\\ \\mathcal{T}\\rightarrow\\mathcal{A}\\), where \\(\\mathcal{T}\\) is the domain (e.g., time \\(t\\in\\mathbb{R}\\) or sample index \\(n\\in\\mathbb{Z}\\)) and \\(\\mathcal{A}\\) is the codomain (e.g., amplitudes in \\(\\mathbb{R}\\) or \\(\\mathbb{C}\\), vectors, or matrices)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Signal Classification",
    "text": "Signal Classification"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-bounded",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-bounded",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Signal Classification ‚Äì Bounded",
    "text": "Signal Classification ‚Äì Bounded"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-compact-support",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-compact-support",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Signal Classification ‚Äì Compact Support",
    "text": "Signal Classification ‚Äì Compact Support"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-causal",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-causal",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Signal Classification ‚Äì Causal",
    "text": "Signal Classification ‚Äì Causal"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---deterministic-vs-random-signals",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---deterministic-vs-random-signals",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Signal Classification - Deterministic vs Random Signals",
    "text": "Signal Classification - Deterministic vs Random Signals\n\nA deterministic signal \\(x_d(t)\\) is completely specified by an explicit rule; it produces the same waveform on every observation (e.g., \\(x_d(t)=A\\cos(2\\pi f_0 t+\\phi)\\)).\nA random signal (stochastic process) \\(X(t)\\) is a family of random variables indexed by \\(t\\); each observation yields a different realization. It is characterized statistically by its mean \\(\\mu_X(t)\\) and autocorrelation \\(R_X(\\tau)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---evenodd",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---evenodd",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Signal Classification - Even/Odd",
    "text": "Signal Classification - Even/Odd\n\n\n\n\n\n\n\n\n\nEven\n\n\n\\[f\\left(t\\right) = f\\left(-t\\right)\\] \\[f\\left[t\\right] = f\\left[-t\\right]\\]\n\n\n\n\n\n\n\n\n\n\n\nOdd\n\n\n\\[f\\left(t\\right) = -f\\left(-t\\right)\\] \\[f\\left[t\\right] = -f\\left[-t\\right]\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-1",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Signal Classification",
    "text": "Signal Classification\n\n\n\n\n\n\n\nDecomposition\n\n\nAll signal can be decomposed in two signals: one even, one odd.\n\\[x(t) = x_{even}(t) + x_{odd}(t)\\]\n\n\n\n\nWhere:\n\\[x_{even}(t) = \\frac{x(t)+x(-t)}{2} \\] \\[x_{odd}(t) = \\frac{x(t)-x(-t)}{2} \\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example",
    "text": "Example\n\n\n\n\n\n\n\nExample\n\n\nDecompose the signal \\(x(t)=e^{t}\\) into its even and odd parts"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-1",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example",
    "text": "Example\n\\[x_{\\text{even}}(t) = \\frac{x(t) + x(-t)}{2}\\]\n\\[x_{\\text{odd}}(t) = \\frac{x(t) - x(-t)}{2}\\]\n\\[x(-t) = e^{-t}\\]\n\\[x_{\\text{even}}(t) = \\frac{e^t + e^{-t}}{2} = \\cosh(t)\\]\n\\[x_{\\text{odd}}(t) = \\frac{e^t - e^{-t}}{2} = \\sinh(t)\\]\n\\[x(t) = x_{\\text{even}}(t) + x_{\\text{odd}}(t)\\]\n\\[e^t = \\cosh(t) + \\sinh(t)\\] ‚Äã"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-2",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-2",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---energy-vs-power-signals",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---energy-vs-power-signals",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Signal Classification - Energy vs Power Signals",
    "text": "Signal Classification - Energy vs Power Signals\nDefinitions. For a signal \\(x(t)\\) (continuous-time, CT) or \\(x[n]\\) (discrete-time, DT):\n\nEnergy: \\(E=\\int_{-\\infty}^{\\infty}\\lvert x(t)\\rvert^2,dt\\) (CT), \\(\\quad E=\\sum_{n=-\\infty}^{\\infty}\\lvert x[n]\\rvert^2\\) (DT).\nAverage power: \\(P=\\lim_{T\\to\\infty}\\dfrac{1}{2T}\\int_{-T}^{T}\\lvert x(t)\\rvert^2,dt\\) (CT), \\(\\quad P=\\lim_{N\\to\\infty}\\dfrac{1}{2N+1}\\sum_{n=-N}^{N}\\lvert x[n]\\rvert^2\\) (DT).\nEnergy signal: \\(0&lt;E&lt;\\infty\\) and \\(P=0\\) (e.g., \\(x_E(t)=e^{-a t}u(t)\\), \\(a&gt;0\\), with \\(E=\\tfrac{1}{2a}\\)).\nPower signal: \\(0&lt;P&lt;\\infty\\) and \\(E=\\infty\\) (e.g., \\(x_P(t)=\\cos(2\\pi f_0 t)\\), with \\(P=\\tfrac{1}{2}\\))."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-transformations",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Signal Transformations",
    "text": "Signal Transformations\nTypes of Transformations\nSignals can undergo two types of transformations:\n\nIndependent variable transformations (affect the time or input axis).\nDependent variable transformations (affect the amplitude or output axis)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#independent-variable-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#independent-variable-transformations",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Independent Variable Transformations",
    "text": "Independent Variable Transformations\nTime Scaling\n\nDefinition: Changes the time scale of the signal. [ x(at), a &gt; 1 , &lt; a &lt; 1 ]\nExample: If ( x(t) = (t) ), then ( x(2t) ) is compressed.\n\nTime Shifting\n\nDefinition: Shifts the signal in time. [ x(t - t_0) ]\nExample: ( x(t - 2) ) shifts the signal 2 units to the right.\n\nTime Reversal\n\nDefinition: Flips the signal across the vertical axis. [ x(-t) ]\nExample: If ( x(t) = t^2 ), then ( x(-t) = t^2 ) (even signal)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#dependent-variable-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#dependent-variable-transformations",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Dependent Variable Transformations",
    "text": "Dependent Variable Transformations\nAmplitude Scaling\n\nDefinition: Multiplies the amplitude by a scalar factor. [ a x(t), a &gt; 1 , &lt; a &lt; 1 ]\nExample: If ( x(t) = (t) ), then ( 2x(t) ) doubles the amplitude.\n\nAmplitude Shifting\n\nDefinition: Adds a constant value to the amplitude. [ x(t) + c ]\nExample: If ( x(t) = (t) ), then ( x(t) + 2 ) shifts the signal up by 2 units."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#combined-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#combined-transformations",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Combined Transformations",
    "text": "Combined Transformations\nExample\nConsider: [ y(t) = 2 x(3t - 1) + 1 ] 1. Time compression: ( x(3t) ) compresses the signal. 2. Time shift: ( x(3t - 1) ) shifts it to the right by 1 unit. 3. Amplitude scaling: ( 2 x(3t - 1) ) amplifies the signal. 4. Amplitude shift: ( +1 ) shifts it upward."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#visualization-example-in-python",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#visualization-example-in-python",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Visualization Example in Python",
    "text": "Visualization Example in Python"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#periodic-functions",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#periodic-functions",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Periodic functions",
    "text": "Periodic functions\n\n\n\n\n\n\n\n\nDefinition\n\n\nAny signal that meets any of this conditions \\[x\\left(t\\right)=x\\left(t + kT\\right)\\] \\[x\\left[n\\right]=x\\left[t + kN\\right]\\]\n\n\n\n\nWhere \\(k, N\\in\\mathbb{z}\\) and \\(T\\in\\mathbb{R}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#sum-of-two-periodic-signals",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#sum-of-two-periodic-signals",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Sum of Two Periodic Signals",
    "text": "Sum of Two Periodic Signals\nIf \\(\\left( x_1(t) \\right)\\) and \\(\\left( x_2(t) \\right)\\) are periodic with periods \\(\\left( T_1 \\right)\\) and \\(\\left( T_2 \\right)\\):\n\\[\nx_1(t + T_1) = x_1(t), \\quad x_2(t + T_2) = x_2(t)\n\\]\nThe sum of both signals is:\n\\[\nx(t) = x_1(t) + x_2(t)\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#condition-for-the-periodicity-of-the-sum",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#condition-for-the-periodicity-of-the-sum",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Condition for the Periodicity of the Sum",
    "text": "Condition for the Periodicity of the Sum\nFor \\(\\left( x(t) \\right)\\) to be periodic, there must exist a common period \\(\\left( T \\right)\\) such that:\n\\[\nT = k_1 T_1 = k_2 T_2\n\\]\nwhere \\(\\left( k_1, k_2 \\right)\\) are positive integers."
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#common-period-and-least-common-multiple",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#common-period-and-least-common-multiple",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Common Period and Least Common Multiple",
    "text": "Common Period and Least Common Multiple\nThe smallest common period is the least common multiple (lcm) of \\(\\left( T_1 \\right)\\) and \\(\\left( T_2 \\right)\\):\n\\[\nT = \\operatorname{lcm}(T_1, T_2)\n\\]\nIf the ratio of the periods is a rational number:\n\\[\n\\frac{T_1}{T_2} \\in \\mathbb{Q}\n\\]\nThen, the sum \\(\\left( x_1(t) + x_2(t) \\right)\\) will be periodic.\nIf the ratio is irrational, the resulting signal will not be periodic."
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#example",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#example",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Digital Filter ‚Äì Introduction",
    "text": "Digital Filter ‚Äì Introduction\n\n\n\nIt is a mathematical algorithm or system that processes digital signals.\nThey enhance, suppress, or modify specific frequency components.\nThese filters are essential for removing noise, extracting relevant information, and improving signal quality."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#what-is-a-system",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#what-is-a-system",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "What is a system?",
    "text": "What is a system?\nA system is a rule that maps an input signal to an output signal. In continuous time and discrete time we depict and denote: \\[\nx(t)\\ \\longrightarrow\\ y(t),\\qquad x[n]\\ \\longrightarrow\\ y[n].\n\\] These are the standard input‚Äìoutput representations used throughout the text."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#inputoutput-operator-notation",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#inputoutput-operator-notation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Input‚Äìoutput operator notation",
    "text": "Input‚Äìoutput operator notation\nWe often write the system as an operator ( {} ): \\[\ny(t)=\\mathcal{T}\\{x(t)\\},\\qquad y[n]=\\mathcal{T}\\{x[n]\\}.\n\\] Block diagrams are used to represent systems and interconnections (series/cascade and parallel)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#overview-what-is-an-inputoutput-relation",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#overview-what-is-an-inputoutput-relation",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Overview: what is an input‚Äìoutput relation?",
    "text": "Overview: what is an input‚Äìoutput relation?\nA system specifies how an input signal produces an output signal: \\[\nx(t)\\ \\longrightarrow\\ y(t),\\qquad x[n]\\ \\longrightarrow\\ y[n].\n\\] We study types of relations used in analysis and design: - Memoryless (static) mappings - Differential/difference-equation descriptions - Convolution (LTI) - Transform-domain forms (frequency, Laplace, (z)) - State‚Äìspace (first-order vector form) - Time-varying vs time-invariant, linear vs nonlinear"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#memoryless-static-relations",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#memoryless-static-relations",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Memoryless (static) relations",
    "text": "Memoryless (static) relations\nA memoryless or static system relates input and output at the same instant: \\[\ny(t)=F\\!\\big(x(t)\\big),\\qquad y[n]=F\\!\\big(x[n]\\big).\n\\] Examples: (y=|x|), (y=x^2), saturation and clipping nonlinearities. These are common as pointwise nonlinear stages preceding or following LTI blocks."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-differential-equations-ct",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-differential-equations-ct",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Linear constant-coefficient differential equations (CT)",
    "text": "Linear constant-coefficient differential equations (CT)\nMany continuous-time LTI systems are described by an LCCDE: \\[\n\\sum_{k=0}^{N} a_k\\,\\frac{d^{\\,k} y(t)}{dt^{\\,k}}\n\\;=\\;\n\\sum_{m=0}^{M} b_m\\,\\frac{d^{\\,m} x(t)}{dt^{\\,m}},\n\\qquad a_0\\neq 0.\n\\] Coefficients (a_k,b_m) are constants for time invariance. This form covers standard electrical/mechanical systems and filters."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-difference-equations-dt",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-difference-equations-dt",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Linear constant-coefficient difference equations (DT)",
    "text": "Linear constant-coefficient difference equations (DT)\nDiscrete-time LTI systems admit an LCCD equation: \\[\n\\sum_{k=0}^{N} a_k\\,y[n-k]\\;=\\;\\sum_{m=0}^{M} b_m\\,x[n-m],\\qquad a_0\\neq 0.\n\\] This representation includes IIR/FIR digital filters and many algorithmic recursions."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution-relations-lti",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution-relations-lti",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Convolution relations (LTI)",
    "text": "Convolution relations (LTI)\nFor LTI systems the input‚Äìoutput relation is convolution with the impulse response: \\[\ny(t)=\\int_{-\\infty}^{\\infty} h(\\tau)\\,x(t-\\tau)\\,d\\tau,\\qquad\ny[n]=\\sum_{k=-\\infty}^{\\infty} h[k]\\;x[n-k].\n\\] Here (h(t)) or (h[n]) is the output to a unit impulse. Causality for LTI corresponds to (h(t)=0) for (t&lt;0) (or (h[n]=0) for (n&lt;0))."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#frequency-domain-inputoutput-fourier",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#frequency-domain-inputoutput-fourier",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Frequency-domain input‚Äìoutput (Fourier)",
    "text": "Frequency-domain input‚Äìoutput (Fourier)\nWhen Fourier transforms exist, convolution becomes multiplication: \\[\nY(\\omega)=H(\\omega)\\,X(\\omega),\\qquad\nY\\!\\big(e^{j\\omega}\\big)=H\\!\\big(e^{j\\omega}\\big)\\,X\\!\\big(e^{j\\omega}\\big).\n\\] (H) is the frequency response (CTFT/DTFT). Magnitude (|H|) scales, phase (H) shifts/warps timing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#laplace-and-z-transform-forms",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#laplace-and-z-transform-forms",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Laplace and (z)-transform forms",
    "text": "Laplace and (z)-transform forms\nWith Laplace and (z)-transforms (for appropriate regions of convergence): \\[\nY(s)=H(s)\\,X(s),\\qquad Y(z)=H(z)\\,X(z),\n\\] and for LCCDE/LCCD systems \\[\nH(s)=\\frac{b_0+b_1 s+\\cdots+b_M s^M}{a_0+a_1 s+\\cdots+a_N s^N},\\qquad\nH(z)=\\frac{b_0+b_1 z^{-1}+\\cdots+b_M z^{-M}}{a_0+a_1 z^{-1}+\\cdots+a_N z^{-N}}.\n\\] These rational forms support pole‚Äìzero analysis and stability checks."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#statespace-first-order-vector-description",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#statespace-first-order-vector-description",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "State‚Äìspace (first-order vector) description",
    "text": "State‚Äìspace (first-order vector) description\nAn equivalent input‚Äìoutput formulation uses state variables: \\[\n\\dot{\\mathbf{s}}(t)=\\mathbf{A}\\,\\mathbf{s}(t)+\\mathbf{b}\\,x(t),\\qquad\ny(t)=\\mathbf{c}^\\top\\mathbf{s}(t)+d\\,x(t).\n\\] Discrete time: \\[\n\\mathbf{s}[n+1]=\\mathbf{A}\\,\\mathbf{s}[n]+\\mathbf{b}\\,x[n],\\qquad\ny[n]=\\mathbf{c}^\\top\\mathbf{s}[n]+d\\,x[n].\n\\] This first-order form is algebraically equivalent to LCCDE/LCCD for LTI systems."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#time-varying-vs-time-invariant-relations",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#time-varying-vs-time-invariant-relations",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Time-varying vs time-invariant relations",
    "text": "Time-varying vs time-invariant relations\n\nTime-invariant (TI): coefficients and operators do not change with time/index; shifts commute with the system.\nTime-varying (TV): coefficients depend on (t) or (n): \\[\n\\sum_{k=0}^{N} a_k(t)\\,\\frac{d^{\\,k} y(t)}{dt^{\\,k}}\n=\\sum_{m=0}^{M} b_m(t)\\,\\frac{d^{\\,m} x(t)}{dt^{\\,m}}.\n\\] TV models arise in modulated systems and adaptive filtering."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-vs-nonlinear-relations",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-vs-nonlinear-relations",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Linear vs nonlinear relations",
    "text": "Linear vs nonlinear relations\n\nLinear: superposition holds ‚Äî additivity and homogeneity.\nNonlinear: violates superposition; examples include squares, rectifiers, saturators, quantizers. Nonlinear stages are often analyzed locally or via small-signal linearization around an operating point."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#stochastic-inputoutput-lti-summary",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#stochastic-inputoutput-lti-summary",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Stochastic input‚Äìoutput (LTI summary)",
    "text": "Stochastic input‚Äìoutput (LTI summary)\nFor wide-sense stationary (WSS) inputs to an LTI system: \\[\n\\mu_y=\\mu_x\\,H(0)\\ \\text{(when defined)},\\qquad\nS_{yy}(\\omega)=\\big|H(\\omega)\\big|^2\\,S_{xx}(\\omega).\n\\] This links input and output statistics through (H), supporting noise and SNR analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#interconnections-examples",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#interconnections-examples",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Interconnections (examples)",
    "text": "Interconnections (examples)\n\nSeries (cascade): output of System 1 feeds System 2.\nParallel: both systems process the same input; outputs are summed. These patterns are foundational for building complex systems from simpler ones."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-memoryless-vs.-with-memory",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-memoryless-vs.-with-memory",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Property: Memoryless vs.¬†with memory",
    "text": "Property: Memoryless vs.¬†with memory\n\nMemoryless: the output at an instant depends only on the input at that same instant.\nWith memory: the output depends on past/future values (e.g., accumulators, averagers). Example: the summer/accumulator (running sum) and its inverse (first difference) illustrate systems with memory: \\[\ny[n]=\\sum_{k=-\\infty}^{n} x[k],\\qquad \\text{inverse: } y[n]=x[n]-x[n-1].\n\\] Both are causal (see next slide)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-causality-general-and-lti",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-causality-general-and-lti",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Property: Causality (general and LTI)",
    "text": "Property: Causality (general and LTI)\nCausal: output depends only on present/past input values. For LTI systems, causality is characterized by the impulse response: \\[\n\\text{Discrete time: } h[n]=0\\ \\text{for } n&lt;0;\\qquad\n\\text{Continuous time: } h(t)=0\\ \\text{for } t&lt;0.\n\\] Under these conditions, the convolution reduces to depend only on past/present input."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-stability-bibo",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-stability-bibo",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Property: Stability (BIBO)",
    "text": "Property: Stability (BIBO)\nBounded-Input Bounded-Output (BIBO) stability: bounded input implies bounded output. For LTI systems: \\[\n\\sum_{k=-\\infty}^{\\infty} |h[k]| &lt; \\infty \\quad \\Longleftrightarrow \\quad \\text{discrete-time LTI is stable},\n\\] \\[\n\\int_{-\\infty}^{\\infty} |h(t)|\\,dt &lt; \\infty \\quad \\Longleftrightarrow \\quad \\text{continuous-time LTI is stable}.\n\\] These are necessary and sufficient conditions."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-linearity-superposition",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-linearity-superposition",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Property: Linearity (superposition)",
    "text": "Property: Linearity (superposition)\nA system is linear if it satisfies additivity and homogeneity: for any signals (x_1,x_2) and scalar (c), \\[\n\\mathcal{T}\\{x_1+x_2\\}=\\mathcal{T}\\{x_1\\}+\\mathcal{T}\\{x_2\\},\\qquad \\mathcal{T}\\{c\\,x\\}=c\\,\\mathcal{T}\\{x\\}.\n\\] (These two conditions together are equivalent to linearity.)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-time-invariance-definition",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-time-invariance-definition",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Property: Time invariance (definition)",
    "text": "Property: Time invariance (definition)\nA system is time-invariant if a shift in the input produces an identical shift in the output: \\[\n\\mathcal{T}\\{x(t-t_0)\\}=y(t-t_0),\\ \\text{whenever}\\ y(t)=\\mathcal{T}\\{x(t)\\}.\n\\] Analogously in discrete time with shifts by integer indices. (Definition used throughout the text in system properties and LTI analysis.)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-invertibility",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-invertibility",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Property: Invertibility",
    "text": "Property: Invertibility\nA system is invertible if distinct inputs produce distinct outputs; equivalently, there exists an inverse system that recovers the input from the output. Example pair (discrete time): the accumulator and the first-difference operator are inverses: \\[\ny[n]=\\sum_{k=-\\infty}^{n} x[k] \\quad \\Longleftrightarrow \\quad x[n]=y[n]-y[n-1].\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#additional-note-interconnections-and-lti-analysis",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#additional-note-interconnections-and-lti-analysis",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Additional note: Interconnections and LTI analysis",
    "text": "Additional note: Interconnections and LTI analysis\nFor LTI systems, interconnections admit simple algebraic descriptions via transforms: e.g., in the Laplace domain, series and parallel lead to product and sum of system functions, respectively: \\[\nH_{\\text{series}}(s)=H_1(s)H_2(s),\\qquad H_{\\text{parallel}}(s)=H_1(s)+H_2(s).\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-1",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Digital Filter ‚Äì Introduction",
    "text": "Digital Filter ‚Äì Introduction\n\n\n\n\n\n\n\nImportante\n\n\nThe digital filter separates the noise and the information of a discrete signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-2",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-2",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Digital Filter ‚Äì Introduction",
    "text": "Digital Filter ‚Äì Introduction"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-3",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-3",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Digital Filter ‚Äì Introduction",
    "text": "Digital Filter ‚Äì Introduction\n\n\n\n\n\n\n\n\nSuppose a discrete time system \\[ y[n] = \\sum_{k=1}^{K} a_k y[n - k] + \\sum_{m=0}^{M} b_m x[n - m]\\]\n\nK y M are the order of the filter.\nWe must know the initial condition."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#examples-of-digital-filters",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#examples-of-digital-filters",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Examples of digital filters",
    "text": "Examples of digital filters\n\n\n\n\n\n\n\n\n\nGain\n\n\n\\[y[n] = G x[n]\\]\n\n\n\n\n\n\n\n\n\n\n\nDelay of \\(n_0\\) samples\n\n\n\\[y[n] = x[n - n_0]\\]\n\n\n\n\n\n\n\n\n\n\n\nTwo points moving average\n\n\n\\[y[n] = \\frac{1}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\n\n\n\nEuler approximation of the derivative\n\n\n\\[y[n] = \\frac{x[n] - x[n - 1]}{T_s}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nAveraging over N consecutive epochs of duration L\n\n\n\\[y[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} x[n - kL]\\]\n\n\n\n\n\n\n\n\n\n\n\nTrapezoidal integration formula\n\n\n\\[y[n] = y[n - 1] + \\frac{T_s}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\n\n\n\nDigital ‚Äúleaky integrator‚Äù (First-order lowpass filter)\n\n\n\\[y[n] = a y[n - 1] + x[n], \\quad 0 &lt; a &lt; 1\\]\n\n\n\n\n\n\n\n\n\n\n\nDigital resonator (Second-order system)\n\n\n\\[y[n] = a_1 y[n - 1] + a_2 y[n - 2] + b x[n], \\quad a_1^2 + 4a_2 &lt; 0\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#the-impulse-response",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#the-impulse-response",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "The impulse response",
    "text": "The impulse response\n\n\n\n\n\n\n\n\n\nThe impulse response, denoted as \\(‚Ñé[n]\\), is the output of a digital filter when the input is a unit impulse function \\(\\delta[n]\\)\nThe impulse response fully describes the system. Given \\(h[n]\\), we can determine the output for any input using convolution.\nDifferent types of filters (low-pass, high-pass, band-pass, etc.) have characteristic impulse responses."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#conditions",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#conditions",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Conditions",
    "text": "Conditions\nFor a system‚Äôs response to be fully described by its impulse response, the system must satisfy the following key conditions.\n\n\n\n\n\n\n\nLinearity\n\n\nIf the system responds to \\(x_1[n]\\) with \\(y_1[n]\\) and to \\(x_2[n]\\) with \\(y_2[n]\\), then:\n\\[y[n] = y_1[n] + y_2[n]\\]\n\n\n\n\n\n\n\n\n\n\n\nHomogeneity\n\n\nIf the input is scaled by a constant \\(c\\), the output is also scaled:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } cx[n] \\rightarrow cy[n]\\]\n\n\n\n\n\n\n\n\n\n\n\nTime Invariance\n\n\nA system must be time-invariant, meaning a time shift in the input causes the same shift in the output:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } x[n - n_0] \\rightarrow y[n - n_0]\\]\n\n\n\n\n\n\n\n\n\n\n\nCausality\n\n\nA causal system is one where the output at time \\(n\\) depends only on present and past inputs:\n\\[h[n] = 0 \\quad \\forall n &lt; 0\\]\n\n\n\n\n\n\n\n\n\n\n\nStability\n\n\nIf the impulse response does not satisfy this condition, the system may produce unbounded outputs.\n\\[\\sum_{n=-\\infty}^{\\infty} |h[n]| &lt; \\infty\\]\n\n\n\n\n\n\n\n\n\n\n\nConvolution Representation\n\n\nIf all condition met then \\[y[n] = x[n] * h[n] = \\sum_{m=-\\infty}^{\\infty} x[m] h[n - m]\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Convolution",
    "text": "Convolution"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction to data adquisition",
    "text": "Introduction to data adquisition\n\n\n\nThere are two main roles in data: capture the information and encode the data in a form tha machine can process.\nData adquisition has three stages:\n\nTransduction\nSignal conditioning\nAnalog-to-digital conversion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction to data adquisition - Transduction",
    "text": "Introduction to data adquisition - Transduction\n\n\n\nTransduction is the conversion from one form of energy to another.\nThe only energy suitable for computer processing is the electrical\nTherefore signals need to be converted to analog voltages whose waveforms are ideally the same as those of the original signals.\nExist two components a captured signal: one component carries the information (signal), the other one is a probabilistic distorsion of the information(noise)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nNoise refers to any unwanted or random variations in a signal that interfere with the desired information. It is an unpredictable disturbance that can distort or obscure the actual data, making it harder to interpret or analyze.\n\n\n\n\nTypes of noise\n\nThermal Noise (Random Noise)\nElectromagnetic Interference (EMI)\nMotion Artifacts\nPhysiological Noise\nQuantization Noise"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\nModelling the noise\n\nAdditive White Gaussian Noise (AWGN): Modeled as a random process with a normal distribution.\nBand-limited Noise: Affects only specific frequency ranges and can be removed with filters.\nAdditive Noise: Adds directly to the original signal.\nMultiplicative Noise: Multiplies the original signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\nGraphsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Par√°metros de la se√±al\nduration = 2  # Duraci√≥n en segundos\nfs = 1000  # Frecuencia de muestreo en Hz\nt = np.linspace(0, duration, duration * fs, endpoint=False)  # Vector de tiempo\n\n# Se√±al senoidal de 10 Hz\nfreq = 10\nsine_wave = np.sin(2 * np.pi * freq * t)\n\n# Se√±al de ruido aleatorio con distribuci√≥n normal\nnoise_normal = np.random.normal(0, 1, len(t))\n\n# Se√±al con ruido aleatorio de 2 a 5 Hz\nlow_freq_noise = np.sin(2 * np.pi * np.random.uniform(2, 5) * t)\nsignal_with_low_freq_noise = sine_wave + low_freq_noise\n\n# Se√±al con ruido aleatorio uniforme sumado\nuniform_noise = np.random.uniform(-0.5, 0.5, len(t))\nsignal_with_uniform_noise = sine_wave + uniform_noise\n\n# Se√±al con ruido aleatorio uniforme multiplicado\nmultiplicative_noise = np.random.uniform(0.5, 1.5, len(t))\nsignal_with_mult_noise = sine_wave * multiplicative_noise\n\n# Graficamos las se√±ales\nfig, axes = plt.subplots(5, 1, figsize=(10, 10), sharex=True)\n\naxes[0].plot(t, sine_wave, label=\"Sine wave (10 Hz)\")\naxes[0].set_title(\"Sine Wave (10 Hz)\")\naxes[0].legend()\n\naxes[1].plot(\n    t, noise_normal, label=\"Random Noise (Normal Distribution)\", color=\"orange\"\n)\naxes[1].set_title(\"Random Noise (Normal Distribution)\")\naxes[1].legend()\n\naxes[2].plot(\n    t, signal_with_low_freq_noise, label=\"Sine + Low Freq Noise (2-5 Hz)\", color=\"green\"\n)\naxes[2].set_title(\"Sine + Low Freq Noise (2-5 Hz)\")\naxes[2].legend()\n\naxes[3].plot(t, signal_with_uniform_noise, label=\"Sine + Uniform Noise\", color=\"red\")\naxes[3].set_title(\"Sine + Uniform Noise\")\naxes[3].legend()\n\naxes[4].plot(t, signal_with_mult_noise, label=\"Sine * Uniform Noise\", color=\"purple\")\naxes[4].set_title(\"Sine * Uniform Noise\")\naxes[4].legend()\n\nplt.xlabel(\"Time [s]\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction to data adquisition - ASP",
    "text": "Introduction to data adquisition - ASP\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAnalog signal processing (ASP) refers to the manipulation of continuous-time signals after they have been acquired from a transducer but before digital conversion. This type of processing is performed using electronic circuits that modify the signal in the analog domain to enhance its quality, extract useful information, or prepare it for further processing.\n\n\n\n\n\n\n\n\n\n\n\nCommon tasks\n\n\n\nAmplification: Increases the signal strength to match the required voltage levels. Example: ECG signals are weak (~1 mV) and need to be amplified before analysis.\nFiltering: Removes unwanted frequency components such as noise or interference.\nModulation/Demodulation: Used for communication systems where signals are modulated onto a higher-frequency carrier wave. Example: Biomedical telemetry systems use amplitude modulation (AM) or frequency modulation (FM) to transmit patient data wirelessly.\nDifferentiation & Integration: Differentiation: Highlights rapid changes in the signal. Example: Used in QRS detection for ECG signal analysis. Integration: Smooths out signals and accumulates values over time. Example: Used in electromyography (EMG) processing to estimate muscle activation.\nSignal Conditioning: Includes impedance matching, offset correction, and dynamic range adjustments. Example: Removing DC offsets in biosignals before digitization."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Introduction to data adquisition - analog-to-digital convertion",
    "text": "Introduction to data adquisition - analog-to-digital convertion\n\n\n\n\n\n\n\nDefinition\n\n\nAn analog-to-digital converter (ADC) is a device that converts a continuous-time signal, obtained through a transducer, into a digital signal that can be processed by a computer. This process consists of two fundamental operations, which occur simultaneously in practical implementations: sampling and quantization.\n\n\n\n\nOperations\n\nSampling involves converting the continuous-time analog signal into a discrete-time signal, where the amplitude remains unrestricted.\nQuantization then maps this continuous-amplitude signal to a finite set of discrete values, making it fully digital."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-in-dsp-purpose-and-context",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-in-dsp-purpose-and-context",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Quantization in DSP: Purpose and Context",
    "text": "Quantization in DSP: Purpose and Context\n\nQuantization maps continuous amplitudes to a finite set of levels to enable digital representation.\nIn acquisition chains: anti-alias filter ‚Üí sampling ‚Üí ADC quantization.\nQuantization introduces an error that behaves like noise under standard assumptions.\nBiomedical relevance: ECG, EEG, EMG, and PPG require appropriate bit depth, gain, and dynamic range to preserve diagnostically relevant features."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#uniform-quantizer-definitions",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#uniform-quantizer-definitions",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Uniform Quantizer: Definitions",
    "text": "Uniform Quantizer: Definitions\n\nInput range: \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\), bit depth \\(b\\), levels \\(L=2^b\\), step size (LSB)\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nMid-tread (round-to-nearest): \\(Q(x)=\\Delta,\\mathrm{round}!\\big(x/\\Delta\\big)\\).\nMid-rise (truncate + half-step): \\(Q(x)=\\Delta\\big(\\lfloor x/\\Delta\\rfloor+\\tfrac12\\big)\\).\nOverload/clipping outside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\): \\(\\tilde{x}=V\\_{\\max}\\) or \\(V\\_{\\min}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#decision-thresholds-and-codebook",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#decision-thresholds-and-codebook",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Decision Thresholds and Codebook",
    "text": "Decision Thresholds and Codebook\n\nDecision thresholds at \\(k\\Delta\\); reconstruction levels at:\n\n\\(k\\Delta\\) (mid-tread), or\n\\((k+\\tfrac12)\\Delta\\) (mid-rise).\n\nPractical note: choose mid-tread for rounding semantics; mid-rise for deterministic staircase without zero level."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-error-model-and-power",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-error-model-and-power",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Quantization Error: Model and Power",
    "text": "Quantization Error: Model and Power\n\nError \\(e=x-Q(x)\\). Under high-resolution assumptions (no clipping, sufficiently dense input):\n\n\\(e=x-Q(x)\\sim\\mathcal{U}\\left[-\\tfrac{\\Delta}{2},\\tfrac{\\Delta}{2}\\right]\\), \\(\\mathbb{E}\\left[e\\right]=0\\), \\(\\mathrm{Var}(e)=\\Delta^2/12\\).\n\nFor a full-scale sinusoid:\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nWith RMS usage fraction \\(\\rho\\) of full scale (FS):\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#effective-number-of-bits-enob",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#effective-number-of-bits-enob",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Effective Number of Bits (ENOB)",
    "text": "Effective Number of Bits (ENOB)\n\nFrom a measured in-band SNR (RMS, same bandwidth):\n\\[\n\\mathrm{ENOB}\\approx\\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]\nUse ENOB to compare real converters (including clock jitter, distortion) against ideal \\(b\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#input-range-analog-gain-and-clipping",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#input-range-analog-gain-and-clipping",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Input Range, Analog Gain, and Clipping",
    "text": "Input Range, Analog Gain, and Clipping\n\nAnalog gain \\(G\\) maps input to ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\Delta/G\\).\nDesign goals:\n\nAvoid overload for rare peaks; 2) Use a large fraction of FS (e.g., \\(50\\)‚Äì\\(80%\\)) to improve SNR."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#biomedical-example-ecg-acquisition",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#biomedical-example-ecg-acquisition",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Biomedical Example: ECG Acquisition",
    "text": "Biomedical Example: ECG Acquisition\n\nSuppose electrode-level ECG peaks \\(\\approx \\pm 5,\\mathrm{mV}\\). Choose \\(G=200\\) so \\(\\pm 5,\\mathrm{mV}\\mapsto \\pm 1,\\mathrm{V}\\) at ADC (\\(V\\_{\\min,\\max}=\\pm 1,\\mathrm{V}\\)).\nWith \\(b=12\\):\n\n\\(\\Delta=\\dfrac{2,\\mathrm{V}}{2^{12}}\\approx 0.488,\\mathrm{mV}\\) (ADC domain).\n\\(\\Delta\\_{\\text{in}}=\\Delta/G\\approx 2.44,\\mu\\mathrm{V}\\).\nInput-referred noise RMS \\(\\sigma\\_q=\\Delta\\_{\\text{in}}/\\sqrt{12}\\approx 0.704,\\mu\\mathrm{V}\\_{\\mathrm{RMS}}\\).\n\nIf \\(\\rho\\approx 0.5\\), then \\(\\mathrm{SNR}\\approx 6.02\\cdot 12 + 1.76 - 6 \\approx 68,\\mathrm{dB}\\) ‚Üí typically adequate for diagnostic ECG."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#non-uniform-quantization-and-companding-brief",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#non-uniform-quantization-and-companding-brief",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Non-Uniform Quantization and Companding (Brief)",
    "text": "Non-Uniform Quantization and Companding (Brief)\n\nFor highly non-uniform amplitude distributions, companding allocates effective resolution to small amplitudes.\n\\(\\mu\\)-law (telephony):\n\\[\ny=\\mathrm{sgn}(x)\\,\\frac{\\ln\\big(1+\\mu |x|/X_{\\max}\\big)}{\\ln(1+\\mu)},\\quad \\mu\\approx 255.\n\\]\nIn biomedicine, primary acquisition usually remains linear; companding is more relevant to low-bit-rate telemetry or storage."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#dither-when-and-why",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#dither-when-and-why",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Dither: When and Why",
    "text": "Dither: When and Why\n\nAdd small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization to decorrelate error, eliminate bias/patterning at low levels, and linearize averages.\nSlight SNR penalty but improved fidelity for low-level features (e.g., EEG baselines)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#practical-design-checklist",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#practical-design-checklist",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Practical Design Checklist",
    "text": "Practical Design Checklist\n\nChoose \\(b\\) to exceed clinical SNR requirements by \\(10\\)‚Äì\\(20,\\mathrm{dB}\\).\nSet \\(G\\) so typical peaks use \\(50\\)‚Äì\\(80%\\) FS; verify worst-case spikes do not clip.\nFull noise budget: electrode + amplifier + ADC quantization + clock jitter (for high \\(f\\)).\nValidate with calibrated sources and report ENOB over the intended bandwidth."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#python-demo-ecg-quantization-at-multiple-bit-depths",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#python-demo-ecg-quantization-at-multiple-bit-depths",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Python Demo: ECG Quantization at Multiple Bit Depths",
    "text": "Python Demo: ECG Quantization at Multiple Bit Depths\n\n# Synthetic ECG, quantization at 8/10/12 bits, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nfs = 360.0\nT = 5.0\nt = np.arange(0, T, 1/fs)\n\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\ndef ecg_template(t):\n    P = g(t, 0.20, 0.045,  0.10)\n    Q = g(t, 0.36, 0.010, -0.25)\n    R = g(t, 0.40, 0.012,  1.00)\n    S = g(t, 0.44, 0.016, -0.35)\n    Tn= g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + Tn\n\nhr = 60.0\nRR = 60.0/hr\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    ecg_mV += ecg_template(t - k*RR)\n\nwander = 0.05*np.sin(2*np.pi*0.3*t)\nnoise  = 0.02*np.random.randn(len(t))\necg_mV = ecg_mV + wander + noise\n\nG = 200.0\nVfs = 1.0\nVmin, Vmax = -Vfs, Vfs\nx_adc = (ecg_mV/1000.0)*G  # mV -&gt; V and gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)\n    return y, Delta\n\ndef snr_db(x, y):\n    e = x - y\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\nprint(\"Summary (ADC domain):\")\n\nSummary (ADC domain):\n\nfor b in bits_list:\n    print(f\"{b:2d}-bit -&gt; LSB Œî = {results[b]['Delta']*1e3:.3f} mV, Measured SNR ‚âà {results[b]['snr_db']:5.1f} dB\")\n\n 8-bit -&gt; LSB Œî = 7.812 mV, Measured SNR ‚âà  24.1 dB\n10-bit -&gt; LSB Œî = 1.953 mV, Measured SNR ‚âà  36.0 dB\n12-bit -&gt; LSB Œî = 0.488 mV, Measured SNR ‚âà  48.1 dB\n\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Œî_in = {Delta_in*1e6:.3f} ¬µV, œÉ_q ‚âà {sigma_q_in*1e6:.3f} ¬µV RMS\")\n\n\nInput-referred (12-bit): Œî_in = 2.441 ¬µV, œÉ_q ‚âà 0.705 ¬µV RMS\n\n# Plot 1: original vs quantized (10-bit)\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n# Plot 2: quantization error histogram (8-bit)\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\nTo explain the analog-to-digital conversion process, we will assume that the input signal is a cosine wave with frequency \\(F\\), angular frequency \\(\\Omega\\) and amplitude \\(a\\).\n\\[x\\left(t\\right) = a \\cos\\left(\\Omega t + \\phi\\right) = a \\cos\\left(2\\pi F t + \\phi\\right)\\]\nObtaining\n\\[x\\left[n\\right] = a \\cos\\left(\\omega n + \\phi\\right) = a \\cos\\left(2\\pi f n + \\phi\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\n\n\n\n\n\n\n\nWhat?\n\n\nMathematically, the sampling process is:\n\\[x[n] = x(nT_s), \\quad -\\infty &lt; n &lt; \\infty\\]\n\n\n\n\nReplacing in previous equations, we have the expression:\n\\[x[n] = x(nT_s) = a \\cos\\left( 2\\pi F n T_s + \\phi \\right) = a \\cos\\left( 2\\pi n \\frac{F}{F_s} + \\phi \\right)\n\\]\nWhere:\n\\[\\omega = \\Omega T_s, \\quad f = \\frac{F}{F_s}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Sample and quantization of an ECG signal",
    "text": "Sample and quantization of an ECG signal\n\nTaskGraphCode\n\n\n\nGenerate a synthetic ECG-like signal.\nSample it at different rates.\nApply quantization with different bit depths.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import chirp\n\n# Generate a synthetic ECG-like signal (chirp function as approximation)\nfs_original = 10000  # High sampling rate (Hz) - \"continuous\" signal\nt = np.linspace(0, 1, fs_original, endpoint=False)  # 1-second signal\nsignal = np.sin(2 * np.pi * 1.7 * (t**2))  # Simulated chirp (similar to ECG waves)\n\n# Downsample (Sampling Process)\nfs_sampled = 200  # Sampling frequency in Hz (e.g., ECG sampled at 200 Hz)\nt_sampled = np.arange(0, 1, 1/fs_sampled)\nsignal_sampled = np.sin(2 * np.pi * 1.7 * (t_sampled**2))\n\n# Quantization (8-bit and 4-bit)\ndef quantize(signal, bits):\n    levels = 2**bits\n    min_val, max_val = signal.min(), signal.max()\n    step = (max_val - min_val) / levels\n    quantized_signal = np.round((signal - min_val) / step) * step + min_val\n    return quantized_signal\n\nsignal_quantized_8bit = quantize(signal_sampled, 8)\nsignal_quantized_4bit = quantize(signal_sampled, 4)\n\n# Plot Results\nplt.figure(figsize=(12, 6))\n\n# Original vs Sampled Signal\nplt.subplot(2, 1, 1)\nplt.plot(t, signal, 'k', alpha=0.3, label='Original Signal (High Resolution)')\nplt.plot(t_sampled, signal_sampled, 'ro-', label=f'Sampled Signal ({fs_sampled} Hz)')\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Sampling Process\")\n\n# Quantized Signals\nplt.subplot(2, 1, 2)\nplt.plot(t_sampled, signal_sampled, 'bo-', alpha=0.5, label=\"Original Sampled\")\nplt.plot(t_sampled, signal_quantized_8bit, 'go-', label=\"Quantized 8-bit\")\nplt.plot(t_sampled, signal_quantized_4bit, 'ro-', label=\"Quantized 4-bit\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Quantization Effect\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\n\nBio - That came from a biological being\nSignal - A signal is a function that conveys information about a physical phenomenon.\nBiosignals - The search for information from living systems to know its health state"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\nThe codification of biosignals into variations: * Electrical * Mechanical * Chemical * Thermal"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1791: Luigi Galvani discovers electrical signals in living tissues (frog legs)\n1830s: Carlo Matteucci studies electrical signals in the heart\n1887: Willem Einthoven invents the first electrocardiograph (ECG)\n1900s: James Mackenzie develops the first clinical ECG machine"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1920s: Electroencephalography (EEG) is developed by Hans Berger\n1930s: Electromyography (EMG) is developed by John Humphrey and others\n1940s: Development of the first commercial ECG machines\n1950s: Signal processing techniques are applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1960s: Digital signal processing and computer analysis of biomedical signals emerge\n1970s: Biomedical signal processing becomes a recognized field\n1980s: Development of Holter monitoring (24-hour ECG)\n1990s: Advances in signal processing and machine learning applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n2000s: Development of wearable devices and mobile health (mHealth) technologies\n2010s: Emergence of big data analytics and cloud computing in biomedical signal processing\n2020s: Integration of artificial intelligence (AI) and machine learning (ML) in biomedical signal processing"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1895: Wilhelm Roentgen discovers X-rays, leading to medical imaging\n1900s: X-ray technology improves with development of modern X-ray tubes\n1913: Albert Salomon develops mammography\n1920s: Ultrasound technology is developed by Karl Dussik and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1930s: Nuclear medicine emerges with development of radioactive tracers\n1950s: Computed Tomography (CT) scans are developed by Godfrey Hounsfield and Allan McLeod Cormack\n1960s: Development of medical ultrasound imaging\n1970s: Magnetic Resonance Imaging (MRI) is developed by Richard Ernst and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1980s: Digital image processing and analysis techniques are applied to biomedical images\n1990s: Advances in MRI and CT scan technology, including 3D imaging\n2000s: Development of functional MRI (fMRI), diffusion tensor imaging (DTI), and other advanced MRI techniques\n2010s: Emergence of artificial intelligence (AI) and machine learning in medical imaging"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Time line",
    "text": "Time line\nAdditional Milestones:\n\n1950s: Development of medical electronics and instrumentation\n1960s: First medical imaging computers are developed\n1970s: Development of digital image processing and analysis software\n1980s: Emergence of medical imaging informatics and PACS (Picture Archiving and Communication Systems)\n1990s: Development of telemedicine and teleradiology\n2000s: Emergence of electronic health records (EHRs) and health information exchanges (HIEs)\n2010s: Development of personalized medicine and precision health initiatives"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\n\n\n\n\n\n\nDefinition\n\n\nAn experiment is a physical procedure that produces some kind of result.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAn event is a set of experiment‚Äôs possible results.\n\n\n\n\n\n\n\n\n\n\n\nConsejo\n\n\nA sample space is the set of ALL possibles results of an experiment."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\nGraphCodeSample SpaceResultDataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata = np.genfromtxt(\"../../data/mitbih_train.csv\", delimiter=\",\")\necg1 = data[1, :-1]\ntime = np.array(range(0,len(ecg1)))/125\nfig = plt.figure()\nplt.plot(time, ecg1)\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Normalized ECG\")\n\n\n\n\nprint(\"Maximun Value: \"+ str(ecg1.max()))\n\nMaximun Value: 1.0\n\nprint(\"Minimun Value: \"+ str(ecg1.min()))\n\nMinimun Value: 0.0\n\n\n\n\n\nprint(ecg1[np.random.choice(ecg1.shape[0], 1, replace=False)])\n\n[0.]\n\n\n\n\nName: ECG Heartbeat Categorization Dataset.\nURL: https://www.kaggle.com/datasets/shayanfazeli/heartbeat?resource=download"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Probability Axioms",
    "text": "Probability Axioms\nFor the given events A and B that are in a sample space S:\n\n\n\n\n\n\n\nAxioms\n\n\n\n\\(0 \\leq P_r \\left(A\\right) \\leq 1\\)\n\\(P_r\\left(S\\right) = 1\\)\nIf \\(A \\cap B = \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right)\\)\nIf \\(A \\cap B \\neq \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right) - P_r\\left(A \\cap B \\right)\\)\n\\(P_r\\left(\\bar{A}\\right) = 1-P_r \\left(A\\right)\\)\nIf \\(A\\subset B\\) then \\(P_r \\left(A\\right)\\leq P_r \\left(B\\right)\\)\n\\(P_r \\left(A|B\\right)=\\frac{P_r \\left(A\\cap B\\right)}{P_r \\left(B\\right)}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable\n\n\n\n\n\n\n\nDefinition\n\n\nA random variable is a real valued function of the elements of a sample space, S . Given an experiment, E , with sample space, S, the random variable maps each possible outcome of E.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nThe probability mass function (PMF), \\(P_X\\left(x\\right)\\), of a random variable, X, is a function that assigns a probability to each possible value of the random variable, X."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nConditions\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sum_{\\chi \\in X}P_X\\left(\\chi \\right) = 1\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\int_{-\\infty}^{\\infty}P_X\\left(\\chi \\right)d\\chi = 1\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nExpected Values\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\mu = \\sum_{\\chi \\in X}\\chi P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\mu=\\int_{-\\infty}^{\\infty}\\chi P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nVariance\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sigma^2 = \\sum_{\\chi \\in X}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\sigma^2 = \\int_{-\\infty}^{\\infty}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "PDF Estimation",
    "text": "PDF Estimation\n\nGraphCodeExp. ValueVariance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncounts01, bin_edges01 = np.histogram(ecg1, bins=10, density=True)\ncounts02, bin_edges02 = np.histogram(ecg1, bins=50, density=True)\ncounts03, bin_edges03 = np.histogram(ecg1, bins=100, density=True)\nfig01=plt.figure()\nplt.plot(bin_edges01[1:], counts01/sum(counts01), label=\"Estimation with 10 bins\")\nplt.plot(bin_edges02[1:], counts02/sum(counts02), label=\"Estimation with 50 bins\")\nplt.plot(bin_edges03[1:], counts03/sum(counts03), label=\"Estimation with 100 bins\")\nplt.legend()\nplt.grid()\nplt.xlabel(\"Normalised ECG Value\")\nplt.ylabel(\"Estimated PDF Value\")\n\n\n\n\n\n0.09001020772910533\n\n\n\n\n\n\n0.02551116143316462"
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#importance-of-frequency-response-filters",
    "href": "presentaciones/PSIM/prueba.html#importance-of-frequency-response-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Importance of Frequency-Response Filters",
    "text": "Importance of Frequency-Response Filters\n\nFrequency-response filters are critical for enhancing specific features or reducing noise in images.\nWidely used in MRI, CT, and ultrasound imaging."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#what-is-a-frequency-response-filter",
    "href": "presentaciones/PSIM/prueba.html#what-is-a-frequency-response-filter",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "What is a Frequency-Response Filter?",
    "text": "What is a Frequency-Response Filter?\n\nA frequency-response filter modifies the frequency components of a signal.\nApplied in image processing to control which frequencies (details) pass or are suppressed."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#types-of-frequency-response-filters",
    "href": "presentaciones/PSIM/prueba.html#types-of-frequency-response-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Types of Frequency-Response Filters",
    "text": "Types of Frequency-Response Filters\n\nLow-pass filters: Allow low frequencies, suppress high frequencies (smoothes image).\nHigh-pass filters: Allow high frequencies, suppress low frequencies (sharpens image).\nBand-pass filters: Allow frequencies in a certain range."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#spatial-vs.-frequency-domain",
    "href": "presentaciones/PSIM/prueba.html#spatial-vs.-frequency-domain",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Spatial vs.¬†Frequency Domain",
    "text": "Spatial vs.¬†Frequency Domain\n\nSpatial domain: Operations on pixel values directly.\nFrequency domain: Operations on the image‚Äôs frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#fourier-transform",
    "href": "presentaciones/PSIM/prueba.html#fourier-transform",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Fourier Transform",
    "text": "Fourier Transform\n\nConverts an image from the spatial domain to the frequency domain.\nFormula: \\[F\\left(u,v\\right) = \\sum\\sum f\\left(x,y\\right) e^{-j2\\pi(\\frac{ux}{M} + \\frac{vy}{N})}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#low-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#low-pass-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Low-Pass Filters",
    "text": "Low-Pass Filters\n\nRemoves high-frequency components (e.g., noise, sharp edges).\nExample: Gaussian filter, Butterworth filter."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#high-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#high-pass-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "High-Pass Filters",
    "text": "High-Pass Filters\n\nEnhances edges and high-frequency details.\nExample: Laplacian filter."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#band-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#band-pass-filters",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Band-Pass Filters",
    "text": "Band-Pass Filters\n\nAllows frequencies within a specific range.\nUseful for isolating specific image features."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#noise-reduction-in-mri",
    "href": "presentaciones/PSIM/prueba.html#noise-reduction-in-mri",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Noise Reduction in MRI",
    "text": "Noise Reduction in MRI\n\nLow-pass filters reduce noise and artifacts in MRI scans.\nSmoothes the image without losing crucial details."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#edge-enhancement-in-ultrasound-images",
    "href": "presentaciones/PSIM/prueba.html#edge-enhancement-in-ultrasound-images",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Edge Enhancement in Ultrasound Images",
    "text": "Edge Enhancement in Ultrasound Images\n\nHigh-pass filters help in detecting tissue boundaries by enhancing edges.\nImproves clarity of anatomical structures."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#feature-extraction-in-ct-scans",
    "href": "presentaciones/PSIM/prueba.html#feature-extraction-in-ct-scans",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Feature Extraction in CT Scans",
    "text": "Feature Extraction in CT Scans\n\nFilters can help in extracting features like tumors or vessels.\nBand-pass filters isolate structures of interest at specific frequency ranges."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "href": "presentaciones/PSIM/prueba.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process",
    "text": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process\n\nLoad MRI image.\nApply Fourier Transform to move the image into the frequency domain.\nDesign and apply a low-pass filter.\nPerform Inverse Fourier Transform to return to the spatial domain.\nVisualize the result."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#summary",
    "href": "presentaciones/PSIM/prueba.html#summary",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Summary",
    "text": "Summary\n\nFrequency-response filters play a crucial role in biomedical image processing.\nHelp enhance key features and suppress unwanted noise."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#future-trends",
    "href": "presentaciones/PSIM/prueba.html#future-trends",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Future Trends",
    "text": "Future Trends\n\nDeep learning integration with traditional filters.\nDevelopment of adaptive filters for real-time processing."
  },
  {
    "objectID": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "href": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Sources of data",
    "text": "Sources of data\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#what-is-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#what-is-thresholding",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "What is Thresholding?",
    "text": "What is Thresholding?\n\nDefinition: A technique to separate objects from the background in images.\nConcept: Converting a grayscale image into a binary image.\nImportance: Simplification for further analysis (e.g., edge detection, segmentation)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#global-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#global-thresholding",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Global Thresholding",
    "text": "Global Thresholding\n\nExplanation of Global Thresholding.\nExample of a fixed threshold ( T ):\n\nIf ( I(x, y) &gt; T ), the pixel becomes white (1), otherwise black (0).\n\nLimitations: Sensitivity to uneven lighting."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#adaptive-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#adaptive-thresholding",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Adaptive Thresholding",
    "text": "Adaptive Thresholding\n\nDefinition of Adaptive Thresholding.\nInstead of a global threshold, the threshold is calculated for different regions of the image.\nAdvantages: Effective in images with varying illumination.\nAlgorithm: Example of an adaptive method based on the local mean of neighboring pixels."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#otsus-algorithm",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#otsus-algorithm",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Otsu‚Äôs Algorithm",
    "text": "Otsu‚Äôs Algorithm\n\nExplanation of Otsu‚Äôs Algorithm.\n\nAutomatic global thresholding that minimizes the within-class variance.\n\nSteps of the algorithm:\n\nCompute image histograms.\nEvaluate the between-class variance function for every possible threshold.\nSelect the threshold that minimizes the within-class variance.\n\nAdvantages: Automatic and effective in bimodal images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#justification-for-using-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#justification-for-using-thresholding",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Justification for Using Thresholding",
    "text": "Justification for Using Thresholding\n\nWhen thresholding is useful:\n\nImages with a clear contrast between the object and the background.\nSituations requiring quick segmentation.\n\nExample applications:\n\nText detection, object recognition, medical images (e.g., X-rays).\n\nLimitations: Less effective in noisy or low-quality images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#comparison-of-thresholding-algorithms",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#comparison-of-thresholding-algorithms",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Comparison of Thresholding Algorithms",
    "text": "Comparison of Thresholding Algorithms\n\n\n\n\n\n\n\n\n\n\nMethod\nPrecision\nProcessing Speed\nEase of Implementation\nTypical Applications\n\n\n\n\nGlobal Threshold\nMedium\nFast\nSimple\nHigh-contrast images\n\n\nAdaptive Threshold\nHigh\nModerate\nModerate\nUnevenly lit images\n\n\nOtsu‚Äôs Algorithm\nHigh\nModerate\nModerate\nBimodal distributions"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nShow examples of original images and the result after applying:\n\nGlobal Thresholding.\nAdaptive Thresholding.\nOtsu‚Äôs Algorithm.\n\nVisualizations highlighting the differences."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples-1",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples-1",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nResultsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.imshow(image_circle, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nplt.imshow(image_gradient, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nplt.imshow(noisy_circle, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh1 = cv2.threshold(image_circle, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh1, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh2 = cv2.threshold(image_gradient, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh3 = cv2.threshold(noisy_circle, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh1 = cv2.adaptiveThreshold(image_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh1, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh2 = cv2.adaptiveThreshold(image_gradient, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh3 = cv2.adaptiveThreshold(noisy_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, otsu_thresh1 = cv2.threshold(image_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh1, cmap=\"gray\")\nplt.axis(\"off\");\nplt.show()\n\n_, otsu_thresh2 = cv2.threshold(image_gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, otsu_thresh3 = cv2.threshold(noisy_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#conclusion-and-questions",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#conclusion-and-questions",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Conclusion and Questions",
    "text": "Conclusion and Questions\n\nSummary of key points:\n\nThresholding as a simple yet powerful technique.\nImportance of choosing the right algorithm depending on the context.\nOtsu‚Äôs algorithm as an effective solution for bimodal images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-morphological-operations",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Introduction to Morphological Operations",
    "text": "Introduction to Morphological Operations\n\nDefinition: Morphological operations apply a structuring element to an image to alter its structure.\nFocus: Primarily used for binary images.\nKey applications: Noise removal, object extraction, shape analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#structuring-element",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#structuring-element",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Structuring Element",
    "text": "Structuring Element\n\nA small matrix used to probe and interact with a given image.\nCommon shapes: Rectangular, circular, elliptical.\nExample: A 3x3 square structuring element.\n\n\\[\\begin{bmatrix}\n  1 & 1 & 1 \\\\\n  1 & 1 & 1 \\\\\n  1 & 1 & 1 \\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#common-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#common-morphological-operations",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Common Morphological Operations",
    "text": "Common Morphological Operations\n\nErosion:\n\nRemoves pixels on object boundaries.\nShrinks the size of objects in the image.\nUsed to eliminate small noise or detach connected objects.\n\nDilation:\n\nAdds pixels to object boundaries.\nEnlarges the object in an image.\nHelps fill small holes and gaps within objects.\n\nOpening:\n\nErosion followed by dilation.\nUsed to remove small objects (noise) while maintaining the shape of larger objects.\n\nClosing:\n\nDilation followed by erosion.\nFills small holes and gaps in an object‚Äôs boundaries.\n\nTop-Hat Transformation:\n\nThe difference between the original image and its opening.\nUsed to highlight bright regions on a dark background.\nDetecting small, bright objects or details in an unevenly illuminated image.\n\nBlack-Hat Transformation:\n\nThe difference between the closing of an image and the original image.\nUsed to highlight dark regions on a bright background.\nEmphasizing dark objects or shadows in an image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#example-of-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#example-of-morphological-operations",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Example of Morphological Operations",
    "text": "Example of Morphological Operations"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-frequency-response",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-frequency-response",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Introduction to Frequency Response",
    "text": "Introduction to Frequency Response\n\nWhat is Frequency Response?\n\nThe frequency response of an image shows how spatial details in the image are distributed across different frequencies.\nIn image processing, this is typically analyzed using the Fourier Transform.\n\nWhy Frequency Analysis?\n\nUseful for identifying patterns, noise, and image structures not easily observed in the spatial domain."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-fourier-transform",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-fourier-transform",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "The Fourier Transform",
    "text": "The Fourier Transform\n\nFourier Transform (FT):\n\nConverts an image from the spatial domain (pixels) to the frequency domain (sinusoids).\nEach point in the frequency domain represents a specific frequency in the image.\n\nMathematical Basis:\n\n\\(F(u,v) = \\sum_x \\sum_y f(x,y) e^{-j 2 \\pi (ux/M + vy/N)}\\)\nWhere \\(F(u,v)\\) is the frequency representation of the image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-and-high-frequencies",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-and-high-frequencies",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Low and High Frequencies",
    "text": "Low and High Frequencies\n\nLow Frequencies:\n\nRepresent slow variations or large structures in the image (e.g., background or smooth gradients).\n\nHigh Frequencies:\n\nRepresent rapid variations or fine details (e.g., edges, noise).\n\nKey Insight: Most of the important structural information in an image is captured in the low-frequency range."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-domain-representation",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-domain-representation",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Frequency Domain Representation",
    "text": "Frequency Domain Representation\n\nThe Fourier Transform of an image produces a frequency spectrum.\nDC Component (center of the spectrum): Represents the average intensity of the image.\nHigher frequencies: Spread out from the center and capture finer details.\nLogarithmic scale: Often used to visualize the frequency spectrum due to the wide range of values."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-2d-discrete-fourier-transform-dft",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-2d-discrete-fourier-transform-dft",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "The 2D Discrete Fourier Transform (DFT)",
    "text": "The 2D Discrete Fourier Transform (DFT)\n\nThe 2D DFT is used to convert a 2D image into its frequency components:\n\nInput: A 2D grayscale image.\nOutput: A complex matrix representing amplitude and phase for each frequency.\n\nInverse DFT: Converts the frequency representation back to the spatial domain."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-pass-and-high-pass-filtering",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-pass-and-high-pass-filtering",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Low-Pass and High-Pass Filtering",
    "text": "Low-Pass and High-Pass Filtering\n\nLow-Pass Filter (LPF):\n\nAllows low frequencies to pass, attenuates high frequencies.\nUsed to blur images, removing high-frequency details like noise and edges.\n\nHigh-Pass Filter (HPF):\n\nAllows high frequencies to pass, attenuates low frequencies.\nUsed to sharpen images by enhancing edges and fine details."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#band-pass-filtering",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#band-pass-filtering",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Band-Pass Filtering",
    "text": "Band-Pass Filtering\n\nBand-Pass Filter:\n\nAllows frequencies within a certain range (band) to pass.\nUseful for selectively enhancing specific frequency components while filtering others.\n\nApplications: Used in image enhancement and texture analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-response-visualization",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-response-visualization",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Frequency Response Visualization",
    "text": "Frequency Response Visualization\n\nMagnitude Spectrum:\n\nRepresents the amplitude of each frequency component.\nTypically visualized using the logarithmic scale to manage the large range of values.\n\nPhase Spectrum:\n\nRepresents the phase of each frequency component.\nLess important for human perception but crucial for reconstructing the image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#applications-of-frequency-domain-processing",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#applications-of-frequency-domain-processing",
    "title": "Procesado de Se√±ales e Im√°genes M√©dicas",
    "section": "Applications of Frequency Domain Processing",
    "text": "Applications of Frequency Domain Processing\n\nNoise Removal: Low-pass filters can smooth out high-frequency noise.\nEdge Detection: High-pass filters enhance edges and sharp transitions.\nImage Compression: Frequency domain analysis helps identify redundant information.\nPattern Recognition: Useful for detecting repetitive patterns like textures."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\nData acquisition is to capture the signal and encode in a form suitable for computer processing.\nSignal conditioning is to remove noise and artifacts from the signal.\nFeature extraction is to extract relevant information from the signal.\nHypothesis testing is to test the hypothesis based on the extracted features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Signal condtioning",
    "text": "Signal condtioning\n\n\n\n\n\n\n\nBase Information\n\n\n\nA 12-lead electrocardiogram for arrhythmia study - Article\nA 12-lead electrocardiogram for arrhythmia study - Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning\n\ndata  = sio.loadmat(path_ecg+\"/JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\nprint(data.keys())\n\ndict_keys(['val'])\n\nprint(type(data['val']))\n\n&lt;class 'numpy.ndarray'&gt;\n\nprint(data['val'].shape)\n\n(12, 5000)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "title": "Procesamiento de Se√±ales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Edge AI",
    "text": "Edge AI\n\n\n\n\n\n\n\nDefinition\n\n\nEdge AI Is the combination of EDGE devices and Artificial Intelligence Algorithms\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nThe accelerometer-based wristband sensor."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI\n\nTaken from ‚ÄúEdge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing‚Äù (Zhou et. al., Proceedings of the IEEE, 2019)"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI\n\n\n\n\n\n\n\nEmbedded ML\n\n\n\nEmbedded ML is the art and science of running machine learning models on embedded systems.\nEmbedded ML, we‚Äôre usually refers to machine learning inference.\nThe training part usually still takes place on a conventional computer.\nHigh requirements of ROM(Model Storing), RAM(Storing intermediate results), computer capabilities(computational intensive tasks).\nEmbedded machine learning is often deployed alongside digital signal processing algorithms\nTiny machine learning, or TinyML, is the concept of doing this on the most constrained embedded hardware available."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-3",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-3",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "BLERP",
    "text": "BLERP\n\n\n\n\n\n\n\n\n\nBandwith\n\n\nIt‚Äôs related to the quantity of information you could send via some kind of connection. More bandwith it‚Äôs needed to send more data. Example: Imagine a smart sensor that monitors the vibration of an magnetic resonator to determine if it is operating correctly. It might use a simple thresholding algorithm to understand when the machine is vibrating too much, or not enough, and then communicate this information via a low bandwidth radio connection.\n\n\n\n\n\n\n\n\n\n\n\nLatency\n\n\nIt‚Äôs related to the time you must wait for the reponse of the sensor. Example: Edge AI solves this problem by removing the round-trip time altogether. A great example of this is a self-driving car. The car‚Äôs AI systems run on onboard computers. This allows it to react nearly instantly to changing conditions, like the driver in front slamming on their brakes.\n\n\n\n\n\n\n\n\n\n\n\n\nEconomy\n\n\nConnectivity costs a lot of money. By processing data on-device, edge AI systems reduce or avoid the costs of transmitting data over a network and processing it in the cloud. Example: Edge AI enables healthcare providers to monitor patients in real time without sending data to the cloud for processing. For example, wearable devices with built-in AI algorithms can analyze physiological signals such as heart rate, oxygen levels, and ECG data locally. This reduces the reliance on cloud services for data transmission and processing.\n\n\n\n\n\n\n\n\n\n\n\nReliability\n\n\nSystems controlled by on-device AI are potentially more reliable than those that depend on a connection to the cloud. When you add wireless connectivity to a device, you‚Äôre adding a vast, overwhelmingly complex web of dependencies, from link-layer communications technologies to the internet servers that may run your application. Example: Traditional Cloud-Based Systems: Data collected by wearable devices must be transmitted to a cloud server, analyzed, and then results are sent back to caregivers or emergency responders. This can introduce delays due to network latency or connectivity issues. Edge AI Systems: Processes the sensor data locally in real time, enabling instant detection of falls or other anomalies.Improvement: Reduces detection and response time from minutes to milliseconds, ensuring immediate action during emergencies.\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy\n\n\nEdge AI provides an alternative. Rather than streaming live video and audio to a remote server, a security camera could use some onboard intelligence to identify that an intruder is present when the owners are out at work. It could then alert the owners in an appropriate way. When data is processed on an embedded system and is never transmitted to the cloud, user privacy is protected and there is less chance of abuse."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "What is Linux",
    "text": "What is Linux\n\nDefinition: Linux is a free, open-source operating system (OS) based on Unix, created by Linus Torvalds in 1991.\nKey Features:\n\nOpen-source: Anyone can view, modify, and distribute the source code.\nFree to use: No licensing fees.\nMulti-user and multitasking.\n\nStructure: Comprises a kernel (core of the OS) and various utilities."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\nControls the hardware.\nTypes of linux kernel\n\nMonolithic kernel: All the concurrent processes are executed simultaneously in the kernel itself. All the processes share same memory recourses.\nMicro kernel: user services and kernel services are executed in separate address spaces. User services are kept in user address space and kernel services are kept in kernel address space.\nHybrid kernel: this kernel has the monolithic speed and the stability of the micro.\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nShell\n\n\nThe shell serves as an interface to the kernel, acting as a bridge between the user and the system‚Äôs core operations. It hides the internal workings of the kernel, allowing users to perform tasks without needing to understand the underlying processes. Users simply enter a command, and the shell leverages the kernel‚Äôs functions to execute the specified task.\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "href": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Why is Linux Popular?",
    "text": "Why is Linux Popular?\n\nFlexibility: Runs on a wide range of devices (PCs, servers, smartphones, embedded systems).\nSecurity: Highly secure and less vulnerable to malware.\nCommunity Support: Strong open-source community for development and troubleshooting.\nCustomization: Highly configurable; users can tailor it to specific needs.\nPerformance: Efficient resource utilization, ideal for servers and low-end devices."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Linux vs Other Operating Systems",
    "text": "Linux vs Other Operating Systems\n\n\n\n\n\n\n\n\n\nFeature\nLinux\nWindows\nmacOS\n\n\n\n\nCost\nFree\nPaid\nPaid\n\n\nSource Code\nOpen-source\nProprietary\nProprietary\n\n\nSecurity\nHighly secure\nVulnerable to malware\nSecure\n\n\nCustomization\nHigh\nLow\nLow\n\n\nUsage\nServers, DevOps, IoT\nDesktop, Gaming\nCreative industries"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Linux Distributions",
    "text": "Linux Distributions\n\nWhat are Distributions (Distros)?\nVariants of Linux tailored for specific purposes.\nPopular Distros:\n\nUbuntu: User-friendly, great for beginners.\nDebian: Stable and widely supported.\nFedora: Cutting-edge technologies.\nCentOS/Red Hat: Enterprise-level stability.\nKali Linux: Security and penetration testing."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Applications of Linux",
    "text": "Applications of Linux\n\nEveryday Use: Desktops and laptops (e.g., Ubuntu, Mint).\nServers: Powers most web servers, databases, and cloud infrastructure.\nEmbedded Systems: Used in IoT devices, routers, and automotive systems.\nSupercomputers: Runs on 100% of the top 500 supercomputers.\nProgramming & Development: Preferred OS for software developers."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nMachine Learning (ML) is a data-driven approach to building predictive models.\nIt is used in various applications such as healthcare, finance, and automation.\nIt is based on identifying patterns in data to make predictions or decisions."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nML enables systems to learn from experience without being explicitly programmed.\nKey application areas include image recognition, natural language processing, and autonomous systems."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Types of Machine Learning ‚Äì Supervised Learning",
    "text": "Types of Machine Learning ‚Äì Supervised Learning\nSupervised Learning: - Uses labeled data to train models. - Example: Spam detection in emails (spam vs.¬†non-spam). - Common algorithms: Linear Regression, Decision Trees, Support Vector Machines (SVM), Neural Networks."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Types of Machine Learning ‚Äì Unsupervised Learnin",
    "text": "Types of Machine Learning ‚Äì Unsupervised Learnin\nUnsupervised Learning: - Finds patterns in unlabeled data. - Example: Customer segmentation in marketing. - Common algorithms: K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Types of Machine Learning ‚Äì Reinforcement Learning",
    "text": "Types of Machine Learning ‚Äì Reinforcement Learning\nReinforcement Learning: - Optimizes decision-making through rewards. - Example: Training an AI to play a game like Chess or Go. - Key components: Agent, Environment, Reward Signal."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nData:\n\nThe quality and quantity of data are fundamental.\nData preprocessing (cleaning, normalization, feature extraction) is crucial.\n\nModel:\n\nA mathematical representation of the problem.\nChosen based on the problem type (classification, regression, clustering)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nError function:\n\nEvaluates the difference between prediction and actual value.\nExample: Mean Squared Error (MSE) for regression, Cross-Entropy Loss for classification.\n\nOptimization:\n\nAlgorithms that adjust the model parameters to minimize error.\nCommon optimization techniques: Gradient Descent, Adam Optimizer."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nInductive Bias:\n\nPrior assumptions that the model uses to generalize.\nExample: Linear models assume data relationships are linear.\n\nSample Bias:\n\nDifferences between training data and real-world data.\nExample: A face recognition system trained on a specific demographic may perform poorly on others."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nBias-Variance Tradeoff:\n\nHigh Bias (Underfitting): The model is too simple, failing to capture patterns.\nHigh Variance (Overfitting): The model memorizes training data but fails on new data."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Example of Bias and Variance",
    "text": "Example of Bias and Variance"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n1. Linear Regression (Supervised Learning - Regression)\n\nPredicts a continuous value based on input features.\nEquation: ( y = mx + b )\nExample: Predicting house prices based on square footage.\n\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept¬†\nTrue\n\n\n\ncopy_X¬†\nTrue\n\n\n\ntol¬†\n1e-06\n\n\n\nn_jobs¬†\nNone\n\n\n\npositive¬†\nFalse\n\n\n\n\n            \n        \n    \n\n\nSlope: [0.6]\n\n\nIntercept: 2.2"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n2. Decision Trees (Supervised Learning - Classification & Regression)\n\nSplits data into decision nodes to make predictions.\nExample: Diagnosing a disease based on symptoms.\n\n\n\nDecisionTreeClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFitted\n        \n            \n                Parameters\n                \n\n\n\n\ncriterion¬†\n'gini'\n\n\n\nsplitter¬†\n'best'\n\n\n\nmax_depth¬†\nNone\n\n\n\nmin_samples_split¬†\n2\n\n\n\nmin_samples_leaf¬†\n1\n\n\n\nmin_weight_fraction_leaf¬†\n0.0\n\n\n\nmax_features¬†\nNone\n\n\n\nrandom_state¬†\nNone\n\n\n\nmax_leaf_nodes¬†\nNone\n\n\n\nmin_impurity_decrease¬†\n0.0\n\n\n\nclass_weight¬†\nNone\n\n\n\nccp_alpha¬†\n0.0\n\n\n\nmonotonic_cst¬†\nNone\n\n\n\n\n            \n        \n    \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n3. K-Means Clustering (Unsupervised Learning)\n\nGroups similar data points together.\nExample: Customer segmentation in marketing.\n\n\n\nCluster Centers: [[10.  2.]\n [ 1.  2.]]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n4. Support Vector Machines (SVM) (Supervised Learning - Classification)\n\nFinds a hyperplane that best separates different classes.\nExample: Classifying tumors as benign or malignant.\n\n\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVC?Documentation for SVCiFitted\n        \n            \n                Parameters\n                \n\n\n\n\nC¬†\n1.0\n\n\n\nkernel¬†\n'rbf'\n\n\n\ndegree¬†\n3\n\n\n\ngamma¬†\n'scale'\n\n\n\ncoef0¬†\n0.0\n\n\n\nshrinking¬†\nTrue\n\n\n\nprobability¬†\nFalse\n\n\n\ntol¬†\n0.001\n\n\n\ncache_size¬†\n200\n\n\n\nclass_weight¬†\nNone\n\n\n\nverbose¬†\nFalse\n\n\n\nmax_iter¬†\n-1\n\n\n\ndecision_function_shape¬†\n'ovr'\n\n\n\nbreak_ties¬†\nFalse\n\n\n\nrandom_state¬†\nNone\n\n\n\n\n            \n        \n    \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n5. Reinforcement Learning Example\n\nUses rewards and penalties to train an agent to make optimal decisions.\nExample: A robot learning to navigate a maze.\n\n\n\nTrained Q-Table:\n [[0.2466039  0.30491591 0.43210016 0.45426578 0.67886292]\n [0.31971819 0.43955893 0.65332032 1.00092929 0.91142778]\n [0.3930344  0.52962554 0.99451373 1.66961098 1.9197123 ]\n [0.55984869 0.78313723 1.77069055 2.80966222 5.20428534]\n [0.67139363 1.13164264 2.20812197 4.9621132  0.        ]]"
  },
  {
    "objectID": "tutoriales/TutorialPython.html",
    "href": "tutoriales/TutorialPython.html",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Tomado del libro Ciencia de Datos para Ciencias Naturales\nSi no tiene experiencia con el lenguaje Markdown utilice esta gu√≠a para enriquecer sus celdas de texto.\n\n\n\nPlataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar c√≥digo Python o R a trav√©s del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de c√≥digo\n\n\n\n\n\nNo requiere configuraci√≥n del programa.\nLa mayor√≠a de librer√≠as y programas ya est√°n preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos.\n\n\n\n\n\nNo se ejecuta sin conexi√≥n.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perder√°n cuando la m√°quina virtual se apague.\nExperiencia m√°s sencilla que otras opciones.\nPermite utilizar m√°s lenguajes: Posgres, Julia.\n\n\n\n\n\nC√≥digo: Para abrir una celda de c√≥digo simplemente haga click en la barra + C√≥digo. Para ejecutar el c√≥digo puede presionar el s√≠mbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#caracter√≠sticas",
    "href": "tutoriales/TutorialPython.html#caracter√≠sticas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Plataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar c√≥digo Python o R a trav√©s del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de c√≥digo"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#ventajas",
    "href": "tutoriales/TutorialPython.html#ventajas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No requiere configuraci√≥n del programa.\nLa mayor√≠a de librer√≠as y programas ya est√°n preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "href": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No se ejecuta sin conexi√≥n.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perder√°n cuando la m√°quina virtual se apague.\nExperiencia m√°s sencilla que otras opciones.\nPermite utilizar m√°s lenguajes: Posgres, Julia."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "href": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "C√≥digo: Para abrir una celda de c√≥digo simplemente haga click en la barra + C√≥digo. Para ejecutar el c√≥digo puede presionar el s√≠mbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#strings",
    "href": "tutoriales/TutorialPython.html#strings",
    "title": "Tutorial de Python",
    "section": "Strings",
    "text": "Strings\n\ncadena_caracteres = \" Diplomado en Anal√≠tica para la Banca \"\n\n#Tama√±o de la cadena de caracteres\nprint(len(cadena_caracteres))\n\n#Corte de variable\nprint(cadena_caracteres[0:10])\nprint(cadena_caracteres[20:30])\n\n#Convertir la variable a may√∫sculas\nprint(cadena_caracteres.upper())\n\n#Convertir la variable a min√∫scula\nprint(cadena_caracteres.lower())\n\n#Contar cuantas veces aparece una cadena de caracteres\nprint(cadena_caracteres.count(\"ca\"))\n\n#Reemplazar en una cadena, una letra con otra\nprint(cadena_caracteres.replace(\"a\", \"0\"))\n\n#Partir la cadena de caracteres cada vez que se encuentre un caracter\nprint(cadena_caracteres.split(\" \"))\n\n#Concatenar dos cadenas de caracteres\ncadena01 = \"Pablo Eduardo\"\ncadena02 = \"Caicedo Rodr√≠guez\"\nprint(cadena01+\" \"+cadena02)\n\n38\n Diplomado\nica para l\n DIPLOMADO EN ANAL√çTICA PARA LA BANCA \n diplomado en anal√≠tica para la banca \n2\n Diplom0do en An0l√≠tic0 p0r0 l0 B0nc0 \n['', 'Diplomado', 'en', 'Anal√≠tica', 'para', 'la', 'Banca', '']\nPablo Eduardo Caicedo Rodr√≠guez"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#listas",
    "href": "tutoriales/TutorialPython.html#listas",
    "title": "Tutorial de Python",
    "section": "Listas",
    "text": "Listas\n\nlista = [3, 2, 1, 0.5, \"hora del cafe\", \"torta chilena\", \"pinto\", \"jugo\"]\nprint(lista)\nlista.append(\"empanadita\")\nprint(lista)\n\"pinto\" in lista\n\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo']\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo', 'empanadita']\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#diccionarios",
    "href": "tutoriales/TutorialPython.html#diccionarios",
    "title": "Tutorial de Python",
    "section": "Diccionarios",
    "text": "Diccionarios\n\ntel = {'Maria': 4098, 'Jorge': 4139}\nprint(tel)\nprint(tel[\"Maria\"])\nprint(tel.keys())\nprint(tel.values)\n'Maria' in tel\n\n{'Maria': 4098, 'Jorge': 4139}\n4098\ndict_keys(['Maria', 'Jorge'])\n&lt;built-in method values of dict object at 0x7e59e414c580&gt;\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tuplas",
    "href": "tutoriales/TutorialPython.html#tuplas",
    "title": "Tutorial de Python",
    "section": "Tuplas",
    "text": "Tuplas\n\nfrutas = ('naranja', 'mango', 'sandia', 'banano', 'kiwi')\nprint(type(frutas))\nfrutas[1]\n\n&lt;class 'tuple'&gt;\n\n\n'mango'"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#numpy",
    "href": "tutoriales/TutorialPython.html#numpy",
    "title": "Tutorial de Python",
    "section": "Numpy",
    "text": "Numpy\nNumPy (Numerical Python), es una biblioteca de Python que da soporte para crear vectores y matrices grandes multidimensionales, junto con una gran colecci√≥n de funciones matem√°ticas de alto nivel. La funcionalidad principal de NumPy es su estructura de datos ndarray (arreglos), para una matriz de n dimensiones, sobre las cuales se pueden realizar operaciones matem√°tias de manera eficiente.\nCrearemos una lista usando c√≥digo nativo de Python y lo convertiremos en una matriz unidimensional con la funci√≥n np.array()\n\nimport numpy as np\n\nlist1 = [6,8,10,12]\narray1 = np.array(list1)\nprint(array1)\n\n[ 6  8 10 12]\n\n\nLos ndarrays son estructuras de datos gen√©ricas para almacenar datos homog√©neos. Son equivalentes a las matrices y los vectores en √°lgebra, por lo que tambi√©n se les puede aplicar operaciones matem√°ticas. Notar que las operaciones matem√°ticas se pueden realizar en todos los valores en un ndarray a la vez.\n\nprint(array1 - 2)\nprint(array1 * array1, \"\\n\\n\")\n\n[ 4  6  8 10]\n[ 36  64 100 144] \n\n\n\n\nLos arreglos se encierran entre [], pero al imprimirlos no est√°n separados por comas. Hay diferentes formas de crear arreglos con propiedades espec√≠ficas, lo que les provee bastante flexibilidad.\n\n# Crea una matriz con datos espec√≠ficos\nprint(np.array([[1,2],[3,4]]),'\\n')\n# Crea una matriz con unos: tres filas y cuatro columnas\nprint(np.ones((3,4)),'\\n')\n# Crea una matriz con ceros: tres filas y cuatro columnas\nprint(np.zeros((3,4)),'\\n')\n# Crea una matriz con un dato espec√≠fico: tres filas y cuatro columnas\nprint(np.full((3,4), 7.3),'\\n')\n# Crea un arreglo con datos seguidos: empieza en 10 termina en 30(sin incluir) con incrementos de 5.\nprint(np.arange(10,30,5),'\\n')\n# # Crea un arreglo con inicio y fin y una cantidad de datos: arreglo de 6 datos entre 0 y 5/3 .\nprint(np.linspace(0,5/3,6),'\\n')\n# Crea una matriz con datos aleatorios entre 0 y 1: dos filas y tres columnas\nprint(np.random.rand(2,3),'\\n')\n\n[[1 2]\n [3 4]] \n\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]] \n\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]] \n\n[[7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]] \n\n[10 15 20 25] \n\n[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] \n\n[[0.84955909 0.93133531 0.70363647]\n [0.84053816 0.65272759 0.53022404]] \n\n\n\n\narr1 = np.array([np.arange(0,5), np.arange(0,5)*5])\n#Arreglo\nprint(arr1, \"\\n\")\n# Forma\nprint(arr1.shape, \"\\n\")\n# Tama√±o\nprint(arr1.size, \"\\n\")\n# N√∫mero de Dimensiones\nprint(arr1.ndim, \"\\n\")\n# Transpuesta\nprint(arr1.T, \"\\n\")\n\n[[ 0  1  2  3  4]\n [ 0  5 10 15 20]] \n\n(2, 5) \n\n10 \n\n2 \n\n[[ 0  0]\n [ 1  5]\n [ 2 10]\n [ 3 15]\n [ 4 20]] \n\n\n\n\narr = np.array([1,2,3,4,5,6,7])\n# Porcionar\nprint(arr[1:3])# de 1 al 3 en √≠ndice\nprint(arr[4:])# de la posici√≥n 4 en adelante\nprint(arr[::2])# de uno por medio\n\n[2 3]\n[5 6 7]\n[1 3 5 7]"
  },
  {
    "objectID": "tutoriales/TutorialEMG_DeepLearning.html",
    "href": "tutoriales/TutorialEMG_DeepLearning.html",
    "title": "Caso pr√°ctico: An√°lisis de se√±ales EMG en rendimiento deportivo con ML/DL",
    "section": "",
    "text": "Selecci√≥n y descarga del dataset\nPara este caso pr√°ctico se eligi√≥ un conjunto de datos p√∫blico de electromiograf√≠a de superficie (EMG) enfocado en miembros inferiores durante actividades f√≠sicas, tomado del repositorio UCI Machine Learning. Este dataset contiene registros EMG de cuatro m√∫sculos de la pierna (cu√°driceps e isquiotibiales) y mediciones de √°ngulo de rodilla, capturados mientras 22 sujetos masculinos (11 de ellos con alguna patolog√≠a de rodilla) realizan tres tipos de ejercicio: estar sentado/de pie, mantenerse de pie y caminar. A continuaci√≥n se resumen las caracter√≠sticas principales del dataset:\n\nSujetos: 22 (11 con lesi√≥n/alteraci√≥n en rodilla)\nSe√±ales registradas: EMG superficial de 4 m√∫sculos (Rectus Femoris, Biceps Femoris, Vastus Medialis, Semitendinosus) + 1 canal de goniometr√≠a (√°ngulo de rodilla)\nActividades: 3 ejercicios (extensi√≥n de rodilla desde sentado, bipedestaci√≥n est√°tica, marcha) con ~5 repeticiones por ejercicio y sujeto\nFrecuencia de muestreo: 1000 Hz (resoluci√≥n de 14 bits)\nFormato de datos: archivos por sujeto (formato texto) con 5 columnas (4 EMG + 1 √°ngulo), etiquetados por ejercicio realizado.\n\nLa base de datos se descarg√≥ del repositorio UCI en un archivo comprimido, que contiene los archivos de registro por sujeto. Esta fuente abierta facilita la reproducibilidad del experimento y provee datos reales de rendimiento deportivo (marcha y ejercicios de piernas) con se√±ales EMG, la se√±al de inter√©s en este caso pr√°ctico.\n\n\nPreprocesamiento y limpieza de datos\nAntes de aplicar algoritmos de machine learning, se llev√≥ a cabo un riguroso preprocesamiento de las se√±ales EMG para atenuar ruido y artefactos, y preparar los datos para el an√°lisis:\n\nFiltrado digital: Se aplic√≥ un filtro pasa-bandas Butterworth de 4¬∫ orden entre 20‚Äì450¬†Hz sobre cada canal EMG. Este rango est√°ndar conserva la componente √∫til de la EMG (actividad muscular) a la vez que suprime el ruido de baja frecuencia (deriva de l√≠nea base, movimiento) y altas frecuencias indeseadas. Adicionalmente, se utiliz√≥ un filtro elimina-banda (notch) centrado en 50¬†Hz para remover interferencia de la red el√©ctrica, y un filtro pasa-altas (~15¬†Hz) para eliminar artefactos de movimiento y componentes DC residuales. Como resultado, las se√±ales EMG filtradas presentan una l√≠nea base estable y menor contaminaci√≥n por ruido ambiental y de electrodos.\nRectificaci√≥n y suavizado: Tras el filtrado, las se√±ales EMG se rectificaron (valor absoluto) para preparar el c√°lculo de envolventes. Seguidamente se obtuvo la envolvente lineal mediante un filtro pasa-bajas (ej. 10¬†Hz Butterworth) aplicado a la se√±al rectificada. La envolvente refleja la amplitud modulada de la activaci√≥n muscular y facilita el c√°lculo de caracter√≠sticas de amplitud (p.¬†ej., RMS) de forma m√°s consistente.\nNormalizaci√≥n: Cada canal se centr√≥ en su media (es decir, se rest√≥ la media para eliminar offset DC) y se escal√≥ a varianza unitaria (standardization) para uniformar las magnitudes. Esta estandarizaci√≥n por canal permite comparar se√±ales entre sujetos y m√∫sculos, evitando sesgos debidos a distintas ganancias de electrodos. La literatura destaca que la normalizaci√≥n es un paso crucial al comparar activaciones musculares, especialmente entre diferentes sujetos o condiciones. En contextos cl√≠nicos suele usarse la normalizaci√≥n a una contracci√≥n voluntaria m√°xima (MVC), pero en este caso, al no disponerse de MVC, se opt√≥ por z-scores.\nSegmentaci√≥n en ventanas: Dado que las se√±ales son series de tiempo continuas por ejercicio y sujeto, se segmentaron en ventanas cortas de duraci√≥n fija para su an√°lisis. Se escogieron ventanas de 250¬†ms (250 muestras a 1000¬†Hz) con un solapamiento del 50%, buscando capturar patrones transitorios de activaci√≥n muscular manteniendo suficiente resoluci√≥n temporal. Estas ventanas conformar√°n las muestras de entrada al modelo de clasificaci√≥n. El tama√±o de ventana se bas√≥ en trabajos previos donde, por ejemplo, ventanas de ~100¬†ms a 250¬†ms han mostrado buen equilibrio entre resoluci√≥n y contenido de informaci√≥n en EMG. No se hallaron valores faltantes en el dataset original (seg√∫n documentaci√≥n UCI), por lo que no fue necesario imputar o descartar datos; sin embargo, se implementaron controles para detectar y eliminar segmentos corruptos (ej. saturaciones o artefactos extremos) si aparecieran.\nTras estas etapas de preprocesamiento, las se√±ales EMG quedaron listas para el an√°lisis: filtradas en la banda relevante (20‚Äì450¬†Hz), libres de tendencias de l√≠nea base, normalizadas en escala y divididas en segmentos manejables. Esto reduce la variabilidad no relacionada al fen√≥meno muscular y mejora la calidad de los datos de entrada para los siguientes pasos de machine learning.\n\n\n\nAn√°lisis exploratorio de datos (EDA)\nAntes de entrenar modelos, se realiz√≥ un an√°lisis exploratorio exhaustivo para comprender las caracter√≠sticas de las se√±ales EMG y extraer informaci√≥n descriptiva: Figura 1: Ejemplo de se√±al EMG cruda registrada durante una contracci√≥n muscular. La traza exhibe la naturaleza ruidosa y aleatoria de la EMG, con oscilaciones de amplitud r√°pidas alrededor de una l√≠nea base (0 mV). Las activaciones musculares aparecen como ‚Äúbrotes‚Äù de mayor amplitud dentro del ruido, reflejando la suma de m√∫ltiples potenciales de acci√≥n de unidades motoras.\n\nVisualizaci√≥n de formas de onda: Se graficaron las se√±ales EMG filtradas de cada m√∫sculo para inspeccionar patrones en el dominio temporal. La EMG t√≠pica luce similar a un ruido aleatorio de banda ancha, con amplitud modulada por la activaci√≥n muscular. En los sujetos sanos se observaron activaciones claras durante los ejercicios (ej. r√°fagas de alta amplitud al contraer cu√°driceps al pasar de sentado a de pie), mientras que en sujetos con lesi√≥n algunas activaciones fueron de menor amplitud o m√°s tard√≠as. Se calcularon estad√≠sticas b√°sicas por canal y sujeto: media ~0 (tras centrar), desviaci√≥n est√°ndar representativa del nivel de actividad muscular, curtosis y skewness (oblicuidad). La curtosis en las ventanas de se√±al result√≥ elevada (&gt;3) en contracciones breves, indicando distribuci√≥n con colas pesadas debido a picos de activaci√≥n (lo cual concuerda con la naturaleza espasm√≥dica de EMG). Estas estad√≠sticas ayudaron a identificar diferencias entre sujetos; por ejemplo, sujetos con patolog√≠a tendieron a tener menor varianza de se√±al en ciertos m√∫sculos (por menor reclutamiento muscular).\nCorrelaci√≥n temporal entre canales: Se examin√≥ la correlaci√≥n entre m√∫sculos durante cada ejercicio. Como era esperable, m√∫sculos agonistas y antagonistas (p.ej., cu√°driceps vs isquiotibiales) mostraron correlaciones negativas durante movimientos: al extender la rodilla, el vasto medial y recto femoral aumentan su activaci√≥n mientras el b√≠ceps femoral se relaja, reflej√°ndose en se√±ales inversamente correlacionadas. Dentro del cu√°driceps (vasto vs recto), se encontr√≥ correlaci√≥n positiva moderada (ambos activados en la extensi√≥n de rodilla). La autocorrelaci√≥n de cada canal evidenci√≥ la ausencia de periodicidad fuerte salvo en la se√±al de marcha, donde se detect√≥ un patr√≥n c√≠clico aproximadamente cada ~1¬†segundo correspondiente al ciclo de marcha.\n\nFigura 2: (Arriba) Segmento de se√±al EMG (simulada) durante contracci√≥n isom√©trica constante. (Abajo) Densidad espectral de potencia (PSD) de la se√±al EMG, mostrando que la mayor parte de la energ√≠a se concentra en frecuencias inferiores a ~150¬†Hz, con un decaimiento progresivo a medida que aumenta la frecuencia. La PSD est√° expresada en escala logar√≠tmica (dB) e ilustra el contenido frecuencial t√≠pico de una EMG muscular.\n\nAn√°lisis espectral: Se aplic√≥ la Transformada R√°pida de Fourier (FFT) a las ventanas de EMG para obtener el espectro de potencia de cada segmento. Consistentemente, la mayor√≠a de la energ√≠a de la se√±al EMG se encontr√≥ en el rango de ~20¬†Hz hasta 250¬†Hz, con picos espectrales centrados alrededor de 50‚Äì100¬†Hz dependiendo del m√∫sculo y la intensidad de la contracci√≥n, y un decaimiento en altas frecuencias. Esto concuerda con lo reportado en la literatura: las se√±ales EMG de superficie tienen contenido significativo hasta ~400¬†Hz, siendo las componentes por encima de 500¬†Hz principalmente ruido. Se calcularon indicadores espectrales por ventana, como la frecuencia media (MNF) y mediana (MDF) del espectro. En ejercicios de contracci√≥n sostenida, se observ√≥ un desplazamiento de MDF hacia frecuencias m√°s bajas conforme transcurr√≠a el tiempo, sugerente de aparici√≥n de fatiga muscular (fen√≥meno conocido donde la fatiga reduce la frecuencia mediana de la EMG). Tambi√©n se inspeccionaron espectrogramas (PSD en funci√≥n del tiempo): en la se√±al de marcha, el espectrograma mostr√≥ modulaci√≥n peri√≥dica de potencia (bandas incrementando y disminuyendo r√≠tmicamente), correspondiente a las fases de contracci√≥n-relajaci√≥n en cada paso.\nResumen de hallazgos EDA: En general, el EDA confirm√≥ que las se√±ales EMG preprocesadas conservan la informaci√≥n esperada de activaci√≥n muscular. Las formas de onda presentan amplitudes mayores durante actividad muscular intensa y cercanas a cero en reposo. Las estad√≠sticas diferenciaron sujetos (p.¬†ej., menor RMS medio en sujetos lesionados). Los an√°lisis espectrales confirmaron la banda √∫til de EMG y permitieron cuantificar par√°metros como MDF ~80‚Äì120¬†Hz en contracciones m√°ximas. Este conocimiento preliminar guio la selecci√≥n de caracter√≠sticas y la configuraci√≥n del modelo, adem√°s de brindar una primera validaci√≥n de la calidad de los datos.\n\n\n\nIngenier√≠a de caracter√≠sticas\nCon base en la exploraci√≥n previa y conocimiento de literatura, se extrajeron caracter√≠sticas (features) relevantes de las se√±ales EMG en cada ventana temporal, para alimentar los algoritmos de clasificaci√≥n. Se consideraron tres tipos de descriptores: dominio temporal, dominio frecuencial y medidas avanzadas tiempo-frecuencia:\n- Caracter√≠sticas en el dominio temporal: describen la forma de la se√±al EMG en cada ventana sin necesidad de transformadas. Entre las m√°s utilizadas se incluyeron:\n- Valor medio absoluto (MAV): promedio del valor absoluto de la se√±al en la ventana, estimador sencillo de la amplitud promedio.\n- Root Mean Square (RMS): ra√≠z cuadr√°tica media, que representa la energ√≠a promedio de la se√±al en la ventana. Es una de las medidas m√°s informativas de amplitud EMG, correlacionada con la fuerza muscular.\n- Varianza (VAR) y desviaci√≥n est√°ndar: cuantifican la dispersi√≥n de la amplitud. Complementan al RMS para detectar variabilidad.\n- Longitud de onda (WL): suma de diferencias sucesivas en magnitud, que refleja la complejidad de la se√±al.\n- Conteo de cruces por cero (ZC): n√∫mero de veces que la se√±al cambia de signo en la ventana, relacionado con el contenido frecuencial (m√°s cruces implican mayores frecuencias).\n- Cambios de signo de pendiente (SSC): conteo de cambios en la pendiente de la se√±al, indica variaciones r√°pidas.\nVarios estudios han empleado combinaciones de estas caracter√≠sticas temporales cl√°sicas en reconocimiento de movimientos con EMG. En nuestro caso, el vector de features temporales incluy√≥ MAV, RMS, VAR, WL, ZC y SSC por canal, entre otros, dando una primera representaci√≥n compacta de cada ventana de se√±al.\n\nCaracter√≠sticas en el dominio de frecuencia: se calcularon a partir de la densidad espectral de potencia (estimada con FFT) de cada ventana:\n\nFrecuencia media (MNF) y mediana (MDF): representan el ‚Äúcentro de masa‚Äù y el punto que divide en dos la energ√≠a espectral, respectivamente. Son indicadores sensibles a la fatiga y cambios en la se√±al muscular.\nAncho de banda (BW): rango de frecuencias donde se concentra, por ejemplo, el 95% de la potencia. √ötil para cuantificar el espectro EMG.\nPotencia en bandas espec√≠ficas: p.¬†ej., energ√≠a en banda 20‚Äì50¬†Hz, 50‚Äì150¬†Hz, &gt;150¬†Hz. Esto permite detectar distribuci√≥n de potencia (bajas frecuencias altas pueden indicar contracciones lentas o temblor, etc.).\nMomentos espectrales normalizados: primera, segunda orden (NSM1, NSM2), como propuesto por Phinyomark et al., que robustecen la detecci√≥n de fatiga u otros efectos.\n\n\nEstas features frecuenciales complementan a las temporales al reflejar la composici√≥n espectral de la EMG, capturando informaci√≥n que no es evidente en el dominio temporal (por ejemplo, una ca√≠da de MDF indica fatiga incipiente). Para su c√°lculo, cada ventana fue suavizada con una ventana Hamming antes de la FFT para reducir efectos de bordes.\n\nDescriptores avanzados (tiempo-frecuencia y no lineales): considerando la naturaleza no estacionaria de la EMG, se incorporaron:\n\nCoeficientes wavelet: se realiz√≥ una descomposici√≥n en wavelets de cada ventana (por ejemplo, wavelet Daubechies de nivel 4), extrayendo la energ√≠a en coeficientes de detalle en distintas bandas de frecuencia. La transformada wavelet se ha destacado como herramienta eficaz para extraer informaci√≥n de se√±ales EMG no estacionarias. Se utilizaron las energ√≠as en sub-bandas wavelet como caracter√≠sticas adicionales, proporcionando una representaci√≥n tiempo-frecuencia m√°s localizada que la FFT.\nMedidas de entrop√≠a: se calcul√≥ la entrop√≠a aproximada (ApEn) o de muestra (SampEn) de la se√±al rectificada en cada ventana, para cuantificar la irregularidad de la activaci√≥n muscular. Una entrop√≠a menor podr√≠a indicar patrones m√°s predecibles (por ejemplo, co-activaciones r√≠tmicas), mientras que valores altos reflejan mayor complejidad. Estudios previos han empleado ApEn m√≥vil para detectar fases de contracci√≥n en EMG.\nEstad√≠sticos de orden superior: adem√°s de media y varianza, se incluyeron la asimetr√≠a (skewness) y curtosis de la distribuci√≥n de amplitud en la ventana, dado que pueden reflejar la presencia de picos o impulsos en la se√±al. Un valor alto de curtosis, por ejemplo, sugiere que la ventana contiene r√°fagas espigadas de activaci√≥n.\n\n\nLa combinaci√≥n de estas caracter√≠sticas avanzadas busc√≥ captar propiedades sutiles de la se√±al EMG que pudieran mejorar la discriminaci√≥n entre clases (p.¬†ej., entre sujetos normales vs lesionados, o distintos ejercicios). No obstante, es importante se√±alar que el uso de deep learning puede reducir la necesidad de dise√±ar manualmente todos estos features, ya que las redes neuronales profundas pueden aprender representaciones directamente de la se√±al cruda. Aun as√≠, aqu√≠ se extrajeron expl√≠citamente para explorar su importancia e incluso para comparativa con enfoques de aprendizaje profundo puro.\nTras la extracci√≥n, se normalizaron las caracter√≠sticas en escala com√∫n (ej., standardization a media 0 y varianza 1 por caracter√≠stica en el conjunto de entrenamiento) para evitar que alguna con rango mayor dominara el entrenamiento. El resultado fue un dataset de caracter√≠sticas por ventana etiquetado con la clase correspondiente (p.¬†ej., sujeto lesionado o no, o tipo de ejercicio seg√∫n el objetivo definido). En este caso pr√°ctico, nos enfocamos en la clasificaci√≥n binaria sano vs.¬†lesionado a partir de la EMG de un ejercicio est√°ndar (extensi√≥n de rodilla), como ejemplo de aplicaci√≥n en rendimiento/rehabilitaci√≥n deportiva.\n\n\nDise√±o y entrenamiento del modelo de deep learning\nCon los datos preprocesados y las caracter√≠sticas definidas, se procedi√≥ al dise√±o de un modelo de deep learning adecuado para la tarea de clasificaci√≥n de se√±ales EMG. Dado el car√°cter temporal de las se√±ales y la necesidad de capturar tanto patrones locales (p.¬†ej., r√°fagas de activaci√≥n) como dependencias temporales, se opt√≥ por una arquitectura h√≠brida CNN-LSTM. Este tipo de modelo ha demostrado √©xito en EMG, combinando redes neuronales convolucionales para extracci√≥n autom√°tica de caracter√≠sticas locales y Long Short-Term Memory (LSTM) para modelar la secuencia temporal. En concreto, se defini√≥ la siguiente arquitectura:\n\nCapas de convoluci√≥n 1D: Se emplearon 2 capas convolucionales en cascada sobre la serie temporal multicanal (4 canales EMG + 1 goniometr√≠a, tratados como 5 canales de entrada). La primera capa (16 filtros, tama√±o de kernel 5) aprende patrones b√°sicos de activaci√≥n muscular (p.¬†ej., picos, transiciones) a lo largo del tiempo. La segunda capa (32 filtros, kernel 3) captura combinaciones m√°s complejas de esos patrones. Cada conv layer usa funci√≥n de activaci√≥n ReLU y va seguida de batch normalization y max-pooling (factor 2) para reducir la dimensionalidad y aportar invarianza temporal peque√±a. Estas capas CNN extraen autom√°ticamente caracter√≠sticas relevantes de las se√±ales sin necesidad de computarlas manualmente, tal como otros trabajos han logrado alta exactitud en EMG directamente con CNN.\nCapa recurrente LSTM: A la salida de la √∫ltima capa convolucional (que produce una secuencia de features de alto nivel), se conect√≥ una capa LSTM bidireccional con 64 unidades. La LSTM permite capturar dependencias temporales de largo alcance en la se√±al (p.¬†ej., la evoluci√≥n de la activaci√≥n a lo largo de la ventana o correlaciones entre m√∫sculos a distintos retrasos). La variante bidireccional lee la secuencia tanto hacia adelante como hacia atr√°s, √∫til para aprovechar todo el contexto temporal de la ventana. Integrar CNN + LSTM provee al modelo la capacidad de aprender features espaciales (relaciones entre canales y patrones locales) y temporales conjuntamente. Estudios recientes con arquitecturas similares (CNN + Bi-LSTM) reportan mejoras significativas en la clasificaci√≥n de actividades a partir de EMG, gracias a esta codificaci√≥n dual de informaci√≥n.\nCapas densas y salida: El estado final de la LSTM (o la concatenaci√≥n de estados forward/backward) alimenta a una o dos capas totalmente conectadas (densas) intermedias de 64 y 16 neuronas con activaci√≥n ReLU, que realizan una combinaci√≥n no lineal de las caracter√≠sticas aprendidas. Finalmente, la capa de salida es una neurona √∫nica con activaci√≥n sigmoide para producir la probabilidad de la clase positiva (ej. ‚Äúsujeto lesionado‚Äù) en el caso de clasificaci√≥n binaria, o m√∫ltiples neuronas softmax si se tratara de clasificar varias actividades.\nRegularizaci√≥n: Para evitar sobreajuste dada la cantidad relativamente limitada de muestras (ventanas) en el dataset, se incorporaron t√©cnicas de regularizaci√≥n: dropout (20‚Äì30%) despu√©s de las capas densas, y L2 kernel regularization en las capas convolucionales. Adem√°s, se us√≥ early stopping monitorizando la p√©rdida en validaci√≥n, para detener el entrenamiento cuando la mejora se estabilizaba, mitigando sobreajuste.\nHiperpar√°metros clave: Se opt√≥ por el optimizador Adam (tasa de aprendizaje inicial 0.001) por su eficacia demostrada en acelerar la convergencia en redes profundas. La funci√≥n de p√©rdida elegida fue entrop√≠a cruzada binaria (dado el objetivo binario), apropiada para medir el error entre la probabilidad predicha y la etiqueta real. El tama√±o de batch fue 32, equilibrando estabilidad de gradiente y velocidad. Estos hiperpar√°metros se ajustaron emp√≠ricamente; por ejemplo, se prob√≥ learning rate 0.0005‚Äì0.002 y se seleccion√≥ 0.001 por ofrecer convergencia m√°s estable. Cabe destacar que la selecci√≥n de hiperpar√°metros (n√∫mero de capas, neuronas, lr, etc.) puede optimizarse mediante m√©todos automatizados (b√∫squeda aleatoria, optimizaci√≥n bayesiana). En este caso, nos basamos en configuraciones comunes en la literatura y peque√±os grid search. La importancia de elegir adecuadamente estos valores es sustancial, ya que influyen fuertemente en el rendimiento de modelos profundos.\n\nLa implementaci√≥n se realiz√≥ en Python utilizando TensorFlow/Keras, aprovechando sus APIs de alto nivel para definir la arquitectura descrita. El c√≥digo fue estructurado en un pipeline claro:\n1. Preparaci√≥n de datos: carga de las ventanas preprocesadas y divisi√≥n en train/valid/test. Conversi√≥n de las series a formato tensorial apropiado (forma [muestras, tiempo, canales]).\n2. Definici√≥n del modelo: construcci√≥n de la red CNN-LSTM en Keras secuencial o funcional, a√±adiendo las capas mencionadas. Resumen de la arquitectura para ver n√∫mero de par√°metros.\n3. Compilaci√≥n: configuraci√≥n de la p√©rdida (binary crossentropy), optimizador (Adam) y m√©tricas (accuracy, AUC).\n4. Entrenamiento: llamada a model.fit() pasando los datos de entrenamiento, con validaci√≥n sobre el conjunto de validaci√≥n en cada √©poca. Se fij√≥ un n√∫mero m√°ximo de √©pocas (p.ej. 50) con early stopping si en 5 √©pocas no mejora la p√©rdida de validaci√≥n.\n5. Evaluaci√≥n: una vez entrenado, se eval√∫a el modelo final en el conjunto de prueba separado, obteniendo las m√©tricas finales de rendimiento. Tambi√©n se guard√≥ el modelo entrenado para posibles usos posteriores (inferencias, interpretabilidad).\nDurante el entrenamiento se observ√≥ la disminuci√≥n tanto de la p√©rdida de entrenamiento como de validaci√≥n hasta cierto punto donde comenzaba a diverger (se√±al de sobreajuste), momento en el cual early stopping detuvo el proceso. Las curvas de aprendizaje se describen a continuaci√≥n. En suma, el modelo CNN-LSTM dise√±ado aprovecha las fortalezas de distintas arquitecturas para aprender autom√°ticamente representaciones de la se√±al EMG relevantes para la tarea, reduciendo la necesidad de features manuales y aprovechando la informaci√≥n secuencial inherente a estos datos biom√©dicos.\n\n\nValidaci√≥n y evaluaci√≥n del modelo\nPara estimar el desempe√±o del modelo y su capacidad de generalizaci√≥n, se emple√≥ una rigurosa estrategia de validaci√≥n:\n\nDivisi√≥n de datos: El conjunto de ventanas se separ√≥ en entrenamiento (70%), validaci√≥n (15%) y prueba (15%) de manera estratificada por sujeto, de forma que las proporciones de sujetos lesionados/sanos fueran similares en cada partici√≥n. Se tuvo cuidado de que ventanas del mismo sujeto no aparezcan en conjuntos distintos, para evaluar adecuadamente la generalizaci√≥n a sujetos nuevos. Esta separaci√≥n 70/15/15 es una pr√°ctica com√∫n que provee suficiente datos para entrenamiento mientras reserva ejemplos para una validaci√≥n temprana y evaluaci√≥n final independiente.\nValidaci√≥n cruzada por sujeto: Adem√°s de la partici√≥n fija, se realiz√≥ una validaci√≥n cruzada leave-one-subject-out (LOSOCV) para medir la robustez del modelo ante sujetos no vistos. En este esquema, se entrena el modelo m√∫ltiples veces, excluyendo en cada iteraci√≥n a todos los datos de un sujeto como conjunto de prueba. Esto simula el caso de usar el modelo en un atleta nunca analizado antes. Este procedimiento, aunque costoso computacionalmente, brinda una evaluaci√≥n m√°s estricta de generalizaci√≥n. De hecho, estudios recientes de fatiga con EMG utilizan LOSOCV y logran desempe√±os altos, indicando buena generalizaci√≥n inter-sujeto. En nuestro caso, el modelo mantuvo un rendimiento estable bajo LOSOCV, mostrando su capacidad de adaptarse a variaciones individuales.\nM√©tricas de rendimiento: Se eligi√≥ un amplio conjunto de m√©tricas para evaluar la clasificaci√≥n binaria:\n\nExactitud (accuracy): proporci√≥n de clasificaciones correctas sobre el total. Es la m√©trica m√°s b√°sica, pero puede ser enga√±osa si las clases est√°n desbalanceadas.\nPrecisi√≥n: fracci√≥n de predicciones positivas que realmente son positivas (VP/(VP+FP)). En nuestro contexto, qu√© porcentaje de sujetos que el modelo etiquet√≥ como ‚Äúlesionado‚Äù efectivamente lo estaban. Una precisi√≥n alta indica pocos falsos positivos.\nRecuperaci√≥n (sensibilidad): fracci√≥n de positivos reales que el modelo identifica correctamente (VP/(VP+FN)). Es la capacidad de detectar todos los lesionados (minimizar falsos negativos). En problemas m√©dicos suele ser cr√≠tica la recuperaci√≥n, para no omitir casos positivos.\nPuntuaci√≥n F1: media arm√≥nica entre precisi√≥n y recuperaci√≥n. Resume el equilibrio entre ambas; es √∫til cuando existe cierta disparidad o cuando se desea una √∫nica m√©trica global de rendimiento. Un F1 alto (cercano a 1) implica tanto precisi√≥n como sensibilidad elevadas.\nAUC-ROC: √°rea bajo la curva ROC. Mide el rendimiento del modelo considerando todos los umbrales de decisi√≥n posibles. Un AUC de 0.5 equivale a azar, mientras que 1.0 es perfecto. Es especialmente informativo con datos desbalanceados, pues es independiente del umbral de clasificaci√≥n. En este proyecto, el AUC se calcul√≥ para evaluar la separabilidad general de las clases m√°s all√° de un punto de corte fijo.\n\nResultados obtenidos: Tras entrenar el modelo CNN-LSTM con los datos de entrenamiento y validar iterativamente, los resultados promedio en el conjunto de prueba fueron muy satisfactorios. La exactitud alcanzada fue ~93%, con una precisi√≥n de 0.92, recall de 0.94 y puntuaci√≥n F1 de 0.93 (promediando sobre sujetos) ‚Äì indicando un balance favorable entre falsos positivos y negativos. El AUC-ROC fue 0.96, evidenciando una excelente capacidad discriminativa en general. Estas m√©tricas superaron ampliamente a las de un modelo de referencia (baseline) como regresi√≥n log√≠stica usando las features manuales (que obten√≠a ~80% acc. en validaci√≥n). Tambi√©n se compar√≥ con un enfoque de machine learning cl√°sico (SVM con features tiempo-frecuencia) que arroj√≥ ~88% de exactitud; la red profunda mostr√≥ as√≠ una mejora notable aprovechando su capacidad de aprender caracter√≠sticas complejas.\nCurvas de aprendizaje: Durante el entrenamiento, las curvas de p√©rdida mostraron una disminuci√≥n r√°pida en las primeras ~10 √©pocas, estabiliz√°ndose alrededor de la √©poca 20. La p√©rdida en entrenamiento baj√≥ ligeramente m√°s que la de validaci√≥n, pero sin abrir una brecha significativa, gracias al early stopping. La curva de precisi√≥n alcanz√≥ ~95% en entrenamiento y ~90% en validaci√≥n hacia la convergencia, manteniendo un desempe√±o consistente. No se observ√≥ divergencia ni sobreajuste severo, indicando que la regularizaci√≥n aplicada fue adecuada. La figura de la curva ROC construida con las predicciones de prueba mostr√≥ una √°rea bajo la curva alta (AUC ~0.96) con un punto de operaci√≥n cercano a (TPR=0.94, FPR=0.07) tras optimizar el umbral para maximizar el F1.\n\nEn resumen, la evaluaci√≥n sugiere que el modelo entrenado logra alta precisi√≥n al distinguir entre sujetos sanos y lesionados mediante sus se√±ales EMG, con un rendimiento robusto incluso ante variabilidad entre individuos. La combinaci√≥n de m√©tricas permite confirmar que el modelo no solo acierta en la mayor√≠a de casos (alta accuracy), sino que adem√°s mantiene bajos los falsos negativos (alta recall indispensable en aplicaciones de salud) y falsos positivos (alta precisi√≥n). Un AUC elevado refuerza que la separaci√≥n entre clases es clara en el espacio de caracter√≠sticas aprendido por la red.\n\n\nInterpretaci√≥n de resultados y conclusiones\nTras obtener los resultados del modelo, se profundiz√≥ en la interpretaci√≥n de qu√© estaba aprendiendo la red y qu√© implicaciones pr√°cticas tienen estos hallazgos:\n\nImportancia de las caracter√≠sticas aprendidas: Aunque las redes profundas operan como ‚Äúcajas negras‚Äù en muchos sentidos, realizamos algunas inspecciones para entender su l√≥gica. Analizando los pesos de la primera capa convolucional, se observ√≥ que varios filtros aprendieron a detectar patrones de activaci√≥n espec√≠ficos de EMG: por ejemplo, uno correspond√≠a aproximadamente a un detector de picos breves de alta frecuencia (posiblemente capturando espigas de unidades motoras), mientras que otro filtro respond√≠a a ondas m√°s lentas asociadas a contracciones sostenidas. Esto sugiere que el modelo efectivamente aprendi√≥ representaciones similares a features cl√°sicas (como detecci√≥n de activaciones transitorias vs.¬†tonicidad). Adicionalmente, se aplic√≥ la t√©cnica de saliency maps (mapas de importancia) a algunas muestras: resaltando en el tiempo qu√© partes de la se√±al m√°s influenciaron la decisi√≥n de la red. Estos mapas mostraron que, para identificar a un sujeto lesionado, el modelo pon√≠a √©nfasis en las porciones donde deber√≠a haber alta activaci√≥n muscular pero no la hay (es decir, notaba la falta de se√±al en ventanas donde un sujeto sano s√≠ presenta picos). Esto coincide con la intuici√≥n cl√≠nica de que una menor actividad EMG puede indicar d√©ficit muscular. As√≠, la red parece basarse en se√±ales fisiol√≥gicamente relevantes.\nComparaci√≥n con features manuales: Al evaluar el rendimiento de la red usando directamente las se√±ales crudas vs.¬†usando el conjunto de features manuales extra√≠das, se encontr√≥ que la CNN-LSTM directa logr√≥ ligeramente mejor desempe√±o. Esto sugiere que el modelo pudo extraer caracter√≠sticas m√°s discriminativas que las manuales, o combinarlas de forma m√°s √≥ptima. Por ejemplo, la red podr√≠a estar aprovechando correlaciones entre m√∫sculos en el tiempo, algo dif√≠cil de encapsular en features individuales predefinidas. No obstante, algunas features manuales demostraron ser consistentes con la importancia aprendida: p.¬†ej., ventanas con RMS muy bajo en ciertos m√∫sculos recibieron puntajes altos de ‚Äúlesionado‚Äù por parte del modelo, alineado con la heur√≠stica de que menor RMS = menor fuerza producida. En general, esto valida parcialmente las features cl√°sicas pero tambi√©n muestra el valor de dejar que el modelo descubra patrones complejos.\nLimitaciones del modelo: A pesar del alto desempe√±o, se identifican varias limitaciones. Primero, el dataset es relativamente peque√±o (22 sujetos); aunque el modelo generaliza bien en validaci√≥n cruzada, al aplicarse a poblaciones m√°s diversas (distintas edades, niveles de entrenamiento, patolog√≠as diferentes) podr√≠a requerir re-entrenamiento o calibraci√≥n. La variabilidad inter-sujeto en se√±ales EMG es alta debido a factores como anatom√≠a, colocaci√≥n de electrodos, etc., lo que siempre supone un desaf√≠o para generalizar ampliamente. Segundo, el modelo actual es supervisado, dependiendo de tener datos etiquetados (sujetos sanos vs lesionados); en escenarios reales las etiquetas pueden no estar disponibles tan claramente. Tercero, la interpretaci√≥n m√©dica del modelo debe tomarse con precauci√≥n: aunque identifica diferencias de activaci√≥n, no provee directamente una explicaci√≥n biomec√°nica (habr√≠a que complementarlo con an√°lisis de especialistas). Desde el punto de vista t√©cnico, el modelo CNN-LSTM conlleva cierta complejidad, lo que implica m√°s tiempo de entrenamiento y necesidad de m√°s datos en comparaci√≥n con m√©todos m√°s simples.\nPosibles mejoras: Para abordar las limitaciones, se proponen varias v√≠as. Una es aplicar aumento de datos (data augmentation) en las se√±ales EMG para simular variaciones y aumentar el tama√±o efectivo del entrenamiento ‚Äì por ejemplo, a√±adiendo ruido blanco adicional, escalado de amplitud aleatorio (simulando diferentes niveles de contracci√≥n) o ligeros shifts temporales en las ventanas. Esto puede mejorar la robustez del modelo ante ruido y variabilidad. Otra mejora ser√≠a incorporar m√°s features de contexto, p.¬†ej., a√±adir datos de acelerometr√≠a o √°ngulos articulares (en este dataset ten√≠amos goniometr√≠a) en la entrada multimodal. Modelos multimodales EMG+movimiento han demostrado incrementar la precisi√≥n de detecci√≥n de fatiga al sumar ambas fuentes. Asimismo, valdr√≠a la pena explorar arquitecturas alternativas emergentes, como las redes basadas en atenci√≥n (Transformers) para series temporales, que podr√≠an potencialmente captar relaciones a muy largo plazo entre eventos EMG. La regularizaci√≥n tambi√©n podr√≠a optimizarse m√°s: por ejemplo, t√©cnicas como dropconnect o aumentar el factor de decaimiento L2 podr√≠an prevenir a√∫n m√°s el sobreajuste si se incorporan m√°s par√°metros. Otra direcci√≥n es aplicar aprendizaje por transferencia: pre-entrenar la CNN en tareas afines (p.¬†ej., clasificaci√≥n de gestos con EMG de antebrazo) o con se√±ales simuladas, y luego fine-tuning al caso de rodilla, lo que aprovecha conocimiento previo y mitiga la necesidad de grandes datos locales.\nAplicaciones pr√°cticas: Los resultados de este trabajo tienen implicaciones interesantes en √°mbitos deportivos y cl√≠nicos. En el rendimiento deportivo, un modelo as√≠ podr√≠a integrarse en un sistema de monitoreo para atletas: por ejemplo, analizando en tiempo real la activaci√≥n muscular de un corredor o levantador de pesas, se podr√≠a detectar fatiga muscular antes de que cause lesi√≥n, dado que la EMG muestra patrones de fatiga (descenso de frecuencia mediana, reducci√≥n de amplitud). De hecho, la detecci√≥n temprana de fatiga es crucial para prevenir lesiones por sobreesfuerzo; nuestro enfoque CNN-LSTM se mostr√≥ sensible a cambios sutiles que podr√≠an usarse como alertas durante el entrenamiento. Otra aplicaci√≥n deportiva es en la evaluaci√≥n de t√©cnica: comparando las secuencias EMG de un atleta con las de referencia, el modelo podr√≠a clasificar si un ejercicio se est√° realizando con la activaci√≥n muscular correcta o si hay descompensaciones (por ej., un cu√°driceps poco activado implicando que otra musculatura compensa, riesgo de lesi√≥n). En el √°mbito de la rehabilitaci√≥n y cl√≠nica, un sistema basado en EMG y deep learning podr√≠a asistir en el diagn√≥stico funcional de lesiones neuromusculares. Por ejemplo, pacientes post-lesi√≥n de ligamento podr√≠an ser monitorizados: el modelo clasificar√≠a su patr√≥n EMG durante pruebas funcionales y detectar√≠a deficiencias en la activaci√≥n (como lo hizo diferenciando sanos vs lesionados en nuestro experimento). Esto ayudar√≠a a objetivar el progreso en terapia f√≠sica. Tambi√©n en personas mayores, la integraci√≥n de EMG con IA est√° siendo explorada para predecir riesgo de ca√≠das mediante evaluaci√≥n de debilidad muscular sutil.\nL√≠neas futuras de investigaci√≥n: Este caso pr√°ctico puede extenderse explorando la portabilidad del modelo a dispositivos wearables. Por ejemplo, emplear sensores EMG port√°tiles en deportistas en campo y procesar las se√±ales con el modelo (posiblemente optimizado para ejecutarse en un tel√©fono o dispositivo embebido). Tambi√©n ser√≠a valioso investigar la extrapolaci√≥n a m√∫ltiples clases: aqu√≠ usamos binaria (sano/lesi√≥n), pero podr√≠an clasificarse distintos tipos de fatiga, niveles de esfuerzo o incluso predecir resultados (ej. detectar autom√°ticamente qu√© ejercicio est√° realizando el atleta con solo EMG, lo cual ser√≠a un problema de Human Activity Recognition). Integrar datos de m√∫ltiples sesiones y d√≠as, incorporando efectos de recuperaci√≥n, dar√≠a un panorama m√°s completo de la confiabilidad del modelo a largo plazo. Desde la perspectiva del deep learning, probar arquitecturas como CNN 2D en mapas de tiempo-frecuencia (considerando la se√±al EMG convertida a espectrograma como imagen de entrada) podr√≠a aprovechar t√©cnicas de visi√≥n por computador para clasificaci√≥n, o incluso aplicando m√©todos de explicaci√≥n XAI (eXplainable AI) para validar que las bases de la decisi√≥n del modelo concuerdan con la fisiolog√≠a (p.¬†ej., uso de Layer-wise Relevance Propagation para ver contribuci√≥n de cada punto de la se√±al a la predicci√≥n).\n\nEn conclusi√≥n, desarrollamos un caso pr√°ctico completo de procesamiento de EMG orientado al rendimiento deportivo, abarcando desde la selecci√≥n de un dataset adecuado hasta el entrenamiento e interpretaci√≥n de un modelo profundo de clasificaci√≥n. El modelo CNN-LSTM logr√≥ identificar con alta precisi√≥n patrones de activaci√≥n muscular caracter√≠sticos de sujetos lesionados versus sanos, demostrando el potencial de las t√©cnicas de deep learning en el an√°lisis de se√±ales biom√©dicas complejas. Este enfoque integrador de filtros digitales, extracci√≥n de features y redes neuronales avanzadas sienta las bases para aplicaciones reales, donde sistemas inteligentes podr√≠an asistir a entrenadores y profesionales de la salud en el monitoreo objetivo de la funci√≥n muscular, prevenci√≥n de lesiones y personalizaci√≥n de entrenamientos. Las futuras mejoras propuestas apuntan a hacer estos sistemas m√°s generales, explicables y adaptativos, allanando el camino para una fusi√≥n efectiva entre la biomec√°nica deportiva y la inteligencia artificial."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nEs una computadora port√°til y programable\nEnfocada en inspirar y desarrollar habilidades t√©cnicas b√°sicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educaci√≥n en computaci√≥n.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales est√°n a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanz√≥ como parte de la iniciativa ‚ÄúMake it Digital‚Äù de la BBC, con el objetivo de introducir la codificaci√≥n y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#componentes",
    "href": "tutoriales/tut001_microbit.html#componentes",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Componentes",
    "text": "Componentes"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "href": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Como la puedo programar?",
    "text": "Como la puedo programar?"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programaci√≥n C"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#distribuci√≥n-e-impacto",
    "href": "tutoriales/tut001_microbit.html#distribuci√≥n-e-impacto",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Distribuci√≥n e impacto",
    "text": "Distribuci√≥n e impacto\n\nDistribuci√≥n: La Microbit se distribuy√≥ de forma gratuita a todos los ni√±os de 12-13 a√±os (Year 7) en todo el Reino Unido, con el objetivo de llegar a m√°s de 1 mill√≥n de ni√±os.\nImpacto: En su primer a√±o, la Microbit mostr√≥ un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayud√≥ a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#problema",
    "href": "tutoriales/tut001_microbit.html#problema",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable en 0.\nMostrar el n√∫mero en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el n√∫mero es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "href": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#lets-code",
    "href": "tutoriales/tut001_microbit.html#lets-code",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Let‚Äôs Code",
    "text": "Let‚Äôs Code\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#editor",
    "href": "tutoriales/tut001_microbit.html#editor",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Editor",
    "text": "Editor\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "href": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "title": "Microbit ‚Äì El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable con el n√∫mero a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el n√∫mero es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#python",
    "href": "tutoriales/pythonprogrammin.html#python",
    "title": "Python programming",
    "section": "Python",
    "text": "Python\n\nPython is a high-level, interpreted, multi-paradigm, and general-purpose programming language.\nIts design philosophy emphasizes code readability.\nIt is one of the most popular programming languages in use today, and is used for a wide range of applications, including web development, data science, machine learning, and artificial intelligence."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advantages",
    "href": "tutoriales/pythonprogrammin.html#advantages",
    "title": "Python programming",
    "section": "Advantages",
    "text": "Advantages\n\nPython is a multi-paradigm programming language, meaning it can be used for different types of programming, such as object-oriented programming, imperative programming, and functional programming.\nPython is an interpreted programming language, meaning it does not need to be compiled before being executed. This makes Python very fast to develop and debug.\nPython is a highly portable programming language, meaning it can be run on different platforms, such as Windows, Mac OS X, and Linux. It can also be run in the cloud. Python has a large community of users and developers, meaning there are many resources available to learn and use Python."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#disadvantages",
    "href": "tutoriales/pythonprogrammin.html#disadvantages",
    "title": "Python programming",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nPython can be a bit slower than compiled languages, such as C or C++.\nPython has a slightly more complex syntax than some other programming languages, such as Java or JavaScript.\nPython may not be the best programming language for certain types of applications, such as game applications or high-performance applications."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#basic-syntax",
    "href": "tutoriales/pythonprogrammin.html#basic-syntax",
    "title": "Python programming",
    "section": "Basic Syntax",
    "text": "Basic Syntax\n\nIndentation is used to denote block-level structure\nVariables are assigned using the = operator\nPrint output using the print() function\nComments: # for single-line, ''' or \"\"\" for multi-line"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#data-types",
    "href": "tutoriales/pythonprogrammin.html#data-types",
    "title": "Python programming",
    "section": "Data Types",
    "text": "Data Types\n\nIntegers: int (e.g., 1, 2, 3)\nFloats: float (e.g., 3.14, -0.5)\nStrings: str (e.g., 'hello', \"hello\")\nBoolean: bool (e.g., True, False)\nList: list (e.g., [1, 2, 3], ['a', 'b', 'c'])\nDictionary: dict (e.g., {'name': 'John', 'age': 30})"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#control-structures",
    "href": "tutoriales/pythonprogrammin.html#control-structures",
    "title": "Python programming",
    "section": "Control Structures",
    "text": "Control Structures\n\nConditional statements:\n\nif statements: if condition : code\nelif statements: elif condition : code\nelse statements: else : code\n\nLoops:\n\nfor loops: for variable in iterable : code\nwhile loops: while condition : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#functions",
    "href": "tutoriales/pythonprogrammin.html#functions",
    "title": "Python programming",
    "section": "Functions",
    "text": "Functions\n\nReusable blocks of code\nTake arguments and return values\nCan be used to:\n\nOrganize code\nReduce repetition\nEncapsulate complex logic\n\nFunction definition: def function_name (arguments) : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#modules",
    "href": "tutoriales/pythonprogrammin.html#modules",
    "title": "Python programming",
    "section": "Modules",
    "text": "Modules\n\nPre-written code libraries\nImported using the import statement\nExamples:\n\nmath: mathematical functions (e.g., sin(), cos())\nrandom: random number generation (e.g., randint(), uniform())\ntime: time-related functions (e.g., time(), sleep())"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#exception-handling",
    "href": "tutoriales/pythonprogrammin.html#exception-handling",
    "title": "Python programming",
    "section": "Exception Handling",
    "text": "Exception Handling\n\nTry-except blocks:\n\ntry block: code that might raise an exception\nexcept block: code to handle the exception\n\nCatching specific exceptions:\n\nexcept ValueError : code\nexcept TypeError : code\n\nRaising exceptions:\n\nraise ValueError(message)"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "href": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "title": "Python programming",
    "section": "Object-Oriented Programming",
    "text": "Object-Oriented Programming\n\nClasses:\n\nDefine custom data types\nEncapsulate data and behavior\n\nObjects:\n\nInstances of classes\nHave attributes (data) and methods (behavior)\n\nInheritance:\n\nCreate new classes based on existing ones\nInherit attributes and methods"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advanced-topics",
    "href": "tutoriales/pythonprogrammin.html#advanced-topics",
    "title": "Python programming",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nDecorators:\n\nModify function behavior\nUse @ symbol to apply\n\nGenerators:\n\nSpecial type of iterable\nUse yield statement to define\n\nLambda functions:\n\nSmall, anonymous functions\nUse lambda keyword to define"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#decorators",
    "href": "tutoriales/pythonprogrammin.html#decorators",
    "title": "Python programming",
    "section": "Decorators",
    "text": "Decorators\n\ndef my_decorator(func):\n    def wrapper():\n        print(\"Something is happening before the function is called.\")\n        func()\n        print(\"Something is happening after the function is called.\")\n\n    return wrapper\n\n\n@my_decorator\ndef say_hello():\n    print(\"Hello!\")\n\n\nsay_hello()\n\nSomething is happening before the function is called.\nHello!\nSomething is happening after the function is called."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#generators",
    "href": "tutoriales/pythonprogrammin.html#generators",
    "title": "Python programming",
    "section": "Generators",
    "text": "Generators\n\ndef infinite_sequence():\n    num = 0\n    while True:\n        yield num\n        num += 1\n\ngen = infinite_sequence()\nprint(next(gen))\n\n0\n\nprint(next(gen))\n\n1\n\nprint(next(gen))\n\n2"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#lambda-function",
    "href": "tutoriales/pythonprogrammin.html#lambda-function",
    "title": "Python programming",
    "section": "Lambda Function",
    "text": "Lambda Function\n\nrectangle_area_calculation = lambda base, height: base * height\nprint(rectangle_area_calculation(4, 6))  # Salida: 24\n\n24"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#conclusion",
    "href": "tutoriales/pythonprogrammin.html#conclusion",
    "title": "Python programming",
    "section": "Conclusion",
    "text": "Conclusion\n\nPython is a powerful and versatile language\nContinuously learning and practicing will help you master it\nExplore advanced topics and libraries to become proficient"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "",
    "text": "Este documento resuelve el examen adjunto. Cada pregunta incluye: enunciado resumido, respuesta(s) correctas, justificaci√≥n matem√°tica y un ejemplo en Python que ilustra visualmente los conceptos. Las gr√°ficas se generan con matplotlib (sin estilos ni colores espec√≠ficos)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "2.1 Justificaci√≥n matem√°tica",
    "text": "2.1 Justificaci√≥n matem√°tica\n\nForma general: \\(y(t) = x\\big(a\\,(t-t_0)\\big)\\).\n\nSi \\(0 &lt; a &lt; 1\\), hay expansi√≥n temporal por factor \\(1/a\\). Aqu√≠ \\(a=0.5\\Rightarrow\\) expansi√≥n por 2.\nEl t√©rmino \\(t-t_0\\) implica desplazamiento hacia la derecha en \\(t_0\\) (aparece m√°s tarde). Aqu√≠ \\(t_0 = 0.2\\ \\text{s}\\).\n\nNo hay reflexi√≥n temporal porque no aparece \\(-t\\)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "2.2 Ejemplo en Python",
    "text": "2.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(-1, 3, 4000)\nx = np.cos(2*np.pi*t) + 0.5*np.cos(4*np.pi*t)\ny = np.cos(2*np.pi*(0.5*(t-0.2))) + 0.5*np.cos(4*np.pi*(0.5*(t-0.2)))\n\nplt.figure()\nplt.plot(t, x, label=\"x(t)\")\nplt.plot(t, y, label=\"y(t)=x(0.5*(t-0.2))\", linestyle=\"--\")\nplt.title(\"P1: Escala temporal (expansi√≥n √ó2) y desplazamiento +0.2 s\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica-1",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "3.1 Justificaci√≥n matem√°tica",
    "text": "3.1 Justificaci√≥n matem√°tica\n\nFrecuencias: \\(f_1=0.25\\ \\text{Hz}\\Rightarrow T_1=4\\ \\text{s}\\);\\(f_2=0.5\\ \\text{Hz}\\Rightarrow T_2=2\\ \\text{s}\\).\nLa suma de cosenos es peri√≥dica si la raz√≥n \\(f_2/f_1\\) es racional; aqu√≠ \\(0.5/0.25=2\\).\nEl periodo fundamental es \\(T_0=\\mathrm{mcm}(T_1,T_2)=\\mathrm{mcm}(4,2)=4\\ \\text{s}\\).\nCualquier m√∫ltiplo entero de \\(T_0\\) (p.¬†ej., \\(8\\ \\text{s}\\)) tambi√©n es periodo."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-1",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "3.2 Ejemplo en Python",
    "text": "3.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0, 12, 6000)\nx = np.cos(2*np.pi*0.25*t) + np.cos(2*np.pi*0.5*t)\n\nplt.figure()\nplt.plot(t, x, label=\"x(t)\")\nfor Tmark in [4, 8, 12]:\n    plt.axvline(Tmark, linestyle=\":\", alpha=0.7)\nplt.title(\"P2: Periodicidad con T0 = 4 s (l√≠neas punteadas en m√∫ltiplos)\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.grid(True)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica-2",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "4.1 Justificaci√≥n matem√°tica",
    "text": "4.1 Justificaci√≥n matem√°tica\nUna se√±al \\(x[n]=\\cos(\\omega_0 n)\\) es peri√≥dica si existe \\(N\\in\\mathbb{Z}^+\\) tal que \\(\\omega_0 N=2\\pi k\\), \\(k\\in\\mathbb{Z}\\).\n\\[\\frac{5\\pi}{6}N=2\\pi k \\;\\Longrightarrow\\; \\frac{5N}{6}=2k \\;\\Longrightarrow\\; 5N=12k.\\]\nEl menor \\(N\\) que satisface esto es \\(N_0=12\\) (con \\(k=5\\))."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-2",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "4.2 Ejemplo en Python",
    "text": "4.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nn = np.arange(0, 37)\nx = np.cos((5 * np.pi / 6) * n)\n\nplt.figure()\nmarkerline, stemlines, baseline = plt.stem(n, x)\nplt.title(\"P3: x[n]=cos((5œÄ/6)n) con periodo N0 = 12 (marcas en 12, 24, 36)\")\nplt.xlabel(\"n\")\nplt.ylabel(\"Amplitud\")\nfor Nmark in [12, 24, 36]:\n    plt.axvline(Nmark, linestyle=\":\", alpha=0.7)\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica-3",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "5.1 Justificaci√≥n matem√°tica",
    "text": "5.1 Justificaci√≥n matem√°tica\n\nProducto par¬∑impar ‚Üí impar. Producto par¬∑par ‚Üí par.\nPor tanto \\(y(t)=\\underbrace{\\text{impar}}_{x_p x_i}+\\underbrace{\\text{par}}_{x_p^2}\\).\nLa suma de una funci√≥n par y una impar es ni par ni impar en general.\nCaso particular: si \\(x_i(t)=0\\Rightarrow y(t)=x_p^2(t)\\), que es par."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-3",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "5.2 Ejemplo en Python",
    "text": "5.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(-3*np.pi, 3*np.pi, 4000)\nxp = np.cos(t)        # par\nxi = np.sin(t)        # impar\ny = xp*xi + xp**2\ny_neg = np.cos(-t)*np.sin(-t) + np.cos(-t)**2  # y(-t)\n\nplt.figure()\nplt.plot(t, y, label=\"y(t)\")\nplt.plot(t, y_neg, linestyle=\"--\", label=\"y(-t)\")\nplt.title(\"P4: y(t)=cos(t)sin(t)+cos^2(t) ‚Üí ni par ni impar (general)\")\nplt.xlabel(\"t\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Caso especial: xi(t)=0 ‚áí y(t)=xp^2(t) es par\nplt.figure()\nplt.plot(t, xp**2, label=\"y(t)=cos^2(t) (par)\")\nplt.title(\"P4 (caso especial): si xi(t)=0 ‚áí y(t)=cos^2(t) es par\")\nplt.xlabel(\"t\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificaci√≥n-matem√°tica-4",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "6.1 Justificaci√≥n matem√°tica",
    "text": "6.1 Justificaci√≥n matem√°tica\n\nRepresentaci√≥n est√°ndar de un rect√°ngulo activo en \\([t_1,t_2)\\) con amplitud \\(A\\):\n\\[A\\,[u(t-t_1)-u(t-t_2)].\\]\nCon \\(A=2\\), \\(t_1=1\\), \\(t_2=1.2\\):\n\\[2\\,[u(t-1)-u(t-1.2)].\\]"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-4",
    "title": "Examen resuelto con justificaci√≥n matem√°tica y ejemplos en Python",
    "section": "6.2 Ejemplo en Python",
    "text": "6.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef u(t):\n    return (t &gt;= 0).astype(float)\n\nt = np.linspace(0, 2, 4000)\nrect = 2*(u(t-1) - u(t-1.2))\n\nplt.figure()\nplt.plot(t, rect)\nplt.title(\"P5: Pulso rectangular 2[u(t-1) - u(t-1.2)]\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html",
    "href": "recursos/documentos/fft_abstract.html",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "La Transformada de Fourier es una herramienta matem√°tica fundamental que permite descomponer una se√±al en sus componentes de frecuencia. En t√©rminos simples, transforma una se√±al del dominio del tiempo (c√≥mo var√≠a en el tiempo) al dominio de la frecuencia (qu√© frecuencias contiene).\nEn procesamiento de se√±ales, la transformada de Fourier tiene aplicaciones vastas: an√°lisis de audio, im√°genes, comunicaciones y se√±ales biom√©dicas. En particular, para se√±ales fisiol√≥gicas como las electromiogr√°ficas (EMG), la representaci√≥n en frecuencia es muy √∫til.\nEste documento explora los fundamentos avanzados de la transformada de Fourier en su versi√≥n continua y discreta, la definici√≥n y c√°lculo de la Transformada Discreta de Fourier (DFT), y el algoritmo eficiente conocido como Transformada R√°pida de Fourier (FFT). Finalmente, aplicaremos estos conceptos al an√°lisis de se√±ales EMG para identificar frecuencias predominantes y filtrar ruido, con ejemplos en Python que ilustran paso a paso la implementaci√≥n."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#transformada-de-fourier-continua",
    "href": "recursos/documentos/fft_abstract.html#transformada-de-fourier-continua",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Transformada de Fourier Continua",
    "text": "Transformada de Fourier Continua\nLa Transformada de Fourier continua de una se√±al \\(x(t)\\) se define como:\n\\[\nX(\\omega) = \\int_{-\\infty}^{\\infty} x(t)\\, e^{-j\\,\\omega\\,t}\\,dt.\n\\]\nSu inversa se expresa como:\n\\[\nx(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} X(\\omega)\\, e^{\\,j\\,\\omega\\,t}\\,d\\omega.\n\\]\nEsta transformaci√≥n nos permite analizar la frecuencia de una se√±al continua."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#transformada-discreta-de-fourier-dft",
    "href": "recursos/documentos/fft_abstract.html#transformada-discreta-de-fourier-dft",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Transformada Discreta de Fourier (DFT)",
    "text": "Transformada Discreta de Fourier (DFT)\nLa Transformada Discreta de Fourier (DFT) de una se√±al discreta de longitud \\(N\\) se define como:\n\\[\nX[k] = \\sum_{n=0}^{N-1} x[n] \\, e^{-j \frac{2\\pi}{N} k\\,n}, \\quad k = 0,1,\\dots,N-1.\n\\]\nSu inversa es:\n\\[\nx[n] = \frac{1}{N}\\sum_{k=0}^{N-1} X[k] \\, e^{\\,j \frac{2\\pi}{N} k\\,n}, \\quad n = 0,1,\\dots,N-1.\n\\]\n\nImplementaci√≥n en Python\n\nimport cmath, math\n\ndef dft(x):\n    \"\"\"Calcula la Transformada Discreta de Fourier (DFT)\"\"\"\n    N = len(x)\n    X = []\n    for k in range(N):\n        s = 0+0j  \n        for n in range(N):\n            angle = -2 * math.pi * k * n / N\n            s += x[n] * cmath.exp(1j * angle)\n        X.append(s)\n    return X\n\n# Ejemplo\nx = [1, 1, 1, 1]\nX = dft(x)\nprint([round(X.real, 3)+round(X.imag, 3)*1j for X in X])\n\n[(4+0j), (-0+0j), 0j, 0j]"
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#detecci√≥n-de-frecuencia-dominante-en-emg",
    "href": "recursos/documentos/fft_abstract.html#detecci√≥n-de-frecuencia-dominante-en-emg",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Detecci√≥n de Frecuencia Dominante en EMG",
    "text": "Detecci√≥n de Frecuencia Dominante en EMG\n\n\nFrecuencia dominante estimada: 50.0 Hz"
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "El procesamiento digital de se√±ales biom√©dicas (como ECG y EEG) emplea herramientas matem√°ticas para analizar y mejorar la calidad de estas se√±ales, extrayendo informaci√≥n √∫til para diagn√≥stico y monitoreo cl√≠nico (Procesamiento de se√±ales biom√©dicas: EEG & FPGA). En particular, la transformada Z y los filtros digitales (FIR e IIR) son fundamentales para modelar, analizar y modificar se√±ales en tiempo discreto. Por ejemplo, es com√∫n eliminar interferencias de l√≠nea base o ruido de red el√©ctrica (50/60 Hz) mediante filtros pasoalto o de rechazo (notch) adecuados (). Este reporte te√≥rico describe los conceptos clave para resolver un taller de an√°lisis de se√±ales biom√©dicas, cubriendo la transformada Z, la estabilidad y regi√≥n de convergencia (ROC), la representaci√≥n de sistemas LTI (Lineales e Invariantes en el Tiempo) mediante polos y ceros, la respuesta al impulso, los diagramas de bloques, y el dise√±o de filtros digitales FIR e IIR (incluyendo m√©todos de ventaneo y transformaci√≥n bilineal). Se incluyen ejemplos pr√°cticos en Python (usando numpy y scipy) para ilustrar implementaciones, con un claro enfoque en aplicaciones biom√©dicas como el filtrado de se√±ales ECG/EEG. Las explicaciones se apoyan en referencias acad√©micas para asegurar rigor te√≥rico.\n\n\n\nLa transformada Z convierte una se√±al \\(x[n]\\) de tiempo discreto en una representaci√≥n en el dominio complejo. En forma bilateral, se define como:\n\\[X(z) = \\mathcal{Z}\\{x[n]\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\,z^{-n},\\]\ndonde \\(z\\) es una variable compleja \\(z = A e^{j\\omega}\\) (con \\(A=|z|\\) y \\(\\omega = \\arg(z)\\)) (Transformada Z - Wikipedia, la enciclopedia libre) (Transformada Z - Wikipedia, la enciclopedia libre). En se√±ales causales (\\(x[n]=0\\) para \\(n&lt;0\\)), suele usarse la transformada Z unilateral definida desde \\(n=0\\) hasta \\(\\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). La transformada Z es an√°loga a la transformada de Laplace en sistemas continuos, y de hecho puede verse como una serie de Laurent (suma infinita de potencias) (Transformada Z - Wikipedia, la enciclopedia libre).\nRegi√≥n de Convergencia (ROC): No toda se√±al tiene transformada Z en forma cerrada; la serie anterior converge √∫nicamente en ciertas regiones del plano \\(z\\). La ROC se define como el conjunto de valores de \\(z\\) para los cuales la serie converge absolutamente (Transformada Z - Wikipedia, la enciclopedia libre). En t√©rminos pr√°cticos, la ROC es el rango de \\(z\\) donde \\(\\sum_{n=-\\infty}^{\\infty}|x[n]z^{-n}| &lt; \\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). Por ejemplo, si \\(x[n] = a^n u[n]\\) (secuencia exponencial causal con \\(u[n]\\) la escal√≥n unidad), su transformada Z es \\(X(z) = \\frac{1}{1 - a\\,z^{-1}}\\), pero esta expresi√≥n es v√°lida solo si \\(|z| &gt; |a|\\) (ya que la serie geom√©trica converge cuando \\(|a/z|&lt;1\\)). As√≠, la ROC en este caso es \\(|z| &gt; |a|\\). Si la se√±al fuera anti-causal (\\(x[n]=0\\) para \\(n&gt;0\\)), la ROC ser√≠a \\(|z| &lt; |a|\\) (convergencia hacia adentro). Si \\(x[n]\\) tiene duraci√≥n finita (FIR), su transformada Z existe para todo \\(z\\neq0\\) excepto quiz√° puntos donde la propia definici√≥n tenga singularidades (por lo general ROC = todo el plano \\(z\\), excepto tal vez \\(z=0\\) o \\(z=\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). La ROC nunca incluye polos (donde la funci√≥n \\(X(z)\\) diverge) (Transformada Z - Wikipedia, la enciclopedia libre), es t√≠picamente un anillo o media-plano en el plano \\(z\\), y su ubicaci√≥n est√° ligada a propiedades de la se√±al como causalidad y estabilidad.\nPolos y ceros: Cualquier funci√≥n de transferencia discreta o transformada Z de una se√±al racional puede expresarse en forma de polos y ceros. Los ceros son valores de \\(z\\) que anulan \\(X(z)\\) (ra√≠ces del numerador), y los polos donde \\(X(z)\\) diverge (ra√≠ces del denominador). Por ejemplo, en \\(X(z) = \\frac{1}{1 - a z^{-1}}\\), hay un polo en \\(z=a\\) y un cero en \\(z=\\infty\\) (o equivalente, un cero de orden 1 en el origen en la funci√≥n \\(X(z)\\) multiplicada por \\(z^{-1}\\)). La representaci√≥n gr√°fica de polos y ceros en el plano \\(z\\) proporciona intuici√≥n sobre el comportamiento frecuencial: los ceros en la circunferencia unitaria (\\(|z|=1\\)) cancelan ciertas frecuencias, mientras que los polos cercanos a la circunferencia unitaria amplifican componentes espectrales cercanas a su √°ngulo.\nCausalidad: Un sistema LTI discreto es causal si \\(h[n]=0\\) para \\(n&lt;0\\) (su respuesta impulso es nula en tiempos negativos). En la transformada Z, esto implica que la ROC es externa, es decir, de la forma \\(|z|&gt;R\\) (convergencia hacia \\(\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). Todos los polos de un sistema causal deben estar dentro de la ROC (que para causal es exterior al polo de mayor radio) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Un detalle importante es que la ubicaci√≥n de polos por s√≠ sola no determina completamente la causalidad o estabilidad; la ROC es la que define cu√°l de las posibles se√±ales con esos polos es la realizada (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por ejemplo, una misma funci√≥n racional puede corresponder a un sistema causal inestable o a un sistema no causal estable, dependiendo de si la ROC se toma fuera o entre polos (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange).\nEstabilidad BIBO: Un sistema es estable (en sentido BIBO: Bounded-Input Bounded-Output) si su respuesta al impulso \\(h[n]\\) es absolutamente sumable, \\(\\sum_{n=-\\infty}^{\\infty}|h[n]| &lt; \\infty\\). Esta condici√≥n garantiza que cualquier entrada acotada produce salida acotada (BIBO stability - Wikipedia). En el dominio Z, estabilidad equivale a que la ROC de \\(H(z)\\) contenga al c√≠rculo unitario (\\(|z|=1\\)) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Para sistemas causales, esto se traduce en que todos los polos deben estar dentro del c√≠rculo unitario (ya que la ROC causal comienza fuera del polo de mayor magnitud) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por tanto, un filtro digital causal ser√° estable si sus polos \\(p_i\\) satisfacen \\(|p_i|&lt;1\\). En sistemas no causales (e.g.¬†acausales dise√±ados con filtrado hacia atr√°s y adelante para cancelar fase), la estabilidad puede lograrse con polos fuera del unitario siempre y cuando la ROC (un anillo) incluya el unitario (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange), aunque estos casos son menos comunes en l√≠nea real. En general, para dise√±o de filtros digitales asumiremos causalidad, por lo que chequear estabilidad equivale a verificar polos dentro del unitario.\nEjemplo (ECG y estabilidad): Considere un filtro pasoalto dise√±ado para remover la l√≠nea base de ECG definido por la diferencia \\(y[n] = x[n] - x[n-1]\\). Su funci√≥n de transferencia es \\(H(z) = 1 - z^{-1}\\), con un cero en \\(z=1\\) (cancela DC) y un polo en \\(z=0\\) (simple, debido al \\(z^{-1}\\)). Este sistema es causal (diferencia causal) y su √∫nico polo \\(z=0\\) est√° dentro del c√≠rculo unitario, por lo que es estable. De hecho, su respuesta al impulso \\(h[n]=\\delta[n] - \\delta[n-1]\\) suma 0 en valor absoluto (sumable). Este filtro elimina componentes de muy baja frecuencia, como la deriva de l√≠nea base en un ECG (), sin inestabilidad.\n\n\n\nUn sistema LTI discreto queda caracterizado completamente por su respuesta al impulso \\(h[n]\\). Dada cualquier entrada \\(x[n]\\), la salida es la convoluci√≥n discreta \\(y[n] = (x*h)[n] = \\sum_{k=-\\infty}^{\\infty} h[k]\\,x[n-k]\\). En el dominio Z, esta convoluci√≥n se convierte en multiplicaci√≥n: \\(Y(z) = H(z)\\,X(z)\\) (dentro de la intersecci√≥n de ROC de \\(X\\) y \\(H\\)). La funci√≥n de transferencia \\(H(z)\\) de un sistema LTI causal viene dada por la transformada Z de \\(h[n]\\) (unilateral). En sistemas de coeficientes constantes (difundidos en ingenier√≠a), \\(H(z)\\) suele ser una funci√≥n racional de \\(z\\):\n\\[H(z) = \\frac{B(z)}{A(z)} = \\frac{b_0 + b_1 z^{-1} + \\cdots + b_M z^{-M}}{1 + a_1 z^{-1} + \\cdots + a_N z^{-N}},\\]\ndonde \\(B(z)\\) y \\(A(z)\\) son polinomios en \\(z^{-1}\\). La raz√≥n de escribir en potencias de \\(z^{-1}\\) es para reflejar la causalidad (solo potencias no positivas de \\(z\\)). La ecuaci√≥n en diferencias asociada es:\n\\[y[n] + a_1 y[n-1] + \\cdots + a_N y[n-N] = b_0 x[n] + b_1 x[n-1] + \\cdots + b_M x[n-M].\\]\nEste es el modelo t√≠pico de sistemas LTI discreto. Si \\(N=0\\) (no hay realimentaci√≥n, solo ceros), el sistema es FIR (Finite Impulse Response), pues \\(h[n]\\) es de duraci√≥n finita (m√°ximo \\(M\\)). Si \\(N&gt;0\\), hay realimentaci√≥n y el sistema es IIR (Infinite Impulse Response), con respuesta al impulso te√≥ricamente infinita (aunque decreciente si es estable).\nDiagramas de bloques: Un LTI puede implementarse mediante sumas, retardos (\\(z^{-1}\\) representa un retardo de 1 muestra) y multiplicaciones por constantes. El diagrama de bloques representa visualmente la ecuaci√≥n en diferencias. Por ejemplo, para un filtro IIR de segundo orden:\n\\[y[n] = -a_1 y[n-1] - a_2 y[n-2] + b_0 x[n] + b_1 x[n-1] + b_2 x[n-2],\\]\nel diagrama en forma Directa II combinar√≠a los t√©rminos en una estructura can√≥nica con dos bloques de retardo en la rama de realimentaci√≥n y avance, sumadores para combinar las ramas, y coeficientes \\(a_i\\), \\(b_i\\). Cada polo corresponde a un lazo de realimentaci√≥n (coeficientes \\(a_i\\)) y cada cero a una ramificaci√≥n hacia la entrada (coeficientes \\(b_i\\)). Dibujar estos diagramas ayuda a entender la estructura interna, pero en este reporte nos enfocaremos m√°s en el an√°lisis matem√°tico. Cabe destacar que el tipo de filtro (pasa-bajos, pasa-altos, etc.) puede inferirse de \\(H(z)\\): por ejemplo, si \\(H(e^{j\\omega})\\) (respuesta en frecuencia) aten√∫a bajas frecuencias y deja pasar altas, es pasa-altos. Un m√©todo pr√°ctico es evaluar \\(H(z)\\) en \\(z=e^{j0}\\) (DC, \\(\\omega=0\\)) y en \\(z=e^{j\\pi}\\) (Nyquist, \\(\\omega=\\pi\\)): si \\(|H(e^{j0})|=0\\) y \\(|H(e^{j\\pi})|\\approx 1\\), es pasa-altos; al rev√©s ser√≠a pasa-bajos. Los ceros en \\(z=1\\) anulan \\(\\omega=0\\) (eliminan DC), t√≠picos en pasa-altos (), mientras ceros en \\(z=-1\\) anulan \\(\\omega=\\pi\\) (eliminan la componente de Nyquist, t√≠picos en pasa-bajos). Por su parte, polos cercanos a \\(z=1\\) refuerzan respuesta en bajas frecuencias; polos cercanos a \\(z=-1\\) refuerzan la alta frecuencia \\(\\pi\\). As√≠, el diagrama polo-cero brinda intuici√≥n: ceros sobre la circunferencia unitaria en cierto √°ngulo \\(\\theta_0\\) causan una notch (anulaci√≥n) en la frecuencia \\(\\omega=\\theta_0\\), mientras polos cerca de la unidad en \\(\\theta_0\\) generan picos (potenciales resonancias) alrededor de esa frecuencia.\nEjemplo (Filtro notch 60 Hz): Un problema com√∫n en biose√±ales es eliminar la interferencia de la red el√©ctrica (50/60 Hz) sobre, por ejemplo, EEG o ECG. Un filtro digital sencillo para eliminar 60 Hz (asumiendo frecuencia de muestreo \\(f_s=5000\\) Hz) es colocar ceros conjugados en \\(z = e^{\\pm j 2\\pi(60/5000)}\\). La funci√≥n de transferencia resultante puede ser:\n\\[H(z) = 1 - 2\\cos(2\\pi\\frac{60}{5000})\\,z^{-1} + z^{-2}.\\]\nEste \\(H(z)\\) tiene ceros en \\(e^{\\pm j2\\pi(60/5000)}\\) que anulan exactamente la componente de 60 Hz, implementando un filtro notch. Adem√°s, es un filtro FIR (orden 2) con coeficientes sim√©tricos, lo que le da fase lineal (importante para no deformar la forma de onda). ¬øEs estable? S√≠, al ser FIR no hay polos fuera del origen (solo polos en 0, con m√≥dulo 0). ¬øEs causal? S√≠, depende solo de muestras presentes y pasadas de la se√±al (\\(x[n]\\), \\(x[n-1]\\), \\(x[n-2]\\)). ¬øQu√© tipo de filtro es? Es un rechaza-banda estrecho centrado en 60 Hz (deja pasar el resto, pero rechaza esa frecuencia). En aplicaciones, este notch suele atenuar ruido de red sin distorsionar significativamente las se√±ales de inter√©s ().\n\n\n\nLos filtros FIR (Respuesta al Impulso Finita) son ampliamente utilizados en procesamiento biom√©dico porque pueden dise√±arse para tener respuesta en fase lineal, evitando distorsi√≥n de fase en la se√±al filtrada (lo cual es √∫til para preservar la morfolog√≠a de ondas ECG, por ejemplo). Una manera conceptualmente sencilla de dise√±ar un FIR es mediante el m√©todo de ventana (WindowFIRDesign.fm). Consiste en: (1) definir la respuesta frecuencial ideal deseada \\(H_d(e^{j\\omega})\\), (2) obtener la respuesta al impulso ideal \\(h_d[n]\\) como la transformada inversa de Fourier de \\(H_d\\), y (3) truncar \\(h_d[n]\\) (que usualmente es infinita o muy larga) mediante una funci√≥n ventana \\(w[n]\\) para obtener un FIR realizable \\(h[n] = h_d[n]\\,w[n]\\).\nPor ejemplo, supongamos que queremos un filtro pasa-bajos ideal con frecuencia de corte \\(\\omega_c\\). El impulso ideal es \\(h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}\\) (un sinc) que se extiende infinitamente. Para obtener un FIR causal de longitud \\(M\\), se multiplica \\(h_d[n]\\) por una ventana \\(w[n]\\) de longitud \\(M\\) centrada apropiadamente (y a menudo se aplica un corrimiento para hacer el filtro causal). Las ventanas com√∫nmente utilizadas incluyen: Rectangular, Bartlett (triangular), Hann (Hanning), Hamming, Blackman, y la Kaiser (que es ajustable). Cada ventana introduce un cierto l√≥bulo principal en la respuesta en frecuencia (determinando la anchura de la transici√≥n) y l√≥bulos laterales (que determinan el ripple o atenuaci√≥n en bandas de rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm).\nLas caracter√≠sticas t√≠picas de ventanas cl√°sicas (seg√∫n Oppenheim et al.¬†(WindowFIRDesign.fm) (WindowFIRDesign.fm)) son:\n\nRectangular: l√≥bulo principal m√°s angosto (ancho \\(\\approx 4\\pi/M\\) rad) pero l√≥bulos laterales m√°s altos (primer sidelobe ~\\(-13\\) dB, atenuaci√≥n de rechazo $$21 dB) (WindowFIRDesign.fm). Da la transici√≥n m√°s abrupta para un orden dado, al costo de peor rechazo de banda.\nBartlett (triangular): l√≥bulo principal algo m√°s ancho (\\(\\approx 8\\pi/M\\)), sidelobes ~\\(-25\\) dB (WindowFIRDesign.fm).\nHann: l√≥bulo principal \\(\\approx 8\\pi/M\\), sidelobes ~\\(-31\\) dB (WindowFIRDesign.fm) (mejor rechazo que rectangular pero transiciones m√°s suaves).\nHamming: l√≥bulo principal \\(\\approx 8\\pi/M\\), sidelobes \\(\\approx -41\\) dB (m√≠nima atenuaci√≥n ~53 dB en rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm). Es muy popular por su buen compromiso entre ancho de transici√≥n y rechazo en banda eliminada.\nBlackman: l√≥bulo principal m√°s ancho (\\(\\approx 12\\pi/M\\)) pero sidelobes muy bajos (~\\(-57\\) dB, atenuaci√≥n ~74 dB) (WindowFIRDesign.fm).\nKaiser: permite escoger un par√°metro \\(\\beta\\) para controlar la atenuaci√≥n de l√≥bulo lateral, ofreciendo flexibilidad. Aproximadamente, para lograr \\(A\\) dB de atenuaci√≥n, \\(\\beta \\approx 0.1102(A-8.7)\\) (para \\(A&gt;50\\)), y el ancho de transici√≥n normalizado \\(\\Delta\\omega\\) se relaciona con el orden \\(M\\) y \\(\\beta\\) por \\(M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\\) (WindowFIRDesign.fm) (estas f√≥rmulas provienen de aproximaciones de Kaiser y ayudan a dimensionar el filtro).\n\nEl m√©todo de ventanas es sencillo pero implica un compromiso fijo entre ancho de transici√≥n y ripple: una vez elegida la ventana, la √∫nica forma de mejorar la pendiente de corte es aumentar \\(M\\) (orden del filtro). Por ejemplo, la ventana Hamming siempre tendr√° ~\\(-53\\) dB de m√≠nimo en rechazo sin importar \\(M\\) (WindowFIRDesign.fm), pero al incrementar \\(M\\) se reducir√° la anchura de transici√≥n. En contraste, la ventana rectangular logra transiciones muy r√°pidas con orden modesto, pero su pobre rechazo (~21 dB) la hace inadecuada si necesitamos, digamos, eliminar ruido fuerte. En se√±ales biom√©dicas, suele preferirse reducir al m√≠nimo distorsiones residuales de ruido, por lo que ventanas con mejor rechazo (Hamming, Blackman o Kaiser ajustada) son comunes.\nC√°lculo del orden para especificaciones dadas: Dado un requerimiento de dise√±o (ej. atenuaci√≥n m√≠nima de 40 dB en banda eliminada y transici√≥n de 10 Hz), podemos estimar el orden necesario. Por ejemplo, en el taller se plantea dise√±ar un pasa-bajos FIR con \\(f_c = 55\\) Hz (definido al nivel de \\(-6\\) dB), que alcance al menos 20 dB de atenuaci√≥n a 60 Hz y &gt;40 dB m√°s all√° de 80 Hz. Esto implica una banda de transici√≥n bastante estrecha (de ~55 a 60 Hz) y un rechazo fuerte. Un enfoque ser√≠a probar varias ventanas:\n\nRectangular: probablemente no pueda dar 40 dB de rechazo (limita ~21 dB).\nHamming: puede dar ~53 dB de rechazo, suficiente, pero el ancho de transici√≥n \\(\\Delta f\\) ser√° ~\\(\\frac{3.3}{M}\\) (en radianes normalizados, equivalente aprox. a \\(\\frac{0.26 f_s}{M}\\) en Hz para banda bilateral). Para \\(\\Delta f \\approx 5\\) Hz con \\(f_s\\) suficientemente grande, requerir√° un \\(M\\) elevado.\nBlackman: dar√≠a &gt;60 dB de rechazo, pero su transici√≥n es m√°s ancha (por ser \\(12\\pi/M\\) rad).\nKaiser: se puede ajustar para 40 dB con quiz√°s menor \\(M\\) que Hamming, porque se elige justo la atenuaci√≥n requerida y minimiza ancho de transici√≥n para ese nivel.\n\nEn el taller, se sugiere calcular el orden m√≠nimo para cada ventana cumpliendo las specs y elegir la de menor orden. Esto implicar√≠a usar f√≥rmulas o tablas est√°ndar (WindowFIRDesign.fm) (WindowFIRDesign.fm). Por ejemplo, para 40 dB de rechazo y \\(\\Delta f = 20\\) Hz (digamos entre 60 y 80 Hz), la Hamming podr√≠a necesitar \\(M \\approx \\frac{3.3\\cdot 2\\pi}{(20/f_s)2\\pi} = \\frac{3.3 f_s}{20}\\) (esta es una estimaci√≥n tosca usando \\(\\Delta\\omega \\approx 8\\pi/M\\)). Si la se√±al es de voz muestreada a 8 kHz (caso t√≠pico, aunque aqu√≠ es biom√©dica a 200 Hz?), podemos obtener n√∫meros espec√≠ficos. En general, se podr√≠a iterar aumentando \\(M\\) y midiendo la respuesta espectral hasta que los requisitos se satisfagan.\nA modo de ilustraci√≥n pr√°ctica, dise√±emos un filtro FIR pasa-bajos con m√©todo del ventaneo en Python, usando scipy.signal.firwin. Por simplicidad, tomemos \\(f_s=200\\) Hz, \\(f_c=30\\) Hz, y usemos ventana de Hamming:\nimport numpy as np\nfrom scipy import signal\nfs = 200.0  # Hz\nfc = 30.0   # Hz (deseamos pasa-bajos)\nN = 51      # orden (se puede ajustar)\ntaps = signal.firwin(N, cutoff=fc, window='hamming', fs=fs)\nw, H = signal.freqz(taps, worN=8000, fs=fs)\n# Convertir respuesta a dB:\nH_db = 20*np.log10(np.abs(H))\n# Encontrar atenuaci√≥n en 60 Hz:\nidx_60 = np.argmin(np.abs(w-60))\nprint(f\"Atenuaci√≥n a 60Hz: {H_db[idx_60]:.2f} dB\")\n(El c√≥digo anterior calcula los coeficientes FIR con ventana de Hamming y eval√∫a la respuesta. Se puede iterar sobre N hasta lograr &gt;40 dB en 80 Hz, etc.)\nEn general, el m√©todo de ventanas es r√°pido y f√°cil de implementar. Su principal limitaci√≥n es la falta de control preciso sobre las bandas: el ripple y transici√≥n vienen determinados por la elecci√≥n de ventana, no exactamente por par√°metros deseados (excepto en Kaiser donde hay m√°s control). A√∫n as√≠, es muy √∫til en procesamiento biom√©dico cuando queremos filtros lineales en fase y podemos permitir √≥rdenes relativamente altos (el costo computacional suele ser menor preocupaci√≥n en aplicaciones off-line, pero en tiempo real un FIR muy largo puede introducir latencia).\n\n\n\nLos filtros IIR (Respuesta Infinita al Impulso) se suelen dise√±ar a partir de filtros anal√≥gicos prototipo utilizando transformaciones como la transformaci√≥n bilineal. Este enfoque aprovecha d√©cadas de dise√±os anal√≥gicos bien estudiados (Butterworth, Chebyshev, El√≠ptico, etc.) y los lleva al dominio digital asegurando estabilidad y correspondiendo frecuencias de inter√©s.\nTransformaci√≥n bilineal: Es una transformaci√≥n conforme que mapea el plano-\\(s\\) (Laplace) en el plano-\\(z\\) (Z) mediante la sustituci√≥n:\n\\[ s = \\frac{2}{T}\\,\\frac{z-1}{\\,z+1\\,}, \\]\ndonde \\(T\\) es el periodo de muestreo (usualmente tomamos \\(T=1\\) para frecuencias normalizadas, o usamos \\(2/T\\) para incluir \\(f_s\\) expl√≠citamente) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). Esta sustituci√≥n se adopta universalmente para convertir funciones de transferencia anal√≥gicas \\(H_a(s)\\) en funciones \\(H_d(z)\\) digitales (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). La clave es que la transformaci√≥n bilineal preserva la estabilidad: polos en el semiplano izquierdo (\\(\\Re(s)&lt;0\\)) mapean dentro del c√≠rculo unitario (\\(|z|&lt;1\\)) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). As√≠, un filtro anal√≥gico estable producir√° un filtro digital estable (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). Tambi√©n mapea el eje \\(j\\omega\\) (eje imaginario \\(s = j\\Omega\\)) en la circunferencia unitaria (\\(z = e^{j\\omega T}\\)) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre), aunque no linealmente en frecuencia. De hecho, existe una distorsi√≥n de la respuesta frecuencial conocida como warping: la relaci√≥n entre frecuencia anal√≥gica \\(\\Omega\\) y digital \\(\\omega\\) viene dada por \\(\\omega = 2 \\arctan(\\Omega T/2)\\) (y su inversa \\(\\Omega = \\frac{2}{T}\\tan(\\omega/2)\\)) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). Esto significa que la escala de frecuencias se comprime al mapear al dominio digital, especialmente conforme \\(\\omega\\) se acerca a Nyquist (\\(\\pi\\) rad/s).\nPara lidiar con el warping, en el dise√±o se realiza una pre-distorsi√≥n (pre-warping) de las especificaciones. Si deseamos que una frecuencia anal√≥gica \\(\\Omega_p\\) de corte corresponda exactamente a una digital \\(\\omega_p\\), calculamos \\(\\Omega_p = \\frac{2}{T}\\tan(\\omega_p/2)\\). Lo mismo para frecuencias de banda de rechazo, etc., antes de dise√±ar el filtro anal√≥gico. Luego aplicamos la transformaci√≥n bilineal. En la pr√°ctica, las funciones auxiliares de dise√±o (como scipy.signal.buttord, cheb1ord, etc.) permiten ingresar especificaciones directamente en el dominio digital y hacen el prewarping internamente (11.3. Common IIR filters ‚Äî Digital Signals Theory) (11.3. Common IIR filters ‚Äî Digital Signals Theory).\nPrototipos anal√≥gicos comunes:\n\nButterworth: Magnitud con m√°xima planitud en banda de paso (respuesta maximally flat). No presenta ondulaciones en banda de paso ni rechazo, pero la transici√≥n es la m√°s lenta de los tipos cl√°sicos (11.3. Common IIR filters ‚Äî Digital Signals Theory). Su funci√≥n de magnitud al cuadrado es \\(|H(j\\Omega)|^2 = \\frac{1}{1 + (\\frac{\\Omega}{\\Omega_c})^{2N}}\\). Para un orden \\(N\\), la atenuaci√≥n en rechazo aumenta gradualmente con la frecuencia. √ötil cuando se quiere respuesta suave sin ripple.\nChebyshev Tipo I: Presenta rizado en banda de paso (Œµ dB de variaci√≥n) pero ninguna ondulaci√≥n en banda de rechazo (11.3. Common IIR filters ‚Äî Digital Signals Theory). A cambio, logra una ca√≠da m√°s abrupta que Butterworth para el mismo orden (11.3. Common IIR filters ‚Äî Digital Signals Theory) (11.3. Common IIR filters ‚Äî Digital Signals Theory). La magnitud cumple \\(|H(j\\Omega)|^2 = \\frac{1}{1 + \\epsilon^2 T_N^2(\\Omega/\\Omega_c)}\\), donde \\(T_N\\) es el polinomio de Chebyshev de primer tipo (oscila entre ¬±1). Permite especificar ripple tolerado en pasobanda.\nChebyshev Tipo II: Lo opuesto: sin ripple en banda de paso, pero con ondulaci√≥n controlada en banda de rechazo. Tambi√©n llamados filtros de Chebyshev inversos. Tienen una transici√≥n algo m√°s lenta que los tipo I para igual orden, pero fase m√°s lineal en pasobanda (al no tener ripple ah√≠).\nEl√≠ptico (Cauer): Permite rizado tanto en pasobanda como en rechazo (ambos controlables) (11.3. Common IIR filters ‚Äî Digital Signals Theory), logrando la ca√≠da m√°s empinada de todas las aproximaciones para un orden dado (11.3. Common IIR filters ‚Äî Digital Signals Theory). Son los m√°s eficientes en t√©rminos de orden, a costa de ripple en ambas bandas y mayor no linealidad de fase. Incluyen ceros de transmisi√≥n en la banda eliminada, lo que les da atenuaci√≥n muy alta cerca de los bordes.\n\nEn resumen (11.3. Common IIR filters ‚Äî Digital Signals Theory): Butterworth no tiene ripple en ninguna banda (pero pendiente menor), Chebyshev I tiene ripple en paso (no en rechazo), Chebyshev II ripple en rechazo (no en paso), y El√≠ptico ripple en ambas, pero transici√≥n m√°s r√°pida. La Figura 1 ilustra las diferencias de respuesta en un ejemplo pr√°ctico.\n(image) Figura 1: Comparaci√≥n de la respuesta en magnitud (en dB) para filtros IIR pasa-bajos dise√±ados con las mismas especificaciones (pasa-bajos con \\(f_{p}=3.4\\) kHz con 1 dB de ripple en banda de paso, \\(f_{s}=3.8\\) kHz con 30 dB de atenuaci√≥n). El filtro el√≠ptico (orden 3, l√≠nea roja) logra la transici√≥n m√°s abrupta (ca√≠da m√°s r√°pida alrededor de 3.4-3.8 kHz) a costa de presentar ondulaciones tanto en la banda de paso como en la de rechazo. El Chebyshev I (orden 3, l√≠nea naranja) exhibe ripple en la banda de paso pero no en la de rechazo, con una pendiente intermedia. El Butterworth (orden 4, l√≠nea amarilla) no tiene ripple en ninguna banda, pero requiere un orden mayor y su ca√≠da es m√°s paulatina (transici√≥n m√°s suave) (11.3. Common IIR filters ‚Äî Digital Signals Theory) (11.3. Common IIR filters ‚Äî Digital Signals Theory). Todos cumplen con los requisitos (‚Äì1 dB a 3.4 kHz, ‚Äì30 dB a 3.8 kHz), pero el orden m√≠nimo necesario var√≠a (Butterworth necesit√≥ \\(N=4\\) mientras Chebyshev I y El√≠ptico lograron con \\(N=3\\)). Esto ilustra el compromiso entre pendiente de transici√≥n y ondulaciones en las distintas aproximaciones.\nEn dise√±o, elegir el tipo de filtro depende de la aplicaci√≥n: en biose√±ales, a veces se prefiere Butterworth para evitar cualquier ripple (ej. filtrar ECG sin distorsionar amplitud de componentes cl√≠nicas), otras veces un Chebyshev o El√≠ptico puede ser apropiado si se necesita un filtro muy selectivo (ej. aislar una banda muy estrecha de EEG) y se puede tolerar cierta variaci√≥n en la ganancia de la banda √∫til. La fase de los IIR no es lineal, pero si la distorsi√≥n de fase es un problema (por ejemplo, desplazamiento o deformaci√≥n de picos en ECG), puede mitigarse aplicando el filtro hacia adelante y hacia atr√°s (filtrado por procesamiento inverso con filtfilt de SciPy, logrando respuesta cero-fase a costa de procesar offline) (). En muchos casos, se pueden usar filtros IIR en tiempo real y lograr correcciones de fase si es necesario mediante t√©cnicas de compensaci√≥n o filtrado bidireccional.\nDise√±o por especificaciones: Las funciones buttord, cheb1ord, cheb2ord, ellipord de Python/MATLAB calculan el orden m√≠nimo y frecuencia de corte necesaria para cumplir especificaciones dadas (paso, rechazo, ripple). Luego butter, cheby1/2, ellip generan los coeficientes. En el taller, se plantea dise√±ar un pasa-bajos IIR para voz (ej. telef√≥nica: \\(f_s=8\\) kHz, \\(f_p=3.4\\) kHz, \\(f_s=3.8\\) kHz, ripple 1 dB, atenuaci√≥n 30 dB). Un proceso t√≠pico ser√≠a: usar ellipord para obtener el orden m√≠nimo el√≠ptico, cheb1ord para Chebyshev I, etc., comparar √≥rdenes y elegir uno. En nuestro ejemplo de la Figura 1, ya vimos c√≥mo Butterworth requer√≠a orden 4 frente a 3 de Chebyshev/El√≠ptico para la misma tarea, lo cual es com√∫n (Butterworth suele necesitar m√°s orden para specs estrictas). Generalmente, El√≠ptico da el menor orden, seguido por Chebyshev, luego Butterworth (11.3. Common IIR filters ‚Äî Digital Signals Theory). Sin embargo, a veces se evita El√≠ptico si un ripple en rechazo muy bajo es cr√≠tico (porque incluso la peque√±a ondulaci√≥n en banda eliminada puede ser indeseable para ciertas mediciones sensibles, aunque en la mayor√≠a de casos biom√©dicos 30 dB de atenuaci√≥n es suficiente sin importar un leve ripple residual).\nImplementaci√≥n en Python: A continuaci√≥n se ilustra c√≥mo dise√±ar un filtro Chebyshev Tipo I con SciPy para cumplir especificaciones de voz:\nimport numpy as np\nfrom scipy.signal import cheb1ord, cheby1, freqz\nfs = 8000.0  # Hz\nfp = 3400.0  # Hz pasabanda\nfsb = 3800.0 # Hz stopband\nrp = 1.0     # dB ripple paso\nrs = 30.0    # dB atenuacion rechazo\nN, Wn = cheb1ord(fp, fsb, rp, rs, fs=fs)  # orden y frecuencia cr√≠tica\nb, a = cheby1(N, rp, Wn, btype='low', fs=fs)\nw, h = freqz(b, a, worN=1024, fs=fs)\n# Verificar desempe√±o:\nH_db = 20*np.log10(np.abs(h))\nprint(f\"Orden Chebyshev I = {N}\")\nprint(f\"Ganancia a 3.4kHz = {H_db[np.argmin(np.abs(w-3400))]:.2f} dB\")\nprint(f\"Atenuaci√≥n a 3.8kHz = {H_db[np.argmin(np.abs(w-3800))]:.2f} dB\")\n(Este c√≥digo calcula el orden m√≠nimo y coeficientes de un Chebyshev I, luego eval√∫a la ganancia en 3.4 kHz y 3.8 kHz para verificar que est√© cerca de ‚Äì1 dB y ‚Äì30 dB respectivamente.)\nEl resultado confirmar√≠a el cumplimiento de especificaciones con el filtro dise√±ado. Del mismo modo podr√≠amos probar ellipord/ellip y buttord/butter. Vale notar que los dise√±os IIR generalmente no tienen control expl√≠cito de fase lineal (la fase es no lineal e importa evaluar el impacto en la se√±al; a veces, se realizan calibraciones o se aplica filtrado hacia atr√°s como mencionado para obtener fase cero).\n\n\n\nUna vez dise√±ado un filtro (FIR o IIR), es crucial validar su respuesta en frecuencia para asegurarse de que cumple con los requisitos. Esto implica computar \\(H(e^{j\\omega})\\) ‚Äì t√≠picamente mediante freqz ‚Äì y verificar ganancias en las bandas de paso (p.ej. p√©rdida de inserci√≥n o ripple) y bandas de rechazo (atenuaci√≥n m√≠nima). Tambi√©n se puede aplicar el filtro a se√±ales de prueba:\n\nImpulso unitario: la salida debe ser \\(h[n]\\) (sirve para obtener la respuesta al impulso directamente).\nEscal√≥n unitario: la salida debe aproximarse a la respuesta al escal√≥n (integral de \\(h[n]\\)), √∫til para verificar estabilidad (un filtro pasaaltos, por ej., a entrada escal√≥n deber√≠a asentarse a un valor constante, indicando que DC fue removido pero no inestabilidad creciente).\nSe√±al senoidal a frecuencias cr√≠ticas: por ejemplo, inyectar una senoide en la frecuencia de corte para ver si sale atenuada a ~-3 dB o -6 dB seg√∫n definici√≥n; inyectar una senoide en banda eliminada para confirmar fuerte atenuaci√≥n.\n\nEn contexto biom√©dico, se suele validar con se√±ales reales. Por ejemplo, si dise√±amos un filtro para eliminar deriva de l√≠nea base en ECG, podemos probarlo con una se√±al ECG con deriva artificial y comprobar que efectivamente la elimina sin distorsionar el complejo QRS.\n(image) Figura 2: Ejemplo de filtrado de un segmento de se√±al ECG con un filtro pasoalto para remover la deriva de l√≠nea base. En naranja se muestra el ECG original contaminado con una deriva lenta (simulada como una componente de muy baja frecuencia que causa que la l√≠nea base oscile). En amarillo se muestra la se√±al tras aplicar un filtro pasaaltos Butterworth de 4¬∞ orden con \\(f_c \\approx 0.5\\) Hz (aplicado con filtrado hacia adelante y atr√°s para lograr fase cero). Se observa que la se√±al filtrada se centra alrededor de cero voltios, eliminando las variaciones lentas de la l√≠nea base, mientras preserva las caracter√≠sticas importantes del ECG (picos QRS, ondas P y T) (). Este proceso mejora la calidad de la se√±al para an√°lisis posterior (por ejemplo, facilitando la detecci√≥n de eventos cardiacos), sin introducir distorsi√≥n apreciable en la forma de onda r√°pida del ECG.\nOtro ejemplo es la eliminaci√≥n de interferencia de red: un filtro notch dise√±ado como en secciones previas se puede aplicar a una se√±al EEG a la que deliberadamente se le suma un seno de 50 Hz; la validaci√≥n consistir√≠a en ver el espectro antes y despu√©s (verificando que la l√≠nea de 50 Hz desaparece tras filtrar) y que la actividad EEG en otras bandas permanece intacta.\nEn el dise√±o de filtros FIR e IIR para voz o biose√±ales, a veces se comparan m√©todos. Por ejemplo, en el taller se pide dise√±ar tanto un FIR por ventana como un IIR por transformaci√≥n bilineal para ciertas especificaciones. Comparar la respuesta espectral es instructivo: un FIR puede requerir mayor orden para lograr la misma nitidez de corte que un IIR, pero tendr√° fase lineal; el IIR lograr√° la especificaci√≥n con menos coeficientes, pero introducir√° dispersi√≥n de fase. Dependiendo de la aplicaci√≥n, uno u otro puede ser preferible. Estudios en filtrado de ECG han encontrado, por ejemplo, que filtros IIR y FIR bien dise√±ados pueden ambos remover el ruido de l√≠nea base efectivamente; los IIR (como filtros Butterworth pasaaltos) pueden ser implementados en tiempo real con pocas operaciones (comp.dsp | How to write a NotchFilter procedure| page 2), mientras que FIR largos podr√≠an introducir retardo si no se aplican con t√©cnicas especiales. Sin embargo, los FIR lineales en fase aseguran que caracter√≠sticas como la amplitud del ST o la morfolog√≠a de la onda P no se deformen ni se desplacen temporalmente, lo cual es cr√≠tico en ciertos an√°lisis diagn√≥sticos.\nEn resumen, la validaci√≥n espectral (y temporal) de los filtros dise√±ados garantiza que el filtro funcione como esperado en las se√±ales biom√©dicas objetivo. Se recomienda siempre verificar ganancia en banda pasante (por ej., asegurarse de que un filtro pasa-bajos no aten√∫e significativamente componentes importantes de la se√±al, salvo el ripple permitido) y atenuaci√≥n en banda eliminada (asegurarse de que el ruido o interferencia objetivo realmente se reduce a niveles aceptables). Con herramientas como Python/Matlab, esta validaci√≥n se realiza f√°cilmente visualizando la respuesta en frecuencia (como en las Figuras 1 y 2) y realizando pruebas con se√±ales sint√©ticas o reales.\n\n\n\nEste reporte abord√≥ los fundamentos te√≥ricos necesarios para analizar y dise√±ar sistemas discretos aplicados a se√±ales biom√©dicas. Se revis√≥ la transformada Z y su papel en caracterizar se√±ales y sistemas LTI, destacando la importancia de la regi√≥n de convergencia, polos, ceros, causalidad y estabilidad (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Tambi√©n se discuti√≥ c√≥mo interpretar y construir diagramas de bloques a partir de ecuaciones en diferencias, algo √∫til para implementar filtros digitalmente. En la parte de dise√±o, se cubrieron dos enfoques contrastantes: filtros FIR por m√©todo de ventanas, sencillos y con fase lineal (deseable en biom√©dica), y filtros IIR por transformaci√≥n bilineal a partir de prototipos anal√≥gicos (eficientes en orden, aunque con fase no lineal). Se compararon los principales tipos de aproximaciones anal√≥gicas (Butterworth, Chebyshev I/II, El√≠ptico) resaltando sus ventajas y compromisos (11.3. Common IIR filters ‚Äî Digital Signals Theory).\nA lo largo del documento, se enfatiz√≥ la aplicaci√≥n en se√±ales reales: eliminar deriva de l√≠nea base con pasaaltos, suprimir interferencia de red con filtros notch, limitar el ancho de banda de voz o EEG con pasabajos, etc., todo soportado por referencias acad√©micas y ejemplos de c√≥digo. En la pr√°ctica, el ingeniero biom√©dico debe decidir el tipo de filtro seg√∫n los requisitos cl√≠nicos: por ejemplo, ¬øes m√°s importante no distorsionar la forma de onda (fase lineal) o tener un filtro muy agudo (menor orden)? Este tipo de decisiones se facilita con la comprensi√≥n profunda de los conceptos aqu√≠ explicados.\nCon este marco te√≥rico, se est√° en capacidad de abordar el taller propuesto: calcular transformadas Z y ROC de se√±ales, analizar sistemas LTI (impulso, estabilidad, salida a entradas dadas), dibujar sus polos, ceros y estructuras, as√≠ como dise√±ar filtros FIR e IIR que satisfagan especificaciones dadas, especialmente dentro del contexto de procesamiento de se√±ales biom√©dicas donde la fidelidad y eficacia del filtrado impactan directamente la calidad de la informaci√≥n diagn√≥stica obtenida.\nReferencias: Las referencias provistas en el texto (ej.„Äê23„Äë,„Äê17„Äë,„Äê40„Äë) corresponden a fuentes que respaldan y complementan los puntos discutidos, incluyendo textos de procesamiento digital de se√±ales, art√≠culos de investigaci√≥n en filtrado de ECG/EEG, y documentaci√≥n de funciones de dise√±o de filtros. Estas fuentes ofrecen mayor detalle para el lector interesado en profundizar en aspectos espec√≠ficos. En particular, se destacan obras cl√°sicas como Oppenheim & Schafer en dise√±o FIR (WindowFIRDesign.fm), y recursos modernos como libros abiertos de se√±ales y sistemas (Transformada Z - Wikipedia, la enciclopedia libre) y tutoriales de SciPy (11.3. Common IIR filters ‚Äî Digital Signals Theory) que enriquecen la comprensi√≥n te√≥rica y pr√°ctica del procesamiento de se√±ales biom√©dicas."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#introducci√≥n",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#introducci√≥n",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "El procesamiento digital de se√±ales biom√©dicas (como ECG y EEG) emplea herramientas matem√°ticas para analizar y mejorar la calidad de estas se√±ales, extrayendo informaci√≥n √∫til para diagn√≥stico y monitoreo cl√≠nico (Procesamiento de se√±ales biom√©dicas: EEG & FPGA). En particular, la transformada Z y los filtros digitales (FIR e IIR) son fundamentales para modelar, analizar y modificar se√±ales en tiempo discreto. Por ejemplo, es com√∫n eliminar interferencias de l√≠nea base o ruido de red el√©ctrica (50/60 Hz) mediante filtros pasoalto o de rechazo (notch) adecuados (). Este reporte te√≥rico describe los conceptos clave para resolver un taller de an√°lisis de se√±ales biom√©dicas, cubriendo la transformada Z, la estabilidad y regi√≥n de convergencia (ROC), la representaci√≥n de sistemas LTI (Lineales e Invariantes en el Tiempo) mediante polos y ceros, la respuesta al impulso, los diagramas de bloques, y el dise√±o de filtros digitales FIR e IIR (incluyendo m√©todos de ventaneo y transformaci√≥n bilineal). Se incluyen ejemplos pr√°cticos en Python (usando numpy y scipy) para ilustrar implementaciones, con un claro enfoque en aplicaciones biom√©dicas como el filtrado de se√±ales ECG/EEG. Las explicaciones se apoyan en referencias acad√©micas para asegurar rigor te√≥rico."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#transformada-z-y-sistemas-lti-discretos",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#transformada-z-y-sistemas-lti-discretos",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "La transformada Z convierte una se√±al \\(x[n]\\) de tiempo discreto en una representaci√≥n en el dominio complejo. En forma bilateral, se define como:\n\\[X(z) = \\mathcal{Z}\\{x[n]\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\,z^{-n},\\]\ndonde \\(z\\) es una variable compleja \\(z = A e^{j\\omega}\\) (con \\(A=|z|\\) y \\(\\omega = \\arg(z)\\)) (Transformada Z - Wikipedia, la enciclopedia libre) (Transformada Z - Wikipedia, la enciclopedia libre). En se√±ales causales (\\(x[n]=0\\) para \\(n&lt;0\\)), suele usarse la transformada Z unilateral definida desde \\(n=0\\) hasta \\(\\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). La transformada Z es an√°loga a la transformada de Laplace en sistemas continuos, y de hecho puede verse como una serie de Laurent (suma infinita de potencias) (Transformada Z - Wikipedia, la enciclopedia libre).\nRegi√≥n de Convergencia (ROC): No toda se√±al tiene transformada Z en forma cerrada; la serie anterior converge √∫nicamente en ciertas regiones del plano \\(z\\). La ROC se define como el conjunto de valores de \\(z\\) para los cuales la serie converge absolutamente (Transformada Z - Wikipedia, la enciclopedia libre). En t√©rminos pr√°cticos, la ROC es el rango de \\(z\\) donde \\(\\sum_{n=-\\infty}^{\\infty}|x[n]z^{-n}| &lt; \\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). Por ejemplo, si \\(x[n] = a^n u[n]\\) (secuencia exponencial causal con \\(u[n]\\) la escal√≥n unidad), su transformada Z es \\(X(z) = \\frac{1}{1 - a\\,z^{-1}}\\), pero esta expresi√≥n es v√°lida solo si \\(|z| &gt; |a|\\) (ya que la serie geom√©trica converge cuando \\(|a/z|&lt;1\\)). As√≠, la ROC en este caso es \\(|z| &gt; |a|\\). Si la se√±al fuera anti-causal (\\(x[n]=0\\) para \\(n&gt;0\\)), la ROC ser√≠a \\(|z| &lt; |a|\\) (convergencia hacia adentro). Si \\(x[n]\\) tiene duraci√≥n finita (FIR), su transformada Z existe para todo \\(z\\neq0\\) excepto quiz√° puntos donde la propia definici√≥n tenga singularidades (por lo general ROC = todo el plano \\(z\\), excepto tal vez \\(z=0\\) o \\(z=\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). La ROC nunca incluye polos (donde la funci√≥n \\(X(z)\\) diverge) (Transformada Z - Wikipedia, la enciclopedia libre), es t√≠picamente un anillo o media-plano en el plano \\(z\\), y su ubicaci√≥n est√° ligada a propiedades de la se√±al como causalidad y estabilidad.\nPolos y ceros: Cualquier funci√≥n de transferencia discreta o transformada Z de una se√±al racional puede expresarse en forma de polos y ceros. Los ceros son valores de \\(z\\) que anulan \\(X(z)\\) (ra√≠ces del numerador), y los polos donde \\(X(z)\\) diverge (ra√≠ces del denominador). Por ejemplo, en \\(X(z) = \\frac{1}{1 - a z^{-1}}\\), hay un polo en \\(z=a\\) y un cero en \\(z=\\infty\\) (o equivalente, un cero de orden 1 en el origen en la funci√≥n \\(X(z)\\) multiplicada por \\(z^{-1}\\)). La representaci√≥n gr√°fica de polos y ceros en el plano \\(z\\) proporciona intuici√≥n sobre el comportamiento frecuencial: los ceros en la circunferencia unitaria (\\(|z|=1\\)) cancelan ciertas frecuencias, mientras que los polos cercanos a la circunferencia unitaria amplifican componentes espectrales cercanas a su √°ngulo.\nCausalidad: Un sistema LTI discreto es causal si \\(h[n]=0\\) para \\(n&lt;0\\) (su respuesta impulso es nula en tiempos negativos). En la transformada Z, esto implica que la ROC es externa, es decir, de la forma \\(|z|&gt;R\\) (convergencia hacia \\(\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). Todos los polos de un sistema causal deben estar dentro de la ROC (que para causal es exterior al polo de mayor radio) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Un detalle importante es que la ubicaci√≥n de polos por s√≠ sola no determina completamente la causalidad o estabilidad; la ROC es la que define cu√°l de las posibles se√±ales con esos polos es la realizada (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por ejemplo, una misma funci√≥n racional puede corresponder a un sistema causal inestable o a un sistema no causal estable, dependiendo de si la ROC se toma fuera o entre polos (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange).\nEstabilidad BIBO: Un sistema es estable (en sentido BIBO: Bounded-Input Bounded-Output) si su respuesta al impulso \\(h[n]\\) es absolutamente sumable, \\(\\sum_{n=-\\infty}^{\\infty}|h[n]| &lt; \\infty\\). Esta condici√≥n garantiza que cualquier entrada acotada produce salida acotada (BIBO stability - Wikipedia). En el dominio Z, estabilidad equivale a que la ROC de \\(H(z)\\) contenga al c√≠rculo unitario (\\(|z|=1\\)) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Para sistemas causales, esto se traduce en que todos los polos deben estar dentro del c√≠rculo unitario (ya que la ROC causal comienza fuera del polo de mayor magnitud) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por tanto, un filtro digital causal ser√° estable si sus polos \\(p_i\\) satisfacen \\(|p_i|&lt;1\\). En sistemas no causales (e.g.¬†acausales dise√±ados con filtrado hacia atr√°s y adelante para cancelar fase), la estabilidad puede lograrse con polos fuera del unitario siempre y cuando la ROC (un anillo) incluya el unitario (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange), aunque estos casos son menos comunes en l√≠nea real. En general, para dise√±o de filtros digitales asumiremos causalidad, por lo que chequear estabilidad equivale a verificar polos dentro del unitario.\nEjemplo (ECG y estabilidad): Considere un filtro pasoalto dise√±ado para remover la l√≠nea base de ECG definido por la diferencia \\(y[n] = x[n] - x[n-1]\\). Su funci√≥n de transferencia es \\(H(z) = 1 - z^{-1}\\), con un cero en \\(z=1\\) (cancela DC) y un polo en \\(z=0\\) (simple, debido al \\(z^{-1}\\)). Este sistema es causal (diferencia causal) y su √∫nico polo \\(z=0\\) est√° dentro del c√≠rculo unitario, por lo que es estable. De hecho, su respuesta al impulso \\(h[n]=\\delta[n] - \\delta[n-1]\\) suma 0 en valor absoluto (sumable). Este filtro elimina componentes de muy baja frecuencia, como la deriva de l√≠nea base en un ECG (), sin inestabilidad."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#an√°lisis-de-sistemas-lti-en-tiempo-discreto",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#an√°lisis-de-sistemas-lti-en-tiempo-discreto",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "Un sistema LTI discreto queda caracterizado completamente por su respuesta al impulso \\(h[n]\\). Dada cualquier entrada \\(x[n]\\), la salida es la convoluci√≥n discreta \\(y[n] = (x*h)[n] = \\sum_{k=-\\infty}^{\\infty} h[k]\\,x[n-k]\\). En el dominio Z, esta convoluci√≥n se convierte en multiplicaci√≥n: \\(Y(z) = H(z)\\,X(z)\\) (dentro de la intersecci√≥n de ROC de \\(X\\) y \\(H\\)). La funci√≥n de transferencia \\(H(z)\\) de un sistema LTI causal viene dada por la transformada Z de \\(h[n]\\) (unilateral). En sistemas de coeficientes constantes (difundidos en ingenier√≠a), \\(H(z)\\) suele ser una funci√≥n racional de \\(z\\):\n\\[H(z) = \\frac{B(z)}{A(z)} = \\frac{b_0 + b_1 z^{-1} + \\cdots + b_M z^{-M}}{1 + a_1 z^{-1} + \\cdots + a_N z^{-N}},\\]\ndonde \\(B(z)\\) y \\(A(z)\\) son polinomios en \\(z^{-1}\\). La raz√≥n de escribir en potencias de \\(z^{-1}\\) es para reflejar la causalidad (solo potencias no positivas de \\(z\\)). La ecuaci√≥n en diferencias asociada es:\n\\[y[n] + a_1 y[n-1] + \\cdots + a_N y[n-N] = b_0 x[n] + b_1 x[n-1] + \\cdots + b_M x[n-M].\\]\nEste es el modelo t√≠pico de sistemas LTI discreto. Si \\(N=0\\) (no hay realimentaci√≥n, solo ceros), el sistema es FIR (Finite Impulse Response), pues \\(h[n]\\) es de duraci√≥n finita (m√°ximo \\(M\\)). Si \\(N&gt;0\\), hay realimentaci√≥n y el sistema es IIR (Infinite Impulse Response), con respuesta al impulso te√≥ricamente infinita (aunque decreciente si es estable).\nDiagramas de bloques: Un LTI puede implementarse mediante sumas, retardos (\\(z^{-1}\\) representa un retardo de 1 muestra) y multiplicaciones por constantes. El diagrama de bloques representa visualmente la ecuaci√≥n en diferencias. Por ejemplo, para un filtro IIR de segundo orden:\n\\[y[n] = -a_1 y[n-1] - a_2 y[n-2] + b_0 x[n] + b_1 x[n-1] + b_2 x[n-2],\\]\nel diagrama en forma Directa II combinar√≠a los t√©rminos en una estructura can√≥nica con dos bloques de retardo en la rama de realimentaci√≥n y avance, sumadores para combinar las ramas, y coeficientes \\(a_i\\), \\(b_i\\). Cada polo corresponde a un lazo de realimentaci√≥n (coeficientes \\(a_i\\)) y cada cero a una ramificaci√≥n hacia la entrada (coeficientes \\(b_i\\)). Dibujar estos diagramas ayuda a entender la estructura interna, pero en este reporte nos enfocaremos m√°s en el an√°lisis matem√°tico. Cabe destacar que el tipo de filtro (pasa-bajos, pasa-altos, etc.) puede inferirse de \\(H(z)\\): por ejemplo, si \\(H(e^{j\\omega})\\) (respuesta en frecuencia) aten√∫a bajas frecuencias y deja pasar altas, es pasa-altos. Un m√©todo pr√°ctico es evaluar \\(H(z)\\) en \\(z=e^{j0}\\) (DC, \\(\\omega=0\\)) y en \\(z=e^{j\\pi}\\) (Nyquist, \\(\\omega=\\pi\\)): si \\(|H(e^{j0})|=0\\) y \\(|H(e^{j\\pi})|\\approx 1\\), es pasa-altos; al rev√©s ser√≠a pasa-bajos. Los ceros en \\(z=1\\) anulan \\(\\omega=0\\) (eliminan DC), t√≠picos en pasa-altos (), mientras ceros en \\(z=-1\\) anulan \\(\\omega=\\pi\\) (eliminan la componente de Nyquist, t√≠picos en pasa-bajos). Por su parte, polos cercanos a \\(z=1\\) refuerzan respuesta en bajas frecuencias; polos cercanos a \\(z=-1\\) refuerzan la alta frecuencia \\(\\pi\\). As√≠, el diagrama polo-cero brinda intuici√≥n: ceros sobre la circunferencia unitaria en cierto √°ngulo \\(\\theta_0\\) causan una notch (anulaci√≥n) en la frecuencia \\(\\omega=\\theta_0\\), mientras polos cerca de la unidad en \\(\\theta_0\\) generan picos (potenciales resonancias) alrededor de esa frecuencia.\nEjemplo (Filtro notch 60 Hz): Un problema com√∫n en biose√±ales es eliminar la interferencia de la red el√©ctrica (50/60 Hz) sobre, por ejemplo, EEG o ECG. Un filtro digital sencillo para eliminar 60 Hz (asumiendo frecuencia de muestreo \\(f_s=5000\\) Hz) es colocar ceros conjugados en \\(z = e^{\\pm j 2\\pi(60/5000)}\\). La funci√≥n de transferencia resultante puede ser:\n\\[H(z) = 1 - 2\\cos(2\\pi\\frac{60}{5000})\\,z^{-1} + z^{-2}.\\]\nEste \\(H(z)\\) tiene ceros en \\(e^{\\pm j2\\pi(60/5000)}\\) que anulan exactamente la componente de 60 Hz, implementando un filtro notch. Adem√°s, es un filtro FIR (orden 2) con coeficientes sim√©tricos, lo que le da fase lineal (importante para no deformar la forma de onda). ¬øEs estable? S√≠, al ser FIR no hay polos fuera del origen (solo polos en 0, con m√≥dulo 0). ¬øEs causal? S√≠, depende solo de muestras presentes y pasadas de la se√±al (\\(x[n]\\), \\(x[n-1]\\), \\(x[n-2]\\)). ¬øQu√© tipo de filtro es? Es un rechaza-banda estrecho centrado en 60 Hz (deja pasar el resto, pero rechaza esa frecuencia). En aplicaciones, este notch suele atenuar ruido de red sin distorsionar significativamente las se√±ales de inter√©s ()."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#dise√±o-de-filtros-fir-por-el-m√©todo-de-ventanas",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#dise√±o-de-filtros-fir-por-el-m√©todo-de-ventanas",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "Los filtros FIR (Respuesta al Impulso Finita) son ampliamente utilizados en procesamiento biom√©dico porque pueden dise√±arse para tener respuesta en fase lineal, evitando distorsi√≥n de fase en la se√±al filtrada (lo cual es √∫til para preservar la morfolog√≠a de ondas ECG, por ejemplo). Una manera conceptualmente sencilla de dise√±ar un FIR es mediante el m√©todo de ventana (WindowFIRDesign.fm). Consiste en: (1) definir la respuesta frecuencial ideal deseada \\(H_d(e^{j\\omega})\\), (2) obtener la respuesta al impulso ideal \\(h_d[n]\\) como la transformada inversa de Fourier de \\(H_d\\), y (3) truncar \\(h_d[n]\\) (que usualmente es infinita o muy larga) mediante una funci√≥n ventana \\(w[n]\\) para obtener un FIR realizable \\(h[n] = h_d[n]\\,w[n]\\).\nPor ejemplo, supongamos que queremos un filtro pasa-bajos ideal con frecuencia de corte \\(\\omega_c\\). El impulso ideal es \\(h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}\\) (un sinc) que se extiende infinitamente. Para obtener un FIR causal de longitud \\(M\\), se multiplica \\(h_d[n]\\) por una ventana \\(w[n]\\) de longitud \\(M\\) centrada apropiadamente (y a menudo se aplica un corrimiento para hacer el filtro causal). Las ventanas com√∫nmente utilizadas incluyen: Rectangular, Bartlett (triangular), Hann (Hanning), Hamming, Blackman, y la Kaiser (que es ajustable). Cada ventana introduce un cierto l√≥bulo principal en la respuesta en frecuencia (determinando la anchura de la transici√≥n) y l√≥bulos laterales (que determinan el ripple o atenuaci√≥n en bandas de rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm).\nLas caracter√≠sticas t√≠picas de ventanas cl√°sicas (seg√∫n Oppenheim et al.¬†(WindowFIRDesign.fm) (WindowFIRDesign.fm)) son:\n\nRectangular: l√≥bulo principal m√°s angosto (ancho \\(\\approx 4\\pi/M\\) rad) pero l√≥bulos laterales m√°s altos (primer sidelobe ~\\(-13\\) dB, atenuaci√≥n de rechazo $$21 dB) (WindowFIRDesign.fm). Da la transici√≥n m√°s abrupta para un orden dado, al costo de peor rechazo de banda.\nBartlett (triangular): l√≥bulo principal algo m√°s ancho (\\(\\approx 8\\pi/M\\)), sidelobes ~\\(-25\\) dB (WindowFIRDesign.fm).\nHann: l√≥bulo principal \\(\\approx 8\\pi/M\\), sidelobes ~\\(-31\\) dB (WindowFIRDesign.fm) (mejor rechazo que rectangular pero transiciones m√°s suaves).\nHamming: l√≥bulo principal \\(\\approx 8\\pi/M\\), sidelobes \\(\\approx -41\\) dB (m√≠nima atenuaci√≥n ~53 dB en rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm). Es muy popular por su buen compromiso entre ancho de transici√≥n y rechazo en banda eliminada.\nBlackman: l√≥bulo principal m√°s ancho (\\(\\approx 12\\pi/M\\)) pero sidelobes muy bajos (~\\(-57\\) dB, atenuaci√≥n ~74 dB) (WindowFIRDesign.fm).\nKaiser: permite escoger un par√°metro \\(\\beta\\) para controlar la atenuaci√≥n de l√≥bulo lateral, ofreciendo flexibilidad. Aproximadamente, para lograr \\(A\\) dB de atenuaci√≥n, \\(\\beta \\approx 0.1102(A-8.7)\\) (para \\(A&gt;50\\)), y el ancho de transici√≥n normalizado \\(\\Delta\\omega\\) se relaciona con el orden \\(M\\) y \\(\\beta\\) por \\(M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\\) (WindowFIRDesign.fm) (estas f√≥rmulas provienen de aproximaciones de Kaiser y ayudan a dimensionar el filtro).\n\nEl m√©todo de ventanas es sencillo pero implica un compromiso fijo entre ancho de transici√≥n y ripple: una vez elegida la ventana, la √∫nica forma de mejorar la pendiente de corte es aumentar \\(M\\) (orden del filtro). Por ejemplo, la ventana Hamming siempre tendr√° ~\\(-53\\) dB de m√≠nimo en rechazo sin importar \\(M\\) (WindowFIRDesign.fm), pero al incrementar \\(M\\) se reducir√° la anchura de transici√≥n. En contraste, la ventana rectangular logra transiciones muy r√°pidas con orden modesto, pero su pobre rechazo (~21 dB) la hace inadecuada si necesitamos, digamos, eliminar ruido fuerte. En se√±ales biom√©dicas, suele preferirse reducir al m√≠nimo distorsiones residuales de ruido, por lo que ventanas con mejor rechazo (Hamming, Blackman o Kaiser ajustada) son comunes.\nC√°lculo del orden para especificaciones dadas: Dado un requerimiento de dise√±o (ej. atenuaci√≥n m√≠nima de 40 dB en banda eliminada y transici√≥n de 10 Hz), podemos estimar el orden necesario. Por ejemplo, en el taller se plantea dise√±ar un pasa-bajos FIR con \\(f_c = 55\\) Hz (definido al nivel de \\(-6\\) dB), que alcance al menos 20 dB de atenuaci√≥n a 60 Hz y &gt;40 dB m√°s all√° de 80 Hz. Esto implica una banda de transici√≥n bastante estrecha (de ~55 a 60 Hz) y un rechazo fuerte. Un enfoque ser√≠a probar varias ventanas:\n\nRectangular: probablemente no pueda dar 40 dB de rechazo (limita ~21 dB).\nHamming: puede dar ~53 dB de rechazo, suficiente, pero el ancho de transici√≥n \\(\\Delta f\\) ser√° ~\\(\\frac{3.3}{M}\\) (en radianes normalizados, equivalente aprox. a \\(\\frac{0.26 f_s}{M}\\) en Hz para banda bilateral). Para \\(\\Delta f \\approx 5\\) Hz con \\(f_s\\) suficientemente grande, requerir√° un \\(M\\) elevado.\nBlackman: dar√≠a &gt;60 dB de rechazo, pero su transici√≥n es m√°s ancha (por ser \\(12\\pi/M\\) rad).\nKaiser: se puede ajustar para 40 dB con quiz√°s menor \\(M\\) que Hamming, porque se elige justo la atenuaci√≥n requerida y minimiza ancho de transici√≥n para ese nivel.\n\nEn el taller, se sugiere calcular el orden m√≠nimo para cada ventana cumpliendo las specs y elegir la de menor orden. Esto implicar√≠a usar f√≥rmulas o tablas est√°ndar (WindowFIRDesign.fm) (WindowFIRDesign.fm). Por ejemplo, para 40 dB de rechazo y \\(\\Delta f = 20\\) Hz (digamos entre 60 y 80 Hz), la Hamming podr√≠a necesitar \\(M \\approx \\frac{3.3\\cdot 2\\pi}{(20/f_s)2\\pi} = \\frac{3.3 f_s}{20}\\) (esta es una estimaci√≥n tosca usando \\(\\Delta\\omega \\approx 8\\pi/M\\)). Si la se√±al es de voz muestreada a 8 kHz (caso t√≠pico, aunque aqu√≠ es biom√©dica a 200 Hz?), podemos obtener n√∫meros espec√≠ficos. En general, se podr√≠a iterar aumentando \\(M\\) y midiendo la respuesta espectral hasta que los requisitos se satisfagan.\nA modo de ilustraci√≥n pr√°ctica, dise√±emos un filtro FIR pasa-bajos con m√©todo del ventaneo en Python, usando scipy.signal.firwin. Por simplicidad, tomemos \\(f_s=200\\) Hz, \\(f_c=30\\) Hz, y usemos ventana de Hamming:\nimport numpy as np\nfrom scipy import signal\nfs = 200.0  # Hz\nfc = 30.0   # Hz (deseamos pasa-bajos)\nN = 51      # orden (se puede ajustar)\ntaps = signal.firwin(N, cutoff=fc, window='hamming', fs=fs)\nw, H = signal.freqz(taps, worN=8000, fs=fs)\n# Convertir respuesta a dB:\nH_db = 20*np.log10(np.abs(H))\n# Encontrar atenuaci√≥n en 60 Hz:\nidx_60 = np.argmin(np.abs(w-60))\nprint(f\"Atenuaci√≥n a 60Hz: {H_db[idx_60]:.2f} dB\")\n(El c√≥digo anterior calcula los coeficientes FIR con ventana de Hamming y eval√∫a la respuesta. Se puede iterar sobre N hasta lograr &gt;40 dB en 80 Hz, etc.)\nEn general, el m√©todo de ventanas es r√°pido y f√°cil de implementar. Su principal limitaci√≥n es la falta de control preciso sobre las bandas: el ripple y transici√≥n vienen determinados por la elecci√≥n de ventana, no exactamente por par√°metros deseados (excepto en Kaiser donde hay m√°s control). A√∫n as√≠, es muy √∫til en procesamiento biom√©dico cuando queremos filtros lineales en fase y podemos permitir √≥rdenes relativamente altos (el costo computacional suele ser menor preocupaci√≥n en aplicaciones off-line, pero en tiempo real un FIR muy largo puede introducir latencia)."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#dise√±o-de-filtros-iir-por-transformaci√≥n-bilineal",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#dise√±o-de-filtros-iir-por-transformaci√≥n-bilineal",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "Los filtros IIR (Respuesta Infinita al Impulso) se suelen dise√±ar a partir de filtros anal√≥gicos prototipo utilizando transformaciones como la transformaci√≥n bilineal. Este enfoque aprovecha d√©cadas de dise√±os anal√≥gicos bien estudiados (Butterworth, Chebyshev, El√≠ptico, etc.) y los lleva al dominio digital asegurando estabilidad y correspondiendo frecuencias de inter√©s.\nTransformaci√≥n bilineal: Es una transformaci√≥n conforme que mapea el plano-\\(s\\) (Laplace) en el plano-\\(z\\) (Z) mediante la sustituci√≥n:\n\\[ s = \\frac{2}{T}\\,\\frac{z-1}{\\,z+1\\,}, \\]\ndonde \\(T\\) es el periodo de muestreo (usualmente tomamos \\(T=1\\) para frecuencias normalizadas, o usamos \\(2/T\\) para incluir \\(f_s\\) expl√≠citamente) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). Esta sustituci√≥n se adopta universalmente para convertir funciones de transferencia anal√≥gicas \\(H_a(s)\\) en funciones \\(H_d(z)\\) digitales (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). La clave es que la transformaci√≥n bilineal preserva la estabilidad: polos en el semiplano izquierdo (\\(\\Re(s)&lt;0\\)) mapean dentro del c√≠rculo unitario (\\(|z|&lt;1\\)) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). As√≠, un filtro anal√≥gico estable producir√° un filtro digital estable (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). Tambi√©n mapea el eje \\(j\\omega\\) (eje imaginario \\(s = j\\Omega\\)) en la circunferencia unitaria (\\(z = e^{j\\omega T}\\)) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre), aunque no linealmente en frecuencia. De hecho, existe una distorsi√≥n de la respuesta frecuencial conocida como warping: la relaci√≥n entre frecuencia anal√≥gica \\(\\Omega\\) y digital \\(\\omega\\) viene dada por \\(\\omega = 2 \\arctan(\\Omega T/2)\\) (y su inversa \\(\\Omega = \\frac{2}{T}\\tan(\\omega/2)\\)) (Transformaci√≥n bilineal - Wikipedia, la enciclopedia libre). Esto significa que la escala de frecuencias se comprime al mapear al dominio digital, especialmente conforme \\(\\omega\\) se acerca a Nyquist (\\(\\pi\\) rad/s).\nPara lidiar con el warping, en el dise√±o se realiza una pre-distorsi√≥n (pre-warping) de las especificaciones. Si deseamos que una frecuencia anal√≥gica \\(\\Omega_p\\) de corte corresponda exactamente a una digital \\(\\omega_p\\), calculamos \\(\\Omega_p = \\frac{2}{T}\\tan(\\omega_p/2)\\). Lo mismo para frecuencias de banda de rechazo, etc., antes de dise√±ar el filtro anal√≥gico. Luego aplicamos la transformaci√≥n bilineal. En la pr√°ctica, las funciones auxiliares de dise√±o (como scipy.signal.buttord, cheb1ord, etc.) permiten ingresar especificaciones directamente en el dominio digital y hacen el prewarping internamente (11.3. Common IIR filters ‚Äî Digital Signals Theory) (11.3. Common IIR filters ‚Äî Digital Signals Theory).\nPrototipos anal√≥gicos comunes:\n\nButterworth: Magnitud con m√°xima planitud en banda de paso (respuesta maximally flat). No presenta ondulaciones en banda de paso ni rechazo, pero la transici√≥n es la m√°s lenta de los tipos cl√°sicos (11.3. Common IIR filters ‚Äî Digital Signals Theory). Su funci√≥n de magnitud al cuadrado es \\(|H(j\\Omega)|^2 = \\frac{1}{1 + (\\frac{\\Omega}{\\Omega_c})^{2N}}\\). Para un orden \\(N\\), la atenuaci√≥n en rechazo aumenta gradualmente con la frecuencia. √ötil cuando se quiere respuesta suave sin ripple.\nChebyshev Tipo I: Presenta rizado en banda de paso (Œµ dB de variaci√≥n) pero ninguna ondulaci√≥n en banda de rechazo (11.3. Common IIR filters ‚Äî Digital Signals Theory). A cambio, logra una ca√≠da m√°s abrupta que Butterworth para el mismo orden (11.3. Common IIR filters ‚Äî Digital Signals Theory) (11.3. Common IIR filters ‚Äî Digital Signals Theory). La magnitud cumple \\(|H(j\\Omega)|^2 = \\frac{1}{1 + \\epsilon^2 T_N^2(\\Omega/\\Omega_c)}\\), donde \\(T_N\\) es el polinomio de Chebyshev de primer tipo (oscila entre ¬±1). Permite especificar ripple tolerado en pasobanda.\nChebyshev Tipo II: Lo opuesto: sin ripple en banda de paso, pero con ondulaci√≥n controlada en banda de rechazo. Tambi√©n llamados filtros de Chebyshev inversos. Tienen una transici√≥n algo m√°s lenta que los tipo I para igual orden, pero fase m√°s lineal en pasobanda (al no tener ripple ah√≠).\nEl√≠ptico (Cauer): Permite rizado tanto en pasobanda como en rechazo (ambos controlables) (11.3. Common IIR filters ‚Äî Digital Signals Theory), logrando la ca√≠da m√°s empinada de todas las aproximaciones para un orden dado (11.3. Common IIR filters ‚Äî Digital Signals Theory). Son los m√°s eficientes en t√©rminos de orden, a costa de ripple en ambas bandas y mayor no linealidad de fase. Incluyen ceros de transmisi√≥n en la banda eliminada, lo que les da atenuaci√≥n muy alta cerca de los bordes.\n\nEn resumen (11.3. Common IIR filters ‚Äî Digital Signals Theory): Butterworth no tiene ripple en ninguna banda (pero pendiente menor), Chebyshev I tiene ripple en paso (no en rechazo), Chebyshev II ripple en rechazo (no en paso), y El√≠ptico ripple en ambas, pero transici√≥n m√°s r√°pida. La Figura 1 ilustra las diferencias de respuesta en un ejemplo pr√°ctico.\n(image) Figura 1: Comparaci√≥n de la respuesta en magnitud (en dB) para filtros IIR pasa-bajos dise√±ados con las mismas especificaciones (pasa-bajos con \\(f_{p}=3.4\\) kHz con 1 dB de ripple en banda de paso, \\(f_{s}=3.8\\) kHz con 30 dB de atenuaci√≥n). El filtro el√≠ptico (orden 3, l√≠nea roja) logra la transici√≥n m√°s abrupta (ca√≠da m√°s r√°pida alrededor de 3.4-3.8 kHz) a costa de presentar ondulaciones tanto en la banda de paso como en la de rechazo. El Chebyshev I (orden 3, l√≠nea naranja) exhibe ripple en la banda de paso pero no en la de rechazo, con una pendiente intermedia. El Butterworth (orden 4, l√≠nea amarilla) no tiene ripple en ninguna banda, pero requiere un orden mayor y su ca√≠da es m√°s paulatina (transici√≥n m√°s suave) (11.3. Common IIR filters ‚Äî Digital Signals Theory) (11.3. Common IIR filters ‚Äî Digital Signals Theory). Todos cumplen con los requisitos (‚Äì1 dB a 3.4 kHz, ‚Äì30 dB a 3.8 kHz), pero el orden m√≠nimo necesario var√≠a (Butterworth necesit√≥ \\(N=4\\) mientras Chebyshev I y El√≠ptico lograron con \\(N=3\\)). Esto ilustra el compromiso entre pendiente de transici√≥n y ondulaciones en las distintas aproximaciones.\nEn dise√±o, elegir el tipo de filtro depende de la aplicaci√≥n: en biose√±ales, a veces se prefiere Butterworth para evitar cualquier ripple (ej. filtrar ECG sin distorsionar amplitud de componentes cl√≠nicas), otras veces un Chebyshev o El√≠ptico puede ser apropiado si se necesita un filtro muy selectivo (ej. aislar una banda muy estrecha de EEG) y se puede tolerar cierta variaci√≥n en la ganancia de la banda √∫til. La fase de los IIR no es lineal, pero si la distorsi√≥n de fase es un problema (por ejemplo, desplazamiento o deformaci√≥n de picos en ECG), puede mitigarse aplicando el filtro hacia adelante y hacia atr√°s (filtrado por procesamiento inverso con filtfilt de SciPy, logrando respuesta cero-fase a costa de procesar offline) (). En muchos casos, se pueden usar filtros IIR en tiempo real y lograr correcciones de fase si es necesario mediante t√©cnicas de compensaci√≥n o filtrado bidireccional.\nDise√±o por especificaciones: Las funciones buttord, cheb1ord, cheb2ord, ellipord de Python/MATLAB calculan el orden m√≠nimo y frecuencia de corte necesaria para cumplir especificaciones dadas (paso, rechazo, ripple). Luego butter, cheby1/2, ellip generan los coeficientes. En el taller, se plantea dise√±ar un pasa-bajos IIR para voz (ej. telef√≥nica: \\(f_s=8\\) kHz, \\(f_p=3.4\\) kHz, \\(f_s=3.8\\) kHz, ripple 1 dB, atenuaci√≥n 30 dB). Un proceso t√≠pico ser√≠a: usar ellipord para obtener el orden m√≠nimo el√≠ptico, cheb1ord para Chebyshev I, etc., comparar √≥rdenes y elegir uno. En nuestro ejemplo de la Figura 1, ya vimos c√≥mo Butterworth requer√≠a orden 4 frente a 3 de Chebyshev/El√≠ptico para la misma tarea, lo cual es com√∫n (Butterworth suele necesitar m√°s orden para specs estrictas). Generalmente, El√≠ptico da el menor orden, seguido por Chebyshev, luego Butterworth (11.3. Common IIR filters ‚Äî Digital Signals Theory). Sin embargo, a veces se evita El√≠ptico si un ripple en rechazo muy bajo es cr√≠tico (porque incluso la peque√±a ondulaci√≥n en banda eliminada puede ser indeseable para ciertas mediciones sensibles, aunque en la mayor√≠a de casos biom√©dicos 30 dB de atenuaci√≥n es suficiente sin importar un leve ripple residual).\nImplementaci√≥n en Python: A continuaci√≥n se ilustra c√≥mo dise√±ar un filtro Chebyshev Tipo I con SciPy para cumplir especificaciones de voz:\nimport numpy as np\nfrom scipy.signal import cheb1ord, cheby1, freqz\nfs = 8000.0  # Hz\nfp = 3400.0  # Hz pasabanda\nfsb = 3800.0 # Hz stopband\nrp = 1.0     # dB ripple paso\nrs = 30.0    # dB atenuacion rechazo\nN, Wn = cheb1ord(fp, fsb, rp, rs, fs=fs)  # orden y frecuencia cr√≠tica\nb, a = cheby1(N, rp, Wn, btype='low', fs=fs)\nw, h = freqz(b, a, worN=1024, fs=fs)\n# Verificar desempe√±o:\nH_db = 20*np.log10(np.abs(h))\nprint(f\"Orden Chebyshev I = {N}\")\nprint(f\"Ganancia a 3.4kHz = {H_db[np.argmin(np.abs(w-3400))]:.2f} dB\")\nprint(f\"Atenuaci√≥n a 3.8kHz = {H_db[np.argmin(np.abs(w-3800))]:.2f} dB\")\n(Este c√≥digo calcula el orden m√≠nimo y coeficientes de un Chebyshev I, luego eval√∫a la ganancia en 3.4 kHz y 3.8 kHz para verificar que est√© cerca de ‚Äì1 dB y ‚Äì30 dB respectivamente.)\nEl resultado confirmar√≠a el cumplimiento de especificaciones con el filtro dise√±ado. Del mismo modo podr√≠amos probar ellipord/ellip y buttord/butter. Vale notar que los dise√±os IIR generalmente no tienen control expl√≠cito de fase lineal (la fase es no lineal e importa evaluar el impacto en la se√±al; a veces, se realizan calibraciones o se aplica filtrado hacia atr√°s como mencionado para obtener fase cero)."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#validaci√≥n-espectral-y-aplicaciones-en-se√±ales-biom√©dicas",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#validaci√≥n-espectral-y-aplicaciones-en-se√±ales-biom√©dicas",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "Una vez dise√±ado un filtro (FIR o IIR), es crucial validar su respuesta en frecuencia para asegurarse de que cumple con los requisitos. Esto implica computar \\(H(e^{j\\omega})\\) ‚Äì t√≠picamente mediante freqz ‚Äì y verificar ganancias en las bandas de paso (p.ej. p√©rdida de inserci√≥n o ripple) y bandas de rechazo (atenuaci√≥n m√≠nima). Tambi√©n se puede aplicar el filtro a se√±ales de prueba:\n\nImpulso unitario: la salida debe ser \\(h[n]\\) (sirve para obtener la respuesta al impulso directamente).\nEscal√≥n unitario: la salida debe aproximarse a la respuesta al escal√≥n (integral de \\(h[n]\\)), √∫til para verificar estabilidad (un filtro pasaaltos, por ej., a entrada escal√≥n deber√≠a asentarse a un valor constante, indicando que DC fue removido pero no inestabilidad creciente).\nSe√±al senoidal a frecuencias cr√≠ticas: por ejemplo, inyectar una senoide en la frecuencia de corte para ver si sale atenuada a ~-3 dB o -6 dB seg√∫n definici√≥n; inyectar una senoide en banda eliminada para confirmar fuerte atenuaci√≥n.\n\nEn contexto biom√©dico, se suele validar con se√±ales reales. Por ejemplo, si dise√±amos un filtro para eliminar deriva de l√≠nea base en ECG, podemos probarlo con una se√±al ECG con deriva artificial y comprobar que efectivamente la elimina sin distorsionar el complejo QRS.\n(image) Figura 2: Ejemplo de filtrado de un segmento de se√±al ECG con un filtro pasoalto para remover la deriva de l√≠nea base. En naranja se muestra el ECG original contaminado con una deriva lenta (simulada como una componente de muy baja frecuencia que causa que la l√≠nea base oscile). En amarillo se muestra la se√±al tras aplicar un filtro pasaaltos Butterworth de 4¬∞ orden con \\(f_c \\approx 0.5\\) Hz (aplicado con filtrado hacia adelante y atr√°s para lograr fase cero). Se observa que la se√±al filtrada se centra alrededor de cero voltios, eliminando las variaciones lentas de la l√≠nea base, mientras preserva las caracter√≠sticas importantes del ECG (picos QRS, ondas P y T) (). Este proceso mejora la calidad de la se√±al para an√°lisis posterior (por ejemplo, facilitando la detecci√≥n de eventos cardiacos), sin introducir distorsi√≥n apreciable en la forma de onda r√°pida del ECG.\nOtro ejemplo es la eliminaci√≥n de interferencia de red: un filtro notch dise√±ado como en secciones previas se puede aplicar a una se√±al EEG a la que deliberadamente se le suma un seno de 50 Hz; la validaci√≥n consistir√≠a en ver el espectro antes y despu√©s (verificando que la l√≠nea de 50 Hz desaparece tras filtrar) y que la actividad EEG en otras bandas permanece intacta.\nEn el dise√±o de filtros FIR e IIR para voz o biose√±ales, a veces se comparan m√©todos. Por ejemplo, en el taller se pide dise√±ar tanto un FIR por ventana como un IIR por transformaci√≥n bilineal para ciertas especificaciones. Comparar la respuesta espectral es instructivo: un FIR puede requerir mayor orden para lograr la misma nitidez de corte que un IIR, pero tendr√° fase lineal; el IIR lograr√° la especificaci√≥n con menos coeficientes, pero introducir√° dispersi√≥n de fase. Dependiendo de la aplicaci√≥n, uno u otro puede ser preferible. Estudios en filtrado de ECG han encontrado, por ejemplo, que filtros IIR y FIR bien dise√±ados pueden ambos remover el ruido de l√≠nea base efectivamente; los IIR (como filtros Butterworth pasaaltos) pueden ser implementados en tiempo real con pocas operaciones (comp.dsp | How to write a NotchFilter procedure| page 2), mientras que FIR largos podr√≠an introducir retardo si no se aplican con t√©cnicas especiales. Sin embargo, los FIR lineales en fase aseguran que caracter√≠sticas como la amplitud del ST o la morfolog√≠a de la onda P no se deformen ni se desplacen temporalmente, lo cual es cr√≠tico en ciertos an√°lisis diagn√≥sticos.\nEn resumen, la validaci√≥n espectral (y temporal) de los filtros dise√±ados garantiza que el filtro funcione como esperado en las se√±ales biom√©dicas objetivo. Se recomienda siempre verificar ganancia en banda pasante (por ej., asegurarse de que un filtro pasa-bajos no aten√∫e significativamente componentes importantes de la se√±al, salvo el ripple permitido) y atenuaci√≥n en banda eliminada (asegurarse de que el ruido o interferencia objetivo realmente se reduce a niveles aceptables). Con herramientas como Python/Matlab, esta validaci√≥n se realiza f√°cilmente visualizando la respuesta en frecuencia (como en las Figuras 1 y 2) y realizando pruebas con se√±ales sint√©ticas o reales."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#conclusiones",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#conclusiones",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "Este reporte abord√≥ los fundamentos te√≥ricos necesarios para analizar y dise√±ar sistemas discretos aplicados a se√±ales biom√©dicas. Se revis√≥ la transformada Z y su papel en caracterizar se√±ales y sistemas LTI, destacando la importancia de la regi√≥n de convergencia, polos, ceros, causalidad y estabilidad (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Tambi√©n se discuti√≥ c√≥mo interpretar y construir diagramas de bloques a partir de ecuaciones en diferencias, algo √∫til para implementar filtros digitalmente. En la parte de dise√±o, se cubrieron dos enfoques contrastantes: filtros FIR por m√©todo de ventanas, sencillos y con fase lineal (deseable en biom√©dica), y filtros IIR por transformaci√≥n bilineal a partir de prototipos anal√≥gicos (eficientes en orden, aunque con fase no lineal). Se compararon los principales tipos de aproximaciones anal√≥gicas (Butterworth, Chebyshev I/II, El√≠ptico) resaltando sus ventajas y compromisos (11.3. Common IIR filters ‚Äî Digital Signals Theory).\nA lo largo del documento, se enfatiz√≥ la aplicaci√≥n en se√±ales reales: eliminar deriva de l√≠nea base con pasaaltos, suprimir interferencia de red con filtros notch, limitar el ancho de banda de voz o EEG con pasabajos, etc., todo soportado por referencias acad√©micas y ejemplos de c√≥digo. En la pr√°ctica, el ingeniero biom√©dico debe decidir el tipo de filtro seg√∫n los requisitos cl√≠nicos: por ejemplo, ¬øes m√°s importante no distorsionar la forma de onda (fase lineal) o tener un filtro muy agudo (menor orden)? Este tipo de decisiones se facilita con la comprensi√≥n profunda de los conceptos aqu√≠ explicados.\nCon este marco te√≥rico, se est√° en capacidad de abordar el taller propuesto: calcular transformadas Z y ROC de se√±ales, analizar sistemas LTI (impulso, estabilidad, salida a entradas dadas), dibujar sus polos, ceros y estructuras, as√≠ como dise√±ar filtros FIR e IIR que satisfagan especificaciones dadas, especialmente dentro del contexto de procesamiento de se√±ales biom√©dicas donde la fidelidad y eficacia del filtrado impactan directamente la calidad de la informaci√≥n diagn√≥stica obtenida.\nReferencias: Las referencias provistas en el texto (ej.„Äê23„Äë,„Äê17„Äë,„Äê40„Äë) corresponden a fuentes que respaldan y complementan los puntos discutidos, incluyendo textos de procesamiento digital de se√±ales, art√≠culos de investigaci√≥n en filtrado de ECG/EEG, y documentaci√≥n de funciones de dise√±o de filtros. Estas fuentes ofrecen mayor detalle para el lector interesado en profundizar en aspectos espec√≠ficos. En particular, se destacan obras cl√°sicas como Oppenheim & Schafer en dise√±o FIR (WindowFIRDesign.fm), y recursos modernos como libros abiertos de se√±ales y sistemas (Transformada Z - Wikipedia, la enciclopedia libre) y tutoriales de SciPy (11.3. Common IIR filters ‚Äî Digital Signals Theory) que enriquecen la comprensi√≥n te√≥rica y pr√°ctica del procesamiento de se√±ales biom√©dicas."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html",
    "title": "Sampling and quantization",
    "section": "",
    "text": "This guide recaps essentials of sampling and quantization for biomedical acquisition chains. Emphasis is on concrete design choices for $f_s$, anti-alias cutoff, bit depth $b$, and input range, with clinical mini-cases. Primary/secondary sources: Oppenheim 2e (ISBN: 978-0138147570), Shannon 1949 (DOI: 10.1109/JRPROC.1949.232969), Jayant & Noll (ISBN: 0-13-211913-7), Webster MI 4e (ISBN: 978-0471676003).\n\n\n\n\nNyquist: $f_s2B$ where $B$ is the highest significant frequency (Shannon 1949).\nSampling model: $T_s=1/f_s$, $x_s(t)=_{n}x(nT_s),(t-nT_s)$ (Oppenheim 2e).\nAnti-aliasing: analog LPF with $f_c&lt;f_s/2$ plus guard band (Oppenheim 2e).\nQuantizer: uniform, range $[V_{},V_{}]$, step $=$ (Oppenheim 2e).\nNoise model: $_q^2=$; full-scale sine $_{},b+1.76$ (Jayant & Noll).\nCompanding (telemetry): $$-law/$A$-law to emphasize small amplitudes before quantization (Jayant & Noll; ITU-T G.711).\n\n\n\n\nGoal: Choose $f_s$, $f_c$, $b$, and input range for diagnostic ECG.\n\nBandwidth: adopt $B¬†$ (Webster MI 4e).\nSampling: choose $f_s=500¬†$ to satisfy $f_s2B$ with guard (Shannon 1949).\nAnti-alias: set $f_c¬†$ (transition to $f_s/2=250¬†$).\nRange: $¬†$ to cover tall QRS and baseline drift after high-pass.\nBits: $b=12$ is common; compute $$ and SNR below.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nVmin, Vmax = -5e-3, 5e-3\nrng = Vmax - Vmin\nbits = np.arange(10, 17)\nDelta = rng / (2**bits)\nsnr_db = 6.02*bits + 1.76  # full-scale sine (Jayant & Noll)\n\nprint(f\"12-bit Œî = {Delta[bits.tolist().index(12)]:.3e} V ‚âà {Delta[bits.tolist().index(12)]*1e6:.2f} ŒºV\")\nprint(f\"Ideal 12-bit SNR ‚âà {snr_db[bits.tolist().index(12)]:.1f} dB\")\n\nplt.figure(figsize=(6,4))\nplt.semilogy(bits, Delta*1e6, marker='o')\nplt.xlabel(\"Bit depth b\")\nplt.ylabel(\"Œî (ŒºV)\")\nplt.title(\"ECG step size vs. bit depth (¬±5 mV)\")\nplt.grid(True, which=\"both\")\nplt.tight_layout()\n\n12-bit Œî = 2.441e-06 V ‚âà 2.44 ŒºV\nIdeal 12-bit SNR ‚âà 74.0 dB\n\n\n\n\n\nECG: step size and ideal quantization SNR for b=10..16 bits, ¬±5 mV range.\n\n\n\n\nInterpretation\n\n$b=12$ ‚áí $¬†$; ideal SNR $¬†$ (Oppenheim 2e; Jayant & Noll).\nMeets diagnostic needs when analog noise $&lt;$ and front-end avoids clipping (Webster MI 4e).\n\n\n\n\nGoal: Retain spindles/K-complexes without aliasing while maximizing sensitivity.\n\nBandwidth: EEG of interest $35¬†$; use $B=40¬†$ (Webster MI 4e).\nSampling: pick $f_s=256¬†$ (multiple of 2 for decimation) ensuring $f_s2B$ (Shannon 1949).\nAnti-alias: $f_c¬†$ (ample guard to $f_s/2=128¬†$).\nRange/bits: EEG tens of $$V ‚áí prefer $b$ with programmable gain to use full-scale.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfs = 256\nt = np.arange(0, 2, 1/fs)\nx = 15e-6*np.sin(2*np.pi*10*t)  # 10 Hz alpha-like\ngain_clip = 400000  # too high =&gt; clips ¬±1 V ADC\ngain_safe = 200000  # safe\n\nadc_fs = 1.0  # ¬±1 V full-scale\ny_clip = np.clip(gain_clip*x, -adc_fs, adc_fs)\ny_safe = np.clip(gain_safe*x, -adc_fs, adc_fs)\n\nplt.figure(figsize=(6,4))\nplt.plot(t[:400], y_clip[:400], label=\"Clipping\")\nplt.plot(t[:400], y_safe[:400], label=\"Safe gain\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"ADC input (V)\")\nplt.title(\"Clipping risk from aggressive gain (EEG)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n\n\n\nEEG: effect of clipping vs.¬†conservative gain (synthetic 15 ŒºV wave).\n\n\n\n\nTakeaways\n\nUse sufficient gain to exploit full-scale but verify headroom for artifacts.\nClipping breaks linearity assumptions and corrupts morphology (Oppenheim 2e; Webster MI 4e).\n\n\n\n\n\nDesign: A PPG sensor needs $B=25¬†$. Pick a safe $f_s$ and justify.\n\nSolution: $f_s2B=50$; choose $f_s=200¬†$ for guard and digital processing overhead (Shannon 1949).\n\nQuantization: For $[V_{},V_{}]=[-2,2]¬†$ and $b=10$, compute $$.\n\nSolution: $==3.90625¬†$ (Oppenheim 2e).\n\nNoise: With $¬†$, what is $_q^2$?\n\nSolution: $_q2=¬†2$ (Oppenheim 2e).\n\nSNR sizing: Target $72¬†$ for a full-scale sine. Minimum $b$?\n\nSolution: $b$ bits (Jayant & Noll).\n\n\n\n\n\n\nBandwidth $B$: Specify clinically required content (e.g., ECG 0.05‚Äì150 Hz; EEG 0.5‚Äì35 Hz).\nSampling $f_s$: Choose $2B$ with guard (e.g., √ó3‚Äì5 margin) and convenience for integer decimation.\nAnti-alias LPF: Set $f_c&lt;f_s/2$; allow sufficient transition; verify analog order and tolerances.\nInput range: Size $[V_{},V_{}]$ from front-end gain so typical peaks approach full-scale without clipping.\nBit depth $b$: Use SNR $6.02b+1.76$ to meet noise targets; consider analog noise and electrode motion.\nTelemetry: For constrained links, consider $$-law/$A$-law; document compander/expander alignment (G.711).\nValidation: Bench test with synthetic and recorded signals; check aliasing, clipping, and effective number of bits (ENOB).\n\n\n\n\n\nOppenheim, A. V., Willsky, A. S., Nawab, S. H., Signals and Systems, 2nd ed., Prentice Hall, ISBN: 978-0138147570.\nShannon, C. E., Proc. IRE, 37(1), 1949, ‚ÄúCommunication in the presence of noise,‚Äù DOI: 10.1109/JRPROC.1949.232969.\nNyquist, H., Trans. AIEE, 47, 1928, ‚ÄúCertain topics in telegraph transmission theory,‚Äù DOI: 10.1109/T-AIEE.1928.5055024.\nJayant, N. S., Noll, P., Digital Coding of Waveforms, Prentice-Hall, 1984, ISBN: 0-13-211913-7.\nWebster, J. G. (ed.), Medical Instrumentation: Application and Design, 4th ed., Wiley, ISBN: 978-0471676003.\nITU-T Recommendation G.711: Pulse Code Modulation (PCM) of voice frequencies (identifier: G.711)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#overview",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#overview",
    "title": "Sampling and quantization",
    "section": "",
    "text": "This guide recaps essentials of sampling and quantization for biomedical acquisition chains. Emphasis is on concrete design choices for $f_s$, anti-alias cutoff, bit depth $b$, and input range, with clinical mini-cases. Primary/secondary sources: Oppenheim 2e (ISBN: 978-0138147570), Shannon 1949 (DOI: 10.1109/JRPROC.1949.232969), Jayant & Noll (ISBN: 0-13-211913-7), Webster MI 4e (ISBN: 978-0471676003)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#concise-theory-recap",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#concise-theory-recap",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Nyquist: $f_s2B$ where $B$ is the highest significant frequency (Shannon 1949).\nSampling model: $T_s=1/f_s$, $x_s(t)=_{n}x(nT_s),(t-nT_s)$ (Oppenheim 2e).\nAnti-aliasing: analog LPF with $f_c&lt;f_s/2$ plus guard band (Oppenheim 2e).\nQuantizer: uniform, range $[V_{},V_{}]$, step $=$ (Oppenheim 2e).\nNoise model: $_q^2=$; full-scale sine $_{},b+1.76$ (Jayant & Noll).\nCompanding (telemetry): $$-law/$A$-law to emphasize small amplitudes before quantization (Jayant & Noll; ITU-T G.711)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-a-ecg-bedside-monitor",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-a-ecg-bedside-monitor",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Goal: Choose $f_s$, $f_c$, $b$, and input range for diagnostic ECG.\n\nBandwidth: adopt $B¬†$ (Webster MI 4e).\nSampling: choose $f_s=500¬†$ to satisfy $f_s2B$ with guard (Shannon 1949).\nAnti-alias: set $f_c¬†$ (transition to $f_s/2=250¬†$).\nRange: $¬†$ to cover tall QRS and baseline drift after high-pass.\nBits: $b=12$ is common; compute $$ and SNR below.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nVmin, Vmax = -5e-3, 5e-3\nrng = Vmax - Vmin\nbits = np.arange(10, 17)\nDelta = rng / (2**bits)\nsnr_db = 6.02*bits + 1.76  # full-scale sine (Jayant & Noll)\n\nprint(f\"12-bit Œî = {Delta[bits.tolist().index(12)]:.3e} V ‚âà {Delta[bits.tolist().index(12)]*1e6:.2f} ŒºV\")\nprint(f\"Ideal 12-bit SNR ‚âà {snr_db[bits.tolist().index(12)]:.1f} dB\")\n\nplt.figure(figsize=(6,4))\nplt.semilogy(bits, Delta*1e6, marker='o')\nplt.xlabel(\"Bit depth b\")\nplt.ylabel(\"Œî (ŒºV)\")\nplt.title(\"ECG step size vs. bit depth (¬±5 mV)\")\nplt.grid(True, which=\"both\")\nplt.tight_layout()\n\n12-bit Œî = 2.441e-06 V ‚âà 2.44 ŒºV\nIdeal 12-bit SNR ‚âà 74.0 dB\n\n\n\n\n\nECG: step size and ideal quantization SNR for b=10..16 bits, ¬±5 mV range.\n\n\n\n\nInterpretation\n\n$b=12$ ‚áí $¬†$; ideal SNR $¬†$ (Oppenheim 2e; Jayant & Noll).\nMeets diagnostic needs when analog noise $&lt;$ and front-end avoids clipping (Webster MI 4e)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-b-eeg-for-sleep-staging",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-b-eeg-for-sleep-staging",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Goal: Retain spindles/K-complexes without aliasing while maximizing sensitivity.\n\nBandwidth: EEG of interest $35¬†$; use $B=40¬†$ (Webster MI 4e).\nSampling: pick $f_s=256¬†$ (multiple of 2 for decimation) ensuring $f_s2B$ (Shannon 1949).\nAnti-alias: $f_c¬†$ (ample guard to $f_s/2=128¬†$).\nRange/bits: EEG tens of $$V ‚áí prefer $b$ with programmable gain to use full-scale.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfs = 256\nt = np.arange(0, 2, 1/fs)\nx = 15e-6*np.sin(2*np.pi*10*t)  # 10 Hz alpha-like\ngain_clip = 400000  # too high =&gt; clips ¬±1 V ADC\ngain_safe = 200000  # safe\n\nadc_fs = 1.0  # ¬±1 V full-scale\ny_clip = np.clip(gain_clip*x, -adc_fs, adc_fs)\ny_safe = np.clip(gain_safe*x, -adc_fs, adc_fs)\n\nplt.figure(figsize=(6,4))\nplt.plot(t[:400], y_clip[:400], label=\"Clipping\")\nplt.plot(t[:400], y_safe[:400], label=\"Safe gain\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"ADC input (V)\")\nplt.title(\"Clipping risk from aggressive gain (EEG)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n\n\n\nEEG: effect of clipping vs.¬†conservative gain (synthetic 15 ŒºV wave).\n\n\n\n\nTakeaways\n\nUse sufficient gain to exploit full-scale but verify headroom for artifacts.\nClipping breaks linearity assumptions and corrupts morphology (Oppenheim 2e; Webster MI 4e)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#four-formative-checks-with-solutions",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#four-formative-checks-with-solutions",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Design: A PPG sensor needs $B=25¬†$. Pick a safe $f_s$ and justify.\n\nSolution: $f_s2B=50$; choose $f_s=200¬†$ for guard and digital processing overhead (Shannon 1949).\n\nQuantization: For $[V_{},V_{}]=[-2,2]¬†$ and $b=10$, compute $$.\n\nSolution: $==3.90625¬†$ (Oppenheim 2e).\n\nNoise: With $¬†$, what is $_q^2$?\n\nSolution: $_q2=¬†2$ (Oppenheim 2e).\n\nSNR sizing: Target $72¬†$ for a full-scale sine. Minimum $b$?\n\nSolution: $b$ bits (Jayant & Noll)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#design-checklist-print-friendly",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#design-checklist-print-friendly",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Bandwidth $B$: Specify clinically required content (e.g., ECG 0.05‚Äì150 Hz; EEG 0.5‚Äì35 Hz).\nSampling $f_s$: Choose $2B$ with guard (e.g., √ó3‚Äì5 margin) and convenience for integer decimation.\nAnti-alias LPF: Set $f_c&lt;f_s/2$; allow sufficient transition; verify analog order and tolerances.\nInput range: Size $[V_{},V_{}]$ from front-end gain so typical peaks approach full-scale without clipping.\nBit depth $b$: Use SNR $6.02b+1.76$ to meet noise targets; consider analog noise and electrode motion.\nTelemetry: For constrained links, consider $$-law/$A$-law; document compander/expander alignment (G.711).\nValidation: Bench test with synthetic and recorded signals; check aliasing, clipping, and effective number of bits (ENOB)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#references-ids-included",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#references-ids-included",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Oppenheim, A. V., Willsky, A. S., Nawab, S. H., Signals and Systems, 2nd ed., Prentice Hall, ISBN: 978-0138147570.\nShannon, C. E., Proc. IRE, 37(1), 1949, ‚ÄúCommunication in the presence of noise,‚Äù DOI: 10.1109/JRPROC.1949.232969.\nNyquist, H., Trans. AIEE, 47, 1928, ‚ÄúCertain topics in telegraph transmission theory,‚Äù DOI: 10.1109/T-AIEE.1928.5055024.\nJayant, N. S., Noll, P., Digital Coding of Waveforms, Prentice-Hall, 1984, ISBN: 0-13-211913-7.\nWebster, J. G. (ed.), Medical Instrumentation: Application and Design, 4th ed., Wiley, ISBN: 978-0471676003.\nITU-T Recommendation G.711: Pulse Code Modulation (PCM) of voice frequencies (identifier: G.711)."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "A trav√©s de este taller se reforzar√°n los conocimientos en: se√±ales, transformaciones de la\nvariable independiente, clasificaci√≥n de se√±ales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#descripci√≥n",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#descripci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "A trav√©s de este taller se reforzar√°n los conocimientos en: se√±ales, transformaciones de la\nvariable independiente, clasificaci√≥n de se√±ales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuaci√≥n.\n\n1. Considere la se√±al\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\n\\(x(t)\\)\n\\(x(t - 2)\\)\n\\(x(2t + 1)\\)\n\\(x(-3t)\\)\n\n\n\n2. Determine si las siguientes se√±ales son peri√≥dicas y encuentre su periodo\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\n\\(x(t) = e^{-j(\\frac{4\\pi}{3})t} + e^{j(\\frac{2\\pi}{5})t}\\)\n\n\\(x(n) = \\cos(n/8) \\cos(\\pi n/8)\\)\n\n\\(x(n) = \\cos(3\\pi n/2) - \\sin(\\frac{\\pi n}{8}) + 3\\cos(\\frac{\\pi n}{4} + \\frac{\\pi}{3})\\)\n\n\n\n3. Demuestre que si \\(x(t)\\) y \\(y(t)\\) son se√±ales impares, entonces:\n\n\\(z(t) = x(t)y(t)\\) es una se√±al par\n\n\\(g(t) = x(t) + y(t)\\) es una se√±al impar.\n\nSiendo \\(x(t) = \\sin(t)\\) y \\(y(t) = t\\), grafique en Python \\(z(t)\\) y \\(g(t)\\). ¬øSe cumple lo indicado en los numerales a y b?\n\n\n\n4. Encuentre la expresi√≥n anal√≠tica de las se√±ales mostradas a continuaci√≥n utilizando funciones \\(u(t)\\) y \\(r(t)\\) (escal√≥n unitario y rampa).\n\n\n\n5. Para una se√±al an√°loga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nIndique si la se√±al \\(x_a(t)\\) es una se√±al peri√≥dica, en caso afirmativo, indique el periodo de la se√±al.\n\nFrecuencia de muestreo que cumpla con el teorema de Nyquist.\n\nEncontrar \\(x_a[n]\\) con la frecuencia de muestreo encontrada en el punto anterior.\n\nIndique si la se√±al \\(x_a[n]\\) es una se√±al peri√≥dica, en caso afirmativo, indique el periodo de la se√±al.\n\n\n\n6. Considere el sistema de procesamiento de se√±ales mostrado en la figura:\n\nSi la entrada es \\(x_a(t) = 2 \\sin(720\\pi t) + 2\\), encontrar:\n\nLa salida \\(x_a[n]\\) si \\(T_{m1} = 12.5ms\\). ¬øCon esta frecuencia se puede reconstruir la se√±al \\(x_a(t)\\) en \\(y(t)\\) si \\(T_{m2} = T_{m1}\\)? Justifique su respuesta.\n\nLa salida \\(x_a[n]\\) si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¬øLa se√±al es peri√≥dica en tiempo discreto? Justifique su respuesta.\n\nPara la se√±al del punto b, encontrar la se√±al cuantizada de un ciclo de la se√±al si el tama√±o del registro es de 4 bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "recursos/talleres/SYSB/Taller3_2025_1.html",
    "href": "recursos/talleres/SYSB/Taller3_2025_1.html",
    "title": "Taller3: An√°lisis y dise√±os de filtros",
    "section": "",
    "text": "Profesores\nJenny Carolina Castiblanco S√°nchez\nPablo Eduardo Caicedo Rodr√≠guez\n\n\nDescripci√≥n\nA trav√©s de este taller se reforzar√°n los conocimientos en:\n\nTransformada Z\nDise√±o, an√°lisis e implementaci√≥n de filtros digitales FIR e IIR\n\n\n\nProcedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuaci√≥n.\n\nTransformada Z y Regi√≥n de Convergencia\nDetermine la transformada Z y dibuje la ROC de las siguientes se√±ales:\n\n\\(x\\left[n\\right] = =\\begin{cases}\\displaystyle \\left(\\frac{1}{3}\\right)^{n}, & n \\ge 0,\\\\[6pt]\\displaystyle \\left(\\frac{1}{2}\\right)^{-n}, & n &lt; 0.\\end{cases}\\)\n\\(x\\left[n\\right]=\\begin{cases}\\displaystyle \\left(\\frac{1}{3}\\right)^{n}, & n \\ge 5,\\\\[6pt]0, & n &lt; 5.\\end{cases}\\)\n\nRespuesta del Sistema\nDetermine la respuesta del sistema\n\\[\ny\\left[n\\right] \\;=\\; \\frac{5}{6}\\,y\\left[n-1\\right]\\;-\\;\\frac{1}{6}\\,y\\left[n-2\\right]\\;+\\;x\\left[n\\right]\n\\]\nA la se√±al de entrada\n\\[\nx\\left[n\\right] \\;=\\; \\delta\\left[n\\right]\\;-\\;\\frac{1}{3}\\,\\delta\\left[n-1\\right]\n\\]\nRespuesta del Sistema\nUna se√±al de entrada ( \\(x[n] = 3^{n}u[-n]\\) ) es aplicada a un sistema LTI discreto con respuesta al impulso ( \\(h[n] = \\left(0.5\\right)^{n}u[n]\\) ).\n\nDetermine la funci√≥n de transferencia del sistema.\n¬øEl sistema es estable?\nEncuentre la se√±al de salida del sistema.\n\nAn√°lisis de Filtro\nConsidere el filtro\n\\[y\\left[n\\right] \\;=\\; b\\,x\\left[n\\right]\\;-\\;0.65\\,y\\left[n-1\\right]\\]\n\nDetermine (b) de modo que \\(\\lvert H\\left[0\\right] \\lvert \\, = \\, 0\\)\n\nDibuje en el plano (z) el diagrama de polos y ceros. ¬øEl sistema es estable?\n\nGrafique el diagrama de bloques.\n\n¬øQu√© tipo de filtro es?\n\nDise√±o de Filtro Anal√≥gico Muestreado\nLa salida de un sistema LTI est√° determinada por la ecuaci√≥n del sistema.\n\\[\ny\\left[n\\right] \\;=\\; x\\left[n\\right]\\;-\\;a\\,y\\left[n-1\\right]\n\\]\nTeniendo en cuenta la funci√≥n de transferencia, se desea dise√±ar un filtro con frecuencia de corte de 60‚ÄØHz para una se√±al anal√≥gica muestreada a 5‚ÄØkHz.\n\n¬øQu√© valor debe tener la variable (a)?\n\n¬øQu√© tipo de filtro se obtiene?\n\n\n\n\nDise√±ar y simular filtros digitales para se√±ales empleando PYTHON.\n\nDise√±ar, simular y analizar un filtro pasbajos FIR por el m√©todo de ventaneo, con frecuencia de corte de 55Hz a los 6dB, atenuaci√≥n m√≠nima en 60Hz de 20 dB y atenuaci√≥n mayor de 40 dB por encima de 80Hz.\n\nDeterminar el m√≠nimo orden del filtro requerido para las siguientes ventanas: Rectangular, triangular, Hann, Hamming, Blackman, Kayser.\nDe los filtros analizados, seleccione el de menor orden que cumpla con las caracter√≠sticas de dise√±o.\n\nDise√±ar y simular filtros digitales IIR para se√±ales de voz empleando Matlab, analizando las diferentes opciones: Butterworth, Chebyshev, El√≠ptico.\n\nDise√±ar, simular y analizar un filtro pasabajos IIR por el m√©todo de transformaci√≥n de filtros anal√≥gicos empleando la transformaci√≥n bilineal, con las siguientes caracter√≠sticas: Frecuencia de muestreo, 8 kHz; frecuencia de corte de 3.4 kHz; rizado en la banda de paso, 1 dB; frecuencia de rechazo, 3.8 kHz; atenuaci√≥n en la banda de rechazo, 30 dB; orden del filtro, m√≠nimo.\nDise√±ar, simular y analizar un filtro pasaltos IIR por el m√©todo de transformaci√≥n de filtros anal√≥gicos empleando la transformaci√≥n bilineal, con las siguientes caracter√≠sticas: Frecuencia de muestreo, 8 kHz; frecuencia de corte de 300 Hz; rizado en la banda de paso, 1 dB; frecuencia de rechazo, 60 Hz; atenuaci√≥n en la banda de rechazo, 30 dB; orden del filtro, m√≠nimo."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "A trav√©s de este taller se reforzar√°n los conocimientos en: se√±ales, transformaciones de la\nvariable independiente, clasificaci√≥n de se√±ales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#descripci√≥n",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#descripci√≥n",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "A trav√©s de este taller se reforzar√°n los conocimientos en: se√±ales, transformaciones de la\nvariable independiente, clasificaci√≥n de se√±ales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#procedimiento",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#procedimiento",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuaci√≥n.\n\n1. Considere la se√±al\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\nSoluci√≥n\nSe grafican las transformaciones solicitadas en Python con Matplotlib.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_t(t):\n    return np.piecewise(t, [(-1 &lt;= t) & (t &lt;= 0), (0 &lt; t) & (t &lt;= 2), (2 &lt; t) & (t &lt;= 3)],\n                         [lambda t: t + 1, 2, 1, 0])\n\nt = np.linspace(-2, 4, 1000)\nplt.plot(t, x_t(t), label='x(t)')\nplt.xlabel('t')\nplt.ylabel('x(t)')\nplt.legend()\nplt.show()\n\n\n\n\n2. Determine si las siguientes se√±ales son peri√≥dicas y encuentre su periodo\n\nSoluci√≥n\nAnalizamos si \\(\\frac{f_0}{f_s}\\) es racional.\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\nPer√≠odos: \\(T_1 = \\frac{2\\pi}{2} = \\pi\\), \\(T_2 = \\frac{2\\pi}{\\pi} = 2\\)\nM√≠nimo com√∫n m√∫ltiplo: **Per√≠odo = 2*\n\n\\(x(t) = e^{-j(4\\pi/3)t} + e^{j(2\\pi/5)t}\\)\n\nSe buscan los per√≠odos fundamentales.\nNo es peri√≥dica porque las razones de frecuencias son irracionales.\n\n\n‚Ä¶\n\n\n\n\n5. Para una se√±al an√°loga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nSoluci√≥n\n\nPer√≠odo de la se√±al:\n\nFrecuencias: \\(f_1 = 300Hz\\), \\(f_2 = 240Hz\\)\nMCM de \\(\\frac{1}{300}\\) y \\(\\frac{1}{240}\\) ‚Üí T = 1/60 s\n\nFrecuencia de muestreo\n\nTeorema de Nyquist: \\(f_s &gt; 2f_{max} = 600Hz\\)\n\nSe√±al muestreada:\nfs = 600  # Hz\nn = np.arange(0, 100)\nxa_n = np.sin(600*np.pi*n/fs) + 3*np.sin(480*np.pi*n/fs)\nplt.stem(n, xa_n)\nplt.show()\n\n‚Ä¶\n\n\n\n6. Muestreo y cuantizaci√≥n\n\nSoluci√≥n\n\nFrecuencia de muestreo:\n\n\\(T_m1 = 12.5ms\\) ‚Üí \\(f_s = 80Hz\\)\nNo cumple Nyquist ‚Üí No se puede reconstruir\n\nMuestreo a 8 veces Nyquist:\n\n\\(f_s = 5760Hz\\)\nSe eval√∫a si \\(\\frac{f_0}{f_s}\\) es racional ‚Üí S√≠ es peri√≥dica\n\nCuantizaci√≥n (4 bits, rango 0-5):\n\nPaso de cuantizaci√≥n: \\(\\Delta = \\frac{5}{2^4}\\)\nSe discretiza la se√±al seg√∫n niveles de cuantizaci√≥n.\n\n\nimport numpy as np\nlevels = np.linspace(0, 5, 16)\nquantized_signal = np.digitize(xa_n, levels) * (5 / 16)\nplt.stem(n, quantized_signal)\nplt.show()\n\nFin del taller."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "href": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "title": "Proyecto Final: PSIM 2024-1",
    "section": "",
    "text": "Criterio\n5.0  (Excelente)\n4.0  (Bueno)\n3.0  (Aceptable)\n1.0  (Deficiente)\n\n\n\n\n1. Objetivo del Proyecto\nClaramente definido, espec√≠fico, relevante y alcanzable, alineado con la problem√°tica.\nClaro y relevante, pero carece de precisi√≥n o profundidad.\nComprensible, pero general o no bien alineado con la problem√°tica.\nConfuso, irrelevante o ausente.\n\n\n2. Justificaci√≥n\nS√≥lida, argumenta importancia e impacto con evidencia o literatura relevante.\nAdecuada, pero le falta profundidad o evidencia clara.\nB√°sica y poco convincente; argumentos d√©biles o generales.\nInexistente o carente de l√≥gica.\n\n\n3. Metodolog√≠a\nBien estructurada, clara y adecuada para los objetivos. T√©cnicas y procedimientos relevantes.\nAdecuada, pero carece de detalle o presenta leves inconsistencias.\nVaga, incompleta o no alineada con los objetivos.\nConfusa, inapropiada o ausente.\n\n\n4. Resultados\nClaros, organizados y rigurosamente analizados. Uso efectivo de herramientas visuales.\nClaros, pero carecen de profundidad en an√°lisis u organizaci√≥n.\nConfusos, incompletos o mal interpretados.\nIrrelevantes, incorrectos o ausentes.\n\n\n5. Discusi√≥n\nInterpreta resultados, relaciona con objetivos y literatura, propone mejoras futuras.\nAborda puntos principales, pero falta profundidad o conexi√≥n con literatura previa.\nSuperficial, no interpreta correctamente resultados ni plantea ideas futuras.\nAusente o irrelevante.\n\n\n6. Respuesta a Preguntas\nResponde con claridad, precisi√≥n y seguridad. Demuestra dominio y an√°lisis cr√≠tico del tema.\nResponde adecuadamente, pero muestra inseguridad en algunos aspectos.\nResponde vagamente, con dificultades para argumentar.\nRespuestas incorrectas, confusas o incapacidad para responder."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "title": "R√∫brica: Proyecto Final An√°lsis Num√©rico",
    "section": "",
    "text": "C√≥mo Preparar una Presentaci√≥n | 5 PASOS para una CONFERENCIA EXITOSA por Sebasti√°n Lora.\n¬øC√≥mo estructurar una presentaci√≥n? por Espacio √ë de la Universidad del Norte\n\n\n\n\n\nC√≥mo Hacer una Buena Presentaci√≥n de Diapositivas (Tips) por Javier Mu√±iz.\nConsejos para una buena presentaci√≥n en POWER POINT por NiboKids en el cole!.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentaci√≥n\nNo se siguen ninguno de los consejos de los videos adjuntos para la creaci√≥n de la presentaci√≥n\nSe siguen algunos de los consejos de los videos adjuntos para la creaci√≥n¬† de la presentaci√≥n\nSe siguen todos los consejos de los videos adjuntos para la creaci√≥n¬† de la presentaci√≥n\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificaci√≥n de los ejemplos\nNo se describe el c√≥digo utilizado para los ejemplos\nSe describe parcialmente el c√≥digo de los ejemplos\nSe describe a cabalidad el c√≥digo de los ejemplos\n\n\nCalidad del c√≥digo\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl c√≥digo utilizado es completamente desarrollado por los estudiantes a excepci√≥n del manejo de datos (NUMPY array y las funciones matem√°ticas elementales) y la graficaci√≥n (MATPLOTLIB)"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generaci√≥n-de-presentaciones",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generaci√≥n-de-presentaciones",
    "title": "R√∫brica: Proyecto Final An√°lsis Num√©rico",
    "section": "",
    "text": "C√≥mo Preparar una Presentaci√≥n | 5 PASOS para una CONFERENCIA EXITOSA por Sebasti√°n Lora.\n¬øC√≥mo estructurar una presentaci√≥n? por Espacio √ë de la Universidad del Norte"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generaci√≥n-de-dipostivas",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generaci√≥n-de-dipostivas",
    "title": "R√∫brica: Proyecto Final An√°lsis Num√©rico",
    "section": "",
    "text": "C√≥mo Hacer una Buena Presentaci√≥n de Diapositivas (Tips) por Javier Mu√±iz.\nConsejos para una buena presentaci√≥n en POWER POINT por NiboKids en el cole!."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#r√∫brica-de-evaluaci√≥n",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#r√∫brica-de-evaluaci√≥n",
    "title": "R√∫brica: Proyecto Final An√°lsis Num√©rico",
    "section": "",
    "text": "Indicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentaci√≥n\nNo se siguen ninguno de los consejos de los videos adjuntos para la creaci√≥n de la presentaci√≥n\nSe siguen algunos de los consejos de los videos adjuntos para la creaci√≥n¬† de la presentaci√≥n\nSe siguen todos los consejos de los videos adjuntos para la creaci√≥n¬† de la presentaci√≥n\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificaci√≥n de los ejemplos\nNo se describe el c√≥digo utilizado para los ejemplos\nSe describe parcialmente el c√≥digo de los ejemplos\nSe describe a cabalidad el c√≥digo de los ejemplos\n\n\nCalidad del c√≥digo\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl c√≥digo utilizado es completamente desarrollado por los estudiantes a excepci√≥n del manejo de datos (NUMPY array y las funciones matem√°ticas elementales) y la graficaci√≥n (MATPLOTLIB)"
  },
  {
    "objectID": "rubricas/Rubrica_Regression.html",
    "href": "rubricas/Rubrica_Regression.html",
    "title": "R√∫brica: Modelos de regresi√≥n",
    "section": "",
    "text": "Equipo 1Equipo 2\n\n\nIntegrantes\n\nLaura Bazante\nNicol√°s Panesso\nNicoll Arcos\n\nDataset: concreto\n\n\nIntegrantes\n\nKatherin Diaz\nHeidy Fern√°ndez\nJuan Mu√±oz\n\nDataset: Rendimiento\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsuficiente0%\nAceptable50%\nSuperior100%\n\n\n\n\nObjetivo an√°lisis exploratorio de datos\nNo hay un objetivo aparente\nExiste un objetivo de an√°lisis exploratorio de datos planteado pero este no se encuentra alineado con el modelo\nEl objetivo del an√°lisis exploratorio de datos planteado se alinea con la construcci√≥n del modelo se encuentra bien descrito\n\n\nContexto del Dataset\nNo es posible establecer el √°mbito al cual pertenecen los datos utilizados para desarrollar el trabajo\nSe hace una descripci√≥n muy b√°sica de las caracter√≠sticas del dataset\nSe hace una descripci√≥n detallada de las caracter√≠sticas y las variables que componen el dataset\n\n\nJustificaci√≥n\nNo existe una justificaci√≥n aparente\nExiste justificaci√≥n pero esta se encuentra mal planteda\nLa justificaci√≥n se encuentra bien planteada\n\n\nPreprocesamiento\nNo se realiz√≥ preprocesamiento de los datos.¬† O no se argumenta de manera clara la raz√≥n de los procedimientos realizados\nAl dataset se le aplicaron solo algunas operaciones de preprocesamiento y los datos no tienen la calidad requerida\nAl dataset se le aplicaron las operaciones de preprocesamiento necesarias para mejorar su calidad y poder construir los modelos de clasificaci√≥n\n\n\nConexi√≥n entre el EDA y el modelo final\nM√°s de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nMenos de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nTodas las decisiones para el modelo inicial fueron tomadas a partir del EDA\n\n\nDuraci√≥n de la presentaci√≥n\nLa presentaci√≥n dura menos de 8 minutos o m√°s de 13 minutos\nLa presentaci√≥n dura menos de 9 minutos o m√°s de 11 minutos\nLa presentaci√≥n dura 10 minutos\n\n\nMaterial de clase\nNo usa la plantilla RMARKDOWN\n\nUsa la plantilla¬† RMARKDOWN\n\n\nUso de gr√°ficos\nNo se usa ESTAD√çSTICA para explicar todas las decisiones\n\nSe usa ESTAD√çSTICA para explicar todas las decisiones\n\n\nJustificaci√≥n de las decisiones del modelo final\nM√°s de dos decisiones del modelo final no est√°n justificadas\nMenos de dos decisiones del modelo final no est√°n justificadas\nLas decisiones del modelo final son justificadas.\n\n\nEvaluaci√≥n del modelo\nNo hace evaluaci√≥n del modelo\nUsa el √≠ndice de determinaci√≥n para evaluar el modelo\nUsa el √≠ndice de determinaci√≥n para evaluar el modelo y adem√°s hace an√°lisis de residuos sobre la salida del modelo\n\n\nModelo de regresi√≥n\nNo se construy√≥ el modelo o el grupo no puede explicar de manera clara la raz√≥n de los procedimientos realizados\nSolo construy√≥ un modelo o no hay claridad sobre las caracter√≠sticas del modelo elegido\nIdentific√≥ el modelo de mayor precisi√≥n despu√©s de realizar varias pruebas, se exponen las caracter√≠sticas del modelo elegido.¬† El modelo se presenta de forma gr√°fica"
  },
  {
    "objectID": "clases/Class_SYSB.html",
    "href": "clases/Class_SYSB.html",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "",
    "text": "El estudio del procesamiento de se√±ales es fundamental en la ingenier√≠a biom√©dica debido a la amplia variedad de aplicaciones que tiene en el an√°lisis, interpretaci√≥n y mejora de datos biom√©dicos. A continuaci√≥n, se presenta una justificaci√≥n estructurada de su relevancia:\nNaturaleza de las se√±ales biom√©dicas\nLas se√±ales biom√©dicas, como las se√±ales electrocardiogr√°ficas (ECG), electromiogr√°ficas (EMG), electroencefalogr√°ficas (EEG), o incluso im√°genes m√©dicas (resonancias magn√©ticas o tomograf√≠as), son complejas y est√°n afectadas por ruido y artefactos.\nEl procesamiento de se√±ales permite extraer informaci√≥n √∫til, filtrar interferencias y maximizar la calidad de los datos obtenidos.\nDiagn√≥stico y monitoreo\nLas se√±ales biom√©dicas son esenciales para el diagn√≥stico de enfermedades y el monitoreo continuo de pacientes. Por ejemplo, el procesamiento de un ECG ayuda a detectar arritmias, mientras que el an√°lisis de un EEG puede identificar epilepsia o trastornos del sue√±o.\nEn entornos de cuidado intensivo, el procesamiento en tiempo real de se√±ales vitales garantiza decisiones cl√≠nicas r√°pidas y precisas.\nOptimizaci√≥n de dispositivos biom√©dicos\nEl dise√±o de dispositivos biom√©dicos como marcapasos, desfibriladores implantables y pr√≥tesis inteligentes requiere algoritmos avanzados de procesamiento de se√±ales para interpretar datos en tiempo real y responder adecuadamente a las necesidades del paciente.\nAvances en tecnolog√≠a m√©dica\nTecnolog√≠as emergentes como el an√°lisis de datos en telemedicina, dispositivos port√°tiles (wearables) y sistemas de salud m√≥vil (mHealth) dependen del procesamiento de se√±ales para garantizar la precisi√≥n y la utilidad de la informaci√≥n presentada.\nIntegraci√≥n con otras disciplinas\nEl procesamiento de se√±ales se combina con inteligencia artificial y aprendizaje autom√°tico para desarrollar modelos predictivos, clasificar patrones patol√≥gicos y personalizar tratamientos.\nInvestigaci√≥n en fisiolog√≠a y biomec√°nica\nEl an√°lisis avanzado de se√±ales contribuye a la comprensi√≥n profunda de procesos fisiol√≥gicos complejos, como la din√°mica del coraz√≥n, el cerebro o el sistema musculoesquel√©tico.\nEducaci√≥n y competencias profesionales\nLa formaci√≥n en procesamiento de se√±ales biom√©dicas dota a los futuros ingenieros de herramientas matem√°ticas y computacionales para enfrentar problemas del mundo real, desarrollar soluciones innovadoras y avanzar en el campo de la ingenier√≠a biom√©dica.\nEl curso est√° dividido en 5 partes:\n1. Introducci√≥n al procesado de se√±ales.\n2. Conceptos de se√±ales cont√≠nuas & discretas.\n3. Muestreo.\n4. Extracci√≥n de caracter√≠sticas de una se√±al.\n5. Filtraje de se√±ales."
  },
  {
    "objectID": "clases/Class_SYSB.html#presentaciones",
    "href": "clases/Class_SYSB.html#presentaciones",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentaci√≥n del curso\nIntroducci√≥n\nClasificacion de se√±ales\nSe√±ales Notables 1/2\nSe√±ales Notables 2/2\nAdquisici√≥n y Muestreo\nFiltros Digitales\nContenido Frecuencial\nTransformada Z"
  },
  {
    "objectID": "clases/Class_SYSB.html#datos",
    "href": "clases/Class_SYSB.html#datos",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_SYSB.html#c√≥digos",
    "href": "clases/Class_SYSB.html#c√≥digos",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "C√≥digos",
    "text": "C√≥digos"
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorios",
    "href": "clases/Class_SYSB.html#laboratorios",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLAB01: C√≥digo python, estad√≠stica, y n√∫meros complejos.\nLAB02: El electrocardiograma. Fundamentos Te√≥ricos.\nLAB03: An√°lisis de informaci√≥n base del dataset (Demograf√≠a y estad√≠stica inicial)\nLAB04: Convoluci√≥n\nLab05: Modelo estad√≠stico para la clasificaci√≥n de arritmias"
  },
  {
    "objectID": "clases/Class_SYSB.html#grupos-2025-1",
    "href": "clases/Class_SYSB.html#grupos-2025-1",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Grupos 2025-1",
    "text": "Grupos 2025-1\n\n\n\n\n\n\n\n\n\nID Estudiante\nNombre\nCorreo Electr√≥nico\nGrupo\n\n\n\n\n¬†1000098844\nCRISTIAN STIVEN CAPERA CERQUERA\ncristian.capera-c@mail.escuelaing.edu.co\nA\n\n\n¬†1000044331\nMARIA ALEJANDRA URIBE RODRIGUEZ\nmaria.uribe-r@mail.escuelaing.edu.co\nA\n\n\n¬†1000098887\nNICOLE JULIANA AYURE MATAMOROS\nnicole.ayure-m@mail.escuelaing.edu.co\nA\n\n\n¬†1000097259\nJENNIFER SOFIA SANCHEZ RAMOS\njennifer.sanchez-r@mail.escuelaing.edu.co\nB\n\n\n¬†1000097273\nMARIA JOSE PI√ëEROS ACU√ëA\nmaria.pineros-a@mail.escuelaing.edu.co\nB\n\n\n¬†1000097287\nMAR√çA JOS√â HERN√ÅNDEZ GUERRA\nmaria.hguerra@mail.escuelaing.edu.co\nB\n\n\n¬†1000099348\nJAIME LEONARDO CALDER√ìN BETANCURT\njaime.calderon-b@mail.escuelaing.edu.co\nC\n\n\n¬†1000098221\nLAURA CAMILA REYES MU√ëOZ\nlaura.reyes-m@mail.escuelaing.edu.co\nC\n\n\n¬†1000045047\nDANIEL FELIPE BRU MENESES\ndaniel.bru@mail.escuelaing.edu.co\nD\n\n\n¬†1000053815\nKEVIN DANIEL BEJARANO OSORIO\nkevin.bejarano@mail.escuelaing.edu.co\nD\n\n\n¬†1000046321\nSANTIAGO ACU√ëA MONCADA\nsantiago.acuna@mail.escuelaing.edu.co\nD\n\n\n¬†1000095641\nANA SOFIA GRANADA LEIVA\nana.granada-l@mail.escuelaing.edu.co\nE\n\n\n¬†1000092619\nLUISA FERNANDA PEREZ SALGADO\nluisa.perez-s@mail.escuelaing.edu.co\nE\n\n\n¬†1000094974\nMARIA FERNANDA GOMEZ CUBIDES\nmaria.gcubides@mail.escuelaing.edu.co\nF\n\n\n¬†1000095693\nMAR√çA PAULA CORTES AVILA\nmaria.cortes-a@mail.escuelaing.edu.co\nF\n\n\n¬†1000053831\nLUISA LORETTA VERGARA ROMERO\nluisa.vergara-r@mail.escuelaing.edu.co\nG\n\n\n¬†1000095027\nPAULA MELISSA MARTINEZ BARRERA\npaula.martinez-b@mail.escuelaing.edu.co\nG\n\n\n¬†1000095101\nSANTIAGO PATI√ëO MEJIA\nsantiago.pmejia@mail.escuelaing.edu.co\nG\n\n\n¬†1000098222\nJULIANA MAYORGA AVILA\njuliana.mayorga-a@mail.escuelaing.edu.co\nH\n\n\n¬†1000099556\nMARIANA FRANCO CARO\nmariana.franco-c@mail.escuelaing.edu.co\nH\n\n\n¬†1000098162\nMAR√çA PAULA G√ìMEZ NI√ëO\nmaria.gomez-n@mail.escuelaing.edu.co\nI"
  },
  {
    "objectID": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nTaller1: Introduccion al procesamiento de se√±ales\nTaller2: Sistemas LTI, Convoluci√≥n, Series de FOURIER\nTaller3: An√°lisis y dise√±os de filtros\nPrimer Parcial 2025-1 A\nPrimer Parcial 2025-1 B"
  },
  {
    "objectID": "clases/Class_SYSB.html#clases",
    "href": "clases/Class_SYSB.html#clases",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Clases",
    "text": "Clases\n\nLunes: 10:00am-11:30am. F204.\n\nJueves: 10:00am-11:30am. F206."
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorio",
    "href": "clases/Class_SYSB.html#laboratorio",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Laboratorio",
    "text": "Laboratorio\n\nMartes: 10:00am-11:30am. I1-308."
  },
  {
    "objectID": "clases/Class_SYSB.html#atenci√≥n-a-estudiantes",
    "href": "clases/Class_SYSB.html#atenci√≥n-a-estudiantes",
    "title": "Sistemas y Se√±ales Biom√©dicos",
    "section": "Atenci√≥n a estudiantes",
    "text": "Atenci√≥n a estudiantes\nGrupo 80:\nGrupo 81:"
  },
  {
    "objectID": "clases/Class_APSB.html",
    "href": "clases/Class_APSB.html",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "",
    "text": "Procesamiento en Tiempo Real\nEn entornos biom√©dicos, muchas aplicaciones requieren procesamiento en tiempo real, como el monitoreo de pacientes cr√≠ticos, an√°lisis de im√°genes m√©dicas (por ejemplo, ultrasonido, radiograf√≠as) y dispositivos port√°tiles. Edge AI permite procesar datos localmente, reduciendo la latencia en comparaci√≥n con el env√≠o de datos a servidores remotos. Ejemplo: Un dispositivo port√°til para monitoreo continuo de ECG puede detectar arritmias en tiempo real sin depender de una conexi√≥n a internet.\nMayor Privacidad y Seguridad\nLos datos m√©dicos son altamente sensibles y est√°n protegidos por regulaciones estrictas (como la HIPAA o el GDPR). Edge AI permite que los datos se procesen y almacenen localmente, minimizando el riesgo de violaciones de seguridad o filtraciones. Ejemplo: Un sensor de glucosa implantable que analiza niveles de glucosa sin enviar los datos a la nube asegura mayor privacidad del paciente.\nReducci√≥n de Costos Operativos\nEl procesamiento en el borde elimina la necesidad de transmitir grandes vol√∫menes de datos a servidores en la nube, lo que reduce costos relacionados con la conectividad y el almacenamiento en l√≠nea. Ejemplo: Un sistema de detecci√≥n de ca√≠das para personas mayores puede analizar los datos del aceler√≥metro directamente en el dispositivo sin enviar grandes vol√∫menes de datos a la nube.\nAplicaciones en Zonas Remotas\nEn √°reas rurales o zonas con conectividad limitada, Edge AI permite el uso de dispositivos m√©dicos avanzados sin depender de conexiones de internet robustas. Ejemplo: Una m√°quina port√°til de ultrasonido que utiliza Edge AI para interpretar im√°genes en tiempo real podr√≠a usarse en campa√±as de salud en comunidades remotas.\nEficiencia Energ√©tica\nLos modelos de Edge AI est√°n dise√±ados para operar en dispositivos de bajo consumo energ√©tico, lo que es ideal para dispositivos m√©dicos port√°tiles y sistemas implantables. Ejemplo: Monitores de salud wearables, como relojes inteligentes o biosensores, que analizan par√°metros fisiol√≥gicos continuamente.\nPersonalizaci√≥n y Adaptaci√≥n en el Lugar\nLos modelos de Edge AI pueden adaptarse a los datos del usuario en tiempo real, permitiendo personalizaci√≥n sin enviar datos sensibles a servidores externos. Ejemplo: Un dispositivo de rehabilitaci√≥n motora que analiza el movimiento del paciente y ajusta los ejercicios en tiempo real seg√∫n su progreso.\nInterdisciplinariedad y Tendencia Futurista\nLa integraci√≥n de Edge AI con la ingenier√≠a biom√©dica fomenta una combinaci√≥n √∫nica de hardware, software y conocimiento m√©dico, lo que te posiciona en el centro de las innovaciones tecnol√≥gicas en salud.\nEl curso est√° dividido en 4 partes:\n1. Introducci√≥n a inteligencia artificial en el borde (EDGE AI).\n2. Hardware y software para EDGE AI.\n3. El flujo de trabajo de EDGE AI.\n4. Dise√±o, desarrollo y evaluaci√≥n de sistemas EDGE AI."
  },
  {
    "objectID": "clases/Class_APSB.html#presentaciones",
    "href": "clases/Class_APSB.html#presentaciones",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentaci√≥n del curso\nIntroducci√≥n 1/2\nIntroducci√≥n 2/2\nLinux\nMetodolog√≠a de desarrollo\nIntroducci√≥n al machine learning\nFlujo de trabajo para proyectos de machine learning"
  },
  {
    "objectID": "clases/Class_APSB.html#datos",
    "href": "clases/Class_APSB.html#datos",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_APSB.html#c√≥digos",
    "href": "clases/Class_APSB.html#c√≥digos",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "C√≥digos",
    "text": "C√≥digos"
  },
  {
    "objectID": "clases/Class_APSB.html#r√∫brica",
    "href": "clases/Class_APSB.html#r√∫brica",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "R√∫brica",
    "text": "R√∫brica\n-Planteamiento del problema"
  },
  {
    "objectID": "clases/Class_APSB.html#laboratorios",
    "href": "clases/Class_APSB.html#laboratorios",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio001: Conociendo LINUX.\nLaboratorio002: An√°lisis exploratorio de datos"
  },
  {
    "objectID": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\n‚ÄúNecesito un documento PDF descargable con la explicaci√≥n de los algoritmos de machine learning utilizados en ciencias de la vida. El texto debe contener una relaci√≥n entre las t√©cnicas de an√°lasis exploratorio y el algoritmo de machine learning, fundamentos te√≥ricos del algoritmo, c√≥digos python para utilizar. Los algoritmos deben ser: KNN, √°rboles de decisi√≥n, m√°quinas de soporte vectorial, bosques aleatorios y gradient boosting machines. Debes verificar la informaci√≥n para evitar alucinaciones.‚Äù\nDocumento 1: machine learning. CHATGPT 4o\nDocumento 2: machine learning. GEMINI 2.0 flash\nJ. D. Kelleher, B. Mac Namee, y A. D‚ÄôArcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed.¬†Cambridge: The MIT press, 2020."
  },
  {
    "objectID": "clases/Class_APSB.html#clases",
    "href": "clases/Class_APSB.html#clases",
    "title": "Adquisici√≥n y Procesamiento de Se√±ales Biom√©dicas en Tecnolog√≠as de Borde",
    "section": "Clases",
    "text": "Clases\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201."
  },
  {
    "objectID": "proyectos/ComparisonML.html",
    "href": "proyectos/ComparisonML.html",
    "title": "Comparing different Machine Learning architectures for classifying medical terms in Colombian sign language",
    "section": "",
    "text": "Presentaci√≥n STSIVA2025"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#introducci√≥n",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#introducci√≥n",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Introducci√≥n",
    "text": "Introducci√≥n"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#adquisici√≥n-de-datos",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#adquisici√≥n-de-datos",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Adquisici√≥n de datos",
    "text": "Adquisici√≥n de datos\n\n\n\nSe utiliz√≥ el sensor XSens MTw Awinda [1].\nSe adquirieron datos de aceleraci√≥n, giroscopio y magnet√≥metro.\nSe uso \\(F_s = 100Hz\\).\nLos sensores capturan se√±ales que representan el movimiento en su propio sistema de coordenadas [2]."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#adquisici√≥n-de-datos-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#adquisici√≥n-de-datos-1",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Adquisici√≥n de datos",
    "text": "Adquisici√≥n de datos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatos adquiridos‚Ä¶\n\n\n\nProtocolo de adquisici√≥n modificado [3]\nActividad con ojos abiertos (eye open), ojos cerrados (eye close) y tarea dual (dual task)"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\n\n\n\n\n\n\n\nPrimer paso\n\n\n\nEliminaci√≥n de datos no √∫tiles.\nDatos eliminados: datos na, columnas PacketCounter y SampleTimeFine\nCreaci√≥n de una columna Time en segundos."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento-1",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\n\n\n\n\n\n\n\nSegundo paso\n\n\n\nConvertir ejes locales a globales. Utilizando el cuaternio generado por el XSens.\nCalcular la magnitud del vector de aceleraci√≥n global y la agregar al DataFrame.\nCalcular la magnitud del vector de velocidad angular global y la agregar al DataFrame.\nSeleccionar 20 segundos de informaci√≥n (eliminar informaci√≥n inicial y final)"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#fusi√≥n-sensorial",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#fusi√≥n-sensorial",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Fusi√≥n sensorial",
    "text": "Fusi√≥n sensorial\n\n\n\n\n\n\n\nAlgoritmo de Fusi√≥n\n\n\n\nSe utiliza el algoritmo de la fusi√≥n de los datos de aceleraci√≥n y giroscopio por defecto de XSens.\nSe utiliza el algoritmo de eliminaci√≥n de distorsi√≥n magn√©tica desarrollado por XSens"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracci√≥n-de-caracter√≠sticas",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracci√≥n-de-caracter√≠sticas",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Extracci√≥n de caracter√≠sticas",
    "text": "Extracci√≥n de caracter√≠sticas\n\n\n\n\n\n\n\nM√©tricas\n\n\n\nRa√≠z cuadr√°tica media (RMS) de la magnitud de la aceleraci√≥n o de la velocidad angular [4].\nAdaptaci√≥n de la longitud de la trayectoria [3].\nArea de de la elipse de oscilaci√≥n (ellipse sway area), t√≠picamente cubriendo el 95% de los datos presentados."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extraccio-de-caracter√≠sticas",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extraccio-de-caracter√≠sticas",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Extraccio de caracter√≠sticas",
    "text": "Extraccio de caracter√≠sticas"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracci√≥n-de-caracter√≠sticas-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracci√≥n-de-caracter√≠sticas-1",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Extracci√≥n de caracter√≠sticas",
    "text": "Extracci√≥n de caracter√≠sticas\n\n\n\n\n\n\n\nRomberg Ratio\n\n\n\nEl test de Romberg es una prueba que se usa frecuentemente en la posturograf√≠a.\nSe basa en la evaluaci√≥n del control postural bajo dos condiciones distintas: con visi√≥n (ojos abiertos) y sin visi√≥n (ojos cerrados).\nEl √≠ndice o ratio de Romberg se calcula dividiendo el balanceo postural (postural sway) en la condici√≥n de ojos cerrados entre el balanceo postural en la condici√≥n de ojos abiertos.\nTambi√©n se puede calcular dividiendo el balanceo postural (postural sway) en la condici√≥n de doble tarea entre el balanceo postural en la condici√≥n de ojos abiertos"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracci√≥n-de-caracter√≠sticas-2",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracci√≥n-de-caracter√≠sticas-2",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Extracci√≥n de caracter√≠sticas",
    "text": "Extracci√≥n de caracter√≠sticas\n\n\n\n\n\n\n\n\n\n\n\n\nEyes Open\nEyes Close\nDual Task\nRatio Romberg 1\nRatio Romberg 2\n\n\n\n\nRMS ACC X\n2,83E-03\n2,91E-03\n2,89E-03\n1,03\n1,02\n\n\nRMS ACC Y\n6,82E-04\n6,80E-03\n6,79E-03\n9,98\n9,96\n\n\nRMS ACC Z\n5,74E-04\n5,08E-04\n4,98E-04\n0,89\n0,87\n\n\nRMS GYR X\n4,24E-07\n3,52E-06\n4,24E-07\n8,29\n1,00\n\n\nRMS GYR Y\n1,02E-05\n8,27E-06\n1,16E-05\n0,81\n1,14\n\n\nRMS GYR Z\n8,68E-08\n6,18E-07\n8,52E-07\n7,12\n9,82\n\n\nPATH TRAJ\n0,0025\n0,0025\n0,0031\n1,00\n1,24\n\n\nAREA_ELIPSE_95%\n5,61E-11\n8,30E-11\n6,55E-12\n1,48\n0,12"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracci√≥n-de-caracter√≠sticas-propuesta",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracci√≥n-de-caracter√≠sticas-propuesta",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Extracci√≥n de caracter√≠sticas (propuesta)",
    "text": "Extracci√≥n de caracter√≠sticas (propuesta)\n\n\n(np.float64(2.7508740895910972), np.float64(3.6048069186140856), np.float64(1.434932874624913), np.float64(2.0295845733092643))"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#referencias",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#referencias",
    "title": "Evaluaci√≥n del equilibrio usando sensores inerciales",
    "section": "Referencias",
    "text": "Referencias\n\n\n[1] M. Paulich, M. Schepers, N. Rudigkeit, y G. Bellusci, ¬´Xsens MTw Awinda: Miniature Wireless Inertial-Magnetic Motion Tracker for Highly Accurate 3D Kinematic Applications¬ª.\n\n\n[2] D. H. Yoon, J.-H. Kim, K. Lee, J.-S. Cho, S.-H. Jang, y S.-U. Lee, ¬´Inertial measurement unit sensor-based gait analysis in adults and older adults: A cross-sectional study¬ª, Gait & Posture, vol. 107, pp. 212-217, ene. 2024, doi: 10.1016/j.gaitpost.2023.10.006.\n\n\n[3] J. Zhou et¬†al., ¬´A novel smartphone App-based assessment of standing postural control: Demonstration of reliability and sensitivity to aging and task constraints¬ª, en 2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM), Shenzhen, China: IEEE, mar. 2021, pp. 1-6. doi: 10.1109/HEALTHCOM49281.2021.9398972.\n\n\n[4] M. Calcagni, P. Kosa, y B. Bielekova, ¬´Smartphone postural sway and pronator drift tests as measures of neurological disability¬ª, BMC Neurol, vol. 25, n.¬∫ 1, p. 50, feb. 2025, doi: 10.1186/s12883-025-04038-2."
  }
]