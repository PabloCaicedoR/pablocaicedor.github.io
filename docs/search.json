[
  {
    "objectID": "proyectos/Sabana/fileProof.html",
    "href": "proyectos/Sabana/fileProof.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport scipy.io as sio\nimport scipy.signal as sig\nfrom scipy.signal import tf2zpk\nfrom scipy.spatial.transform import Rotation as R\n\npath_ecg = \"../../data\"\n\n\ndef plot_imu_frame(axis_length=1.0, arrow_ratio=0.1):\n    \"\"\"\n    Dibuja el sistema de coordenadas de una IMU en 3D.\n\n    Parámetros:\n    - axis_length: longitud de cada eje.\n    - arrow_ratio: fracción del eje destinada a la cabeza de la flecha.\n    \"\"\"\n    # Creamos la figura y el eje 3D\n    fig = plt.figure(figsize=(6, 6))\n    ax = fig.add_subplot(111, projection=\"3d\")\n\n    # Origen de los ejes\n    origin = np.array([0, 0, 0])\n\n    # Vectores unitarios para X, Y, Z\n    axes = np.eye(3) * axis_length\n    colors = [\"r\", \"g\", \"b\"]\n    labels = [\"N\", \"Y\", \"-g\"]\n\n    # Dibujar cada eje con quiver (flecha)\n    for vec, c, lab in zip(axes, colors, labels):\n        ax.quiver(\n            origin[0],\n            origin[1],\n            origin[2],\n            vec[0],\n            vec[1],\n            vec[2],\n            color=c,\n            arrow_length_ratio=arrow_ratio,\n            linewidth=2,\n        )\n        # Etiquetar el extremo del eje\n        ax.text(\n            vec[0] * 1.05,\n            vec[1] * 1.05,\n            vec[2] * 1.05,\n            lab,\n            color=c,\n            fontsize=14,\n            fontweight=\"bold\",\n        )\n\n    # Ajustes de estilo\n    ax.set_xlim(0, axis_length * 1.2)\n    ax.set_ylim(0, axis_length * 1.2)\n    ax.set_zlim(0, axis_length * 1.2)\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n    ax.set_zlabel(\"Z\")\n    ax.set_title(\"Sistema de coordenadas IMU\")\n    ax.grid(True)\n\n    # Mostrar proporción igual para los tres ejes\n    ax.set_box_aspect([1, 1, 1])\n\n    plt.tight_layout()\n    plt.show()\n\n\ndef calcular_relacion_romberg(\n    param_eyes_open: float,\n    param_eyes_close: float,\n) -&gt; float:\n    return param_eyes_close / param_eyes_open\n\n\ndef calcular_rms(signal1):\n    return np.sqrt(np.mean(np.square(signal1)))\n\n\ndef calcular_magnitud_angular_velocity(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleración global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Gyr_Global_Mag\"] = np.sqrt(\n        df[\"Gyr_X_global\"] ** 2 + df[\"Gyr_Y_global\"] ** 2 + df[\"Gyr_Z_global\"] ** 2\n    )\n    return df.copy()\n\n\ndef calcular_magnitud_aceleracion_local(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleración global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Acc_Local_Mag\"] = np.sqrt(df[\"Acc_Y\"] ** 2 + df[\"Acc_Z\"] ** 2)\n    return df.copy()\n\n\ndef calcular_magnitud_aceleracion(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleración global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Acc_Global_Mag\"] = np.sqrt(df[\"Acc_X_global\"] ** 2 + df[\"Acc_Y_global\"] ** 2)\n    return df.copy()\n\n\ndef CalculateGlobalVectors(df):\n    # Cuaterniones y aceleración local\n    quaternions = df[[\"Quat_q0\", \"Quat_q1\", \"Quat_q2\", \"Quat_q3\"]].values\n    acc_local = df[[\"Acc_X\", \"Acc_Y\", \"Acc_Z\"]].values\n    ang_vel_local = df[[\"Gyr_X\", \"Gyr_Y\", \"Gyr_Z\"]].values\n\n    sig_filtersos = sig.butter(10, 4, \"low\", fs=100, output=\"sos\")\n\n    # Aplicar filtro a las columnas de aceleración\n    acc_local = sig.sosfilt(sig_filtersos, acc_local)\n    ang_vel_local = sig.sosfilt(sig_filtersos, ang_vel_local)\n    df[[\"Acc_X\", \"Acc_Y\", \"Acc_Z\"]] = acc_local\n    df[[\"Gyr_X\", \"Gyr_Y\", \"Gyr_Z\"]] = ang_vel_local\n\n    # Rotar aceleraciones al sistema global\n    rot = R.from_quat(quaternions)\n    acc_global = rot.apply(acc_local)\n    ang_vel_global = rot.apply(ang_vel_local)\n\n    # 🔁 Normalizar Y y Z a máximo absoluto de 1\n    # acc_global[:, 1] = acc_global[:, 1] / np.max(np.abs(acc_global[:, 1]))\n    # acc_global[:, 2] = acc_global[:, 2] / np.max(np.abs(acc_global[:, 2]))\n\n    # Guardar aceleraciones normalizadas\n    df[\"Acc_X_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 0])\n    df[\"Acc_Y_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 1])\n    df[\"Acc_Z_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 2])\n    df[\"Gyr_X_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 0])\n    df[\"Gyr_Y_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 1])\n    df[\"Gyr_Z_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 2])\n    return df.copy()\n\n\ndef select_mid_segment(\n    df: pd.DataFrame,\n    time_col: str = \"Time\",\n    half_length: float = 10.0,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Selecciona el segmento de df que comprende `pre_sec` segundos\n    antes y `post_sec` segundos después del punto medio de la serie\n    temporal indicada por `time_col`.\n\n    Parámetros\n    ----------\n    df : pd.DataFrame\n        DataFrame que debe contener la columna de tiempo `time_col`.\n    time_col : str\n        Nombre de la columna de tiempo (en segundos).\n    pre_sec : float\n        Segundos a incluir antes del punto medio.\n    post_sec : float\n        Segundos a incluir después del punto medio.\n\n    Devuelve\n    -------\n    pd.DataFrame\n        Sub-DataFrame con las mismas columnas que `df`, filtrado\n        para el intervalo [midpoint - pre_sec, midpoint + post_sec].\n    \"\"\"\n    # Calcular extremo inferior y superior del tiempo\n    t_min = df[time_col].min()\n    t_max = df[time_col].max()\n    midpoint = (t_min + t_max) / 2\n\n    start_time = midpoint - half_length\n    end_time = midpoint + half_length\n\n    # Filtrar el DataFrame por el rango de tiempo\n    segment = df[(df[time_col] &gt;= start_time) & (df[time_col] &lt;= end_time)].copy()\n\n    return segment\n\n\ndataDualTask = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/dt_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeClosed = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/ec_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeOpen = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/eo_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeClosed = dataEyeClosed.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\ndataDualTask = dataDualTask.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\ndataEyeOpen = dataEyeOpen.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\nfs = 100\nTs = 1 / fs\ndataEyeOpen[\"Time\"] = Ts * np.arange(0, len(dataEyeOpen))\ndataEyeClosed[\"Time\"] = Ts * np.arange(0, len(dataEyeClosed))\ndataDualTask[\"Time\"] = Ts * np.arange(0, len(dataDualTask))\ndataDualTask = CalculateGlobalVectors(dataDualTask)\ndataEyeClosed = CalculateGlobalVectors(dataEyeClosed)\ndataEyeOpen = CalculateGlobalVectors(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_aceleracion(dataDualTask)\ndataEyeClosed = calcular_magnitud_aceleracion(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_aceleracion(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_aceleracion_local(dataDualTask)\ndataEyeClosed = calcular_magnitud_aceleracion_local(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_aceleracion_local(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_angular_velocity(dataDualTask)\ndataEyeClosed = calcular_magnitud_angular_velocity(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_angular_velocity(dataEyeOpen)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2\n\n\ndef ellipse_sway_area(x, y, confidence=0.95, plot=True):\n    \"\"\"\n    Calcula el área y dibuja la elipse de oscilación para los datos (x,y)\n    cubriendo el porcentaje de confianza dado (p.ej. 0.95 para 95%).\n\n    Parámetros:\n    - x, y: arrays de coordenadas (misma longitud).\n    - confidence: nivel de confianza (entre 0 y 1).\n    - plot: si True, dibuja los puntos y la elipse.\n\n    Retorna:\n    - area: área de la elipse.\n    - width, height: semiejes mayor y menor.\n    - angle: ángulo de rotación en grados.\n    \"\"\"\n    # Centro (media)\n    mu = np.array([np.mean(x), np.mean(y)])\n    # Matriz de covarianza\n    cov = np.cov(x, y)\n    # Eigenvalores y eigenvectores\n    vals, vecs = np.linalg.eigh(cov)\n    # Ordenar de mayor a menor\n    order = vals.argsort()[::-1]\n    vals = vals[order]\n    vecs = vecs[:, order]\n\n    # Factor de escala: chi-cuadrado inverso para 2 grados y nivel dado\n    chi2_val = chi2.ppf(confidence, df=2)\n    # Semiejes\n    a = np.sqrt(vals[0] * chi2_val)\n    b = np.sqrt(vals[1] * chi2_val)\n    area = np.pi * a * b\n\n    # Ángulo de rotación (en grados) del semieje mayor respecto al eje X\n    angle = np.degrees(np.arctan2(vecs[1, 0], vecs[0, 0]))\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(6, 6))\n        ax.scatter(x, y, s=10, alpha=0.5, label=\"Datos\")\n        # Dibujo de la elipse\n        from matplotlib.patches import Ellipse\n\n        ellipse = Ellipse(\n            xy=mu,\n            width=2 * a,\n            height=2 * b,\n            angle=angle,\n            edgecolor=\"r\",\n            facecolor=\"none\",\n            lw=2,\n            label=f\"{int(confidence*100)}% Elipse\",\n        )\n        ax.add_patch(ellipse)\n        ax.set_aspect(\"equal\")\n        ax.set_xlabel(\"X\")\n        ax.set_ylabel(\"Y\")\n        ax.set_title(\n            f\"Elipse de oscilación ({int(confidence*100)}% conf.)\\nÁrea = {area:.2f}\"\n        )\n        ax.legend()\n        plt.grid(True)\n        plt.show()\n\n    return area, a, b, angle\n\n\n# Ejemplo de uso:\nif __name__ == \"__main__\":\n    # Simulamos datos de sway\n    np.random.seed(0)\n    x = np.random.normal(0, 1, size=500)\n    y = 0.5 * x + np.random.normal(0, 0.8, size=500)\n\n    area, a, b, angle = ellipse_sway_area(\n        dataDualTask[\"Acc_X_global\"], dataDualTask[\"Acc_Y_global\"], confidence=0.95\n    )\n    print(f\"Área de la elipse al 95 %: {area:.4f}\")\n    print(f\"Semiejes: a={a:.2f}, b={b:.2f}, ángulo={angle:.1f}°\")\n\n\n\n\n\n\n\n\nÁrea de la elipse al 95 %: 0.0000\nSemiejes: a=0.00, b=0.00, ángulo=67.1°\n\n\n\nrmsAccX_eo = calcular_rms(dataEyeOpen[\"Acc_X_global\"])\nrmsAccY_eo = calcular_rms(dataEyeOpen[\"Acc_Y_global\"])\nrmsAccZ_eo = calcular_rms(dataEyeOpen[\"Acc_Z_global\"])\n\nrmsGyrX_eo = calcular_rms(dataEyeOpen[\"Gyr_X_global\"])\nrmsGyrY_eo = calcular_rms(dataEyeOpen[\"Gyr_Y_global\"])\nrmsGyrZ_eo = calcular_rms(dataEyeOpen[\"Gyr_Z_global\"])\n\npathTrajectAcc_eo = np.sum(dataEyeOpen[\"Acc_Local_Mag\"])\nareaAcc_eo, a, b, angle = ellipse_sway_area(\n    dataEyeOpen[\"Acc_X_global\"],\n    dataEyeOpen[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\n\nrmsAccX_ec = calcular_rms(dataEyeClosed[\"Acc_X_global\"])\nrmsAccY_ec = calcular_rms(dataEyeClosed[\"Acc_Y_global\"])\nrmsAccZ_ec = calcular_rms(dataEyeClosed[\"Acc_Z_global\"])\n\nrmsGyrX_ec = calcular_rms(dataEyeClosed[\"Gyr_X_global\"])\nrmsGyrY_ec = calcular_rms(dataEyeClosed[\"Gyr_Y_global\"])\nrmsGyrZ_ec = calcular_rms(dataEyeClosed[\"Gyr_Z_global\"])\n\npathTrajectAcc_ec = np.sum(dataEyeClosed[\"Acc_Local_Mag\"])\nareaAcc_ec, a, b, angle = ellipse_sway_area(\n    dataEyeClosed[\"Acc_X_global\"],\n    dataEyeClosed[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\n\nrmsAccX_dt = calcular_rms(dataDualTask[\"Acc_X_global\"])\nrmsAccY_dt = calcular_rms(dataDualTask[\"Acc_Y_global\"])\nrmsAccZ_dt = calcular_rms(dataDualTask[\"Acc_Z_global\"])\n\nrmsGyrX_dt = calcular_rms(dataDualTask[\"Gyr_X_global\"])\nrmsGyrY_dt = calcular_rms(dataDualTask[\"Gyr_Y_global\"])\nrmsGyrZ_dt = calcular_rms(dataDualTask[\"Gyr_Z_global\"])\n\npathTrajectAcc_dt = np.sum(dataDualTask[\"Acc_Local_Mag\"])\nareaAcc_dt, a, b, angle = ellipse_sway_area(\n    dataDualTask[\"Acc_X_global\"], dataDualTask[\"Acc_Y_global\"], confidence=0.95,plot=False\n)\n\n\nrmsAccX_dt = calcular_rms(dataDualTask[\"Acc_X_global\"])\nrmsAccY_dt = calcular_rms(dataDualTask[\"Acc_Y_global\"])\nrmsAccZ_dt = calcular_rms(dataDualTask[\"Acc_Z_global\"])\n\nrmsGyrX_dt = calcular_rms(dataDualTask[\"Gyr_X_global\"])\nrmsGyrY_dt = calcular_rms(dataDualTask[\"Gyr_Y_global\"])\nrmsGyrZ_dt = calcular_rms(dataDualTask[\"Gyr_Z_global\"])\n\npathTrajectAcc_dt = np.sum(dataDualTask[\"Acc_Local_Mag\"])\nareaAcc_dt, a, b, angle = ellipse_sway_area(\n    dataDualTask[\"Acc_X_global\"],\n    dataDualTask[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\nrmsAccX_ec = calcular_rms(dataEyeClosed[\"Acc_X_global\"])\nrmsAccY_ec = calcular_rms(dataEyeClosed[\"Acc_Y_global\"])\nrmsAccZ_ec = calcular_rms(dataEyeClosed[\"Acc_Z_global\"])\n\nrmsGyrX_ec = calcular_rms(dataEyeClosed[\"Gyr_X_global\"])\nrmsGyrY_ec = calcular_rms(dataEyeClosed[\"Gyr_Y_global\"])\nrmsGyrZ_ec = calcular_rms(dataEyeClosed[\"Gyr_Z_global\"])\n\npathTrajectAcc_ec = np.sum(dataEyeClosed[\"Acc_Local_Mag\"])\nareaAcc_ec, a, b, angle = ellipse_sway_area(\n    dataEyeClosed[\"Acc_X_global\"],\n    dataEyeClosed[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\nrmsAccX_eo = calcular_rms(dataEyeOpen[\"Acc_X_global\"])\nrmsAccY_eo = calcular_rms(dataEyeOpen[\"Acc_Y_global\"])\nrmsAccZ_eo = calcular_rms(dataEyeOpen[\"Acc_Z_global\"])\n\nrmsGyrX_eo = calcular_rms(dataEyeOpen[\"Gyr_X_global\"])\nrmsGyrY_eo = calcular_rms(dataEyeOpen[\"Gyr_Y_global\"])\nrmsGyrZ_eo = calcular_rms(dataEyeOpen[\"Gyr_Z_global\"])\n\npathTrajectAcc_eo = np.sum(dataEyeOpen[\"Acc_Local_Mag\"])\nareaAcc_eo, a, b, angle = ellipse_sway_area(\n    dataEyeOpen[\"Acc_X_global\"],\n    dataEyeOpen[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)"
  },
  {
    "objectID": "clases/talleres.html",
    "href": "clases/talleres.html",
    "title": "Talleres",
    "section": "",
    "text": "Taller Primer Semestre"
  },
  {
    "objectID": "clases/Class_PSIM.html",
    "href": "clases/Class_PSIM.html",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "“Un área de rápido crecimiento y variedad de aplicaciones en la ingeniería biomédica a nivel nacional y global es el procesamiento digital de señales e imágenes médicas. Es por eso, que a través de este curso se desea dar las herramientas necesarias para los graduados del programa puedan tener competencias básicas en las técnicas clásicas y algunas técnicas modernas de procesamiento de señales e imágenes. La primera parte del curso se encuentra enfocada al desarrollo de técnicas de procesamiento para señales biomédicas unidimensionales, exponiendo primero su origen fisiológico y siguiendo con la presentación de las principales técnicas para su análisis y procesamiento. La segunda parte del curso hace énfasis en el estudio de imágenes médicas, partiendo de una explicación de los principales métodos computacionales utilizados para procesamiento digital de imágenes y luego exponiendo brevemente el proceso de su formación. A través de prácticas de laboratorio con señales e imágenes médicas (reales o simuladas), el estudiante podrá aplicar y reforzar los conocimientos aprendidos en el curso” fragmento tomado del microcurriculo de la asignatura.\nEl curso está dividido en 4 partes:\n1. Introducción al procesado de señales e imágenes biomédicas.\n2. Fundamentos procesado de señales e imágenes biomédicas\n3. Extracción de características de señales biomédicas.\n4. Extracción de características de imágenes biomédicas."
  },
  {
    "objectID": "clases/Class_PSIM.html#presentaciones",
    "href": "clases/Class_PSIM.html#presentaciones",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción\nIntroducción al procesamiento de imagenes\nLa imagen digital. Procesamiento de Imágenes 1/4\nLa imagen digital. Procesamiento de Imágenes 2/4\nRespuesta en frecuencia. (3/4)\nWavelets 4/4"
  },
  {
    "objectID": "clases/Class_PSIM.html#datos",
    "href": "clases/Class_PSIM.html#datos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_PSIM.html#códigos",
    "href": "clases/Class_PSIM.html#códigos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_PSIM.html#laboratorios",
    "href": "clases/Class_PSIM.html#laboratorios",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio 01\nLaboratorio 02\nLaboratorio 03"
  },
  {
    "objectID": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "href": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nPrimer Parcial\nSegundo Parcial\nTercer Parcial"
  },
  {
    "objectID": "clases/Class_ASIM.html",
    "href": "clases/Class_ASIM.html",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "",
    "text": "Aprender procesamiento de señales e imágenes con aprendizaje automático en medicina es crucial para mejorar la precisión y eficiencia en el diagnóstico y tratamiento de enfermedades. El aprendizaje automático permite analizar grandes cantidades de datos de imágenes médicas y señales biomédicas, como rayos X, tomografías computarizadas, resonancia magnética, ECG, EEG y EMG, para identificar patrones y anomalías que pueden indicar la presencia de enfermedades. Esto puede llevar a un diagnóstico más preciso y temprano, lo que a su vez puede mejorar los resultados para los pacientes y reducir la morbilidad y mortalidad.\nAdemás, el aprendizaje automático puede ayudar a personalizar tratamientos para pacientes individuales según sus características únicas de imágenes médicas y señales. También puede automatizar tareas clínicas rutinarias, como segmentación de imágenes, extracción de características y análisis de datos, lo que permite a los médicos centrarse en la toma de decisiones de alto nivel.\nLa aplicación del aprendizaje automático en medicina también puede facilitar la investigación médica, analizando grandes conjuntos de datos para identificar tendencias y patrones que pueden revelar nuevos conocimientos sobre enfermedades y tratamientos. Además, puede permitir la monitorización remota de pacientes y la telemedicina, ampliando el acceso a servicios de atención médica."
  },
  {
    "objectID": "clases/Class_ASIM.html#presentaciones",
    "href": "clases/Class_ASIM.html#presentaciones",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nClase 001: Introducción al machine learning"
  },
  {
    "objectID": "clases/Class_ASIM.html#laboratorios",
    "href": "clases/Class_ASIM.html#laboratorios",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLab00: Conducta de entrada\nLab01: Programación orientada a objetos"
  },
  {
    "objectID": "clases/Class_ASIM.html#atención-a-estudiantes",
    "href": "clases/Class_ASIM.html#atención-a-estudiantes",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "href": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "title": "Proyecto Final: APSB1",
    "section": "",
    "text": "Criterio\n1 - Deficiente\n2 - Insuficiente\n3 - Aceptable\n4 - Bueno\n5 - Excelente\nPonderación\n\n\n\n\nDefinición del Problema y Justificación\nNo se identifica un problema biomédico claro.\nSe identifica un problema, pero sin relevancia biomédica o justificación.\nSe plantea un problema relevante con justificación básica.\nProblema bien definido con referencias científicas.\nProblema biomédico bien formulado, con justificación sólida basada en literatura científica.\n15%\n\n\nAdquisición y Procesamiento de Datos en el Borde\nNo se especifica el tipo de datos ni sensores.\nSe mencionan sensores, pero sin detalles sobre la captura y preprocesamiento.\nSe describe la adquisición de datos con procesamiento básico.\nSe justifica la selección de sensores y se menciona un preprocesamiento adecuado.\nSelección óptima de sensores con procesamiento avanzado y justificación técnica detallada.\n20%\n\n\nDesarrollo e Implementación del Modelo de IA\nNo se propone un modelo de IA.\nSe menciona un modelo, pero sin adecuación a Edge AI.\nSe plantea un modelo básico con justificación limitada.\nSe elige un modelo adecuado y optimizado para Edge AI.\nModelo avanzado con técnicas de optimización y justificadas con métricas.\n20%\n\n\nValidación y Pruebas en Tiempo Real\nNo se contempla validación del modelo.\nSe menciona validación, pero sin metodología clara.\nSe plantea una validación con datos simulados.\nSe incluyen pruebas con datos reales y métricas de rendimiento.\nValidación robusta con pruebas extensivas y comparación con estándares biomédicos.\n20%\n\n\nEscalabilidad y Aplicabilidad en la Industria Biomédica\nNo se considera la escalabilidad del proyecto.\nSe menciona la escalabilidad, pero sin detalles técnicos.\nSe plantea una estrategia básica de escalabilidad.\nEstrategia clara de implementación y compatibilidad con sistemas médicos.\nProyecto altamente escalable, con integración en entornos clínicos y estándares como HL7 o FHIR.\n15%\n\n\nPresentación y Documentación\nNo hay documentación ni presentación clara.\nDocumentación incompleta o desordenada.\nPresentación básica con documentación limitada.\nPresentación clara y documentada correctamente.\nDocumentación profesional con detalles técnicos y presentación estructurada.\n10%"
  },
  {
    "objectID": "rubricas/Rubrica_EDA.html",
    "href": "rubricas/Rubrica_EDA.html",
    "title": "Rúbrica: Análisis Exploratorio de Datos",
    "section": "",
    "text": "Indicador\nBueno\nSuficiente\nInsuficiente\n\n\n\n\nLimpieza del Dataset\nEl dataset no presenta ni registros nulos, ni vacíos. Existe una estrategia para manejo de atípicos (100%)\nEl dataset no presenta ni registros nulos, ni vacíos (50%)\nEl dataset presenta registros nulos y/o vacíos. No existe una estrategia para manejo de atípicos (0%)\n\n\nConsumo de información\nSe consumen al menos 2 fuentes de datos provenientes de las sugerencias de los organizadores (100%)\nSe consume una fuente de datos proveniente de las sugerencias de los organizadores (50%)\nNo se consume ninguna fuente de datos conocida (0%)\n\n\nEDA sobre nuevas variables\nSe plantean correctamente las relaciones entre la variables y estas se demuestran a plenitud utilizando matemática y/o estadística (100%)\nSe plantean dos relaciones entre las variables (50%)\nNo se plantean las relaciones entre las variables (0%)\n\n\nUso de plantilla\nUsan la plantilla rmarkdown (100%)\n\nNo se usa la plantilla rmarkdown(0%)\n\n\nVisualización de la informacion\nLa información de TODAS las gráficas se observa plenamente (100%)\nLa información de las gráficas se observa parcialmente(50%)\nLa información de la gráfica no se observa (0%)\n\n\nJustificación del problema\nExiste una justificación del problema(100%)\n\nNo Existe justificación al problema resuelto (0%)\n\n\nUbicación del problema\nSe plantea correctamente la ubicación del problema 100%\n\nNo se plantea correctamente la ubicación del problema 0%"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n10 oct 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n25 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de Talleres Ingeniería Biomédica en la Escuela Colombiana de Ingeniería\n\n\n\n11 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Sistemas y Señales Biomédicoss en la Escuela Colombiana de Ingeniería\n\n\n\n9 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde en la Escuela Colombiana de Ingeniería\n\n\n\n8 sept 2025\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#clases",
    "href": "index.html#clases",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n10 oct 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n25 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de Talleres Ingeniería Biomédica en la Escuela Colombiana de Ingeniería\n\n\n\n11 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Sistemas y Señales Biomédicoss en la Escuela Colombiana de Ingeniería\n\n\n\n9 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde en la Escuela Colombiana de Ingeniería\n\n\n\n8 sept 2025\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#tutoriales",
    "href": "index.html#tutoriales",
    "title": "PECR Knowledge Hub",
    "section": "Tutoriales",
    "text": "Tutoriales\n\n\n\n\n\n\n\n\n\n\nInstalación de Entorno de trabajo. Ubuntu WSL2\n\n\nTutorial\n\n\n\n8 sept 2025\n\n\n\n\n\n\n\n\n\n\n\nCaso práctico: Análisis de señales EMG en rendimiento deportivo con ML/DL\n\n\nASIM_M\n\n\n\n23 jul 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython programming\n\n\nA small tutorial in python in slides\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\nMicrobit – El minicomputador\n\n\nTutorial: Electrónica Básica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\nMicrobit – El minicomputador\n\n\nTutorial: Electrónica Básica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial de Python\n\n\nBreve Tutorial de Python\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputación de seno y coseno usando expansión de Taylor\n\n\nUn ejemplo de clase del cálculo de una serie de Taylor sin uso de librerías especiales de Python – En construcción –\n\n\n\n6 feb 2023\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#proyectos",
    "href": "index.html#proyectos",
    "title": "PECR Knowledge Hub",
    "section": "Proyectos",
    "text": "Proyectos\n\n\n\n\n\n\n\n\n\n\nPredictive modeling for seizure detection in pharmacoresistant epilepsy: a machine learning approach\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparing different Machine Learning architectures for classifying medical terms in Colombian sign language\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "recursos/talleres/SYSB/Taller_2025_1.html",
    "href": "recursos/talleres/SYSB/Taller_2025_1.html",
    "title": "Taller 1 - Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Taller 1\nProfesores\nJenny Carolina Castiblanco Sánchez\nPablo Eduardo Caicedo Rodríguez\nDescripción\nA través de este taller se reforzarán los conocimientos en: señales, transformaciones de la variable independiente, clasificación de señales, ADC y DAC.\nProcedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\nConsidere la señal\nDibuje:\nDetermine si las siguientes señales son periódicas y encuentre su periodo\nPara las siguientes señales encuentre, la potencia instantánea, la energía y la potencia promedio. Indique si la señal se considera de energía o de potencia.\nDemuestre que si y son señales impares, entonces:\n, es una señal par\nes una señal impar.\nSiendo y , grafique en Python y . ¿se cumple lo indicado en el numeral a y b?\nEncuentre la expresión analítica de las señales mostradas a continuación utilizando funciones y (escalón unitario y rampa).\nPara una señal análoga encontrar\nIndique si la señal es una señal periódica, en caso afirmativo, indique el periodo de la señal.\nFrecuencia de muestro que cumpla con el teorema de Nyquist.\nEncontrar con la frecuencia de muestreo encontrada en el punto anterior.\nIndique si la señal es una señal periódica, en caso afirmativo, indique el periodo de la señal.\nConsidere el sistema de procesamiento de señales mostrado en la figura:\nRecuerde que . Si la entrada es , encontrar:\nLa salida si . ¿Con esta frecuencia se puede reconstruir la señal en si ? Justifique su respuesta.\nLa salida si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¿La señal es periódica en tiempo discreto? Justifique su respuesta.\nPara la señal del punto b, encontrar la señal cuantizada de un ciclo de la señal si el tamaño del registro es de 4bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripción",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\nSolución\nSe grafican las transformaciones solicitadas en Python con Matplotlib.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_t(t):\n    return np.piecewise(t, [(-1 &lt;= t) & (t &lt;= 0), (0 &lt; t) & (t &lt;= 2), (2 &lt; t) & (t &lt;= 3)],\n                         [lambda t: t + 1, 2, 1, 0])\n\nt = np.linspace(-2, 4, 1000)\nplt.plot(t, x_t(t), label='x(t)')\nplt.xlabel('t')\nplt.ylabel('x(t)')\nplt.legend()\nplt.show()\n\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\nSolución\nAnalizamos si \\(\\frac{f_0}{f_s}\\) es racional.\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\nPeríodos: \\(T_1 = \\frac{2\\pi}{2} = \\pi\\), \\(T_2 = \\frac{2\\pi}{\\pi} = 2\\)\nMínimo común múltiplo: **Período = 2*\n\n\\(x(t) = e^{-j(4\\pi/3)t} + e^{j(2\\pi/5)t}\\)\n\nSe buscan los períodos fundamentales.\nNo es periódica porque las razones de frecuencias son irracionales.\n\n\n…\n\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nSolución\n\nPeríodo de la señal:\n\nFrecuencias: \\(f_1 = 300Hz\\), \\(f_2 = 240Hz\\)\nMCM de \\(\\frac{1}{300}\\) y \\(\\frac{1}{240}\\) → T = 1/60 s\n\nFrecuencia de muestreo\n\nTeorema de Nyquist: \\(f_s &gt; 2f_{max} = 600Hz\\)\n\nSeñal muestreada:\nfs = 600  # Hz\nn = np.arange(0, 100)\nxa_n = np.sin(600*np.pi*n/fs) + 3*np.sin(480*np.pi*n/fs)\nplt.stem(n, xa_n)\nplt.show()\n\n…\n\n\n\n6. Muestreo y cuantización\n\nSolución\n\nFrecuencia de muestreo:\n\n\\(T_m1 = 12.5ms\\) → \\(f_s = 80Hz\\)\nNo cumple Nyquist → No se puede reconstruir\n\nMuestreo a 8 veces Nyquist:\n\n\\(f_s = 5760Hz\\)\nSe evalúa si \\(\\frac{f_0}{f_s}\\) es racional → Sí es periódica\n\nCuantización (4 bits, rango 0-5):\n\nPaso de cuantización: \\(\\Delta = \\frac{5}{2^4}\\)\nSe discretiza la señal según niveles de cuantización.\n\n\nimport numpy as np\nlevels = np.linspace(0, 5, 16)\nquantized_signal = np.digitize(xa_n, levels) * (5 / 16)\nplt.stem(n, quantized_signal)\nplt.show()\n\nFin del taller."
  },
  {
    "objectID": "recursos/documentos/Teoria_SeñalesEnergiaPotencia.html",
    "href": "recursos/documentos/Teoria_SeñalesEnergiaPotencia.html",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "¿Por qué distinguir entre señales de energía y señales de potencia en procesamiento de señales?\n\nEl conjunto matemático adecuado.Las señales de energía pertenecen a \\(L^{2}\\) con norma finita \\(\\lVert x\\rVert_{2}=\\sqrt{E}\\), lo que habilita resultados como Parseval/Plancherel (p. ej., \\(\\int_{-\\infty}^{\\infty}\\lvert x(t)\\rvert^{2},dt=\\tfrac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert X(\\omega)\\rvert^{2},d\\omega\\)). Las señales de potencia suelen requerir promedios temporales y estadísticas de segundo orden en lugar de normas finitas.\nEl análisis espectral difiere. En señales de energía, el objeto natural es la transformada de Fourier \\(X(\\omega)\\) y la energía se concentra en \\(\\lvert X(\\omega)\\rvert^{2}\\). En señales de potencia (p. ej., periódicas o estacionarias), el objeto clave es la densidad espectral de potencia (PSD) \\(S_{X}(\\omega)\\), obtenida a partir de la autocorrelación \\(R_{X}(\\tau)\\) vía Wiener–Khinchin: \\(S_{X}(\\omega)=\\mathcal{F}{R_{X}(\\tau)}\\).\nLas métricas de desempeño dependen de la clase. La relación señal-ruido se formula como SNR de energía \\(\\mathrm{SNR}=E_{s}/E_{n}\\) para pulsos/transitorios y como SNR de potencia \\(\\mathrm{SNR}=P_{s}/P_{n}\\) para procesos de larga duración o estacionarios. Usar la métrica incorrecta sesga el diseño de detectores/estimadores.\nDiseño y evaluación de filtros. Para señales de energía, la detección óptima usa filtros casados que maximizan la energía de salida. Para señales de potencia/estacionarias, se modela el ruido mediante la PSD (p. ej., filtrado de Wiener) y se evalúa la potencia o varianza de salida.\nMuestreo, ventanas y práctica con DFT/FFT. Señales de energía: se integra la energía en el intervalo observado e interprete \\(\\lvert X[k]\\rvert^{2}\\) como distribución de energía por bins de la DFT. Señales de potencia: se estima la PSD con periodogramas/Welch; \\(S_{X}(\\omega)\\) tiene unidades de potencia por Hz y se promedia entre ventanas para reducir varianza.\nModelado de bioseñales reales. Muchos estallidos/transitorios biomédicos (ráfagas de EMG, potenciales evocados) se comportan como señales de energía; componentes cuasi-periódicos o estacionarios de larga duración (fundamental del ECG en reposo, respiración en minutos) se comportan como señales de potencia. Modelarlas correctamente guía la extracción de rasgos (envolventes basadas en energía vs. bandas de PSD).\nArgumentos de convergencia y estabilidad. Demostraciones de convergencia para estimadores y cotas de estabilidad para sistemas suelen asumir energía finita o potencia promedio finita; clasificar mal invalida esas garantías.\nUnidades e interpretación. Los espectros de energía se relacionan con \\(\\lvert X(\\omega)\\rvert^{2}\\) (su integral total da \\(E\\)). La PSD integra a potencia promedio: \\(\\tfrac{1}{2\\pi}\\int_{-\\infty}^{\\infty}S_{X}(\\omega),d\\omega=P\\).\nRegla rápida. Si la señal se extingue o es estrictamente acotada en tiempo y \\(\\int\\lvert x\\rvert^{2}\\) es finita, trátela como energía; si persiste indefinidamente con promedio bien definido, trátela como potencia y use \\(R_{X}(\\tau)\\)/\\(S_{X}(\\omega)\\)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html",
    "href": "recursos/documentos/SYSB/cuantizacion.html",
    "title": "Quantization",
    "section": "",
    "text": "Quantization maps a continuous-amplitude signal to a finite set of discrete levels so that it can be represented by digits. After anti-alias filtering and sampling, an analog-to-digital converter (ADC) applies quantization. This process introduces an error that acts like noise under standard conditions; understanding its magnitude is essential to sizing bit depth, gain, and dynamic range in biomedical systems (ECG, EEG, EMG, PPG).\n\n\n\nLet the ADC input range be \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\) with \\(b\\) bits and \\(L=2^b\\) levels. The step size (LSB) is\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nTwo common realizations:\n\nMid-tread (rounding): \\(Q(x)=\\Delta,\\mathrm{round}\\left(\\frac{x}{\\Delta}\\right)\\) for \\(x\\in(V\\_{\\min},V\\_{\\max})\\).\nMid-rise (truncate with half-step offset): \\(Q(x)=\\Delta!\\left(\\left\\lfloor\\frac{x}{\\Delta}\\right\\rfloor+\\tfrac12\\right)\\).\n\nOutside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\), overload/clipping occurs: \\(\\tilde{x}=Q(x)=V\\_{\\max}\\) if \\(x&gt;V\\_{\\max}\\) and \\(\\tilde{x}=V\\_{\\min}\\) if \\(x\\&lt;V\\_{\\min}\\).\nCodebook and decision thresholds: Decision thresholds lie at \\(k\\Delta\\) and reconstruction levels at either \\(k\\Delta\\) (mid-tread) or \\((k+\\tfrac12)\\Delta\\) (mid-rise).\n\n\n\nDefine the quantization error \\(e=x-Q(x)\\). Under the high-resolution assumptions (signal varies slowly relative to \\(\\Delta\\), input well distributed within the range, and no overload), the error is modeled as white, signal-independent, and uniformly distributed on \\(\\left[-\\frac{\\Delta}{2},\\frac{\\Delta}{2}\\right]\\):\n\nMean: \\(\\mathbb{E}\\left[e\\right]=0\\).\nVariance (power): \\(\\sigma\\_e^2=\\dfrac{\\Delta^2}{12}\\).\nRMS: \\(\\sigma\\_e=\\dfrac{\\Delta}{\\sqrt{12}}\\).\n\nFor a full-scale sinusoid, the theoretical SNR is\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nIf the signal uses only a fraction \\(\\rho\\) (\\(0&lt;\\rho\\le 1\\)) of full scale (FS) in RMS, then\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]\nEffective Number of Bits (ENOB) from a measured in-band SNR:\n\\[\n\\mathrm{ENOB} \\approx \\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]\n\n\n\nFront-end analog gain \\(G\\) maps a biomedical signal \\(x\\_{\\text{in}}\\) to the ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\). The input-referred LSB is\n\\[\n\\Delta_{\\text{in}}=\\frac{\\Delta}{G}.\n\\]\nChoose \\(G\\) to:\n\navoid overload for rare peaks, and 2) maximize FS utilization to improve SNR. Poor gain wastes bits (small \\(\\rho\\)) or clips clinically relevant transients (e.g., ECG pacer spikes).\n\n\n\n\nSuppose a resting ECG has peak amplitudes around \\(\\pm 5,\\text{mV}\\) at the electrodes. We design the analog front end so that \\(\\pm 5,\\text{mV}\\) maps to \\(\\pm 1,\\text{V}\\) at the ADC, i.e., \\(G=200\\). Use a \\(b=12\\)-bit ADC over \\(\\left[-1,\\text{V},,1,\\text{V}\\right]\\):\n\nADC LSB: \\(\\Delta = \\dfrac{2,\\text{V}}{2^{12}} \\approx 0.488,\\text{mV}\\) (at the ADC input).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\dfrac{0.488,\\text{mV}}{200}\\approx 2.44,\\mu\\text{V}\\).\nInput-referred quantization-noise RMS: \\(\\dfrac{\\Delta\\_{\\text{in}}}{\\sqrt{12}}\\approx 0.704,\\mu\\text{V}\\_{\\mathrm{RMS}}\\).\n\nIf the ECG uses \\(\\rho=0.5\\) of full scale (typical margin against clipping), the quantization-limited SNR is approximately\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\times 12 + 1.76 + 20\\log_{10}(0.5) \\approx 74.0 - 6.0 \\approx 68\\,\\text{dB}.\n\\]\nThis is usually below amplifier and electrode noise constraints, so 12 bits are adequate for diagnostic ECG in this setting. If the chain is quieter (e.g., invasive potentials), higher bit depth or larger \\(G\\) may be justified.\n\n\n\nWhen the amplitude distribution is strongly non-uniform, companding transforms \\(x\\) before uniform quantization to allocate more levels where the signal spends more time. Classical laws:\n\n\\(\\mu\\)-law: \\(y=\\mathrm{sgn}(x),\\dfrac{\\ln(1+\\mu |x|/X\\_{\\max})}{\\ln(1+\\mu)}\\), \\(\\mu\\approx 255\\) (telephony).\n\\(A\\)-law: piecewise logarithmic with parameter \\(A\\) (Europe).\n\nCompanding is common in speech/audio telemetry; in biomedicine it is less standard for primary acquisition, but can help in low-bit-rate wireless monitoring where dynamic range is wide (e.g., PPG with motion).\n\n\n\nAdding small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization decorrelates the error from the signal, eliminating patterning and bias at low amplitudes. This linearizes averages at the cost of a small SNR penalty. Dither can be beneficial for low-level EEG/EMG features and precise baseline estimates.\n\n\n\n\nChoose \\(b\\) so that \\(\\mathrm{SNR}\\_{\\mathrm{dB}}\\) exceeds clinical SNR needs by margin (10–20 dB).\nSet \\(G\\) so typical peaks use \\(50\\)–\\(80%\\) FS; verify pacer spikes and motion spikes do not clip.\nBudget noise: electrode + amplifier + ADC quantization; the largest non-white source often dominates.\nValidate with a calibrated source (sinusoidal and biomedical-like waveforms) and measure in-band SNR/ENOB.\n\n\n\n\n\n\n# Synthetic ECG, uniform quantization at multiple bit depths, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# --- 1) Build a simple ECG template (P-QRS-T) using Gaussians ---\nfs = 360.0                      # sampling rate [Hz]\nT = 5.0                         # duration [s]\nt = np.arange(0, T, 1/fs)\n\nhr = 60.0                       # heart rate [bpm]\nRR = 60.0/hr                    # seconds per beat\n\n# Gaussian helper\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\n# One-beat template (times in seconds relative to beat onset)\ndef ecg_template(t):\n    # amplitudes in mV, widths in s (very simplified)\n    P  = g(t, 0.20, 0.045,  0.10)\n    Q  = g(t, 0.36, 0.010, -0.25)\n    R  = g(t, 0.40, 0.012,  1.00)\n    S  = g(t, 0.44, 0.016, -0.35)\n    T  = g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + T\n\n# Tile the template every RR seconds\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    tau = t - k*RR\n    ecg_mV += ecg_template(tau)\n\n# Optional baseline wander + small EMG-like noise (for realism)\nwander = 0.05*np.sin(2*np.pi*0.3*t)        # 0.05 mV @ 0.3 Hz\nnoise  = 0.02*np.random.randn(len(t))      # 0.02 mV RMS\necg_mV = ecg_mV + wander + noise\n\n# --- 2) Analog front-end gain and ADC setup ---\nG = 200.0                     # gain: mV (input) -&gt; V (ADC input)\nVfs = 1.0                     # full-scale = +/-1 V\nVmin, Vmax = -Vfs, Vfs\n\nx_adc = (ecg_mV/1000.0)*G     # convert mV to V and apply gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    # Saturate to avoid numeric overflow\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)  # ensure within codebook range\n    return y, Delta\n\ndef snr_db(x, y):\n    # SNR over the un-clipped region; compute RMS of signal and error\n    e = x - y\n    # Remove DC for SNR assessment\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\n# --- 3) Quantize at different bit depths ---\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\n# Print a small summary (ADC-domain). Input-referred values via division by G.\nprint(\"Summary (ADC domain):\")\nfor b in bits_list:\n    Delta = results[b][\"Delta\"]\n    snr = results[b][\"snr_db\"]\n    print(f\"{b:2d}-bit -&gt; LSB Δ = {Delta*1e3:.3f} mV, Theoretical/Measured SNR ≈ {snr:5.1f} dB\")\n\n# Input-referred LSB and noise RMS for the 12-bit case\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Δ_in = {Delta_in*1e6:.3f} µV, σ_q ≈ {sigma_q_in*1e6:.3f} µV RMS\")\n\n# --- 4) Plot: original vs quantized (choose 10-bit for visibility) ---\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)  # show about one beat\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- 5) Plot: quantization error histogram (8-bit to exaggerate steps) ---\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()\n\nSummary (ADC domain):\n 8-bit -&gt; LSB Δ = 7.812 mV, Theoretical/Measured SNR ≈  24.1 dB\n10-bit -&gt; LSB Δ = 1.953 mV, Theoretical/Measured SNR ≈  36.0 dB\n12-bit -&gt; LSB Δ = 0.488 mV, Theoretical/Measured SNR ≈  48.1 dB\n\nInput-referred (12-bit): Δ_in = 2.441 µV, σ_q ≈ 0.705 µV RMS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nThe summary reports the measured SNR from the synthetic ECG after quantization for 8/10/12 bits; values will be below the \\(6.02b+1.76\\) bound because the signal does not use full scale constantly and includes non-sinusoidal content.\nThe input-referred \\(\\Delta\\_{\\text{in}}\\) and \\(\\sigma\\_q\\) for 12 bits match the analytical estimates in Section 5 (a few \\(\\mu\\text{V}\\)), consistent with common ECG design targets.\nThe error histogram approaches a uniform distribution as assumptions hold; deviations indicate correlation (e.g., at low amplitudes or with deterministic waveforms)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#purpose-and-big-picture",
    "href": "recursos/documentos/SYSB/cuantizacion.html#purpose-and-big-picture",
    "title": "Quantization",
    "section": "",
    "text": "Quantization maps a continuous-amplitude signal to a finite set of discrete levels so that it can be represented by digits. After anti-alias filtering and sampling, an analog-to-digital converter (ADC) applies quantization. This process introduces an error that acts like noise under standard conditions; understanding its magnitude is essential to sizing bit depth, gain, and dynamic range in biomedical systems (ECG, EEG, EMG, PPG)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#uniform-quantizer-model",
    "href": "recursos/documentos/SYSB/cuantizacion.html#uniform-quantizer-model",
    "title": "Quantization",
    "section": "",
    "text": "Let the ADC input range be \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\) with \\(b\\) bits and \\(L=2^b\\) levels. The step size (LSB) is\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nTwo common realizations:\n\nMid-tread (rounding): \\(Q(x)=\\Delta,\\mathrm{round}\\left(\\frac{x}{\\Delta}\\right)\\) for \\(x\\in(V\\_{\\min},V\\_{\\max})\\).\nMid-rise (truncate with half-step offset): \\(Q(x)=\\Delta!\\left(\\left\\lfloor\\frac{x}{\\Delta}\\right\\rfloor+\\tfrac12\\right)\\).\n\nOutside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\), overload/clipping occurs: \\(\\tilde{x}=Q(x)=V\\_{\\max}\\) if \\(x&gt;V\\_{\\max}\\) and \\(\\tilde{x}=V\\_{\\min}\\) if \\(x\\&lt;V\\_{\\min}\\).\nCodebook and decision thresholds: Decision thresholds lie at \\(k\\Delta\\) and reconstruction levels at either \\(k\\Delta\\) (mid-tread) or \\((k+\\tfrac12)\\Delta\\) (mid-rise)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#quantization-error-and-its-statistics",
    "href": "recursos/documentos/SYSB/cuantizacion.html#quantization-error-and-its-statistics",
    "title": "Quantization",
    "section": "",
    "text": "Define the quantization error \\(e=x-Q(x)\\). Under the high-resolution assumptions (signal varies slowly relative to \\(\\Delta\\), input well distributed within the range, and no overload), the error is modeled as white, signal-independent, and uniformly distributed on \\(\\left[-\\frac{\\Delta}{2},\\frac{\\Delta}{2}\\right]\\):\n\nMean: \\(\\mathbb{E}\\left[e\\right]=0\\).\nVariance (power): \\(\\sigma\\_e^2=\\dfrac{\\Delta^2}{12}\\).\nRMS: \\(\\sigma\\_e=\\dfrac{\\Delta}{\\sqrt{12}}\\).\n\nFor a full-scale sinusoid, the theoretical SNR is\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nIf the signal uses only a fraction \\(\\rho\\) (\\(0&lt;\\rho\\le 1\\)) of full scale (FS) in RMS, then\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]\nEffective Number of Bits (ENOB) from a measured in-band SNR:\n\\[\n\\mathrm{ENOB} \\approx \\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]"
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#input-range-gain-and-clipping",
    "href": "recursos/documentos/SYSB/cuantizacion.html#input-range-gain-and-clipping",
    "title": "Quantization",
    "section": "",
    "text": "Front-end analog gain \\(G\\) maps a biomedical signal \\(x\\_{\\text{in}}\\) to the ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\). The input-referred LSB is\n\\[\n\\Delta_{\\text{in}}=\\frac{\\Delta}{G}.\n\\]\nChoose \\(G\\) to:\n\navoid overload for rare peaks, and 2) maximize FS utilization to improve SNR. Poor gain wastes bits (small \\(\\rho\\)) or clips clinically relevant transients (e.g., ECG pacer spikes)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#biomedical-example-ecg-acquisition",
    "href": "recursos/documentos/SYSB/cuantizacion.html#biomedical-example-ecg-acquisition",
    "title": "Quantization",
    "section": "",
    "text": "Suppose a resting ECG has peak amplitudes around \\(\\pm 5,\\text{mV}\\) at the electrodes. We design the analog front end so that \\(\\pm 5,\\text{mV}\\) maps to \\(\\pm 1,\\text{V}\\) at the ADC, i.e., \\(G=200\\). Use a \\(b=12\\)-bit ADC over \\(\\left[-1,\\text{V},,1,\\text{V}\\right]\\):\n\nADC LSB: \\(\\Delta = \\dfrac{2,\\text{V}}{2^{12}} \\approx 0.488,\\text{mV}\\) (at the ADC input).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\dfrac{0.488,\\text{mV}}{200}\\approx 2.44,\\mu\\text{V}\\).\nInput-referred quantization-noise RMS: \\(\\dfrac{\\Delta\\_{\\text{in}}}{\\sqrt{12}}\\approx 0.704,\\mu\\text{V}\\_{\\mathrm{RMS}}\\).\n\nIf the ECG uses \\(\\rho=0.5\\) of full scale (typical margin against clipping), the quantization-limited SNR is approximately\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\times 12 + 1.76 + 20\\log_{10}(0.5) \\approx 74.0 - 6.0 \\approx 68\\,\\text{dB}.\n\\]\nThis is usually below amplifier and electrode noise constraints, so 12 bits are adequate for diagnostic ECG in this setting. If the chain is quieter (e.g., invasive potentials), higher bit depth or larger \\(G\\) may be justified."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#non-uniform-quantization-and-companding-brief",
    "href": "recursos/documentos/SYSB/cuantizacion.html#non-uniform-quantization-and-companding-brief",
    "title": "Quantization",
    "section": "",
    "text": "When the amplitude distribution is strongly non-uniform, companding transforms \\(x\\) before uniform quantization to allocate more levels where the signal spends more time. Classical laws:\n\n\\(\\mu\\)-law: \\(y=\\mathrm{sgn}(x),\\dfrac{\\ln(1+\\mu |x|/X\\_{\\max})}{\\ln(1+\\mu)}\\), \\(\\mu\\approx 255\\) (telephony).\n\\(A\\)-law: piecewise logarithmic with parameter \\(A\\) (Europe).\n\nCompanding is common in speech/audio telemetry; in biomedicine it is less standard for primary acquisition, but can help in low-bit-rate wireless monitoring where dynamic range is wide (e.g., PPG with motion)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#dither-optional-but-practical",
    "href": "recursos/documentos/SYSB/cuantizacion.html#dither-optional-but-practical",
    "title": "Quantization",
    "section": "",
    "text": "Adding small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization decorrelates the error from the signal, eliminating patterning and bias at low amplitudes. This linearizes averages at the cost of a small SNR penalty. Dither can be beneficial for low-level EEG/EMG features and precise baseline estimates."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#practical-checklist",
    "href": "recursos/documentos/SYSB/cuantizacion.html#practical-checklist",
    "title": "Quantization",
    "section": "",
    "text": "Choose \\(b\\) so that \\(\\mathrm{SNR}\\_{\\mathrm{dB}}\\) exceeds clinical SNR needs by margin (10–20 dB).\nSet \\(G\\) so typical peaks use \\(50\\)–\\(80%\\) FS; verify pacer spikes and motion spikes do not clip.\nBudget noise: electrode + amplifier + ADC quantization; the largest non-white source often dominates.\nValidate with a calibrated source (sinusoidal and biomedical-like waveforms) and measure in-band SNR/ENOB."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#python-demonstration-ecg-quantization-snr-and-error-statistics",
    "href": "recursos/documentos/SYSB/cuantizacion.html#python-demonstration-ecg-quantization-snr-and-error-statistics",
    "title": "Quantization",
    "section": "",
    "text": "# Synthetic ECG, uniform quantization at multiple bit depths, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# --- 1) Build a simple ECG template (P-QRS-T) using Gaussians ---\nfs = 360.0                      # sampling rate [Hz]\nT = 5.0                         # duration [s]\nt = np.arange(0, T, 1/fs)\n\nhr = 60.0                       # heart rate [bpm]\nRR = 60.0/hr                    # seconds per beat\n\n# Gaussian helper\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\n# One-beat template (times in seconds relative to beat onset)\ndef ecg_template(t):\n    # amplitudes in mV, widths in s (very simplified)\n    P  = g(t, 0.20, 0.045,  0.10)\n    Q  = g(t, 0.36, 0.010, -0.25)\n    R  = g(t, 0.40, 0.012,  1.00)\n    S  = g(t, 0.44, 0.016, -0.35)\n    T  = g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + T\n\n# Tile the template every RR seconds\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    tau = t - k*RR\n    ecg_mV += ecg_template(tau)\n\n# Optional baseline wander + small EMG-like noise (for realism)\nwander = 0.05*np.sin(2*np.pi*0.3*t)        # 0.05 mV @ 0.3 Hz\nnoise  = 0.02*np.random.randn(len(t))      # 0.02 mV RMS\necg_mV = ecg_mV + wander + noise\n\n# --- 2) Analog front-end gain and ADC setup ---\nG = 200.0                     # gain: mV (input) -&gt; V (ADC input)\nVfs = 1.0                     # full-scale = +/-1 V\nVmin, Vmax = -Vfs, Vfs\n\nx_adc = (ecg_mV/1000.0)*G     # convert mV to V and apply gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    # Saturate to avoid numeric overflow\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)  # ensure within codebook range\n    return y, Delta\n\ndef snr_db(x, y):\n    # SNR over the un-clipped region; compute RMS of signal and error\n    e = x - y\n    # Remove DC for SNR assessment\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\n# --- 3) Quantize at different bit depths ---\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\n# Print a small summary (ADC-domain). Input-referred values via division by G.\nprint(\"Summary (ADC domain):\")\nfor b in bits_list:\n    Delta = results[b][\"Delta\"]\n    snr = results[b][\"snr_db\"]\n    print(f\"{b:2d}-bit -&gt; LSB Δ = {Delta*1e3:.3f} mV, Theoretical/Measured SNR ≈ {snr:5.1f} dB\")\n\n# Input-referred LSB and noise RMS for the 12-bit case\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Δ_in = {Delta_in*1e6:.3f} µV, σ_q ≈ {sigma_q_in*1e6:.3f} µV RMS\")\n\n# --- 4) Plot: original vs quantized (choose 10-bit for visibility) ---\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)  # show about one beat\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- 5) Plot: quantization error histogram (8-bit to exaggerate steps) ---\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()\n\nSummary (ADC domain):\n 8-bit -&gt; LSB Δ = 7.812 mV, Theoretical/Measured SNR ≈  24.1 dB\n10-bit -&gt; LSB Δ = 1.953 mV, Theoretical/Measured SNR ≈  36.0 dB\n12-bit -&gt; LSB Δ = 0.488 mV, Theoretical/Measured SNR ≈  48.1 dB\n\nInput-referred (12-bit): Δ_in = 2.441 µV, σ_q ≈ 0.705 µV RMS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nThe summary reports the measured SNR from the synthetic ECG after quantization for 8/10/12 bits; values will be below the \\(6.02b+1.76\\) bound because the signal does not use full scale constantly and includes non-sinusoidal content.\nThe input-referred \\(\\Delta\\_{\\text{in}}\\) and \\(\\sigma\\_q\\) for 12 bits match the analytical estimates in Section 5 (a few \\(\\mu\\text{V}\\)), consistent with common ECG design targets.\nThe error histogram approaches a uniform distribution as assumptions hold; deviations indicate correlation (e.g., at low amplitudes or with deterministic waveforms)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "",
    "text": "Nota: Documento en formato Quarto listo para renderizar a HTML (quarto render). Incluye respuestas correctas y una explicación breve por ítem."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-1",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "1 Pregunta 1",
    "text": "1 Pregunta 1\nEnunciado resumido: Sea \\(y(t)=x(3-1{,}5\\,t)\\). Sobre la relación temporal entre \\(x(t)\\) y \\(y(t)\\), marca las correctas.\nRespuestas correctas: A, B, D, E.\nExplicación\nEscribimos \\(y(t)=x(3-1{,}5\\,t)=x\\big(-1{,}5\\,(t-2)\\big)\\).\n- A: Verdadera, es la misma forma \\(x\\big(-1{,}5\\,(t-2)\\big)\\).\n- B: Verdadera, el factor negativo implica inversión temporal (time-reversal).\n- C: Falsa, no es solo desplazamiento; hay inversión y escala temporal.\n- D: Verdadera, al comprimir en el tiempo por \\(|a|=1{,}5\\) la frecuencia aparente se multiplica por 1,5.\n- E: Verdadera, \\(|a|=1{,}5&gt;1\\) implica compresión temporal por 1,5 (la señal “va más rápido”)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-2",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "2 Pregunta 2",
    "text": "2 Pregunta 2\nEnunciado: \\(x(t)=\\cos\\big(2\\pi\\frac{12}{5}t\\big)+\\sin\\big(2\\pi\\frac{7}{3}t\\big)\\). Periodicidad en TC.\nRespuestas correctas: B, D, E.\nExplicación\nLas frecuencias son \\(f_1=12/5\\) y \\(f_2=7/3\\). La razón \\(f_1/f_2=(12/5)/(7/3)=36/35\\) es racional, por tanto la suma es periódica en TC.\nLos periodos individuales: \\(T_1=5/12\\) y \\(T_2=3/7\\). El periodo fundamental conjunto cumple \\(36T_1=35T_2=15\\text{s}\\).\n- A: Falsa, sí comparten múltiplos enteros.\n- B: Verdadera, al cambiar \\(12/5\\) por \\(12/5+1/\\pi\\) la razón de frecuencias típicamente deja de ser racional \\(\\Rightarrow\\) no periódica.\n- C: Falsa, sumar un DC no rompe la periodicidad.\n- D: Verdadera, \\(T_0=15\\text{s}\\) es un periodo fundamental posible.\n- E: Verdadera, todo múltiplo entero de \\(15\\text{s}\\) también es periodo."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-3",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "3 Pregunta 3",
    "text": "3 Pregunta 3\nEnunciado: \\(x[n]=\\sin\\big(\\frac{5\\pi}{14}n\\big)+\\cos\\big(\\frac{3\\pi}{7}n+\\frac{\\pi}{6}\\big)\\). Periodicidad en TD.\nRespuestas correctas: A, D, E.\nExplicación\nPara \\(\\sin(\\Omega n)\\) o \\(\\cos(\\Omega n+\\phi)\\) hay periodicidad si \\(\\Omega/2\\pi\\) es racional.\n- \\(\\Omega_1=5\\pi/14=(5/28)\\,2\\pi\\Rightarrow N_1=28\\).\n- \\(\\Omega_2=3\\pi/7=(3/14)\\,2\\pi\\Rightarrow N_2=14\\).\nEl periodo conjunto es \\(\\mathrm{{lcm}}(28,14)=28\\). La fase no altera la periodicidad.\n- A: Verdadera, \\(N_0=28\\).\n- B: Falsa, cambiar \\(\\pi/6\\) no rompe periodicidad.\n- C: Falsa, \\(\\sin(5\\pi/14\\,n)\\) sigue siendo periódica por sí sola.\n- D: Verdadera, al sumar \\(\\sin(\\pi/3\\,n)\\) (periodo 6), el conjunto sigue siendo periódico con \\(N_0=\\mathrm{{lcm}}(28,6)=84\\).\n- E: Verdadera, el término coseno tiene periodo 14."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-4",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "4 Pregunta 4",
    "text": "4 Pregunta 4\nEnunciado: Sea \\(x(t)=x_p(t)+x_i(t)\\) con \\(x_p\\) par y \\(x_i\\) impar. Defínase\n\\[ y(t)=x_p(t+1)\\,x_i(t-1)+\\frac{d}{dt}x_i(t). \\]\nRespuestas correctas: B, C, D, E.\nExplicación\n- Un desplazamiento rompe la paridad: \\(x_p(t+1)\\) y \\(x_i(t-1)\\) son, en general, ni pares ni impares (\\(\\Rightarrow\\) B verdadera).\n- El producto \\(x_p(t+1)\\,x_i(t-1)\\) no resulta ni par ni impar en general (no es impar) (\\(\\Rightarrow\\) A falsa).\n- Si se cambiara el segundo término por $ frac{d}{dt}x_p(t)$ (derivada de función par), ésta es impar; sumada con un término “ni par ni impar” el total puede seguir siendo “ni par ni impar” (\\(\\Rightarrow\\) C verdadera).\n- La derivada de una función impar es par (\\(\\Rightarrow\\) E verdadera).\n- Suma de un término “ni par ni impar” con un término par da, en general, una función ni par ni impar (\\(\\Rightarrow\\) D verdadera)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-5",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-5",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "5 Pregunta 5",
    "text": "5 Pregunta 5\nEnunciado: Tres pulsos con solapamiento\n- Pulso 1: amplitud \\(2\\), de \\(t=0{,}8\\) a \\(1{,}4\\).\n- Pulso 2: amplitud \\(1{,}5\\), de \\(t=1{,}2\\) a \\(1{,}8\\).\n- Pulso 3: amplitud \\(-1\\), de \\(t=1{,}6\\) a \\(2{,}0\\).\nSea \\(v(t)\\) la suma. Representación con \\(u(t)\\) y propiedades.\nRespuestas correctas: B, C, D, E.\nExplicación\n- Alturas por intervalos:\n- \\(0{,}8-1{,}2\\): \\(2\\)\n- \\(1{,}2-1{,}4\\): \\(2+1{,}5=3{,}5\\) (máximo)\n- \\(1{,}4-1{,}6\\): \\(1{,}5\\)\n- \\(1{,}6-1{,}8\\): \\(1{,}5-1=0{,}5\\)\n- \\(1{,}8-2{,}0\\): \\(-1\\)\nPor tanto A es falsa (el máximo \\(3{,}5\\) ocurre en \\(1{,}2-1{,}4\\)).\n- Forma por escalones:\n\\[ v(t)=2[u(t-0{,}8)-u(t-1{,}4)]+1{,}5[u(t-1{,}2)-u(t-1{,}8)]- [u(t-1{,}6)-u(t-2{,}0)], \\]\nequivalente a la suma de saltos en \\(t_k\\in\\{0{,}8,1{,}2,1{,}4,1{,}6,1{,}8,2{,}0\\}\\) con amplitudes \\(\\{+2,+1{,}5,-2,-1,-1{,}5,+1\\}\\).\nAsí, B, C y D son verdaderas.\n- Área total (linealidad del integral):\n\\[ \\int v(t)\\,dt=2\\cdot0{,}6+1{,}5\\cdot0{,}6-1\\cdot0{,}4=1{,}7, \\]\nindependiente del solapamiento (\\(\\Rightarrow\\) E verdadera)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#resumen-de-respuestas-clave",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#resumen-de-respuestas-clave",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "6 Resumen de respuestas (clave)",
    "text": "6 Resumen de respuestas (clave)\n\nP1: A, B, D, E\n\nP2: B, D, E\n\nP3: A, D, E\n\nP4: B, C, D, E\n\nP5: B, C, D, E"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html",
    "title": "Ejemplo de CRISP-DM",
    "section": "",
    "text": "# %% ------------------ Imports y RNG ------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n\nrng = np.random.default_rng(42)\n\n# %% ------------------ Simulador cohorte rehab ictus ------------------\ndef simulate_stroke_rehab_regression(n=300):\n    age = rng.normal(62, 12, n).clip(18, 90)\n    sex = rng.choice([\"F\",\"M\"], size=n, p=[0.52, 0.48])\n    nihss = rng.integers(0, 16, n)                             # muestra ambulatoria\n    days_since_stroke = rng.integers(14, 180, n)               # 2 semanas a 6 meses\n    comorb = rng.poisson(1.2, n).clip(0, 6)\n\n    sixmwt_base = rng.normal(250, 95, n).clip(30, 600)         # m\n    tug_base = rng.normal(25, 10, n).clip(8, 120)              # s\n\n    therapy_min = rng.normal(160, 40, n).clip(40, 360)         # min/semana\n    cadence = rng.normal(90, 15, n).clip(40, 140)              # pasos/min\n    step_var = np.abs(rng.normal(0.12, 0.05, n))               # CV (adimensional)\n\n    # Mecanismo generador para Δ6MWT (señal + ruido)\n    signal = (\n        0.30*(therapy_min-160) +\n        1.2*(cadence-90) -\n        120*(step_var-0.12) -\n        4.0*nihss -\n        0.08*(days_since_stroke-60) -\n        2.0*(tug_base-25) -\n        8.0*comorb +\n        0.12*(sixmwt_base-250)\n    )\n    noise = rng.normal(0, 40, n)\n    delta_6mwt = (120 + signal + noise).clip(-50, 300)         # m, plausibilidad\n\n    df = pd.DataFrame({\n        \"age\": age.round(1),\n        \"sex\": sex,\n        \"nihss\": nihss.astype(int),\n        \"days_since_stroke\": days_since_stroke.astype(int),\n        \"comorb\": comorb.astype(int),\n        \"sixmwt_base\": sixmwt_base.round(1),\n        \"tug_base\": tug_base.round(1),\n        \"therapy_min\": therapy_min.round(1),\n        \"cadence\": cadence.round(1),\n        \"step_var\": step_var.round(3),\n        \"delta_6mwt\": delta_6mwt.round(1)\n    })\n\n    # Problemas de calidad intencionales para practicar:\n    # 1) Faltantes en ~5% de columnas clave\n    for col in [\"sixmwt_base\", \"tug_base\", \"therapy_min\"]:\n        idx = rng.choice(df.index, size=int(0.05*n), replace=False)\n        df.loc[idx, col] = np.nan\n\n    # 2) Outliers puntuales en dosis de terapia\n    idx_hi = rng.choice(df.index, size=max(1, n//100), replace=False)\n    df.loc[idx_hi, \"therapy_min\"] = df[\"therapy_min\"].max() * 3\n\n    return df\n\ndf = simulate_stroke_rehab_regression(n=1000)\nprint(df.head())\nprint(\"\\nShape:\", df.shape)\n\n    age sex  nihss  days_since_stroke  comorb  sixmwt_base  tug_base  \\\n0  65.7   M      1                164       2        264.1      21.0   \n1  49.5   F     12                111       0        354.0      13.0   \n2  71.0   F     13                 42       1        180.6      44.9   \n3  73.3   F     15                143       3        253.0      24.0   \n4  38.6   F      5                 37       2          NaN      31.4   \n\n   therapy_min  cadence  step_var  delta_6mwt  \n0        230.4    103.2     0.104       132.7  \n1        180.9     93.2     0.073        72.9  \n2        238.6     98.3     0.143        43.7  \n3        196.0     85.3     0.143        74.2  \n4         87.8     91.7     0.097        56.7  \n\nShape: (1000, 11)"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#simluación-de-datos",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#simluación-de-datos",
    "title": "Ejemplo de CRISP-DM",
    "section": "",
    "text": "# %% ------------------ Imports y RNG ------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n\nrng = np.random.default_rng(42)\n\n# %% ------------------ Simulador cohorte rehab ictus ------------------\ndef simulate_stroke_rehab_regression(n=300):\n    age = rng.normal(62, 12, n).clip(18, 90)\n    sex = rng.choice([\"F\",\"M\"], size=n, p=[0.52, 0.48])\n    nihss = rng.integers(0, 16, n)                             # muestra ambulatoria\n    days_since_stroke = rng.integers(14, 180, n)               # 2 semanas a 6 meses\n    comorb = rng.poisson(1.2, n).clip(0, 6)\n\n    sixmwt_base = rng.normal(250, 95, n).clip(30, 600)         # m\n    tug_base = rng.normal(25, 10, n).clip(8, 120)              # s\n\n    therapy_min = rng.normal(160, 40, n).clip(40, 360)         # min/semana\n    cadence = rng.normal(90, 15, n).clip(40, 140)              # pasos/min\n    step_var = np.abs(rng.normal(0.12, 0.05, n))               # CV (adimensional)\n\n    # Mecanismo generador para Δ6MWT (señal + ruido)\n    signal = (\n        0.30*(therapy_min-160) +\n        1.2*(cadence-90) -\n        120*(step_var-0.12) -\n        4.0*nihss -\n        0.08*(days_since_stroke-60) -\n        2.0*(tug_base-25) -\n        8.0*comorb +\n        0.12*(sixmwt_base-250)\n    )\n    noise = rng.normal(0, 40, n)\n    delta_6mwt = (120 + signal + noise).clip(-50, 300)         # m, plausibilidad\n\n    df = pd.DataFrame({\n        \"age\": age.round(1),\n        \"sex\": sex,\n        \"nihss\": nihss.astype(int),\n        \"days_since_stroke\": days_since_stroke.astype(int),\n        \"comorb\": comorb.astype(int),\n        \"sixmwt_base\": sixmwt_base.round(1),\n        \"tug_base\": tug_base.round(1),\n        \"therapy_min\": therapy_min.round(1),\n        \"cadence\": cadence.round(1),\n        \"step_var\": step_var.round(3),\n        \"delta_6mwt\": delta_6mwt.round(1)\n    })\n\n    # Problemas de calidad intencionales para practicar:\n    # 1) Faltantes en ~5% de columnas clave\n    for col in [\"sixmwt_base\", \"tug_base\", \"therapy_min\"]:\n        idx = rng.choice(df.index, size=int(0.05*n), replace=False)\n        df.loc[idx, col] = np.nan\n\n    # 2) Outliers puntuales en dosis de terapia\n    idx_hi = rng.choice(df.index, size=max(1, n//100), replace=False)\n    df.loc[idx_hi, \"therapy_min\"] = df[\"therapy_min\"].max() * 3\n\n    return df\n\ndf = simulate_stroke_rehab_regression(n=1000)\nprint(df.head())\nprint(\"\\nShape:\", df.shape)\n\n    age sex  nihss  days_since_stroke  comorb  sixmwt_base  tug_base  \\\n0  65.7   M      1                164       2        264.1      21.0   \n1  49.5   F     12                111       0        354.0      13.0   \n2  71.0   F     13                 42       1        180.6      44.9   \n3  73.3   F     15                143       3        253.0      24.0   \n4  38.6   F      5                 37       2          NaN      31.4   \n\n   therapy_min  cadence  step_var  delta_6mwt  \n0        230.4    103.2     0.104       132.7  \n1        180.9     93.2     0.073        72.9  \n2        238.6     98.3     0.143        43.7  \n3        196.0     85.3     0.143        74.2  \n4         87.8     91.7     0.097        56.7  \n\nShape: (1000, 11)"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-understanding",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-understanding",
    "title": "Ejemplo de CRISP-DM",
    "section": "Data Understanding",
    "text": "Data Understanding\n\n# %% ------------------ Perfil exploratorio básico ------------------\ndef describe_cardinality(s: pd.Series):\n    return pd.Series({\n        \"dtype\": s.dtype,\n        \"n_unique\": s.nunique(dropna=True),\n        \"pct_unique\": 100*s.nunique(dropna=True)/len(s),\n        \"n_missing\": s.isna().sum(),\n        \"pct_missing\": 100*s.isna().mean()\n    })\n\nprofile = df.apply(describe_cardinality).T\nsummary = df.describe(include=\"all\").T\n\nprint(\"\\n=== Cardinalidad & Faltantes ===\")\nprint(profile)\n\nprint(\"\\n=== Resumen numérico ===\")\nprint(summary)\n\n# %% ------------------ Detección simple de outliers (IQR) ------------------\ndef iqr_outliers_report(df_numeric: pd.DataFrame, k=1.5):\n    rows = []\n    for col in df_numeric.columns:\n        x = df_numeric[col].dropna().values\n        q1, q3 = np.percentile(x, [25, 75])\n        iqr = q3 - q1\n        lo, hi = q1 - k*iqr, q3 + k*iqr\n        n_lo = (df_numeric[col] &lt; lo).sum()\n        n_hi = (df_numeric[col] &gt; hi).sum()\n        rows.append({\"variable\": col, \"q1\": q1, \"q3\": q3, \"iqr\": iqr,\n                     \"low_thresh\": lo, \"high_thresh\": hi,\n                     \"n_low\": int(n_lo), \"n_high\": int(n_hi)})\n    return pd.DataFrame(rows).sort_values(\"n_high\", ascending=False)\n\nnum_cols = df.select_dtypes(include=[np.number]).columns.tolist()\noutliers_table = iqr_outliers_report(df[num_cols])\nprint(\"\\n=== Outliers (IQR 1.5) ===\")\nprint(outliers_table)\n\n# %% ------------------ Visual quick checks (opcional) ------------------\nplt.figure()\ndf[\"delta_6mwt\"].hist(bins=30)\nplt.title(\"Distribución Δ6MWT (m)\")\nplt.xlabel(\"m\"); plt.ylabel(\"frecuencia\")\nplt.show()\n\nplt.figure()\ndf.boxplot(column=[\"therapy_min\"])\nplt.title(\"Boxplot therapy_min (detección outliers)\")\nplt.show()\n\n\n=== Cardinalidad & Faltantes ===\n                     dtype n_unique pct_unique n_missing pct_missing\nage                float64      411       41.1         0         0.0\nsex                 object        2        0.2         0         0.0\nnihss                int64       16        1.6         0         0.0\ndays_since_stroke    int64      166       16.6         0         0.0\ncomorb               int64        7        0.7         0         0.0\nsixmwt_base        float64      821       82.1        50         5.0\ntug_base           float64      336       33.6        50         5.0\ntherapy_min        float64      677       67.7        50         5.0\ncadence            float64      495       49.5         0         0.0\nstep_var           float64      222       22.2         0         0.0\ndelta_6mwt         float64      771       77.1         0         0.0\n\n=== Resumen numérico ===\n                    count unique  top freq        mean        std   min  \\\nage                1000.0    NaN  NaN  NaN     61.6208  11.779899  18.2   \nsex                  1000      2    F  527         NaN        NaN   NaN   \nnihss              1000.0    NaN  NaN  NaN       7.453   4.708924   0.0   \ndays_since_stroke  1000.0    NaN  NaN  NaN      95.709  46.490727  14.0   \ncomorb             1000.0    NaN  NaN  NaN       1.139   1.064336   0.0   \nsixmwt_base         950.0    NaN  NaN  NaN  255.519474  94.649212  30.0   \ntug_base            950.0    NaN  NaN  NaN      25.284   9.764767   8.0   \ntherapy_min         950.0    NaN  NaN  NaN  166.018737  83.033507  40.0   \ncadence            1000.0    NaN  NaN  NaN     90.4363  15.165442  40.0   \nstep_var           1000.0    NaN  NaN  NaN    0.117729   0.050345   0.0   \ndelta_6mwt         1000.0    NaN  NaN  NaN     78.8412  56.194987 -50.0   \n\n                       25%     50%      75%    max  \nage                   53.6    62.1     69.1   90.0  \nsex                    NaN     NaN      NaN    NaN  \nnihss                  4.0     7.0     12.0   15.0  \ndays_since_stroke     55.0    96.0    136.0  179.0  \ncomorb                 0.0     1.0      2.0    6.0  \nsixmwt_base          190.8  256.95   317.35  557.9  \ntug_base              18.5    24.4   32.275   56.0  \ntherapy_min          133.9  158.35  185.275  875.4  \ncadence               80.5    90.5    100.5  140.0  \nstep_var           0.08375   0.117    0.152  0.282  \ndelta_6mwt            41.2    79.8  116.075  262.5  \n\n=== Outliers (IQR 1.5) ===\n            variable         q1       q3        iqr  low_thresh  high_thresh  \\\n6        therapy_min  133.90000  185.275   51.37500   56.837500   262.337500   \n8           step_var    0.08375    0.152    0.06825   -0.018625     0.254375   \n9         delta_6mwt   41.20000  116.075   74.87500  -71.112500   228.387500   \n7            cadence   80.50000  100.500   20.00000   50.500000   130.500000   \n4        sixmwt_base  190.80000  317.350  126.55000    0.975000   507.175000   \n3             comorb    0.00000    2.000    2.00000   -3.000000     5.000000   \n5           tug_base   18.50000   32.275   13.77500   -2.162500    52.937500   \n0                age   53.60000   69.100   15.50000   30.350000    92.350000   \n1              nihss    4.00000   12.000    8.00000   -8.000000    24.000000   \n2  days_since_stroke   55.00000  136.000   81.00000  -66.500000   257.500000   \n\n   n_low  n_high  \n6      7      15  \n8      0       6  \n9      0       4  \n7      4       4  \n4      0       4  \n3      0       2  \n5      0       1  \n0      4       0  \n1      0       0  \n2      0       0"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-quality",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-quality",
    "title": "Ejemplo de CRISP-DM",
    "section": "Data Quality",
    "text": "Data Quality\n\n# %% ------------------ Plan de calidad de datos ------------------\n# 1) Imputación: media para numéricos; mantén categóricas como 'missing' si aplica.\nnumeric_features = [\"age\",\"nihss\",\"days_since_stroke\",\"comorb\",\n                    \"sixmwt_base\",\"tug_base\",\"therapy_min\",\"cadence\",\"step_var\"]\ncategorical_features = [\"sex\"]\n\nnum_imputer = SimpleImputer(strategy=\"median\")\ncat_imputer = SimpleImputer(strategy=\"most_frequent\")\n\n# 2) Escalado (para modelos lineales/regularizados)\nnum_scaler = StandardScaler()\n\n# 3) Codificación one-hot de categóricas\nohe = OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\")\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"num\", Pipeline([(\"imputer\", num_imputer), (\"scaler\", num_scaler)]), numeric_features),\n        (\"cat\", Pipeline([(\"imputer\", cat_imputer), (\"ohe\", ohe)]), categorical_features),\n    ]\n)"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#baseline-de-modelado",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#baseline-de-modelado",
    "title": "Ejemplo de CRISP-DM",
    "section": "Baseline de Modelado",
    "text": "Baseline de Modelado\n\n# %% ------------------ Partición y métricas ------------------\nX = df.drop(columns=[\"delta_6mwt\"])\ny = df[\"delta_6mwt\"].values\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=7\n)\n\nscorers = {\n    \"MAE\": make_scorer(mean_absolute_error),\n    \"RMSE\": make_scorer(lambda yt, yp: mean_squared_error(yt, yp)),\n    \"R2\": make_scorer(r2_score),\n}\n\ncv = KFold(n_splits=5, shuffle=True, random_state=7)\n\ndef evaluate_model(model, name):\n    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", model)])\n    cvres = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scorers, n_jobs=-1)\n    print(f\"\\n{name} - CV resultados (train):\")\n    for m in scorers.keys():\n        print(f\"  {m}: {cvres['test_'+m].mean():.2f} ± {cvres['test_'+m].std():.2f}\")\n    pipe.fit(X_train, y_train)\n    yhat = pipe.predict(X_test)\n    print(f\"{name} - Test:\")\n    print(f\"  MAE:  {mean_absolute_error(y_test, yhat):.2f}\")\n    print(f\"  RMSE: {mean_squared_error(y_test, yhat):.2f}\")\n    print(f\"  R2:   {r2_score(y_test, yhat):.3f}\")\n    return pipe\n\nlin = evaluate_model(LinearRegression(), \"LinearRegression\")\nrid = evaluate_model(Ridge(alpha=1.0), \"Ridge(alpha=1.0)\")\nlas = evaluate_model(Lasso(alpha=0.05, max_iter=5000), \"Lasso(alpha=0.05)\")\n\n\nLinearRegression - CV resultados (train):\n  MAE: 34.25 ± 2.12\n  RMSE: 1809.09 ± 156.01\n  R2: 0.42 ± 0.06\nLinearRegression - Test:\n  MAE:  32.75\n  RMSE: 1691.19\n  R2:   0.464\n\nRidge(alpha=1.0) - CV resultados (train):\n  MAE: 34.25 ± 2.12\n  RMSE: 1808.99 ± 155.65\n  R2: 0.42 ± 0.06\nRidge(alpha=1.0) - Test:\n  MAE:  32.75\n  RMSE: 1690.92\n  R2:   0.464\n\nLasso(alpha=0.05) - CV resultados (train):\n  MAE: 34.24 ± 2.12\n  RMSE: 1809.04 ± 155.68\n  R2: 0.42 ± 0.06\nLasso(alpha=0.05) - Test:\n  MAE:  32.73\n  RMSE: 1689.67\n  R2:   0.465"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit",
    "href": "tutoriales/tut002_IA.html#que-es-microbit",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#componentes",
    "href": "tutoriales/tut002_IA.html#componentes",
    "title": "Microbit – El minicomputador",
    "section": "Componentes",
    "text": "Componentes"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#como-la-puedo-programar",
    "href": "tutoriales/tut002_IA.html#como-la-puedo-programar",
    "title": "Microbit – El minicomputador",
    "section": "Como la puedo programar?",
    "text": "Como la puedo programar?"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#distribución-e-impacto",
    "href": "tutoriales/tut002_IA.html#distribución-e-impacto",
    "title": "Microbit – El minicomputador",
    "section": "Distribución e impacto",
    "text": "Distribución e impacto\n\nDistribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#problema",
    "href": "tutoriales/tut002_IA.html#problema",
    "title": "Microbit – El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable en 0.\nMostrar el número en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "href": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "title": "Microbit – El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#lets-code",
    "href": "tutoriales/tut002_IA.html#lets-code",
    "title": "Microbit – El minicomputador",
    "section": "Let’s Code",
    "text": "Let’s Code\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#editor",
    "href": "tutoriales/tut002_IA.html#editor",
    "title": "Microbit – El minicomputador",
    "section": "Editor",
    "text": "Editor\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "href": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "title": "Microbit – El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable con el número a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "tutoriales/ExpansionTaylor.html",
    "href": "tutoriales/ExpansionTaylor.html",
    "title": "Computación de seno y coseno usando expansión de Taylor",
    "section": "",
    "text": "Las ecuaciones de las expansiones de Taylor (centradas en cero) fueron extraídas de la recopilación que hizo Wikipedia\n\\[cos\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{x^{2n}}{2n!}\\left(-1\\right)^{n}}\\]\n\\[sin\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{\\left(-1\\right)^{n}}{\\left(2n+1\\right)!}x^{2n+1}}\\]\n\ndef factorial(x):\n    output = 1\n    for k in range(1,x+1):\n        output = output*k\n    return output\n\n\ndef sin_taylor_expansion(x,n):\n    pi = 3.141592653589793238462643383279502884197169399375105820974944\n    x = pi*x/180\n    output = 0\n    for k in range(0, n):\n        term = (((-1)**k)/factorial(2*k + 1))*(x**(2*k+1))\n        output = output+term\n    return output\n\n\nv_est = sin_taylor_expansion(30,5)\n\nprint(v_est)\n\nprint(\"Error Relativo:\", abs(0.5-v_est)/0.5)\n\n0.5000000000202799\nError Relativo: 4.0559777758630844e-11"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html",
    "href": "tutoriales/tutInstallPythonR.html",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "",
    "text": "Antes de compilar Python, es necesario disponer de Ubuntu corriendo bajo WSL2 en Windows 11. Sigue estos pasos:\n\nVerificar requisitos:\n\nWindows 11 (build 22000 o superior).\nVirtualización habilitada en BIOS/UEFI (Intel VT-x o AMD SVM).\nPermisos de administrador en Windows.\n\nHabilitar WSL y plataforma de máquina virtual:\nAbre PowerShell como administrador y ejecuta:\npowershell  wsl --install\n\nEsto activa las características “Virtual Machine Platform” y “Windows Subsystem for Linux”.\nDescarga e instala Ubuntu por defecto (puedes ignorar o desinstalar luego).\nReinicia el equipo si se solicita.\n\nInstalar Ubuntu:\n\nVía PowerShell:\nwsl --install -d Ubuntu\nO desde Microsoft Store:\n\nAbre Microsoft Store.\nBusca “Ubuntu” y pulsa Instalar.\n\n\nPrimer arranque de Ubuntu:\n\nAbre Ubuntu desde el menú Inicio o Windows Terminal.\npowershell      wsl -d Ubuntu\nCrea tu usuario y contraseña de Linux.\n\nActualizar paquetes del sistema:\nsudo apt update && sudo apt upgrade -y"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-repositorios-e-instalar-dependencias-de-compilación",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-repositorios-e-instalar-dependencias-de-compilación",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "1. Actualizar repositorios e instalar dependencias de compilación",
    "text": "1. Actualizar repositorios e instalar dependencias de compilación\nEjecuta los siguientes comandos para actualizar el sistema e instalar las bibliotecas necesarias para compilar Python desde el código fuente:\nsudo apt update\nsudo apt install -y \\\n  build-essential \\\n  checkinstall \\\n  libncurses-dev \\\n  libssl-dev \\\n  zlib1g \\\n  zlib1g-dev \\\n  libreadline-dev \\\n  libsqlite3-dev \\\n  libgdbm-dev libdb5.3-dev \\\n  libbz2-dev \\\n  libexpat1-dev \\\n  libc6-dev \\\n  libffi-dev \\\n  liblzma-dev \\\n  tk-dev \\\n  dirmngr \\\n  gnupg \\\n  apt-transport-https \\\n  ca-certificates \\\n  software-properties-common wget \\\n  libxml2-dev \\\n  libharfbuzz-dev \\\n  libfribidi-dev \\\n  libcurl4-openssl-dev \\\n  libmagick++-dev \\\n  libnsl-dev \\\n  cmake\\\n  wget"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#obtener-el-kit-de-repositorio-cuda-de-nvidia",
    "href": "tutoriales/tutInstallPythonR.html#obtener-el-kit-de-repositorio-cuda-de-nvidia",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "2. Obtener el kit de repositorio CUDA de NVIDIA:",
    "text": "2. Obtener el kit de repositorio CUDA de NVIDIA:\ncd ~\nmkdir instaladores\ncd instaladores\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/12.9.1/local_installers/cuda-repo-wsl-ubuntu-12-9-local_12.9.1-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-12-9-local_12.9.1-1_amd64.deb\nsudo apt update\nsudo apt -y install cuda-toolkit-12-9"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-instalación",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-instalación",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "3. Verificar la instalación:",
    "text": "3. Verificar la instalación:\n# Verifica la versión de nvcc\nnvcc --version\n# Verifica que la GPU sea detectada\nnvidia-smi"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#instalación-de-la-versión-más-reciente-de-r",
    "href": "tutoriales/tutInstallPythonR.html#instalación-de-la-versión-más-reciente-de-r",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "4. Instalación de la versión más reciente de R",
    "text": "4. Instalación de la versión más reciente de R\nPara instalar la versión más reciente de R en Ubuntu bajo WSL2, sigue estos pasos:\n\n1. Agregar la clave y el repositorio oficial de CRAN:\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\nsudo add-apt-repository \"deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/\"\n\n\n2. Instalar R:\nsudo apt update\nsudo apt install -y r-base r-base-dev r-recommended\n\n\n3. Verificar la instalación:\nR --version    # Debe mostrar la versión de R recién instalada\nsudo R\ninstall.packages(c(\"DiagrammeR\", \"reticulate\", \"kableExtra\", \"tidyverse\", \"knitr\", \"cowplot\", \"ggfx\", \"rstatix\", \"languageserver\", \"bibliometrix\"))"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#descargar-y-extraer-python-3.12",
    "href": "tutoriales/tutInstallPythonR.html#descargar-y-extraer-python-3.12",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "5. Descargar y extraer Python 3.12",
    "text": "5. Descargar y extraer Python 3.12\n\n1. Descarga el código fuente de Python 3.12 y descomprímelo en /usr/src:\ncd /usr/src\nsudo wget https://www.python.org/ftp/python/3.12.11/Python-3.12.11.tgz\nsudo tar -xzf Python-3.12.11.tgz\ncd Python-3.12.11\n\n\n2. Configura la compilación con optimizaciones y el instalador de pip integrado:\n```bash\nsudo ./configure --enable-optimizations --with-ensurepip=install --enable-shared\n```\n\n\n3. Compila utilizando todos los núcleos disponibles:\n```bash\nsudo make -j $(nproc)\n```\n\n\n4. Instala Python 3.12 sin sobrescribir la versión del sistema por defecto:\n```bash\nsudo make altinstall\n```\nLos ejecutables quedarán en /usr/local/bin/python3.12 y /usr/local/bin/pip3.12.\n\n\n5. Verificación de la instalación\nComprueba las versiones instaladas:\n/usr/local/bin/python3.12 --version   # Debe mostrar Python 3.12.0\n/usr/local/bin/pip3.12 --version      # Debe mostrar la versión de pip correspondiente\necho 'export PATH=\"$PATH:/home/sylph/.local/bin\"' &gt;&gt; ~/.bashrc\nsource\n\n\n6. Crear y activar un entorno virtual\n\n1. Crea un directorio de trabajo\n```bash\nmkdir -p ~/proyectos\ncd ~/proyectos\n```\n\n\n2. Crea un entorno virtual (mienv) con Python 3.12:\n```bash\n/usr/local/bin/python3.12 -m venv mienv\n```\n\n\n3. Activa el entorno:\n```bash\nsource mienv/bin/activate\n```\n\n\n4. Verifica que python y pip apunten a la versión 3.12:\n```bash\npython --version   # Python 3.12.X\npip --version      # pip x.y.z\n```\n\n\n5. Instala las bibliotecas necesarias:\n```bash\npython -m pip cache purge\npython -m pip install -U --upgrade-strategy eager pip setuptools wheel packaging build\npython -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu129\npython -m pip install pandas matplotlib scikit-learn opencv-contrib-python opencv-python pywavelets statsmodels scipy seaborn plotly scikit-image scikit-image[data] scikit-image[optional] jupyter scikit-image\n```\n\n\n5. desactivar el entorno, ejecuta:\ndeactivate"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-índices-de-paquetes",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-índices-de-paquetes",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "1. Actualizar índices de paquetes",
    "text": "1. Actualizar índices de paquetes\nsudo apt update"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#descargar-el-instalador-oficial",
    "href": "tutoriales/tutInstallPythonR.html#descargar-el-instalador-oficial",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "2. Descargar el instalador oficial",
    "text": "2. Descargar el instalador oficial\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-integridad-opcional",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-integridad-opcional",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "3. Verificar la integridad (opcional)",
    "text": "3. Verificar la integridad (opcional)\nCompara el hash SHA‑256 generado con el publicado en el sitio oficial:\nsha256sum ~/miniconda.sh\n# Comprueba que el resultado coincida con el valor en https://repo.anaconda.com/miniconda/"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#ejecutar-el-instalador-en-modo-silencioso",
    "href": "tutoriales/tutInstallPythonR.html#ejecutar-el-instalador-en-modo-silencioso",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "4. Ejecutar el instalador en modo silencioso",
    "text": "4. Ejecutar el instalador en modo silencioso\nEsto instalará Miniconda en ~/miniconda sin interacción:\nbash ~/miniconda.sh -b -p $HOME/miniconda"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#inicializar-conda-en-tu-shell",
    "href": "tutoriales/tutInstallPythonR.html#inicializar-conda-en-tu-shell",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "5. Inicializar Conda en tu shell",
    "text": "5. Inicializar Conda en tu shell\nPara que conda esté disponible cada vez que abras la terminal:\neval \"$(~/miniconda/bin/conda shell.bash hook)\"\nconda init"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#recargar-la-configuración-de-shell",
    "href": "tutoriales/tutInstallPythonR.html#recargar-la-configuración-de-shell",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "6. Recargar la configuración de shell",
    "text": "6. Recargar la configuración de shell\nsource ~/.bashrc"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-conda-a-la-última-versión",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-conda-a-la-última-versión",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "7. Actualizar Conda a la última versión",
    "text": "7. Actualizar Conda a la última versión\nconda tos interactive\nconda update -n base -c defaults conda -y"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-instalación-2",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-instalación-2",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "8. Verificar la instalación",
    "text": "8. Verificar la instalación\nconda --version\n# Deberías ver algo como: conda 23.x.x"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#crear-un-entorno-virtual",
    "href": "tutoriales/tutInstallPythonR.html#crear-un-entorno-virtual",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "9. Crear un entorno virtual",
    "text": "9. Crear un entorno virtual\nconda create -n ai-env python=3.12"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Understanding Workflow.",
    "text": "Data Understanding Workflow.\n\n\n\n\n\n\n\nExploratory data analysis\n\n\n\nData Loading.\nBasic Statistics: Displays summary statistics.\nMissing Values Check: Identifies missing values.\nFeature Distributions: Visualizes distributions using histograms or countplots.\nRelationship between variables."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Understanding Workflow",
    "text": "Data Understanding Workflow\n\n# Identify variable types\ndiscrete_vars = [\"Pregnancies\"]  # Discrete numerical variable\ncategorical_vars = [\"Outcome\"]  # Class label\ncontinuous_vars = [\n    col\n    for col in data.select_dtypes(include=[np.number]).columns\n    if col not in discrete_vars + [\"Outcome\"]\n]\n\n# Basic dataset information\nprint(\"Dataset Information:\\n\", data.info())\nprint(\"\\nSummary Statistics:\\n\", data.describe())\nprint(\"\\nMissing Values:\\n\", data.isnull().sum())\n\n# Ensure numeric data and handle NaN or infinite values\nnumeric_data = data.select_dtypes(include=[np.number]).dropna()\nnumeric_data = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n\n# Dynamically determine the number of rows for subplots\nnum_cont_vars = len(continuous_vars)\nrows = (num_cont_vars // 3) + (num_cont_vars % 3 &gt; 0)  # Ensures proper grid layout\n\n# Plot distributions for continuous variables\nplt.figure(figsize=(12, 4 * rows))\nfor i, column in enumerate(continuous_vars, 1):\n    plt.subplot(rows, 3, i)\n    sns.histplot(numeric_data[column], kde=True, bins=20, color=\"skyblue\")\n    plt.title(f\"Distribution of {column}\")\nplt.tight_layout()\nplt.show()\n\n# Plot distribution for discrete variable (Pregnancies) using a countplot\nplt.figure(figsize=(8, 4))\nsns.countplot(x=\"Pregnancies\", data=numeric_data, palette=\"viridis\")\nplt.title(\"Count of Pregnancies\")\nplt.show()\n\n# Plot class distribution for Outcome\nplt.figure(figsize=(6, 4))\nsns.countplot(x=\"Outcome\", data=data, palette=\"coolwarm\")\nplt.title(\"Class Distribution of Outcome\")\nplt.xlabel(\"Diabetes Diagnosis (0: No, 1: Yes)\")\nplt.ylabel(\"Count\")\nplt.show()\n\n# Correlation heatmap to check relationships\nplt.figure(figsize=(10, 6))\nsns.heatmap(numeric_data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nKey Term\n\n\nThe term edge AI is a union of two buzzwords, fused together into one mighty term. It’s often heard alongside its siblings, embedded machine learning and TinyML.\n\n\n\n\n\n\n\n\n\n\n\nEmbedded\n\n\n\nEmbedded systems are the computers that control the electronics of all sorts of physical devices.\nIn contrast to general-purpose computers, embedded systems are usually meant to perform one specific, dedicated task.\nIt’s common for embedded systems to reflect the constraints of the environments into which they are deployed. For example, many embedded systems are required to run on battery power, so they’re designed with energy efficiency in mind—perhaps with limited memory or an extremely slow clock rate.\nProgramming embedded systems is the art of navigating these constraints, writing software that performs the task required while making the most out of limited resources."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nThe history of computer networks has been a gigantic tug of war.\nIn the first systems—individual computers the size of a room—computation was inherently centralized.\nComputers were connected to terminals that took over some of their responsibilities. Example the terminal renders the letters in an monitor."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nOver time, terminals became more and more sophisticated, taking over more and more functions that were previously the job of the central computer. The personal computer was invented.\nSmall computers could do useful work without even being connected to another machine.\nThe growth of the internet, along with web applications and services, made it possible to do some really cool stuff\nOver the past decade, most of our computing has become centralized again—this time in the “cloud.”"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-3",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nThe Internet of Things (IoT) includes everything you can think of: industrial sensors, smart refrigerators, internet-connected security cameras, personal automobiles, shipping containers, fitness trackers, and coffee machines.\nAll of these devices are embedded systems.\nSince they’re at the edge of the network, we can also call them edge devices.\nThe edge isn’t a single place; it’s more like a broad region.\nThe edge is where all the data comes from!\nEdge devices are our link between the internet and the physical world"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\n\n\nAI\n\n\n\nSince the dawn of time, humans have dreamed of creating intelligent entities that can help us in our struggle to survive.\nIn the modern world we dream of robot sidekicks who assist us.\nTo define AI, we have to define intelligence\n\n\n\n\n\n\n\n\n\n“Slime Mould Solves Maze in One Pass Assisted by Gradient of Chemo-Attractants” (Andrew Adamatzky, arXiv, 2011)"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-6",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-6",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "href": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Methodology for designing an edge ai device",
    "text": "Methodology for designing an edge ai device\n\nProblem Definition & Use Case Analysis\nData Collection & Preprocessing\nModel Selection & Optimization\nHardware Selection\nDeployment & Model Inference\nTesting, Validation, and Continuous Improvement\nFinal Deployment & Scaling"
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Problem Definition & Use Case Analysis",
    "text": "Problem Definition & Use Case Analysis\n\nIdentify the specific AI task (e.g., real-time ECG analysis, fall detection, predictive maintenance in IoT).\nDetermine operational constraints, including:\n\nPower consumption (battery-operated vs. wired).\nLatency requirements (real-time processing vs. periodic updates).\nCommunication needs (Wi-Fi, Bluetooth, LoRa, standalone processing)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Collection & Preprocessing",
    "text": "Data Collection & Preprocessing\n\nSensor Selection: Choose sensors relevant to the application (e.g., accelerometers for motion tracking, biosensors for health monitoring).\nEdge-Compatible Data Acquisition: Optimize data formats to reduce memory and computational load.\nPreprocessing on Edge:\n\nSignal filtering (e.g., noise reduction in biomedical signals).\nFeature extraction (e.g., time-series features for motion classification)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Model Selection & Optimization",
    "text": "Model Selection & Optimization\n\nModel Selection:\n\nLightweight CNNs (for image processing).\nRecurrent Neural Networks (RNNs) / LSTMs (for time-series data like ECG).\nTinyML models optimized for microcontrollers (e.g., TensorFlow Lite, PyTorch Mobile).\n\nModel Optimization for Edge Deployment:\n\nQuantization: Convert floating-point models to int8 or int16 to reduce size and computation load.\nPruning: Remove unnecessary neurons or layers while preserving accuracy.\nDistillation: Train a smaller model using knowledge from a larger one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Hardware Selection",
    "text": "Hardware Selection\n\nProcessing Unit:\n\nMicrocontrollers (MCUs) (e.g., ARM Cortex-M, ESP32) → Low-power, simple AI tasks.\nEdge AI Accelerators (e.g., Google Edge TPU, NVIDIA Jetson Nano) → More complex AI processing.\nFPGAs (Field-Programmable Gate Arrays) → Custom AI workloads for high-speed processing.\n\nMemory & Storage:\n\nRAM Optimization: Choose embedded SRAM or external DRAM depending on model size.\nFlash Storage: Store inference models efficiently.\n\nConnectivity:\n\nOffline processing for low-latency applications.\nEdge-to-cloud integration for periodic updates."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Deployment & Model Inference",
    "text": "Deployment & Model Inference\n\nConvert trained AI models into optimized edge-compatible formats (e.g., TensorFlow Lite, ONNX).\nImplement real-time inference using hardware-accelerated libraries (e.g., TensorRT, OpenVINO).\nOptimize firmware for energy efficiency using duty-cycling techniques (process only when necessary)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Testing, Validation, and Continuous Improvement",
    "text": "Testing, Validation, and Continuous Improvement\n\nEdge Benchmarking:\n\nMeasure inference speed and power consumption.\nValidate model accuracy on real-world edge-generated data.\n\nSecurity & Reliability:\n\nImplement secure boot & firmware updates to prevent cyber threats.\nEnsure robust error handling for sensor malfunctions.\n\nFeedback & Model Updating:\n\nIf connected to a cloud system, update models periodically using federated learning.\nOptimize AI pipelines with incremental learning on-device where feasible."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Final Deployment & Scaling",
    "text": "Final Deployment & Scaling\n\nDeploy at scale, ensuring the Edge AI model adapts to different environments.\nImplement remote monitoring & diagnostics for predictive maintenance.\nEnable over-the-air (OTA) updates to improve AI models post-deployment."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "href": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Abstract",
    "text": "Abstract\nThe hardware-software co-design approach is the most widely used methodology for Edge AI device development. It ensures:\n\nReal-time performance with optimized AI models.\nEnergy-efficient processing for battery-operated or low-power devices.\nScalability and security in edge environments.\n\nThis methodology is industry-standard and used by leading companies in healthcare, automotive, and industrial IoT, ensuring robust and reliable Edge AI solutions."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "href": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Example of application",
    "text": "Example of application\n\n\n\n\n\n\n\nUse case\n\n\nA wearable ECG monitoring device designed for continuous heart health tracking and arrhythmia detection. This Edge AI-based solution analyzes ECG signals in real-time on a low-power microcontroller, providing instant alerts for cardiac irregularities without relying on cloud computing."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 1: Problem Definition & Use Case Analysis",
    "text": "Step 1: Problem Definition & Use Case Analysis\n\n\n\n\n\n\n\nObjective\n\n\nDetect abnormal heart rhythms (arrhythmias) in real-time using a wearable ECG device.\n\n\n\n\nOperational Constraints:\n\nMust be energy-efficient (battery-operated, low power consumption).\nNeeds real-time inference for immediate alerts.\nShould operate offline, but sync with mobile apps for periodic review.\n\nKey Challenges:\n\nProcessing ECG data on a low-power Edge device.\nMinimizing false positives/negatives in arrhythmia detection.\nEnsuring high reliability and accuracy."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 2: Data Collection & Preprocessing",
    "text": "Step 2: Data Collection & Preprocessing\nSensor Selection:\n\nECG sensor (e.g., AD8232) captures raw heart signals.\nAccelerometer (optional) for motion artifacts reduction.\n\nEdge-Compatible Data Acquisition:\n\nSample rate: 250 Hz (sufficient for arrhythmia detection).\nUse on-device filtering (low-pass filters) to remove noise.\n\nPreprocessing on Edge:\n\nApply Butterworth filters for noise reduction.\nR-peak detection using Pan-Tompkins algorithm for heart rate calculation.\nExtract features like RR intervals, QRS width, and HR variability."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 3: Model Selection & Optimization",
    "text": "Step 3: Model Selection & Optimization\nAI Model:\n\nUse 1D CNN + LSTM hybrid model (efficient for ECG signal processing).\nTrain the model using MIT-BIH Arrhythmia Database.\n\nModel Optimization for Edge AI:\n\nQuantization: Convert model to int8 precision using TensorFlow Lite.\nPruning: Remove redundant neurons to reduce computation load.\nKnowledge Distillation: Train a smaller model from a high-performing one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 4: Hardware Selection",
    "text": "Step 4: Hardware Selection\nMicrocontroller (MCU):\n\nNordic nRF52840 (low-power ARM Cortex-M4 + BLE connectivity).\nAlternative: ESP32 (for low-cost AI inference).\n\nMemory & Storage:\n\nRAM: 512KB (optimized for Edge AI processing).\nFlash storage: 4MB (stores ECG data logs for later analysis).\n\nConnectivity:\n\nBluetooth Low Energy (BLE) for periodic sync with mobile apps.\nCan function offline with real-time alerts."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 5: Deployment & Model Inference",
    "text": "Step 5: Deployment & Model Inference\n\nConvert trained TensorFlow model → TensorFlow Lite for Edge AI inference.\nDeploy on the Nordic nRF52840 MCU using TensorFlow Lite for Microcontrollers.\nUse hardware-accelerated inference for efficient processing.\nImplement event-driven processing (AI runs only on abnormal detections to save power)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 6: Testing, Validation, and Continuous Improvement",
    "text": "Step 6: Testing, Validation, and Continuous Improvement\nEdge Benchmarking:\n\nReal-time inference latency: &lt;10 ms per ECG segment.\nPower consumption: 5mW (optimized for long battery life).\n\nSecurity & Reliability:\n\nSecure Boot & Firmware Updates to prevent hacking.\nAdaptive AI Models: Learns individual patient heart patterns to reduce false alarms.\n\nFeedback & Model Updating:\n\nSync detected arrhythmia events with a cloud server for validation.\nUse federated learning to improve AI models without sharing raw patient data."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 7: Final Deployment & Scaling",
    "text": "Step 7: Final Deployment & Scaling\n\nMass production of the device for hospitals, clinics, and home use.\nIntegration with mobile apps for patient-doctor communication.\nRegulatory Approval: Submit for FDA/CE certification for medical device compliance.\nOver-the-Air (OTA) Updates: Allow model updates based on new ECG patterns."
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción a inteligencia artificial en el borde (EDGE AI).\nHardware y software para EDGE AI.\nEl flujo de trabajo de EDGE AI.\nDiseño, desarrollo y evaluación de sistemas EDGE AI."
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluación",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nLaboratorios (60%)\nProyecto Final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluación-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (30%)\nLaboratorios (30%)\nProyecto final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201.\n\nInterpretes: R y python.\nOS: Linux\nLenguajes: C/C++\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#bibliografía",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980.\n[42] D. Situnayake y J. Plunkett, AI at the Edge: solving real-world problems with embedded machine learning. Sebastopol: O’Reilly, 2023.\n[43] X. Wang, Y. Han, V. C. M. Leung, D. Niyato, X. Yan, y X. Chen, Edge AI: Convergence of Edge Computing and Artificial Intelligence. Singapore: Springer Singapore, 2020. doi: 10.1007/978-981-15-6186-3.\n[44] A. Koul, S. Ganju, y M. Kasam, «Practical Deep Learning for Cloud, Mobile, and Edge».\n[45] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[46] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[47] V. Subramanian, Deep learning with PyTorch: a practical approach to building neural network models using PyTorch. Birmingham, UK: Packt Publishing, 2018.\n[48] Diagnostic Biomedical Signal and Image Processing Applications with Deep Learning Methods. Elsevier, 2023. doi: 10.1016/C2021-0-02190-8.\n[49] J. D. Kelleher, B. Mac Namee, y A. D’Arcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed. Cambridge: The MIT press, 2020.\n[50] A. A. Patel, «Hands-On Unsupervised Learning Using Python».\n[51] P. Raj, P. B. Soundarabai, y P. Augustine, Machine Intelligence: Computer Vision and Natural Language Processing, 1.ª ed. Boca Raton: Auerbach Publications, 2023. doi: 10.1201/9781003424550.\n[52] M. Roy y L. R. Gupta, Eds., Machine Learning and Data Analytics for Predicting, Managing, and Monitoring Disease: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2021. doi: 10.4018/978-1-7998-7188-0.\n[53] A. R. Jha, Mastering PyTorch: create and deploy deep learning models from CNNs to multimodal models, LLMs, and beyond, Second edition. en Expert insight. Birmingham: Packt Publishing Limited, 2024.\n[54] V. K. Ayyadevara y Y. Reddy, Modern computer vision with PyTorch: a practical roadmap from deep learning fundamentals to advanced applications and Generative AI, Second edition. Birmingham, UK: Packt Publishing Ltd., 2024.\n[55] E. Priya y V. Rajinikanth, Eds., Signal and Image Processing Techniques for the Development of Intelligent Healthcare Systems. Singapore: Springer Singapore, 2021. doi: 10.1007/978-981-15-6141-2.\n[56] M. M. Richter, S. Paul, V. Këpuska, y M. Silaghi, Signal Processing and Machine Learning with Applications. Cham: Springer International Publishing, 2022. doi: 10.1007/978-3-319-45372-9."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#importance-of-frequency-response-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#importance-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Importance of Frequency-Response Filters",
    "text": "Importance of Frequency-Response Filters\n\nFrequency-response filters are critical for enhancing specific features or reducing noise in images.\nWidely used in MRI, CT, and ultrasound imaging."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#what-is-a-frequency-response-filter",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#what-is-a-frequency-response-filter",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is a Frequency-Response Filter?",
    "text": "What is a Frequency-Response Filter?\n\nA frequency-response filter modifies the frequency components of a signal.\nApplied in image processing to control which frequencies (details) pass or are suppressed."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#types-of-frequency-response-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#types-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Types of Frequency-Response Filters",
    "text": "Types of Frequency-Response Filters\n\nLow-pass filters: Allow low frequencies, suppress high frequencies (smoothes image).\nHigh-pass filters: Allow high frequencies, suppress low frequencies (sharpens image).\nBand-pass filters: Allow frequencies in a certain range."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#spatial-vs.-frequency-domain",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#spatial-vs.-frequency-domain",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Spatial vs. Frequency Domain",
    "text": "Spatial vs. Frequency Domain\n\nSpatial domain: Operations on pixel values directly.\nFrequency domain: Operations on the image’s frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#fourier-transform",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#fourier-transform",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Fourier Transform",
    "text": "Fourier Transform\n\nConverts an image from the spatial domain to the frequency domain.\nFormula: \\[F\\left(u,v\\right) = \\sum\\sum f\\left(x,y\\right) e^{-j2\\pi(\\frac{ux}{M} + \\frac{vy}{N})}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#low-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#low-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low-Pass Filters",
    "text": "Low-Pass Filters\n\nRemoves high-frequency components (e.g., noise, sharp edges).\nExample: Gaussian filter, Butterworth filter."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#high-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#high-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "High-Pass Filters",
    "text": "High-Pass Filters\n\nEnhances edges and high-frequency details.\nExample: Laplacian filter."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#band-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#band-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Band-Pass Filters",
    "text": "Band-Pass Filters\n\nAllows frequencies within a specific range.\nUseful for isolating specific image features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#noise-reduction-in-mri",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#noise-reduction-in-mri",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Noise Reduction in MRI",
    "text": "Noise Reduction in MRI\n\nLow-pass filters reduce noise and artifacts in MRI scans.\nSmoothes the image without losing crucial details."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#edge-enhancement-in-ultrasound-images",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#edge-enhancement-in-ultrasound-images",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge Enhancement in Ultrasound Images",
    "text": "Edge Enhancement in Ultrasound Images\n\nHigh-pass filters help in detecting tissue boundaries by enhancing edges.\nImproves clarity of anatomical structures."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#feature-extraction-in-ct-scans",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#feature-extraction-in-ct-scans",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Feature Extraction in CT Scans",
    "text": "Feature Extraction in CT Scans\n\nFilters can help in extracting features like tumors or vessels.\nBand-pass filters isolate structures of interest at specific frequency ranges."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process",
    "text": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process\n\nLoad MRI image.\nApply Fourier Transform to move the image into the frequency domain.\nDesign and apply a low-pass filter.\nPerform Inverse Fourier Transform to return to the spatial domain.\nVisualize the result."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#summary",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#summary",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Summary",
    "text": "Summary\n\nFrequency-response filters play a crucial role in biomedical image processing.\nHelp enhance key features and suppress unwanted noise."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#future-trends",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#future-trends",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Future Trends",
    "text": "Future Trends\n\nDeep learning integration with traditional filters.\nDevelopment of adaptive filters for real-time processing."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n(-1.0, 6.0)\n\n\n(-1.0, 5.0)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\nIt’s a mathematical tool for signal decomposition, like Fourier’s Transform.\nJust as the Fourier transform decomposes a signal into a series of sine and cosine functions, the wavelet transform does so using a set of functions known as wavelets.\nWavelets are functions generated by scaling and shifting a base function known as the mother wavelet."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\nMorlet: Popular for time-frequency analysis in EEG and ECG.\nMexican Hat (Ricker): Often used in spike detection in neural signals.\nHaar: Useful in quick decomposition of signals and feature extraction.\nDaubechies: Frequently used in ECG signal denoising and compression.\nSymlet: Another option for signal processing and feature extraction in EEG.\nCoiflet: Useful for denoising and baseline correction in biomedical signals."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-4",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-4",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\nConditionsIIIIIIIVV\n\n\n\nHave a mean of zero (to capture details in the signal).\nBe square integrable (finite energy).\nSatisfy the admissibility condition on its Fourier transform.\nBe oscillatory to capture frequency information.\n(Optionally) have compact support for efficient computation and localization.\n\n\n\n\n\n\n\n\n\n\nZero Mean (Admissibility Condition)\n\n\nThe function must have an average value of zero. Mathematically, this is expressed as:\n\\[\\int_{-\\infty}^{\\infty} \\psi(t) \\, dt = 0\\]\nThis condition ensures that the wavelet can detect changes or “details” in the signal rather than its average or constant components.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSquare Integrability\n\n\nThe function \\(\\psi(t)\\) must be square integrable, meaning it has finite energy:\n\\[\\int_{-\\infty}^{\\infty} |\\psi(t)|^2 \\, dt &lt; \\infty\\]\nThis requirement ensures that the wavelet’s energy is finite, making it possible to localize the function in both time and frequency domains. Functions that satisfy this belong to the \\(L^2(\\rm I\\!R)\\) space, which is the space of all functions with finite energy.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdmissibility Constant\n\n\nThe wavelet’s Fourier transform, \\(\\hat{\\psi}(\\omega)\\), should satisfy the admissibility condition:\n\\[C_\\psi = \\int_{-\\infty}^{\\infty} \\frac{|\\hat{\\psi}(\\omega)|^2}{|\\omega|} \\, d\\omega &lt; \\infty\\]\nwhere \\(\\hat{\\psi}(\\omega)\\) is the Fourier transform of \\(\\psi(t)\\), and \\(\\omega\\) represents angular frequency. This condition implies that \\(\\hat{\\psi}(\\omega)\\) must approach zero as \\(\\omega \\rightarrow 0\\) meaning the wavelet has no component at zero frequency (or DC component). This condition is crucial for ensuring that the wavelet transform is invertible.\n\n\n\n\n\n\n\n\n\n\n\n\n\nOscillatory Nature\n\n\nA mother wavelet should generally be oscillatory or “wavelike” (hence the term “wavelet”). This oscillatory behavior allows the wavelet to capture variations in the signal. For example, wavelets like the Morlet wavelet resemble decaying sinusoids. This oscillatory nature helps the wavelet capture both high-frequency and low-frequency components effectively.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompact Support\n\n\nAlthough not strictly necessary, compact support is often a desirable property. Compact support means that the function is non-zero only over a finite interval, making it well-localized in time. This allows for efficient computation and good localization in the time domain. For example, the Haar wavelet has compact support, while others, like the Morlet wavelet, do not have strict compact support but still decay rapidly."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "A wavelet transformation",
    "text": "A wavelet transformation\n\n\n(0.0, 1.0)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "A wavelet transformation",
    "text": "A wavelet transformation"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe continuous wavelet transform of a signal \\(f(t)\\) is defined as:\n\\[W_f(a, b) = \\int_{-\\infty}^{\\infty} f(t) \\, \\psi^*\\left(\\frac{t - b}{a}\\right) \\, dt\\]\nwhere:\n\n\\(f(t)\\) is the input signal,\n\\(\\psi\\) is the mother wavelet,\n\\(a\\) is the scale parameter (controls the width of the wavelet),\n\\(b\\) is the translation parameter (controls the position of the wavelet),\n\\(\\psi^*\\) denotes the complex conjugate of the mother wavelet. ## Mathematical Expressions\n\nThe continuous wavelet transform of a signal \\(f(t)\\) is defined as:\n\\[W_f(a, b) = \\int_{-\\infty}^{\\infty} f(t) \\, \\psi^*\\left(\\frac{t - b}{a}\\right) \\, dt\\]\nwhere:\n\n\\(f(t)\\) is the input signal,\n\\(\\psi\\) is the mother wavelet,\n\\(a\\) is the scale parameter (controls the width of the wavelet),\n\\(b\\) is the translation parameter (controls the position of the wavelet),\n\\(\\psi^*\\) denotes the complex conjugate of the mother wavelet."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe inverse continuous wavelet transform is given by:\n\\[f(t) = \\frac{1}{C_{\\psi}} \\int_{0}^{\\infty} \\int_{-\\infty}^{\\infty} W_f(a, b) \\, \\psi\\left(\\frac{t - b}{a}\\right) \\frac{db \\, da}{a^2}\\]\nwhere:\nwhere \\(C_{\\psi}\\) is a normalization constant, defined as:\n\\[C_{\\psi} = \\int_{0}^{\\infty} \\frac{|\\hat{\\psi}(\\omega)|^2}{\\omega} \\, d\\omega\\]\nand \\(\\hat{\\psi}(\\omega)\\) is the Fourier transform of the wavelet \\(\\psi(t)\\)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe discrete wavelet transform decomposes the signal at discrete levels of scale. For a signal \\(x[n]\\), the wavelet decomposition is defined as:\n\\[c_{j, k} = \\sum_{n} x[n] \\, \\psi_{j, k}(n)\\]\nwhere:\n\n\\(\\psi_{j, k}(n)= \\frac{1}{\\sqrt{2}}\\psi\\left(\\frac{n-2^{j}k}{2^{j}}\\right)\\) represents the scaled and translated versions of the mother wavelet \\(\\psi\\)\n\\(j\\) is the scale index, and \\(k\\) is the translation index.\n\nThe decomposition typically consists of approximation and detail coefficients at each scale:\nApproximation coefficients \\(a_j\\): capture the low-frequency components. Detail coefficients \\(d_j\\) capture the high-frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe inverse discrete wavelet transform reconstructs the original signal from its approximation and detail coefficients: \\[x[n] = \\sum_{j} \\sum_{k} c_{j, k} \\, \\psi_{j, k}(n)\\]\nThis reconstruction process involves upsampling and filtering of the approximation and detail coefficients at each scale."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#using-cwt",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#using-cwt",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Using CWT",
    "text": "Using CWT\n\nPurpose: The CWT is used when you need a highly detailed, continuous analysis of a signal over all possible scales and positions.\nOutput: CWT gives you a “heatmap” of wavelet coefficients, showing which frequencies (or scales) are present in the signal at each point in time. This allows for a continuous representation.\nApplications: CWT is useful for analyzing signals where you want to see the evolution of frequencies over time, such as:\n\nDetecting subtle changes in frequencies over time (like brainwave analysis in EEG).\nSignals with non-repeating, transient features (like spikes in biomedical signals, e.g., ECG).\n\nTrade-Off: CWT is more computationally expensive because it analyzes all scales and translations continuously. It gives lots of data but is slower and requires more memory.\n\n\n\n\n\n\n\n\nUse CWT when:\n\n\n\nYou need a detailed, continuous representation.\nYou want to detect subtle or fast-changing features across time.\nYou’re okay with higher computational costs to get very fine-grained analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#using-dwt",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#using-dwt",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Using DWT",
    "text": "Using DWT\n\nPurpose: The DWT is used when you want a compact, efficient representation of a signal, usually for compression or feature extraction. It analyzes only specific scales (powers of two), not continuously.\nOutput: DWT gives you a set of coefficients at each level (or scale), capturing information at that specific scale. It’s efficient and uses fewer data points.\nApplications: DWT is ideal when you want to reduce the size of data or focus on a smaller set of frequencies, such as:\n\nImage and audio compression (like JPEG 2000 or MP3 formats).\nFeature extraction for machine learning (e.g., identifying specific patterns).\nDe-noising signals by discarding certain scales that contain noise.\n\nTrade-Off: DWT is computationally cheaper but less detailed than CWT. It doesn’t give a continuous heatmap but rather a discrete set of scales.\n\n\n\n\n\n\n\n\nUse DWT when:\n\n\n\nYou need a compact and efficient representation.\nYou’re focused on data compression, de-noising, or feature extraction.\nYou want faster computations with less data storage requirements."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-analyzing-complex-signals",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-analyzing-complex-signals",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction: Analyzing Complex Signals",
    "text": "Introduction: Analyzing Complex Signals\n\nSignals like ECG are often non-stationary.\nTheir frequency content and characteristics change over time.\nTraditional methods (e.g., Fourier Transform) analyze the signal globally, losing temporal information.\nNeed a method to analyze signals at different time scales and frequency bands simultaneously."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#what-is-multiresolution-analysis-mra",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#what-is-multiresolution-analysis-mra",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is Multiresolution Analysis (MRA)?",
    "text": "What is Multiresolution Analysis (MRA)?\n\nA mathematical framework to decompose a signal into components at different levels of resolution or detail.\nThink of it like looking at a picture:\n\nCoarse view (low resolution): See the overall structure.\nFine view (high resolution): See small details.\n\nMRA decomposes a signal into a series of approximations and details, capturing information across various scales.\nOften implemented using Wavelet Transforms (specifically the Discrete Wavelet Transform - DWT)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mra-the-nested-subspace-concept",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mra-the-nested-subspace-concept",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "MRA: The Nested Subspace Concept",
    "text": "MRA: The Nested Subspace Concept\n\nMRA is built upon a sequence of nested subspaces \\(V_j\\) in \\(L^2(\\mathbb{R})\\).\nThese subspaces represent approximations of the signal at different resolutions.\nKey Properties:\n\nNesting: \\(\\dots \\subset V_2 \\subset V_1 \\subset V_0 \\subset V_{-1} \\subset V_{-2} \\subset \\dots\\)\nDensity: The union of \\(V_j\\) is dense in \\(L^2(\\mathbb{R})\\).\nSeparation: The intersection of \\(V_j\\) is \\(\\{0\\}\\).\nScaling: \\(f(t) \\in V_j \\iff f(2t) \\in V_{j-1}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#the-scaling-function-phi",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#the-scaling-function-phi",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The Scaling Function (\\(\\phi\\))",
    "text": "The Scaling Function (\\(\\phi\\))\n\nEach subspace \\(V_j\\) is generated by scaled and translated versions of a single function called the scaling function, \\(\\phi(t)\\).\n\\(\\{\\phi(t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(V_0\\).\n\\(\\{\\sqrt{2^j}\\phi(2^j t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(V_j\\).\nThe scaling function captures the “smooth” or low-frequency components – the approximation of the signal at a given scale."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#the-wavelet-function-psi",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#the-wavelet-function-psi",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The Wavelet Function (\\(\\psi\\))",
    "text": "The Wavelet Function (\\(\\psi\\))\n\nThe difference in information between two successive approximation spaces (\\(V_j\\) and \\(V_{j-1}\\)) is captured by the detail spaces, \\(W_j\\).\n\\(V_{j-1} = V_j \\oplus W_j\\), where \\(W_j\\) is the orthogonal complement of \\(V_j\\) in \\(V_{j-1}\\).\nThere exists a function \\(\\psi(t) \\in W_0\\), the wavelet function (or mother wavelet).\n\\(\\{\\psi(t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(W_0\\).\n\\(\\{\\sqrt{2^j}\\psi(2^j t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(W_j\\).\nThe wavelet function captures the “details” or high-frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#linking-phi-and-psi-two-scale-equations",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#linking-phi-and-psi-two-scale-equations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Linking \\(\\phi\\) and \\(\\psi\\): Two-Scale Equations",
    "text": "Linking \\(\\phi\\) and \\(\\psi\\): Two-Scale Equations\n\nThe scaling and wavelet functions are related through coefficients \\(h_k\\) and \\(g_k\\).\n\\(\\phi(t) = \\sqrt{2} \\sum_k h_k \\phi(2t - k)\\)\n\\(\\psi(t) = \\sqrt{2} \\sum_k g_k \\phi(2t - k)\\)\nThese equations show how functions at one scale (left side) are constructed from functions at a finer scale (right side).\nThe coefficients \\(h_k\\) and \\(g_k\\) are critical – they define the specific wavelet and are the impulse responses of filters used in discrete implementations."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#from-math-to-practice-filters",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#from-math-to-practice-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "From Math to Practice: Filters",
    "text": "From Math to Practice: Filters\n\nThe sequences \\(h_k\\) and \\(g_k\\) correspond to digital filters:\n\n\\(H = \\{h_k\\}\\) is a low-pass filter.\n\\(G = \\{g_k\\}\\) is a high-pass filter.\n\nThese filters are designed such that \\(G\\) is derived from \\(H\\) (for orthonormal wavelets, \\(g_k = (-1)^k h_{N-1-k}\\)).\nApplying the low-pass filter and downsampling corresponds to projecting the signal onto \\(V_j\\).\nApplying the high-pass filter and downsampling corresponds to projecting the signal onto \\(W_j\\)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#discrete-mra-mallats-algorithm",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#discrete-mra-mallats-algorithm",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Discrete MRA: Mallat’s Algorithm",
    "text": "Discrete MRA: Mallat’s Algorithm\n\nThe discrete implementation of MRA is efficiently computed using Mallat’s Algorithm (or the Fast Wavelet Transform - FWT).\nIt’s a pyramidal algorithm based on filter banks and downsampling/upsampling.\nDecomposes the discrete signal into approximation (\\(A\\)) and detail (\\(D\\)) coefficients at successive levels."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-decomposition",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-decomposition",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mallat’s Algorithm: Decomposition",
    "text": "Mallat’s Algorithm: Decomposition\nStarting with signal \\(x[n]\\) (considered \\(A_0\\)):\n\nConvolve \\(A_j\\) with low-pass filter \\(H\\) and high-pass filter \\(G\\).\nDownsample outputs by 2 (\\(\\downarrow 2\\)).\n\nOutput of \\(H \\to \\downarrow 2\\) gives approximation coefficients \\(A_{j+1}\\).\nOutput of \\(G \\to \\downarrow 2\\) gives detail coefficients \\(D_{j+1}\\).\n\nRepeat the process on the approximation coefficients \\(A_{j+1}\\) for the next level.\n\n\\[ A_{j+1} = (A_j * H) \\downarrow 2 \\] \\[ D_{j+1} = (A_j * G) \\downarrow 2 \\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-reconstruction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-reconstruction",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mallat’s Algorithm: Reconstruction",
    "text": "Mallat’s Algorithm: Reconstruction\nReconstructing signal \\(A_j\\) from \\(A_{j+1}\\) and \\(D_{j+1}\\):\n\nUpsample \\(A_{j+1}\\) and \\(D_{j+1}\\) by 2 (\\(\\uparrow 2\\), insert zeros).\nConvolve upsampled coefficients with reconstruction filters \\(H'\\) and \\(G'\\).\nAdd the results to get \\(A_j\\).\nRepeat until the original signal \\(A_0\\) is reconstructed.\n\n\\[ A_j = (A_{j+1} \\uparrow 2 * H') + (D_{j+1} \\uparrow 2 * G') \\] (For orthonormal wavelets, \\(H'\\) and \\(G'\\) are time-reversed \\(H\\) and \\(G\\))"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mra-architecture",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mra-architecture",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "MRA Architecture",
    "text": "MRA Architecture"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#why-mra-for-ecg",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#why-mra-for-ecg",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Why MRA for ECG?",
    "text": "Why MRA for ECG?\n\nECG signals are non-stationary and have features at different scales:\n\nQRS complex: Sharp, high frequency, short duration.\nP and T waves: Broader, lower frequency, longer duration.\nBaseline wander: Very low frequency.\nMuscle noise: High frequency.\n\nMRA naturally separates these components into different frequency bands (detail levels), making analysis easier."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-denoising",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-denoising",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Applications of MRA in ECG: Denoising",
    "text": "Applications of MRA in ECG: Denoising\n\nNoise (powerline, muscle, baseline wander) occupies different frequency bands.\nDecompose noisy ECG using MRA.\nNoise components are isolated in specific detail coefficients:\n\nHigh-frequency noise in fine detail levels.\nBaseline wander in coarse approximation/detail levels.\n\nApply thresholding to the noise-dominated coefficients (e.g., set small values to zero).\nReconstruct the signal from the modified coefficients to get a denoised ECG."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-feature-extraction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-feature-extraction",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Applications of MRA in ECG: Feature Extraction",
    "text": "Applications of MRA in ECG: Feature Extraction\n\nDifferent ECG waves are highlighted in different MRA levels:\n\nQRS complex: Often prominent in mid-to-high frequency detail coefficients.\nP and T waves: Appear in lower frequency detail coefficients or approximation coefficients.\n\nAnalyze coefficients at relevant scales:\n\nDetect QRS peaks by finding local maxima in specific detail levels.\nDelineate P and T waves by analyzing the shape and zero-crossings of coefficients at coarser scales.\n\nExtract clinically relevant features (intervals, amplitudes) from the detected waves."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#other-applications-in-ecg",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#other-applications-in-ecg",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Other Applications in ECG",
    "text": "Other Applications in ECG\n\nCompression: MRA provides a sparse representation; many coefficients are small and can be discarded or quantized, reducing data size.\nAbnormality Detection and Classification: Features derived from the distribution or patterns of coefficients across different MRA levels can be used as input for machine learning algorithms to classify arrhythmias or other heart conditions."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#practical-implementation-steps",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#practical-implementation-steps",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Practical Implementation Steps",
    "text": "Practical Implementation Steps\n\nAcquisition & Preprocessing: Get digitized ECG data. Basic filtering might precede MRA if necessary.\nChoose Wavelet: Select a wavelet family (e.g., Daubechies ‘dbN’, Symlets ‘symN’). Consider similarity of wavelet shape to ECG features (e.g., QRS) and vanishing moments.\nDetermine Decomposition Levels: Choose the number of levels (\\(J\\)) based on sampling frequency (\\(F_s\\)) and the frequency bands of interest. Detail level \\(j\\) covers frequencies approx. \\([F_s/2^{j+1}, F_s/2^j]\\).\nPerform Decomposition: Apply Mallat’s algorithm (DWT) to get approximation and detail coefficients.\nAnalyze/Process Coefficients: Apply denoising (thresholding) or feature extraction techniques to the relevant coefficients.\nReconstruct (Optional): Reconstruct the signal if a filtered or modified ECG is needed."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#implementation-wavelet-choice-levels",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#implementation-wavelet-choice-levels",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Implementation: Wavelet Choice & Levels",
    "text": "Implementation: Wavelet Choice & Levels\n\nWavelet Family: Daubechies (db) and Symlets (sym) are common for ECG. ‘db4’ is often cited for its similarity to the QRS complex.\nNumber of Levels (\\(J\\)):\n\nHigher levels give coarser approximations and lower frequency details.\nChoose \\(J\\) so that key ECG features fall into specific, separable detail levels.\nE.g., for a 360 Hz ECG, QRS (10-50 Hz) might be in D3-D5, P/T (1-10 Hz) in D5-D7, baseline wander (&lt;1 Hz) in A7 or D8+."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#conclusion",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#conclusion",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Conclusion",
    "text": "Conclusion\n\nMultiresolution Analysis is a powerful technique for analyzing non-stationary signals like ECG.\nIt decomposes the signal into different frequency bands/scales using scaling and wavelet functions.\nImplemented efficiently via Mallat’s algorithm (DWT).\nEnables effective ECG denoising by isolating noise at specific levels.\nFacilitates robust feature extraction (P, QRS, T) by highlighting them in different detail coefficients.\nA fundamental tool in modern automated ECG analysis systems."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis\n\n# Elegir wavelet y nivel de descomposición\nwavelet = \"db4\"\nmax_level = 3\n\n# Descomposición multiresolución\ncoeffs = pywt.wavedec(ecg001, wavelet, level=max_level)\n# coeffs[0]: coeficientes de aproximación al nivel 3 (cA3)\n# coeffs[1:], coeficientes de detalle en niveles 3, 2, 1 (cD3, cD2, cD1)\n\n# Reconstruir aproximación al nivel máximo\narr_approx = [coeffs[0]] + [np.zeros_like(c) for c in coeffs[1:]]\napprox = pywt.waverec(arr_approx, wavelet)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis\n\n\n# Reconstruir detalles por cada nivel\ndetails = []\nfor i in range(1, max_level + 1):\n    arr_detail = [np.zeros_like(c) for c in coeffs]\n    arr_detail[i] = coeffs[i]\n    detail = pywt.waverec(arr_detail, wavelet)\n    details.append(detail)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-4",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-4",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---element-wise-operation",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---element-wise-operation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Element-Wise Operation",
    "text": "Basic Mathematic - Element-Wise Operation\n\n\n\n\n\n\n\nDefinition\n\n\nOperation involving one or more images is carried out on a pixel-bypixel basis\n\n\n\n\n\\[\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{bmatrix} \\oplus \\begin{bmatrix} b_{11} & b_{12} \\\\  b_{21} & b_{22}\\end{bmatrix} = \\begin{bmatrix} a_{11}+b_{11} & a_{12}+b_{12} \\\\  a_{21}+b_{21} & a_{22}+b_{22}\\end{bmatrix} \\]\n\\[\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{bmatrix} \\odot \\begin{bmatrix} b_{11} & b_{12} \\\\  b_{21} & b_{22}\\end{bmatrix} = \\begin{bmatrix} a_{11}.b_{11} & a_{12}.b_{12} \\\\  a_{21}.b_{21} & a_{22}.b_{22}\\end{bmatrix} \\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---linear-operations",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---linear-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Linear Operations",
    "text": "Basic Mathematic - Linear Operations\n\n\n\n\n\n\n\nDefinition\n\n\nGiven two arbitrary constants, \\(\\alpha_1\\) and \\(\\alpha_2\\), and two arbitrary images \\(f_1\\left(x,y\\right)\\) and \\(f_2\\left(x,y\\right)\\), \\(\\varkappa\\) is said to be a linear operator if:\n\\[ \\begin{equation}\\begin{split} \\varkappa\\left[\\alpha_1 f_1\\left(x,y\\right) + \\alpha_2 f_2\\left(x,y\\right)\\right] & =  \\alpha_1 \\varkappa\\left[ f_1\\left(x,y\\right)\\right] + \\alpha_2 \\varkappa\\left[f_2\\left(x,y\\right)\\right] \\\\ & = \\alpha_1 g_1\\left(x,y\\right) + \\alpha_2 g_2\\left(x,y\\right) \\end{split}\\end{equation} \\]\n\n\n\n\nSupose \\(\\alpha_1 = 5\\), \\(\\alpha_2 = 2\\), \\(\\varkappa = max\\) and consider:\n\\[f_1 = \\begin{bmatrix}0 & -1 \\\\2 & 4\\end{bmatrix}\\], \\[f_2 = \\begin{bmatrix}30 & 4 \\\\-2 & -3\\end{bmatrix}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Adding",
    "text": "Basic Mathematic - Adding"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Adding",
    "text": "Basic Mathematic - Adding\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_ray_chest = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/female-chest-x-ray.jpg\")\nplt.imshow(x_ray_chest, cmap=\"gray\")\nplt.show()\nimage_synt1 = 100*np.abs(np.random.normal(0, 1, x_ray_chest.shape))\nplt.imshow(image_synt1)\nplt.show()\nfinal_image = np.uint8(x_ray_chest+image_synt1)\nplt.imshow(final_image)\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---multiplying",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---multiplying",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Multiplying",
    "text": "Basic Mathematic - Multiplying\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_ray_chest = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/female-chest-x-ray.jpg\")\nmask = np.uint8(np.zeros(x_ray_chest.shape))\nmask[400:700, 250:600, :]=1\nplt.imshow(x_ray_chest)\nplt.show()\nplt.imshow(255*mask)\nplt.show()\nplt.imshow(np.multiply(x_ray_chest,mask))\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---basic-transformation",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---basic-transformation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Basic transformation",
    "text": "Basic Mathematic - Basic transformation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[x_{\\text{rescaled}} = n_{\\min} + \\frac{(x - \\min)}{\\max - \\min} \\, (n_{\\max} - n_{\\min})\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\nImagesCode\n\n\n\n\n\n\n\n\nExp=1.2\n\n\n\n\n\n\n\nExp=0.2\n\n\n\n\n\n\n\nExp=0.30\n\n\n\n\n\n\n\n\n\nExp=0.5\n\n\n\n\n\n\n\nOriginal\n\n\n\n\n\n\n\nExp=1.1\n\n\n\n\n\n\n\n\nx_ray_chest_gray = cv2.cvtColor(x_ray_chest, cv2.COLOR_BGR2GRAY)\nplt.imshow(x_ray_chest_gray, cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,1.1), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,1.2), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.2), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.3), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.5), cmap=\"gray\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood Operations",
    "text": "Neighborhood Operations\n\nFor example, suppose that the specified operation is to compute the average value of the pixels in a rectangular neighborhood of size mn × centered on \\(\\left(x,y\\right)\\). The coordinates of pixels in this region are the elements of set \\(S_{xy}\\).\n\n\nImagescode\n\n\n\n\n\n\n\n\n\nElderly woman image\n\n\n\n\n\n\n\n\n\n\nGray-scale image\n\n\n\n\n\n\n\n\n#|\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nplt.imshow(elderly)\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nOriginalAveragingCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN = 10\nkernel = np.ones((N,N),np.float32)/(N*N)\ndst = cv2.filter2D(elderly_gray,-1,kernel)\nplt.imshow(dst, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-3",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nOriginalMedianCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN=11\n\ndst1 = cv2.medianBlur(elderly_gray, N)\nplt.imshow(dst1, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-4",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-4",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nMeanMedian"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-5",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-5",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-6",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-6",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: http://datagenetics.com/blog/august32013/index.html"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge dection",
    "text": "Edge dection"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge dection",
    "text": "Edge dection"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge dection",
    "text": "Edge dection\n\nImages Grad YImages Grad XImages Grad Trunc YImages Trunc Grad XCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndst = cv2.Sobel(elderly_gray, cv2.CV_16S, 1, 0,  ksize=3, scale=1, delta=0, borderType= cv2.BORDER_DEFAULT)\ndst1 = np.uint8(255*dst/np.max(dst))\nplt.imshow(dst1, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram",
    "text": "Histogram\n\nHistogramCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram",
    "text": "Histogram\n\nFirst thing to doImageCodeRecommended Reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n3\n2\n2\n1\n1\n0\n3\n0\n1\n\n\n2\n2\n2\n3\n2\n2\n0\n2\n2\n1\n\n\n0\n3\n2\n0\n1\n1\n3\n1\n1\n1\n\n\n3\n0\n2\n0\n2\n3\n1\n0\n2\n1\n\n\n2\n2\n0\n0\n3\n1\n3\n1\n3\n1\n\n\n3\n3\n2\n0\n3\n0\n3\n2\n0\n3\n\n\n3\n3\n1\n1\n2\n3\n0\n3\n1\n3\n\n\n3\n1\n3\n3\n2\n0\n3\n0\n2\n1\n\n\n2\n1\n1\n3\n3\n1\n3\n2\n2\n1\n\n\n0\n3\n2\n2\n1\n1\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\n\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"red\")\nplt.show()\n\n\n\ncv2.calcHist(images, channels, mask, histSize, ranges)\nHelp Docs Opencv"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-3",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram",
    "text": "Histogram\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef adjust_gamma(image, gamma=1.0):\n   invGamma = 1.0 / gamma\n   table = np.array([((i / 255.0) ** invGamma) * 255\n      for i in np.arange(0, 256)]).astype(\"uint8\")\n\n   return cv2.LUT(image, table)\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"red\")\nplt.show()\nelderly_gray_light = adjust_gamma(image=elderly_gray, gamma=2)\nplt.imshow(elderly_gray_light, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_light = cv2.calcHist(elderly_gray_light, [0], None, [256], [0,256])\nplt.plot(elderly_hist_light, color=\"red\")\nplt.show()\nelderly_gray_dark = adjust_gamma(image=elderly_gray, gamma=0.3)\nplt.imshow(elderly_gray_dark, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_dark = cv2.calcHist(elderly_gray_dark, [0], None, [256], [0,256])\nplt.plot(elderly_hist_dark, color=\"red\")\nplt.show()\nelderly_gray_lowcontrast=np.uint8(0.1*elderly_gray)+172\nplt.imshow(elderly_gray_lowcontrast, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_lowcontrast = cv2.calcHist(elderly_gray_lowcontrast, [0], None, [256], [0,256])\nplt.plot(elderly_hist_lowcontrast, color=\"red\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram Equalization",
    "text": "Histogram Equalization\n\n\n\n\n\n\n\nAlgorithm\n\n\n\nCalculate Histogram: Calculate the histogram of the original image, showing the frequency distribution of each intensity level.\nCalculate Cumulative Distribution Function (CDF): Calculate the cumulative distribution function (CDF) of the histogram. The CDF represents the cumulative sum of frequencies for each intensity level.\nEqualization: For each pixel in the original image, calculate the new intensity value using the formula: \\[New_value = (CDF(old value) * (L-1))\\] where L is the number of intensity levels (e.g., 256 for an 8-bit image).\nAssign New Values: Assign the new intensity values calculated in step 3 to the equalized image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram Equalization",
    "text": "Histogram Equalization\n\nImagesCodeRecommended Reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.imshow(elderly_gray_lowcontrast, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\nplt.plot(elderly_hist_lowcontrast, color=\"red\")\nplt.show()\n\nelderly_hist_equ = cv2.equalizeHist(elderly_gray_lowcontrast)\nplt.imshow(elderly_hist_equ, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\nelderly_hist_equ = cv2.calcHist(elderly_hist_equ, [0], None, [256], [0,256])\nplt.plot(elderly_hist_equ, color=\"red\")\nplt.show()\n\n\n\nHistogram Equalization OPENCV tutorial"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-matching",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-matching",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram Matching",
    "text": "Histogram Matching\n\nExplainAlgorithmResultCode\n\n\n\n\n\nTaken from PyImageSearch\n\n\n\n\nStep 1: Calculate Histograms Compute the histograms of the source image (Hs) and target image (Ht) for intensity values (r).\nStep 2: Calculate CDFs Compute the cumulative distribution functions (CDFs) for the source image (CDFs) and target image (CDFt).\nStep 3: Establish Correspondence Find the corresponding intensity values between the source and target images using the inverse CDF of the target image.\nStep 4: Apply Transformation Apply the intensity transformation to the source image using the established correspondence.\nStep 5: Verify Similarity Calculate the mean absolute difference between the transformed source image and the target image to verify their similarity.\n\n\n\n\n\n\n\n\n\n\n\n(np.float64(-0.5), np.float64(1199.5), np.float64(799.5), np.float64(-0.5))\n\n\n\n\n\n\n\n\n\nDiferencia media absoluta: 4.501011458333333\n\n\n\n\n\n# Cargar la imagen fuente y objetivo\nimg_s = cv2.imread('imagen_fuente.jpg')\nimg_t = cv2.imread('imagen_objetivo.jpg')\n\n# Calcula los histogramas\nhist_s = cv2.calcHist([img_s], [0], None, [256], [0, 256])\nhist_t = cv2.calcHist([img_t], [0], None, [256], [0, 256])\n\n# Calcula las CDF\ncdf_s = np.cumsum(hist_s)\ncdf_t = np.cumsum(hist_t)\n\n# Establece la correspondencia\nr_t = np.interp(cdf_s, cdf_t, np.arange(256))\n\n# Aplica la transformación\nimg_t_match = cv2.LUT(img_s, r_t)\n\n# Verifica la similitud\ndiff = np.mean(np.abs(img_t_match - img_t))\n\nprint(f'Diferencia media absoluta: {diff}')"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción al procesado de señales e imágenes biomédicas.\nFundamentos procesado de señales e imágenes biomédicas\nExtracción de características de señales biomédicas.\nExtracción de características de imágenes biomédicas."
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluación final\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nExamen parcial 1 (15%)\nExamen parcial 2 (15%)\nExamen final (20%)\nLaboratorios (30%)\nProyecto Final (20%)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (15%)\nLaboratorios (15%)\nProyecto final (20%)\n\n\nExamen Parcial 1 (15%)\nExamen Parcial 2 (15%)\nExamen final (20%)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nLunes 2:30pm-4:00pm F-105. Martes 2:30pm-4:00pm D-201.\nLaboratorio\nJUEVES 2:30pm-4:00pm. I1-304\n\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#bibliografía",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\nDefinition\n\n\n\nTwo-dimensional function, f(x, y)\nWhere x and y are spatial coordinates.\nThe amplitude of f at any pair of coordinates (x, y) is called the intensity.\n\n\n\n\n\n\n\n\n\n\n\n\nThe digital image\n\n\nIf the coordinates and the intensity are discrete quantities the image turns into a digital image."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\nDefinition\n\n\nA digital image is composed by a finite number of elements called PIXEL.\n\n\n\n\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\n\nDepth\n\n\n\nA digital image is composed by a finite number of elements called PIXEL. Bpp( Bits per pixel)\n\n1bpp. B/W image, monochrome.\n2bpp. CGA Image.\n4bpp. Minimun for VGA standard.\n8bpp. Super-VGA image.\n24bpp. Truecolor image.\n48bpp. Professional-level images."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\n\nColor Space\n\n\nHow can i represent the color\n\nRGB.\nCMYK.\nHSV.\nAmong others."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"image01.tif\")\nfig001 = plt.figure()\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"lena.tif\")\nRGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig002 = plt.figure()\nplt.imshow(RGB_img)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nThe paradigm surrounding the conceptualization of light and perception has undergone significant evolution.\nInitially, the prevailing understanding within humanity posited that visual stimuli emanated from the eye itself.\nHowever, contemporary knowledge has elucidated that light originates from external sources, undergoes reflection from objects within the environment, and is subsequently captured by the eye."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nImportant\n\n\nWe also understand that light is a type of electromagnetic radiation, and its wavelength falls within a range from 400 nanometers to 700 nanometers.\n\n\n\n\n\nTaken from Corke 2023"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nImportant\n\n\n\nThe most common way light is made is by something getting really hot. This makes energy that comes out as light.\nSome important term are:\n\nAbsortion: It is the fraction of light which a body absorbs depending on the wavelength.\nReflectance: It is the fraction of the incoming light which a body reflects. It’s a number between 0 to 1 and also depends on wavelength.\nLuminance: It is the fraction of the incoming light which a surface reflects. It’s a function of absortion and reflectance, and because of that luminance depends on wavelength."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nThe eye\n\n\n\nOur eye has two types of cells. Cones and Rods.\nCones are the most sensitive cells but above all these are color sensitive.\nRods responds only two intensity and they used on night, mostly.\nHumans, like most primates, are trichomats. This means that humans have three types of cones (Long, Medium and shorts).\n\n65% of longs (Sense red)\n33% of mediums (Sense green)\n2% of shortsv(Sense blue)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nThe artificial eye\n\n\n\n\n\nTaken from Corke 2023\n\n\n\n\n\n\nThe currents from each sensor are function of the luminance and the spectral response filter."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\n\n\n\n\n\n\nDefinition\n\n\nSampling: Digitalization of the spatial coordinates.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nQuantiazation: Digitalization of the light intensity (amplitude)."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1bit\n\n\n\n\n\n\n\n\n\n2bit\n\n\n\n\n\n\n\n\n\n3bit\n\n\n\n\n\n\n\n\n\n4bit\n\n\n\n\n\n\n\n\n\n\n\n5bit\n\n\n\n\n\n\n\n\n\n6bit\n\n\n\n\n\n\n\n\n\n7bit\n\n\n\n\n\n\n\n\n\n8bit"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Linear indexing",
    "text": "Linear indexing\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\nFrom normal to linear\n\n\n\\[\\alpha = My+x\\]\n\n\n\n\n\n\n\n\n\n\n\n\nFrom linear to normal\n\n\n\\[x = \\alpha \\bmod M\\]\n\\[y = \\frac{\\alpha - x}{M}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Spatial resolution",
    "text": "Spatial resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Intensity resolution",
    "text": "Intensity resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Intensity resolution",
    "text": "Intensity resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "“A simple problem”",
    "text": "“A simple problem”\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "“A simple problem”",
    "text": "“A simple problem”\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\nNeighborhood\n\n\n\n\n\n\n\n\n\n\nN4\n\n\n\n\n\n\n\nND\n\n\n\n\n\n\n\nN8\n\n\n\n\n\n\nFigura 1"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Neighborhood",
    "text": "Relationships between pixels – Neighborhood\n\n\n\n\n\n\n\nNeighborhood\n\n\n\n\n\n\n\n\n\n\nN4-\\(N_4\\left(p\\right)\\)\n\n\n\n\n\n\n\nND-\\(N_D\\left(p\\right)\\)\n\n\n\n\n\n\n\nN8-\\(N_8\\left(p\\right)\\)\n\n\n\n\n\n\nFigura 2: Neighborhoods"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Adjacency",
    "text": "Relationships between pixels – Adjacency\n\n\n\n\n\n\n\nRules for adjecency\n\n\n\n4-Adjecncy: Two pixels p and q with values from V are 4-adjacent if q is in the set \\(N_4\\left(p\\right)\\)\n8-adjacency. Two pixels p and q with values from V are 8-adjacent if q is in the set \\(N_8\\left(p\\right)\\)\nm-adjacency (also called mixed adjacency). Two pixels p and q with values from V are m-adjacent if:\n\nq is in \\(N_4\\left(p\\right)\\).\nq is in \\(N_D\\left(p\\right)\\) and the set \\(N_4\\left(p\\right) \\cap N_4\\left(q\\right)\\) has no pixels whose values are from V."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\nAdjacency"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\n\n\n\nA4\n\n\n\n\n\n\n\n\n\n\n\nA8\n\n\n\n\n\n\n\n\n\n\n\n\n\nA-m"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Path",
    "text": "Relationships between pixels – Path\n\n\n\n\n\n\n\nDigital path\n\n\nIt is a sequence of adjacent pixels.\n\\[\\left(x_0, y_0\\right), \\left(x_1, y_1\\right), \\left(x_2, y_2\\right), \\dots \\left(x_n, y_n\\right)\\]\nIf \\(\\left(x_0, y_0\\right)=\\left(x_n, y_n\\right)\\) the path is known as closed path\nLet S represent a subset of pixels in an image. Two pixels p and q are said to be connected in S if there exists a path between them consisting entirely of pixels in S."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Path, Connected Subset",
    "text": "Relationships between pixels – Path, Connected Subset"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Regions",
    "text": "Relationships between pixels – Regions"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Boundary",
    "text": "Relationships between pixels – Boundary"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Distance",
    "text": "Relationships between pixels – Distance\n\n\n\n\n\n\n\nDistance\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\nDistance\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nSignals can be analyzed in both time domain and frequency domain.\nThe frequency content of a signal describes how different frequency components contribute to the overall signal.\nApplications in biomedical signals, audio processing, communications, and image processing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-in-time-domain",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-in-time-domain",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution in Time Domain",
    "text": "Convolution in Time Domain\n\nConvolution is a fundamental operation in signal processing.\nGiven two signals \\(x(t)\\) and \\(h(t)\\), their convolution is defined as:\n\\[ y(t) = x(t) * h(t) = \\int_{-\\infty}^{\\infty} x(\\tau) h(t - \\tau) d\\tau \\]\nIn discrete-time, convolution is:\n\\[ y[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n-k] \\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-theorem",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution Theorem",
    "text": "Convolution Theorem\n\nConvolution in time domain corresponds to multiplication in frequency domain:\n\\[ X(f) H(f) = Y(f) \\]\nThis property is crucial in filter design and system analysis.\n\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\n\n(-1.0, 4.0)\n\n\n(-1.0, 4.0)\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\nConvolution requiere the representation of the signal in a sum of impulse functions.\nFourier series represents periodic signals as a sum of sinusoids:\n\\[ x(t) = \\sum_{n=-\\infty}^{\\infty} C_n e^{jn\\omega_0 t} \\]\nwhere \\(C_n\\) are the Fourier coefficients.\nDecomposing a signal into sinusoidal components allows frequency analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#fourier-coefficients",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#fourier-coefficients",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fourier Coefficients",
    "text": "Fourier Coefficients\n\nThe Fourier coefficients \\(C_n\\) are computed as:\n\\[ C_n = \\frac{1}{T} \\int_{0}^{T} x(t) e^{-jn\\omega_0 t} dt \\]\nDetermines how much of each frequency is present in the signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-fourier-series-expansion",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-fourier-series-expansion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example of Fourier Series Expansion",
    "text": "Example of Fourier Series Expansion\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example 2 of Fourier Series",
    "text": "Example 2 of Fourier Series\n\n\n(array([-5.,  0.,  5., 10., 15., 20., 25., 30., 35.]), [Text(-5.0, 0, '−5'), Text(0.0, 0, '0'), Text(5.0, 0, '5'), Text(10.0, 0, '10'), Text(15.0, 0, '15'), Text(20.0, 0, '20'), Text(25.0, 0, '25'), Text(30.0, 0, '30'), Text(35.0, 0, '35')])\n\n\n(array([4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5]), [Text(0, 4.5, '4.5'), Text(0, 5.0, '5.0'), Text(0, 5.5, '5.5'), Text(0, 6.0, '6.0'), Text(0, 6.5, '6.5'), Text(0, 7.0, '7.0'), Text(0, 7.5, '7.5'), Text(0, 8.0, '8.0'), Text(0, 8.5, '8.5')])\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example 2 of Fourier Series",
    "text": "Example 2 of Fourier Series\n\n\n(array([-40., -30., -20., -10.,   0.,  10.,  20.,  30.,  40.]), [Text(-40.0, 0, '−40'), Text(-30.0, 0, '−30'), Text(-20.0, 0, '−20'), Text(-10.0, 0, '−10'), Text(0.0, 0, '0'), Text(10.0, 0, '10'), Text(20.0, 0, '20'), Text(30.0, 0, '30'), Text(40.0, 0, '40')])\n\n\n(array([4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5]), [Text(0, 4.5, '4.5'), Text(0, 5.0, '5.0'), Text(0, 5.5, '5.5'), Text(0, 6.0, '6.0'), Text(0, 6.5, '6.5'), Text(0, 7.0, '7.0'), Text(0, 7.5, '7.5'), Text(0, 8.0, '8.0'), Text(0, 8.5, '8.5')])\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Linearity",
    "text": "Linearity\n\nIf \\(f_1(x)\\) and \\(f_2(x)\\) have Fourier series,\nThen for any constants \\(a, b\\),\n\\(a f_1(x) + b f_2(x)\\) has a Fourier series,\nWith coefficients scaled accordingly."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#time-shifting",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#time-shifting",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time Shifting",
    "text": "Time Shifting\n\nIf \\(f(x)\\) has Fourier coefficients \\(a_n, b_n\\),\nThen \\(f(x - x_0)\\) has coefficients:\n\\(a_n \\cos(n\\omega x_0) + b_n \\sin(n\\omega x_0)\\),\nAnd \\(b_n \\cos(n\\omega x_0) - a_n \\sin(n\\omega x_0)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-scaling",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-scaling",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Frequency Scaling",
    "text": "Frequency Scaling\n\nIf \\(g(x) = f(cx)\\),\nThen the period scales by \\(c\\),\nThe fundamental frequency changes to \\(c\\omega\\),\nFourier coefficients adjust accordingly."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#differentiation-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#differentiation-property",
    "title": "Sistemas y Señales Biomédicos",
    "section": "** Differentiation Property**",
    "text": "** Differentiation Property**\n\nIf \\(f(x)\\) is differentiable,\nThen \\(f'(x)\\) has Fourier series,\nWith coefficients scaled as \\(n a_n, n b_n\\),\nHigher frequencies get amplified."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#integration-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#integration-property",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Integration Property",
    "text": "Integration Property\n\nIf \\(f(x)\\) has a Fourier series,\nThen \\(\\int f(x) dx\\) has a Fourier series,\nWith coefficients scaled as \\(\\frac{a_n}{n}, \\frac{b_n}{n}\\),\nLower frequencies get emphasized."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#parsevals-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#parsevals-theorem",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Parseval’s Theorem",
    "text": "Parseval’s Theorem\n\nThe total signal energy is conserved,\nEnergy in time domain equals energy in frequency domain,\nGiven by:\n\\(\\sum (a_n^2 + b_n^2) = \\frac{1}{T} \\int |f(x)|^2 dx\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-property",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution Property",
    "text": "Convolution Property\n\nConvolution in time domain,\nIs multiplication in Fourier series coefficients,\nIf \\(f_1\\) and \\(f_2\\) are convoluted,\nTheir Fourier coefficients multiply component-wise."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#discrete-time-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#discrete-time-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Discrete Time Fourier Series",
    "text": "Discrete Time Fourier Series\n\nRepresents periodic discrete signals using harmonics.\nExtends Fourier series to discrete-time domain.\nFundamental in digital signal processing.\nBasis for the Discrete Fourier Transform (DFT)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-expression",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-expression",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Mathematical Expression",
    "text": "Mathematical Expression\n\nA periodic sequence \\(x[n]\\) can be expressed as:\n\\[x[n] = \\sum_{k=0}^{N-1} C_k e^{j(2\\pi k n / N)}\\].\nThe coefficients \\(C_k\\) are computed as:\n\\(C_k = \\frac{1}{N} \\sum_{n=0}^{N-1} x[n] e^{-j(2\\pi k n / N)}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#periodicity-and-symmetry",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#periodicity-and-symmetry",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Periodicity and Symmetry",
    "text": "Periodicity and Symmetry\n\nThe coefficients \\(C_k\\) repeat every \\(N\\).\nEnsures correct reconstruction of signals.\nExplains frequency domain representation.\nBasis for spectral analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#key-properties",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#key-properties",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Key Properties",
    "text": "Key Properties\n\nLinearity: Superposition holds.\nTime Shift: Causes phase shift in coefficients.\nParseval’s Theorem: Energy conservation.\nConvolution: Time convolution → Frequency multiplication."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-domain-interpretation",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-domain-interpretation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Frequency Domain Interpretation",
    "text": "Frequency Domain Interpretation\n\n\\(C_k\\) represents discrete frequency content.\nThe spectrum consists of \\(N\\) harmonics.\nResolution improves with larger \\(N\\).\nEssential for analyzing periodic discrete signals."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#comparison-with-continuous-case",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#comparison-with-continuous-case",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Comparison with Continuous Case",
    "text": "Comparison with Continuous Case\n\nDTFS applies to discrete periodic signals.\nContinuous Fourier series applies to continuous functions.\nBoth represent signals as sums of sinusoids.\nDTFS is used in digital communications and audio processing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-th-dtfs",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-th-dtfs",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example of th DTFS",
    "text": "Example of th DTFS\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\n\n\n\nDTFS Coefficients:\n\n\nC[0] = 2.0000+0.0000j\nC[1] = -0.6036-0.6036j\nC[2] = 0.0000+0.0000j\nC[3] = 0.1036-0.1036j\nC[4] = 0.0000+0.0000j\nC[5] = 0.1036+0.1036j\nC[6] = 0.0000+0.0000j\nC[7] = -0.6036+0.6036j"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-02",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-02",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example 02",
    "text": "Example 02\n\n\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found.\nfindfont: Font family 'Fira Code' not found."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#conceptual-foundation",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#conceptual-foundation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Conceptual Foundation",
    "text": "Conceptual Foundation\n\nFourier Series represents periodic signals in terms of sinusoids.\nAs period \\(T \\to \\infty\\), the signal becomes aperiodic.\nThe Fourier Transform generalizes Fourier Series to aperiodic signals.\nTransforms signals from time to frequency domain."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-transition",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-transition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Mathematical Transition",
    "text": "Mathematical Transition\n\nFourier Series of a periodic signal:\n\\[f(x) = \\sum_{n=-\\infty}^{\\infty} C_n e^{j(2\\pi n x / T)}\\].\nAs \\(T \\to \\infty\\), frequency spacing \\(\\frac{1}{T}\\) → differential.\nLeads to the Fourier Transform:\n\\[F(\\omega) = \\int_{-\\infty}^{\\infty} f(x) e^{-j\\omega x} dx\\]."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-spectrum-interpretation",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-spectrum-interpretation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Frequency Spectrum Interpretation",
    "text": "Frequency Spectrum Interpretation\n\nFourier Series: discrete frequency spectrum.\nFourier Transform: continuous frequency spectrum.\nCoefficients \\(C_n\\) become the function \\(F(\\omega)\\).\nAllows analysis of arbitrary signals in frequency domain."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#inverse-fourier-transform",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#inverse-fourier-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Inverse Fourier Transform",
    "text": "Inverse Fourier Transform\n\nRecovers time-domain signal from \\(F(\\omega)\\).\nDefined as:\n\\[f(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} F(\\omega) e^{j\\omega x} d\\omega\\].\nEnsures complete information preservation.\nBasis for signal reconstruction in DSP."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#energy-and-parsevals-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#energy-and-parsevals-theorem",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Energy and Parseval’s Theorem",
    "text": "Energy and Parseval’s Theorem\n\nEnergy conservation in time and frequency domains.\nParseval’s theorem states:\n\\[\\int |f(x)|^2 dx = \\frac{1}{2\\pi} \\int |F(\\omega)|^2 d\\omega\\]\nEnsures no energy loss between domains."
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-step",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-step",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Unit Step",
    "text": "Unit Step\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[u(t) =\n\\begin{cases}\n0, & t &lt; 0 \\\\\n1, & t \\geq 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[u[n] =\n\\begin{cases}\n0, & n &lt; 0 \\\\\n1, & n \\geq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-ramp",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-ramp",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Unit Ramp",
    "text": "Unit Ramp\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[u(t) =\n\\begin{cases}\n0, & t &lt; 0 \\\\\nt, & t \\geq 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[u[n] =\n\\begin{cases}\n0, & n &lt; 0 \\\\\nn, & n \\geq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#sync-function",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#sync-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sync Function",
    "text": "Sync Function\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[\\text{sinc}(t) =\n\\begin{cases}\n\\frac{\\sin(\\pi t)}{\\pi t}, & t \\neq 0 \\\\\n1, & t = 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\text{sinc}[n] =\n\\begin{cases}\n\\frac{\\sin(\\pi n)}{\\pi n}, & n \\neq 0 \\\\\n1, & n = 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#diracs-delta",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#diracs-delta",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Dirac’s Delta",
    "text": "Dirac’s Delta\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[\\delta(t) =\n\\begin{cases}\n+\\infty, & t = 0 \\\\\n0, & t \\neq 0\n\\end{cases}\\]\n\\(\\int_{-\\infty}^{\\infty} \\delta(t) dt = 1\\)\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\delta[n] =\n\\begin{cases}\n1, & n = 0 \\\\\n0, & n \\neq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-time",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-time",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – Translation in time",
    "text": "Basic Transformations on Singular signals – Translation in time"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-amplitude",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-amplitude",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – Translation in amplitude",
    "text": "Basic Transformations on Singular signals – Translation in amplitude"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-time",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-time",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – scailing in time",
    "text": "Basic Transformations on Singular signals – scailing in time"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-amplitude",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-amplitude",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – scailing in amplitude",
    "text": "Basic Transformations on Singular signals – scailing in amplitude"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#example",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\n\nQuestionSolutionCode for the graph 1/2Code for the graph 2/2\n\n\nHow can i create the following signal using only singular signals\n\n\n\n\n\n\n\n\n\n\n\n\\[x(t) = 5u(t) - 5(t-3)\\]\n\n\n\nt = np.linspace(-10,10,1000)\nx = np.zeros(t.shape)\n\nx[t&gt;=0]=5\nx[t&gt;=3]=0\n\nplt.figure(figsize=(16,6.75))\nplt.plot(t,x)\nplt.grid()\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Amplitude\")\n\n\n\n\nt = np.linspace(-10,10,1000)\nx = np.zeros(t.shape)\n\nx=5*np.heaviside(t,1)-5*np.heaviside(t-3,1)\n\nplt.figure(figsize=(16,6.75))\nplt.plot(t,x)\nplt.grid()\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Amplitude\")"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#exercisae-singular-signals",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#exercisae-singular-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Exercisae Singular Signals",
    "text": "Exercisae Singular Signals\n\nQuestion\n\n\nHow can i create the following signal using only singular signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\n\nBio - That came from a biological being\nSignal - A signal is a function that conveys information about a physical phenomenon.\nBiosignals - The search for information from living systems to know its health state"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-1",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\nThe codification of biosignals into variations: * Electrical * Mechanical * Chemical * Thermal"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-2",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-3",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1791: Luigi Galvani discovers electrical signals in living tissues (frog legs)\n1830s: Carlo Matteucci studies electrical signals in the heart\n1887: Willem Einthoven invents the first electrocardiograph (ECG)\n1900s: James Mackenzie develops the first clinical ECG machine"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-1",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1920s: Electroencephalography (EEG) is developed by Hans Berger\n1930s: Electromyography (EMG) is developed by John Humphrey and others\n1940s: Development of the first commercial ECG machines\n1950s: Signal processing techniques are applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-2",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1960s: Digital signal processing and computer analysis of biomedical signals emerge\n1970s: Biomedical signal processing becomes a recognized field\n1980s: Development of Holter monitoring (24-hour ECG)\n1990s: Advances in signal processing and machine learning applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-3",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n2000s: Development of wearable devices and mobile health (mHealth) technologies\n2010s: Emergence of big data analytics and cloud computing in biomedical signal processing\n2020s: Integration of artificial intelligence (AI) and machine learning (ML) in biomedical signal processing"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-4",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-4",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1895: Wilhelm Roentgen discovers X-rays, leading to medical imaging\n1900s: X-ray technology improves with development of modern X-ray tubes\n1913: Albert Salomon develops mammography\n1920s: Ultrasound technology is developed by Karl Dussik and others"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-5",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1930s: Nuclear medicine emerges with development of radioactive tracers\n1950s: Computed Tomography (CT) scans are developed by Godfrey Hounsfield and Allan McLeod Cormack\n1960s: Development of medical ultrasound imaging\n1970s: Magnetic Resonance Imaging (MRI) is developed by Richard Ernst and others"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-6",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-6",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1980s: Digital image processing and analysis techniques are applied to biomedical images\n1990s: Advances in MRI and CT scan technology, including 3D imaging\n2000s: Development of functional MRI (fMRI), diffusion tensor imaging (DTI), and other advanced MRI techniques\n2010s: Emergence of artificial intelligence (AI) and machine learning in medical imaging"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-7",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-7",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nAdditional Milestones:\n\n1950s: Development of medical electronics and instrumentation\n1960s: First medical imaging computers are developed\n1970s: Development of digital image processing and analysis software\n1980s: Emergence of medical imaging informatics and PACS (Picture Archiving and Communication Systems)\n1990s: Development of telemedicine and teleradiology\n2000s: Emergence of electronic health records (EHRs) and health information exchanges (HIEs)\n2010s: Development of personalized medicine and precision health initiatives"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-the-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-the-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Why the Z-Transform?",
    "text": "Why the Z-Transform?\n\nThe Fourier Transform assumes signals are stable and well-behaved\nBut some biosignals or systems may not be absolutely summable\nThe Z-Transform generalizes the Fourier Transform\nUseful for analyzing discrete-time systems, especially when stability and causality matter"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#definition",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#definition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Definition",
    "text": "Definition\nLet \\(x[n]\\) be a discrete-time signal.\nThe Z-Transform is defined as:\n\\[X(z) = \\sum_{n=-\\infty}^{\\infty} x[n] z^{-n}\\]\nWhere: - \\(z \\in \\mathbb{C}\\) is a complex variable - \\(z = re^{j\\omega}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#region-of-convergence-roc",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#region-of-convergence-roc",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Region of Convergence (ROC)",
    "text": "Region of Convergence (ROC)\n\nThe Z-Transform converges only for certain values of \\(z\\)\nThe set of \\(z\\) for which the series converges is the ROC\nROC is critical for system stability and causality\n\n\n\nCausal Signals\nROC is outside outermost pole\nAnti-Causal Signals\nROC is inside innermost pole"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-plane-representation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-plane-representation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Z-Plane Representation",
    "text": "Z-Plane Representation\n\nPoles: values of \\(z\\) where \\(X(z) \\to \\infty\\)\nZeros: values where \\(X(z) = 0\\)\nVisualization of poles and zeros helps in understanding system behavior\n\n\nTransfer functionZPK (Zero-Pole-Kernel) Representation\n\n\n\\[H(z) = 1.00 \\cdot \\frac{(z - 0.50)}{(z - 0.90)}\\]\n\n\n\n\n(-1.5, 1.5)\n\n\n(-1.5, 1.5)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relationship-with-fourier-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relationship-with-fourier-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Relationship with Fourier Transform",
    "text": "Relationship with Fourier Transform\nIf the ROC includes the unit circle, \\(|z| = 1\\), then:\n\\[X(e^{j\\omega}) = \\sum_{n=-\\infty}^{\\infty} x[n] e^{-j\\omega n}\\]\nSo the Fourier Transform is a special case of the Z-Transform."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-signal",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-signal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example Signal",
    "text": "Example Signal\nLet:\n\\[x[n] = a^n u[n]\\]\nWhere: - \\(a \\in \\mathbb{R}\\) - \\(u[n]\\) is the unit step function (0 for \\(n&lt;0\\), 1 for \\(n\\geq 0\\))"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Z-Transform",
    "text": "Step 1: Z-Transform\nApply the definition:\n\\[X(z) = \\sum_{n=0}^{\\infty} a^n z^{-n}\n= \\sum_{n=0}^{\\infty} (az^{-1})^n\\]\nThis is a geometric series:\n\\[X(z) = \\frac{1}{1 - az^{-1}} = \\frac{z}{z - a}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#what-is-a-geometric-series",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#what-is-a-geometric-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "What is a Geometric Series?",
    "text": "What is a Geometric Series?\nA geometric series is a sum of terms where each term is multiplied by the same constant:\n\\[S = \\sum_{n=0}^{\\infty} r^n = 1 + r + r^2 + r^3 + \\cdots\\]\nThe value of \\(r\\) determines whether this sum converges (has a finite limit) or diverges."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#goal",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#goal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Goal",
    "text": "Goal\nUnderstand why this series:\n\\[\\sum_{n=0}^{\\infty} r^n\\]\nconverges if and only if:\n\\[\\boxed{|r| &lt; 1}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#partial-sums",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#partial-sums",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Partial Sums",
    "text": "Partial Sums\nLet’s consider the sum up to the \\(N\\)-th term:\n\\[S_N = \\sum_{n=0}^{N} r^n = 1 + r + r^2 + \\cdots + r^N\\]\nThis has a closed-form expression:\n\\[S_N = \\frac{1 - r^{N+1}}{1 - r} \\quad \\text{for } r \\neq 1\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#taking-the-limit",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#taking-the-limit",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Taking the Limit",
    "text": "Taking the Limit\nTo find the sum of the infinite series, take the limit as \\(N \\to \\infty\\):\n\\[S = \\lim_{N \\to \\infty} S_N = \\lim_{N \\to \\infty} \\frac{1 - r^{N+1}}{1 - r}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-1-r-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-1-r-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Case 1: \\(|r| < 1\\)",
    "text": "Case 1: \\(|r| &lt; 1\\)\nIf \\(|r| &lt; 1\\), then:\n\\[r^{N+1} \\to 0 \\quad \\text{as } N \\to \\infty\\]\nSo the sum becomes:\n\\[S = \\frac{1}{1 - r}\\]\n✅ The geometric series converges."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-2-r-geq-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-2-r-geq-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Case 2: \\(|r| \\geq 1\\)",
    "text": "Case 2: \\(|r| \\geq 1\\)\n\nIf \\(r = 1\\), then \\(S_N = N + 1 \\to \\infty\\)\nIf \\(r = -1\\), the sum oscillates: \\(1 - 1 + 1 - 1 + \\cdots\\)\nIf \\(|r| &gt; 1\\), then \\(r^{N+1} \\to \\infty\\)\n\n❌ In all cases: the series diverges"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#intuition",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#intuition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Intuition",
    "text": "Intuition\n\nWhen \\(|r| &lt; 1\\), each term \\(r^n\\) gets smaller and smaller\nTheir total sum settles to a finite number\nWhen \\(|r| \\geq 1\\), the terms don’t vanish — the sum keeps growing or oscillating"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-r-0.5",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-r-0.5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example: \\(r = 0.5\\)",
    "text": "Example: \\(r = 0.5\\)\n\\[S = 1 + 0.5 + 0.25 + 0.125 + \\cdots = \\frac{1}{1 - 0.5} = 2\\]\nEvery term adds less. The sum “flattens out.”"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-this-matters",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-this-matters",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Why This Matters",
    "text": "Why This Matters\nThe Z-Transform often gives us geometric series like:\n\\[\\sum_{n=0}^{\\infty} (az^{-1})^n\\]\nThis converges only if:\n\\[|az^{-1}| &lt; 1 \\Rightarrow |z| &gt; |a|\\]\nSo, understanding convergence of geometric series = understanding ROC in Z-transforms."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary",
    "text": "Summary\n\n\n\nCondition\nBehavior\nResult\n\n\n\n\n\\(|r| &lt; 1\\)\nTerms shrink\nSeries converges\n\n\n\\(|r| \\geq 1\\)\nTerms grow or oscillate\nDiverges\n\n\n\n\\[\\sum_{n=0}^{\\infty} r^n = \\frac{1}{1 - r} \\quad \\text{if } |r| &lt; 1\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-region-of-convergence-roc",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-region-of-convergence-roc",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Region of Convergence (ROC)",
    "text": "Step 2: Region of Convergence (ROC)\nFor convergence of the geometric series:\n\\[|az^{-1}| &lt; 1 \\Rightarrow |z| &gt; |a|\\]\nTherefore, the ROC is:\n\\[\\boxed{|z| &gt; |a|}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#interpretation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#interpretation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Interpretation",
    "text": "Interpretation\n\nCausal signal (defined for \\(n \\geq 0\\))\nROC is outside the outermost pole\nStable system only if ROC includes the unit circle \\(|z| = 1\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-a-0.5",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-a-0.5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example: \\(a = 0.5\\)",
    "text": "Example: \\(a = 0.5\\)\n\\[x[n] = (0.5)^n u[n]\\]\nZ-Transform:\n\\[X(z) = \\sum_{n=0}^{\\infty} (0.5)^n z^{-n} = \\frac{z}{z - 0.5}\\]\nRegion of Convergence:\n\\[\\boxed{|z| &gt; 0.5}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\nSignal\nZ-Transform\nROC\n\n\n\n\n\\(x[n] = a^n u[n]\\)\n\\(\\frac{z}{z - a}\\)\n\\(|z| &gt; |a|\\)\n\n\nExample: \\(a = 0.5\\)\n\\(\\frac{z}{z - 0.5}\\)\n\\(|z| &gt; 0.5\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#properties-of-the-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#properties-of-the-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Properties of the Z-Transform",
    "text": "Properties of the Z-Transform\n\nLinearity: \\(a x[n] + b y[n] \\to aX(z) + bY(z)\\)\nTime shifting: \\(x[n - k] \\to z^{-k} X(z)\\)\nScaling in the z-domain: \\(a^n x[n] \\to X(z/a)\\)\nConvolution: \\(x[n] * h[n] \\to X(z)H(z)\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\nLet \\(x[n] = a^n u[n]\\), where \\(|a| &lt; 1\\)\n\\[X(z) = \\sum_{n=0}^{\\infty} a^n z^{-n} = \\frac{1}{1 - az^{-1}}, \\quad \\text{ROC: } |z| &gt; |a|\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#difference-equations-in-dsp",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#difference-equations-in-dsp",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Difference Equations in DSP",
    "text": "Difference Equations in DSP\nA difference equation relates input and output values at different time steps.\n\\[y[n] - a_1 y[n-1] - a_2 y[n-2] = b_0 x[n] + b_1 x[n-1]\\]\nCommon in: - Digital filters (FIR, IIR) - Signal models in ECG, EEG analysis - Implementation in real-time biosignal systems"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-transform-of-time-shifted-terms",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-transform-of-time-shifted-terms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Z-Transform of Time-Shifted Terms",
    "text": "Z-Transform of Time-Shifted Terms\nThe Z-Transform turns time shifts into powers of \\(z^{-1}\\):\n\n\n\nTime Domain\nZ-Domain\n\n\n\n\n\\(x[n]\\)\n\\(X(z)\\)\n\n\n\\(x[n-k]\\)\n\\(z^{-k} X(z)\\)\n\n\n\\(y[n-k]\\)\n\\(z^{-k} Y(z)\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-apply-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-apply-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Apply Z-Transform",
    "text": "Step 1: Apply Z-Transform\nGiven:\n\\[y[n] - a_1 y[n-1] - a_2 y[n-2] = b_0 x[n] + b_1 x[n-1]\\]\nApply \\(\\mathcal{Z} \\{ \\cdot \\}\\):\n\\[Y(z) - a_1 z^{-1} Y(z) - a_2 z^{-2} Y(z) = b_0 X(z) + b_1 z^{-1} X(z)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-factor-and-solve-for-hz",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-factor-and-solve-for-hz",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Factor and Solve for \\(H(z)\\)",
    "text": "Step 2: Factor and Solve for \\(H(z)\\)\nGroup:\n\\[Y(z)(1 - a_1 z^{-1} - a_2 z^{-2}) = X(z)(b_0 + b_1 z^{-1})\\]\nDivide both sides:\n\\[H(z) = \\frac{Y(z)}{X(z)} = \\frac{b_0 + b_1 z^{-1}}{1 - a_1 z^{-1} - a_2 z^{-2}}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\nGiven:\n\\[y[n] - 0.9 y[n-1] = x[n] - 0.5 x[n-1]\\]\nZ-Transform:\n\\[Y(z)(1 - 0.9 z^{-1}) = X(z)(1 - 0.5 z^{-1})\\]\nTransfer Function:\n\\[H(z) = \\frac{1 - 0.5 z^{-1}}{1 - 0.9 z^{-1}}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#poles-and-zeros",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#poles-and-zeros",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Poles and Zeros",
    "text": "Poles and Zeros\nLet’s analyze \\(H(z)\\):\n\nZeros: Roots of the numerator \\(\\Rightarrow z = 0.5\\)\nPoles: Roots of the denominator \\(\\Rightarrow z = 0.9\\)\n\n\n\nPole-Zero Plot\nVisualizes system behavior\nCheck for: - Stability (poles inside unit circle) - Frequency shaping"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#practice",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#practice",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Practice",
    "text": "Practice\nConvert this equation:\n\\[y[n] = 0.6 y[n-1] + x[n] + x[n-1]\\]\nFind: - \\(H(z)\\) - Poles and zeros - Plot them in the Z-plane"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#application-in-biosignal-processing",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#application-in-biosignal-processing",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Application in Biosignal Processing",
    "text": "Application in Biosignal Processing\n\nAnalysis of digital filters for ECG, EEG, etc.\nDesign of stable and causal filtering systems\nUseful in difference equation modeling of biosignals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-2",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary",
    "text": "Summary\n\nZ-Transform is a powerful tool for analyzing discrete systems\nProvides insight into stability, causality, and system behavior\nA generalization of the Fourier Transform\nCrucial in digital signal processing of biosignals\nZ-Transform converts difference equations into algebraic expressions\nTransfer function \\(H(z)\\) tells us how the system responds to inputs\nKey for digital filter design in biosignal processing"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#next-steps",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#next-steps",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Next Steps",
    "text": "Next Steps\n\nPractice Z-Transform computations\nPole-zero plotting exercises\nApplication to real biosignal filtering problems"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n\n\n\n\n\n\nNotch Filter\n\n\nA common issue in biosignal processing is removing power‐line interference (50/60 Hz) from, for example, EEG or ECG signals. A simple digital filter to eliminate 60 Hz interference (assuming a sampling frequency \\(f_s = 5000\\) Hz) is to place complex‐conjugate zeros at\n\\[\nz = e^{\\pm j 2\\pi\\frac{60}{5000}}.\n\\]\nThe resulting transfer function can be written as\n\\[\nH(z) = 1 \\;-\\; 2\\cos\\!\\Bigl(2\\pi\\frac{60}{5000}\\Bigr)\\,z^{-1} \\;+\\; z^{-2}.\n\\]\nThis \\(H(z)\\) has zeros at \\(e^{\\pm j2\\pi(60/5000)}\\) that precisely cancel the 60 Hz component, thereby implementing a notch filter. Moreover, it is a second‐order FIR filter with symmetric coefficients, which grants it linear phase (important to avoid waveform distortion)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\ndef design_filter(zeros=None, poles=None, gain=1.0):\n    \"\"\"\n    Diseña un filtro digital a partir de ceros y/o polos y una ganancia.\n\n    Parámetros:\n    - zeros: lista de ceros (raíces del numerador), o None para no incluir\n    - poles: lista de polos (raíces del denominador), o None para no incluir\n    - gain: ganancia escalar del filtro\n\n    Devuelve:\n    - b: coeficientes del numerador\n    - a: coeficientes del denominador\n    \"\"\"\n    # Si no se pasan ceros, asumimos un FIR trivial (b = [gain])\n    if zeros:\n        b = gain * np.poly(zeros)\n    else:\n        b = np.array([gain], dtype=float)\n\n    # Si no se pasan polos, asumimos sistema FIR (a = [1])\n    if poles:\n        a = np.poly(poles)\n    else:\n        a = np.array([1.0], dtype=float)\n\n    return b, a"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-2",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\ndef gaussian(x, mu, sigma, A):\n    \"\"\"\n    Genera una función gaussiana.\n\n    Parámetros:\n    - x: array de tiempos\n    - mu: posición central de la gaussiana\n    - sigma: desviación estándar\n    - A: amplitud\n    \"\"\"\n    return A * np.exp(-((x - mu) ** 2) / (2 * sigma**2))"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-3",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\ndef simulate_ecg(duration=10.0, fs=500, heart_rate=60):\n    \"\"\"\n    Simula un ECG sintético basado en la superposición de ondas gaussianas.\n\n    Parámetros:\n    - duration: duración de la señal en segundos\n    - fs: frecuencia de muestreo en Hz\n    - heart_rate: frecuencia cardiaca en latidos por minuto\n\n    Devuelve:\n    - t: vector de tiempos\n    - ecg: señal simulada de ECG en mV\n    \"\"\"\n    dt = 1 / fs\n    t = np.arange(0, duration, dt)\n    rr = 60 / heart_rate  # intervalo RR en segundos\n\n    # Inicializar señal\n    ecg = np.zeros_like(t)\n\n    # Parámetros de las ondas (posiciones relativas en segundos)\n    # P wave\n    p_amp, p_dur, p_delay = 0.25, 0.09, 0.16\n    # Q wave\n    q_amp, q_dur, q_delay = -0.05, 0.066, 0.166\n    # R wave\n    r_amp, r_dur, r_delay = 1.6, 0.1, 0.166\n    # S wave\n    s_amp, s_dur, s_delay = -0.25, 0.066, 0.19\n    # T wave\n    t_amp, t_dur, t_delay = 0.35, 0.142, 0.36\n\n    # Generar cada latido\n    for beat_start in np.arange(0, duration, rr):\n        mask = (t &gt;= beat_start) & (t &lt; beat_start + rr)\n        tb = t[mask] - beat_start\n        ecg[mask] += gaussian(tb, p_delay, p_dur / 2, p_amp)\n        ecg[mask] += gaussian(tb, q_delay, q_dur / 2, q_amp)\n        ecg[mask] += gaussian(tb, r_delay, r_dur / 2, r_amp)\n        ecg[mask] += gaussian(tb, s_delay, s_dur / 2, s_amp)\n        ecg[mask] += gaussian(tb, t_delay, t_dur / 2, t_amp)\n\n    return t, ecg+0.1*np.cos(2*np.pi*60*t)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-4",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-4",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n# Parámetros de simulación\nDURATION = 10    # segundos\nFS = 500         # Hz\nHR = 70          # latidos por minuto\n\n# Generar señal\nt, ecg_signal = simulate_ecg(duration=DURATION, fs=FS, heart_rate=HR)\n\n# Graficar resultado\nplt.figure(figsize=(12, 4))\nplt.plot(t, ecg_signal, linewidth=1)\nplt.title(f'Señal de ECG sintética ({HR} bpm)')\nplt.xlabel('Tiempo (s)')\nplt.ylabel('Amplitud (mV)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-5",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\nn = len(ecg_signal)\nyf = np.fft.fft(ecg_signal)\nxf = np.fft.fftfreq(n, 1/fs)[:n//2]\nplt.plot(xf, 2.0/n * np.abs(yf[0:n//2]))\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-6",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-6",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\nfc = 60\nb,a =design_filter(zeros=[np.exp(1j*2*np.pi*fc/fs), np.exp(-1j*2*np.pi*fc/fs)])\nprint(a)\nprint(b)\n\nw, h = sig.freqz(a, b, worN=8000)\nplt.plot(w/np.pi*fs/2, 20*np.log10(abs(h)))\nplt.grid()\nplt.xlabel('Frequency (Hz)')"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-7",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-7",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n\n\n\n\n\n\nFIR filters\n\n\nFIR filters (Finite Impulse Response) are widely used in biomedical processing because they can be designed to have linear phase response, avoiding phase distortion in the filtered signal (which is useful for preserving the morphology of ECG waves, for example)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-8",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-8",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n\n\n\n\n\n\nFilter Design Process\n\n\n\nDefining the desired ideal frequency response \\(H_d(e^{j\\omega})\\).\nObtaining the ideal impulse response \\(h_d[n]\\) as the inverse Fourier transform of \\(H_d\\).\nTruncating \\(h_d[n]\\) (which is usually infinite or very long) with a window function \\(w[n]\\) to obtain a realizable FIR filter\n\\[\nh[n] = h_d[n]\\,w[n].\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-9",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-9",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\nYou obtain \\(h_d[n]\\) as the inverse discrete–time Fourier transform of your ideal frequency response \\(H_d(e^{j\\omega})\\). For a low-pass filter with cutoff \\(\\omega_c\\),\n\\[\nH_d(e^{j\\omega}) =\n\\begin{cases}\n1, & |\\omega|\\le\\omega_c,\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\]\nBy definition of the inverse DTFT,\n\\[\nh_d[n] \\;=\\; \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} H_d(e^{j\\omega})\\,e^{j\\omega n}\\,d\\omega\n\\;=\\;\\frac{1}{2\\pi}\\int_{-\\omega_c}^{\\omega_c} e^{j\\omega n}\\,d\\omega.\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-10",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-10",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\nCarry out the integral in two cases:\n\nFor \\(n\\neq 0\\):\n\\[\nh_d[n]\n=\\frac{1}{2\\pi}\\,\\frac{e^{j\\omega n}}{j\\,n}\\Biggr|_{-\\omega_c}^{\\omega_c}\n=\\frac{1}{2\\pi}\\,\\frac{e^{j\\omega_c n}-e^{-j\\omega_c n}}{j\\,n}\n=\\frac{\\sin(\\omega_c\\,n)}{\\pi\\,n}.\n\\]\nFor \\(n=0\\):\n\\[\nh_d[0]\n=\\frac{1}{2\\pi}\\int_{-\\omega_c}^{\\omega_c} 1\\,d\\omega\n=\\frac{2\\,\\omega_c}{2\\pi}\n=\\frac{\\omega_c}{\\pi}.\n\\]\n\nPutting both together,\n\\[\nh_d[n]\n=\\begin{cases}\n\\dfrac{\\sin(\\omega_c\\,n)}{\\pi\\,n}, & n\\neq 0,\\\\[1em]\n\\dfrac{\\omega_c}{\\pi},                & n=0.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relating-to-sampling-frequency",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relating-to-sampling-frequency",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Relating to sampling frequency",
    "text": "Relating to sampling frequency\nIf your cutoff is specified in Hz, \\(f_c\\), and sampling rate is \\(f_s\\), then\n\\[\n\\omega_c = 2\\pi\\,\\frac{f_c}{f_s},\n\\]\nso you can write\n\\[\nh_d[n]\n=\\frac{\\sin\\!\\bigl(2\\pi \\frac{f_c}{f_s}\\,n\\bigr)}{\\pi\\,n}\n=\\;2\\;\\frac{f_c}{f_s}\\;\\frac{\\sin\\!\\bigl(2\\pi \\frac{f_c}{f_s}\\,n\\bigr)}{2\\pi \\frac{f_c}{f_s}\\,n}\n=2\\frac{f_c}{f_s}\\,\\mathrm{sinc}\\!\\Bigl(2\\frac{f_c}{f_s}\\,n\\Bigr),\n\\]\nwhere we define the normalized sinc as \\(\\mathrm{sinc}(x)=\\frac{\\sin(\\pi x)}{\\pi x}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#key-takeaway",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#key-takeaway",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Key takeaway",
    "text": "Key takeaway\n\n\\(h_d[n]\\) is exactly the inverse‐DTFT of the ideal (“brick‐wall”) frequency specification.\nIt produces a sinc-shaped impulse response of infinite length.\nTruncation (with a window) makes it realizable as a finite-length FIR."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-11",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-11",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\nThe typical characteristics of classic windows are:\n\nRectangular: narrowest main lobe (width ≈ 4π/M rad) but highest sidelobes (first sidelobe ≈ –13 dB, stop-band attenuation ≈ 21 dB). It gives the steepest transition for a given filter order, at the expense of poorer stop-band rejection.\nBartlett (triangular): somewhat wider main lobe (≈ 8π/M), sidelobes ≈ –25 dB.\nHann: main lobe ≈ 8π/M, sidelobes ≈ –31 dB (better rejection than rectangular but smoother transitions).\nHamming: main lobe ≈ 8π/M, sidelobes ≈ –41 dB (minimum stop-band attenuation ≈ 53 dB). Very popular for its good compromise between transition width and stop-band attenuation.\nBlackman: wider main lobe (≈ 12π/M) but very low sidelobes (≈ –57 dB, attenuation ≈ 74 dB).\nKaiser: allows selection of a parameter β to control sidelobe attenuation, offering flexibility. Approximately, to achieve A dB of attenuation,\n\\[\n  \\beta \\approx 0.1102\\,(A - 8.7)\\quad(\\text{for }A&gt;50),\n\\]\nand the normalized transition width Δω relates to the order M and β by\n\\[\n  M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\n\\]\n\nThese formulas stem from Kaiser’s approximations and help in sizing the filter."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#windows-forms",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#windows-forms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Windows Forms",
    "text": "Windows Forms\n\nTimeFrequencyCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(-100.0, 5.0)\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal.windows import (\n    boxcar,       # Rectangular\n    bartlett,    # Triangular\n    hann,        # Hann\n    hamming,     # Hamming\n    blackman,    # Blackman\n    kaiser       # Kaiser\n)\n\n# Parameters\nM = 64               # window length\nbeta = 8.6           # Kaiser parameter for moderate sidelobe attenuation\nnfft = 512           # FFT length for frequency response\nfs = 1.0             # normalized sampling rate\n\n# Generate windows\nwindows = {\n    'Rectangular': boxcar(M),\n    'Bartlett':    bartlett(M),\n    'Hann':        hann(M),\n    'Hamming':     hamming(M),\n    'Blackman':    blackman(M),\n    f'Kaiser (β={beta})': kaiser(M, beta)\n}\n\n# Time-domain plot\nplt.figure(figsize=(8, 4))\nfor name, w in windows.items():\n    plt.plot(np.arange(M), w, label=name)\nplt.title('Window Functions — Time Domain')\nplt.xlabel('Sample index n')\nplt.ylabel('Amplitude')\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.tight_layout()\n\n# Frequency-domain plot\nplt.figure(figsize=(8, 4))\nfor name, w in windows.items():\n    # Compute normalized frequency response\n    W = np.fft.fft(w, nfft)\n    W_mag = 20 * np.log10(np.abs(W) / np.max(np.abs(W)))\n    freqs = np.fft.fftfreq(nfft, d=1/fs)\n    # Only plot 0 ≤ f ≤ 0.5 (normalized Nyquist)\n    idx = np.logical_and(freqs &gt;= 0, freqs &lt;= 0.5)\n    plt.plot(freqs[idx], W_mag[idx], label=name)\nplt.title('Window Functions — Frequency Response')\nplt.xlabel('Normalized Frequency (cycles/sample)')\nplt.ylabel('Magnitude (dB)')\nplt.ylim(-100, 5)\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.tight_layout()\n\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-12",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-12",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN = 101\nfc = 30\n\n# 2. Compute the ideal impulse response h_d[n] of a low-pass filter\nn = np.arange(N)\nM = (N - 1) / 2\n# Using the normalized sinc: sinc(x) = sin(pi*x)/(pi*x)\nh_d = (2 * fc / FS) * np.sinc(2 * fc * (n - M) / FS)\n\n# 3. Choose a window w[n] (here: Hamming) and truncate\nw = np.hamming(N)\nh = h_d * w\n\n# 4. Normalize to ensure unity gain at DC\nh /= np.sum(h)\n\n# 6. Filter it (only allowed library call)\ny = sig.lfilter(h, 1.0, ecg_signal)\n\n# 7. Plot input vs. output\nplt.figure(figsize=(8, 4))\nplt.plot(t, ecg_signal, label='Original signal')\nplt.plot(t, y, label='Filtered signal', linewidth=2)\nplt.xlabel('Time [s]')\nplt.ylabel('Amplitude')\nplt.title('Low-pass FIR (window method) – Cutoff 100 Hz')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-iir-filter-design-strategy",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-iir-filter-design-strategy",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction: IIR Filter Design Strategy",
    "text": "Introduction: IIR Filter Design Strategy\n\nGoal: Design digital Infinite Impulse Response (IIR) filters.\nApproach: Leverage well-established theory and techniques from analog filter design.\nMethod:\n\nDesign a suitable analog filter prototype \\(H(s)\\).\nTransform this analog design into a digital filter \\(H(z)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---laplace-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---laplace-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 0: The Analog Domain - Laplace Transform",
    "text": "Step 0: The Analog Domain - Laplace Transform\n\nContext: Continuous-time signals and Linear Time-Invariant (LTI) systems.\nTool: The Laplace Transform converts differential equations (time domain) to algebraic equations (s-domain).\nTransfer Function \\(H(s)\\): Represents the system in the s-domain. \\[H(s) = \\frac{Y(s)}{X(s)}\\] where \\(s = \\sigma + j\\Omega\\) is the complex frequency (\\(\\Omega\\) = analog angular frequency)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---s-plane-analysis",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---s-plane-analysis",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 0: The Analog Domain - s-Plane Analysis",
    "text": "Step 0: The Analog Domain - s-Plane Analysis\n\ns-Plane: Complex plane where \\(H(s)\\) is analyzed.\nPoles & Zeros: Roots of the denominator & numerator of \\(H(s)\\), respectively. Their locations determine filter behavior.\nFrequency Response: Determined by \\(H(j\\Omega)\\) (evaluating \\(H(s)\\) on the imaginary axis).\nStability: For a causal system to be stable, all poles must be in the Left-Half Plane (LHP), i.e., \\(\\text{Re}\\{s\\} &lt; 0\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---filter-prototypes",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---filter-prototypes",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 0: The Analog Domain - Filter Prototypes",
    "text": "Step 0: The Analog Domain - Filter Prototypes\n\nStandardized, well-understood analog filter approximations:\n\nButterworth: Maximally flat passband.\nChebyshev Type I: Equiripple passband, monotonic stopband.\nChebyshev Type II: Monotonic passband, equiripple stopband.\nElliptic (Cauer): Equiripple in both passband and stopband (sharpest transition for a given order).\n\nDesign usually starts with a normalized low-pass prototype."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#the-bridge-analog-to-digital-mapping",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#the-bridge-analog-to-digital-mapping",
    "title": "Sistemas y Señales Biomédicos",
    "section": "The Bridge: Analog-to-Digital Mapping",
    "text": "The Bridge: Analog-to-Digital Mapping\n\nCore Task: Convert the analog filter \\(H(s)\\) (s-plane) into a digital filter \\(H(z)\\) (z-plane).\nNeed a mapping that relates the continuous frequency \\(\\Omega\\) to the discrete frequency \\(\\omega\\).\nCrucially, the stable region (LHP in s-plane) should map to the stable region (inside the unit circle in z-plane)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Digital Filter Specifications",
    "text": "Step 1: Digital Filter Specifications\n\nDefine the desired characteristics of the digital filter:\n\nCritical Frequencies:\n\nPassband edge: \\(\\omega_p\\)\nStopband edge: \\(\\omega_s\\)\n(Normalized digital angular frequencies, e.g., \\(0 \\le \\omega \\le \\pi\\))\n\nTolerances:\n\nMax. passband ripple/attenuation: \\(A_p\\) (dB) or \\(\\delta_p\\)\nMin. stopband attenuation: \\(A_s\\) (dB) or \\(\\delta_s\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-transformation-methods---overview",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-transformation-methods---overview",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Transformation Methods - Overview",
    "text": "Step 2: Transformation Methods - Overview\n\nMathematical mappings from the s-plane to the z-plane.\nTwo primary methods:\n\nImpulse Invariance\nBilinear Transformation"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-1---impulse-invariance",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-1---impulse-invariance",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Method 1 - Impulse Invariance",
    "text": "Step 2: Method 1 - Impulse Invariance\n\nConcept: Match the impulse response: \\(h_{digital}[n] \\approx T \\cdot h_{analog}(nT)\\).\nMapping: Maps s-plane pole \\(s_k\\) to z-plane pole \\(z_k = e^{s_k T}\\).\n\nUses partial fraction expansion of \\(H(s)\\).\n\nPros: Preserves impulse response shape.\nCons: Suffers from frequency aliasing if \\(H(j\\Omega)\\) is not bandlimited below Nyquist frequency (\\(F_s/2\\)). Best for low-pass/band-pass filters."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-2---bilinear-transformation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-2---bilinear-transformation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Method 2 - Bilinear Transformation",
    "text": "Step 2: Method 2 - Bilinear Transformation\n\nConcept: An algebraic substitution mapping the \\(j\\Omega\\) axis onto the unit circle.\nMapping Formula: \\[s = \\frac{2}{T} \\frac{1 - z^{-1}}{1 + z^{-1}}\\] (T = sampling period, often set to 2 for simplicity during derivation).\nPros:\n\nNo aliasing: Maps entire \\(j\\Omega\\) axis to the unit circle (\\(-\\pi \\le \\omega \\le \\pi\\)).\nPreserves stability: Maps LHP (stable s-region) to inside the unit circle (stable z-region).\n\nCons: Introduces non-linear frequency warping."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#understanding-frequency-warping-bilinear",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#understanding-frequency-warping-bilinear",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Understanding Frequency Warping (Bilinear)",
    "text": "Understanding Frequency Warping (Bilinear)\n\nThe relationship between analog (\\(\\Omega\\)) and digital (\\(\\omega\\)) frequencies is non-linear: \\[\\Omega = \\frac{2}{T} \\tan\\left(\\frac{\\omega}{2}\\right)\\] or equivalently: \\[\\omega = 2 \\arctan\\left(\\frac{\\Omega T}{2}\\right)\\]\nThis compresses the infinite analog frequency axis onto the finite digital frequency range \\([-\\pi, \\pi]\\).\nThe mapping is non-uniform, most distorted near \\(\\omega = \\pm \\pi\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-3-frequency-pre-warping-bilinear-only",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-3-frequency-pre-warping-bilinear-only",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 3: Frequency Pre-warping (Bilinear Only)",
    "text": "Step 3: Frequency Pre-warping (Bilinear Only)\n\nProblem: Frequency warping distorts the locations of \\(\\omega_p\\) and \\(\\omega_s\\).\nSolution: Pre-warp the digital specifications (\\(\\omega_p, \\omega_s\\)) into corresponding analog frequencies (\\(\\Omega_p, \\Omega_s\\)) before designing the analog filter.\nFormula: Use the warping relationship: \\[\\Omega_p = \\frac{2}{T} \\tan\\left(\\frac{\\omega_p}{2}\\right)\\] \\[\\Omega_s = \\frac{2}{T} \\tan\\left(\\frac{\\omega_s}{2}\\right)\\]\nUse these \\(\\Omega_p, \\Omega_s\\) values for the analog design step."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-4-analog-prototype-design-workflow",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-4-analog-prototype-design-workflow",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 4: Analog Prototype Design Workflow",
    "text": "Step 4: Analog Prototype Design Workflow\n\nSelect Prototype: Choose Butterworth, Chebyshev, Elliptic based on specs (ripple, transition width) using the (pre-warped) \\(\\Omega_p, \\Omega_s, A_p, A_s\\).\nDetermine Order (N) & Cutoff (\\(\\Omega_c\\)): Calculate required analog filter order and cutoff frequency using prototype-specific formulas.\nFind Normalized LP \\(H_{LP}(s)\\): Obtain the transfer function for the normalized low-pass prototype.\nFrequency Transformation (Analog): If needed, transform \\(H_{LP}(s)\\) to target type (HP, BP, BS) using analog transformations.\n\nResult: The final analog filter transfer function \\(H_a(s)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#analog-filter-design-overview",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#analog-filter-design-overview",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog Filter Design: Overview",
    "text": "Analog Filter Design: Overview\nDesigning an analog filter translates desired signal filtering characteristics into a physical electronic circuit.\nKey Stages:\n\nDefine Specifications\nChoose an Approximation Method\nDetermine Filter Order\nFind Normalized Low-Pass Prototype (Conceptual)\nDenormalize & Transform (Conceptual)\nSynthesize the Circuit\nComponent Selection & Simulation\n\nWe’ll illustrate steps 1, 3, and aspects of 4/5 using Python’s scipy.signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#define-filter-specifications",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#define-filter-specifications",
    "title": "Sistemas y Señales Biomédicos",
    "section": "1. Define Filter Specifications",
    "text": "1. Define Filter Specifications\nThis is the most crucial first step.\n\nType: Low-Pass (LPF), High-Pass (HPF), Band-Pass (BPF), Band-Stop (BSF).\nCritical Frequencies (Analog, \\(\\Omega\\) in rad/s or \\(f\\) in Hz):\n\nCutoff (\\(\\Omega_c, f_c\\))\nPassband Edge(s) (\\(\\Omega_p, f_p\\))\nStopband Edge(s) (\\(\\Omega_s, f_s\\))\n\nAttenuation Levels (dB):\n\nMax. Passband Attenuation/Ripple (\\(A_{max}\\) or gpass)\nMin. Stopband Attenuation (\\(A_{min}\\) or gstop)\n\nPhase Response: Linear phase (e.g., Bessel) or not critical.\nImpedance: Source/Load matching."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#specifications-python-example-low-pass",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#specifications-python-example-low-pass",
    "title": "Sistemas y Señales Biomédicos",
    "section": "1. Specifications: Python Example (Low-Pass)",
    "text": "1. Specifications: Python Example (Low-Pass)\nLet’s define specs for an analog low-pass filter. Frequencies for analog filters in scipy are typically in rad/s.\n\n\nPassband edge: 6283.19 rad/s (1000 Hz)\n\n\nStopband edge: 9424.78 rad/s (1500 Hz)\n\n\nMax Passband Loss: 1.0 dB\n\n\nMin Stopband Attenuation: 40.0 dB"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#choose-an-approximation-method-filter-family",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#choose-an-approximation-method-filter-family",
    "title": "Sistemas y Señales Biomédicos",
    "section": "2. Choose an Approximation Method (Filter Family)",
    "text": "2. Choose an Approximation Method (Filter Family)\nSelect based on trade-offs (roll-off, ripple, phase).\n\nButterworth: Maximally flat passband, smooth roll-off.\nChebyshev Type I: Steeper roll-off than Butterworth, passband ripple.\nChebyshev Type II: Steeper roll-off, stopband ripple, flat passband.\nElliptic (Cauer): Steepest roll-off, ripple in both bands.\nBessel-Thomson: Best phase linearity (constant group delay), slowest roll-off.\n\nFor our Python examples, we’ll use Butterworth."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-filter-fundamentals",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-filter-fundamentals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth Filter Fundamentals",
    "text": "Butterworth Filter Fundamentals\nThe Butterworth filter is maximally flat in the passband.\nThe normalized prototype has a cutoff frequency \\(\\omega_c = 1\\) rad/s.\nPoles are placed on the unit circle in the \\(s\\)-plane at angles: \\[s_k = e^{j\\pi\\frac{2k + n - 1}{2n}}, \\quad k = 1,2,\\ldots,n.\\]\nThe Butterworth polynomial of order \\(n\\) is: \\[B_n(s) = \\prod_{k=1}^{n} (s - s_k).\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-lp-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-lp-transfer-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Lowpass (LP) Transfer Function",
    "text": "Normalized Lowpass (LP) Transfer Function\nThe normalized \\(n\\)th-order lowpass prototype is: \\[H_{LP}(s) = \\frac{1}{B_n(s)} = \\frac{1}{\\prod_{k=1}^n (s - s_k)}.\\] This yields a cutoff at \\(|H_{LP}(j1)| = 1/\\sqrt{2}\\) (the –3 dB point)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-highpass-hp-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-highpass-hp-transfer-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Highpass (HP) Transfer Function",
    "text": "Normalized Highpass (HP) Transfer Function\nApply the frequency transformation \\(s \\to 1/s\\) and multiply by \\(s^n\\): \\[H_{HP}(s) = H_{LP}(1/s)\\,s^n = \\frac{s^n}{B_n(1/s)} = \\frac{s^n}{\\prod_{k=1}^n (1/s - s_k)} = \\frac{\\prod_{k=1}^n(-s_k)\\;s^n}{\\prod_{k=1}^n(s - s_k^{-1})}.\\] This prototype has a normalized cutoff at \\(\\omega=1\\) rad/s in the highpass sense."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandpass-bp-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandpass-bp-transfer-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Bandpass (BP) Transfer Function",
    "text": "Normalized Bandpass (BP) Transfer Function\nUse the bandpass transformation: \\[s \\to \\frac{s^2 + \\Omega_0^2}{B\\,s},\\] where \\(\\Omega_0 = \\sqrt{\\omega_1\\omega_2}\\) and \\(B = \\omega_2 - \\omega_1\\).\nFor a normalized prototype, we set \\(\\Omega_0 = 1\\), \\(B = 1\\), giving: \\[H_{BP}(s) = H_{LP}\\left(\\frac{s^2 + 1}{s}\\right) = \\frac{(s)^n}{\\prod_{k=1}^n\\left(\\frac{s^2 + 1}{s} - s_k\\right)} = \\frac{s^n}{\\prod_{k=1}^n\\left(s^2 + 1 - s\\,s_k\\right)}.\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandstop-bs-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandstop-bs-transfer-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Bandstop (BS) Transfer Function",
    "text": "Normalized Bandstop (BS) Transfer Function\nUse the bandstop transformation: \\[s \\to \\frac{s}{\\frac{s^2 + 1}{s}} = \\frac{s^2}{s^2 + 1},\\] or equivalently \\(s \\to (B\\,s)/(s^2 + \\Omega_0^2)\\) with \\(B=1\\), \\(\\Omega_0=1\\). Then: \\[H_{BS}(s) = H_{LP}\\left(\\frac{s}{s^2 + 1}\\right) = \\frac{1}{B_n\\left(\\frac{s}{s^2+1}\\right)} = \\frac{1}{\\prod_{k=1}^n\\left(\\frac{s}{s^2+1} - s_k\\right)} = \\frac{(s^2+1)^n}{\\prod_{k=1}^n\\left(s - s_k(s^2+1)\\right)} = \\frac{(s^2+1)^n}{\\prod_{k=1}^n\\left(s - s_ks^2 - s_k\\right)}.\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n",
    "title": "Sistemas y Señales Biomédicos",
    "section": "3. Determine the Filter Order (N)",
    "text": "3. Determine the Filter Order (N)\nEstimating the filter order (\\(N\\)) is a crucial first step in analog filter design after defining specifications. The order determines the filter’s complexity and steepness of its frequency response roll-off.\nThese equations are for Butterworth filters. The calculated \\(N\\) is a real number and must be rounded up to the next integer.\nCommon Variables: * \\(N\\): Filter order (integer, result of formula is rounded up). * \\(A_{min}\\): Minimum stopband attenuation (dB, positive value, e.g., 40 dB). * \\(A_{max}\\): Maximum passband attenuation/ripple (dB, positive value, e.g., 1 dB). * \\(\\log_{10}\\): Base-10 logarithm. * All \\(\\Omega\\) values are angular frequencies in rad/s."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-low-pass-lp-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-low-pass-lp-filter-order",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth Low-Pass (LP) Filter Order",
    "text": "Butterworth Low-Pass (LP) Filter Order\n\\[N \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\frac{\\Omega_s}{\\Omega_p}\\right)}\\]\nExplanation of LP-Specific Variables: * \\(\\Omega_p\\): Passband edge angular frequency. The frequency up to which signals pass with at most \\(A_{max}\\) attenuation. * \\(\\Omega_s\\): Stopband edge angular frequency. The frequency from which signals are attenuated by at least \\(A_{min}\\). * For a low-pass filter, \\(\\Omega_s &gt; \\Omega_p\\). The term \\(\\frac{\\Omega_s}{\\Omega_p}\\) is the transition ratio."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-high-pass-hp-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-high-pass-hp-filter-order",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth High-Pass (HP) Filter Order",
    "text": "Butterworth High-Pass (HP) Filter Order\n\\[N \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\frac{\\Omega_p}{\\Omega_s}\\right)}\\]\nExplanation of HP-Specific Variables: * \\(\\Omega_p\\): Passband edge angular frequency. The frequency from which signals pass with at most \\(A_{max}\\) attenuation. * \\(\\Omega_s\\): Stopband edge angular frequency. The frequency down to which signals are attenuated by at least \\(A_{min}\\). * For a high-pass filter, \\(\\Omega_p &gt; \\Omega_s\\). The term \\(\\frac{\\Omega_p}{\\Omega_s}\\) is the transition ratio (inverted compared to LP to keep it &gt;1 for the logarithm)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-pass-bp-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-pass-bp-filter-order",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth Band-Pass (BP) Filter Order",
    "text": "Butterworth Band-Pass (BP) Filter Order\nThe order \\(N_{BP}\\) is the same as an equivalent Low-Pass Prototype. \\[N_{BP} \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\Omega_{s,LP_equiv}\\right)}\\]\nExplanation of BP-Specific Variables: * \\(\\Omega_{p1}, \\Omega_{p2}\\): Passband edge angular frequencies (\\(\\Omega_{p1} &lt; \\Omega_{p2}\\)). * \\(\\Omega_{s1}, \\Omega_{s2}\\): Stopband edge angular frequencies (\\(\\Omega_{s1} &lt; \\Omega_{p1}\\) and \\(\\Omega_{s2} &gt; \\Omega_{p2}\\)). * \\(\\Omega_0 = \\sqrt{\\Omega_{p1}\\Omega_{p2}}\\): Geometric center frequency of the passband. * \\(B = \\Omega_{p2} - \\Omega_{p1}\\): Bandwidth of the passband. * \\(\\Omega_{s,LP_equiv} = \\min\\left( \\left| \\frac{\\Omega_{s1}^2 - \\Omega_0^2}{\\Omega_{s1} B} \\right|, \\left| \\frac{\\Omega_{s2}^2 - \\Omega_0^2}{\\Omega_{s2} B} \\right| \\right)\\) * This \\(\\Omega_{s,LP_equiv}\\) is the stopband edge of an equivalent low-pass prototype whose passband edge is normalized to 1 rad/s. It represents the more stringent of the two possible transitions from the passband edges to the stopband edges."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-stop-bs-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-stop-bs-filter-order",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth Band-Stop (BS) Filter Order",
    "text": "Butterworth Band-Stop (BS) Filter Order\nThe order \\(N_{BS}\\) is the same as an equivalent Low-Pass Prototype. \\[N_{BS} \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\Omega_{trans,LP_equiv}\\right)}\\]\nExplanation of BS-Specific Variables: * \\(\\Omega_{s1}, \\Omega_{s2}\\): Stopband edge angular frequencies defining the rejected band (\\(\\Omega_{s1} &lt; \\Omega_{s2}\\)). \\(A_{min}\\) is the attenuation in this band. * \\(\\Omega_{p1}, \\Omega_{p2}\\): Passband edge angular frequencies outside the stopband (\\(\\Omega_{p1} &lt; \\Omega_{s1}\\) and \\(\\Omega_{p2} &gt; \\Omega_{s2}\\)). \\(A_{max}\\) is the ripple in these passbands. * \\(\\Omega_0 = \\sqrt{\\Omega_{s1}\\Omega_{s2}}\\): Geometric center frequency of the stopband. * \\(B = \\Omega_{s2} - \\Omega_{s1}\\): Bandwidth of the stopband. * \\(\\Omega_{p,LP_i} = \\left| \\frac{\\Omega_{pi} B}{\\Omega_{pi}^2 - \\Omega_0^2} \\right|\\) for \\(i=1\\) (using \\(\\Omega_{p1}\\)) and \\(i=2\\) (using \\(\\Omega_{p2}\\)). * These are the passband edges of an equivalent low-pass prototype whose stopband edge is normalized to 1 rad/s. * \\(\\Omega_{trans,LP_equiv} = \\frac{1}{\\min(\\Omega_{p,LP1}, \\Omega_{p,LP2})}\\) * This is the effective transition ratio (stopband edge / passband edge) for the equivalent low-pass prototype."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization",
    "title": "Sistemas y Señales Biomédicos",
    "section": "3. Determine the Filter Order (N) & Denormalization",
    "text": "3. Determine the Filter Order (N) & Denormalization\nCalculated based on specs and chosen filter type. scipy.signal.buttord (and similar for other types) can find this for analog filters.\n\n\n\nRequired Butterworth Filter Order (N): 14\n\n\nButterworth Natural Frequency (Wn_buttord): 6593.83 rad/s\n\n\n\nWn_buttord is the natural angular frequency (\\(\\Omega_n\\)) for the filter. For Butterworth, this is the -3dB cutoff frequency \\(\\Omega_c\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "3. Determine the Filter Order (N) & Denormalization",
    "text": "3. Determine the Filter Order (N) & Denormalization\nNormalized Lowpass to Denormalized Lowpass\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized LP with cutoff \\(\\Omega_c\\).\nTransformation: Replace \\(s_{norm}\\) with \\(s / \\Omega_c\\). \\[s_{norm} \\to \\frac{s}{\\Omega_c}\\]\nDenormalized Transfer Function: \\[H_{LP}(s) = H_{norm}\\left(\\frac{s}{\\Omega_c}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-highpass",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-highpass",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Lowpass to Denormalized Highpass",
    "text": "Normalized Lowpass to Denormalized Highpass\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized HP with cutoff \\(\\Omega_c\\).\nTransformation: Replace \\(s_{norm}\\) with \\(\\Omega_c / s\\). \\[s_{norm} \\to \\frac{\\Omega_c}{s}\\]\nDenormalized Transfer Function: \\[H_{HP}(s) = H_{norm}\\left(\\frac{\\Omega_c}{s}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandpass",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandpass",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Lowpass to Denormalized Bandpass",
    "text": "Normalized Lowpass to Denormalized Bandpass\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized BP with center frequency \\(\\Omega_0\\) and bandwidth \\(B\\).\nTransformation: Replace \\(s_{norm}\\) with \\(\\frac{s^2 + \\Omega_0^2}{B s}\\). \\[s_{norm} \\to \\frac{s^2 + \\Omega_0^2}{B s}\\]\nParameters:\n\n\\(\\Omega_0 = \\sqrt{\\Omega_1 \\Omega_2}\\) (geometric mean)\n\\(B = \\Omega_2 - \\Omega_1\\) (bandwidth) (\\(\\Omega_1, \\Omega_2\\) are the desired band edges in rad/s)\n\nDenormalized Transfer Function: \\[H_{BP}(s) = H_{norm}\\left(\\frac{s^2 + \\Omega_0^2}{B s}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandstop",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandstop",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Lowpass to Denormalized Bandstop",
    "text": "Normalized Lowpass to Denormalized Bandstop\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized BS with center frequency \\(\\Omega_0\\) and bandwidth \\(B\\).\nTransformation: Replace \\(s_{norm}\\) with \\(\\frac{B s}{s^2 + \\Omega_0^2}\\). \\[s_{norm} \\to \\frac{B s}{s^2 + \\Omega_0^2}\\]\nParameters:\n\n\\(\\Omega_0 = \\sqrt{\\Omega_1 \\Omega_2}\\)\n\\(B = \\Omega_2 - \\Omega_1\\)\n\nDenormalized Transfer Function: \\[H_{BS}(s) = H_{norm}\\left(\\frac{B s}{s^2 + \\Omega_0^2}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#obtain-analog-filter-transfer-function-h_as",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#obtain-analog-filter-transfer-function-h_as",
    "title": "Sistemas y Señales Biomédicos",
    "section": "4 & 5. Obtain Analog Filter Transfer Function \\(H_a(s)\\)",
    "text": "4 & 5. Obtain Analog Filter Transfer Function \\(H_a(s)\\)\nConceptually: Find normalized LP prototype \\(\\rightarrow\\) Denormalize \\(\\rightarrow\\) Transform.\nscipy.signal functions like butter, cheby1, etc., (with analog=True) perform these steps internally to give the final analog filter transfer function \\(H_a(s)\\).\n\\(H_a(s)\\) can be represented as: 1. Numerator (\\(b\\)) and Denominator (\\(a\\)) coefficients: \\(H_a(s) = \\frac{b_0 s^M + b_1 s^{M-1} + \\dots + b_M}{a_0 s^N + a_1 s^{N-1} + \\dots + a_N}\\) 2. Zeros (\\(z\\)), Poles (\\(p\\)), and Gain (\\(k\\)): \\(H_a(s) = k \\frac{\\prod (s-z_i)}{\\prod (s-p_j)}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#python-design-h_as-butterworth-lpf",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#python-design-h_as-butterworth-lpf",
    "title": "Sistemas y Señales Biomédicos",
    "section": "4 & 5. Python: Design \\(H_a(s)\\) (Butterworth LPF)",
    "text": "4 & 5. Python: Design \\(H_a(s)\\) (Butterworth LPF)\nUsing signal.butter with analog=True. The Wn parameter here should be the cutoff frequency \\(\\Omega_c\\). For buttord, the returned Wn_buttord is exactly this \\(\\Omega_c\\).\n\n\n\nAnalog Filter Coefficients (Numerator b, Denominator a):\n\n\nb_analog = [2.93718174e+53]\n\n\na_analog = [1.00000000e+00 5.88921844e+04 1.73414469e+09 3.37531810e+13\n 4.84169654e+17 5.40639098e+21 4.84125527e+25 3.52958830e+29\n 2.10491137e+33 1.02201934e+37 3.97946840e+40 1.20619642e+44\n 2.69441500e+47 3.97843852e+50 2.93718174e+53]\n\n\n\nAnalog Filter Zeros, Poles, Gain (ZPK):\n\n\nZeros (z_analog) = []\n\n\nPoles (p_analog) = [ -738.27500968+6552.37193897j -2177.8048373 +6223.80864963j\n -3508.13043664+5583.15760623j -4662.54372722+4662.54372722j\n -5583.15760623+3508.13043664j -6223.80864963+2177.8048373j\n -6552.37193897 +738.27500968j -6552.37193897 -738.27500968j\n -6223.80864963-2177.8048373j  -5583.15760623-3508.13043664j\n -4662.54372722-4662.54372722j -3508.13043664-5583.15760623j\n -2177.8048373 -6223.80864963j  -738.27500968-6552.37193897j]\n\n\nGain (k_analog) = 293718173729774468825490597908032846661500110135885824.00"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-analog-frequency-response-python",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-analog-frequency-response-python",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Visualizing Analog Frequency Response (Python)",
    "text": "Visualizing Analog Frequency Response (Python)\nUse scipy.signal.freqs to compute the frequency response of an analog filter given its \\(b,a\\) coefficients.\n\n\n(100.0, 7500)\n\n\n(-60.0, 5.0)\n\n\n(100.0, 7500)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#synthesize-the-circuit-realization",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#synthesize-the-circuit-realization",
    "title": "Sistemas y Señales Biomédicos",
    "section": "6. Synthesize the Circuit (Realization)",
    "text": "6. Synthesize the Circuit (Realization)\nConvert the mathematical \\(H_a(s)\\) into a physical electronic circuit. This step is not done by scipy.signal. It requires circuit design knowledge.\n\nPassive Filters:\n\nResistors (R), Inductors (L), Capacitors (C).\nCommonly “ladder” structures.\nInductors can be bulky/non-ideal, especially at low frequencies.\n\nActive Filters:\n\nOp-Amps, Resistors (R), Capacitors (C) (avoids inductors).\nCan provide gain, easy to cascade.\nRequires power. Limited by op-amp performance.\nCommon topologies: Sallen-Key, Multiple Feedback (MFB), State-Variable/Biquad.\nHigher-order filters are often cascaded 2nd-order sections."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#component-selection-and-simulation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#component-selection-and-simulation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "7. Component Selection and Simulation",
    "text": "7. Component Selection and Simulation\n\nComponent Values: Choose standard, available component values (R, C, L, Op-Amps) that are close to calculated ideals.\nTolerances: Account for component variations.\nNon-Idealities: Consider real-world behavior of components.\nCircuit Simulation (Essential):\n\nUse SPICE-based simulators (LTspice, QUCS, PSpice, etc.).\nVerify performance against specifications.\nIterate on design and component values as needed.\n\n\nThis is also outside the scope of scipy.signal but critical for hardware implementation."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#tools-for-analog-filter-design",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#tools-for-analog-filter-design",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Tools for Analog Filter Design",
    "text": "Tools for Analog Filter Design\n\nMathematical Software:\n\nPython with scipy.signal: Excellent for determining filter parameters (\\(N, \\Omega_c\\)) and transfer functions (\\(b,a\\) or \\(z,p,k\\)), and plotting responses.\nMATLAB (Signal Processing Toolbox), Octave.\n\nFilter Design Calculators/Software:\n\nTexas Instruments FilterPro™, Analog Devices Filter Wizard®.\nOnline calculators and dedicated filter design suites.\n\nCircuit Simulators:\n\nLTspice, QUCS, PSpice, NI Multisim™, Keysight ADS.\n\nFilter Design Handbooks:\n\nClassic texts (e.g., by Van Valkenburg, Zverev) provide theory, tables, and formulas."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#conclusion-for-analog-filter-design",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#conclusion-for-analog-filter-design",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Conclusion – For Analog Filter Design",
    "text": "Conclusion – For Analog Filter Design\nAnalog filter design is a multi-step process:\n\nSpecs \\(\\rightarrow\\) Theory \\(\\rightarrow\\) Math (\\(H_a(s)\\)) \\(\\rightarrow\\) Circuit \\(\\rightarrow\\) Verification.\nscipy.signal in Python is a powerful tool for the mathematical parts: determining order, calculating transfer function coefficients/poles/zeros, and analyzing frequency response for various analog filter prototypes.\nRealizing the physical circuit requires additional circuit design knowledge and simulation tools."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-apply-digital-transformation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-apply-digital-transformation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 5: Apply Digital Transformation",
    "text": "Step 5: Apply Digital Transformation\n\nConvert the designed analog filter \\(H_a(s)\\) to the digital domain \\(H(z)\\):\n\nIf Impulse Invariance: Use partial fractions and the \\(s_k \\rightarrow e^{s_k T}\\) mapping.\nIf Bilinear Transformation: Substitute \\(s = \\frac{2}{T} \\frac{1 - z^{-1}}{1 + z^{-1}}\\) into \\(H_a(s)\\) and simplify algebraically.\n\nResult: The digital filter transfer function: \\[H(z) = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{1 + \\sum_{k=1}^{N} a_k z^{-k}}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-implementation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-implementation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 6: Realization (Implementation)",
    "text": "Step 6: Realization (Implementation)\n\nThe transfer function \\(H(z)\\) corresponds directly to a difference equation: \\[y[n] = \\sum_{k=0}^{M} b_k x[n-k] - \\sum_{k=1}^{N} a_k y[n-k]\\]\n\\(x[n]\\): Input sequence\n\\(y[n]\\): Output sequence\n\\(b_k, a_k\\): Filter coefficients derived from \\(H(z)\\).\nThe feedback term (sum involving \\(y[n-k]\\)) makes the impulse response potentially infinite (IIR)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary: IIR Design Process",
    "text": "Summary: IIR Design Process\n\nDefine Digital Specs (\\(\\omega_p, \\omega_s, A_p, A_s\\)).\nSelect Transformation (e.g., Bilinear).\nPre-warp Frequencies (if Bilinear: \\(\\omega \\rightarrow \\Omega\\)).\nDesign Analog Filter \\(H_a(s)\\) (using prototypes & transformations).\nTransform to Digital \\(H(z)\\) (apply Bilinear or Impulse Invariance).\nRealize as Difference Equation for Implementation."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Digital Filter Specifications",
    "text": "Step 1: Digital Filter Specifications\n\nDefine the desired characteristics of the digital filter:\n\nSampling Frequency: \\(F_s\\) (Hz)\nCritical Frequencies (Digital):\n\nPassband edge: \\(f_p\\) (Hz) \\(\\implies \\omega_p = 2\\pi f_p / F_s\\) (radians/sample)\nStopband edge: \\(f_s\\) (Hz) \\(\\implies \\omega_s = 2\\pi f_s / F_s\\) (radians/sample)\nNote: Scipy often uses frequencies normalized to Nyquist: \\(W_p = f_p / (F_s/2)\\), \\(W_s = f_s / (F_s/2)\\)\n\nTolerances:\n\nMax. passband ripple/attenuation: \\(A_p\\) or gpass (dB)\nMin. stopband attenuation: \\(A_s\\) or gstop (dB)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-example-specifications-python",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-example-specifications-python",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Example Specifications (Python)",
    "text": "Step 1: Example Specifications (Python)\n\n\nSampling Frequency: 10000 Hz\n\n\nNormalized Passband Edge: 0.200 (pi rad/sample)\n\n\nNormalized Stopband Edge: 0.300 (pi rad/sample)\n\n\nMax Passband Loss: 1 dB\n\n\nMin Stopband Attenuation: 40 dB"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-designing-conceptual",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-designing-conceptual",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Steps 2-4: Finding Order & Designing (Conceptual)",
    "text": "Steps 2-4: Finding Order & Designing (Conceptual)\n\nTransformation: Bilinear Transform is implicitly used by many scipy.signal functions for IIR design.\nFrequency Pre-warping: Handled internally by Scipy when given digital frequency specs.\nAnalog Design: Scipy calculates the required analog prototype order and parameters based on the (internally pre-warped) specs.\nGoal: Find filter order \\(N\\) and digital cutoff frequency \\(W_n\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-wn-python---butterworth-example",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-wn-python---butterworth-example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Steps 2-4: Finding Order & Wn (Python - Butterworth Example)",
    "text": "Steps 2-4: Finding Order & Wn (Python - Butterworth Example)\n\nUse scipy.signal.buttord to find the minimum order and cutoff frequency for a digital Butterworth filter meeting the specs.\n\n\n\n\nMinimum Filter Order (N): 12\n\n\nButterworth Natural Frequency (Wn): 0.211 (pi rad/sample)\n\n\n\nanalog=False specifies we want parameters for a digital filter.\nWn is the digital cutoff frequency (scalar for LP/HP, tuple for BP/BS) required by the butter function. It’s often close to wp."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-designing-the-digital-filter-python---butterworth",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-designing-the-digital-filter-python---butterworth",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 5: Designing the Digital Filter (Python - Butterworth)",
    "text": "Step 5: Designing the Digital Filter (Python - Butterworth)\n\nUse scipy.signal.butter (or cheby1, cheby2, ellip) to get the filter coefficients \\(b\\) (numerator) and \\(a\\) (denominator) of \\(H(z)\\).\n\n\n\n\nFilter Coefficients:\n\n\nNumerator (b): [0.0e+00 0.0e+00 1.0e-05 4.0e-05 1.0e-04 1.6e-04 1.9e-04 1.6e-04 1.0e-04\n 4.0e-05 1.0e-05 0.0e+00 0.0e+00]\n\n\nDenominator (a): [ 1.000000e+00 -6.930840e+00  2.271843e+01 -4.632962e+01  6.523097e+01\n -6.662310e+01  5.050575e+01 -2.858485e+01  1.197050e+01 -3.612930e+00\n  7.452400e-01 -9.424000e-02  5.520000e-03]\n\n\n\noutput='ba' gives numerator/denominator coefficients. Other options: 'sos' (second-order sections - numerically better), 'zpk' (zeros, poles, gain)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-frequency-response-python",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-frequency-response-python",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Visualizing Frequency Response (Python)",
    "text": "Visualizing Frequency Response (Python)\n\nCalculate the frequency response using scipy.signal.freqz.\nPlot magnitude (in dB) and phase.\n\n\n\n(0.0, 5000.0)\n\n\n(-60.0, 5.0)\n\n\n(0.0, 5000.0)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-filtering-python-example",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-filtering-python-example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 6: Realization & Filtering (Python Example)",
    "text": "Step 6: Realization & Filtering (Python Example)\n\nThe coefficients b, a define the difference equation.\nUse scipy.signal.lfilter to apply the filter to a signal.\n\n\n\n(-1.5, 1.5)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process-with-scipy",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process-with-scipy",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary: IIR Design Process (with Scipy)",
    "text": "Summary: IIR Design Process (with Scipy)\n\nDefine Digital Specs (\\(f_p, f_s, gpass, gstop, F_s\\)). Normalize frequencies (\\(W_p, W_s\\)).\nSelect Filter Type (e.g., Butterworth) & find order/cutoff using buttord (digital).\nDesign Filter to get coefficients (\\(b, a\\)) using butter (digital).\nAnalyze Frequency Response using freqz.\nImplement/Apply Filter using lfilter (uses the difference equation implicitly).\n\n\nScipy handles the underlying analog prototype mapping, pre-warping, and bilinear transformation internally."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-machine-learning-ml",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-machine-learning-ml",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "¿Qué es Machine Learning (ML)?",
    "text": "¿Qué es Machine Learning (ML)?\n\nEl Machine Learning (Aprendizaje Automático) es un proceso automatizado que se encarga de extraer patrones a partir de los datos.\n\n\nEs un campo de conocimiento crucial y una tecnología omnipresente.\n\n\nSu objetivo fundamental es ajustar modelos a los datos proporcionados para permitir la predicción y clasificación."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-rol-de-la-predicción",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-rol-de-la-predicción",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "El Rol de la Predicción",
    "text": "El Rol de la Predicción\n\nEl ML busca aprender a predecir (estimar o aproximar) la etiqueta de un punto de datos basándose exclusivamente en sus características (features).\n\n\nImplementa el principio científico de “prueba y error”.\n\n\nEsto se logra refinando continuamente un modelo de forma iterativa, basándose en la pérdida incurrida por sus predicciones frente a los datos reales observados."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#componentes-esenciales",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#componentes-esenciales",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Componentes Esenciales",
    "text": "Componentes Esenciales\nLa teoría del Machine Learning se presenta como la combinación de tres componentes básicos e interdependientes:\n\nDatos (Data): La materia prima a partir de la cual el sistema aprende.\nModelo (Model): La estructura matemática que se ajusta a los datos (ej. red neuronal, árbol de decisión).\nFunción de Pérdida (Loss Function): Mide la discrepancia entre las predicciones del modelo y los valores reales observados."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-machine-learning-ml-y-la-sanidad",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-machine-learning-ml-y-la-sanidad",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "El Machine Learning (ML) y la Sanidad",
    "text": "El Machine Learning (ML) y la Sanidad\nEl Machine Learning (ML) es un proceso automatizado que se dedica a extraer patrones complejos de los datos. En el sector salud, el objetivo es utilizar el ML para apoyar la toma de decisiones clínicas y operacionales.\nEl ML supervisado aprende un modelo a partir de un conjunto de características descriptivas y una característica objetivo, basándose en un conjunto de ejemplos históricos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#tipos-de-modelos-de-ml",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#tipos-de-modelos-de-ml",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Tipos de Modelos de ML",
    "text": "Tipos de Modelos de ML\n\nModelos Predictivos: Permiten asignar un valor a cualquier variable desconocida, incluso si no tiene un aspecto temporal (como predecir un diagnóstico).\nRedes Neuronales Convolucionales (CNNs): Modelos de Deep Learning ideales para procesar datos con estructura de cuadrícula, como las imágenes, cruciales en el diagnóstico médico.\nIA Causal: Utilizada para hacer inferencias sobre causa y efecto, lo cual es vital en la biología, la medicina y el desarrollo de fármacos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#casos-de-uso-en-el-diagnóstico-médico",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#casos-de-uso-en-el-diagnóstico-médico",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Casos de Uso en el Diagnóstico Médico",
    "text": "Casos de Uso en el Diagnóstico Médico\nLa analítica predictiva se utiliza para construir modelos que asisten en el diagnóstico, aprovechando grandes colecciones de ejemplos históricos que superan lo que un solo individuo vería en su carrera.\n\nClasificación de Imágenes: Las CNNs son adecuadas para tareas que involucran datos con estructuras de cuadrícula fija.\nDetección de Cáncer: Los modelos se pueden construir para la identificación de especies bacterianas o la clasificación de muestras de tejido para el cáncer de mama.\nPredicción de Riesgo Cardiovascular (CVD): Los modelos de regresión logística pueden predecir la probabilidad de que un paciente tenga una enfermedad.\nMedicina de Precisión: Las distribuciones de probabilidad se usan para modelar poblaciones y subpoblaciones, lo cual ayuda a dirigir tratamientos específicos a grupos de pacientes que podrían beneficiarse, por ejemplo, los que tienen diabetes."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#desafíos-del-ml-en-el-sector-salud",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#desafíos-del-ml-en-el-sector-salud",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Desafíos del ML en el Sector Salud",
    "text": "Desafíos del ML en el Sector Salud\nLa IA Causal es fundamental para ir más allá de la correlación y estimar los efectos de una acción.\n\nOptimización de Dosis: Los modelos pueden predecir las dosis óptimas de un medicamento basándose en datos históricos de tratamientos y resultados asociados.\nCostos de I+D: El desarrollo de nuevos fármacos es costoso (puede llegar a USD 2-3 mil millones) y tiene una alta tasa de fracaso (95% en ensayos clínicos).\nErrores de Atribución: Una parte significativa de los fracasos en el desarrollo de medicamentos se atribuye a errores de atribución causal, como la mala selección de objetivos farmacológicos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#estimación-de-efectos-y-robustez",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#estimación-de-efectos-y-robustez",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Estimación de Efectos y Robustez",
    "text": "Estimación de Efectos y Robustez\n\nEfectos Heterogéneos del Tratamiento (CATEs): Miden cómo varían los efectos de un tratamiento en diferentes segmentos de la población.\nRobutsez Adversarial: En aplicaciones sensibles, la seguridad de los modelos debe ser evaluada frente a ataques, como la manipulación de imágenes médicas."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#la-necesidad-de-modelos-interpretables",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#la-necesidad-de-modelos-interpretables",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "La Necesidad de Modelos Interpretables",
    "text": "La Necesidad de Modelos Interpretables\nLa interpretación es esencial para garantizar que los modelos sean seguros, justos y fiables.\n\nTransparencia y Explicación: La interpretabilidad reduce la brecha entre los complejos algoritmos y los usuarios humanos.\nDecisiones Cruciales: En ámbitos como el diagnóstico de cáncer, la interpretación del modelo es crucial para justificar las predicciones.\nEquidad y Rendición de Cuentas (FAT): La interpretación ayuda a asegurar que las predicciones se hagan sin sesgos discernibles (equidad) y a explicar por qué se tomaron ciertas decisiones (rendición de cuentas).\nModelos de Caja Blanca: Modelos como la regresión logística son inherentemente interpretables (intrínsecamente interpretables) porque su lógica es transparente."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-problema-fundamental-búsqueda-y-bias",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-problema-fundamental-búsqueda-y-bias",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "El Problema Fundamental: Búsqueda y Bias",
    "text": "El Problema Fundamental: Búsqueda y Bias\nLos algoritmos de ML funcionan buscando entre un conjunto de modelos posibles para encontrar aquel que mejor se ajusta a los datos.\n\nProblema Mal Planteado (Ill-Posed Problem): La muestra de datos de entrenamiento es limitada. Como resultado, muchos modelos pueden ser consistentes con los datos, haciendo imposible elegir una solución única solo por la consistencia.\nSin una guía, un modelo solo memorizaría los datos (un extremo de sobreajuste)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#guía-para-la-selección-del-modelo",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#guía-para-la-selección-del-modelo",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Guía para la Selección del Modelo",
    "text": "Guía para la Selección del Modelo\nPara encontrar el modelo que mejor generaliza, los algoritmos utilizan un conjunto de suposiciones llamado Bias Inductivo.\nEste bias dirige la búsqueda del algoritmo hacia modelos específicos que se asumen más apropiados para el dominio.\n\n\nTipos de Bias\n\nBias de Restricción: Limita el conjunto de modelos posibles (ej. solo considerar modelos lineales).\nBias de Preferencia: Prefiere modelos con ciertas características (ej. preferir modelos más simples o menos complejos).\n\n\nErrores Comunes\nSi el bias inductivo es inapropiado, el modelo cometerá errores de generalización: - Underfitting (Subajuste): Modelo demasiado simplista que no captura la relación subyacente. - Overfitting (Sobreajuste): Modelo demasiado complejo que se ajusta al ruido en los datos de entrenamiento."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-error",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-error",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Paradigmas de Aprendizaje: Modelos Basados en Error",
    "text": "Paradigmas de Aprendizaje: Modelos Basados en Error\nEstos modelos buscan un conjunto de parámetros que minimice el error total en las predicciones con respecto al conjunto de entrenamiento.\n\nConcepto Central: Descenso de Gradiente (Gradient Descent). Es un algoritmo de búsqueda guiada que ajusta iterativamente los parámetros del modelo (pesos) para moverse hacia el mínimo global en una superficie de error.\nFunción de Pérdida: Típicamente el Error Cuadrático Sumado (\\(L2\\)) o la Pérdida de Entropía Cruzada.\nEjemplo: Regresión Logística/Lineal. El modelo se define mediante una combinación lineal de las características descriptivas multiplicadas por un conjunto de pesos.\nRegla de Actualización: El ajuste del peso (\\(\\Delta w\\)) es proporcional a la tasa de aprendizaje (\\(\\alpha\\)) y al gradiente de error."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-similitud",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-similitud",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Paradigmas de Aprendizaje: Modelos Basados en Similitud",
    "text": "Paradigmas de Aprendizaje: Modelos Basados en Similitud\nSe basan en la idea de que si una instancia es similar a instancias históricas, tendrá la misma etiqueta o valor objetivo.\n\nAlgoritmos: k-Vecinos Más Cercanos (k-NN).\nEspacio de Características: Las instancias se representan como puntos en un espacio de características, y la distancia entre ellas mide su disimilitud.\nFuncionamiento: Para una nueva consulta, el modelo identifica los \\(k\\) vecinos más cercanos y predice la clase por voto mayoritario o el valor por promedio de sus vecinos.\nMétricas: Comúnmente se usa la Distancia Euclidiana o la Distancia Mahalanobis (que considera la covarianza entre características)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-información",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-información",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Paradigmas de Aprendizaje: Modelos Basados en Información",
    "text": "Paradigmas de Aprendizaje: Modelos Basados en Información\nEstos modelos determinan qué características son las más informativas para realizar una secuencia de pruebas.\n\nAlgoritmos: Árboles de Decisión (Decision Trees).\nEstructura: Se construye una estructura jerárquica donde los nodos internos representan pruebas de características y los nodos hoja representan la predicción.\nMedida Clave: La Ganancia de Información (Information Gain), calculada a partir de la Entropía, mide la reducción en la impureza del conjunto de datos al dividirlo por una característica.\nBias: Los algoritmos (como ID3) prefieren los árboles más superficiales (menos complejos)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-crisp-dm",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-crisp-dm",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "¿Qué es CRISP-DM?",
    "text": "¿Qué es CRISP-DM?\n\nEstándar de facto para proyectos analíticos.\n6 fases iterativas: Entendimiento del negocio, Entendimiento de los datos, Preparación de los datos, Modelado, Evaluación, Despliegue.\nCiclo no lineal; retroalimentación entre fases."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-diagrama",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-diagrama",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Visión general (diagrama)",
    "text": "Visión general (diagrama)\n\n\n\n\n\n\n\nArtefactos\n\n\ncluster0\n\n1. Negocio\n\n\ncluster1\n\n2. Datos\n\n\ncluster2\n\n3. Preparación\n\n\ncluster3\n\n4. Modelado\n\n\ncluster4\n\n5. Evaluación\n\n\ncluster5\n\n6. Despliegue\n\n\n\nN1\n\n\n\nPICO/PECO\n\n\n\nD1\n\n\n\nInventario de fuentes\n\n\n\nN1-&gt;D1\n\n\nrequisitos\n de datos\n\n\n\nN2\n\n\n\nKPIs & Umbrales\n\n\n\nN3\n\n\n\nRiesgos & Ética\n\n\n\nD2\n\n\n\nData Dictionary\n\n\n\nD3\n\n\n\nData Quality Report\n\n\n\nP1\n\n\n\nLimpieza/Imputación\n\n\n\nD3-&gt;P1\n\n\ncalidad\n\n\n\nP1-&gt;D2\n\n\nmetadatos\n\n\n\nP2\n\n\n\nIngeniería de features\n\n\n\nP3\n\n\n\nSplits anti-fuga\n\n\n\nM1\n\n\n\nBaselines\n\n\n\nP3-&gt;M1\n\n\ndataset\n modelable\n\n\n\nM1-&gt;P2\n\n\nfeatures\n\n\n\nM2\n\n\n\nTuning & CV\n\n\n\nM3\n\n\n\nArtefacto de inferencia\n\n\n\nE1\n\n\n\nROC/PR/Calibración\n\n\n\nM3-&gt;E1\n\n\nmodelo\n\n\n\nE1-&gt;M1\n\n\najustes\n\n\n\nE2\n\n\n\nErrores críticos\n\n\n\nE3\n\n\n\nAnálisis por subgrupos\n\n\n\nS1\n\n\n\nContenedor/Package\n\n\n\nE3-&gt;S1\n\n\ngo/no-go\n\n\n\nS2\n\n\n\nMonitoreo & Alertas\n\n\n\nS3\n\n\n\nPlan de retraining"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entendimiento del negocio",
    "text": "Entendimiento del negocio\n\nProblema clínico/laboral y población objetivo.\nMetas analíticas: clasificación, regresión, segmentación, detección.\nKPIs y restricciones: seguridad, costo, tiempo, privacidad.\nCriterio de éxito: p. ej., AUC ≥ 0.90, sensibilidad ≥ 0.95 en clase minoritaria.\nPlan del proyecto: roles, riesgos, cronograma y datos requeridos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 1)",
    "text": "Entregables (Fase 1)\n\nDeclaración PICO/PECO del problema.\nMapa de stakeholders y requisitos.\nMétricas primarias/secundarias y umbrales mínimos.\nProtocolos de ética y gobernanza de datos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#pico-ensayos-clínicos-intervenciones",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#pico-ensayos-clínicos-intervenciones",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "PICO (ensayos clínicos / intervenciones)",
    "text": "PICO (ensayos clínicos / intervenciones)\n\nPopulation (Población): ¿en quiénes? (pacientes, criterios de inclusión/exclusión).\nIntervention (Intervención): ¿qué intervención/exposición activa? (tratamiento, protocolo, dispositivo).\nComparator (Comparador): ¿contra qué se compara? (placebo, estándar de cuidado, otra intervención).\nOutcome (Resultado): ¿qué desenlaces medimos? (clínicos, funcionales, seguridad), con definición operacional y horizonte temporal.\n\nCuándo usarlo: preguntas de efectividad/eficacia de una intervención (típico en ECA o cuasi-experimentos).\nEjemplo (biomédico – señales)\n\nP: Adultos con sospecha de fibrilación auricular en monitoreo Holter.\nI: Algoritmo de detección basado en ECG de 1 derivación con filtro adaptativo.\nC: Lectura por cardiólogo + algoritmo convencional validado.\nO: Sensibilidad ≥ 0.95 y valor predictivo positivo ≥ 0.90 para episodios ≥ 30 s, en validación ciega."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#peco-observacionales-exposiciones",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#peco-observacionales-exposiciones",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "PECO (observacionales / exposiciones)",
    "text": "PECO (observacionales / exposiciones)\n\nPopulation (Población): ¿en quiénes?\nExposure (Exposición): ¿qué factor de exposición? (p. ej., carga mecánica, turno nocturno, tabaquismo).\nComparator (Comparador): nivel de exposición de referencia (no expuestos / menos expuestos).\nOutcome (Resultado): desenlaces (incidencia, progresión, biomarcadores), con definición y ventana temporal.\n\nCuándo usarlo: preguntas de asociación causal o riesgo en estudios cohortes/casos y controles/transversales.\nEjemplo (biomecánica – LCA)\n\nP: Deportistas amateur 18–35 años post-reconstrucción de LCA.\nE: Asimetría de momento extensor de rodilla &gt; 15% durante salto con caída.\nC: Asimetría ≤ 15%.\nO: Re-lesión contralateral o ipsilateral a 12 meses."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#consejos-operativos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#consejos-operativos",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Consejos operativos",
    "text": "Consejos operativos\n\nDefinir Outcomes con métricas, umbrales y ventana temporal (p. ej., “∆IKDC ≥ 10 puntos a 6 meses”).\nEn PECO, describir la medición de la exposición (instrumento, frecuencia, umbral) para minimizar sesgo de clasificación.\nEspecificar a priori confusores y plan de ajuste (edad, sexo, dominio lateral, centro).\nEvitar outcomes compuestos mal justificados; priorizar uno primario y secundarios jerárquicos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#plantillas-rápidas",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#plantillas-rápidas",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Plantillas rápidas",
    "text": "Plantillas rápidas\n\nPICO: “En P, ¿la I comparada con C mejora O en T?”\nPECO: “En P, ¿la E frente a C se asocia con O en T, controlando por confusores?”"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entendimiento de los datos",
    "text": "Entendimiento de los datos\n\nInventario de fuentes: dispositivos, HIS/RIS, PACS, cuadernos de campo.\nExploración: tipos de variables, distribución, cardinalidad, valores faltantes.\nCalidad de datos: outliers, inconsistencias, sesgos de muestreo.\nPlan de calidad (qué corregir ahora vs. más adelante).\n\n\n\nRecomendación: elaborar un Data Quality Report y un diccionario de datos versionado."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 2)",
    "text": "Entregables (Fase 2)\n\nData Quality Report (resumen estadístico + visualizaciones clave).\nDiccionario de datos y esquema de metadatos.\nLista de riesgos de validez (fuga de datos, leakage temporal, etc.)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparación-de-los-datos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparación-de-los-datos",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Preparación de los datos",
    "text": "Preparación de los datos\n\nLimpieza: imputación, manejo de atípicos, corrección de etiquetas.\nTransformaciones: normalización/estandarización, codificación categórica.\nIngeniería de características: ventanas temporales, espectro, texturas, ROI.\nParticiones: train/val/test con reglas anti-fuga (por paciente/centro).\n\n\n\nBiomédico: documente pipelines reproducibles con scripts y seed fijo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 3)",
    "text": "Entregables (Fase 3)\n\nABT (Analytical Base Table) o dataset modelable, con versión.\nPipelines de preproceso (código + parámetros + pruebas).\nEvidencia de no-fuga y balance/clase."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Modelado",
    "text": "Modelado\n\nBaselines robustos y trazables (p. ej., regresión logística, NB, SVM).\nModelos avanzados: árboles/ensembles, deep learning si aplica.\nValidación: K-fold estratificado por sujeto/centro; early stopping.\nTuning: búsqueda de hiperparámetros; ablation de features."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 4)",
    "text": "Entregables (Fase 4)\n\nReporte de experimentos (configuraciones, semillas, versiones).\nCurvas y tablas: ROC/PR, aprendizaje, calibración, importancia de variables.\nModelo empaquetado (artefacto + inference script + schema de I/O)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluación",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Evaluación",
    "text": "Evaluación\n\nValidez técnica: desempeño, incertidumbre, estabilidad temporal.\nValidez clínica/operacional: umbrales de decisión, impacto, costos.\nExplicabilidad: errores críticos, análisis por subgrupos (equidad).\nRevisión de riesgos: seguridad, privacidad, robustez, shift de dominio."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 5)",
    "text": "Entregables (Fase 5)\n\nInforme de evaluación con estratificación por subpoblaciones.\nMatriz de confusión, curvas ROC/PR, lift/gain si hay casos raros.\nDecisiones de go/no-go y plan de mitigación de riesgos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Despliegue",
    "text": "Despliegue\n\nMVP en entorno controlado (sandbox/val clínica) con monitoreo.\nMLOps: versionado de datos/modelos, CI/CD, model registry.\nMonitoreo post-despliegue: drift, desempeño, alertas.\nCiclo de mantenimiento: retraining, gobernanza, auditoría."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 6)",
    "text": "Entregables (Fase 6)\n\nPaquete de despliegue (contenedor o wheel), manual de integración.\nTablero de monitoreo y protocolo de incidentes.\nPlan de actualización y retiro seguro del modelo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Checklist resumido",
    "text": "Checklist resumido\n\nProblema y métricas claros.\nDatos caracterizados y limpios.\nParticiones sin fuga.\nBaseline y SOTA comparables.\nEvaluación por subgrupos.\nPlan de despliegue y monitoreo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-crisp-dm-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-crisp-dm-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "¿Qué es CRISP-DM?",
    "text": "¿Qué es CRISP-DM?\n\nEstándar de facto para proyectos analíticos.\n6 fases iterativas: Entendimiento del negocio, Entendimiento de los datos, Preparación de los datos, Modelado, Evaluación, Despliegue.\nCiclo no lineal; retroalimentación entre fases.\n\n\n\nConsejo: marque explícitamente supuestos, riesgos y decisiones en actas breves por fase."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-diagrama-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-diagrama-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Visión general (diagrama)",
    "text": "Visión general (diagrama)\n\n\n\n\n\n\n\nCRISPDM\n\n\n\nA\n\nEntendimiento\n del negocio\n\n\n\nB\n\nEntendimiento\n de los datos\n\n\n\nA-&gt;B\n\n\n\n\n\nC\n\nPreparación\n de los datos\n\n\n\nB-&gt;C\n\n\n\n\n\nC-&gt;B\n\n\nretrabajo\n\n\n\nD\n\nModelado\n\n\n\nC-&gt;D\n\n\n\n\n\nD-&gt;B\n\n\ndiagnósticos\n\n\n\nE\n\nEvaluación\n\n\n\nD-&gt;E\n\n\n\n\n\nE-&gt;A\n\n\nredefinir metas\n\n\n\nF\n\nDespliegue\n\n\n\nE-&gt;F"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-artefactos-por-fase",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-artefactos-por-fase",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Visión general (artefactos por fase)",
    "text": "Visión general (artefactos por fase)\n\n\n\n\n\n\n\nArtefactos\n\n\ncluster0\n\n1. Negocio\n\n\ncluster1\n\n2. Datos\n\n\ncluster2\n\n3. Preparación\n\n\ncluster3\n\n4. Modelado\n\n\ncluster4\n\n5. Evaluación\n\n\ncluster5\n\n6. Despliegue\n\n\n\nN1\n\n\n\nPICO/PECO\n\n\n\nD1\n\n\n\nInventario de fuentes\n\n\n\nN1-&gt;D1\n\n\nrequisitos\n de datos\n\n\n\nN2\n\n\n\nKPIs & Umbrales\n\n\n\nN3\n\n\n\nRiesgos & Ética\n\n\n\nD2\n\n\n\nData Dictionary\n\n\n\nD3\n\n\n\nData Quality Report\n\n\n\nP1\n\n\n\nLimpieza/Imputación\n\n\n\nD3-&gt;P1\n\n\ncalidad\n\n\n\nP1-&gt;D2\n\n\nmetadatos\n\n\n\nP2\n\n\n\nIngeniería de features\n\n\n\nP3\n\n\n\nSplits anti-fuga\n\n\n\nM1\n\n\n\nBaselines\n\n\n\nP3-&gt;M1\n\n\ndataset\n modelable\n\n\n\nM1-&gt;P2\n\n\nfeatures\n\n\n\nM2\n\n\n\nTuning & CV\n\n\n\nM3\n\n\n\nArtefacto de inferencia\n\n\n\nE1\n\n\n\nROC/PR/Calibración\n\n\n\nM3-&gt;E1\n\n\nmodelo\n\n\n\nE1-&gt;M1\n\n\najustes\n\n\n\nE2\n\n\n\nErrores críticos\n\n\n\nE3\n\n\n\nAnálisis por subgrupos\n\n\n\nS1\n\n\n\nContenedor/Package\n\n\n\nE3-&gt;S1\n\n\ngo/no-go\n\n\n\nS2\n\n\n\nMonitoreo & Alertas\n\n\n\nS3\n\n\n\nPlan de retraining"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "1) Entendimiento del negocio",
    "text": "1) Entendimiento del negocio\n\nProblema clínico/laboral y población objetivo.\nMetas analíticas: clasificación, regresión, segmentación, detección.\nKPIs y restricciones: seguridad, costo, tiempo, privacidad.\nCriterio de éxito: p. ej., AUC ≥ 0.90, sensibilidad ≥ 0.95 en clase minoritaria.\nPlan del proyecto: roles, riesgos, cronograma y datos requeridos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 1)",
    "text": "Entregables (Fase 1)\n\nDeclaración PICO/PECO del problema.\nMapa de stakeholders y requisitos.\nMétricas primarias/secundarias y umbrales mínimos.\nProtocolos de ética y gobernanza de datos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "2) Entendimiento de los datos",
    "text": "2) Entendimiento de los datos\n\nInventario de fuentes: dispositivos, HIS/RIS, PACS, cuadernos de campo.\nExploración: tipos de variables, distribución, cardinalidad, valores faltantes.\nCalidad de datos: outliers, inconsistencias, sesgos de muestreo.\nPlan de calidad (qué corregir ahora vs. más adelante).\n\n\n\nRecomendación: elaborar un Data Quality Report y un diccionario de datos versionado."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 2)",
    "text": "Entregables (Fase 2)\n\nData Quality Report (resumen estadístico + visualizaciones clave).\nDiccionario de datos y esquema de metadatos.\nLista de riesgos de validez (fuga de datos, leakage temporal, etc.)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparación-de-los-datos-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparación-de-los-datos-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "3) Preparación de los datos",
    "text": "3) Preparación de los datos\n\nLimpieza: imputación, manejo de atípicos, corrección de etiquetas.\nTransformaciones: normalización/estandarización, codificación categórica.\nIngeniería de características: ventanas temporales, espectro, texturas, ROI.\nParticiones: train/val/test con reglas anti-fuga (por paciente/centro).\n\n\n\nBiomédico: documente pipelines reproducibles con scripts y seed fijo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 3)",
    "text": "Entregables (Fase 3)\n\nABT (Analytical Base Table) o dataset modelable, con versión.\nPipelines de preproceso (código + parámetros + pruebas).\nEvidencia de no-fuga y balance/clase."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "4) Modelado",
    "text": "4) Modelado\n\nBaselines robustos y trazables (p. ej., regresión logística, NB, SVM).\nModelos avanzados: árboles/ensembles, deep learning si aplica.\nValidación: K-fold estratificado por sujeto/centro; early stopping.\nTuning: búsqueda de hiperparámetros; ablation de features."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 4)",
    "text": "Entregables (Fase 4)\n\nReporte de experimentos (configuraciones, semillas, versiones).\nCurvas y tablas: ROC/PR, aprendizaje, calibración, importancia de variables.\nModelo empaquetado (artefacto + inference script + schema de I/O)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluación-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "5) Evaluación",
    "text": "5) Evaluación\n\nValidez técnica: desempeño, incertidumbre, estabilidad temporal.\nValidez clínica/operacional: umbrales de decisión, impacto, costos.\nExplicabilidad: errores críticos, análisis por subgrupos (equidad).\nRevisión de riesgos: seguridad, privacidad, robustez, shift de dominio."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 5)",
    "text": "Entregables (Fase 5)\n\nInforme de evaluación con estratificación por subpoblaciones.\nMatriz de confusión, curvas ROC/PR, lift/gain si hay casos raros.\nDecisiones de go/no-go y plan de mitigación de riesgos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "6) Despliegue",
    "text": "6) Despliegue\n\nMVP en entorno controlado (sandbox/val clínica) con monitoreo.\nMLOps: versionado de datos/modelos, CI/CD, model registry.\nMonitoreo post-despliegue: drift, desempeño, alertas.\nCiclo de mantenimiento: retraining, gobernanza, auditoría."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 6)",
    "text": "Entregables (Fase 6)\n\nPaquete de despliegue (contenedor o wheel), manual de integración.\nTablero de monitoreo y protocolo de incidentes.\nPlan de actualización y retiro seguro del modelo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Checklist resumido",
    "text": "Checklist resumido\n\nProblema y métricas claros.\nDatos caracterizados y limpios.\nParticiones sin fuga.\nBaseline y SOTA comparables.\nEvaluación por subgrupos.\nPlan de despliegue y monitoreo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-1-negocio",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-1-negocio",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 1 — Negocio",
    "text": "Fase 1 — Negocio\n1.1 Declaración PICO/PECO\n**Tipo**: PICO | PECO\n**Población (P)**:\n**Intervención/Exposición (I/E)**:\n**Comparador (C)**:\n**Outcomes (O)**:\n**Horizonte temporal (T)**:\n**Confusores a controlar**:\n**Criterio de éxito** (umbral y justificación):\n1.2 Mapa de stakeholders y requisitos\n**Stakeholders clave**: clínica, ingeniería, TI, ética, pacientes.\n**Requisitos funcionales**:\n- RF1:\n- RF2:\n**Requisitos no funcionales** (seguridad, latencia, costo):\n- RNF1:\n- RNF2:\n**Riesgos y supuestos**:\n- R1:\n- S1:\n1.3 Métricas primarias/ secundarias\n**Tarea**: clasificación | regresión | segmentación | detección\n**Métrica primaria**: (p. ej., Sensibilidad@95% especificidad)\n**Métricas secundarias**: (AUC, F1, Brier, MAE, Dice/IoU)\n**Umbrales mínimos**:\n**Justificación clínica/operativa**:\n1.4 Ética y gobernanza de datos\n**Base legal** (consentimiento/anonimización):\n**Evaluación de riesgo** (privacidad, sesgo, seguridad):\n**Controles** (pseudonimización, control de acceso, auditoría):\n**Plan de datos** (retención, eliminación, transferencia):"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-2-datos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-2-datos",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 2 — Datos",
    "text": "Fase 2 — Datos\n2.1 Data Quality Report (DQR)\n**Origen de datos**: dispositivos/HIS/PACS/CSV/etc.\n**Cobertura temporal**:\n**Resumen por variable**:\n| Variable | Tipo | Unidades | % NA | Únicos | Min | Q1 | Mediana | Q3 | Max |\n|---|---|---|---:|---:|---:|---:|---:|---:|---:|\n| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n\n**Chequeos de reglas** (rangos plausibles, consistencia):\n- R1:\n- R2:\n**Outliers y tratamiento propuesto**:\n**Sesgos potenciales** (selección, medición):\n2.2 Diccionario de datos\n| Nombre | Descripción | Tipo | Dominio/Unidades | Fuente | Notas |\n|---|---|---|---|---|---|\n| ... | ... | ... | ... | ... | ... |\n2.3 Riesgos de validez\n**Fugas potenciales**: por paciente, por tiempo, por sitio.\n**Dependencias**: variables derivadas del futuro.\n**Mitigaciones**: reglas de partición, ventanas estrictas."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-3-preparación",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-3-preparación",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 3 — Preparación",
    "text": "Fase 3 — Preparación\n3.1 ABT / Dataset modelable (versión)\n**ID de versión**: abt_vYYYYMMDD\n**Clave de unidad analítica**: (p. ej., paciente, estudio, ventana)\n**Target**:\n**Features**: listado y fuente de cada una\n**Partición**: train/val/test con conteos por clase y por paciente\n3.2 Pipelines de preprocesamiento\n# pipeline_prepro.yaml\nversion: 1\nstages:\n  - name: limpieza\n    steps:\n      - imputacion: {estrategia: median, variables: [x1, x2]}\n      - winsorizacion: {p: 0.01}\n  - name: transformaciones\n    steps:\n      - estandarizacion: {método: zscore, by: train}\n      - pca: {var_explicada: 0.95}\nartifacts:\n  logs_dir: logs/\n  seed: 42\n3.3 Evidencia de no-fuga y balance\n**Regla anti-fuga**: split por paciente/centro/fecha.\n**Chequeo**: 0 pacientes compartidos entre train/val/test.\n**Distribución de clases**:\n| Partición | n | Clase+ | Clase- | %+ |\n|---|---:|---:|---:|---:|\n| Train | | | | |\n| Val   | | | | |\n| Test  | | | | |"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-4-modelado",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-4-modelado",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 4 — Modelado",
    "text": "Fase 4 — Modelado\n4.1 Reporte de experimentos\n**ID experimento**: exp_YYYYMMDD_hhmm\n**Código/commit**:\n**Semilla**: 42\n**Modelo**: (p. ej., LogisticRegression, ResNet18)\n**Features/inputs**:\n**Hiperparámetros**:\n**Esquema de validación**: K-fold estratificado (por paciente)\n4.2 Resultados\n**Curvas**: ROC, PR, calibración (con bandas de confianza)\n**Tablas**: métricas por fold y promedio ± IC95%\n**Importancia de variables/atributos**: SHAP/coeficientes\n4.3 Artefacto de inferencia\n**Formato**: .pt | .onnx | .joblib | contenedor\n**Schema I/O**: tipos, unidades, validaciones\n**Script**: `inference.py` con prepro + postpro\n**Checksum y versión**:"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-5-evaluación",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-5-evaluación",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 5 — Evaluación",
    "text": "Fase 5 — Evaluación\n5.1 Informe técnico de evaluación\n**Desempeño en test**: tabla principal de métricas\n**Estratificación**: por sexo/edad/centro/dispositivo\n**Análisis de errores**: casos representativos, costos\n**Equidad**: diferencias absolutas/relativas entre subgrupos\n5.2 Matrices y curvas\n**Matriz de confusión**: umbral óptimo/operativo\n**Curvas**: ROC/PR; métricas agregadas (AUC, AP)\n**Lift/Gain** (si prevalencia baja)\n5.3 Decisión y riesgos\n**Go/No-Go**: criterio y evidencia\n**Riesgos residuales**: lista y mitigaciones\n**Plan de validación externa**: sitio/fecha/muestra"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-6-despliegue",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-6-despliegue",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 6 — Despliegue",
    "text": "Fase 6 — Despliegue\n6.1 Paquete de despliegue\n**Estrategia**: contenedor | wheel | servicio\n**Infra**: CPU/GPU, RAM, almacenamiento\n**Integración**: API/HL7/DICOM, autenticación\n**Rollback**: versión estable y procedimiento\n6.2 Monitoreo y respuesta a incidentes\n**KPIs en producción**: latencia, tasa de error, drift, desempeño\n**Alertas**: umbrales y canal (email/ops)\n**Runbooks**: pasos ante fallo de modelo/datos/infra\n6.3 Mantenimiento y retiro\n**Retraining**: criterio de activación, datos y frecuencia\n**Auditoría**: trazabilidad de versiones y accesos\n**Retiro seguro**: plan de sustitución y archivo de modelos"
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Rol: Diseñador instruccional (AA en señales e imágenes médicas)\nAudiencia: Pregrado (profundización, nivel avanzado)\nDuración total: 24 horas (8 sesiones × 3 h)\nStack principal: Python 3.12, scikit-learn, PyTorch, MONAI, MNE (según caso)\nPolítica de validación: subject-wise k-fold en todas las prácticas\nEvaluación sumativa: 7 mini-labs (70%) + quiz final (30%)\nÉnfasis clínico: Musculoesquelético (EMG/RX/TC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n#\nTítulo\nBloque\nHoras\nEntregable\n\n\n\n\n1\nFundamentos de AA en salud: tareas, métricas y pipeline\nFundamentos\n3\nMini-lab 1: pipeline clásico (sklearn)\n\n\n2\nValidación rigurosa y reproducibilidad (subject-wise)\nFundamentos\n3\nMini-lab 2: split subject-wise + baseline\n\n\n3\nSeñales biomédicas I: preprocesado y features (ECG/EMG)\nSeñales\n3\nMini-lab 3: filtro → features → clasificación\n\n\n4\nSeñales biomédicas II: ML clásico vs CNN 1D\nSeñales\n3\nMini-lab 4: baseline vs CNN1D (comparativa)\n\n\n5\nSeñales biomédicas III: LSTM/GRU/Transformers 1D + explicabilidad\nSeñales\n3\nMini-lab 5: secuenciales + saliency/IG\n\n\n6\nImágenes médicas I: DICOM, preprocesado y transfer learning\nImágenes\n3\nMini-lab 6: fine-tuning (MONAI)\n\n\n7\nImágenes médicas II: U-Net/ResNet, métricas y Grad-CAM\nImágenes\n3\nMini-lab 7: segmentación + Grad-CAM\n\n\n8\nIntegración, buenas prácticas y quiz final\nImágenes (cierre)\n3\nQuiz final + repositorio reproducible\n\n\n\nBalance de horas por bloque (aprox.): Fundamentos 6 h (≈30%), Señales 9 h (≈35%), Imágenes 9 h (≈35%).\nEvaluación (modelo 5B): 7 mini-labs × 10% c/u = 70%; Quiz final = 30%.\n\n\n\n\n\nResultados de aprendizaje:\nRA1. Diferenciar tareas (clasificación, regresión, segmentación).\nRA2. Seleccionar métricas apropiadas por tarea (Acc, AUC, F1, MAE; Dice/IoU para segmentación).\nRA3. Describir un pipeline reproducible de AA en salud.\nConceptos clave: problema/tarea, train/val/test, baseline, feature engineering, normalización, data leakage.\nActividad práctica (PhysioNet, sklearn):\nClasificar latidos ECG (e.g., MIT-BIH o PTB-XL de PhysioNet). Preproceso básico, split estratificado por paciente (sin fuga), baseline con LogReg/SVM.\nStack: Python 3.12, scikit-learn, numpy, pandas, matplotlib.\nValidación: subject-wise k-fold (k=5).\nEvaluación: Mini-lab 1 (10%).\nReferencias sugeridas (verificar DOI/ISBN antes de publicar):\n\nBishop, Pattern Recognition and Machine Learning, 2006, ISBN 978-0387310732.\nPedregosa et al., Scikit-learn: Machine Learning in Python, JMLR 12:2825–2830, 2011.\n\nRiesgos comunes: fuga por segmentos del mismo paciente; métricas inadecuadas por clase desbalanceada.\n\n\n\n\n\n\nResultados:\nRA1. Implementar subject-wise k-fold y reportes por clase.\nRA2. Configurar entorno reproducible y seeds.\nRA3. Documentar experimentos (versionado y data cards).\nConceptos: subject-wise vs aleatorio, nested CV, semillas, hojas de datos, readme de experimentos.\nActividad (PhysioNet, sklearn):\nRepetir baseline sesión 1 con particionamiento subject-wise k-fold y reporte de varianza entre folds.\nStack: scikit-learn, mlflow (opcional), pyproject.toml o conda env, control de versiones.\nValidación: subject-wise k-fold con estratificación si aplica.\nEvaluación: Mini-lab 2 (10%).\nReferencias:\n\nGéron, Hands-On Machine Learning, 2ª/3ª ed., O’Reilly, ISBN 978-1492032649.\n\nRiesgos: comparar métricas de folds no homólogos; no fijar semillas; no congelar versiones.\n\n\n\n\n\n\nResultados:\nRA1. Aplicar filtrado, resampling y normalización en ECG/EMG.\nRA2. Extraer features en tiempo/frecuencia (RMS, picos R, bandas).\nRA3. Entrenar un clasificador clásico y evaluar robustez.\nConceptos: filtros pasa-banda, remoción de línea base, windowing, PSD, z-score.\nActividad (PhysioNet):\nECG MIT-BIH: detección de picos R + features → clasificación de latidos con RandomForest vs LogReg.\nStack: scikit-learn, scipy, wfdb (lectura PhysioNet), matplotlib.\nValidación: subject-wise k-fold; métricas: F1 macro, sensibilidad por clase.\nEvaluación: Mini-lab 3 (10%).\nReferencias:\n\nGoldberger et al., PhysioNet (portal oficial).\n\nRiesgos: overfitting por feature selection en todo el set; filtrado que distorsiona morfología.\n\n\n\n\n\n\nResultados:\nRA1. Implementar una CNN 1D simple y compararla con ML clásico.\nRA2. Seleccionar métricas y early stopping.\nRA3. Analizar errores por sujeto.\nConceptos: convolución 1D, receptive field, padding/stride, learning rate.\nActividad (PhysioNet):\nECG PTB-XL (multi-derivación) o MIT-BIH re-muestreado: baseline SVM vs CNN1D en PyTorch.\nStack: PyTorch, scikit-learn.\nValidación: subject-wise k-fold; confusion matrix por sujeto.\nEvaluación: Mini-lab 4 (10%).\nReferencias:\n\nGoodfellow et al., Deep Learning, MIT Press, ISBN 978-0262035613.\n\nRiesgos: comparar modelos con splits distintos; no balancear clases.\n\n\n\n\n\n\nResultados:\nRA1. Implementar LSTM/GRU/Transformers 1D para detección de eventos.\nRA2. Aplicar explicabilidad 1D (saliency, Integrated Gradients).\nRA3. Reportar variabilidad entre folds.\nConceptos: dependencias temporales, enmascaramiento, longitudes variables, atención.\nActividad (PhysioNet):\nPTB-XL (o EEG PhysioNet para eventos): modelo secuencial + saliency/IG (Captum).\nStack: PyTorch, captum, mne (si EEG).\nValidación: subject-wise k-fold; métricas por evento.\nEvaluación: Mini-lab 5 (10%).\nReferencias:\n\nHochreiter & Schmidhuber, LSTM (1997).\nVaswani et al., Attention Is All You Need (2017).\n\nRiesgos: secuencias truncadas sesgando etiquetas; explicaciones no estables entre folds.\n\n\n\n\n\n\nResultados:\nRA1. Cargar DICOM/series y normalizar intensidades.\nRA2. Ejecutar transfer learning con MONAI.\nRA3. Documentar data transforms y augmentations.\nConceptos: spacing, windowing, normalización, recortes, augment.\nActividad (TCIA):\nLIDC-IDRI (TCIA): clasificación simple de nódulos (benigno/sospechoso como etiqueta didáctica) con fine-tuning de ResNet.\nStack: MONAI, PyTorch, pydicom.\nValidación: subject-wise k-fold por paciente.\nEvaluación: Mini-lab 6 (10%).\nReferencias:\n\nMONAI (docs oficiales).\nArmato et al., LIDC-IDRI (descripción del dataset).\n\nRiesgos: fuga por cortes múltiples del mismo paciente en train/test; augment que altera anatomía.\n\n\n\n\n\n\nResultados:\nRA1. Entrenar U-Net para segmentación 2D.\nRA2. Evaluar con Dice/IoU y curvas de volumen.\nRA3. Aplicar Grad-CAM para inspección de atención.\nConceptos: U-Net (encoder-decoder), pérdida (Dice/BCE), tiling, posprocesado.\nActividad (TCIA):\nLIDC-IDRI: segmentación de nódulos con U-Net (MONAI) + Grad-CAM sobre cortes con ResNet para inspección.\nStack: MONAI, PyTorch, captum.\nValidación: subject-wise k-fold; reporte Dice por paciente.\nEvaluación: Mini-lab 7 (10%).\nReferencias:\n\nRonneberger et al., U-Net, MICCAI 2015 (DOI disponible).\nHe et al., ResNet, CVPR 2016.\n\nRiesgos: entrenar/validar en cortes del mismo estudio; segmentación con máscaras ruidosas.\n\n\n\n\n\n\nResultados:\nRA1. Integrar pipeline completo (datos → modelo → validación → reporte).\nRA2. Elaborar model card y data card resumidas.\nRA3. Defender decisiones de diseño con evidencia.\nConceptos: estructura de repositorio, model/data cards, checklist de reproducibilidad, trazabilidad de experimentos.\nActividad:\nIntegrar un caso señal (ECG) o imagen (TCIA) a elección: notebook final con README y report de métricas.\nStack: PyTorch, MONAI, scikit-learn, matplotlib.\nValidación: subject-wise k-fold; reporte agregando media±DE.\nEvaluación: Quiz final (30%).\nReferencias:\n\nMitchell et al., Model Cards for Model Reporting (FAccT).\n\nRiesgos: falta de seeds, rutas relativas no reproducibles, dependencias sin fijar versión.\n\n\n\n\n\n\nPython==3.12.*, seed fija (e.g., 42), requirements.txt o environment.yml, carpetas data/, notebooks/, models/, reports/.\nSubject-wise k-fold obligatorio; no mezclar cortes/derivaciones del mismo paciente entre splits.\nReportar media±DE por fold y por paciente cuando aplique.\n\n\n\n\n\n\nTextos:\n\nBishop (2006), PRML, ISBN 978-0387310732.\nGoodfellow, Bengio, Courville (2016), Deep Learning, ISBN 978-0262035613.\n\nSoftware:\n\nPedregosa et al. (2011), Scikit-learn, JMLR 12.\nPaszke et al. (2019), PyTorch (NeurIPS).\nMONAI (documentación oficial).\n\nSeñales (PhysioNet): MIT-BIH, PTB-XL, EEG Motor/Imagery. (Usar portal oficial; añadir DOI/URL confirmados antes de publicar)\nImágenes (TCIA): LIDC-IDRI. (Añadir DOI/URL confirmados antes de publicar)"
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#tabla-de-sesiones-24-h-8-sesiones-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#tabla-de-sesiones-24-h-8-sesiones-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "#\nTítulo\nBloque\nHoras\nEntregable\n\n\n\n\n1\nFundamentos de AA en salud: tareas, métricas y pipeline\nFundamentos\n3\nMini-lab 1: pipeline clásico (sklearn)\n\n\n2\nValidación rigurosa y reproducibilidad (subject-wise)\nFundamentos\n3\nMini-lab 2: split subject-wise + baseline\n\n\n3\nSeñales biomédicas I: preprocesado y features (ECG/EMG)\nSeñales\n3\nMini-lab 3: filtro → features → clasificación\n\n\n4\nSeñales biomédicas II: ML clásico vs CNN 1D\nSeñales\n3\nMini-lab 4: baseline vs CNN1D (comparativa)\n\n\n5\nSeñales biomédicas III: LSTM/GRU/Transformers 1D + explicabilidad\nSeñales\n3\nMini-lab 5: secuenciales + saliency/IG\n\n\n6\nImágenes médicas I: DICOM, preprocesado y transfer learning\nImágenes\n3\nMini-lab 6: fine-tuning (MONAI)\n\n\n7\nImágenes médicas II: U-Net/ResNet, métricas y Grad-CAM\nImágenes\n3\nMini-lab 7: segmentación + Grad-CAM\n\n\n8\nIntegración, buenas prácticas y quiz final\nImágenes (cierre)\n3\nQuiz final + repositorio reproducible\n\n\n\nBalance de horas por bloque (aprox.): Fundamentos 6 h (≈30%), Señales 9 h (≈35%), Imágenes 9 h (≈35%).\nEvaluación (modelo 5B): 7 mini-labs × 10% c/u = 70%; Quiz final = 30%."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#fundamentos-de-aa-en-salud-tareas-métricas-y-pipeline-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#fundamentos-de-aa-en-salud-tareas-métricas-y-pipeline-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados de aprendizaje:\nRA1. Diferenciar tareas (clasificación, regresión, segmentación).\nRA2. Seleccionar métricas apropiadas por tarea (Acc, AUC, F1, MAE; Dice/IoU para segmentación).\nRA3. Describir un pipeline reproducible de AA en salud.\nConceptos clave: problema/tarea, train/val/test, baseline, feature engineering, normalización, data leakage.\nActividad práctica (PhysioNet, sklearn):\nClasificar latidos ECG (e.g., MIT-BIH o PTB-XL de PhysioNet). Preproceso básico, split estratificado por paciente (sin fuga), baseline con LogReg/SVM.\nStack: Python 3.12, scikit-learn, numpy, pandas, matplotlib.\nValidación: subject-wise k-fold (k=5).\nEvaluación: Mini-lab 1 (10%).\nReferencias sugeridas (verificar DOI/ISBN antes de publicar):\n\nBishop, Pattern Recognition and Machine Learning, 2006, ISBN 978-0387310732.\nPedregosa et al., Scikit-learn: Machine Learning in Python, JMLR 12:2825–2830, 2011.\n\nRiesgos comunes: fuga por segmentos del mismo paciente; métricas inadecuadas por clase desbalanceada."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#validación-rigurosa-y-reproducibilidad-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#validación-rigurosa-y-reproducibilidad-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Implementar subject-wise k-fold y reportes por clase.\nRA2. Configurar entorno reproducible y seeds.\nRA3. Documentar experimentos (versionado y data cards).\nConceptos: subject-wise vs aleatorio, nested CV, semillas, hojas de datos, readme de experimentos.\nActividad (PhysioNet, sklearn):\nRepetir baseline sesión 1 con particionamiento subject-wise k-fold y reporte de varianza entre folds.\nStack: scikit-learn, mlflow (opcional), pyproject.toml o conda env, control de versiones.\nValidación: subject-wise k-fold con estratificación si aplica.\nEvaluación: Mini-lab 2 (10%).\nReferencias:\n\nGéron, Hands-On Machine Learning, 2ª/3ª ed., O’Reilly, ISBN 978-1492032649.\n\nRiesgos: comparar métricas de folds no homólogos; no fijar semillas; no congelar versiones."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-i-preprocesado-y-features-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-i-preprocesado-y-features-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Aplicar filtrado, resampling y normalización en ECG/EMG.\nRA2. Extraer features en tiempo/frecuencia (RMS, picos R, bandas).\nRA3. Entrenar un clasificador clásico y evaluar robustez.\nConceptos: filtros pasa-banda, remoción de línea base, windowing, PSD, z-score.\nActividad (PhysioNet):\nECG MIT-BIH: detección de picos R + features → clasificación de latidos con RandomForest vs LogReg.\nStack: scikit-learn, scipy, wfdb (lectura PhysioNet), matplotlib.\nValidación: subject-wise k-fold; métricas: F1 macro, sensibilidad por clase.\nEvaluación: Mini-lab 3 (10%).\nReferencias:\n\nGoldberger et al., PhysioNet (portal oficial).\n\nRiesgos: overfitting por feature selection en todo el set; filtrado que distorsiona morfología."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-ii-ml-clásico-vs-cnn-1d-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-ii-ml-clásico-vs-cnn-1d-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Implementar una CNN 1D simple y compararla con ML clásico.\nRA2. Seleccionar métricas y early stopping.\nRA3. Analizar errores por sujeto.\nConceptos: convolución 1D, receptive field, padding/stride, learning rate.\nActividad (PhysioNet):\nECG PTB-XL (multi-derivación) o MIT-BIH re-muestreado: baseline SVM vs CNN1D en PyTorch.\nStack: PyTorch, scikit-learn.\nValidación: subject-wise k-fold; confusion matrix por sujeto.\nEvaluación: Mini-lab 4 (10%).\nReferencias:\n\nGoodfellow et al., Deep Learning, MIT Press, ISBN 978-0262035613.\n\nRiesgos: comparar modelos con splits distintos; no balancear clases."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-iii-lstmgrutransformers-1d-explicabilidad-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-iii-lstmgrutransformers-1d-explicabilidad-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Implementar LSTM/GRU/Transformers 1D para detección de eventos.\nRA2. Aplicar explicabilidad 1D (saliency, Integrated Gradients).\nRA3. Reportar variabilidad entre folds.\nConceptos: dependencias temporales, enmascaramiento, longitudes variables, atención.\nActividad (PhysioNet):\nPTB-XL (o EEG PhysioNet para eventos): modelo secuencial + saliency/IG (Captum).\nStack: PyTorch, captum, mne (si EEG).\nValidación: subject-wise k-fold; métricas por evento.\nEvaluación: Mini-lab 5 (10%).\nReferencias:\n\nHochreiter & Schmidhuber, LSTM (1997).\nVaswani et al., Attention Is All You Need (2017).\n\nRiesgos: secuencias truncadas sesgando etiquetas; explicaciones no estables entre folds."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#imágenes-médicas-i-dicom-preprocesado-y-transfer-learning-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#imágenes-médicas-i-dicom-preprocesado-y-transfer-learning-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Cargar DICOM/series y normalizar intensidades.\nRA2. Ejecutar transfer learning con MONAI.\nRA3. Documentar data transforms y augmentations.\nConceptos: spacing, windowing, normalización, recortes, augment.\nActividad (TCIA):\nLIDC-IDRI (TCIA): clasificación simple de nódulos (benigno/sospechoso como etiqueta didáctica) con fine-tuning de ResNet.\nStack: MONAI, PyTorch, pydicom.\nValidación: subject-wise k-fold por paciente.\nEvaluación: Mini-lab 6 (10%).\nReferencias:\n\nMONAI (docs oficiales).\nArmato et al., LIDC-IDRI (descripción del dataset).\n\nRiesgos: fuga por cortes múltiples del mismo paciente en train/test; augment que altera anatomía."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#imágenes-médicas-ii-u-netresnet-métricas-y-grad-cam-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#imágenes-médicas-ii-u-netresnet-métricas-y-grad-cam-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Entrenar U-Net para segmentación 2D.\nRA2. Evaluar con Dice/IoU y curvas de volumen.\nRA3. Aplicar Grad-CAM para inspección de atención.\nConceptos: U-Net (encoder-decoder), pérdida (Dice/BCE), tiling, posprocesado.\nActividad (TCIA):\nLIDC-IDRI: segmentación de nódulos con U-Net (MONAI) + Grad-CAM sobre cortes con ResNet para inspección.\nStack: MONAI, PyTorch, captum.\nValidación: subject-wise k-fold; reporte Dice por paciente.\nEvaluación: Mini-lab 7 (10%).\nReferencias:\n\nRonneberger et al., U-Net, MICCAI 2015 (DOI disponible).\nHe et al., ResNet, CVPR 2016.\n\nRiesgos: entrenar/validar en cortes del mismo estudio; segmentación con máscaras ruidosas."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#integración-buenas-prácticas-y-quiz-final-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#integración-buenas-prácticas-y-quiz-final-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Integrar pipeline completo (datos → modelo → validación → reporte).\nRA2. Elaborar model card y data card resumidas.\nRA3. Defender decisiones de diseño con evidencia.\nConceptos: estructura de repositorio, model/data cards, checklist de reproducibilidad, trazabilidad de experimentos.\nActividad:\nIntegrar un caso señal (ECG) o imagen (TCIA) a elección: notebook final con README y report de métricas.\nStack: PyTorch, MONAI, scikit-learn, matplotlib.\nValidación: subject-wise k-fold; reporte agregando media±DE.\nEvaluación: Quiz final (30%).\nReferencias:\n\nMitchell et al., Model Cards for Model Reporting (FAccT).\n\nRiesgos: falta de seeds, rutas relativas no reproducibles, dependencias sin fijar versión."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#requisitos-de-reproducibilidad",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#requisitos-de-reproducibilidad",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Python==3.12.*, seed fija (e.g., 42), requirements.txt o environment.yml, carpetas data/, notebooks/, models/, reports/.\nSubject-wise k-fold obligatorio; no mezclar cortes/derivaciones del mismo paciente entre splits.\nReportar media±DE por fold y por paciente cuando aplique."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#apéndice-referencias-globales-y-datasets-portal-oficial",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#apéndice-referencias-globales-y-datasets-portal-oficial",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Textos:\n\nBishop (2006), PRML, ISBN 978-0387310732.\nGoodfellow, Bengio, Courville (2016), Deep Learning, ISBN 978-0262035613.\n\nSoftware:\n\nPedregosa et al. (2011), Scikit-learn, JMLR 12.\nPaszke et al. (2019), PyTorch (NeurIPS).\nMONAI (documentación oficial).\n\nSeñales (PhysioNet): MIT-BIH, PTB-XL, EEG Motor/Imagery. (Usar portal oficial; añadir DOI/URL confirmados antes de publicar)\nImágenes (TCIA): LIDC-IDRI. (Añadir DOI/URL confirmados antes de publicar)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nSuposse…\n\n\nA dataset of M tuples \\((\\mathbf{x}_i, \\mathbf{y}_i)\\) with i = 1, …, M.\n\n\\(\\mathbf{x}_i\\): Inputs\n\\(\\mathbf{y}_i\\): Outputs\n\n\n\n\n\n\n\n\n\n\n\n\nWhat it is a neural network\n\n\nIs a mathematical function (sometimes called a network function) that takes some kind of input (typically multi-dimensional) called x iand generate some output."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nNetwork function\n\n\n\nThe output generated by the network function is called \\(\\hat{y}_i\\)\nThe network function normally depends on a certain number N of parameters, which we will indicate with \\(\\mathbf{\\theta}_k\\) \\[ \\mathbf{\\hat{y}}_i = f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), where, k=0,1,2,\\ldots,N \\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nImportante\n\n\nA neural network is nothing more than a mathematical function that depends on a set of parameters that are tuned, hopefully in some smart way, to make the network output as close as possible to some expected output.\n\n\n\n\n\n\n\n\\(\\mathbf{x}_i \\in \\mathbb{R}^n\\)\n\\(\\mathbf{y}_i \\in \\mathbb{R}^k\\)\n\\(i = 0,1,2,\\ldots,M\\)\n\\(\\mathbf{\\theta}_k \\in \\mathbb{R}^N\\)\n\\(k = 0,1,2,\\ldots,N\\)\n\n\n\nLoss function \\(L \\left( \\mathbf{\\hat{y}}_i, \\mathbf{y}_i \\right) = L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\)\nLoss function measures how close are \\(\\mathbf{\\hat{y}}_i\\) and \\(\\mathbf{y}_i\\)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nLearning\n\n\n\n$ _{_k ^N} L ( f ( _k, _i ), _i ) $\n\\(\\min_{\\mathbf{\\theta}_k \\in \\mathbb{R}^N} L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\) subject to \\(c_q, q=1,2,3,\\ldots,Q\\) with \\(Q \\in \\mathbb{N}\\)\nThe learning process is the search of a minima. However, most of the algorithms can search only a “local” minima.\nIn principle, we want to find the global minimum or, in other words, the point for which the function value is the smallest between all possible points.\n\n\n\n\n\n\nIdentifying if the minimum is a local or a global minimum is impossible, due to the network function complexity.\nThis is one (albeit not the only one) of the reasons that training large neural networks is such a challenging numerical problem."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "A single neuron",
    "text": "A single neuron"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Neural Network",
    "text": "Neural Network"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Neural Network",
    "text": "Neural Network\n\nTaken from GeeksforGeeks"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\nNeural Networks have a great number of internal parameters for learning; which varying in a vast range of values.\nThis number of parameters is fundamental for neural network knowledge representation\n\n\n\n\n\n\n\nProblem\n\n\nBut if this number increases too much the neural network is prone to overfitting"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\n\n\n\n\n\n\nDefinition\n\n\nRegularization techniques reduce the possibility of a neural network overfitting by constraining the range of values that the weight values within the network hold.\n\n\n\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\nRegularization works on assumption that smaller weights generate simpler model and thus helps avoid overfitting.\nThe simpler model is less prone to overfitting.\nAdding the regularization term to the sum of squared differences between the actual value and predicted value."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k\n\\end{eqnarray}\\]\n\n\n\n\n\n\n\nNota\n\n\n\\(\\lambda\\) is the penalty term or regularization parameter which determines how much to penalizes the weights."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Types of Regularization",
    "text": "Types of Regularization\n\n\nL1 Regularization or Lasso or L1 norm\n\nL1 penalizes sum of absolute value of weights.\nL1 has a sparse solution.\nL1 has multiple solutions.\nL1 has built in feature selection.\nL1 is robust to outliers.\nL1 generates model that are simple and interpretable but cannot learn complex patterns.\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\lvert \\theta_k \\rvert\n\\end{eqnarray}\\]\n\nL2 Regularization or Ridge Regularization\n\nL2 regularization penalizes sum of square weights.\nL2 has a non sparse solution\nL2 has one solution\nL2 has no feature selection\nL2 is not robust to outliers\nL2 gives better prediction when output variable is a function of all input features\nL2 regularization is able to learn complex data patterns\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation",
    "text": "Evaluation\n\n\n\n\n\n\n\nRegression\n\n\n\n\\(R^2\\)\nResidual graph\nAutocorrelation analysis\n\n\n\n\n\n\n\n\n\n\n\n\nClassification\n\n\n\nConfusion Matrix(Matriz de Confusión)\nPrecision(Precisión)\nRecall(Exhaustividad)\nF1-score(Valor-F)\nAccuracy(Exactitud)\nTrue Positive(Positivos Verdaderos)\nTrue Negative(Negativos Verdaderos)\nFalse Positive(Positivos Falsos)\nFalse Negative(Negativos Falsos)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nConfusion Matrix\n\n\n“Also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one.”"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nTrue Negative\n\n\nValues that being negative have been classified as negative\n\n\n\n\n\n\n\n\n\n\n\nTrue Positive\n\n\nValues that being positive have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Positive\n\n\nValues that being negative have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Negative\n\n\nValues that being negative have been classified as positive"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nSensitivity or Recall\n\n\nHow good is my classifier at detecting positive cases? \\[ \\frac{TP}{TP+FN} \\]\n\n\n\n\n\n\n\n\n\n\n\nSpecificity\n\n\nHow good is my classifier at avoiding negative cases? \\[ \\frac{TN}{TN+FP} \\]\n\n\n\n\n\n\n\n\n\n\n\n\nPrecision\n\n\nHow credible is my classifier when it detects a positive case? \\[\\frac{TP}{TP+FP}\\]\n\n\n\n\n\n\n\n\n\n\n\nAccuracy and Balance Accuracy\n\n\nHow many cases the classifier correctly identifies? \\[Accuracy = \\frac{TP+TN}{TP+FP+FN+TN}\\] \\[BalancedAccuracy = \\frac{Specificity+Sensitivity}{2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nPrevalence\n\n\nHow often does the positive condition actually occur in our sample? \\[\\frac{TP+FN}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nDetection Rate\n\n\nPercentage of true positives \\[\\frac{TP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nDetection Prevalence\n\n\nPercentage of positives \\[\\frac{TP+FP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nHarmonic mean of recall and precision.\n\n\n\\[2\\frac{\\left( Precision \\right) \\left( Sensitivity \\right)}{Precision+Sensitivity}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 1"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 2"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\n\n\nFor Class 3"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-gran-pregunta",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-gran-pregunta",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "La Gran Pregunta",
    "text": "La Gran Pregunta\n\n\n\n\n\n\nNota\n\n\n\n¿Y si tu celular pudiera detectar una enfermedad cardíaca con solo tocarlo?\n¿Y si una computadora pudiera ver un tumor que el ojo humano más experto aún no distingue?\n\n\n\n\n\nImaginen por un momento… ¿Y si su celular pudiera detectar una enfermedad cardíaca con solo tocarlo? ¿Y si una computadora pudiera ver un tumor en una radiografía, incluso antes de que el ojo humano más experto lo note? Esto no es ciencia ficción. Es lo que hacemos todos los días en este campo. La pregunta no es ‘si’ es posible, sino ‘cómo’ lo hacemos posible."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#bienvenida",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#bienvenida",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Bienvenida",
    "text": "Bienvenida\nProcesamiento de señales e imágenes\nDe los sonidos y las fotos a la salud y la tecnología.\n\nGuion: Preguntar a los estudiantes: ¿Qué señales usan sin darse cuenta? (Wi-Fi, música, ritmo del corazón). Explicar que hoy aprenderán a mirar cómo las computadoras entienden esas señales e imágenes."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestro-viaje-de-hoy",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestro-viaje-de-hoy",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Nuestro Viaje de Hoy",
    "text": "Nuestro Viaje de Hoy\n\nLos Lenguajes Secretos del Cuerpo: Descubriremos las señales eléctricas que nos mantienen vivos.\nUna Imagen Vale Más que Mil Pruebas: Veremos cómo convertimos el interior del cuerpo en imágenes.\nEl Truco de Magia: ‘Procesar’: Aprenderemos a limpiar y mejorar estos datos para encontrar pistas.\n¡Tu Turno! Conviértete en Ingeniero/a Biomédico/a: Realizarán análisis reales en nuestro laboratorio digital.\n\n\nPara entender cómo funciona esta ‘magia’, nuestro viaje de hoy tendrá cuatro paradas. Primero, descifraremos los lenguajes secretos del cuerpo, las señales eléctricas. Luego, veremos cómo creamos imágenes del interior de nuestro cuerpo. Después, revelaremos el truco de magia que llamamos ‘procesamiento’ para limpiar y mejorar estos datos. Y finalmente, la parte más emocionante: ustedes mismos se convertirán en ingenieros y realizarán análisis en nuestro laboratorio digital."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#qué-es-una-señal-información-en-movimiento",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#qué-es-una-señal-información-en-movimiento",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "¿Qué es una Señal? Información en Movimiento",
    "text": "¿Qué es una Señal? Información en Movimiento\n\nUna señal es simplemente información que cambia con el tiempo.\nEmpecemos por lo básico. ¿Qué es una señal? Es simplemente información que cambia con el tiempo. Piensen en la música: las notas suben y bajan, creando una melodía. Eso es una señal. O la temperatura a lo largo de un día: sube al mediodía y baja por la noche. En el cuerpo, en lugar de notas o grados, medimos cosas como la actividad eléctrica, que sube y baja de formas muy específicas."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-sinfonía-eléctrica-del-cuerpo",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-sinfonía-eléctrica-del-cuerpo",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "La Sinfonía Eléctrica del Cuerpo",
    "text": "La Sinfonía Eléctrica del Cuerpo\n\n\nEl Electrocardiograma (ECG) es el ritmo del corazón, nuestro tambor principal.\n\n\n\n\n\nSeñal de ECG ideal, mostrando el patrón rítmico del corazón.\n\n\n\n\n\n¿Qué nos dice el ECG?\n\n¿Cuál es el ritmo cardíaco?\n¿El corazón late muy rápido o muy lento?\n¿Hay alguna parte que no funciona en armonía?\nPermite diagnosticar problemas y salvar vidas.\n\n\n\nNuestro cuerpo es como una orquesta eléctrica. El corazón es el tambor, marcando un ritmo constante y poderoso. La señal que produce se llama Electrocardiograma o ECG. El cerebro es como la sección de cuerdas, con miles de neuronas ‘hablando’ a la vez en una conversación compleja. Esa señal es el Electroencefalograma o EEG. Escuchando estas ‘melodías’, los médicos pueden saber si todo funciona en armonía."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desafío-encontrar-la-señal-en-el-ruido",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desafío-encontrar-la-señal-en-el-ruido",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "El Desafío: Encontrar la Señal en el Ruido",
    "text": "El Desafío: Encontrar la Señal en el Ruido\n\nUna señal de ECG real a menudo está contaminada con ruido.\nPero en el mundo real, estas señales no son tan claras. Imaginen tratar de escuchar a un amigo en una fiesta muy ruidosa. El ‘ruido’ es todo lo que interfiere: otros aparatos eléctricos, el movimiento del paciente, etc. Este ruido puede ocultar información vital que el médico necesita ver. Como ven aquí, el patrón claro del latido casi ha desaparecido."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-solución-cancelación-de-ruido-digital",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-solución-cancelación-de-ruido-digital",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "La Solución: Cancelación de Ruido Digital",
    "text": "La Solución: Cancelación de Ruido Digital\n\n\nSeñal Ruidosa (Original)\n\n\n\n\n\n\n\n\n\n\nSeñal Filtrada (Limpia)\n\n\n\n\n\n\n\n\n\n\n\nAquí es donde entra nuestra ‘magia’. Usamos algoritmos de ‘filtrado’. Es como ponerse unos audífonos con cancelación de ruido. La computadora mira cada punto de la señal y lo promedia con sus vecinos de una manera inteligente. El ruido, al ser aleatorio y rápido, se cancela, ¡pero el patrón real del latido, que es más lento y repetitivo, se mantiene! Así ‘rescatamos’ la información importante, como pueden ver en la gráfica de la derecha. Pasamos de algo ilegible a una señal clara y diagnóstica."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#qué-es-una-imagen-una-pintura-por-números",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#qué-es-una-imagen-una-pintura-por-números",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "¿Qué es una Imagen? Una Pintura por Números",
    "text": "¿Qué es una Imagen? Una Pintura por Números\n\n\nLos Números (Píxeles)\n\n\n\n\n\nMatriz de números que representa una imagen simple.\n\n\n\n\n\nLa Imagen Resultante\n\n\n\n\n\nLa imagen en escala de grises generada por la matriz de números.\n\n\n\n\n\n\nAhora hablemos de imágenes. Para una computadora, una imagen no es una foto, es una cuadrícula gigante de números. ¡Como un lienzo para pintar por números! Cada número representa el brillo de un puntito llamado ‘píxel’. Un número bajo como 0 puede ser negro, un número alto como 255 puede ser blanco, y los números intermedios son todos los tonos de gris. A la izquierda ven los números, y a la derecha, la imagen que la computadora crea a partir de ellos."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#una-ventana-hacia-el-cuerpo",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#una-ventana-hacia-el-cuerpo",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Una Ventana Hacia el Cuerpo",
    "text": "Una Ventana Hacia el Cuerpo\n\n\nRadiografía (Rayos X) Ideal para ver estructuras densas como los huesos.\n\n\n\n\n\nEjemplo de una radiografía de tórax.\n\n\n\n\n\nResonancia Magnética (MRI) Perfecta para ver tejidos blandos como el cerebro.\n\n\n\n\n\nEjemplo de una resonancia magnética cerebral.\n\n\n\n\n\n\nCon esta idea, podemos crear ventanas increíbles hacia el interior del cuerpo. Las Radiografías (Rayos X) son como la sombra del cuerpo; son excelentes para ver cosas densas como los huesos. Las Resonancias Magnéticas (MRI) son diferentes; crean un mapa detallado del agua en nuestro cuerpo, lo que las hace perfectas para ver tejidos blandos como el cerebro, los músculos o los órganos."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desafío-hacer-visible-lo-invisible",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desafío-hacer-visible-lo-invisible",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "El Desafío: Hacer Visible lo Invisible",
    "text": "El Desafío: Hacer Visible lo Invisible\n\nUna imagen médica con bajo contraste donde los detalles son difíciles de ver.\nA veces, la información que buscamos en una imagen médica es muy sutil. Puede ser como tratar de encontrar a un amigo en una foto muy oscura o con mucha niebla. El contraste puede ser bajo, o los bordes entre un tejido sano y uno enfermo pueden ser borrosos. El ojo humano puede pasar por alto estos detalles cruciales."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-solución-resaltadores-digitales",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-solución-resaltadores-digitales",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "La Solución: Resaltadores Digitales",
    "text": "La Solución: Resaltadores Digitales\n\n\nImagen Original\n\n\n\n\n\n\n\n\n\n\nImagen Mejorada\n\n\n\n\n\n\n\n\n\n\n\n¡De nuevo, el procesamiento viene al rescate! Podemos darle ‘superpoderes’ a la imagen. Con el ajuste de contraste, le decimos a la computadora: ‘haz que las partes oscuras sean más oscuras y las claras más claras’, ¡como ajustar el brillo en Instagram! Fíjense cómo en la imagen de la derecha, los detalles que antes estaban ocultos ahora son perfectamente visibles. Otra técnica es la detección de bordes, que dibuja una línea donde hay un cambio brusco de brillo, ayudando a los médicos a ver la forma exacta de los órganos o tumores."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#áreas-de-aplicación-del-procesamiento-de-señales-e-imágenes",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#áreas-de-aplicación-del-procesamiento-de-señales-e-imágenes",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Áreas de aplicación del procesamiento de señales e imágenes",
    "text": "Áreas de aplicación del procesamiento de señales e imágenes\n\n\n\nDiagnóstico automatizado\nIdentificación de enfermedades en ECG, EEG o imágenes médicas.\nMonitoreo en tiempo real\nVigilancia en UCI con señales continuas de corazón, respiración y cerebro.\nTelemedicina\nTransmisión y compresión de señales para consultas a distancia.\nRehabilitación y prótesis inteligentes\nUso de señales EMG para controlar prótesis y exoesqueletos.\n\n\n\nDetección temprana de eventos críticos\nAnticipación de arritmias, crisis epilépticas o caídas.\nBiometría y seguridad\nReconocimiento de voz, rostro o iris.\nImagenología avanzada\nSegmentación de órganos o tumores en 3D para cirugía o radioterapia.\nEntretenimiento y multimedia\nFiltros en fotos y videos, mejora de audio y realidad aumentada.\n\n\n\nGuion: resaltar que la mitad de las aplicaciones impacta directamente en salud y la otra mitad en la vida cotidiana. Pedir a los estudiantes que piensen en qué columna usan más sin darse cuenta."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Plataforma para el monitoreo de salud de adultos mayores",
    "text": "Plataforma para el monitoreo de salud de adultos mayores\n\nDetección ambulatoria de actividades diarias.\nDetección ambulatoria de riesgo de caída.\nDetección ambulatoria de riesgo neuronal.\nDetección ambulatoria de riesgo psico-social.\nDetección ambulatoria de riesgo cardíaco\nMonitorización de terapias ambulatorias para la rehabilitación de adultos mayores"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#creación-de-ambientes-de-habitación-saludables-usando-realimentación-sensorial",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#creación-de-ambientes-de-habitación-saludables-usando-realimentación-sensorial",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Creación de ambientes de habitación saludables usando realimentación sensorial",
    "text": "Creación de ambientes de habitación saludables usando realimentación sensorial\n\nNeurofeedback emocional usando música.\nNeurofeedback de memoria procedimental.\nNeurofeedback en automotores.\nMonitorización ambulatoria de estado emocional.\nMonitorización ambulatoria de terapias emocionales"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#apoyo-tecnológico-mediante-ia-a-intervenciones-clínicas",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#apoyo-tecnológico-mediante-ia-a-intervenciones-clínicas",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Apoyo tecnológico mediante IA a intervenciones clínicas",
    "text": "Apoyo tecnológico mediante IA a intervenciones clínicas\n\nDetección de anomalías en imágenes mediante segmentación heurística.\nPlaneación pre-operatoria mediante el uso de inteligencia artificial.\nEvaluación de espasticidad mediante el uso tecnología."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#detección-de-información-en-terapias-y-proyectos-de-rehabilitación",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#detección-de-información-en-terapias-y-proyectos-de-rehabilitación",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Detección de información en terapias y proyectos de rehabilitación",
    "text": "Detección de información en terapias y proyectos de rehabilitación\n\nGeneración de interfaces cerebro-computador\nGeneración de algoritmos de clasificación de intención de movimiento\nMonitorización de terapias de rehabilitación."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#invitación",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#invitación",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Invitación",
    "text": "Invitación\n\nInvitación"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestras-herramientas",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestras-herramientas",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Nuestras Herramientas",
    "text": "Nuestras Herramientas\nVamos a usar este mismo documento como nuestro cuaderno de laboratorio digital.\n\nVerán bloques de código en Python.\nNo necesitan ser expertos. El código ya está escrito.\nSu misión: ejecutarlo (con el botón de play ►), observar los resultados e incluso experimentar cambiando algunos valores.\n\n¡Vamos a hacer ciencia de verdad!\n\n¡Suficiente teoría! Es hora de que se pongan la bata de laboratorio. Vamos a usar este mismo documento como nuestro ‘cuaderno de laboratorio digital’. Verán bloques de código en Python. No se asusten, no necesitan ser expertos. El código ya está escrito. Su misión es ejecutarlo, observar los resultados e incluso experimentar cambiando algunas cosas. ¡Vamos a hacer ciencia de verdad!"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-1-de-números-a-dibujos",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-1-de-números-a-dibujos",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Misión 1: ¡De Números a Dibujos! 📝",
    "text": "Misión 1: ¡De Números a Dibujos! 📝\nObjetivo: Comprender que las imágenes son, en el fondo, solo listas de números e instrucciones.\nMateriales: Una hoja de papel cuadriculado y un lápiz.\nInstrucciones (Parte A - La Imagen Misteriosa):\nEn una hoja resalta los números pares y los primos permitiendo ver el mensaje secreto."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-2-de-números-a-dibujos",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-2-de-números-a-dibujos",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Misión 2: ¡De Números a Dibujos! 📝",
    "text": "Misión 2: ¡De Números a Dibujos! 📝\nObjetivo: Comprender que las señales e imágenes son, en el fondo, solo listas de números e instrucciones.\nMateriales: Una hoja de papel cuadriculado y un lápiz.\nInstrucciones (Parte A - La Señal Misteriosa):\n\nEn tu hoja, dibuja un eje: el horizontal se llama “Tiempo” (de 1 a 10) y el vertical “Valor” (de 1 a 10).\nTe daré pares de números (Tiempo, Valor). Dibuja un punto en cada coordenada.\nCoordenadas: (1, 2), (2, 4), (3, 6), (4, 8), (5, 6), (6, 4), (7, 2), (8, 4), (9, 6), (10, 8).\nUne los puntos en orden. ¿Qué letra o forma simple has dibujado?\n\nInstrucciones (Parte B - La Imagen Secreta):\n\nEn otra parte de tu hoja, dibuja una cuadrícula de 8x8.\nTe daré coordenadas (fila, columna) que debes rellenar o colorear. La fila 1 es la de arriba, la columna 1 es la de la izquierda.\nPíxeles a colorear:\n\nFila 2: Columnas 3, 4, 5, 6\nFila 3: Columnas 2, 7\nFila 4: Columnas 2, 4, 5, 7\nFila 5: Columnas 2, 7\nFila 6: Columnas 3, 6\nFila 7: Columnas 4, 5\n\nAléjate un poco… ¿Qué imagen has creado?"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-3-rescatar-un-latido",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-3-rescatar-un-latido",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Misión 3: Rescatar un Latido",
    "text": "Misión 3: Rescatar un Latido\nEl Reto: Hemos recibido la señal de ECG de un paciente, pero está llena de ruido. Es imposible para un médico leerla así.\nTu Tarea: Ejecuta el código de abajo para aplicar un filtro digital y limpiar la señal. ¡El diagnóstico del paciente depende de ti!\n\n\nMostrando la señal original recibida del paciente...\n\n\n\n\n\n\n\n\n\n\n¡Filtro aplicado! Mostrando la señal recuperada..."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-4-mapear-el-cerebro",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-4-mapear-el-cerebro",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Misión 4: Mapear el Cerebro",
    "text": "Misión 4: Mapear el Cerebro\nEl Reto: Tenemos una imagen de resonancia magnética. Para estudiarla, un neurólogo necesita ver claramente los contornos de las diferentes estructuras.\nTu Tarea: Ejecuta el código para aplicar un filtro de ‘detección de bordes’ y crear un mapa de los contornos del cerebro.\n\n\nCargando imagen de resonancia magnética...\n¡Filtro de bordes aplicado! Mostrando comparación..."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#preguntas",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#preguntas",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "¿Preguntas?",
    "text": "¿Preguntas?\n¡Gracias!\n\nGracias por su atención y su excelente trabajo como ingenieros. Ahora, me encantaría responder a cualquier pregunta que tengan."
  },
  {
    "objectID": "codigo/preparing_slides.html",
    "href": "codigo/preparing_slides.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport pywt\nimport matplotlib.pyplot as plt\nimport imageio\nfrom scipy import signal\n\nplt.rcParams.update(\n    {\n        \"text.usetex\": True,  # usar LaTeX real\n        \"font.family\": \"Fira Code\",       # familia general\n        \"mathtext.fontset\": \"custom\",     # fuente personalizada para fórmulas\n        \"mathtext.rm\": \"Fira Code\",       # texto “roman”\n        \"mathtext.it\": \"Fira Code:italic\",# texto itálico\n        \"mathtext.bf\": \"Fira Code:bold\",   # texto en negrita\n        \"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n    }\n)\n\n# Time vector\nt = np.linspace(-3, 3, 500)\n\n# Define the original function and its components\nf_t = np.exp(t)  # Original function: e^t\nf_even = (np.exp(t) + np.exp(-t)) / 2  # Even part: cosh(t)\nf_odd = (np.exp(t) - np.exp(-t)) / 2  # Odd part: sinh(t)\n\n# Create the subplots\nfig, axs = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n\n# Plot the original function\naxs[0].plot(t, f_t, label=r\"$f(t) = e^t$\", color=\"blue\", linewidth=2)\naxs[0].set_title(\"Original Function\", fontsize=14)\naxs[0].set_ylabel(\"Amplitude\", fontsize=12)\naxs[0].legend(fontsize=12)\naxs[0].grid(True)\n\n# Plot the even part\naxs[1].plot(\n    t, f_even, label=r\"$f_{\\text{even}}(t) = \\cosh(t)$\", color=\"green\", linewidth=2\n)\naxs[1].set_title(\"Even Part of the Function\", fontsize=14)\naxs[1].set_ylabel(\"Amplitude\", fontsize=12)\naxs[1].legend(fontsize=12)\naxs[1].grid(True)\n\n# Plot the odd part\naxs[2].plot(t, f_odd, label=r\"$f_{\\text{odd}}(t) = \\sinh(t)$\", color=\"red\", linewidth=2)\naxs[2].set_title(\"Odd Part of the Function\", fontsize=14)\naxs[2].set_xlabel(\"Time (s)\", fontsize=12)\naxs[2].set_ylabel(\"Amplitude\", fontsize=12)\naxs[2].legend(fontsize=12)\naxs[2].grid(True)\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time base\nnp.random.seed(7)\nfs = 500  # Hz\nT = 2.0  # s\nt = np.linspace(0, T, int(fs * T), endpoint=False)\n\n# Deterministic signal: sinusoid\nA, f0, phi = 1.0, 5.0, np.pi / 6\nx_det = A * np.cos(2 * np.pi * f0 * t + phi)\n\n# Random signal: zero-mean Gaussian sequence, smoothed to be signal-like\nnoise = np.random.randn(t.size)\nM = 25  # moving-average window length (odd)\nkernel = np.ones(M) / M\nx_rand = np.convolve(noise, kernel, mode=\"same\") * 0.8  # scaled for visibility\n\n# Plot (two panels on a single slide)\nfig, axes = plt.subplots(2, 1, figsize=(9, 5), sharex=True)\n\naxes[0].plot(t, x_det, lw=1.4)\naxes[0].set_title(r\"Deterministic signal: $x_d(t)=A\\cos(2\\pi f_0 t+\\phi)$\")\naxes[0].set_ylabel(\"Amplitude\")\naxes[0].grid(alpha=0.3)\n\naxes[1].plot(t, x_rand, lw=1.2)\naxes[1].set_title(r\"Random signal (one realization): $X(t)$ with $\\mathbb{E}[X(t)]=0$\")\naxes[1].set_xlabel(r\"Time $t$ [s]\")\naxes[1].set_ylabel(\"Amplitude\")\naxes[1].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/PSIM/cod003_FourierImage.html",
    "href": "codigo/PSIM/cod003_FourierImage.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Step 1: Load the Ultrasound Image\nimage = cv2.imread(\n    \"../../data/malignant_breast_cancer.png\", \n    cv2.IMREAD_GRAYSCALE\n)\n\n\nsharpening_kernel1 = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\nsharpening_kernel2 = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n\nsharpened_image1 = cv2.filter2D(image, -1, sharpening_kernel1)\nsharpened_image2 = cv2.filter2D(image, -1, sharpening_kernel2)\n\n\n# Step 4: Display the Original and Sharpened Images Side-by-Side\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 3, 1)\nplt.title(\"Original Ultrasound Image\")\nplt.imshow(image, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 2)\nplt.title(\"Sharpened Ultrasound Image Kernel1\")\nplt.imshow(sharpened_image1, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 3)\nplt.title(\"Sharpened Ultrasound Image Kernel2\")\nplt.imshow(sharpened_image2, cmap=\"gray\")\nplt.axis(\"off\")\n\n\n\n\n\n\n\n\n\ndft1 = cv2.dft(np.float32(image), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift1 = np.fft.fftshift(dft1)\nmagnitude_spectrum1 = 20 * np.log(cv2.magnitude(dft_shift1[:, :, 0], dft_shift1[:, :, 1]))\n\ndft2 = cv2.dft(np.float32(sharpened_image1), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift2 = np.fft.fftshift(dft2)\nmagnitude_spectrum2 = 20 * np.log(\n    cv2.magnitude(dft_shift2[:, :, 0], dft_shift2[:, :, 1])\n)\n\ndft3 = cv2.dft(np.float32(sharpened_image2), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift3 = np.fft.fftshift(dft3)\nmagnitude_spectrum3 = 20 * np.log(\n    cv2.magnitude(dft_shift3[:, :, 0], dft_shift3[:, :, 1])\n)\n\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(3, 1, 1)\nplt.title(\"Magnitude Spectrum of initial image in log scale\")\nplt.imshow(magnitude_spectrum1, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(3, 1, 2)\nplt.title(\"Magnitude Spectrum of the first sharpended image in log scale\")\nplt.imshow(magnitude_spectrum2, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(3, 1, 3)\nplt.title(\"Magnitude Spectrum of the second sharpended image in log scale\")\nplt.imshow(magnitude_spectrum3, cmap=\"gray\")\nplt.axis(\"off\")\n\n\n\n\n\n\n\n\n\nrows, cols = image.shape\ncrow, ccol = rows // 2, cols // 2  # Coordenadas del centro\n\n# Crear una máscara pasa-altas\n# Empezamos con una matriz de unos\nmask = np.ones((rows, cols, 2), np.uint8)\n\n# Crear una región cuadrada en el centro de la máscara que representa las bajas frecuencias\nr = 10  # Radio de la región de bajas frecuencias que queremos eliminar\nmask[crow - r : crow + r, ccol - r : ccol + r] = (\n    0  # Zona central donde eliminamos las bajas frecuencias\n)\n\nplt.imshow(mask[:,:,1])\n\n\n\n\n\n\n\n\n\n# Aplicar la máscara pasa-altas al espectro DFT\nfshift = dft_shift1 * mask\n\n# Desplazar de vuelta las frecuencias (inverso de fftshift)\nf_ishift = np.fft.ifftshift(fshift)\n\n# Aplicar la transformada inversa de Fourier (IDFT)\nimg_back = cv2.idft(f_ishift)\n\n# Calcular la magnitud para obtener la imagen final filtrada\nimg_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n\n# Mostrar las imágenes original y filtrada\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.imshow(image, cmap=\"gray\")\nplt.title(\"Imagen Original\")\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(img_back, cmap=\"gray\")\nplt.title(\"Imagen Filtrada (Pasa-Altas)\")\nplt.axis(\"off\")\n\nplt.show()"
  },
  {
    "objectID": "codigo/PSIM/cod004_wavelet_explain.html",
    "href": "codigo/PSIM/cod004_wavelet_explain.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nFs = 100\nt = np.arange(0,8, 1/Fs)\nx1 = np.exp(-t)\nx1[np.uint(2/0.01)]=0.8\nplt.plot(t,x1)\nplt.show()\n\n\n\n\n\n\n\n\n\ndef EspectroMagnitudFourier(t, x):\n    N = len(t)\n    Fs = 1/np.mean(np.diff(t))\n    x_fft = np.fft.fftshift(np.fft.fft(x))\n    f = np.fft.fftshift(np.fft.fftfreq(N, 1/Fs))\n    plt.plot(f, np.abs(x_fft))\n\n\nEspectroMagnitudFourier(t,x1)\n\n\n\n\n\n\n\n\n\nfrom scipy.signal import chirp\n\n\nx2 = np.sin(2*np.pi*2*t)+np.sin(2*np.pi*5*t)+np.sin(2*np.pi*10*t)\nEspectroMagnitudFourier(t,x2)\n\n\n\n\n\n\n\n\n\nx3 = np.zeros(t.shape)\nt1 = np.uint(3/0.01)\nt2 = np.uint(5/0.01)\nx3[0:t1] = np.sin(2*np.pi*2*t[0:t1])\n\nx3[t1:t2] = np.sin(2*np.pi*5*t[t1:t2])\nx3[t2:] = np.sin(2*np.pi*10*t[t2:])\nplt.plot(t,x3)\nplt.show()\n\n\n\nEspectroMagnitudFourier(t,x3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport scaleogram as scg  # Assuming you have `scaleogram` installed.\nimport pywt\n\n\n# Define the scales (`scales`)\nnum_points = x3.shape[0]\nmax_scale2 = 50  # You can adjust this based on your requirements\nscales = np.arange(1, max_scale2 + 1)  # Proper definition of scales\n\n# Define the wavelet to be used for the CWT\nwavelet_name = \"cmor0.5-1.0\"  \n\n# Compute the Continuous Wavelet Transform (CWT)\ncoef, freqs = pywt.cwt(x3, scales, wavelet=wavelet_name)\n\n# Plot the scalogram\nplt.figure(figsize=(10, 6))\nplt.imshow(\n    np.abs(coef),\n    aspect=\"auto\",\n    extent=[0, num_points, scales[-1], scales[0]],\n    cmap=\"viridis\",\n)\nplt.colorbar(label=\"Magnitude\")\nplt.ylabel(\"Scales\")\nplt.xlabel(\"Time\")\nplt.title(f\"Continuous Wavelet Transform (Scalogram) using {wavelet_name} wavelet\")\nplt.gca().invert_yaxis()  # Invert y-axis to have larger scales at the bottom\nplt.show()\n\n# Plot the mother wavelet function\nwavelet = pywt.ContinuousWavelet(wavelet_name)\n\n# Get the wavelet function (psi) and time points (x)\npsi, x = wavelet.wavefun(level=10)  # Level determines the resolution\n\n# Plotting the wavelet function (psi)\nplt.figure(figsize=(10, 6))\nplt.plot(x, psi, label=f\"{wavelet_name} wavelet\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.title(f\"Wavelet Function: {wavelet_name}\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport pywt\nimport scaleogram as scg\nimport scipy.io as sio\n\nanchos = np.uint(np.arange(1,np.log2(x3.shape[0])))\n\ncoef, freqs = pywt.cwt(x3,anchos,\"gaus1\") \nplt.matshow(coef)\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\ndata = sio.loadmat(\"../../data/JS00001.mat\")\necg001 = data[\"val\"][9, :]\nt = np.linspace(0,10, 5000)\nplt.plot(t,ecg001)\n\n\n\n\n\n\n\n\n\nimport scipy.signal as sig\nt_decimate=sig.decimate(t, 2)\n\n\ncoef_lvl1 = pywt.dwt(ecg001, wavelet=\"db1\")\nplt.plot(t_decimate, coef_lvl1[0]/np.max(coef_lvl1[0]))\nplt.plot(t_decimate, coef_lvl1[1]/np.max(coef_lvl1[1]))\nplt.show()\n\nplt.plot(t_decimate, coef_lvl1[0])\nplt.plot(t, ecg001)\nplt.show()\n\nplt.plot(t_decimate, coef_lvl1[1]/np.max(coef_lvl1[1]))\nplt.plot(t,ecg001/np.max(ecg001))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Descomposición con la Transformada Wavelet Discreta\nwavelet = \"db4\"  # Elegimos la wavelet Daubechies de nivel 4\nmax_level = pywt.dwt_max_level(len(ecg001), wavelet)\ncoeffs = pywt.wavedec(ecg001, wavelet, level=max_level)\n\n\n# Apply soft thresholding to detail coefficients\ncoeffs_thresh = [coeffs[0]]  # Keep approximation coefficients unchanged\ncoeffs_thresh.extend(\n    pywt.threshold(detail, 2000, mode=\"soft\") for detail in coeffs[1:]\n)\n\n\n# Reconstrucción de la señal desde los coeficientes\nreconstructed_signal = pywt.waverec(coeffs_thresh, wavelet)\n\n# Visualización de la señal original, ruidosa y reconstruida\nplt.figure(figsize=(12, 8))\n\n# Señal image\nplt.plot(t, ecg001, label=\"Señal Ruidosa\", color=\"orange\")\nplt.plot(t, reconstructed_signal, label=\"Señal Reconstruida\", color=\"green\")\n\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport cv2\nfrom scipy.signal import convolve2d\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pywt\nimport pywt.data\n\noriginal = cv2.imread(\"../../data/female-chest-x-ray.jpg\", cv2.IMREAD_GRAYSCALE)\n\n\nfrom scipy.signal import convolve2d\n\n# Filtros de paso bajo y paso alto para la wavelet Haar\nlow_pass = np.array([1, 1]) / np.sqrt(2)\nhigh_pass = np.array([1, -1]) / np.sqrt(2)\n\nprint(low_pass[:, None])\n\n# Convolución en las filas\nLL_rows = convolve2d(original, low_pass[:, None], mode=\"same\")  # Paso bajo en filas\nHL_rows = convolve2d(original, high_pass[:, None], mode=\"same\")  # Paso alto en filas\n\n# Convolución en las columnas\nLL_scratch = convolve2d(LL_rows, low_pass[None, :], mode=\"same\")  # Paso bajo en columnas\nLH_scratch = convolve2d(LL_rows, high_pass[None, :], mode=\"same\")  # Paso alto en columnas\nHL_scratch = convolve2d(\n    HL_rows, low_pass[None, :], mode=\"same\"\n)  # Paso bajo en columnas\nHH_scratch = convolve2d(\n    HL_rows, high_pass[None, :], mode=\"same\"\n)  # Paso alto en columnas\n\n# Visualización de las subbandas\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 3, 1)\nplt.title(\"Imagen Original\")\nplt.imshow(original, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 2)\nplt.title(\"Subbanda LL (Low-Low)\")\nplt.imshow(LL_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 3)\nplt.title(\"Subbanda LH (Low-High)\")\nplt.imshow(LH_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 5)\nplt.title(\"Subbanda HL (High-Low)\")\nplt.imshow(HL_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 6)\nplt.title(\"Subbanda HH (High-High)\")\nplt.imshow(HH_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\n[[0.70710678]\n [0.70710678]]\nfloat32\n\n\n\n\n\n\n\n\n\n\nimagen_oscura = np.uint8(cv2.normalize(LL_scratch, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX))\nhistograma = cv2.calcHist([imagen_oscura], [0], None, [256], [0, 256])\nplt.plot(histograma)\n\n\n\n\n\n\n\n\n\n\n# Load image\n#original = pywt.data.camera()\n\n# Wavelet transform of image, and plot approximation and details\ntitles = ['Approximation', ' Horizontal detail',\n          'Vertical detail', 'Diagonal detail']\ncoeffs2 = pywt.dwt2(original, 'haar')\nLL, (LH, HL, HH) = coeffs2\nfig = plt.figure(figsize=(12, 3))\nfor i, a in enumerate([LL, LH, HL, HH]):\n    ax = fig.add_subplot(1, 4, i + 1)\n    ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n    ax.set_title(titles[i], fontsize=10)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfig.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nth1 = 0.7*np.max([LL,HL,LH,HH])\nLL[LL&lt;th1]=0\nHL[HL&lt;th1]=0\nLH[LH&lt;th1]=0\nHH[HH&lt;th1]=0\ncoeffs2_denoise = (LL, (LH, HL, HH))\nimagen_recons=pywt.idwt2(coeffs2_denoise, wavelet=\"haar\")\nplt.imshow(np.hstack((original, imagen_recons)), cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(original-imagen_recons, cmap=\"gray\")"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html",
    "href": "codigo/PSIM/cod001_signal_conditioning.html",
    "title": "Paginas importantes",
    "section": "",
    "text": "https://www.nature.com/articles/s41597-020-0386-x\nhttps://physionet.org/content/ecg-arrhythmia/1.0.0/"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librerías",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librerías",
    "title": "Paginas importantes",
    "section": "Carga de librerías",
    "text": "Carga de librerías\n\nnumpy: Para manipulación numérica y funciones estadísticas básicas\nmatplotlib.pyplot: Para generación de gráficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\nscipy.signal: Para análisis de señales de la librería SCIPY\nscipy.optimize: Para realizar el ajuste de curva\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.signal as signal\nfrom scipy.signal import freqz, butter, cheby1, firwin\nfrom scipy.optimize import curve_fit"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#configuración-de-carpetas",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#configuración-de-carpetas",
    "title": "Paginas importantes",
    "section": "Configuración de carpetas",
    "text": "Configuración de carpetas\n\ndata_path = \"/content/drive/MyDrive/ECG_Dataset/\""
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "title": "Paginas importantes",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\nplt.plot(f_vect1, mag_ecg_fft1**2)\nplt.grid()\n\n\n\n\n\n\n\n\n\nfs = 500\nfcut = 50\norder = 4\n\nf_corte = fcut/(fs/2)\n\nb, a = signal.butter(order, f_corte, \"lowpass\")\n\n\ndef plot_filter_response(b, a=1, fs=1.0):\n    \"\"\"Grafica la respuesta en frecuencia de un filtro dado.\"\"\"\n    w, h = freqz(b, a, worN=2048, fs=fs)  # Calcula la respuesta en frecuencia\n\n    # Magnitud de la respuesta en frecuencia\n    plt.figure(figsize=(10, 6))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(w, 20 * np.log10(abs(h)), \"b\")\n    plt.title(\"Respuesta en Frecuencia del Filtro\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Magnitud [dB]\")\n    plt.grid()\n\n    # Fase de la respuesta en frecuencia\n    plt.subplot(2, 1, 2)\n    plt.plot(w, np.angle(h), \"g\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Fase [radianes]\")\n    plt.grid()\n\n    plt.tight_layout()\n    plt.show()\n\n\n# Parámetros del filtro\nfs = 1000  # Frecuencia de muestreo en Hz\ncutoff = 200  # Frecuencia de corte en Hz\norder = 4  # Orden del filtro\n\n# Filtro IIR Butterworth\nb_iir, a_iir = butter(order, cutoff, fs=fs, btype=\"low\", analog=False)\nprint(\"Filtro IIR Butterworth\")\nplot_filter_response(b_iir, a_iir, fs=fs)\n\n# Filtro FIR (ventana de Hamming)\nnumtaps = 50  # Número de coeficientes del FIR\nb_fir = firwin(numtaps, cutoff, fs=fs, window=\"hamming\")\nprint(\"Filtro FIR (Ventana de Hamming)\")\nplot_filter_response(b_fir, fs=fs)\n\n\necg_filt_1 = signal.lfilter(b, a, lead_10)\necg_filt_2 = signal.filtfilt(b, a, lead_10) # No causal.\n\n\nplt.plot(t, ecg_filt_1)\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nmag_ecg_filt = np.abs(np.fft.fft(ecg_filt_2))[:np.uint(N/2)]\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.plot(f_vect1, mag_ecg_filt)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\ndef modelo_artefacto(time, p0, p1, p2, p3, p4):\n  return p0+p1*np.sin(p2*time)+p3*np.cos(p4*time)\n\n\npopt, pcov = curve_fit(modelo_artefacto, t, ecg_filt_2)\n\n\npopt[1]\n\n152.2437794044702\n\n\n\nplt.plot(t, modelo_artefacto(t, *popt))\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2-modelo_artefacto(t, *popt))"
  },
  {
    "objectID": "codigo/Preparaciones/python_01_01.html",
    "href": "codigo/Preparaciones/python_01_01.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "\"\"\"\nMatrix 15x15 with two letters:\n- \"I\" drawn using EVEN numbers.\n- \"B\" drawn using PRIME numbers.\n- Background filled with ODD COMPOSITE numbers to visually \"hide\" the letters.\n\nReproducible and self-contained.\n\"\"\"\n\nimport numpy as np\n\nrng = np.random.default_rng(42)\n\n\n# --- helpers ---\ndef is_prime(n: int) -&gt; bool:\n    if n &lt; 2:\n        return False\n    if n % 2 == 0:\n        return n == 2\n    d = 3\n    while d * d &lt;= n:\n        if n % d == 0:\n            return False\n        d += 2\n    return True\n\n\n# pools\neven_pool = np.array([n for n in range(2, 100) if n % 2 == 0])\nprime_pool = np.array([n for n in range(2, 100) if is_prime(n)])\n# odd composite numbers (not prime, not even, &gt;1)\noddcomp_pool = np.array([n for n in range(3, 100, 2) if not is_prime(n)])\n\n# --- canvas ---\nH, W = 15, 15\nM = rng.choice(oddcomp_pool, size=(H, W))  # background: odd composite\n\n\n# Coordinate helper (row, col) with 0-based indexing\ndef put(vals, coords):\n    \"\"\"Place random values from `vals` at integer coordinates `coords`.\"\"\"\n    rr, cc = zip(*coords)\n    M[tuple(rr), tuple(cc)] = rng.choice(vals, size=len(coords))\n\n\n# --- draw \"I\" with even numbers (left side) ---\n# Use a simple blocky \"I\": top bar, vertical stem, bottom bar\ntop_row, bottom_row = 2, 12  # keep margins\nleft_col, right_col = 1, 3\nstem_col = 2\n\nI_coords = []\n# top bar\nI_coords += [(top_row, c) for c in range(left_col, right_col + 1)]\n# bottom bar\nI_coords += [(bottom_row, c) for c in range(left_col, right_col + 1)]\n# vertical stem\nI_coords += [(r, stem_col) for r in range(top_row, bottom_row + 1)]\n\nput(even_pool, I_coords)\n\n# --- draw \"B\" with primes (right side) ---\n# Spine + two bowls (top and bottom) approximated with block pixels\nspine_col = 10\nright_edge = 12\ntop, mid, bot = 2, 7, 12\n\nB_coords = []\n# vertical spine\nB_coords += [(r, spine_col) for r in range(top, bot + 1)]\n# top horizontal\nB_coords += [(top, c) for c in range(spine_col, right_edge + 1)]\n# mid horizontal (waist)\nB_coords += [(mid, c) for c in range(spine_col, right_edge)]\n# bottom horizontal\nB_coords += [(bot, c) for c in range(spine_col, right_edge + 1)]\n# right edges of bowls\nB_coords += [(r, right_edge) for r in range(top + 1, mid)]\nB_coords += [(r, right_edge) for r in range(mid + 1, bot)]\n\nput(prime_pool, B_coords)\n\n\n# --- sanity checks (optional) ---\ndef all_in_pool(vals, coords):\n    rr, cc = zip(*coords)\n    flat = M[tuple(rr), tuple(cc)].ravel().tolist()\n    return all(v in vals for v in flat)\n\n\nassert all_in_pool(set(even_pool.tolist()), I_coords), \"I must be even numbers\"\nassert all_in_pool(set(prime_pool.tolist()), B_coords), \"B must be primes\"\n\n# Background should be odd composite (not even, not prime)\nfor r in range(H):\n    for c in range(W):\n        if (r, c) in I_coords or (r, c) in B_coords:\n            continue\n        v = M[r, c]\n        assert v % 2 == 1 and not is_prime(v), \"Background must be odd composite\"\n\n# --- pretty print ---\nnp.set_printoptions(linewidth=200, formatter={\"int\": lambda x: f\"{x:02d}\"})\nprint(M)\n\n[[21 85 75 51 51 91 21 77 33 21 63 99 81 85 77]\n [85 57 25 87 55 57 49 27 95 85 75 51 87 63 55]\n [55 30 84 58 93 15 91 87 35 69 23 59 07 45 15]\n [99 55 02 75 85 81 27 49 55 57 59 63 11 81 77]\n [95 81 76 99 51 45 93 49 15 55 53 27 19 25 77]\n [55 45 50 65 75 95 51 27 87 69 05 21 89 85 87]\n [51 87 72 49 93 39 33 77 69 25 67 27 97 09 85]\n [85 85 66 55 77 35 85 63 55 57 59 05 25 35 21]\n [51 75 44 55 91 65 15 85 65 69 71 63 47 63 85]\n [39 69 32 45 51 99 33 35 51 99 03 09 37 87 15]\n [91 39 62 39 51 75 25 63 57 85 11 75 23 51 51]\n [87 45 14 45 09 21 21 85 81 77 41 77 53 93 57]\n [95 54 58 46 57 55 27 49 33 39 11 47 71 49 95]\n [21 45 21 45 99 49 93 57 77 55 35 85 99 35 85]\n [35 77 85 55 81 35 15 21 55 93 25 55 77 33 81]]\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# --- Función para identificar primos ---\ndef is_prime(n: int) -&gt; bool:\n    if n &lt; 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    for i in range(3, int(n**0.5) + 1, 2):\n        if n % i == 0:\n            return False\n    return True\n\n\n# # Crear matriz aleatoria 15x15 con números entre 1 y 100\n# np.random.seed(42)\n# M = np.random.randint(1, 100, (15, 5))\n\n# Máscaras lógicas\nmask_even = M % 2 == 0  # pares\nmask_prime = np.vectorize(is_prime)(M)  # primos\n\n# --- Visualización ---\nfig, ax = plt.subplots(figsize=(10, 6.7))\nax.matshow(np.ones_like(M), cmap=\"gray_r\")  # fondo gris claro\n\n# Mostrar números\nfor i in range(M.shape[0]):\n    for j in range(M.shape[1]):\n        val = M[i, j]\n        color = \"black\"\n        weight = \"normal\"\n        if mask_even[i, j]:\n            color = \"black\"\n            weight = \"normal\"\n        if mask_prime[i, j]:\n            color = \"black\"\n            weight = \"normal\"\n        ax.text(\n            j, i, f\"{val:2d}\", va=\"center\", ha=\"center\", color=color, fontweight=weight\n        )\n\nax.set_xticks([])\nax.set_yticks([])\nax.set_title(\"Matriz 15x15\", fontsize=18)\n\nplt.savefig(\"mision01.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# --- Función para identificar primos ---\ndef is_prime(n: int) -&gt; bool:\n    if n &lt; 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    for i in range(3, int(n**0.5) + 1, 2):\n        if n % i == 0:\n            return False\n    return True\n\n\n# # Crear matriz aleatoria 15x15 con números entre 1 y 100\n# np.random.seed(42)\n# M = np.random.randint(1, 100, (15, 15))\n\n# Máscaras lógicas\nmask_even = M % 2 == 0  # pares\nmask_prime = np.vectorize(is_prime)(M)  # primos\n\n# --- Visualización ---\nfig, ax = plt.subplots(figsize=(8, 8))\nax.matshow(np.ones_like(M), cmap=\"gray_r\")  # fondo gris claro\n\n# Mostrar números\nfor i in range(M.shape[0]):\n    for j in range(M.shape[1]):\n        val = M[i, j]\n        color = \"black\"\n        weight = \"normal\"\n        if mask_even[i, j]:\n            color = \"blue\"\n            weight = \"bold\"\n        if mask_prime[i, j]:\n            color = \"red\"\n            weight = \"bold\"\n        ax.text(\n            j, i, f\"{val:2d}\", va=\"center\", ha=\"center\", color=color, fontweight=weight\n        )\n\nax.set_xticks([])\nax.set_yticks([])\nax.set_title(\"Matriz 15x15 con pares (azul) y primos (rojo)\", fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Plotting the polyline defined by the coordinates\nimport matplotlib.pyplot as plt\n\n# Data\nt = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nv = [2, 4, 6, 8, 6, 4, 2, 4, 6, 8]\n\n# Figure\nplt.figure(figsize=(7, 4.5))  # one figure only; fast to render\nplt.plot(t, v, marker=\"o\", linewidth=2)\nplt.xticks(range(1, 11))\nplt.yticks(range(1, 11))\nplt.xlim(1, 10)\nplt.ylim(1, 10)\nplt.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.6)\nplt.xlabel(\"Tiempo\")\nplt.ylabel(\"Valor\")\nplt.title(\"Puntos conectados en el plano (Tiempo vs. Valor)\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/SYSB/remuestreo.html",
    "href": "codigo/SYSB/remuestreo.html",
    "title": "Parámetros Iniciales de la señal",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\\[x\\left(t\\right) = 10\\sin\\left(2\\pi3t\\right)\\]\n\\[t\\in\\left[0, 5\\right]\\]\n\\[f_{s_1} = 20Hz\\]\n\\[f_{s_2} = 100Hz\\]\nt0 = 0\ntf = 1"
  },
  {
    "objectID": "codigo/SYSB/remuestreo.html#gráficas-iniciales",
    "href": "codigo/SYSB/remuestreo.html#gráficas-iniciales",
    "title": "Parámetros Iniciales de la señal",
    "section": "Gráficas iniciales",
    "text": "Gráficas iniciales\n\nt_graph = np.linspace(t0, tf, 1000)\nx = 10*np.sin(2*np.pi*3*t_graph)\nplt.figure(figsize=(10,6))\nplt.plot(t_graph, x)\n\n\n\n\n\n\n\n\n\nfs1 = 20\nt_1 = np.linspace(t0, tf, fs1*(tf-t0), endpoint=False)\nx_1 = 10 * np.sin(2 * np.pi * 3 * t_1)\nplt.figure(figsize=(10, 6))\nplt.plot(t_graph, x)\nplt.plot(t_1, x_1, 'r*')\nplt.grid()\n\n\n\n\n\n\n\n\n\nt_oversample = [t0]\nx_1_over = [x_1[0]]\n\ndelta_t1 = np.mean(np.diff(t_1))\n\nt_oversample = np.empty(len(t_1)+len(t_1))\nt_oversample[0::2] = t_1\nt_oversample[1::2] = t_1 + (delta_t1/2)\n\nx_1_over = np.empty(len(t_1) + len(t_1))\nx_1_over[0::2] = x_1\nx_1_over[1::2] = (x_1+np.roll(x_1,-1))/2\n\nplt.figure(figsize=(10, 6))\nplt.plot(t_graph, x, \"k\")\nplt.plot(t_oversample, x_1_over, \"g*\")\nplt.plot(t_1, x_1, \"r*\")\nplt.grid()\n\n\n\n\n\n\n\n\n\n4//2\n\n2\n\n\n\n4%3\n\n1"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\ndata = pd.read_csv(\"../../data/diabetes.csv\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values\n\ndata.describe()\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n\n\n\ncol_entradas = [\n    \"Pregnancies\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"BMI\",\n    \"DiabetesPedigreeFunction\",\n    \"Age\"\n]\ncol_salidas = [\n    \"Outcome\"\n]\n\n\ndata[col_salidas].head()\n\n\n\n\n\n\n\n\nOutcome\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n2\n1\n\n\n3\n0\n\n\n4\n1"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship\n\nsns.countplot(data=data, x=\"Outcome\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data\n\nstandarScaler_features = StandardScaler().fit(data[col_entradas])\nentradas_norm = standarScaler_features.transform(data[col_entradas])\nsalida_norm = data[col_salidas].values"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#create-neural-network-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#create-neural-network-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network data",
    "text": "Create neural network data\n\nCreate Dataset\n\nclass TabularDataset(Dataset):\n    def __init__(self, ent, sal):\n        self.inputs = torch.tensor(ent, dtype=torch.float32)\n        self.outputs = torch.tensor(sal, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return self.inputs[idx], self.outputs[idx]\n\n\nconjuntoDatos = TabularDataset(ent=entradas_norm, sal=salida_norm)\n\ntrain_ds, val_ds, test_ds = random_split(conjuntoDatos, [0.7, 0.15, 0.15])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=True)\n\n\nfor batch in train_loader:\n    X_batch, y_batch = batch\n    print(X_batch.shape, y_batch.shape)\n\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([26, 8]) torch.Size([26, 1])"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model\n\nclass RedNeuronal(nn.Module):\n    def __init__(self, ent, sal):\n        super(RedNeuronal, self).__init__()\n        self.num_caract = ent\n        self.num_salidas = sal\n        self.fc1 = nn.Linear(self.num_caract, 10)  # Capa oculta 1\n        self.act1 = nn.ReLU()\n        self.fc2 = nn.Linear(10, 12) # Capa oculta 2\n        self.act2 = nn.ReLU()\n        self.fc3 = nn.Linear(12, 13)  # Capa oculta 3\n        self.act3 = nn.ReLU()\n        self.fc4 = nn.Linear(13, self.num_salidas)  # Capa de salida\n        self.act4 = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.act1(self.fc1(x))\n        x = self.act2(self.fc2(x))\n        x = self.act3(self.fc3(x))\n        x = self.act4(self.fc4(x))\n        return x\n\n\nepocas = 1000  # Número de épocas de entrenamiento\nbatch_size = 32  # Tamaño del lote\n\n\nred = RedNeuronal(8, 1)\nred = red.to(device=device1)\n\n\nprint(red.parameters())\n\n&lt;generator object Module.parameters at 0x7f7ae23a5ee0&gt;\n\n\n\ncriterio = nn.BCELoss()\noptimizador = optim.Adam(red.parameters(), lr=0.001)\n\n\n# Entrenar la red neuronal\nfor epoca in range(epocas):\n    perdida_entrenamiento = 0\n    for X_batch, y_batch in train_loader:\n        # Pasar los datos por la red neuronal\n        salida = red(X_batch.to(device=device1))\n\n        # Calcular la pérdida\n        perdida = criterio(salida, y_batch.to(device=device1))\n\n        # Actualizar los pesos\n        optimizador.zero_grad()\n        perdida.backward()\n        optimizador.step()\n        perdida_entrenamiento += perdida.item()\n\n    # Imprimir la pérdida en cada época\n    #print(f\"Época {epoca+1}, pérdida: {perdida.item():.8f}\")\n    perdida_validacion = 0\n    con_exactitud = 0\n    total = 0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            # Pasar los datos por la red neuronal\n            salida = red(X_batch.to(device=device1))\n\n            # Calcular la pérdida\n            perdida = criterio(salida, y_batch.to(device=device1))\n\n            perdida_validacion += perdida.item()\n\n            # Calcular la exactitud\n            _, predicciones = torch.max(salida, 1)\n            con_exactitud += (predicciones.cpu().numpy() == y_batch.cpu().numpy()).sum().item()\n            total += y_batch.shape[0]\n\n    # Imprimir los resultados\n    print(f\"Época {epoca+1}\")\n    print(f\"Perdida entrenamiento: {perdida_entrenamiento/len(train_loader)}\")\n    print(f\"Perdida validación: {perdida_validacion/len(val_loader)}\")\n    print(f\"Exactitud validación: {con_exactitud/total:.4f}\")\n\nÉpoca 1\nPerdida entrenamiento: 0.6791575761402354\nPerdida validación: 0.6788250803947449\nExactitud validación: 18.0609\nÉpoca 2\nPerdida entrenamiento: 0.672294301145217\nPerdida validación: 0.6751690059900284\nExactitud validación: 18.4000\nÉpoca 3\nPerdida entrenamiento: 0.6647399173063391\nPerdida validación: 0.6713864207267761\nExactitud validación: 18.7391\nÉpoca 4\nPerdida entrenamiento: 0.6535137961892521\nPerdida validación: 0.6575797200202942\nExactitud validación: 18.4000\nÉpoca 5\nPerdida entrenamiento: 0.6389946797314812\nPerdida validación: 0.6436730623245239\nExactitud validación: 18.2870\nÉpoca 6\nPerdida entrenamiento: 0.6213853324160856\nPerdida validación: 0.6348690390586853\nExactitud validación: 18.6261\nÉpoca 7\nPerdida entrenamiento: 0.5960922311334049\nPerdida validación: 0.6058164685964584\nExactitud validación: 18.5130\nÉpoca 8\nPerdida entrenamiento: 0.5712940009201274\nPerdida validación: 0.5880416631698608\nExactitud validación: 18.7391\nÉpoca 9\nPerdida entrenamiento: 0.5457583104862886\nPerdida validación: 0.5503197610378265\nExactitud validación: 18.4000\nÉpoca 10\nPerdida entrenamiento: 0.5210335955900305\nPerdida validación: 0.5285529047250748\nExactitud validación: 18.4000\nÉpoca 11\nPerdida entrenamiento: 0.4988165813333848\nPerdida validación: 0.5061830580234528\nExactitud validación: 18.2870\nÉpoca 12\nPerdida entrenamiento: 0.48283538572928486\nPerdida validación: 0.5024331212043762\nExactitud validación: 18.5130\nÉpoca 13\nPerdida entrenamiento: 0.4708527694730198\nPerdida validación: 0.5093462020158768\nExactitud validación: 18.4000\nÉpoca 14\nPerdida entrenamiento: 0.4619144955102135\nPerdida validación: 0.4764373451471329\nExactitud validación: 18.4000\nÉpoca 15\nPerdida entrenamiento: 0.4541836258243112\nPerdida validación: 0.4746478497982025\nExactitud validación: 17.9478\nÉpoca 16\nPerdida entrenamiento: 0.4520234956460841\nPerdida validación: 0.48348189145326614\nExactitud validación: 18.5130\nÉpoca 17\nPerdida entrenamiento: 0.44661900751730976\nPerdida validación: 0.47032642364501953\nExactitud validación: 18.0609\nÉpoca 18\nPerdida entrenamiento: 0.44420213033171263\nPerdida validación: 0.4675467982888222\nExactitud validación: 18.4000\nÉpoca 19\nPerdida entrenamiento: 0.44500470512053547\nPerdida validación: 0.46534235775470734\nExactitud validación: 18.5130\nÉpoca 20\nPerdida entrenamiento: 0.44122909447726083\nPerdida validación: 0.49303658306598663\nExactitud validación: 18.4000\nÉpoca 21\nPerdida entrenamiento: 0.439960497267106\nPerdida validación: 0.4710696116089821\nExactitud validación: 18.0609\nÉpoca 22\nPerdida entrenamiento: 0.43822164395276236\nPerdida validación: 0.4644882157444954\nExactitud validación: 18.4000\nÉpoca 23\nPerdida entrenamiento: 0.43539681855370016\nPerdida validación: 0.48128364980220795\nExactitud validación: 18.4000\nÉpoca 24\nPerdida entrenamiento: 0.43452516373466044\nPerdida validación: 0.49383869767189026\nExactitud validación: 18.5130\nÉpoca 25\nPerdida entrenamiento: 0.4337502367356244\nPerdida validación: 0.461711123585701\nExactitud validación: 18.1739\nÉpoca 26\nPerdida entrenamiento: 0.4328044530223398\nPerdida validación: 0.4867813438177109\nExactitud validación: 18.6261\nÉpoca 27\nPerdida entrenamiento: 0.4315945961896111\nPerdida validación: 0.49709317088127136\nExactitud validación: 18.8522\nÉpoca 28\nPerdida entrenamiento: 0.43218792361371655\nPerdida validación: 0.4762030094861984\nExactitud validación: 18.6261\nÉpoca 29\nPerdida entrenamiento: 0.42929310570744905\nPerdida validación: 0.4678042158484459\nExactitud validación: 18.4000\nÉpoca 30\nPerdida entrenamiento: 0.42652833286453695\nPerdida validación: 0.4651280418038368\nExactitud validación: 18.6261\nÉpoca 31\nPerdida entrenamiento: 0.4259583511773278\nPerdida validación: 0.48188481479883194\nExactitud validación: 18.6261\nÉpoca 32\nPerdida entrenamiento: 0.4245906016405891\nPerdida validación: 0.48621364682912827\nExactitud validación: 18.1739\nÉpoca 33\nPerdida entrenamiento: 0.4256867608603309\nPerdida validación: 0.5174973607063293\nExactitud validación: 18.6261\nÉpoca 34\nPerdida entrenamiento: 0.4248025277081658\nPerdida validación: 0.4981654956936836\nExactitud validación: 18.7391\nÉpoca 35\nPerdida entrenamiento: 0.42286987865672393\nPerdida validación: 0.4870433583855629\nExactitud validación: 18.7391\nÉpoca 36\nPerdida entrenamiento: 0.42132503057227416\nPerdida validación: 0.48050128668546677\nExactitud validación: 18.6261\nÉpoca 37\nPerdida entrenamiento: 0.422717108446009\nPerdida validación: 0.4715006574988365\nExactitud validación: 18.2870\nÉpoca 38\nPerdida entrenamiento: 0.41828276742907133\nPerdida validación: 0.4957212060689926\nExactitud validación: 18.4000\nÉpoca 39\nPerdida entrenamiento: 0.41759711153366985\nPerdida validación: 0.4781687557697296\nExactitud validación: 18.1739\nÉpoca 40\nPerdida entrenamiento: 0.4186316009830026\nPerdida validación: 0.467018261551857\nExactitud validación: 18.7391\nÉpoca 41\nPerdida entrenamiento: 0.41757552763995004\nPerdida validación: 0.47248195111751556\nExactitud validación: 18.5130\nÉpoca 42\nPerdida entrenamiento: 0.41657427479239073\nPerdida validación: 0.5107008069753647\nExactitud validación: 18.9652\nÉpoca 43\nPerdida entrenamiento: 0.41385892559500304\nPerdida validación: 0.48618149757385254\nExactitud validación: 18.6261\nÉpoca 44\nPerdida entrenamiento: 0.4130455264273812\nPerdida validación: 0.48718027025461197\nExactitud validación: 18.1739\nÉpoca 45\nPerdida entrenamiento: 0.4121672230608323\nPerdida validación: 0.49359724670648575\nExactitud validación: 18.4000\nÉpoca 46\nPerdida entrenamiento: 0.4103984973009895\nPerdida validación: 0.5008325800299644\nExactitud validación: 18.6261\nÉpoca 47\nPerdida entrenamiento: 0.40746283005265627\nPerdida validación: 0.5021576881408691\nExactitud validación: 18.4000\nÉpoca 48\nPerdida entrenamiento: 0.4073647067827337\nPerdida validación: 0.4890240281820297\nExactitud validación: 18.5130\nÉpoca 49\nPerdida entrenamiento: 0.40921850765452666\nPerdida validación: 0.5141201466321945\nExactitud validación: 18.4000\nÉpoca 50\nPerdida entrenamiento: 0.40371377503170686\nPerdida validación: 0.5138585902750492\nExactitud validación: 18.4000\nÉpoca 51\nPerdida entrenamiento: 0.40545569798525644\nPerdida validación: 0.49403806775808334\nExactitud validación: 18.7391\nÉpoca 52\nPerdida entrenamiento: 0.4029516472535975\nPerdida validación: 0.4981403201818466\nExactitud validación: 18.4000\nÉpoca 53\nPerdida entrenamiento: 0.40148040301659527\nPerdida validación: 0.470258504152298\nExactitud validación: 18.1739\nÉpoca 54\nPerdida entrenamiento: 0.4014539648504818\nPerdida validación: 0.5071394890546799\nExactitud validación: 18.5130\nÉpoca 55\nPerdida entrenamiento: 0.4001041352748871\nPerdida validación: 0.5059882402420044\nExactitud validación: 18.7391\nÉpoca 56\nPerdida entrenamiento: 0.398499013746486\nPerdida validación: 0.465816680341959\nExactitud validación: 18.1739\nÉpoca 57\nPerdida entrenamiento: 0.39581065318163705\nPerdida validación: 0.4719567634165287\nExactitud validación: 18.4000\nÉpoca 58\nPerdida entrenamiento: 0.3962685343097238\nPerdida validación: 0.49108629673719406\nExactitud validación: 17.9478\nÉpoca 59\nPerdida entrenamiento: 0.3972399699337342\nPerdida validación: 0.5343546643853188\nExactitud validación: 18.4000\nÉpoca 60\nPerdida entrenamiento: 0.39424481111414295\nPerdida validación: 0.5204134956002235\nExactitud validación: 18.0609\nÉpoca 61\nPerdida entrenamiento: 0.3933473562493044\nPerdida validación: 0.48885199427604675\nExactitud validación: 18.2870\nÉpoca 62\nPerdida entrenamiento: 0.39581848593319163\nPerdida validación: 0.5045148134231567\nExactitud validación: 18.6261\nÉpoca 63\nPerdida entrenamiento: 0.39225762381273155\nPerdida validación: 0.49928755313158035\nExactitud validación: 18.5130\nÉpoca 64\nPerdida entrenamiento: 0.39095135120784535\nPerdida validación: 0.49818097054958344\nExactitud validación: 18.4000\nÉpoca 65\nPerdida entrenamiento: 0.39278412917081046\nPerdida validación: 0.51187414675951\nExactitud validación: 18.4000\nÉpoca 66\nPerdida entrenamiento: 0.3880087408949347\nPerdida validación: 0.5048925578594208\nExactitud validación: 18.4000\nÉpoca 67\nPerdida entrenamiento: 0.3891824781894684\nPerdida validación: 0.49526503682136536\nExactitud validación: 18.6261\nÉpoca 68\nPerdida entrenamiento: 0.38694337185691385\nPerdida validación: 0.520538330078125\nExactitud validación: 18.7391\nÉpoca 69\nPerdida entrenamiento: 0.3850225508213043\nPerdida validación: 0.4962310940027237\nExactitud validación: 18.1739\nÉpoca 70\nPerdida entrenamiento: 0.3856160588124219\nPerdida validación: 0.5117396265268326\nExactitud validación: 18.6261\nÉpoca 71\nPerdida entrenamiento: 0.38290825836798725\nPerdida validación: 0.48271531239151955\nExactitud validación: 18.7391\nÉpoca 72\nPerdida entrenamiento: 0.3842119478127536\nPerdida validación: 0.5159867852926254\nExactitud validación: 18.1739\nÉpoca 73\nPerdida entrenamiento: 0.38493889570236206\nPerdida validación: 0.5417948067188263\nExactitud validación: 18.5130\nÉpoca 74\nPerdida entrenamiento: 0.38206734727410707\nPerdida validación: 0.4967944473028183\nExactitud validación: 18.4000\nÉpoca 75\nPerdida entrenamiento: 0.3789928336353863\nPerdida validación: 0.518608808517456\nExactitud validación: 18.5130\nÉpoca 76\nPerdida entrenamiento: 0.3797504796701319\nPerdida validación: 0.5038291662931442\nExactitud validación: 18.2870\nÉpoca 77\nPerdida entrenamiento: 0.3783522914437687\nPerdida validación: 0.5356133580207825\nExactitud validación: 18.1739\nÉpoca 78\nPerdida entrenamiento: 0.37765972754534555\nPerdida validación: 0.5259551480412483\nExactitud validación: 18.4000\nÉpoca 79\nPerdida entrenamiento: 0.3763415795915267\nPerdida validación: 0.5199824124574661\nExactitud validación: 18.0609\nÉpoca 80\nPerdida entrenamiento: 0.3773508159553303\nPerdida validación: 0.49937019497156143\nExactitud validación: 18.2870\nÉpoca 81\nPerdida entrenamiento: 0.37419071442940655\nPerdida validación: 0.5143114551901817\nExactitud validación: 18.6261\nÉpoca 82\nPerdida entrenamiento: 0.37580522544243755\nPerdida validación: 0.5341081693768501\nExactitud validación: 18.4000\nÉpoca 83\nPerdida entrenamiento: 0.3732707009595983\nPerdida validación: 0.5355776324868202\nExactitud validación: 18.6261\nÉpoca 84\nPerdida entrenamiento: 0.37286416923298554\nPerdida validación: 0.5186856985092163\nExactitud validación: 18.4000\nÉpoca 85\nPerdida entrenamiento: 0.3705448946532081\nPerdida validación: 0.5483004599809647\nExactitud validación: 18.4000\nÉpoca 86\nPerdida entrenamiento: 0.3727482636185253\nPerdida validación: 0.5254365280270576\nExactitud validación: 18.2870\nÉpoca 87\nPerdida entrenamiento: 0.3692259718390072\nPerdida validación: 0.5111869126558304\nExactitud validación: 18.5130\nÉpoca 88\nPerdida entrenamiento: 0.37127525315565224\nPerdida validación: 0.5337236076593399\nExactitud validación: 18.4000\nÉpoca 89\nPerdida entrenamiento: 0.37246738461887136\nPerdida validación: 0.5206818729639053\nExactitud validación: 18.1739\nÉpoca 90\nPerdida entrenamiento: 0.3690295158063664\nPerdida validación: 0.5593036413192749\nExactitud validación: 18.5130\nÉpoca 91\nPerdida entrenamiento: 0.369259593241355\nPerdida validación: 0.5117775499820709\nExactitud validación: 18.2870\nÉpoca 92\nPerdida entrenamiento: 0.3679639767198002\nPerdida validación: 0.5290718674659729\nExactitud validación: 18.4000\nÉpoca 93\nPerdida entrenamiento: 0.36736031928483176\nPerdida validación: 0.5078761726617813\nExactitud validación: 18.4000\nÉpoca 94\nPerdida entrenamiento: 0.3644753282561022\nPerdida validación: 0.5632258951663971\nExactitud validación: 18.7391\nÉpoca 95\nPerdida entrenamiento: 0.36306865776286407\nPerdida validación: 0.5218587443232536\nExactitud validación: 18.2870\nÉpoca 96\nPerdida entrenamiento: 0.3643888498053831\nPerdida validación: 0.5354526937007904\nExactitud validación: 18.2870\nÉpoca 97\nPerdida entrenamiento: 0.3653539445470361\nPerdida validación: 0.51034265011549\nExactitud validación: 18.4000\nÉpoca 98\nPerdida entrenamiento: 0.36249710707103505\nPerdida validación: 0.5734138116240501\nExactitud validación: 18.6261\nÉpoca 99\nPerdida entrenamiento: 0.36265045316780314\nPerdida validación: 0.5656266584992409\nExactitud validación: 18.7391\nÉpoca 100\nPerdida entrenamiento: 0.3610046874074375\nPerdida validación: 0.521674856543541\nExactitud validación: 18.2870\nÉpoca 101\nPerdida entrenamiento: 0.35992640081573934\nPerdida validación: 0.5487679094076157\nExactitud validación: 18.2870\nÉpoca 102\nPerdida entrenamiento: 0.3585259414771024\nPerdida validación: 0.548629879951477\nExactitud validación: 18.5130\nÉpoca 103\nPerdida entrenamiento: 0.35833654684178967\nPerdida validación: 0.5379441231489182\nExactitud validación: 18.4000\nÉpoca 104\nPerdida entrenamiento: 0.3592461680664736\nPerdida validación: 0.543404832482338\nExactitud validación: 18.4000\nÉpoca 105\nPerdida entrenamiento: 0.3567296178901897\nPerdida validación: 0.5594352409243584\nExactitud validación: 18.2870\nÉpoca 106\nPerdida entrenamiento: 0.3556781069320791\nPerdida validación: 0.5586513355374336\nExactitud validación: 18.4000\nÉpoca 107\nPerdida entrenamiento: 0.35517681609181795\nPerdida validación: 0.5655415803194046\nExactitud validación: 18.4000\nÉpoca 108\nPerdida entrenamiento: 0.35475079189328584\nPerdida validación: 0.5609813407063484\nExactitud validación: 18.8522\nÉpoca 109\nPerdida entrenamiento: 0.3557695606175591\nPerdida validación: 0.5627079755067825\nExactitud validación: 18.2870\nÉpoca 110\nPerdida entrenamiento: 0.3561686961089863\nPerdida validación: 0.5387836992740631\nExactitud validación: 18.4000\nÉpoca 111\nPerdida entrenamiento: 0.35163088756449085\nPerdida validación: 0.5590721815824509\nExactitud validación: 18.1739\nÉpoca 112\nPerdida entrenamiento: 0.35371597812456246\nPerdida validación: 0.5587764009833336\nExactitud validación: 18.2870\nÉpoca 113\nPerdida entrenamiento: 0.3535332837525536\nPerdida validación: 0.5312048122286797\nExactitud validación: 18.5130\nÉpoca 114\nPerdida entrenamiento: 0.35189832834636464\nPerdida validación: 0.6044761911034584\nExactitud validación: 18.8522\nÉpoca 115\nPerdida entrenamiento: 0.3514702092198765\nPerdida validación: 0.5321017280220985\nExactitud validación: 18.6261\nÉpoca 116\nPerdida entrenamiento: 0.351543351131327\nPerdida validación: 0.5573963150382042\nExactitud validación: 18.6261\nÉpoca 117\nPerdida entrenamiento: 0.3497464911026113\nPerdida validación: 0.5573238208889961\nExactitud validación: 18.4000\nÉpoca 118\nPerdida entrenamiento: 0.3498367386705735\nPerdida validación: 0.5645684897899628\nExactitud validación: 18.2870\nÉpoca 119\nPerdida entrenamiento: 0.35061120899284587\nPerdida validación: 0.5626191198825836\nExactitud validación: 18.5130\nÉpoca 120\nPerdida entrenamiento: 0.34882452558068666\nPerdida validación: 0.5745996534824371\nExactitud validación: 18.2870\nÉpoca 121\nPerdida entrenamiento: 0.3476862302597831\nPerdida validación: 0.5468194410204887\nExactitud validación: 18.4000\nÉpoca 122\nPerdida entrenamiento: 0.34637948432389426\nPerdida validación: 0.533638957887888\nExactitud validación: 17.9478\nÉpoca 123\nPerdida entrenamiento: 0.34753450838958516\nPerdida validación: 0.5294349901378155\nExactitud validación: 18.1739\nÉpoca 124\nPerdida entrenamiento: 0.3470301829716739\nPerdida validación: 0.5638434365391731\nExactitud validación: 18.4000\nÉpoca 125\nPerdida entrenamiento: 0.3439143107217901\nPerdida validación: 0.5707154497504234\nExactitud validación: 18.8522\nÉpoca 126\nPerdida entrenamiento: 0.34399966369656954\nPerdida validación: 0.5750905275344849\nExactitud validación: 18.5130\nÉpoca 127\nPerdida entrenamiento: 0.3459861094460768\nPerdida validación: 0.5637594535946846\nExactitud validación: 18.2870\nÉpoca 128\nPerdida entrenamiento: 0.3425804122405894\nPerdida validación: 0.5966473817825317\nExactitud validación: 18.7391\nÉpoca 129\nPerdida entrenamiento: 0.34382107065004464\nPerdida validación: 0.5452658385038376\nExactitud validación: 18.4000\nÉpoca 130\nPerdida entrenamiento: 0.3432043326251647\nPerdida validación: 0.568010963499546\nExactitud validación: 18.5130\nÉpoca 131\nPerdida entrenamiento: 0.34486333587590384\nPerdida validación: 0.5764288678765297\nExactitud validación: 18.4000\nÉpoca 132\nPerdida entrenamiento: 0.3452732370180242\nPerdida validación: 0.5937597900629044\nExactitud validación: 18.5130\nÉpoca 133\nPerdida entrenamiento: 0.343221268233131\nPerdida validación: 0.6223113089799881\nExactitud validación: 18.7391\nÉpoca 134\nPerdida entrenamiento: 0.3406377662630642\nPerdida validación: 0.6121482476592064\nExactitud validación: 18.7391\nÉpoca 135\nPerdida entrenamiento: 0.34228555770481334\nPerdida validación: 0.5532180443406105\nExactitud validación: 18.1739\nÉpoca 136\nPerdida entrenamiento: 0.3407059855320874\nPerdida validación: 0.6256612241268158\nExactitud validación: 18.6261\nÉpoca 137\nPerdida entrenamiento: 0.33841385210261626\nPerdida validación: 0.6118277311325073\nExactitud validación: 18.7391\nÉpoca 138\nPerdida entrenamiento: 0.3379518126740175\nPerdida validación: 0.5608039274811745\nExactitud validación: 18.4000\nÉpoca 139\nPerdida entrenamiento: 0.33698144818053527\nPerdida validación: 0.6184676513075829\nExactitud validación: 18.6261\nÉpoca 140\nPerdida entrenamiento: 0.3397687033695333\nPerdida validación: 0.6316100880503654\nExactitud validación: 18.5130\nÉpoca 141\nPerdida entrenamiento: 0.33633708515587973\nPerdida validación: 0.5819898918271065\nExactitud validación: 18.6261\nÉpoca 142\nPerdida entrenamiento: 0.33748694290133086\nPerdida validación: 0.6265446171164513\nExactitud validación: 18.1739\nÉpoca 143\nPerdida entrenamiento: 0.3356994197649114\nPerdida validación: 0.6239243969321251\nExactitud validación: 18.4000\nÉpoca 144\nPerdida entrenamiento: 0.33472176159129424\nPerdida validación: 0.6359140202403069\nExactitud validación: 18.4000\nÉpoca 145\nPerdida entrenamiento: 0.3353544543771183\nPerdida validación: 0.623450018465519\nExactitud validación: 18.4000\nÉpoca 146\nPerdida entrenamiento: 0.33618306412416343\nPerdida validación: 0.5927932560443878\nExactitud validación: 18.0609\nÉpoca 147\nPerdida entrenamiento: 0.3340167955440633\nPerdida validación: 0.6286558359861374\nExactitud validación: 18.6261\nÉpoca 148\nPerdida entrenamiento: 0.33400292519260855\nPerdida validación: 0.6745086014270782\nExactitud validación: 18.1739\nÉpoca 149\nPerdida entrenamiento: 0.3350304067134857\nPerdida validación: 0.6481637880206108\nExactitud validación: 18.5130\nÉpoca 150\nPerdida entrenamiento: 0.3336921281674329\nPerdida validación: 0.6298792809247971\nExactitud validación: 18.7391\nÉpoca 151\nPerdida entrenamiento: 0.3350611933890511\nPerdida validación: 0.5883950218558311\nExactitud validación: 18.0609\nÉpoca 152\nPerdida entrenamiento: 0.3336448108448702\nPerdida validación: 0.6367370784282684\nExactitud validación: 18.5130\nÉpoca 153\nPerdida entrenamiento: 0.3326067302156897\nPerdida validación: 0.6520734950900078\nExactitud validación: 18.2870\nÉpoca 154\nPerdida entrenamiento: 0.3309824501766878\nPerdida validación: 0.6116059124469757\nExactitud validación: 18.2870\nÉpoca 155\nPerdida entrenamiento: 0.3331507540800992\nPerdida validación: 0.590815544128418\nExactitud validación: 18.5130\nÉpoca 156\nPerdida entrenamiento: 0.33216743872446175\nPerdida validación: 0.6476473957300186\nExactitud validación: 18.2870\nÉpoca 157\nPerdida entrenamiento: 0.3311873867231257\nPerdida validación: 0.6468140035867691\nExactitud validación: 18.0609\nÉpoca 158\nPerdida entrenamiento: 0.32796593273387237\nPerdida validación: 0.6146449446678162\nExactitud validación: 18.1739\nÉpoca 159\nPerdida entrenamiento: 0.33034057389287386\nPerdida validación: 0.6230598539113998\nExactitud validación: 18.5130\nÉpoca 160\nPerdida entrenamiento: 0.3273730260484359\nPerdida validación: 0.6443871557712555\nExactitud validación: 18.4000\nÉpoca 161\nPerdida entrenamiento: 0.330964570536333\nPerdida validación: 0.6126606613397598\nExactitud validación: 18.6261\nÉpoca 162\nPerdida entrenamiento: 0.33085155487060547\nPerdida validación: 0.6176680326461792\nExactitud validación: 18.5130\nÉpoca 163\nPerdida entrenamiento: 0.32789769067483787\nPerdida validación: 0.5946464017033577\nExactitud validación: 18.5130\nÉpoca 164\nPerdida entrenamiento: 0.3267712610609391\nPerdida validación: 0.6227770447731018\nExactitud validación: 18.2870\nÉpoca 165\nPerdida entrenamiento: 0.3263696502236759\nPerdida validación: 0.6890445426106453\nExactitud validación: 18.2870\nÉpoca 166\nPerdida entrenamiento: 0.3250192473916447\nPerdida validación: 0.6499665081501007\nExactitud validación: 18.5130\nÉpoca 167\nPerdida entrenamiento: 0.3261696854058434\nPerdida validación: 0.6132025644183159\nExactitud validación: 18.2870\nÉpoca 168\nPerdida entrenamiento: 0.3261833287337247\nPerdida validación: 0.6634091883897781\nExactitud validación: 18.5130\nÉpoca 169\nPerdida entrenamiento: 0.32349429411046643\nPerdida validación: 0.6630931124091148\nExactitud validación: 18.6261\nÉpoca 170\nPerdida entrenamiento: 0.3271436393260956\nPerdida validación: 0.612961657345295\nExactitud validación: 18.5130\nÉpoca 171\nPerdida entrenamiento: 0.32476263098856983\nPerdida validación: 0.6598226502537727\nExactitud validación: 18.2870\nÉpoca 172\nPerdida entrenamiento: 0.324515997486956\nPerdida validación: 0.6418932229280472\nExactitud validación: 18.4000\nÉpoca 173\nPerdida entrenamiento: 0.32433526919168587\nPerdida validación: 0.7335801050066948\nExactitud validación: 18.2870\nÉpoca 174\nPerdida entrenamiento: 0.3219207516487907\nPerdida validación: 0.653811901807785\nExactitud validación: 18.2870\nÉpoca 175\nPerdida entrenamiento: 0.3205060888739193\nPerdida validación: 0.6664783358573914\nExactitud validación: 18.5130\nÉpoca 176\nPerdida entrenamiento: 0.3207370875512852\nPerdida validación: 0.6229857131838799\nExactitud validación: 18.0609\nÉpoca 177\nPerdida entrenamiento: 0.3227768680628608\nPerdida validación: 0.6437440887093544\nExactitud validación: 18.2870\nÉpoca 178\nPerdida entrenamiento: 0.3209051349583794\nPerdida validación: 0.6665943264961243\nExactitud validación: 18.4000\nÉpoca 179\nPerdida entrenamiento: 0.32111615643781777\nPerdida validación: 0.6589837148785591\nExactitud validación: 18.5130\nÉpoca 180\nPerdida entrenamiento: 0.3208710200646344\nPerdida validación: 0.6451635211706161\nExactitud validación: 18.4000\nÉpoca 181\nPerdida entrenamiento: 0.3188728216816397\nPerdida validación: 0.6509027481079102\nExactitud validación: 18.4000\nÉpoca 182\nPerdida entrenamiento: 0.3178029682706384\nPerdida validación: 0.6660331636667252\nExactitud validación: 18.2870\nÉpoca 183\nPerdida entrenamiento: 0.31673886320170236\nPerdida validación: 0.6581268012523651\nExactitud validación: 18.2870\nÉpoca 184\nPerdida entrenamiento: 0.31750109002870675\nPerdida validación: 0.6372020319104195\nExactitud validación: 18.5130\nÉpoca 185\nPerdida entrenamiento: 0.31816011930213256\nPerdida validación: 0.7313763499259949\nExactitud validación: 18.4000\nÉpoca 186\nPerdida entrenamiento: 0.3156069096396951\nPerdida validación: 0.6771089732646942\nExactitud validación: 18.4000\nÉpoca 187\nPerdida entrenamiento: 0.31772204532342796\nPerdida validación: 0.6511183455586433\nExactitud validación: 18.4000\nÉpoca 188\nPerdida entrenamiento: 0.31324949685265036\nPerdida validación: 0.6433937773108482\nExactitud validación: 18.1739\nÉpoca 189\nPerdida entrenamiento: 0.31725497894427357\nPerdida validación: 0.68333500623703\nExactitud validación: 18.1739\nÉpoca 190\nPerdida entrenamiento: 0.3123554464648752\nPerdida validación: 0.6660071387887001\nExactitud validación: 18.8522\nÉpoca 191\nPerdida entrenamiento: 0.3153311452444862\nPerdida validación: 0.7063699811697006\nExactitud validación: 18.7391\nÉpoca 192\nPerdida entrenamiento: 0.31404705433284535\nPerdida validación: 0.6741388291120529\nExactitud validación: 18.7391\nÉpoca 193\nPerdida entrenamiento: 0.31402675632168264\nPerdida validación: 0.6543318554759026\nExactitud validación: 18.1739\nÉpoca 194\nPerdida entrenamiento: 0.3119946630562053\nPerdida validación: 0.6574038416147232\nExactitud validación: 18.5130\nÉpoca 195\nPerdida entrenamiento: 0.3136322226594476\nPerdida validación: 0.7180648446083069\nExactitud validación: 18.2870\nÉpoca 196\nPerdida entrenamiento: 0.3097478344159968\nPerdida validación: 0.6812009885907173\nExactitud validación: 18.2870\nÉpoca 197\nPerdida entrenamiento: 0.3116472389768152\nPerdida validación: 0.6507846117019653\nExactitud validación: 18.4000\nÉpoca 198\nPerdida entrenamiento: 0.31110472188276406\nPerdida validación: 0.6414782479405403\nExactitud validación: 18.2870\nÉpoca 199\nPerdida entrenamiento: 0.3103514997398152\nPerdida validación: 0.6524050757288933\nExactitud validación: 18.4000\nÉpoca 200\nPerdida entrenamiento: 0.31179756802671094\nPerdida validación: 0.6920239329338074\nExactitud validación: 18.7391\nÉpoca 201\nPerdida entrenamiento: 0.3084581047296524\nPerdida validación: 0.764978215098381\nExactitud validación: 18.0609\nÉpoca 202\nPerdida entrenamiento: 0.30916617986033945\nPerdida validación: 0.7176909744739532\nExactitud validación: 18.4000\nÉpoca 203\nPerdida entrenamiento: 0.3087397515773773\nPerdida validación: 0.7063323929905891\nExactitud validación: 18.2870\nÉpoca 204\nPerdida entrenamiento: 0.3106594672974418\nPerdida validación: 0.6954813897609711\nExactitud validación: 18.4000\nÉpoca 205\nPerdida entrenamiento: 0.30759740226409016\nPerdida validación: 0.7038579732179642\nExactitud validación: 18.1739\nÉpoca 206\nPerdida entrenamiento: 0.3062534963383394\nPerdida validación: 0.7156248390674591\nExactitud validación: 18.2870\nÉpoca 207\nPerdida entrenamiento: 0.30647197278106914\nPerdida validación: 0.688948281109333\nExactitud validación: 18.5130\nÉpoca 208\nPerdida entrenamiento: 0.3078196758733076\nPerdida validación: 0.692335918545723\nExactitud validación: 18.6261\nÉpoca 209\nPerdida entrenamiento: 0.30704403011237874\nPerdida validación: 0.6741050034761429\nExactitud validación: 17.9478\nÉpoca 210\nPerdida entrenamiento: 0.30527643508770885\nPerdida validación: 0.6659369245171547\nExactitud validación: 18.5130\nÉpoca 211\nPerdida entrenamiento: 0.3071153356748469\nPerdida validación: 0.7391846030950546\nExactitud validación: 18.6261\nÉpoca 212\nPerdida entrenamiento: 0.30531730371363025\nPerdida validación: 0.7998167648911476\nExactitud validación: 18.5130\nÉpoca 213\nPerdida entrenamiento: 0.3038189893259722\nPerdida validación: 0.7052174434065819\nExactitud validación: 17.9478\nÉpoca 214\nPerdida entrenamiento: 0.30341966976137724\nPerdida validación: 0.7350720167160034\nExactitud validación: 18.5130\nÉpoca 215\nPerdida entrenamiento: 0.30246863645665784\nPerdida validación: 0.7088495343923569\nExactitud validación: 18.5130\nÉpoca 216\nPerdida entrenamiento: 0.30353131013758045\nPerdida validación: 0.6834466755390167\nExactitud validación: 18.6261\nÉpoca 217\nPerdida entrenamiento: 0.30161605074125175\nPerdida validación: 0.7241852506995201\nExactitud validación: 17.9478\nÉpoca 218\nPerdida entrenamiento: 0.3025359528906205\nPerdida validación: 0.6786011755466461\nExactitud validación: 18.1739\nÉpoca 219\nPerdida entrenamiento: 0.3013206886894563\nPerdida validación: 0.679993025958538\nExactitud validación: 18.5130\nÉpoca 220\nPerdida entrenamiento: 0.3010849926401587\nPerdida validación: 0.8055609986186028\nExactitud validación: 18.7391\nÉpoca 221\nPerdida entrenamiento: 0.299965525374693\nPerdida validación: 0.6772769540548325\nExactitud validación: 18.4000\nÉpoca 222\nPerdida entrenamiento: 0.3033907431013444\nPerdida validación: 0.736585833132267\nExactitud validación: 18.5130\nÉpoca 223\nPerdida entrenamiento: 0.3007599991910598\nPerdida validación: 0.7596707493066788\nExactitud validación: 18.2870\nÉpoca 224\nPerdida entrenamiento: 0.30001555558513193\nPerdida validación: 0.6992309913039207\nExactitud validación: 18.2870\nÉpoca 225\nPerdida entrenamiento: 0.2969650775194168\nPerdida validación: 0.7044773250818253\nExactitud validación: 18.2870\nÉpoca 226\nPerdida entrenamiento: 0.29871873557567596\nPerdida validación: 0.6746115535497665\nExactitud validación: 18.5130\nÉpoca 227\nPerdida entrenamiento: 0.2973190230481765\nPerdida validación: 0.684038981795311\nExactitud validación: 18.4000\nÉpoca 228\nPerdida entrenamiento: 0.2981330340399462\nPerdida validación: 0.7490448206663132\nExactitud validación: 18.8522\nÉpoca 229\nPerdida entrenamiento: 0.29559924935593324\nPerdida validación: 0.694603718817234\nExactitud validación: 18.4000\nÉpoca 230\nPerdida entrenamiento: 0.2944230069132412\nPerdida validación: 0.7294625043869019\nExactitud validación: 18.5130\nÉpoca 231\nPerdida entrenamiento: 0.29362457640030803\nPerdida validación: 0.7362787425518036\nExactitud validación: 18.6261\nÉpoca 232\nPerdida entrenamiento: 0.294377674074734\nPerdida validación: 0.7065712809562683\nExactitud validación: 18.5130\nÉpoca 233\nPerdida entrenamiento: 0.29613833129405975\nPerdida validación: 0.7128828167915344\nExactitud validación: 18.2870\nÉpoca 234\nPerdida entrenamiento: 0.29697078904684854\nPerdida validación: 0.7355586439371109\nExactitud validación: 18.2870\nÉpoca 235\nPerdida entrenamiento: 0.2928716233547996\nPerdida validación: 0.8148213103413582\nExactitud validación: 18.7391\nÉpoca 236\nPerdida entrenamiento: 0.2956160175449708\nPerdida validación: 0.7032250016927719\nExactitud validación: 18.5130\nÉpoca 237\nPerdida entrenamiento: 0.29322683942668576\nPerdida validación: 0.7366586253046989\nExactitud validación: 18.6261\nÉpoca 238\nPerdida entrenamiento: 0.29531940730179057\nPerdida validación: 0.716269001364708\nExactitud validación: 18.2870\nÉpoca 239\nPerdida entrenamiento: 0.29456058582838845\nPerdida validación: 0.8046405576169491\nExactitud validación: 18.6261\nÉpoca 240\nPerdida entrenamiento: 0.2919597485486199\nPerdida validación: 0.7698554992675781\nExactitud validación: 18.1739\nÉpoca 241\nPerdida entrenamiento: 0.2926513622788822\nPerdida validación: 0.6973117738962173\nExactitud validación: 18.7391\nÉpoca 242\nPerdida entrenamiento: 0.2892984853071325\nPerdida validación: 0.7638273388147354\nExactitud validación: 18.4000\nÉpoca 243\nPerdida entrenamiento: 0.29051580937469706\nPerdida validación: 0.7815098166465759\nExactitud validación: 18.7391\nÉpoca 244\nPerdida entrenamiento: 0.2899246417424258\nPerdida validación: 0.7704179286956787\nExactitud validación: 18.1739\nÉpoca 245\nPerdida entrenamiento: 0.28837614375002246\nPerdida validación: 0.7450488656759262\nExactitud validación: 18.4000\nÉpoca 246\nPerdida entrenamiento: 0.29001492174232707\nPerdida validación: 0.7398979514837265\nExactitud validación: 18.1739\nÉpoca 247\nPerdida entrenamiento: 0.28900785919497995\nPerdida validación: 0.7784785479307175\nExactitud validación: 18.0609\nÉpoca 248\nPerdida entrenamiento: 0.28841665474807515\nPerdida validación: 0.7403790205717087\nExactitud validación: 18.5130\nÉpoca 249\nPerdida entrenamiento: 0.2894595230326933\nPerdida validación: 0.7213053703308105\nExactitud validación: 18.2870\nÉpoca 250\nPerdida entrenamiento: 0.2888253462665221\nPerdida validación: 0.766401544213295\nExactitud validación: 18.2870\nÉpoca 251\nPerdida entrenamiento: 0.2866971107090221\nPerdida validación: 0.7406387180089951\nExactitud validación: 18.5130\nÉpoca 252\nPerdida entrenamiento: 0.2872468583724078\nPerdida validación: 0.7808045633137226\nExactitud validación: 18.5130\nÉpoca 253\nPerdida entrenamiento: 0.2877846333910437\nPerdida validación: 0.7809512466192245\nExactitud validación: 18.4000\nÉpoca 254\nPerdida entrenamiento: 0.2867770826115328\nPerdida validación: 0.7319426983594894\nExactitud validación: 18.1739\nÉpoca 255\nPerdida entrenamiento: 0.28648798080051646\nPerdida validación: 0.7230148687958717\nExactitud validación: 18.4000\nÉpoca 256\nPerdida entrenamiento: 0.2846994154593524\nPerdida validación: 0.7592649683356285\nExactitud validación: 18.4000\nÉpoca 257\nPerdida entrenamiento: 0.2864809036254883\nPerdida validación: 0.7423518821597099\nExactitud validación: 18.2870\nÉpoca 258\nPerdida entrenamiento: 0.2850097224992864\nPerdida validación: 0.8285829573869705\nExactitud validación: 18.2870\nÉpoca 259\nPerdida entrenamiento: 0.2860611309023464\nPerdida validación: 0.7817785143852234\nExactitud validación: 18.5130\nÉpoca 260\nPerdida entrenamiento: 0.28397778027197895\nPerdida validación: 0.7759557962417603\nExactitud validación: 18.1739\nÉpoca 261\nPerdida entrenamiento: 0.2851453958188786\nPerdida validación: 0.773240715265274\nExactitud validación: 18.1739\nÉpoca 262\nPerdida entrenamiento: 0.28346505322877097\nPerdida validación: 0.8145815879106522\nExactitud validación: 18.4000\nÉpoca 263\nPerdida entrenamiento: 0.2839648855083129\nPerdida validación: 0.8247283324599266\nExactitud validación: 18.2870\nÉpoca 264\nPerdida entrenamiento: 0.2820875758633894\nPerdida validación: 0.7470234334468842\nExactitud validación: 18.1739\nÉpoca 265\nPerdida entrenamiento: 0.2828727487255545\nPerdida validación: 0.7517593279480934\nExactitud validación: 18.4000\nÉpoca 266\nPerdida entrenamiento: 0.28342335364397836\nPerdida validación: 0.745085820555687\nExactitud validación: 18.0609\nÉpoca 267\nPerdida entrenamiento: 0.28173114271724925\nPerdida validación: 0.8318959027528763\nExactitud validación: 18.5130\nÉpoca 268\nPerdida entrenamiento: 0.28258827241028056\nPerdida validación: 0.7550449594855309\nExactitud validación: 18.5130\nÉpoca 269\nPerdida entrenamiento: 0.2806198824854458\nPerdida validación: 0.815860778093338\nExactitud validación: 17.9478\nÉpoca 270\nPerdida entrenamiento: 0.2798441560829387\nPerdida validación: 0.8292346000671387\nExactitud validación: 18.7391\nÉpoca 271\nPerdida entrenamiento: 0.28328849813517404\nPerdida validación: 0.84027498960495\nExactitud validación: 17.9478\nÉpoca 272\nPerdida entrenamiento: 0.27925308399340687\nPerdida validación: 0.8446707427501678\nExactitud validación: 18.5130\nÉpoca 273\nPerdida entrenamiento: 0.279740308137501\nPerdida validación: 0.7891214042901993\nExactitud validación: 18.4000\nÉpoca 274\nPerdida entrenamiento: 0.2804296621504952\nPerdida validación: 0.7523273676633835\nExactitud validación: 18.6261\nÉpoca 275\nPerdida entrenamiento: 0.2786500278641196\nPerdida validación: 0.8763114959001541\nExactitud validación: 18.5130\nÉpoca 276\nPerdida entrenamiento: 0.2789465942803551\nPerdida validación: 0.7518940791487694\nExactitud validación: 18.4000\nÉpoca 277\nPerdida entrenamiento: 0.2798019025255652\nPerdida validación: 0.8489273488521576\nExactitud validación: 18.7391\nÉpoca 278\nPerdida entrenamiento: 0.280226955519003\nPerdida validación: 0.766749732196331\nExactitud validación: 18.5130\nÉpoca 279\nPerdida entrenamiento: 0.2779183343929403\nPerdida validación: 0.7820227146148682\nExactitud validación: 18.4000\nÉpoca 280\nPerdida entrenamiento: 0.2765612396247247\nPerdida validación: 0.7857282161712646\nExactitud validación: 18.4000\nÉpoca 281\nPerdida entrenamiento: 0.27886566169121685\nPerdida validación: 0.8160237297415733\nExactitud validación: 18.6261\nÉpoca 282\nPerdida entrenamiento: 0.2769961637609145\nPerdida validación: 0.8009995818138123\nExactitud validación: 18.5130\nÉpoca 283\nPerdida entrenamiento: 0.2754744019578485\nPerdida validación: 0.8242090195417404\nExactitud validación: 18.2870\nÉpoca 284\nPerdida entrenamiento: 0.27566534894354205\nPerdida validación: 0.8263423070311546\nExactitud validación: 18.4000\nÉpoca 285\nPerdida entrenamiento: 0.275710387264981\nPerdida validación: 0.7984395027160645\nExactitud validación: 18.7391\nÉpoca 286\nPerdida entrenamiento: 0.2722511160023072\nPerdida validación: 0.7776636183261871\nExactitud validación: 18.7391\nÉpoca 287\nPerdida entrenamiento: 0.2785680565763922\nPerdida validación: 0.8693821281194687\nExactitud validación: 18.1739\nÉpoca 288\nPerdida entrenamiento: 0.2776385243324673\nPerdida validación: 0.8111721277236938\nExactitud validación: 18.5130\nÉpoca 289\nPerdida entrenamiento: 0.2753101648653255\nPerdida validación: 0.7979157716035843\nExactitud validación: 18.6261\nÉpoca 290\nPerdida entrenamiento: 0.2721212304690305\nPerdida validación: 0.8984339684247971\nExactitud validación: 18.1739\nÉpoca 291\nPerdida entrenamiento: 0.27208081150756164\nPerdida validación: 0.8066085278987885\nExactitud validación: 18.0609\nÉpoca 292\nPerdida entrenamiento: 0.2724810707218507\nPerdida validación: 0.858610674738884\nExactitud validación: 18.1739\nÉpoca 293\nPerdida entrenamiento: 0.2749691465321709\nPerdida validación: 0.8009930029511452\nExactitud validación: 18.4000\nÉpoca 294\nPerdida entrenamiento: 0.2745845510679133\nPerdida validación: 0.8322249576449394\nExactitud validación: 18.6261\nÉpoca 295\nPerdida entrenamiento: 0.27191179903114543\nPerdida validación: 0.8544426411390305\nExactitud validación: 18.5130\nÉpoca 296\nPerdida entrenamiento: 0.2718319112763685\nPerdida validación: 0.7973638772964478\nExactitud validación: 18.2870\nÉpoca 297\nPerdida entrenamiento: 0.27322857257197886\nPerdida validación: 0.8390850126743317\nExactitud validación: 18.2870\nÉpoca 298\nPerdida entrenamiento: 0.2706087967928718\nPerdida validación: 0.8332074135541916\nExactitud validación: 18.2870\nÉpoca 299\nPerdida entrenamiento: 0.27064647394068103\nPerdida validación: 0.7855604067444801\nExactitud validación: 18.6261\nÉpoca 300\nPerdida entrenamiento: 0.27028607620912437\nPerdida validación: 0.844075620174408\nExactitud validación: 18.5130\nÉpoca 301\nPerdida entrenamiento: 0.27047083395368915\nPerdida validación: 0.7950586900115013\nExactitud validación: 18.7391\nÉpoca 302\nPerdida entrenamiento: 0.2688707393758437\nPerdida validación: 0.8446274772286415\nExactitud validación: 18.4000\nÉpoca 303\nPerdida entrenamiento: 0.27010226337348714\nPerdida validación: 0.8923372030258179\nExactitud validación: 18.1739\nÉpoca 304\nPerdida entrenamiento: 0.26951658988700194\nPerdida validación: 0.8144352659583092\nExactitud validación: 18.7391\nÉpoca 305\nPerdida entrenamiento: 0.2690744391259025\nPerdida validación: 0.9116105735301971\nExactitud validación: 18.4000\nÉpoca 306\nPerdida entrenamiento: 0.26870520588229685\nPerdida validación: 0.8943951576948166\nExactitud validación: 18.6261\nÉpoca 307\nPerdida entrenamiento: 0.27256863783387575\nPerdida validación: 0.9162701666355133\nExactitud validación: 18.2870\nÉpoca 308\nPerdida entrenamiento: 0.26849985648604\nPerdida validación: 0.8575167655944824\nExactitud validación: 18.1739\nÉpoca 309\nPerdida entrenamiento: 0.2659115265397465\nPerdida validación: 0.8369210362434387\nExactitud validación: 18.9652\nÉpoca 310\nPerdida entrenamiento: 0.26523913004819083\nPerdida validación: 0.8102370351552963\nExactitud validación: 18.5130\nÉpoca 311\nPerdida entrenamiento: 0.26695583322468924\nPerdida validación: 0.8106616139411926\nExactitud validación: 18.5130\nÉpoca 312\nPerdida entrenamiento: 0.26486619518083687\nPerdida validación: 0.862990252673626\nExactitud validación: 18.7391\nÉpoca 313\nPerdida entrenamiento: 0.2670781770173241\nPerdida validación: 0.9409219324588776\nExactitud validación: 18.2870\nÉpoca 314\nPerdida entrenamiento: 0.26387015773969535\nPerdida validación: 0.8297825679183006\nExactitud validación: 18.5130\nÉpoca 315\nPerdida entrenamiento: 0.2630258443600991\nPerdida validación: 0.8401200473308563\nExactitud validación: 18.6261\nÉpoca 316\nPerdida entrenamiento: 0.26609305248540993\nPerdida validación: 0.8802365660667419\nExactitud validación: 18.4000\nÉpoca 317\nPerdida entrenamiento: 0.26455171406269073\nPerdida validación: 0.85386922955513\nExactitud validación: 18.7391\nÉpoca 318\nPerdida entrenamiento: 0.2650342899210313\nPerdida validación: 0.913348600268364\nExactitud validación: 18.6261\nÉpoca 319\nPerdida entrenamiento: 0.2632635078009437\nPerdida validación: 0.8332754224538803\nExactitud validación: 18.6261\nÉpoca 320\nPerdida entrenamiento: 0.2620505313662922\nPerdida validación: 0.8459868878126144\nExactitud validación: 18.1739\nÉpoca 321\nPerdida entrenamiento: 0.2629975974559784\nPerdida validación: 0.96159228682518\nExactitud validación: 18.8522\nÉpoca 322\nPerdida entrenamiento: 0.26157911384806914\nPerdida validación: 0.8396739363670349\nExactitud validación: 18.6261\nÉpoca 323\nPerdida entrenamiento: 0.2618062881862416\nPerdida validación: 0.8706338852643967\nExactitud validación: 18.1739\nÉpoca 324\nPerdida entrenamiento: 0.26290398397866416\nPerdida validación: 0.9644896686077118\nExactitud validación: 18.6261\nÉpoca 325\nPerdida entrenamiento: 0.2609732878558776\nPerdida validación: 0.9126636236906052\nExactitud validación: 18.0609\nÉpoca 326\nPerdida entrenamiento: 0.26105780110639687\nPerdida validación: 0.9232337772846222\nExactitud validación: 18.1739\nÉpoca 327\nPerdida entrenamiento: 0.26264332410167246\nPerdida validación: 0.8974900245666504\nExactitud validación: 18.4000\nÉpoca 328\nPerdida entrenamiento: 0.2613668257699293\nPerdida validación: 0.8862783759832382\nExactitud validación: 18.4000\nÉpoca 329\nPerdida entrenamiento: 0.25836709930616264\nPerdida validación: 0.8626670092344284\nExactitud validación: 18.5130\nÉpoca 330\nPerdida entrenamiento: 0.25922364522429076\nPerdida validación: 0.8830067962408066\nExactitud validación: 18.4000\nÉpoca 331\nPerdida entrenamiento: 0.26386993597535524\nPerdida validación: 0.8540544435381889\nExactitud validación: 18.2870\nÉpoca 332\nPerdida entrenamiento: 0.2593020134988953\nPerdida validación: 0.9039890021085739\nExactitud validación: 18.6261\nÉpoca 333\nPerdida entrenamiento: 0.2595018516568577\nPerdida validación: 0.8899291157722473\nExactitud validación: 17.9478\nÉpoca 334\nPerdida entrenamiento: 0.25665878986611085\nPerdida validación: 0.8394737765192986\nExactitud validación: 18.5130\nÉpoca 335\nPerdida entrenamiento: 0.25748301604214835\nPerdida validación: 0.9290647059679031\nExactitud validación: 18.7391\nÉpoca 336\nPerdida entrenamiento: 0.2590382677667281\nPerdida validación: 0.8649090602993965\nExactitud validación: 18.2870\nÉpoca 337\nPerdida entrenamiento: 0.2554243496235679\nPerdida validación: 0.9593407809734344\nExactitud validación: 18.7391\nÉpoca 338\nPerdida entrenamiento: 0.25691094906891093\nPerdida validación: 0.9706677794456482\nExactitud validación: 18.2870\nÉpoca 339\nPerdida entrenamiento: 0.25731626678915587\nPerdida validación: 0.9453080892562866\nExactitud validación: 18.6261\nÉpoca 340\nPerdida entrenamiento: 0.25507257659645644\nPerdida validación: 1.0293856039643288\nExactitud validación: 18.1739\nÉpoca 341\nPerdida entrenamiento: 0.25653984616784486\nPerdida validación: 0.9515304788947105\nExactitud validación: 18.6261\nÉpoca 342\nPerdida entrenamiento: 0.2530783467433032\nPerdida validación: 0.9056045934557915\nExactitud validación: 18.5130\nÉpoca 343\nPerdida entrenamiento: 0.25274669072207284\nPerdida validación: 0.918601781129837\nExactitud validación: 18.5130\nÉpoca 344\nPerdida entrenamiento: 0.25438859269899483\nPerdida validación: 0.8851798251271248\nExactitud validación: 18.6261\nÉpoca 345\nPerdida entrenamiento: 0.25582583599230824\nPerdida validación: 0.8939363956451416\nExactitud validación: 18.5130\nÉpoca 346\nPerdida entrenamiento: 0.25355858443414464\nPerdida validación: 0.9068932980298996\nExactitud validación: 18.5130\nÉpoca 347\nPerdida entrenamiento: 0.2524866067311343\nPerdida validación: 0.8788146674633026\nExactitud validación: 18.1739\nÉpoca 348\nPerdida entrenamiento: 0.2536166170064141\nPerdida validación: 0.9186953902244568\nExactitud validación: 18.5130\nÉpoca 349\nPerdida entrenamiento: 0.25076256341793957\nPerdida validación: 0.9136313498020172\nExactitud validación: 18.1739\nÉpoca 350\nPerdida entrenamiento: 0.2505396744784187\nPerdida validación: 0.8769859820604324\nExactitud validación: 18.1739\nÉpoca 351\nPerdida entrenamiento: 0.2476857444819282\nPerdida validación: 0.9611544162034988\nExactitud validación: 18.1739\nÉpoca 352\nPerdida entrenamiento: 0.2510046801146339\nPerdida validación: 0.8769300132989883\nExactitud validación: 18.7391\nÉpoca 353\nPerdida entrenamiento: 0.2519538367495817\nPerdida validación: 1.009942501783371\nExactitud validación: 18.6261\nÉpoca 354\nPerdida entrenamiento: 0.25590333780821634\nPerdida validación: 1.0110169053077698\nExactitud validación: 18.4000\nÉpoca 355\nPerdida entrenamiento: 0.24665287882089615\nPerdida validación: 0.963760256767273\nExactitud validación: 18.4000\nÉpoca 356\nPerdida entrenamiento: 0.24831677973270416\nPerdida validación: 0.9520362615585327\nExactitud validación: 18.4000\nÉpoca 357\nPerdida entrenamiento: 0.25036969605614157\nPerdida validación: 0.9705468714237213\nExactitud validación: 18.1739\nÉpoca 358\nPerdida entrenamiento: 0.2493774198433932\nPerdida validación: 0.9390139281749725\nExactitud validación: 18.2870\nÉpoca 359\nPerdida entrenamiento: 0.24896152755793402\nPerdida validación: 0.9668420851230621\nExactitud validación: 18.8522\nÉpoca 360\nPerdida entrenamiento: 0.24545341993079467\nPerdida validación: 0.9598726183176041\nExactitud validación: 18.4000\nÉpoca 361\nPerdida entrenamiento: 0.2458833907456959\nPerdida validación: 0.9334637522697449\nExactitud validación: 18.1739\nÉpoca 362\nPerdida entrenamiento: 0.24675725137486176\nPerdida validación: 0.9621522575616837\nExactitud validación: 18.0609\nÉpoca 363\nPerdida entrenamiento: 0.24821498946231954\nPerdida validación: 0.9556918889284134\nExactitud validación: 18.7391\nÉpoca 364\nPerdida entrenamiento: 0.24909637824577444\nPerdida validación: 0.8772937767207623\nExactitud validación: 18.4000\nÉpoca 365\nPerdida entrenamiento: 0.2441341666614308\nPerdida validación: 0.9345356523990631\nExactitud validación: 18.6261\nÉpoca 366\nPerdida entrenamiento: 0.2470776263405295\nPerdida validación: 1.1278765723109245\nExactitud validación: 18.4000\nÉpoca 367\nPerdida entrenamiento: 0.24338742038782904\nPerdida validación: 0.9173186719417572\nExactitud validación: 18.7391\nÉpoca 368\nPerdida entrenamiento: 0.24587972418350332\nPerdida validación: 0.9912368655204773\nExactitud validación: 18.0609\nÉpoca 369\nPerdida entrenamiento: 0.2427884471767089\nPerdida validación: 0.9538993611931801\nExactitud validación: 18.7391\nÉpoca 370\nPerdida entrenamiento: 0.243407864780987\nPerdida validación: 1.0761137753725052\nExactitud validación: 18.4000\nÉpoca 371\nPerdida entrenamiento: 0.24230772344505086\nPerdida validación: 0.968388170003891\nExactitud validación: 18.6261\nÉpoca 372\nPerdida entrenamiento: 0.2439663826542742\nPerdida validación: 0.9714508131146431\nExactitud validación: 18.6261\nÉpoca 373\nPerdida entrenamiento: 0.24384574592113495\nPerdida validación: 0.9771965891122818\nExactitud validación: 18.4000\nÉpoca 374\nPerdida entrenamiento: 0.24184141614857843\nPerdida validación: 0.9964085817337036\nExactitud validación: 18.4000\nÉpoca 375\nPerdida entrenamiento: 0.24101467518245473\nPerdida validación: 0.9356465041637421\nExactitud validación: 17.9478\nÉpoca 376\nPerdida entrenamiento: 0.24006997969220667\nPerdida validación: 0.9156605526804924\nExactitud validación: 18.0609\nÉpoca 377\nPerdida entrenamiento: 0.23987779985455907\nPerdida validación: 1.0531059503555298\nExactitud validación: 18.2870\nÉpoca 378\nPerdida entrenamiento: 0.24004541951067307\nPerdida validación: 1.0218062326312065\nExactitud validación: 18.6261\nÉpoca 379\nPerdida entrenamiento: 0.23972525666741765\nPerdida validación: 1.0781173408031464\nExactitud validación: 18.4000\nÉpoca 380\nPerdida entrenamiento: 0.23826756415998235\nPerdida validación: 1.0114049911499023\nExactitud validación: 18.2870\nÉpoca 381\nPerdida entrenamiento: 0.24126425473129048\nPerdida validación: 0.9385729283094406\nExactitud validación: 18.2870\nÉpoca 382\nPerdida entrenamiento: 0.23986119557829463\nPerdida validación: 1.0387549847364426\nExactitud validación: 18.5130\nÉpoca 383\nPerdida entrenamiento: 0.2385270192342646\nPerdida validación: 0.9609201848506927\nExactitud validación: 18.6261\nÉpoca 384\nPerdida entrenamiento: 0.23623030238291798\nPerdida validación: 0.9485830962657928\nExactitud validación: 18.9652\nÉpoca 385\nPerdida entrenamiento: 0.2384230853880153\nPerdida validación: 0.9416188150644302\nExactitud validación: 18.4000\nÉpoca 386\nPerdida entrenamiento: 0.23678378015756607\nPerdida validación: 0.9777514040470123\nExactitud validación: 18.5130\nÉpoca 387\nPerdida entrenamiento: 0.2363624467569239\nPerdida validación: 1.0215286016464233\nExactitud validación: 18.7391\nÉpoca 388\nPerdida entrenamiento: 0.23862669660764582\nPerdida validación: 0.9029609151184559\nExactitud validación: 18.1739\nÉpoca 389\nPerdida entrenamiento: 0.23591116070747375\nPerdida validación: 0.981246717274189\nExactitud validación: 18.6261\nÉpoca 390\nPerdida entrenamiento: 0.23835155718466816\nPerdida validación: 1.0086095109581947\nExactitud validación: 18.2870\nÉpoca 391\nPerdida entrenamiento: 0.2371460374663858\nPerdida validación: 1.0065960884094238\nExactitud validación: 18.1739\nÉpoca 392\nPerdida entrenamiento: 0.23677723285029917\nPerdida validación: 0.9826027452945709\nExactitud validación: 18.5130\nÉpoca 393\nPerdida entrenamiento: 0.23566791196079814\nPerdida validación: 1.0341725945472717\nExactitud validación: 18.7391\nÉpoca 394\nPerdida entrenamiento: 0.23627526444547317\nPerdida validación: 1.0409796610474586\nExactitud validación: 18.6261\nÉpoca 395\nPerdida entrenamiento: 0.23617835518191843\nPerdida validación: 1.6217666417360306\nExactitud validación: 18.5130\nÉpoca 396\nPerdida entrenamiento: 0.233415008029517\nPerdida validación: 0.9137831814587116\nExactitud validación: 18.4000\nÉpoca 397\nPerdida entrenamiento: 0.2343826009070172\nPerdida validación: 1.7579079121351242\nExactitud validación: 18.7391\nÉpoca 398\nPerdida entrenamiento: 0.23368020224220612\nPerdida validación: 1.0100515186786652\nExactitud validación: 18.7391\nÉpoca 399\nPerdida entrenamiento: 0.2321076200288885\nPerdida validación: 1.6793339550495148\nExactitud validación: 18.6261\nÉpoca 400\nPerdida entrenamiento: 0.23293223012896144\nPerdida validación: 1.610338568687439\nExactitud validación: 18.6261\nÉpoca 401\nPerdida entrenamiento: 0.23105231278082905\nPerdida validación: 1.6416560858488083\nExactitud validación: 18.4000\nÉpoca 402\nPerdida entrenamiento: 0.23033762372591915\nPerdida validación: 1.66363063454628\nExactitud validación: 18.4000\nÉpoca 403\nPerdida entrenamiento: 0.23017951057237737\nPerdida validación: 1.6514071226119995\nExactitud validación: 18.4000\nÉpoca 404\nPerdida entrenamiento: 0.23135478268651402\nPerdida validación: 1.703551098704338\nExactitud validación: 18.6261\nÉpoca 405\nPerdida entrenamiento: 0.23199564174694173\nPerdida validación: 1.6757195889949799\nExactitud validación: 18.2870\nÉpoca 406\nPerdida entrenamiento: 0.23011183563400717\nPerdida validación: 2.195468708872795\nExactitud validación: 18.5130\nÉpoca 407\nPerdida entrenamiento: 0.2305179115603952\nPerdida validación: 2.174595355987549\nExactitud validación: 18.7391\nÉpoca 408\nPerdida entrenamiento: 0.23433966364930658\nPerdida validación: 1.7009802162647247\nExactitud validación: 18.5130\nÉpoca 409\nPerdida entrenamiento: 0.23122593146913192\nPerdida validación: 1.6614426672458649\nExactitud validación: 18.9652\nÉpoca 410\nPerdida entrenamiento: 0.22980902212507584\nPerdida validación: 1.6923879534006119\nExactitud validación: 18.5130\nÉpoca 411\nPerdida entrenamiento: 0.2278544008731842\nPerdida validación: 1.6532950922846794\nExactitud validación: 18.4000\nÉpoca 412\nPerdida entrenamiento: 0.22777951815549066\nPerdida validación: 1.680533990263939\nExactitud validación: 18.6261\nÉpoca 413\nPerdida entrenamiento: 0.22783642744316773\nPerdida validación: 1.6505683958530426\nExactitud validación: 18.4000\nÉpoca 414\nPerdida entrenamiento: 0.22797440430697272\nPerdida validación: 1.6364076286554337\nExactitud validación: 18.2870\nÉpoca 415\nPerdida entrenamiento: 0.22762182880850398\nPerdida validación: 1.630989708006382\nExactitud validación: 18.2870\nÉpoca 416\nPerdida entrenamiento: 0.227926942793762\nPerdida validación: 1.6618505418300629\nExactitud validación: 18.6261\nÉpoca 417\nPerdida entrenamiento: 0.22629480239223032\nPerdida validación: 1.6968141943216324\nExactitud validación: 18.4000\nÉpoca 418\nPerdida entrenamiento: 0.22488318559001474\nPerdida validación: 1.7578092515468597\nExactitud validación: 18.2870\nÉpoca 419\nPerdida entrenamiento: 0.2263673219610663\nPerdida validación: 1.6131335943937302\nExactitud validación: 18.1739\nÉpoca 420\nPerdida entrenamiento: 0.22987113630070405\nPerdida validación: 1.7163729965686798\nExactitud validación: 18.1739\nÉpoca 421\nPerdida entrenamiento: 0.22674175527165918\nPerdida validación: 1.6752920597791672\nExactitud validación: 18.8522\nÉpoca 422\nPerdida entrenamiento: 0.22827263702364528\nPerdida validación: 1.7154240310192108\nExactitud validación: 18.5130\nÉpoca 423\nPerdida entrenamiento: 0.2220915402559673\nPerdida validación: 1.6310960724949837\nExactitud validación: 18.1739\nÉpoca 424\nPerdida entrenamiento: 0.22505173613043392\nPerdida validación: 1.6115675866603851\nExactitud validación: 18.1739\nÉpoca 425\nPerdida entrenamiento: 0.22220089418046615\nPerdida validación: 2.214143306016922\nExactitud validación: 18.1739\nÉpoca 426\nPerdida entrenamiento: 0.2250201561871697\nPerdida validación: 1.64544016122818\nExactitud validación: 18.1739\nÉpoca 427\nPerdida entrenamiento: 0.22550559876596227\nPerdida validación: 1.6851514726877213\nExactitud validación: 18.7391\nÉpoca 428\nPerdida entrenamiento: 0.22317052457262487\nPerdida validación: 1.7038426101207733\nExactitud validación: 18.7391\nÉpoca 429\nPerdida entrenamiento: 0.22356641993803136\nPerdida validación: 1.710338070988655\nExactitud validación: 18.4000\nÉpoca 430\nPerdida entrenamiento: 0.22142810199190588\nPerdida validación: 1.7483271360397339\nExactitud validación: 18.7391\nÉpoca 431\nPerdida entrenamiento: 0.22034293062546673\nPerdida validación: 1.6430785655975342\nExactitud validación: 18.7391\nÉpoca 432\nPerdida entrenamiento: 0.22316901824053595\nPerdida validación: 1.7672994136810303\nExactitud validación: 18.4000\nÉpoca 433\nPerdida entrenamiento: 0.22463338383856943\nPerdida validación: 1.6433425098657608\nExactitud validación: 18.4000\nÉpoca 434\nPerdida entrenamiento: 0.22231091646587148\nPerdida validación: 1.6801955252885818\nExactitud validación: 18.5130\nÉpoca 435\nPerdida entrenamiento: 0.2208845168352127\nPerdida validación: 1.6813064217567444\nExactitud validación: 18.2870\nÉpoca 436\nPerdida entrenamiento: 0.22095614584053264\nPerdida validación: 1.6760065108537674\nExactitud validación: 18.6261\nÉpoca 437\nPerdida entrenamiento: 0.22033456712961197\nPerdida validación: 1.678830772638321\nExactitud validación: 18.7391\nÉpoca 438\nPerdida entrenamiento: 0.22007577559527228\nPerdida validación: 1.6954376250505447\nExactitud validación: 18.6261\nÉpoca 439\nPerdida entrenamiento: 0.22003603507490718\nPerdida validación: 1.725928619503975\nExactitud validación: 18.8522\nÉpoca 440\nPerdida entrenamiento: 0.22195249708259807\nPerdida validación: 1.8037448972463608\nExactitud validación: 18.5130\nÉpoca 441\nPerdida entrenamiento: 0.21979504736030803\nPerdida validación: 1.6947238594293594\nExactitud validación: 18.1739\nÉpoca 442\nPerdida entrenamiento: 0.21700231205014622\nPerdida validación: 1.7131413221359253\nExactitud validación: 18.5130\nÉpoca 443\nPerdida entrenamiento: 0.21716881061301513\nPerdida validación: 1.7016572207212448\nExactitud validación: 18.2870\nÉpoca 444\nPerdida entrenamiento: 0.21755946778199253\nPerdida validación: 2.2080706506967545\nExactitud validación: 18.4000\nÉpoca 445\nPerdida entrenamiento: 0.21960881308597677\nPerdida validación: 2.2232966125011444\nExactitud validación: 18.2870\nÉpoca 446\nPerdida entrenamiento: 0.2177817536627545\nPerdida validación: 1.674214854836464\nExactitud validación: 18.2870\nÉpoca 447\nPerdida entrenamiento: 0.22076668239691677\nPerdida validación: 1.6826488673686981\nExactitud validación: 18.4000\nÉpoca 448\nPerdida entrenamiento: 0.2175587897791582\nPerdida validación: 1.684437245130539\nExactitud validación: 18.4000\nÉpoca 449\nPerdida entrenamiento: 0.21597974396803798\nPerdida validación: 1.7088166177272797\nExactitud validación: 18.2870\nÉpoca 450\nPerdida entrenamiento: 0.21813132044147043\nPerdida validación: 1.733146995306015\nExactitud validación: 18.1739\nÉpoca 451\nPerdida entrenamiento: 0.21773759976905935\nPerdida validación: 1.6941641122102737\nExactitud validación: 18.2870\nÉpoca 452\nPerdida entrenamiento: 0.21535080583656535\nPerdida validación: 1.76713265478611\nExactitud validación: 18.4000\nÉpoca 453\nPerdida entrenamiento: 0.21499554462292614\nPerdida validación: 1.725937306880951\nExactitud validación: 18.4000\nÉpoca 454\nPerdida entrenamiento: 0.21762167399420457\nPerdida validación: 1.745834544301033\nExactitud validación: 18.4000\nÉpoca 455\nPerdida entrenamiento: 0.21529359852566438\nPerdida validación: 1.7183891236782074\nExactitud validación: 18.6261\nÉpoca 456\nPerdida entrenamiento: 0.21322160959243774\nPerdida validación: 1.665738008916378\nExactitud validación: 18.5130\nÉpoca 457\nPerdida entrenamiento: 0.21297074021661982\nPerdida validación: 1.6415093056857586\nExactitud validación: 18.1739\nÉpoca 458\nPerdida entrenamiento: 0.2120342228342505\nPerdida validación: 1.6675629317760468\nExactitud validación: 18.5130\nÉpoca 459\nPerdida entrenamiento: 0.21290872377507827\nPerdida validación: 1.7062142491340637\nExactitud validación: 18.1739\nÉpoca 460\nPerdida entrenamiento: 0.2155881883466945\nPerdida validación: 1.6664244383573532\nExactitud validación: 18.6261\nÉpoca 461\nPerdida entrenamiento: 0.2123072870513972\nPerdida validación: 1.6892398595809937\nExactitud validación: 18.1739\nÉpoca 462\nPerdida entrenamiento: 0.21215057285392985\nPerdida validación: 1.71298286318779\nExactitud validación: 18.5130\nÉpoca 463\nPerdida entrenamiento: 0.2131307668545667\nPerdida validación: 2.3371381908655167\nExactitud validación: 18.4000\nÉpoca 464\nPerdida entrenamiento: 0.21063883252003612\nPerdida validación: 1.6871272176504135\nExactitud validación: 18.4000\nÉpoca 465\nPerdida entrenamiento: 0.21041779746027553\nPerdida validación: 1.7584034204483032\nExactitud validación: 18.8522\nÉpoca 466\nPerdida entrenamiento: 0.20908518573817084\nPerdida validación: 1.7399623692035675\nExactitud validación: 18.2870\nÉpoca 467\nPerdida entrenamiento: 0.20974228049025817\nPerdida validación: 1.7392813563346863\nExactitud validación: 18.0609\nÉpoca 468\nPerdida entrenamiento: 0.20860017222516677\nPerdida validación: 1.7459359467029572\nExactitud validación: 18.6261\nÉpoca 469\nPerdida entrenamiento: 0.20901529490947723\nPerdida validación: 1.6576770320534706\nExactitud validación: 18.2870\nÉpoca 470\nPerdida entrenamiento: 0.20985684850636652\nPerdida validación: 1.6809408068656921\nExactitud validación: 17.8348\nÉpoca 471\nPerdida entrenamiento: 0.20888636611840306\nPerdida validación: 1.7095791101455688\nExactitud validación: 18.4000\nÉpoca 472\nPerdida entrenamiento: 0.20915422983029308\nPerdida validación: 1.735638752579689\nExactitud validación: 18.6261\nÉpoca 473\nPerdida entrenamiento: 0.21087617295629837\nPerdida validación: 2.223282590508461\nExactitud validación: 18.8522\nÉpoca 474\nPerdida entrenamiento: 0.21059176501105814\nPerdida validación: 2.2696365863084793\nExactitud validación: 18.4000\nÉpoca 475\nPerdida entrenamiento: 0.20993135518887462\nPerdida validación: 2.3144669383764267\nExactitud validación: 18.4000\nÉpoca 476\nPerdida entrenamiento: 0.2069975641720435\nPerdida validación: 1.7147362232208252\nExactitud validación: 17.9478\nÉpoca 477\nPerdida entrenamiento: 0.20739179674316854\nPerdida validación: 1.7762307822704315\nExactitud validación: 18.4000\nÉpoca 478\nPerdida entrenamiento: 0.20736681187854095\nPerdida validación: 1.7321285605430603\nExactitud validación: 18.7391\nÉpoca 479\nPerdida entrenamiento: 0.20850269627921722\nPerdida validación: 1.7248305529356003\nExactitud validación: 18.5130\nÉpoca 480\nPerdida entrenamiento: 0.20808968561537125\nPerdida validación: 1.6793062910437584\nExactitud validación: 18.5130\nÉpoca 481\nPerdida entrenamiento: 0.2063585151644314\nPerdida validación: 2.3160250037908554\nExactitud validación: 18.4000\nÉpoca 482\nPerdida entrenamiento: 0.20922441298470779\nPerdida validación: 1.7382783144712448\nExactitud validación: 18.7391\nÉpoca 483\nPerdida entrenamiento: 0.2089783260050942\nPerdida validación: 1.675756473094225\nExactitud validación: 18.2870\nÉpoca 484\nPerdida entrenamiento: 0.20955036317600922\nPerdida validación: 1.7968875467777252\nExactitud validación: 18.5130\nÉpoca 485\nPerdida entrenamiento: 0.20719658802537358\nPerdida validación: 2.281432792544365\nExactitud validación: 18.2870\nÉpoca 486\nPerdida entrenamiento: 0.20671694988713546\nPerdida validación: 2.290306895971298\nExactitud validación: 18.5130\nÉpoca 487\nPerdida entrenamiento: 0.20706017490695505\nPerdida validación: 1.7116160094738007\nExactitud validación: 18.4000\nÉpoca 488\nPerdida entrenamiento: 0.20524413971339955\nPerdida validación: 1.8093033283948898\nExactitud validación: 18.5130\nÉpoca 489\nPerdida entrenamiento: 0.2051747401847559\nPerdida validación: 1.7765755355358124\nExactitud validación: 18.6261\nÉpoca 490\nPerdida entrenamiento: 0.20630764128530726\nPerdida validación: 1.7870673686265945\nExactitud validación: 18.2870\nÉpoca 491\nPerdida entrenamiento: 0.20644442780929453\nPerdida validación: 2.2809912860393524\nExactitud validación: 18.5130\nÉpoca 492\nPerdida entrenamiento: 0.2057285668218837\nPerdida validación: 2.258572533726692\nExactitud validación: 17.8348\nÉpoca 493\nPerdida entrenamiento: 0.2029068154447219\nPerdida validación: 1.6803431659936905\nExactitud validación: 18.7391\nÉpoca 494\nPerdida entrenamiento: 0.2028874272809309\nPerdida validación: 1.8127751350402832\nExactitud validación: 18.7391\nÉpoca 495\nPerdida entrenamiento: 0.2052424208206289\nPerdida validación: 1.7849414199590683\nExactitud validación: 18.7391\nÉpoca 496\nPerdida entrenamiento: 0.20392162791069815\nPerdida validación: 1.7237890660762787\nExactitud validación: 18.4000\nÉpoca 497\nPerdida entrenamiento: 0.20092843429130666\nPerdida validación: 2.2871531173586845\nExactitud validación: 18.6261\nÉpoca 498\nPerdida entrenamiento: 0.20234436278834061\nPerdida validación: 2.2854884639382362\nExactitud validación: 18.2870\nÉpoca 499\nPerdida entrenamiento: 0.20332733541727066\nPerdida validación: 1.7827043235301971\nExactitud validación: 18.6261\nÉpoca 500\nPerdida entrenamiento: 0.20469026092220755\nPerdida validación: 2.3745395615696907\nExactitud validación: 18.5130\nÉpoca 501\nPerdida entrenamiento: 0.20449996783452876\nPerdida validación: 1.7906746417284012\nExactitud validación: 18.6261\nÉpoca 502\nPerdida entrenamiento: 0.20517864034456365\nPerdida validación: 1.732749417424202\nExactitud validación: 18.5130\nÉpoca 503\nPerdida entrenamiento: 0.20195804273380952\nPerdida validación: 2.2683166712522507\nExactitud validación: 18.5130\nÉpoca 504\nPerdida entrenamiento: 0.2007514510084601\nPerdida validación: 1.7528420686721802\nExactitud validación: 18.4000\nÉpoca 505\nPerdida entrenamiento: 0.2026394693290486\nPerdida validación: 1.7850606441497803\nExactitud validación: 18.4000\nÉpoca 506\nPerdida entrenamiento: 0.20051894775208304\nPerdida validación: 1.7376345694065094\nExactitud validación: 18.5130\nÉpoca 507\nPerdida entrenamiento: 0.1994068114196553\nPerdida validación: 1.813426986336708\nExactitud validación: 18.2870\nÉpoca 508\nPerdida entrenamiento: 0.20079496415222392\nPerdida validación: 2.327720493078232\nExactitud validación: 18.2870\nÉpoca 509\nPerdida entrenamiento: 0.20256532158921747\nPerdida validación: 1.7458709627389908\nExactitud validación: 18.4000\nÉpoca 510\nPerdida entrenamiento: 0.20124467067858753\nPerdida validación: 1.7705589160323143\nExactitud validación: 18.5130\nÉpoca 511\nPerdida entrenamiento: 0.19941148468676737\nPerdida validación: 1.796208769083023\nExactitud validación: 18.4000\nÉpoca 512\nPerdida entrenamiento: 0.19882883394465728\nPerdida validación: 1.749910831451416\nExactitud validación: 18.4000\nÉpoca 513\nPerdida entrenamiento: 0.2000570288475822\nPerdida validación: 1.796690434217453\nExactitud validación: 18.5130\nÉpoca 514\nPerdida entrenamiento: 0.19875034295460758\nPerdida validación: 1.7634713500738144\nExactitud validación: 18.4000\nÉpoca 515\nPerdida entrenamiento: 0.19847256471129024\nPerdida validación: 1.7303752601146698\nExactitud validación: 18.2870\nÉpoca 516\nPerdida entrenamiento: 0.19714518767945907\nPerdida validación: 1.7873051464557648\nExactitud validación: 18.7391\nÉpoca 517\nPerdida entrenamiento: 0.19987665379748626\nPerdida validación: 2.3726578801870346\nExactitud validación: 18.0609\nÉpoca 518\nPerdida entrenamiento: 0.19713971062618144\nPerdida validación: 1.8600481450557709\nExactitud validación: 18.6261\nÉpoca 519\nPerdida entrenamiento: 0.19719707089311936\nPerdida validación: 1.7947774976491928\nExactitud validación: 18.5130\nÉpoca 520\nPerdida entrenamiento: 0.19800057525143905\nPerdida validación: 1.8386373445391655\nExactitud validación: 18.4000\nÉpoca 521\nPerdida entrenamiento: 0.19503561845597098\nPerdida validación: 1.86511692404747\nExactitud validación: 18.0609\nÉpoca 522\nPerdida entrenamiento: 0.19703502164167516\nPerdida validación: 2.2786576449871063\nExactitud validación: 18.7391\nÉpoca 523\nPerdida entrenamiento: 0.1965047695180949\nPerdida validación: 1.7550715208053589\nExactitud validación: 18.5130\nÉpoca 524\nPerdida entrenamiento: 0.19743618281448588\nPerdida validación: 1.7788794338703156\nExactitud validación: 18.4000\nÉpoca 525\nPerdida entrenamiento: 0.19581336571889765\nPerdida validación: 2.3412183597683907\nExactitud validación: 18.6261\nÉpoca 526\nPerdida entrenamiento: 0.19735115065294154\nPerdida validación: 1.7944573611021042\nExactitud validación: 18.5130\nÉpoca 527\nPerdida entrenamiento: 0.1972572623806841\nPerdida validación: 1.7847600281238556\nExactitud validación: 18.4000\nÉpoca 528\nPerdida entrenamiento: 0.19613027397324057\nPerdida validación: 1.8530294448137283\nExactitud validación: 18.2870\nÉpoca 529\nPerdida entrenamiento: 0.19604966395041523\nPerdida validación: 1.8482124507427216\nExactitud validación: 18.6261\nÉpoca 530\nPerdida entrenamiento: 0.19563549099599614\nPerdida validación: 1.7713856101036072\nExactitud validación: 18.6261\nÉpoca 531\nPerdida entrenamiento: 0.1955263259656289\nPerdida validación: 1.8069935888051987\nExactitud validación: 17.9478\nÉpoca 532\nPerdida entrenamiento: 0.19411977774956646\nPerdida validación: 1.8041860908269882\nExactitud validación: 18.6261\nÉpoca 533\nPerdida entrenamiento: 0.1945977715008399\nPerdida validación: 1.825106680393219\nExactitud validación: 18.2870\nÉpoca 534\nPerdida entrenamiento: 0.1952920450883753\nPerdida validación: 2.3135114312171936\nExactitud validación: 18.6261\nÉpoca 535\nPerdida entrenamiento: 0.19248855683733435\nPerdida validación: 1.8990767300128937\nExactitud validación: 18.4000\nÉpoca 536\nPerdida entrenamiento: 0.19831059960757985\nPerdida validación: 1.80620726197958\nExactitud validación: 18.2870\nÉpoca 537\nPerdida entrenamiento: 0.1929608224069371\nPerdida validación: 1.7912742048501968\nExactitud validación: 18.4000\nÉpoca 538\nPerdida entrenamiento: 0.19296798898893244\nPerdida validación: 1.7543442994356155\nExactitud validación: 18.1739\nÉpoca 539\nPerdida entrenamiento: 0.1950954786118339\nPerdida validación: 1.8118992149829865\nExactitud validación: 18.4000\nÉpoca 540\nPerdida entrenamiento: 0.1945850323228275\nPerdida validación: 1.8098999336361885\nExactitud validación: 18.2870\nÉpoca 541\nPerdida entrenamiento: 0.19389351413530462\nPerdida validación: 2.289820373058319\nExactitud validación: 18.2870\nÉpoca 542\nPerdida entrenamiento: 0.19105484468095443\nPerdida validación: 1.794912725687027\nExactitud validación: 18.0609\nÉpoca 543\nPerdida entrenamiento: 0.19384890005869024\nPerdida validación: 1.875189632177353\nExactitud validación: 18.1739\nÉpoca 544\nPerdida entrenamiento: 0.19117492963286006\nPerdida validación: 1.809283822774887\nExactitud validación: 18.4000\nÉpoca 545\nPerdida entrenamiento: 0.19236618893987992\nPerdida validación: 2.2911151945590973\nExactitud validación: 18.6261\nÉpoca 546\nPerdida entrenamiento: 0.19125396495356278\nPerdida validación: 1.7524409666657448\nExactitud validación: 18.5130\nÉpoca 547\nPerdida entrenamiento: 0.19026901047019398\nPerdida validación: 1.8327823728322983\nExactitud validación: 18.4000\nÉpoca 548\nPerdida entrenamiento: 0.1921607873895589\nPerdida validación: 2.307979680597782\nExactitud validación: 18.2870\nÉpoca 549\nPerdida entrenamiento: 0.19157351816401763\nPerdida validación: 1.8872595876455307\nExactitud validación: 18.4000\nÉpoca 550\nPerdida entrenamiento: 0.19094288480632446\nPerdida validación: 1.9153790324926376\nExactitud validación: 18.6261\nÉpoca 551\nPerdida entrenamiento: 0.19048834592103958\nPerdida validación: 1.7659415304660797\nExactitud validación: 18.5130\nÉpoca 552\nPerdida entrenamiento: 0.19038300785948248\nPerdida validación: 1.7611987218260765\nExactitud validación: 18.4000\nÉpoca 553\nPerdida entrenamiento: 0.18965064383604946\nPerdida validación: 1.871100902557373\nExactitud validación: 18.2870\nÉpoca 554\nPerdida entrenamiento: 0.19062230779844172\nPerdida validación: 1.8860596120357513\nExactitud validación: 18.2870\nÉpoca 555\nPerdida entrenamiento: 0.18969056185554056\nPerdida validación: 2.3548885583877563\nExactitud validación: 18.0609\nÉpoca 556\nPerdida entrenamiento: 0.18985140696167946\nPerdida validación: 2.386777237057686\nExactitud validación: 18.5130\nÉpoca 557\nPerdida entrenamiento: 0.19206796192071018\nPerdida validación: 1.804469645023346\nExactitud validación: 18.2870\nÉpoca 558\nPerdida entrenamiento: 0.1930651068687439\nPerdida validación: 1.8630142956972122\nExactitud validación: 18.4000\nÉpoca 559\nPerdida entrenamiento: 0.1930370124823907\nPerdida validación: 1.7798155397176743\nExactitud validación: 18.4000\nÉpoca 560\nPerdida entrenamiento: 0.1902738498414264\nPerdida validación: 1.8318945318460464\nExactitud validación: 18.4000\nÉpoca 561\nPerdida entrenamiento: 0.19049055655212963\nPerdida validación: 1.7881848067045212\nExactitud validación: 18.4000\nÉpoca 562\nPerdida entrenamiento: 0.18791185231769786\nPerdida validación: 1.8009058833122253\nExactitud validación: 18.7391\nÉpoca 563\nPerdida entrenamiento: 0.18878159409060197\nPerdida validación: 2.3612941056489944\nExactitud validación: 18.2870\nÉpoca 564\nPerdida entrenamiento: 0.18708483611836152\nPerdida validación: 1.795827567577362\nExactitud validación: 18.6261\nÉpoca 565\nPerdida entrenamiento: 0.18627881477860844\nPerdida validación: 1.8481564670801163\nExactitud validación: 18.5130\nÉpoca 566\nPerdida entrenamiento: 0.18686316863578908\nPerdida validación: 1.8827480152249336\nExactitud validación: 18.5130\nÉpoca 567\nPerdida entrenamiento: 0.18734496525105307\nPerdida validación: 2.437557488679886\nExactitud validación: 18.6261\nÉpoca 568\nPerdida entrenamiento: 0.18700052578659618\nPerdida validación: 1.8809164464473724\nExactitud validación: 18.6261\nÉpoca 569\nPerdida entrenamiento: 0.1859943498583401\nPerdida validación: 2.3979000598192215\nExactitud validación: 18.5130\nÉpoca 570\nPerdida entrenamiento: 0.1867598135243444\nPerdida validación: 2.401433676481247\nExactitud validación: 18.4000\nÉpoca 571\nPerdida entrenamiento: 0.18641008743468454\nPerdida validación: 1.8099213689565659\nExactitud validación: 18.4000\nÉpoca 572\nPerdida entrenamiento: 0.1878149176345152\nPerdida validación: 1.8095275163650513\nExactitud validación: 18.7391\nÉpoca 573\nPerdida entrenamiento: 0.1844573288279421\nPerdida validación: 1.815418690443039\nExactitud validación: 18.4000\nÉpoca 574\nPerdida entrenamiento: 0.18568310711313696\nPerdida validación: 1.7979236990213394\nExactitud validación: 18.5130\nÉpoca 575\nPerdida entrenamiento: 0.1849901847103063\nPerdida validación: 1.8825554847717285\nExactitud validación: 18.4000\nÉpoca 576\nPerdida entrenamiento: 0.18612053245306015\nPerdida validación: 1.80270117521286\nExactitud validación: 18.4000\nÉpoca 577\nPerdida entrenamiento: 0.1876081745414173\nPerdida validación: 1.8711232542991638\nExactitud validación: 18.2870\nÉpoca 578\nPerdida entrenamiento: 0.18576577305793762\nPerdida validación: 1.908687710762024\nExactitud validación: 18.2870\nÉpoca 579\nPerdida entrenamiento: 0.18641850834383683\nPerdida validación: 1.86570705473423\nExactitud validación: 17.9478\nÉpoca 580\nPerdida entrenamiento: 0.1835003499599064\nPerdida validación: 1.8697331100702286\nExactitud validación: 18.6261\nÉpoca 581\nPerdida entrenamiento: 0.18529456985347412\nPerdida validación: 1.7919117659330368\nExactitud validación: 18.2870\nÉpoca 582\nPerdida entrenamiento: 0.1841503298457931\nPerdida validación: 2.4412302374839783\nExactitud validación: 18.7391\nÉpoca 583\nPerdida entrenamiento: 0.18371729158303318\nPerdida validación: 1.8544679284095764\nExactitud validación: 18.8522\nÉpoca 584\nPerdida entrenamiento: 0.18499108140959458\nPerdida validación: 1.8232229053974152\nExactitud validación: 18.5130\nÉpoca 585\nPerdida entrenamiento: 0.1860760952181676\nPerdida validación: 1.841095194220543\nExactitud validación: 18.5130\nÉpoca 586\nPerdida entrenamiento: 0.18593923703712575\nPerdida validación: 1.8760543167591095\nExactitud validación: 18.5130\nÉpoca 587\nPerdida entrenamiento: 0.18209941509891958\nPerdida validación: 1.9005913734436035\nExactitud validación: 18.5130\nÉpoca 588\nPerdida entrenamiento: 0.18258259160553708\nPerdida validación: 1.858061134815216\nExactitud validación: 18.6261\nÉpoca 589\nPerdida entrenamiento: 0.18598782183492885\nPerdida validación: 2.420540153980255\nExactitud validación: 18.2870\nÉpoca 590\nPerdida entrenamiento: 0.1828598489656168\nPerdida validación: 1.8328881710767746\nExactitud validación: 18.6261\nÉpoca 591\nPerdida entrenamiento: 0.1841830584932776\nPerdida validación: 1.8384827971458435\nExactitud validación: 18.5130\nÉpoca 592\nPerdida entrenamiento: 0.1838392247171963\nPerdida validación: 2.3826200664043427\nExactitud validación: 18.6261\nÉpoca 593\nPerdida entrenamiento: 0.18054470770499287\nPerdida validación: 2.3773992508649826\nExactitud validación: 18.7391\nÉpoca 594\nPerdida entrenamiento: 0.18052921707139297\nPerdida validación: 1.9906710982322693\nExactitud validación: 18.0609\nÉpoca 595\nPerdida entrenamiento: 0.18146830621887655\nPerdida validación: 2.434752732515335\nExactitud validación: 18.5130\nÉpoca 596\nPerdida entrenamiento: 0.17948470089365454\nPerdida validación: 1.852248728275299\nExactitud validación: 18.7391\nÉpoca 597\nPerdida entrenamiento: 0.17860462297411525\nPerdida validación: 2.346190959215164\nExactitud validación: 18.5130\nÉpoca 598\nPerdida entrenamiento: 0.18151379288995967\nPerdida validación: 1.9093308448791504\nExactitud validación: 18.5130\nÉpoca 599\nPerdida entrenamiento: 0.17953513781814015\nPerdida validación: 1.927807793021202\nExactitud validación: 18.6261\nÉpoca 600\nPerdida entrenamiento: 0.18134287832414403\nPerdida validación: 1.8202008605003357\nExactitud validación: 17.9478\nÉpoca 601\nPerdida entrenamiento: 0.18065105510108612\nPerdida validación: 2.4191258996725082\nExactitud validación: 18.0609\nÉpoca 602\nPerdida entrenamiento: 0.17909427337786732\nPerdida validación: 2.3444060534238815\nExactitud validación: 17.9478\nÉpoca 603\nPerdida entrenamiento: 0.1807249688050326\nPerdida validación: 1.859527364373207\nExactitud validación: 18.6261\nÉpoca 604\nPerdida entrenamiento: 0.17981747581678278\nPerdida validación: 1.8991383910179138\nExactitud validación: 18.4000\nÉpoca 605\nPerdida entrenamiento: 0.18046181123046315\nPerdida validación: 1.9196833372116089\nExactitud validación: 18.2870\nÉpoca 606\nPerdida entrenamiento: 0.17735964761060827\nPerdida validación: 1.8872027397155762\nExactitud validación: 18.4000\nÉpoca 607\nPerdida entrenamiento: 0.17956263265189001\nPerdida validación: 1.8883287459611893\nExactitud validación: 18.2870\nÉpoca 608\nPerdida entrenamiento: 0.17843612239641302\nPerdida validación: 2.382715880870819\nExactitud validación: 18.2870\nÉpoca 609\nPerdida entrenamiento: 0.17757347269969828\nPerdida validación: 1.932212918996811\nExactitud validación: 18.6261\nÉpoca 610\nPerdida entrenamiento: 0.1786287356825436\nPerdida validación: 1.9283054769039154\nExactitud validación: 18.4000\nÉpoca 611\nPerdida entrenamiento: 0.17991680958691766\nPerdida validación: 2.5501490607857704\nExactitud validación: 18.2870\nÉpoca 612\nPerdida entrenamiento: 0.18011304056819746\nPerdida validación: 1.7971415668725967\nExactitud validación: 18.4000\nÉpoca 613\nPerdida entrenamiento: 0.17593874650843003\nPerdida validación: 2.426175683736801\nExactitud validación: 18.4000\nÉpoca 614\nPerdida entrenamiento: 0.17618215829133987\nPerdida validación: 2.452900141477585\nExactitud validación: 18.5130\nÉpoca 615\nPerdida entrenamiento: 0.17730087129508748\nPerdida validación: 1.8392793536186218\nExactitud validación: 18.5130\nÉpoca 616\nPerdida entrenamiento: 0.1800769615699263\nPerdida validación: 1.9838367700576782\nExactitud validación: 18.8522\nÉpoca 617\nPerdida entrenamiento: 0.17642011405790553\nPerdida validación: 1.9059662222862244\nExactitud validación: 18.7391\nÉpoca 618\nPerdida entrenamiento: 0.17710689542924657\nPerdida validación: 1.862879142165184\nExactitud validación: 18.5130\nÉpoca 619\nPerdida entrenamiento: 0.17686956814106772\nPerdida validación: 1.8814306408166885\nExactitud validación: 18.4000\nÉpoca 620\nPerdida entrenamiento: 0.17600232581881917\nPerdida validación: 1.8020828627049923\nExactitud validación: 18.1739\nÉpoca 621\nPerdida entrenamiento: 0.17544799276134548\nPerdida validación: 1.811521127820015\nExactitud validación: 18.6261\nÉpoca 622\nPerdida entrenamiento: 0.17697353485752554\nPerdida validación: 1.877358078956604\nExactitud validación: 18.5130\nÉpoca 623\nPerdida entrenamiento: 0.17406106301966837\nPerdida validación: 1.8654315024614334\nExactitud validación: 18.1739\nÉpoca 624\nPerdida entrenamiento: 0.17648298687794628\nPerdida validación: 1.8686436414718628\nExactitud validación: 18.5130\nÉpoca 625\nPerdida entrenamiento: 0.17434970179901405\nPerdida validación: 1.919616162776947\nExactitud validación: 18.9652\nÉpoca 626\nPerdida entrenamiento: 0.17567084598190644\nPerdida validación: 1.9153682887554169\nExactitud validación: 18.0609\nÉpoca 627\nPerdida entrenamiento: 0.17896952392423854\nPerdida validación: 1.8582693189382553\nExactitud validación: 18.0609\nÉpoca 628\nPerdida entrenamiento: 0.17745003915008375\nPerdida validación: 1.9257307648658752\nExactitud validación: 18.5130\nÉpoca 629\nPerdida entrenamiento: 0.1788088896257036\nPerdida validación: 1.931223213672638\nExactitud validación: 18.5130\nÉpoca 630\nPerdida entrenamiento: 0.17631110548973083\nPerdida validación: 2.3573699593544006\nExactitud validación: 18.6261\nÉpoca 631\nPerdida entrenamiento: 0.17479468860170422\nPerdida validación: 1.9445046782493591\nExactitud validación: 18.6261\nÉpoca 632\nPerdida entrenamiento: 0.1756579818971017\nPerdida validación: 1.973215788602829\nExactitud validación: 18.1739\nÉpoca 633\nPerdida entrenamiento: 0.17561784189413576\nPerdida validación: 1.9100207686424255\nExactitud validación: 18.8522\nÉpoca 634\nPerdida entrenamiento: 0.1757204962127349\nPerdida validación: 1.939280390739441\nExactitud validación: 18.1739\nÉpoca 635\nPerdida entrenamiento: 0.17755503207445145\nPerdida validación: 1.981196641921997\nExactitud validación: 18.5130\nÉpoca 636\nPerdida entrenamiento: 0.17460980178678737\nPerdida validación: 1.9405174255371094\nExactitud validación: 18.4000\nÉpoca 637\nPerdida entrenamiento: 0.17348291571525967\nPerdida validación: 1.8273062705993652\nExactitud validación: 18.4000\nÉpoca 638\nPerdida entrenamiento: 0.1731029485954958\nPerdida validación: 2.380571126937866\nExactitud validación: 18.0609\nÉpoca 639\nPerdida entrenamiento: 0.17311051268787944\nPerdida validación: 2.059565246105194\nExactitud validación: 18.4000\nÉpoca 640\nPerdida entrenamiento: 0.17420342915198384\nPerdida validación: 1.9567348062992096\nExactitud validación: 18.6261\nÉpoca 641\nPerdida entrenamiento: 0.17315113938906612\nPerdida validación: 1.9034782350063324\nExactitud validación: 18.5130\nÉpoca 642\nPerdida entrenamiento: 0.1723686158657074\nPerdida validación: 1.9813492596149445\nExactitud validación: 18.5130\nÉpoca 643\nPerdida entrenamiento: 0.1716386500526877\nPerdida validación: 1.9668281972408295\nExactitud validación: 18.4000\nÉpoca 644\nPerdida entrenamiento: 0.17454188360887415\nPerdida validación: 2.3830559104681015\nExactitud validación: 18.2870\nÉpoca 645\nPerdida entrenamiento: 0.17409280687570572\nPerdida validación: 1.8761438131332397\nExactitud validación: 18.1739\nÉpoca 646\nPerdida entrenamiento: 0.17281085559550455\nPerdida validación: 1.8756016343832016\nExactitud validación: 18.4000\nÉpoca 647\nPerdida entrenamiento: 0.17153984615031412\nPerdida validación: 1.9308282732963562\nExactitud validación: 18.7391\nÉpoca 648\nPerdida entrenamiento: 0.17411951852195404\nPerdida validación: 1.8359106853604317\nExactitud validación: 17.8348\nÉpoca 649\nPerdida entrenamiento: 0.17255713790655136\nPerdida validación: 1.8988316506147385\nExactitud validación: 18.5130\nÉpoca 650\nPerdida entrenamiento: 0.17018533541875727\nPerdida validación: 1.949387177824974\nExactitud validación: 18.6261\nÉpoca 651\nPerdida entrenamiento: 0.17180895630051107\nPerdida validación: 1.9061071127653122\nExactitud validación: 18.5130\nÉpoca 652\nPerdida entrenamiento: 0.1712561582817751\nPerdida validación: 1.9416884183883667\nExactitud validación: 18.9652\nÉpoca 653\nPerdida entrenamiento: 0.17215262353420258\nPerdida validación: 1.8685024976730347\nExactitud validación: 18.8522\nÉpoca 654\nPerdida entrenamiento: 0.16887790841214798\nPerdida validación: 1.8882263749837875\nExactitud validación: 18.2870\nÉpoca 655\nPerdida entrenamiento: 0.17128623868612683\nPerdida validación: 2.458386555314064\nExactitud validación: 18.1739\nÉpoca 656\nPerdida entrenamiento: 0.170212522149086\nPerdida validación: 1.954999327659607\nExactitud validación: 18.5130\nÉpoca 657\nPerdida entrenamiento: 0.1741621494293213\nPerdida validación: 1.9523300230503082\nExactitud validación: 18.5130\nÉpoca 658\nPerdida entrenamiento: 0.17083424548892415\nPerdida validación: 1.959117352962494\nExactitud validación: 18.7391\nÉpoca 659\nPerdida entrenamiento: 0.16970867137698567\nPerdida validación: 1.8965559303760529\nExactitud validación: 18.4000\nÉpoca 660\nPerdida entrenamiento: 0.16913258941734538\nPerdida validación: 1.9195391535758972\nExactitud validación: 18.2870\nÉpoca 661\nPerdida entrenamiento: 0.16958869686898062\nPerdida validación: 2.4342183619737625\nExactitud validación: 17.7217\nÉpoca 662\nPerdida entrenamiento: 0.1689609788796481\nPerdida validación: 1.990819126367569\nExactitud validación: 18.6261\nÉpoca 663\nPerdida entrenamiento: 0.17155426433857748\nPerdida validación: 2.4798940420150757\nExactitud validación: 18.6261\nÉpoca 664\nPerdida entrenamiento: 0.17054487940143137\nPerdida validación: 1.982157289981842\nExactitud validación: 18.5130\nÉpoca 665\nPerdida entrenamiento: 0.16904305841992884\nPerdida validación: 1.8254309445619583\nExactitud validación: 18.4000\nÉpoca 666\nPerdida entrenamiento: 0.16776984053499558\nPerdida validación: 1.9470479041337967\nExactitud validación: 18.6261\nÉpoca 667\nPerdida entrenamiento: 0.16710532982559764\nPerdida validación: 2.491328239440918\nExactitud validación: 18.8522\nÉpoca 668\nPerdida entrenamiento: 0.16992384808904984\nPerdida validación: 1.9949734210968018\nExactitud validación: 18.7391\nÉpoca 669\nPerdida entrenamiento: 0.16685624595950632\nPerdida validación: 1.8857195228338242\nExactitud validación: 18.4000\nÉpoca 670\nPerdida entrenamiento: 0.16876719979678884\nPerdida validación: 1.880652368068695\nExactitud validación: 18.8522\nÉpoca 671\nPerdida entrenamiento: 0.1676985665279276\nPerdida validación: 1.9278014451265335\nExactitud validación: 18.0609\nÉpoca 672\nPerdida entrenamiento: 0.1676903353894458\nPerdida validación: 1.950418546795845\nExactitud validación: 18.6261\nÉpoca 673\nPerdida entrenamiento: 0.1701295621254865\nPerdida validación: 1.8648300468921661\nExactitud validación: 17.9478\nÉpoca 674\nPerdida entrenamiento: 0.17001822459347107\nPerdida validación: 1.8509264029562473\nExactitud validación: 18.1739\nÉpoca 675\nPerdida entrenamiento: 0.16711394970907884\nPerdida validación: 1.954179808497429\nExactitud validación: 18.5130\nÉpoca 676\nPerdida entrenamiento: 0.16708773023941936\nPerdida validación: 1.924515724182129\nExactitud validación: 18.2870\nÉpoca 677\nPerdida entrenamiento: 0.16858496648423812\nPerdida validación: 2.000500962138176\nExactitud validación: 18.4000\nÉpoca 678\nPerdida entrenamiento: 0.16450631793807535\nPerdida validación: 2.566338747739792\nExactitud validación: 18.2870\nÉpoca 679\nPerdida entrenamiento: 0.16761167566565907\nPerdida validación: 2.0148858428001404\nExactitud validación: 18.4000\nÉpoca 680\nPerdida entrenamiento: 0.16833147757193623\nPerdida validación: 2.074228048324585\nExactitud validación: 18.6261\nÉpoca 681\nPerdida entrenamiento: 0.16532384385080898\nPerdida validación: 1.9695260673761368\nExactitud validación: 18.6261\nÉpoca 682\nPerdida entrenamiento: 0.16553058124640407\nPerdida validación: 1.9510675370693207\nExactitud validación: 18.4000\nÉpoca 683\nPerdida entrenamiento: 0.16487656051621719\nPerdida validación: 2.4368354082107544\nExactitud validación: 18.0609\nÉpoca 684\nPerdida entrenamiento: 0.1665136836030904\nPerdida validación: 1.9446289241313934\nExactitud validación: 18.6261\nÉpoca 685\nPerdida entrenamiento: 0.16706801074392655\nPerdida validación: 2.0074078142642975\nExactitud validación: 18.2870\nÉpoca 686\nPerdida entrenamiento: 0.16774573746849508\nPerdida validación: 1.9531133472919464\nExactitud validación: 18.2870\nÉpoca 687\nPerdida entrenamiento: 0.1662634378846954\nPerdida validación: 1.9650149643421173\nExactitud validación: 18.1739\nÉpoca 688\nPerdida entrenamiento: 0.165897518834647\nPerdida validación: 1.9263443648815155\nExactitud validación: 18.5130\nÉpoca 689\nPerdida entrenamiento: 0.16783844898728764\nPerdida validación: 2.5158949941396713\nExactitud validación: 18.1739\nÉpoca 690\nPerdida entrenamiento: 0.1632937078966814\nPerdida validación: 2.1293532699346542\nExactitud validación: 18.4000\nÉpoca 691\nPerdida entrenamiento: 0.16604621116729343\nPerdida validación: 1.994159609079361\nExactitud validación: 18.2870\nÉpoca 692\nPerdida entrenamiento: 0.16435301785959916\nPerdida validación: 1.955128014087677\nExactitud validación: 18.5130\nÉpoca 693\nPerdida entrenamiento: 0.16429974248304086\nPerdida validación: 1.9711505323648453\nExactitud validación: 18.4000\nÉpoca 694\nPerdida entrenamiento: 0.1655895092031535\nPerdida validación: 1.929766833782196\nExactitud validación: 18.4000\nÉpoca 695\nPerdida entrenamiento: 0.16631515455596588\nPerdida validación: 2.5120222568511963\nExactitud validación: 18.6261\nÉpoca 696\nPerdida entrenamiento: 0.16254296022302964\nPerdida validación: 2.6067320108413696\nExactitud validación: 18.5130\nÉpoca 697\nPerdida entrenamiento: 0.16614514501655803\nPerdida validación: 1.9055406600236893\nExactitud validación: 18.2870\nÉpoca 698\nPerdida entrenamiento: 0.16295288327862234\nPerdida validación: 2.6316159069538116\nExactitud validación: 18.4000\nÉpoca 699\nPerdida entrenamiento: 0.16373521878438838\nPerdida validación: 1.9525791704654694\nExactitud validación: 18.4000\nÉpoca 700\nPerdida entrenamiento: 0.16521619216484182\nPerdida validación: 2.574406772851944\nExactitud validación: 18.4000\nÉpoca 701\nPerdida entrenamiento: 0.1622587906963685\nPerdida validación: 2.044219732284546\nExactitud validación: 18.5130\nÉpoca 702\nPerdida entrenamiento: 0.16276384846252553\nPerdida validación: 2.4917390048503876\nExactitud validación: 18.2870\nÉpoca 703\nPerdida entrenamiento: 0.16085231830092037\nPerdida validación: 2.0034276843070984\nExactitud validación: 18.7391\nÉpoca 704\nPerdida entrenamiento: 0.1621255900929956\nPerdida validación: 1.8788238018751144\nExactitud validación: 18.0609\nÉpoca 705\nPerdida entrenamiento: 0.16276478811221964\nPerdida validación: 2.609136253595352\nExactitud validación: 18.7391\nÉpoca 706\nPerdida entrenamiento: 0.16290473981815226\nPerdida validación: 2.039955824613571\nExactitud validación: 18.1739\nÉpoca 707\nPerdida entrenamiento: 0.1612090832170318\nPerdida validación: 2.555538982152939\nExactitud validación: 18.6261\nÉpoca 708\nPerdida entrenamiento: 0.16272959770525203\nPerdida validación: 2.6732825934886932\nExactitud validación: 18.6261\nÉpoca 709\nPerdida entrenamiento: 0.16046422807609334\nPerdida validación: 2.65529066324234\nExactitud validación: 18.2870\nÉpoca 710\nPerdida entrenamiento: 0.1593300660743433\nPerdida validación: 2.6579330414533615\nExactitud validación: 18.1739\nÉpoca 711\nPerdida entrenamiento: 0.16260490128222635\nPerdida validación: 3.1879926919937134\nExactitud validación: 18.2870\nÉpoca 712\nPerdida entrenamiento: 0.1639710743637646\nPerdida validación: 2.5582952350378036\nExactitud validación: 18.1739\nÉpoca 713\nPerdida entrenamiento: 0.16152114859398672\nPerdida validación: 3.1042632460594177\nExactitud validación: 18.0609\nÉpoca 714\nPerdida entrenamiento: 0.16002430547686183\nPerdida validación: 2.019172251224518\nExactitud validación: 18.5130\nÉpoca 715\nPerdida entrenamiento: 0.162712872685755\nPerdida validación: 2.5908713340759277\nExactitud validación: 18.2870\nÉpoca 716\nPerdida entrenamiento: 0.16232478969237385\nPerdida validación: 3.1466260999441147\nExactitud validación: 18.6261\nÉpoca 717\nPerdida entrenamiento: 0.15897689803558238\nPerdida validación: 2.5849307030439377\nExactitud validación: 18.1739\nÉpoca 718\nPerdida entrenamiento: 0.16153902823434158\nPerdida validación: 2.647393435239792\nExactitud validación: 18.1739\nÉpoca 719\nPerdida entrenamiento: 0.16119855642318726\nPerdida validación: 2.612269088625908\nExactitud validación: 18.5130\nÉpoca 720\nPerdida entrenamiento: 0.15967204334104762\nPerdida validación: 2.601207673549652\nExactitud validación: 18.0609\nÉpoca 721\nPerdida entrenamiento: 0.15950890805791407\nPerdida validación: 2.5986678898334503\nExactitud validación: 18.4000\nÉpoca 722\nPerdida entrenamiento: 0.1589717917582568\nPerdida validación: 2.7100989818573\nExactitud validación: 18.5130\nÉpoca 723\nPerdida entrenamiento: 0.16081694338251562\nPerdida validación: 3.600108325481415\nExactitud validación: 18.2870\nÉpoca 724\nPerdida entrenamiento: 0.16270827458185308\nPerdida validación: 2.6002797037363052\nExactitud validación: 18.2870\nÉpoca 725\nPerdida entrenamiento: 0.1581830897313707\nPerdida validación: 2.6805626302957535\nExactitud validación: 18.4000\nÉpoca 726\nPerdida entrenamiento: 0.1591141451807583\nPerdida validación: 2.6532941460609436\nExactitud validación: 18.9652\nÉpoca 727\nPerdida entrenamiento: 0.157598956981126\nPerdida validación: 2.572138734161854\nExactitud validación: 18.2870\nÉpoca 728\nPerdida entrenamiento: 0.15787621149245432\nPerdida validación: 2.6060239374637604\nExactitud validación: 18.1739\nÉpoca 729\nPerdida entrenamiento: 0.15959105903611465\nPerdida validación: 2.6934962272644043\nExactitud validación: 18.2870\nÉpoca 730\nPerdida entrenamiento: 0.1582015459151829\nPerdida validación: 2.60768923163414\nExactitud validación: 18.5130\nÉpoca 731\nPerdida entrenamiento: 0.157621492357815\nPerdida validación: 3.6954606622457504\nExactitud validación: 18.6261\nÉpoca 732\nPerdida entrenamiento: 0.15893621874206207\nPerdida validación: 2.7011904567480087\nExactitud validación: 18.6261\nÉpoca 733\nPerdida entrenamiento: 0.15736218322725856\nPerdida validación: 2.8146928548812866\nExactitud validación: 18.6261\nÉpoca 734\nPerdida entrenamiento: 0.1576247026815134\nPerdida validación: 3.218151092529297\nExactitud validación: 18.4000\nÉpoca 735\nPerdida entrenamiento: 0.15623568064149687\nPerdida validación: 2.5988488644361496\nExactitud validación: 18.2870\nÉpoca 736\nPerdida entrenamiento: 0.1571689445306273\nPerdida validación: 2.706854522228241\nExactitud validación: 18.2870\nÉpoca 737\nPerdida entrenamiento: 0.15617569579797633\nPerdida validación: 2.713013231754303\nExactitud validación: 18.8522\nÉpoca 738\nPerdida entrenamiento: 0.15783894587965572\nPerdida validación: 2.7247913777828217\nExactitud validación: 18.4000\nÉpoca 739\nPerdida entrenamiento: 0.15578018676708727\nPerdida validación: 2.6655010879039764\nExactitud validación: 18.5130\nÉpoca 740\nPerdida entrenamiento: 0.15636154088903875\nPerdida validación: 3.165435329079628\nExactitud validación: 18.2870\nÉpoca 741\nPerdida entrenamiento: 0.15926396539982626\nPerdida validación: 2.5721025094389915\nExactitud validación: 18.0609\nÉpoca 742\nPerdida entrenamiento: 0.156381642774624\nPerdida validación: 2.6201601326465607\nExactitud validación: 18.2870\nÉpoca 743\nPerdida entrenamiento: 0.15768505413742626\nPerdida validación: 2.618269592523575\nExactitud validación: 18.5130\nÉpoca 744\nPerdida entrenamiento: 0.1584767182083691\nPerdida validación: 2.642210215330124\nExactitud validación: 18.2870\nÉpoca 745\nPerdida entrenamiento: 0.1547083705663681\nPerdida validación: 2.74025359749794\nExactitud validación: 18.2870\nÉpoca 746\nPerdida entrenamiento: 0.15429270661929073\nPerdida validación: 2.722310483455658\nExactitud validación: 18.9652\nÉpoca 747\nPerdida entrenamiento: 0.15567336516345248\nPerdida validación: 2.602600187063217\nExactitud validación: 18.4000\nÉpoca 748\nPerdida entrenamiento: 0.15859329021152327\nPerdida validación: 2.6595190167427063\nExactitud validación: 18.4000\nÉpoca 749\nPerdida entrenamiento: 0.1617139963542714\nPerdida validación: 2.670899897813797\nExactitud validación: 18.2870\nÉpoca 750\nPerdida entrenamiento: 0.1628905837150181\nPerdida validación: 3.219875618815422\nExactitud validación: 18.6261\nÉpoca 751\nPerdida entrenamiento: 0.16012920132454703\nPerdida validación: 3.225644052028656\nExactitud validación: 18.2870\nÉpoca 752\nPerdida entrenamiento: 0.15868979188449242\nPerdida validación: 2.67586637288332\nExactitud validación: 18.4000\nÉpoca 753\nPerdida entrenamiento: 0.1629258720752071\nPerdida validación: 2.6681269705295563\nExactitud validación: 18.4000\nÉpoca 754\nPerdida entrenamiento: 0.15711017215953155\nPerdida validación: 3.1297914385795593\nExactitud validación: 17.8348\nÉpoca 755\nPerdida entrenamiento: 0.1531862835673725\nPerdida validación: 2.726800709962845\nExactitud validación: 18.6261\nÉpoca 756\nPerdida entrenamiento: 0.15572210028767586\nPerdida validación: 2.682586520910263\nExactitud validación: 18.4000\nÉpoca 757\nPerdida entrenamiento: 0.15500885072876425\nPerdida validación: 2.609253168106079\nExactitud validación: 18.6261\nÉpoca 758\nPerdida entrenamiento: 0.1528870090842247\nPerdida validación: 2.7033819258213043\nExactitud validación: 18.4000\nÉpoca 759\nPerdida entrenamiento: 0.15350659870926073\nPerdida validación: 3.182022213935852\nExactitud validación: 18.2870\nÉpoca 760\nPerdida entrenamiento: 0.15298916180344188\nPerdida validación: 2.600184068083763\nExactitud validación: 18.4000\nÉpoca 761\nPerdida entrenamiento: 0.1532105700496365\nPerdida validación: 2.6323400884866714\nExactitud validación: 18.2870\nÉpoca 762\nPerdida entrenamiento: 0.15355657391688404\nPerdida validación: 2.684819757938385\nExactitud validación: 18.7391\nÉpoca 763\nPerdida entrenamiento: 0.15543739366180756\nPerdida validación: 3.7091951966285706\nExactitud validación: 18.4000\nÉpoca 764\nPerdida entrenamiento: 0.15140601116068222\nPerdida validación: 3.2474584877490997\nExactitud validación: 18.1739\nÉpoca 765\nPerdida entrenamiento: 0.1533643844373086\nPerdida validación: 2.633063405752182\nExactitud validación: 18.5130\nÉpoca 766\nPerdida entrenamiento: 0.15192966732908697\nPerdida validación: 3.1432758569717407\nExactitud validación: 18.1739\nÉpoca 767\nPerdida entrenamiento: 0.15253492926850037\nPerdida validación: 3.246622011065483\nExactitud validación: 18.5130\nÉpoca 768\nPerdida entrenamiento: 0.15309041738510132\nPerdida validación: 2.62382273375988\nExactitud validación: 18.6261\nÉpoca 769\nPerdida entrenamiento: 0.15307236353264136\nPerdida validación: 3.6945867389440536\nExactitud validación: 17.9478\nÉpoca 770\nPerdida entrenamiento: 0.15285500949796507\nPerdida validación: 2.6508836895227432\nExactitud validación: 18.2870\nÉpoca 771\nPerdida entrenamiento: 0.15295826271176338\nPerdida validación: 2.6306875497102737\nExactitud validación: 17.8348\nÉpoca 772\nPerdida entrenamiento: 0.15547319151022854\nPerdida validación: 2.6264542788267136\nExactitud validación: 18.2870\nÉpoca 773\nPerdida entrenamiento: 0.1503035711014972\nPerdida validación: 2.7056295573711395\nExactitud validación: 18.4000\nÉpoca 774\nPerdida entrenamiento: 0.15113376037162893\nPerdida validación: 3.1897840797901154\nExactitud validación: 18.2870\nÉpoca 775\nPerdida entrenamiento: 0.15134701746351578\nPerdida validación: 2.728394031524658\nExactitud validación: 18.4000\nÉpoca 776\nPerdida entrenamiento: 0.1525684919427423\nPerdida validación: 2.6042723059654236\nExactitud validación: 18.1739\nÉpoca 777\nPerdida entrenamiento: 0.1504207696108257\nPerdida validación: 2.600286602973938\nExactitud validación: 18.0609\nÉpoca 778\nPerdida entrenamiento: 0.14879275551613638\nPerdida validación: 3.278126984834671\nExactitud validación: 18.6261\nÉpoca 779\nPerdida entrenamiento: 0.1492233626982745\nPerdida validación: 3.162637710571289\nExactitud validación: 17.9478\nÉpoca 780\nPerdida entrenamiento: 0.15052652950672543\nPerdida validación: 3.2997718304395676\nExactitud validación: 18.5130\nÉpoca 781\nPerdida entrenamiento: 0.1493004634976387\nPerdida validación: 2.6290631741285324\nExactitud validación: 18.4000\nÉpoca 782\nPerdida entrenamiento: 0.15232405197971008\nPerdida validación: 2.6413462162017822\nExactitud validación: 18.1739\nÉpoca 783\nPerdida entrenamiento: 0.149240040603806\nPerdida validación: 3.256709098815918\nExactitud validación: 18.6261\nÉpoca 784\nPerdida entrenamiento: 0.15085110112148173\nPerdida validación: 3.1722599267959595\nExactitud validación: 18.4000\nÉpoca 785\nPerdida entrenamiento: 0.151833686101086\nPerdida validación: 2.7989502251148224\nExactitud validación: 18.6261\nÉpoca 786\nPerdida entrenamiento: 0.1522596204543815\nPerdida validación: 3.242053836584091\nExactitud validación: 18.2870\nÉpoca 787\nPerdida entrenamiento: 0.14921585799140089\nPerdida validación: 2.6283081024885178\nExactitud validación: 18.0609\nÉpoca 788\nPerdida entrenamiento: 0.14916231044951608\nPerdida validación: 2.6112345829606056\nExactitud validación: 18.5130\nÉpoca 789\nPerdida entrenamiento: 0.14993023477932987\nPerdida validación: 2.7713897675275803\nExactitud validación: 18.5130\nÉpoca 790\nPerdida entrenamiento: 0.14652396913836985\nPerdida validación: 2.666732057929039\nExactitud validación: 18.2870\nÉpoca 791\nPerdida entrenamiento: 0.14829734318396626\nPerdida validación: 2.7664362490177155\nExactitud validación: 18.5130\nÉpoca 792\nPerdida entrenamiento: 0.14896368410657435\nPerdida validación: 2.713522434234619\nExactitud validación: 18.1739\nÉpoca 793\nPerdida entrenamiento: 0.1503126388963531\nPerdida validación: 2.7845799028873444\nExactitud validación: 18.4000\nÉpoca 794\nPerdida entrenamiento: 0.1479355679715381\nPerdida validación: 3.245860606431961\nExactitud validación: 18.2870\nÉpoca 795\nPerdida entrenamiento: 0.14547785524936283\nPerdida validación: 3.1711438596248627\nExactitud validación: 17.9478\nÉpoca 796\nPerdida entrenamiento: 0.14639997482299805\nPerdida validación: 2.6832973659038544\nExactitud validación: 18.0609\nÉpoca 797\nPerdida entrenamiento: 0.14787339857395956\nPerdida validación: 3.2161754816770554\nExactitud validación: 18.8522\nÉpoca 798\nPerdida entrenamiento: 0.14859987883006825\nPerdida validación: 2.6865431666374207\nExactitud validación: 18.4000\nÉpoca 799\nPerdida entrenamiento: 0.1477495445048108\nPerdida validación: 2.63492251932621\nExactitud validación: 18.2870\nÉpoca 800\nPerdida entrenamiento: 0.14877094437970834\nPerdida validación: 2.6738118827342987\nExactitud validación: 18.1739\nÉpoca 801\nPerdida entrenamiento: 0.1459410251939998\nPerdida validación: 2.6356877088546753\nExactitud validación: 18.2870\nÉpoca 802\nPerdida entrenamiento: 0.14662704945487134\nPerdida validación: 2.6701188534498215\nExactitud validación: 18.0609\nÉpoca 803\nPerdida entrenamiento: 0.14530917300897486\nPerdida validación: 2.6025548111647367\nExactitud validación: 18.0609\nÉpoca 804\nPerdida entrenamiento: 0.14726974793216763\nPerdida validación: 2.7442044615745544\nExactitud validación: 18.6261\nÉpoca 805\nPerdida entrenamiento: 0.14796733768547282\nPerdida validación: 2.7691594064235687\nExactitud validación: 18.4000\nÉpoca 806\nPerdida entrenamiento: 0.144820795777966\nPerdida validación: 2.7950679063796997\nExactitud validación: 18.1739\nÉpoca 807\nPerdida entrenamiento: 0.1451437639839509\nPerdida validación: 2.794357866048813\nExactitud validación: 18.4000\nÉpoca 808\nPerdida entrenamiento: 0.14519775439711177\nPerdida validación: 3.242251545190811\nExactitud validación: 18.5130\nÉpoca 809\nPerdida entrenamiento: 0.14527228825232563\nPerdida validación: 3.215233623981476\nExactitud validación: 18.4000\nÉpoca 810\nPerdida entrenamiento: 0.14561747715753667\nPerdida validación: 2.7339600920677185\nExactitud validación: 18.1739\nÉpoca 811\nPerdida entrenamiento: 0.1456113238545025\nPerdida validación: 2.7056923508644104\nExactitud validación: 18.6261\nÉpoca 812\nPerdida entrenamiento: 0.14788693189620972\nPerdida validación: 2.826267398893833\nExactitud validación: 18.6261\nÉpoca 813\nPerdida entrenamiento: 0.14552707049776525\nPerdida validación: 2.6988613605499268\nExactitud validación: 18.2870\nÉpoca 814\nPerdida entrenamiento: 0.14622166621334412\nPerdida validación: 2.7413794100284576\nExactitud validación: 18.6261\nÉpoca 815\nPerdida entrenamiento: 0.143801851745914\nPerdida validación: 2.6483813747763634\nExactitud validación: 18.6261\nÉpoca 816\nPerdida entrenamiento: 0.14336932428619442\nPerdida validación: 2.7818442583084106\nExactitud validación: 18.7391\nÉpoca 817\nPerdida entrenamiento: 0.14512714743614197\nPerdida validación: 3.2018503546714783\nExactitud validación: 18.1739\nÉpoca 818\nPerdida entrenamiento: 0.14359367025249145\nPerdida validación: 3.8155419528484344\nExactitud validación: 18.4000\nÉpoca 819\nPerdida entrenamiento: 0.14185754341237686\nPerdida validación: 2.6466083750128746\nExactitud validación: 18.7391\nÉpoca 820\nPerdida entrenamiento: 0.14415400869706096\nPerdida validación: 2.8113376051187515\nExactitud validación: 18.7391\nÉpoca 821\nPerdida entrenamiento: 0.14479920443366556\nPerdida validación: 2.733074575662613\nExactitud validación: 18.2870\nÉpoca 822\nPerdida entrenamiento: 0.14300062858006535\nPerdida validación: 2.66407323628664\nExactitud validación: 17.9478\nÉpoca 823\nPerdida entrenamiento: 0.14438624636215322\nPerdida validación: 2.725124940276146\nExactitud validación: 18.6261\nÉpoca 824\nPerdida entrenamiento: 0.14179060323273435\nPerdida validación: 3.7919468730688095\nExactitud validación: 18.7391\nÉpoca 825\nPerdida entrenamiento: 0.14401953755056157\nPerdida validación: 2.940170705318451\nExactitud validación: 18.8522\nÉpoca 826\nPerdida entrenamiento: 0.14078793148784077\nPerdida validación: 2.730820268392563\nExactitud validación: 18.6261\nÉpoca 827\nPerdida entrenamiento: 0.14310375184697263\nPerdida validación: 2.7902650237083435\nExactitud validación: 18.8522\nÉpoca 828\nPerdida entrenamiento: 0.1415631906951175\nPerdida validación: 2.798295736312866\nExactitud validación: 18.5130\nÉpoca 829\nPerdida entrenamiento: 0.1424680740079459\nPerdida validación: 2.751399964094162\nExactitud validación: 18.4000\nÉpoca 830\nPerdida entrenamiento: 0.1435266877798473\nPerdida validación: 2.73421211540699\nExactitud validación: 18.1739\nÉpoca 831\nPerdida entrenamiento: 0.14105699036051245\nPerdida validación: 2.752659022808075\nExactitud validación: 18.1739\nÉpoca 832\nPerdida entrenamiento: 0.1436002629206461\nPerdida validación: 2.6599045991897583\nExactitud validación: 18.5130\nÉpoca 833\nPerdida entrenamiento: 0.14401213079690933\nPerdida validación: 2.719948261976242\nExactitud validación: 18.2870\nÉpoca 834\nPerdida entrenamiento: 0.14162796144099796\nPerdida validación: 3.2921559512615204\nExactitud validación: 18.2870\nÉpoca 835\nPerdida entrenamiento: 0.14128982319551356\nPerdida validación: 2.6709438040852547\nExactitud validación: 18.4000\nÉpoca 836\nPerdida entrenamiento: 0.14059947935097358\nPerdida validación: 2.7341255843639374\nExactitud validación: 18.4000\nÉpoca 837\nPerdida entrenamiento: 0.1398994068012518\nPerdida validación: 2.786491632461548\nExactitud validación: 18.5130\nÉpoca 838\nPerdida entrenamiento: 0.14133495618315303\nPerdida validación: 2.690669760107994\nExactitud validación: 18.2870\nÉpoca 839\nPerdida entrenamiento: 0.1424069856019581\nPerdida validación: 3.295660972595215\nExactitud validación: 18.4000\nÉpoca 840\nPerdida entrenamiento: 0.1393086116980104\nPerdida validación: 2.660525068640709\nExactitud validación: 18.5130\nÉpoca 841\nPerdida entrenamiento: 0.14105064158930497\nPerdida validación: 2.737117111682892\nExactitud validación: 18.4000\nÉpoca 842\nPerdida entrenamiento: 0.13984821671072176\nPerdida validación: 2.802027255296707\nExactitud validación: 18.5130\nÉpoca 843\nPerdida entrenamiento: 0.14101365844116492\nPerdida validación: 2.8786006718873978\nExactitud validación: 18.6261\nÉpoca 844\nPerdida entrenamiento: 0.14051969480865142\nPerdida validación: 2.7385316342115402\nExactitud validación: 18.6261\nÉpoca 845\nPerdida entrenamiento: 0.14059160868911183\nPerdida validación: 3.7438178658485413\nExactitud validación: 18.4000\nÉpoca 846\nPerdida entrenamiento: 0.1408574015778654\nPerdida validación: 3.268863081932068\nExactitud validación: 18.2870\nÉpoca 847\nPerdida entrenamiento: 0.14002320258056417\nPerdida validación: 3.4570556730031967\nExactitud validación: 18.5130\nÉpoca 848\nPerdida entrenamiento: 0.14203892955008676\nPerdida validación: 2.8030443489551544\nExactitud validación: 18.4000\nÉpoca 849\nPerdida entrenamiento: 0.14011239435742884\nPerdida validación: 2.820237874984741\nExactitud validación: 18.2870\nÉpoca 850\nPerdida entrenamiento: 0.1396850124001503\nPerdida validación: 3.243169218301773\nExactitud validación: 18.5130\nÉpoca 851\nPerdida entrenamiento: 0.13872243946089463\nPerdida validación: 2.7179784178733826\nExactitud validación: 18.5130\nÉpoca 852\nPerdida entrenamiento: 0.13912279465619257\nPerdida validación: 2.7133824974298477\nExactitud validación: 18.1739\nÉpoca 853\nPerdida entrenamiento: 0.13690624988692648\nPerdida validación: 2.8744891583919525\nExactitud validación: 18.1739\nÉpoca 854\nPerdida entrenamiento: 0.1364170865100973\nPerdida validación: 2.780077964067459\nExactitud validación: 18.4000\nÉpoca 855\nPerdida entrenamiento: 0.13848148680785122\nPerdida validación: 2.732403054833412\nExactitud validación: 18.4000\nÉpoca 856\nPerdida entrenamiento: 0.13774363828056\nPerdida validación: 2.748747408390045\nExactitud validación: 18.1739\nÉpoca 857\nPerdida entrenamiento: 0.13970747677718892\nPerdida validación: 2.7384248077869415\nExactitud validación: 18.7391\nÉpoca 858\nPerdida entrenamiento: 0.13931907012182124\nPerdida validación: 2.7981139421463013\nExactitud validación: 18.5130\nÉpoca 859\nPerdida entrenamiento: 0.13711956625475602\nPerdida validación: 2.746776044368744\nExactitud validación: 18.4000\nÉpoca 860\nPerdida entrenamiento: 0.14136996602310853\nPerdida validación: 2.961911305785179\nExactitud validación: 18.8522\nÉpoca 861\nPerdida entrenamiento: 0.1371486279017785\nPerdida validación: 2.920855939388275\nExactitud validación: 18.9652\nÉpoca 862\nPerdida entrenamiento: 0.1369148339418804\nPerdida validación: 3.3346258997917175\nExactitud validación: 17.9478\nÉpoca 863\nPerdida entrenamiento: 0.1381302679724553\nPerdida validación: 2.696602389216423\nExactitud validación: 18.1739\nÉpoca 864\nPerdida entrenamiento: 0.13654666306341395\nPerdida validación: 2.7097426876425743\nExactitud validación: 18.5130\nÉpoca 865\nPerdida entrenamiento: 0.1373768339262289\nPerdida validación: 2.822031795978546\nExactitud validación: 17.8348\nÉpoca 866\nPerdida entrenamiento: 0.1341216191649437\nPerdida validación: 2.705332897603512\nExactitud validación: 18.1739\nÉpoca 867\nPerdida entrenamiento: 0.1376872159102384\nPerdida validación: 2.7694733440876007\nExactitud validación: 18.0609\nÉpoca 868\nPerdida entrenamiento: 0.13436881759587457\nPerdida validación: 2.782355934381485\nExactitud validación: 18.6261\nÉpoca 869\nPerdida entrenamiento: 0.13662084586480083\nPerdida validación: 2.75421804189682\nExactitud validación: 18.1739\nÉpoca 870\nPerdida entrenamiento: 0.1360327185076826\nPerdida validación: 2.8113476634025574\nExactitud validación: 18.7391\nÉpoca 871\nPerdida entrenamiento: 0.13782303298220916\nPerdida validación: 2.779130682349205\nExactitud validación: 18.5130\nÉpoca 872\nPerdida entrenamiento: 0.13344334416529713\nPerdida validación: 2.784419059753418\nExactitud validación: 18.2870\nÉpoca 873\nPerdida entrenamiento: 0.13555954462465117\nPerdida validación: 2.7529250234365463\nExactitud validación: 18.2870\nÉpoca 874\nPerdida entrenamiento: 0.1355480694157236\nPerdida validación: 3.300339162349701\nExactitud validación: 18.4000\nÉpoca 875\nPerdida entrenamiento: 0.13865461638745138\nPerdida validación: 2.9780090004205704\nExactitud validación: 18.7391\nÉpoca 876\nPerdida entrenamiento: 0.1376051098546561\nPerdida validación: 2.8903158009052277\nExactitud validación: 18.2870\nÉpoca 877\nPerdida entrenamiento: 0.13494748030515277\nPerdida validación: 2.7917942702770233\nExactitud validación: 18.6261\nÉpoca 878\nPerdida entrenamiento: 0.1352824815275038\nPerdida validación: 3.3168766498565674\nExactitud validación: 18.6261\nÉpoca 879\nPerdida entrenamiento: 0.1324736436500269\nPerdida validación: 2.7636314928531647\nExactitud validación: 18.4000\nÉpoca 880\nPerdida entrenamiento: 0.13348486493615544\nPerdida validación: 2.871694028377533\nExactitud validación: 18.5130\nÉpoca 881\nPerdida entrenamiento: 0.13614112927633173\nPerdida validación: 2.82409131526947\nExactitud validación: 18.7391\nÉpoca 882\nPerdida entrenamiento: 0.13355802678886583\nPerdida validación: 2.7636439353227615\nExactitud validación: 18.4000\nÉpoca 883\nPerdida entrenamiento: 0.1327956191757146\nPerdida validación: 2.812580853700638\nExactitud validación: 18.1739\nÉpoca 884\nPerdida entrenamiento: 0.13378482684493065\nPerdida validación: 2.7658906280994415\nExactitud validación: 18.2870\nÉpoca 885\nPerdida entrenamiento: 0.1324151684256161\nPerdida validación: 2.857463538646698\nExactitud validación: 18.4000\nÉpoca 886\nPerdida entrenamiento: 0.1337796228335184\nPerdida validación: 3.4032358527183533\nExactitud validación: 18.4000\nÉpoca 887\nPerdida entrenamiento: 0.13265221697442672\nPerdida validación: 3.3464408963918686\nExactitud validación: 18.2870\nÉpoca 888\nPerdida entrenamiento: 0.13283191577476613\nPerdida validación: 2.790514573454857\nExactitud validación: 18.5130\nÉpoca 889\nPerdida entrenamiento: 0.13208355623133042\nPerdida validación: 2.8009232729673386\nExactitud validación: 18.5130\nÉpoca 890\nPerdida entrenamiento: 0.13509997550178976\nPerdida validación: 2.8039220198988914\nExactitud validación: 18.5130\nÉpoca 891\nPerdida entrenamiento: 0.13466739829848795\nPerdida validación: 2.90687495470047\nExactitud validación: 18.2870\nÉpoca 892\nPerdida entrenamiento: 0.1318563308347674\nPerdida validación: 2.8616604059934616\nExactitud validación: 18.6261\nÉpoca 893\nPerdida entrenamiento: 0.13101407315801172\nPerdida validación: 2.96872079372406\nExactitud validación: 18.6261\nÉpoca 894\nPerdida entrenamiento: 0.13524135245996363\nPerdida validación: 2.829436719417572\nExactitud validación: 18.5130\nÉpoca 895\nPerdida entrenamiento: 0.13446547616930568\nPerdida validación: 2.8921854197978973\nExactitud validación: 18.4000\nÉpoca 896\nPerdida entrenamiento: 0.13377005256274166\nPerdida validación: 2.9073114544153214\nExactitud validación: 18.5130\nÉpoca 897\nPerdida entrenamiento: 0.13366495949380539\nPerdida validación: 2.869605004787445\nExactitud validación: 18.4000\nÉpoca 898\nPerdida entrenamiento: 0.13367976116783478\nPerdida validación: 2.8357715904712677\nExactitud validación: 18.2870\nÉpoca 899\nPerdida entrenamiento: 0.13272172037292929\nPerdida validación: 3.323453515768051\nExactitud validación: 18.2870\nÉpoca 900\nPerdida entrenamiento: 0.132703357759644\nPerdida validación: 2.9263442158699036\nExactitud validación: 18.6261\nÉpoca 901\nPerdida entrenamiento: 0.13167799373759942\nPerdida validación: 3.4298669397830963\nExactitud validación: 18.0609\nÉpoca 902\nPerdida entrenamiento: 0.1339989497381098\nPerdida validación: 2.8030209839344025\nExactitud validación: 18.2870\nÉpoca 903\nPerdida entrenamiento: 0.1287992243819377\nPerdida validación: 2.8654688000679016\nExactitud validación: 18.7391\nÉpoca 904\nPerdida entrenamiento: 0.13100341444506364\nPerdida validación: 3.4879584312438965\nExactitud validación: 18.4000\nÉpoca 905\nPerdida entrenamiento: 0.1310742236673832\nPerdida validación: 2.7952137142419815\nExactitud validación: 18.2870\nÉpoca 906\nPerdida entrenamiento: 0.12950651961214402\nPerdida validación: 2.8933157920837402\nExactitud validación: 18.5130\nÉpoca 907\nPerdida entrenamiento: 0.12948743275859775\nPerdida validación: 2.920369252562523\nExactitud validación: 18.9652\nÉpoca 908\nPerdida entrenamiento: 0.12981591811951468\nPerdida validación: 2.874404937028885\nExactitud validación: 18.2870\nÉpoca 909\nPerdida entrenamiento: 0.1289715587216265\nPerdida validación: 3.2992987632751465\nExactitud validación: 18.7391\nÉpoca 910\nPerdida entrenamiento: 0.1300869676120141\nPerdida validación: 3.415118455886841\nExactitud validación: 18.1739\nÉpoca 911\nPerdida entrenamiento: 0.1314496520687552\nPerdida validación: 2.855779469013214\nExactitud validación: 18.4000\nÉpoca 912\nPerdida entrenamiento: 0.13039520207573385\nPerdida validación: 2.863826960325241\nExactitud validación: 18.2870\nÉpoca 913\nPerdida entrenamiento: 0.12854845580809257\nPerdida validación: 3.4703205823898315\nExactitud validación: 18.5130\nÉpoca 914\nPerdida entrenamiento: 0.1311737588223289\nPerdida validación: 2.8276840299367905\nExactitud validación: 18.1739\nÉpoca 915\nPerdida entrenamiento: 0.12898599926163168\nPerdida validación: 2.808225929737091\nExactitud validación: 18.2870\nÉpoca 916\nPerdida entrenamiento: 0.12826384625890674\nPerdida validación: 2.954753652215004\nExactitud validación: 18.0609\nÉpoca 917\nPerdida entrenamiento: 0.1291312752839397\nPerdida validación: 3.455663487315178\nExactitud validación: 18.2870\nÉpoca 918\nPerdida entrenamiento: 0.1272546608439263\nPerdida validación: 2.840626373887062\nExactitud validación: 18.6261\nÉpoca 919\nPerdida entrenamiento: 0.12807583589764202\nPerdida validación: 2.908486932516098\nExactitud validación: 18.7391\nÉpoca 920\nPerdida entrenamiento: 0.12984531920622377\nPerdida validación: 2.949549823999405\nExactitud validación: 18.1739\nÉpoca 921\nPerdida entrenamiento: 0.12714826140333624\nPerdida validación: 2.9026261270046234\nExactitud validación: 18.0609\nÉpoca 922\nPerdida entrenamiento: 0.12683334858978496\nPerdida validación: 3.4384027123451233\nExactitud validación: 18.4000\nÉpoca 923\nPerdida entrenamiento: 0.12668604359907262\nPerdida validación: 3.4019243717193604\nExactitud validación: 17.9478\nÉpoca 924\nPerdida entrenamiento: 0.1273968097041635\nPerdida validación: 3.4543668031692505\nExactitud validación: 18.0609\nÉpoca 925\nPerdida entrenamiento: 0.1270380519768771\nPerdida validación: 2.9080685824155807\nExactitud validación: 18.4000\nÉpoca 926\nPerdida entrenamiento: 0.12678182059351137\nPerdida validación: 2.854278191924095\nExactitud validación: 18.6261\nÉpoca 927\nPerdida entrenamiento: 0.1272417313474066\nPerdida validación: 3.409367948770523\nExactitud validación: 18.5130\nÉpoca 928\nPerdida entrenamiento: 0.12685667372801723\nPerdida validación: 4.08304163813591\nExactitud validación: 18.4000\nÉpoca 929\nPerdida entrenamiento: 0.12677246003466494\nPerdida validación: 2.8712600469589233\nExactitud validación: 18.4000\nÉpoca 930\nPerdida entrenamiento: 0.12664389434982748\nPerdida validación: 2.9682075679302216\nExactitud validación: 18.5130\nÉpoca 931\nPerdida entrenamiento: 0.12917877909015207\nPerdida validación: 2.8417866826057434\nExactitud validación: 18.1739\nÉpoca 932\nPerdida entrenamiento: 0.12731395530350068\nPerdida validación: 2.898645430803299\nExactitud validación: 18.4000\nÉpoca 933\nPerdida entrenamiento: 0.12507441157803817\nPerdida validación: 2.914635419845581\nExactitud validación: 18.5130\nÉpoca 934\nPerdida entrenamiento: 0.12594195674447453\nPerdida validación: 2.912827104330063\nExactitud validación: 18.4000\nÉpoca 935\nPerdida entrenamiento: 0.1251837317557896\nPerdida validación: 3.5243859738111496\nExactitud validación: 18.4000\nÉpoca 936\nPerdida entrenamiento: 0.12473153717377607\nPerdida validación: 2.9899864494800568\nExactitud validación: 18.6261\nÉpoca 937\nPerdida entrenamiento: 0.12627896666526794\nPerdida validación: 2.940245568752289\nExactitud validación: 17.9478\nÉpoca 938\nPerdida entrenamiento: 0.12539050552774877\nPerdida validación: 3.506003439426422\nExactitud validación: 18.6261\nÉpoca 939\nPerdida entrenamiento: 0.12461071943535525\nPerdida validación: 2.9693265557289124\nExactitud validación: 18.8522\nÉpoca 940\nPerdida entrenamiento: 0.12703695104402654\nPerdida validación: 3.0138815343379974\nExactitud validación: 18.6261\nÉpoca 941\nPerdida entrenamiento: 0.12593218640369527\nPerdida validación: 3.412371516227722\nExactitud validación: 18.8522\nÉpoca 942\nPerdida entrenamiento: 0.12484191182781668\nPerdida validación: 2.875510886311531\nExactitud validación: 18.4000\nÉpoca 943\nPerdida entrenamiento: 0.12549839157830267\nPerdida validación: 3.0640504956245422\nExactitud validación: 18.2870\nÉpoca 944\nPerdida entrenamiento: 0.1243065052172717\nPerdida validación: 3.010021924972534\nExactitud validación: 18.5130\nÉpoca 945\nPerdida entrenamiento: 0.12402418606421527\nPerdida validación: 2.888392746448517\nExactitud validación: 18.6261\nÉpoca 946\nPerdida entrenamiento: 0.12377885378458921\nPerdida validación: 2.8283270969986916\nExactitud validación: 18.1739\nÉpoca 947\nPerdida entrenamiento: 0.12332157023689326\nPerdida validación: 3.4357332587242126\nExactitud validación: 18.1739\nÉpoca 948\nPerdida entrenamiento: 0.12415540525141884\nPerdida validación: 2.9335389137268066\nExactitud validación: 18.7391\nÉpoca 949\nPerdida entrenamiento: 0.12486725640209283\nPerdida validación: 2.931018203496933\nExactitud validación: 18.6261\nÉpoca 950\nPerdida entrenamiento: 0.12408434424330206\nPerdida validación: 3.054698035120964\nExactitud validación: 18.6261\nÉpoca 951\nPerdida entrenamiento: 0.12574190032832763\nPerdida validación: 3.0038841366767883\nExactitud validación: 18.2870\nÉpoca 952\nPerdida entrenamiento: 0.12242736294865608\nPerdida validación: 4.074982047080994\nExactitud validación: 18.4000\nÉpoca 953\nPerdida entrenamiento: 0.12435674601617981\nPerdida validación: 2.973332405090332\nExactitud validación: 18.5130\nÉpoca 954\nPerdida entrenamiento: 0.12533021915484877\nPerdida validación: 3.4903931617736816\nExactitud validación: 18.5130\nÉpoca 955\nPerdida entrenamiento: 0.12362913436749402\nPerdida validación: 2.894077181816101\nExactitud validación: 18.0609\nÉpoca 956\nPerdida entrenamiento: 0.1241259554072338\nPerdida validación: 3.5641388595104218\nExactitud validación: 18.8522\nÉpoca 957\nPerdida entrenamiento: 0.12326250049997778\nPerdida validación: 2.894750624895096\nExactitud validación: 18.7391\nÉpoca 958\nPerdida entrenamiento: 0.12201590529259514\nPerdida validación: 3.554157704114914\nExactitud validación: 18.7391\nÉpoca 959\nPerdida entrenamiento: 0.12234444193103734\nPerdida validación: 3.0658498108386993\nExactitud validación: 18.7391\nÉpoca 960\nPerdida entrenamiento: 0.1225890420815524\nPerdida validación: 2.9639132916927338\nExactitud validación: 18.2870\nÉpoca 961\nPerdida entrenamiento: 0.12655563323813326\nPerdida validación: 3.4610494822263718\nExactitud validación: 18.2870\nÉpoca 962\nPerdida entrenamiento: 0.12557828514014974\nPerdida validación: 3.0472725331783295\nExactitud validación: 18.7391\nÉpoca 963\nPerdida entrenamiento: 0.12406371117514722\nPerdida validación: 3.4296689927577972\nExactitud validación: 18.5130\nÉpoca 964\nPerdida entrenamiento: 0.12306797109982547\nPerdida validación: 2.8831294775009155\nExactitud validación: 18.6261\nÉpoca 965\nPerdida entrenamiento: 0.12154533823623377\nPerdida validación: 3.0393559336662292\nExactitud validación: 18.0609\nÉpoca 966\nPerdida entrenamiento: 0.12231333071694654\nPerdida validación: 2.893571987748146\nExactitud validación: 18.2870\nÉpoca 967\nPerdida entrenamiento: 0.12442432300132863\nPerdida validación: 2.8784404695034027\nExactitud validación: 18.8522\nÉpoca 968\nPerdida entrenamiento: 0.12219117998200305\nPerdida validación: 3.0569884181022644\nExactitud validación: 18.5130\nÉpoca 969\nPerdida entrenamiento: 0.1204835956587511\nPerdida validación: 3.0531783998012543\nExactitud validación: 18.1739\nÉpoca 970\nPerdida entrenamiento: 0.12147321595865138\nPerdida validación: 3.105465844273567\nExactitud validación: 18.5130\nÉpoca 971\nPerdida entrenamiento: 0.11965199538013514\nPerdida validación: 2.9067180305719376\nExactitud validación: 18.2870\nÉpoca 972\nPerdida entrenamiento: 0.1203617955393651\nPerdida validación: 2.853972941637039\nExactitud validación: 18.2870\nÉpoca 973\nPerdida entrenamiento: 0.12197020540342611\nPerdida validación: 2.951186329126358\nExactitud validación: 18.6261\nÉpoca 974\nPerdida entrenamiento: 0.12436810749418595\nPerdida validación: 3.067672148346901\nExactitud validación: 18.6261\nÉpoca 975\nPerdida entrenamiento: 0.12134960271856364\nPerdida validación: 3.5442528426647186\nExactitud validación: 18.2870\nÉpoca 976\nPerdida entrenamiento: 0.1222062270869227\nPerdida validación: 3.071064904332161\nExactitud validación: 18.7391\nÉpoca 977\nPerdida entrenamiento: 0.12381410642581828\nPerdida validación: 2.9515878558158875\nExactitud validación: 18.1739\nÉpoca 978\nPerdida entrenamiento: 0.11919486478847616\nPerdida validación: 2.987251326441765\nExactitud validación: 18.8522\nÉpoca 979\nPerdida entrenamiento: 0.12118908982066547\nPerdida validación: 2.964499592781067\nExactitud validación: 18.2870\nÉpoca 980\nPerdida entrenamiento: 0.11982706517857664\nPerdida validación: 2.884852759540081\nExactitud validación: 18.2870\nÉpoca 981\nPerdida entrenamiento: 0.12243366482503273\nPerdida validación: 2.9526966214179993\nExactitud validación: 18.5130\nÉpoca 982\nPerdida entrenamiento: 0.12023616615025436\nPerdida validación: 2.892222762107849\nExactitud validación: 18.5130\nÉpoca 983\nPerdida entrenamiento: 0.11949533388456877\nPerdida validación: 3.0738677978515625\nExactitud validación: 18.5130\nÉpoca 984\nPerdida entrenamiento: 0.11815058308489182\nPerdida validación: 2.943865194916725\nExactitud validación: 18.1739\nÉpoca 985\nPerdida entrenamiento: 0.12010063581606921\nPerdida validación: 3.0461696088314056\nExactitud validación: 18.2870\nÉpoca 986\nPerdida entrenamiento: 0.1200608185985509\nPerdida validación: 4.0663831532001495\nExactitud validación: 18.4000\nÉpoca 987\nPerdida entrenamiento: 0.11974002442815725\nPerdida validación: 3.468088820576668\nExactitud validación: 18.1739\nÉpoca 988\nPerdida entrenamiento: 0.11906973097254248\nPerdida validación: 2.943978175520897\nExactitud validación: 18.0609\nÉpoca 989\nPerdida entrenamiento: 0.12085146150168251\nPerdida validación: 3.0875197649002075\nExactitud validación: 18.4000\nÉpoca 990\nPerdida entrenamiento: 0.11931220442056656\nPerdida validación: 3.4530164301395416\nExactitud validación: 18.2870\nÉpoca 991\nPerdida entrenamiento: 0.1200842373073101\nPerdida validación: 3.108154445886612\nExactitud validación: 18.4000\nÉpoca 992\nPerdida entrenamiento: 0.11944863528889768\nPerdida validación: 3.4121116399765015\nExactitud validación: 18.2870\nÉpoca 993\nPerdida entrenamiento: 0.11968237862867467\nPerdida validación: 2.9360441118478775\nExactitud validación: 18.2870\nÉpoca 994\nPerdida entrenamiento: 0.11799231237348388\nPerdida validación: 3.036650687456131\nExactitud validación: 18.4000\nÉpoca 995\nPerdida entrenamiento: 0.11872703187605914\nPerdida validación: 2.939451888203621\nExactitud validación: 18.4000\nÉpoca 996\nPerdida entrenamiento: 0.1186886644538711\nPerdida validación: 3.0029216408729553\nExactitud validación: 18.4000\nÉpoca 997\nPerdida entrenamiento: 0.11697329558870372\nPerdida validación: 2.912400111556053\nExactitud validación: 18.1739\nÉpoca 998\nPerdida entrenamiento: 0.11653838547713616\nPerdida validación: 3.0047235190868378\nExactitud validación: 18.1739\nÉpoca 999\nPerdida entrenamiento: 0.11792571338660576\nPerdida validación: 4.158627465367317\nExactitud validación: 18.5130\nÉpoca 1000\nPerdida entrenamiento: 0.11670456804773387\nPerdida validación: 2.9439720809459686\nExactitud validación: 18.1739"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‘Machine Learning with R’ by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book’s specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book’s examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution\n\ndata_path = \"../../data/\""
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load\n\ndata = pd.read_csv(data_path+\"insurance_2.csv\")\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\nNumber of GPUs available: 1\nGPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   salary    1338 non-null   float64\n 6   region    1338 non-null   object \n 7   charges   1338 non-null   float64\ndtypes: float64(3), int64(2), object(3)\nmemory usage: 83.8+ KB\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\ncount\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n\n\nmean\n39.207025\n30.663397\n1.094918\n159064.411451\n13270.422265\n\n\nstd\n14.049960\n6.098187\n1.205493\n41741.994963\n12110.011237\n\n\nmin\n18.000000\n15.960000\n0.000000\n104622.922023\n1121.873900\n\n\n25%\n27.000000\n26.296250\n0.000000\n130087.161933\n4740.287150\n\n\n50%\n39.000000\n30.400000\n1.000000\n146740.897257\n9382.033000\n\n\n75%\n51.000000\n34.693750\n2.000000\n171897.191284\n16639.912515\n\n\nmax\n64.000000\n53.130000\n5.000000\n338460.517246\n63770.428010\n\n\n\n\n\n\n\n\ndata.select_dtypes(\"object\")\n\n\n\n\n\n\n\n\nsex\nsmoker\nregion\n\n\n\n\n0\nfemale\nyes\nsouthwest\n\n\n1\nmale\nno\nsoutheast\n\n\n2\nmale\nno\nsoutheast\n\n\n3\nmale\nno\nnorthwest\n\n\n4\nmale\nno\nnorthwest\n\n\n...\n...\n...\n...\n\n\n1333\nmale\nno\nnorthwest\n\n\n1334\nfemale\nno\nnortheast\n\n\n1335\nfemale\nno\nsoutheast\n\n\n1336\nfemale\nno\nsouthwest\n\n\n1337\nfemale\nyes\nnorthwest\n\n\n\n\n1338 rows × 3 columns\n\n\n\n\ndata[\"sex\"] = data[\"sex\"].astype(\"category\")\ndata[\"smoker\"] = data[\"smoker\"].astype(\"category\")\ndata[\"region\"] = data[\"region\"].astype(\"category\")\n\n\ndata.select_dtypes(\"number\")\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\n0\n19\n27.900\n0\n159272.812482\n16884.92400\n\n\n1\n18\n33.770\n1\n117088.625944\n1725.55230\n\n\n2\n28\n33.000\n3\n129043.852213\n4449.46200\n\n\n3\n33\n22.705\n0\n194635.486180\n21984.47061\n\n\n4\n32\n28.880\n0\n113585.904592\n3866.85520\n\n\n...\n...\n...\n...\n...\n...\n\n\n1333\n50\n30.970\n3\n145933.927725\n10600.54830\n\n\n1334\n18\n31.920\n0\n117665.917758\n2205.98080\n\n\n1335\n18\n36.850\n0\n133402.353115\n1629.83350\n\n\n1336\n21\n25.800\n0\n133975.682996\n2007.94500\n\n\n1337\n61\n29.070\n0\n216658.755628\n29141.36030\n\n\n\n\n1338 rows × 5 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   age       1338 non-null   int64   \n 1   sex       1338 non-null   category\n 2   bmi       1338 non-null   float64 \n 3   children  1338 non-null   int64   \n 4   smoker    1338 non-null   category\n 5   salary    1338 non-null   float64 \n 6   region    1338 non-null   category\n 7   charges   1338 non-null   float64 \ndtypes: category(3), float64(3), int64(2)\nmemory usage: 56.8 KB\n\n\n\n\n2. Visualizing distributions\n\nsns.histplot(data[\"bmi\"], stat=\"probability\")\n\n\n\n\n\n\n\n\n\n\n3. Exploring relationships between variables\n\nsns.scatterplot(data=data, x=\"bmi\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\n\n4. Analyzing categorical variables\n\nsns.countplot(data=data, x=\"smoker\", stat=\"probability\")\n\n\n\n\n\n\n\n\n\nsns.boxplot(data=data, y=\"charges\", x=\"smoker\")\n\n\n\n\n\n\n\n\n\nsns.pointplot(data=data, x=\"sex\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\ng001 = sns.FacetGrid(data=data, col=\"smoker\", row=\"sex\")\ng001.map(plt.scatter, \"bmi\", \"charges\")\n\n\n\n\n\n\n\n\n\nsns.regplot(data=data, x=\"salary\", y=\"charges\",\n            scatter_kws={\"color\": \"blue\"},  # Color de los puntos\n            line_kws={\"color\": \"red\"})"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "title": "Health Care Cost Predictor",
    "section": "5. Checking availability of GPU",
    "text": "5. Checking availability of GPU\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\ndevice1\n\nUsing device: cuda:0\n\n\ndevice(type='cuda', index=0)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "title": "Health Care Cost Predictor",
    "section": "6. Splitting data",
    "text": "6. Splitting data\n\nentrada = data[\"salary\"].to_numpy().reshape(-1, 1)\nsalida = data[\"charges\"].to_numpy().reshape(-1, 1)\n\n\nstandarScaler_features = StandardScaler().fit(entrada)\nstandarScaler_output = StandardScaler().fit(salida)\n\n\nsalary_train, salary_test, charges_train, charges_test = train_test_split(\n    standarScaler_features.transform(entrada),\n    standarScaler_output.transform(salida),\n    train_size=0.7,\n    shuffle=True,\n)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "title": "Health Care Cost Predictor",
    "section": "7. Converting Data To Tensor",
    "text": "7. Converting Data To Tensor\n\nt_salary_train = torch.tensor(salary_train, dtype=torch.float32, device=device1)\nt_salary_test = torch.tensor(salary_test, dtype=torch.float32, device=device1)\nt_charges_train = torch.tensor(charges_train, dtype=torch.float32, device=device1)\nt_charges_test = torch.tensor(charges_test, dtype=torch.float32, device=device1)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "8. Model Implementation",
    "text": "8. Model Implementation\n\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\nmodel = LinearRegression().to(device1)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "10. Train Model",
    "text": "10. Train Model\n\nnum_epochs = 1000\nfor epoch in range(num_epochs):\n\n     # Fordward Pass and loss\n\n     charges_predicted = model(t_salary_train)\n     loss = criterion(charges_predicted, t_charges_train)\n\n     # Backward pass\n     loss.backward()\n\n     #wweights update\n     optimizer.step()\n     optimizer.zero_grad()\n\n     # Progress tracking\n\n     if (epoch+1)%10 ==0:\n          print(f\"Epoch: {epoch+1}, loss={loss.item():.4f}\")\n\nEpoch: 10, loss=1.2763\nEpoch: 20, loss=0.8460\nEpoch: 30, loss=0.5655\nEpoch: 40, loss=0.3828\nEpoch: 50, loss=0.2637\nEpoch: 60, loss=0.1861\nEpoch: 70, loss=0.1355\nEpoch: 80, loss=0.1026\nEpoch: 90, loss=0.0811\nEpoch: 100, loss=0.0671\nEpoch: 110, loss=0.0579\nEpoch: 120, loss=0.0520\nEpoch: 130, loss=0.0481\nEpoch: 140, loss=0.0456\nEpoch: 150, loss=0.0439\nEpoch: 160, loss=0.0428\nEpoch: 170, loss=0.0421\nEpoch: 180, loss=0.0417\nEpoch: 190, loss=0.0414\nEpoch: 200, loss=0.0412\nEpoch: 210, loss=0.0411\nEpoch: 220, loss=0.0410\nEpoch: 230, loss=0.0409\nEpoch: 240, loss=0.0409\nEpoch: 250, loss=0.0409\nEpoch: 260, loss=0.0408\nEpoch: 270, loss=0.0408\nEpoch: 280, loss=0.0408\nEpoch: 290, loss=0.0408\nEpoch: 300, loss=0.0408\nEpoch: 310, loss=0.0408\nEpoch: 320, loss=0.0408\nEpoch: 330, loss=0.0408\nEpoch: 340, loss=0.0408\nEpoch: 350, loss=0.0408\nEpoch: 360, loss=0.0408\nEpoch: 370, loss=0.0408\nEpoch: 380, loss=0.0408\nEpoch: 390, loss=0.0408\nEpoch: 400, loss=0.0408\nEpoch: 410, loss=0.0408\nEpoch: 420, loss=0.0408\nEpoch: 430, loss=0.0408\nEpoch: 440, loss=0.0408\nEpoch: 450, loss=0.0408\nEpoch: 460, loss=0.0408\nEpoch: 470, loss=0.0408\nEpoch: 480, loss=0.0408\nEpoch: 490, loss=0.0408\nEpoch: 500, loss=0.0408\nEpoch: 510, loss=0.0408\nEpoch: 520, loss=0.0408\nEpoch: 530, loss=0.0408\nEpoch: 540, loss=0.0408\nEpoch: 550, loss=0.0408\nEpoch: 560, loss=0.0408\nEpoch: 570, loss=0.0408\nEpoch: 580, loss=0.0408\nEpoch: 590, loss=0.0408\nEpoch: 600, loss=0.0408\nEpoch: 610, loss=0.0408\nEpoch: 620, loss=0.0408\nEpoch: 630, loss=0.0408\nEpoch: 640, loss=0.0408\nEpoch: 650, loss=0.0408\nEpoch: 660, loss=0.0408\nEpoch: 670, loss=0.0408\nEpoch: 680, loss=0.0408\nEpoch: 690, loss=0.0408\nEpoch: 700, loss=0.0408\nEpoch: 710, loss=0.0408\nEpoch: 720, loss=0.0408\nEpoch: 730, loss=0.0408\nEpoch: 740, loss=0.0408\nEpoch: 750, loss=0.0408\nEpoch: 760, loss=0.0408\nEpoch: 770, loss=0.0408\nEpoch: 780, loss=0.0408\nEpoch: 790, loss=0.0408\nEpoch: 800, loss=0.0408\nEpoch: 810, loss=0.0408\nEpoch: 820, loss=0.0408\nEpoch: 830, loss=0.0408\nEpoch: 840, loss=0.0408\nEpoch: 850, loss=0.0408\nEpoch: 860, loss=0.0408\nEpoch: 870, loss=0.0408\nEpoch: 880, loss=0.0408\nEpoch: 890, loss=0.0408\nEpoch: 900, loss=0.0408\nEpoch: 910, loss=0.0408\nEpoch: 920, loss=0.0408\nEpoch: 930, loss=0.0408\nEpoch: 940, loss=0.0408\nEpoch: 950, loss=0.0408\nEpoch: 960, loss=0.0408\nEpoch: 970, loss=0.0408\nEpoch: 980, loss=0.0408\nEpoch: 990, loss=0.0408\nEpoch: 1000, loss=0.0408\n\n\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )\n\n\n\n\n\n\n\n\n\ns_predicha = standarScaler_output.inverse_transform(prediction.cpu().numpy())\ns_real = standarScaler_output.inverse_transform(charges_test)\n\nresiduos = s_real- s_predicha\n\nsm.graphics.tsa.plot_acf(residuos, lags=100)"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\n#data = pd.read_csv(\"drive/MyDrive/ASIM/diabetes.csv\")\ndata = pd.read_csv(\"../../data/diabetes.csv\")\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\ncount\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n\n\nmean\n3.845052\n120.894531\n69.105469\n20.536458\n79.799479\n31.992578\n0.471876\n33.240885\n0.348958\n\n\nstd\n3.369578\n31.972618\n19.355807\n15.952218\n115.244002\n7.884160\n0.331329\n11.760232\n0.476951\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.078000\n21.000000\n0.000000\n\n\n25%\n1.000000\n99.000000\n62.000000\n0.000000\n0.000000\n27.300000\n0.243750\n24.000000\n0.000000\n\n\n50%\n3.000000\n117.000000\n72.000000\n23.000000\n30.500000\n32.000000\n0.372500\n29.000000\n0.000000\n\n\n75%\n6.000000\n140.250000\n80.000000\n32.000000\n127.250000\n36.600000\n0.626250\n41.000000\n1.000000\n\n\nmax\n17.000000\n199.000000\n122.000000\n99.000000\n846.000000\n67.100000\n2.420000\n81.000000\n1.000000"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values\n\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship\n\nsns.histplot(data=data, x=\"BloodPressure\", kde=True)\n\n\n\n\n\n\n\n\n\nsns.countplot(data=data, x=\"Outcome\")\n\n\n\n\n\n\n\n\n\ndata.drop(data[data[\"BloodPressure\"]==0].index, inplace=True)\n\n\nsns.countplot(data=data, x=\"Outcome\")\n\n\n\n\n\n\n\n\n\nfeatures = [\n    \"Pregnancies\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"BMI\",\n    \"DiabetesPedigreeFunction\",\n    \"Age\"\n]\n\noutput = [\n    \"Outcome\"\n]"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data\n\nstandardScaler_features = StandardScaler().fit(data[features])\nstandardScaler_output = StandardScaler().fit(data[output])\n\nstandard_features = standardScaler_features.transform(data[features])\nstandard_output = data[output].values.reshape(-1,1)\n\n\nclass ConjuntoDatosTabulares(Dataset):\n  def __init__(self, ent, sal):\n    self.inputs = torch.tensor(ent, dtype=torch.float32)\n    self.outputs = torch.tensor(sal, dtype=torch.float32)\n\n  def __len__(self):\n    return len(self.inputs)\n\n  def __getitem__(self, idx):\n    return self.inputs[idx], self.outputs[idx]\n\n\n\nbs = 32  # Tamaño del lote\n\n\ntotal_data = ConjuntoDatosTabulares(ent=standard_features, sal=standard_output)\ntotal_data_dataloader = DataLoader(total_data, batch_size = 32, shuffle=True)\n\n\ntrain_ds, val_ds, test_ds = random_split(total_data, [0.56, 0.14, 0.3])\n\ntrain_loader = DataLoader(train_ds, batch_size = bs, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size = bs, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size = bs, shuffle=True)\n\n\na = next(iter(total_data_dataloader))\nx, y = a"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#create-neural-network",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#create-neural-network",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network",
    "text": "Create neural network\n\nclass RedNeuronal(nn.Module):\n  def __init__(self, num_caract, num_salidas):\n    super(RedNeuronal, self).__init__()\n    self.num_inputs = num_caract\n    self.num_outputs = num_salidas\n    self.hidden1 = nn.Linear(self.num_inputs, 10)\n    self.fact1 = nn.ReLU()\n    self.hidden2 = nn.Linear(10, 12)\n    self.fact2 = nn.ReLU()\n    self.hidden3 = nn.Linear(12, 13)\n    self.fact3 = nn.ReLU()\n    self.hidden4 = nn.Linear(13, self.num_outputs)\n    self.fact4 = nn.Sigmoid()\n\n  def forward(self, x):\n    x = self.fact1(self.hidden1(x))\n    x = self.fact2(self.hidden2(x))\n    x = self.fact3(self.hidden3(x))\n    x = self.fact4(self.hidden4(x))\n    return x"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model\n\nepocas = 1000  # Número de épocas de entrenamiento\n\n\nred = RedNeuronal(8, 1)\nred = red.to(device=device1)\n\n\nprint(red.parameters())\n\n&lt;generator object Module.parameters at 0x7fcf6518c190&gt;\n\n\n\ncriterio = nn.BCELoss()\noptimizador = optim.Adam(red.parameters(), lr=0.001)\n\n\n# Entrenar la red neuronal\nfor epoca in range(epocas):\n    perdida_entrenamiento = 0\n    for X_batch, y_batch in train_loader:\n        # Pasar los datos por la red neuronal\n        salida = red(X_batch.to(device=device1))\n\n        # Calcular la pérdida\n        perdida = criterio(salida, y_batch.to(device=device1))\n\n        # Actualizar los pesos\n        optimizador.zero_grad()\n        perdida.backward()\n        optimizador.step()\n        perdida_entrenamiento += perdida.item()\n\n    # Imprimir la pérdida en cada época\n    # print(f\"Época {epoca+1}, pérdida: {perdida.item():.8f}\")\n    perdida_validacion = 0\n    con_exactitud = 0\n    total = 0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            # Pasar los datos por la red neuronal\n            salida = red(X_batch.to(device=device1))\n\n            # Calcular la pérdida\n            perdida = criterio(salida, y_batch.to(device=device1))\n\n            perdida_validacion += perdida.item()\n\n    # Imprimir los resultados\n    print(f\"Época {epoca+1}\")\n    print(f\"Perdida entrenamiento: {perdida_entrenamiento/len(train_loader)}\")\n    print(f\"Perdida validación: {perdida_validacion/len(val_loader)}\")\n\nÉpoca 1\nPerdida entrenamiento: 0.7267978053826553\nPerdida validación: 0.7159790992736816\nÉpoca 2\nPerdida entrenamiento: 0.7182281980147729\nPerdida validación: 0.7118411660194397\nÉpoca 3\nPerdida entrenamiento: 0.7104145655265222\nPerdida validación: 0.7019551694393158\nÉpoca 4\nPerdida entrenamiento: 0.7015121854268588\nPerdida validación: 0.6946617513895035\nÉpoca 5\nPerdida entrenamiento: 0.6905638575553894\nPerdida validación: 0.6804916262626648\nÉpoca 6\nPerdida entrenamiento: 0.6800636832530682\nPerdida validación: 0.6584434807300568\nÉpoca 7\nPerdida entrenamiento: 0.6666435966124902\nPerdida validación: 0.6408872753381729\nÉpoca 8\nPerdida entrenamiento: 0.6524532116376437\nPerdida validación: 0.6386194676160812\nÉpoca 9\nPerdida entrenamiento: 0.6351055273642907\nPerdida validación: 0.602764829993248\nÉpoca 10\nPerdida entrenamiento: 0.6161944040885339\nPerdida validación: 0.5701538622379303\nÉpoca 11\nPerdida entrenamiento: 0.5947254254267766\nPerdida validación: 0.5622555166482925\nÉpoca 12\nPerdida entrenamiento: 0.5704072484603295\nPerdida validación: 0.5211050510406494\nÉpoca 13\nPerdida entrenamiento: 0.548466084095148\nPerdida validación: 0.480282261967659\nÉpoca 14\nPerdida entrenamiento: 0.5316605155284588\nPerdida validación: 0.4288185238838196\nÉpoca 15\nPerdida entrenamiento: 0.5179111269804147\nPerdida validación: 0.4584948718547821\nÉpoca 16\nPerdida entrenamiento: 0.5062230687875015\nPerdida validación: 0.4407348707318306\nÉpoca 17\nPerdida entrenamiento: 0.49960110966975874\nPerdida validación: 0.4830065444111824\nÉpoca 18\nPerdida entrenamiento: 0.49942563359554\nPerdida validación: 0.3943897932767868\nÉpoca 19\nPerdida entrenamiento: 0.48894316875017607\nPerdida validación: 0.4019322246313095\nÉpoca 20\nPerdida entrenamiento: 0.4884497339908893\nPerdida validación: 0.37546899914741516\nÉpoca 21\nPerdida entrenamiento: 0.4813868930706611\nPerdida validación: 0.39141348749399185\nÉpoca 22\nPerdida entrenamiento: 0.4776655458486997\nPerdida validación: 0.3661811575293541\nÉpoca 23\nPerdida entrenamiento: 0.47272541660528916\nPerdida validación: 0.45798082649707794\nÉpoca 24\nPerdida entrenamiento: 0.4703685755913074\nPerdida validación: 0.44551635533571243\nÉpoca 25\nPerdida entrenamiento: 0.46607735523810756\nPerdida validación: 0.4059871584177017\nÉpoca 26\nPerdida entrenamiento: 0.4660418469172258\nPerdida validación: 0.38415608555078506\nÉpoca 27\nPerdida entrenamiento: 0.4620107962534978\nPerdida validación: 0.4321253150701523\nÉpoca 28\nPerdida entrenamiento: 0.45929738879203796\nPerdida validación: 0.3779127597808838\nÉpoca 29\nPerdida entrenamiento: 0.4604421624770531\nPerdida validación: 0.39340754598379135\nÉpoca 30\nPerdida entrenamiento: 0.45797420465029204\nPerdida validación: 0.41168972104787827\nÉpoca 31\nPerdida entrenamiento: 0.453733898126162\nPerdida validación: 0.3659657798707485\nÉpoca 32\nPerdida entrenamiento: 0.4509870432890378\nPerdida validación: 0.35692010819911957\nÉpoca 33\nPerdida entrenamiento: 0.4491236439118019\nPerdida validación: 0.39127306640148163\nÉpoca 34\nPerdida entrenamiento: 0.44821084233430714\nPerdida validación: 0.4903676062822342\nÉpoca 35\nPerdida entrenamiento: 0.4483366654469417\nPerdida validación: 0.41949494183063507\nÉpoca 36\nPerdida entrenamiento: 0.4433157375225654\nPerdida validación: 0.3596146032214165\nÉpoca 37\nPerdida entrenamiento: 0.44532549610504735\nPerdida validación: 0.4067723825573921\nÉpoca 38\nPerdida entrenamiento: 0.441569637793761\nPerdida validación: 0.3658885098993778\nÉpoca 39\nPerdida entrenamiento: 0.4414483675589928\nPerdida validación: 0.36617711186408997\nÉpoca 40\nPerdida entrenamiento: 0.442814643566425\nPerdida validación: 0.43410953134298325\nÉpoca 41\nPerdida entrenamiento: 0.44105668709828305\nPerdida validación: 0.41927940398454666\nÉpoca 42\nPerdida entrenamiento: 0.4365276006551889\nPerdida validación: 0.4514813870191574\nÉpoca 43\nPerdida entrenamiento: 0.4371137320995331\nPerdida validación: 0.40512615442276\nÉpoca 44\nPerdida entrenamiento: 0.4338447176493131\nPerdida validación: 0.3971825987100601\nÉpoca 45\nPerdida entrenamiento: 0.4321022881911351\nPerdida validación: 0.4355890303850174\nÉpoca 46\nPerdida entrenamiento: 0.43205584012545073\nPerdida validación: 0.41393060982227325\nÉpoca 47\nPerdida entrenamiento: 0.4316117866681172\nPerdida validación: 0.3700167201459408\nÉpoca 48\nPerdida entrenamiento: 0.4322385054368239\nPerdida validación: 0.5200365260243416\nÉpoca 49\nPerdida entrenamiento: 0.4290507435798645\nPerdida validación: 0.4920997768640518\nÉpoca 50\nPerdida entrenamiento: 0.4292399768645947\nPerdida validación: 0.36969228461384773\nÉpoca 51\nPerdida entrenamiento: 0.42718150180119735\nPerdida validación: 0.4156232178211212\nÉpoca 52\nPerdida entrenamiento: 0.424829540344385\nPerdida validación: 0.4026588648557663\nÉpoca 53\nPerdida entrenamiento: 0.42635376636798566\nPerdida validación: 0.5363039597868919\nÉpoca 54\nPerdida entrenamiento: 0.42566425525225127\nPerdida validación: 0.3764454163610935\nÉpoca 55\nPerdida entrenamiento: 0.4237565237742204\nPerdida validación: 0.3808739259839058\nÉpoca 56\nPerdida entrenamiento: 0.4219471537149869\nPerdida validación: 0.4832487851381302\nÉpoca 57\nPerdida entrenamiento: 0.4212725300055284\nPerdida validación: 0.41617023199796677\nÉpoca 58\nPerdida entrenamiento: 0.4186098369268271\nPerdida validación: 0.3641137257218361\nÉpoca 59\nPerdida entrenamiento: 0.42065096359986526\nPerdida validación: 0.4038226157426834\nÉpoca 60\nPerdida entrenamiento: 0.41977634911353773\nPerdida validación: 0.38351573422551155\nÉpoca 61\nPerdida entrenamiento: 0.42114768578455997\nPerdida validación: 0.4520387575030327\nÉpoca 62\nPerdida entrenamiento: 0.4161078998675713\nPerdida validación: 0.393571600317955\nÉpoca 63\nPerdida entrenamiento: 0.4192577485854809\nPerdida validación: 0.41231170296669006\nÉpoca 64\nPerdida entrenamiento: 0.4160077480169443\nPerdida validación: 0.3934858366847038\nÉpoca 65\nPerdida entrenamiento: 0.41279572592331815\nPerdida validación: 0.3768220767378807\nÉpoca 66\nPerdida entrenamiento: 0.41775457904889035\nPerdida validación: 0.4513847976922989\nÉpoca 67\nPerdida entrenamiento: 0.4163452753653893\nPerdida validación: 0.4106815755367279\nÉpoca 68\nPerdida entrenamiento: 0.41231613205029416\nPerdida validación: 0.47492188960313797\nÉpoca 69\nPerdida entrenamiento: 0.41317373743424046\nPerdida validación: 0.3622148148715496\nÉpoca 70\nPerdida entrenamiento: 0.41339464027148026\nPerdida validación: 0.39243172109127045\nÉpoca 71\nPerdida entrenamiento: 0.41166099447470444\nPerdida validación: 0.4348529800772667\nÉpoca 72\nPerdida entrenamiento: 0.41057429634607756\nPerdida validación: 0.45380373299121857\nÉpoca 73\nPerdida entrenamiento: 0.40971608803822446\nPerdida validación: 0.43138349056243896\nÉpoca 74\nPerdida entrenamiento: 0.4103902509579292\nPerdida validación: 0.3543439395725727\nÉpoca 75\nPerdida entrenamiento: 0.41078854409547955\nPerdida validación: 0.4501536637544632\nÉpoca 76\nPerdida entrenamiento: 0.40908563137054443\nPerdida validación: 0.4332057163119316\nÉpoca 77\nPerdida entrenamiento: 0.40671666998129624\nPerdida validación: 0.47097714990377426\nÉpoca 78\nPerdida entrenamiento: 0.4092497917322012\nPerdida validación: 0.3809227794408798\nÉpoca 79\nPerdida entrenamiento: 0.40779951214790344\nPerdida validación: 0.39128022640943527\nÉpoca 80\nPerdida entrenamiento: 0.40222956010928523\nPerdida validación: 0.38470108062028885\nÉpoca 81\nPerdida entrenamiento: 0.40348539444116444\nPerdida validación: 0.3810441344976425\nÉpoca 82\nPerdida entrenamiento: 0.402382846062\nPerdida validación: 0.42453859001398087\nÉpoca 83\nPerdida entrenamiento: 0.4035201118542598\nPerdida validación: 0.42277510464191437\nÉpoca 84\nPerdida entrenamiento: 0.40302718602694\nPerdida validación: 0.4245646893978119\nÉpoca 85\nPerdida entrenamiento: 0.40186390509972203\nPerdida validación: 0.4499344155192375\nÉpoca 86\nPerdida entrenamiento: 0.40172262031298417\nPerdida validación: 0.49974845349788666\nÉpoca 87\nPerdida entrenamiento: 0.400823359306042\nPerdida validación: 0.425841860473156\nÉpoca 88\nPerdida entrenamiento: 0.39879807142110973\nPerdida validación: 0.3989344537258148\nÉpoca 89\nPerdida entrenamiento: 0.3981326176570012\nPerdida validación: 0.4065830484032631\nÉpoca 90\nPerdida entrenamiento: 0.3998530392463391\nPerdida validación: 0.39869045466184616\nÉpoca 91\nPerdida entrenamiento: 0.39560900972439694\nPerdida validación: 0.37907231599092484\nÉpoca 92\nPerdida entrenamiento: 0.3956319529276628\nPerdida validación: 0.3895183838903904\nÉpoca 93\nPerdida entrenamiento: 0.3948855010362772\nPerdida validación: 0.40453095734119415\nÉpoca 94\nPerdida entrenamiento: 0.3942739229935866\nPerdida validación: 0.42533183097839355\nÉpoca 95\nPerdida entrenamiento: 0.39367732405662537\nPerdida validación: 0.49657849967479706\nÉpoca 96\nPerdida entrenamiento: 0.39477550295683056\nPerdida validación: 0.42017025500535965\nÉpoca 97\nPerdida entrenamiento: 0.39310317773085374\nPerdida validación: 0.38999152556061745\nÉpoca 98\nPerdida entrenamiento: 0.3917583009371391\nPerdida validación: 0.43369147926568985\nÉpoca 99\nPerdida entrenamiento: 0.38949758960650516\nPerdida validación: 0.4349787309765816\nÉpoca 100\nPerdida entrenamiento: 0.39008616025631243\nPerdida validación: 0.395715843886137\nÉpoca 101\nPerdida entrenamiento: 0.38877419783518863\nPerdida validación: 0.36947037652134895\nÉpoca 102\nPerdida entrenamiento: 0.39078972202080947\nPerdida validación: 0.4100741744041443\nÉpoca 103\nPerdida entrenamiento: 0.39032559669934785\nPerdida validación: 0.42708979547023773\nÉpoca 104\nPerdida entrenamiento: 0.3895266938668031\nPerdida validación: 0.4977172240614891\nÉpoca 105\nPerdida entrenamiento: 0.3862973955961374\nPerdida validación: 0.4343803748488426\nÉpoca 106\nPerdida entrenamiento: 0.38772000716282773\nPerdida validación: 0.4120924770832062\nÉpoca 107\nPerdida entrenamiento: 0.387257273380573\nPerdida validación: 0.46935633569955826\nÉpoca 108\nPerdida entrenamiento: 0.3854876779592954\nPerdida validación: 0.4736231788992882\nÉpoca 109\nPerdida entrenamiento: 0.3852063004787152\nPerdida validación: 0.4230464696884155\nÉpoca 110\nPerdida entrenamiento: 0.3828760408438169\nPerdida validación: 0.5397054925560951\nÉpoca 111\nPerdida entrenamiento: 0.3831189355024925\nPerdida validación: 0.43693213164806366\nÉpoca 112\nPerdida entrenamiento: 0.3818291677878453\nPerdida validación: 0.39886316657066345\nÉpoca 113\nPerdida entrenamiento: 0.38133204671052784\nPerdida validación: 0.4186994433403015\nÉpoca 114\nPerdida entrenamiento: 0.38088562855353725\nPerdida validación: 0.39437006786465645\nÉpoca 115\nPerdida entrenamiento: 0.38014946763332075\nPerdida validación: 0.42200181633234024\nÉpoca 116\nPerdida entrenamiento: 0.3776790407987741\nPerdida validación: 0.3852379620075226\nÉpoca 117\nPerdida entrenamiento: 0.37825816640487087\nPerdida validación: 0.4611133188009262\nÉpoca 118\nPerdida entrenamiento: 0.3772958150276771\nPerdida validación: 0.38224026188254356\nÉpoca 119\nPerdida entrenamiento: 0.3778039331619556\nPerdida validación: 0.4286082088947296\nÉpoca 120\nPerdida entrenamiento: 0.3743162567798908\nPerdida validación: 0.39137063175439835\nÉpoca 121\nPerdida entrenamiento: 0.3749724511916821\nPerdida validación: 0.4739982336759567\nÉpoca 122\nPerdida entrenamiento: 0.37313790504749006\nPerdida validación: 0.39009249955415726\nÉpoca 123\nPerdida entrenamiento: 0.3736418072993939\nPerdida validación: 0.48800554871559143\nÉpoca 124\nPerdida entrenamiento: 0.3741052127801455\nPerdida validación: 0.4744153171777725\nÉpoca 125\nPerdida entrenamiento: 0.37422877779373753\nPerdida validación: 0.43327439576387405\nÉpoca 126\nPerdida entrenamiento: 0.371814754146796\nPerdida validación: 0.4883398041129112\nÉpoca 127\nPerdida entrenamiento: 0.3707105219364166\nPerdida validación: 0.4257439374923706\nÉpoca 128\nPerdida entrenamiento: 0.3705435876662915\nPerdida validación: 0.4996122717857361\nÉpoca 129\nPerdida entrenamiento: 0.36863908630151015\nPerdida validación: 0.44596949219703674\nÉpoca 130\nPerdida entrenamiento: 0.36837688088417053\nPerdida validación: 0.5108792632818222\nÉpoca 131\nPerdida entrenamiento: 0.3644952911597032\nPerdida validación: 0.4148697182536125\nÉpoca 132\nPerdida entrenamiento: 0.3676655269586123\nPerdida validación: 0.4180637337267399\nÉpoca 133\nPerdida entrenamiento: 0.36441197762122524\nPerdida validación: 0.4463004618883133\nÉpoca 134\nPerdida entrenamiento: 0.364000148498095\nPerdida validación: 0.45392312854528427\nÉpoca 135\nPerdida entrenamiento: 0.3633742378308223\nPerdida validación: 0.5120198130607605\nÉpoca 136\nPerdida entrenamiento: 0.36356962414888233\nPerdida validación: 0.5091618970036507\nÉpoca 137\nPerdida entrenamiento: 0.3639798118517949\nPerdida validación: 0.4719684571027756\nÉpoca 138\nPerdida entrenamiento: 0.3627295471154727\nPerdida validación: 0.44826727360486984\nÉpoca 139\nPerdida entrenamiento: 0.3609895293529217\nPerdida validación: 0.4631754010915756\nÉpoca 140\nPerdida entrenamiento: 0.3619653765971844\nPerdida validación: 0.5464806333184242\nÉpoca 141\nPerdida entrenamiento: 0.3585687061915031\nPerdida validación: 0.5189626067876816\nÉpoca 142\nPerdida entrenamiento: 0.3566366388247563\nPerdida validación: 0.46764953434467316\nÉpoca 143\nPerdida entrenamiento: 0.36353538128045887\nPerdida validación: 0.46592652797698975\nÉpoca 144\nPerdida entrenamiento: 0.35643438536387223\nPerdida validación: 0.43039967119693756\nÉpoca 145\nPerdida entrenamiento: 0.35604520256702715\nPerdida validación: 0.5149550661444664\nÉpoca 146\nPerdida entrenamiento: 0.35637769676171815\nPerdida validación: 0.4144183583557606\nÉpoca 147\nPerdida entrenamiento: 0.355108747115502\nPerdida validación: 0.4768465459346771\nÉpoca 148\nPerdida entrenamiento: 0.35542476864961475\nPerdida validación: 0.4844294711947441\nÉpoca 149\nPerdida entrenamiento: 0.3519860024635608\nPerdida validación: 0.4547104239463806\nÉpoca 150\nPerdida entrenamiento: 0.3521421987276811\nPerdida validación: 0.466669999063015\nÉpoca 151\nPerdida entrenamiento: 0.3548166167277556\nPerdida validación: 0.5513210147619247\nÉpoca 152\nPerdida entrenamiento: 0.35027686334573305\nPerdida validación: 0.5020348504185677\nÉpoca 153\nPerdida entrenamiento: 0.34959811774583965\nPerdida validación: 0.5455379039049149\nÉpoca 154\nPerdida entrenamiento: 0.3523002461745189\nPerdida validación: 0.47232835739851\nÉpoca 155\nPerdida entrenamiento: 0.35344558495741624\nPerdida validación: 0.5145654082298279\nÉpoca 156\nPerdida entrenamiento: 0.3485158762106529\nPerdida validación: 0.486834391951561\nÉpoca 157\nPerdida entrenamiento: 0.34897099549953753\nPerdida validación: 0.5043940991163254\nÉpoca 158\nPerdida entrenamiento: 0.34723360263384306\nPerdida validación: 0.5066465809941292\nÉpoca 159\nPerdida entrenamiento: 0.34640762439140904\nPerdida validación: 0.5473715737462044\nÉpoca 160\nPerdida entrenamiento: 0.34859538536805373\nPerdida validación: 0.4481390565633774\nÉpoca 161\nPerdida entrenamiento: 0.3447049787411323\nPerdida validación: 0.424229035153985\nÉpoca 162\nPerdida entrenamiento: 0.34568210060779864\nPerdida validación: 0.4851425141096115\nÉpoca 163\nPerdida entrenamiento: 0.3433854981110646\nPerdida validación: 0.48836609721183777\nÉpoca 164\nPerdida entrenamiento: 0.3420627174469141\nPerdida validación: 0.509034663438797\nÉpoca 165\nPerdida entrenamiento: 0.34017568826675415\nPerdida validación: 0.6002066135406494\nÉpoca 166\nPerdida entrenamiento: 0.34276773035526276\nPerdida validación: 0.52107934653759\nÉpoca 167\nPerdida entrenamiento: 0.34077843106709993\nPerdida validación: 0.48411911725997925\nÉpoca 168\nPerdida entrenamiento: 0.3387271555570456\nPerdida validación: 0.446561835706234\nÉpoca 169\nPerdida entrenamiento: 0.34064857547099775\nPerdida validación: 0.4455733299255371\nÉpoca 170\nPerdida entrenamiento: 0.3393576191021846\nPerdida validación: 0.4353795200586319\nÉpoca 171\nPerdida entrenamiento: 0.34231315094691056\nPerdida validación: 0.4627293348312378\nÉpoca 172\nPerdida entrenamiento: 0.3361229976782432\nPerdida validación: 0.5688041225075722\nÉpoca 173\nPerdida entrenamiento: 0.33672307087824893\nPerdida validación: 0.45936134085059166\nÉpoca 174\nPerdida entrenamiento: 0.33723970445302814\nPerdida validación: 0.5437187701463699\nÉpoca 175\nPerdida entrenamiento: 0.3378218343624702\nPerdida validación: 0.6265709698200226\nÉpoca 176\nPerdida entrenamiento: 0.3348902968259958\nPerdida validación: 0.4678940027952194\nÉpoca 177\nPerdida entrenamiento: 0.33359681299099553\nPerdida validación: 0.49202893674373627\nÉpoca 178\nPerdida entrenamiento: 0.3337265390616197\nPerdida validación: 0.46057265624403954\nÉpoca 179\nPerdida entrenamiento: 0.33145728134191954\nPerdida validación: 0.5372823402285576\nÉpoca 180\nPerdida entrenamiento: 0.33341708091589123\nPerdida validación: 0.4422183372080326\nÉpoca 181\nPerdida entrenamiento: 0.3310887057047624\nPerdida validación: 0.7397722750902176\nÉpoca 182\nPerdida entrenamiento: 0.32945447243176973\nPerdida validación: 0.4633013419806957\nÉpoca 183\nPerdida entrenamiento: 0.32728753983974457\nPerdida validación: 0.4701136499643326\nÉpoca 184\nPerdida entrenamiento: 0.3269531589287978\nPerdida validación: 0.5811994299292564\nÉpoca 185\nPerdida entrenamiento: 0.3289144921761293\nPerdida validación: 0.6501174867153168\nÉpoca 186\nPerdida entrenamiento: 0.3250019389849443\nPerdida validación: 0.48658087104558945\nÉpoca 187\nPerdida entrenamiento: 0.3252809208173018\nPerdida validación: 0.5948077514767647\nÉpoca 188\nPerdida entrenamiento: 0.32456459448887753\nPerdida validación: 0.5170600488781929\nÉpoca 189\nPerdida entrenamiento: 0.3248377591371536\nPerdida validación: 0.5801271125674248\nÉpoca 190\nPerdida entrenamiento: 0.3258056640625\nPerdida validación: 0.5002523139119148\nÉpoca 191\nPerdida entrenamiento: 0.3205260726121756\nPerdida validación: 0.7138897553086281\nÉpoca 192\nPerdida entrenamiento: 0.3199167068188007\nPerdida validación: 0.5612407624721527\nÉpoca 193\nPerdida entrenamiento: 0.31928349229005665\nPerdida validación: 0.6081007793545723\nÉpoca 194\nPerdida entrenamiento: 0.3201474203513219\nPerdida validación: 0.5727706551551819\nÉpoca 195\nPerdida entrenamiento: 0.3193618678129636\nPerdida validación: 0.47843847796320915\nÉpoca 196\nPerdida entrenamiento: 0.3186295720247122\nPerdida validación: 0.5062254294753075\nÉpoca 197\nPerdida entrenamiento: 0.3170779118171105\nPerdida validación: 0.6240173578262329\nÉpoca 198\nPerdida entrenamiento: 0.31651219954857457\nPerdida validación: 0.733600378036499\nÉpoca 199\nPerdida entrenamiento: 0.31591541492022\nPerdida validación: 0.5893783569335938\nÉpoca 200\nPerdida entrenamiento: 0.31407135954269993\nPerdida validación: 0.672258049249649\nÉpoca 201\nPerdida entrenamiento: 0.3167167156934738\nPerdida validación: 0.5906193181872368\nÉpoca 202\nPerdida entrenamiento: 0.31775486125395846\nPerdida validación: 0.6703383028507233\nÉpoca 203\nPerdida entrenamiento: 0.3142982469155238\nPerdida validación: 0.493832191452384\nÉpoca 204\nPerdida entrenamiento: 0.3143202100808804\nPerdida validación: 0.6293051838874817\nÉpoca 205\nPerdida entrenamiento: 0.3154367025081928\nPerdida validación: 0.5778104141354561\nÉpoca 206\nPerdida entrenamiento: 0.312066729252155\nPerdida validación: 0.5893872007727623\nÉpoca 207\nPerdida entrenamiento: 0.3136929445541822\nPerdida validación: 0.516918983310461\nÉpoca 208\nPerdida entrenamiento: 0.30938355510051435\nPerdida validación: 0.582847073674202\nÉpoca 209\nPerdida entrenamiento: 0.3098432135123473\nPerdida validación: 0.5286299884319305\nÉpoca 210\nPerdida entrenamiento: 0.3081144358103092\nPerdida validación: 0.5873531252145767\nÉpoca 211\nPerdida entrenamiento: 0.3083389034638038\nPerdida validación: 0.602348081767559\nÉpoca 212\nPerdida entrenamiento: 0.3055564474601012\nPerdida validación: 0.6705131381750107\nÉpoca 213\nPerdida entrenamiento: 0.30720986884373885\nPerdida validación: 0.6529285907745361\nÉpoca 214\nPerdida entrenamiento: 0.3054585216137079\nPerdida validación: 0.6688360720872879\nÉpoca 215\nPerdida entrenamiento: 0.30763639509677887\nPerdida validación: 0.5135140027850866\nÉpoca 216\nPerdida entrenamiento: 0.303421927186159\nPerdida validación: 0.5739713087677956\nÉpoca 217\nPerdida entrenamiento: 0.3031972520626508\nPerdida validación: 0.5670073255896568\nÉpoca 218\nPerdida entrenamiento: 0.30217409363159764\nPerdida validación: 0.592064693570137\nÉpoca 219\nPerdida entrenamiento: 0.30135699533499205\nPerdida validación: 0.636160098016262\nÉpoca 220\nPerdida entrenamiento: 0.3016016884491994\nPerdida validación: 0.5606770887970924\nÉpoca 221\nPerdida entrenamiento: 0.3024453268601344\nPerdida validación: 0.5745292976498604\nÉpoca 222\nPerdida entrenamiento: 0.3018904064710324\nPerdida validación: 0.7433184385299683\nÉpoca 223\nPerdida entrenamiento: 0.2971323464925473\nPerdida validación: 0.740757018327713\nÉpoca 224\nPerdida entrenamiento: 0.2984556464048532\nPerdida validación: 0.5652462765574455\nÉpoca 225\nPerdida entrenamiento: 0.29587332101968616\nPerdida validación: 0.5960354954004288\nÉpoca 226\nPerdida entrenamiento: 0.298045168702419\nPerdida validación: 0.6095506846904755\nÉpoca 227\nPerdida entrenamiento: 0.2962602503024615\nPerdida validación: 0.8097492754459381\nÉpoca 228\nPerdida entrenamiento: 0.29590065891926104\nPerdida validación: 0.642509862780571\nÉpoca 229\nPerdida entrenamiento: 0.29353805115589726\nPerdida validación: 0.6805313527584076\nÉpoca 230\nPerdida entrenamiento: 0.2950842518072862\nPerdida validación: 0.5805027037858963\nÉpoca 231\nPerdida entrenamiento: 0.2943579313846735\nPerdida validación: 0.5456069093197584\nÉpoca 232\nPerdida entrenamiento: 0.293004646897316\nPerdida validación: 0.5370007765013725\nÉpoca 233\nPerdida entrenamiento: 0.2904043530042355\nPerdida validación: 0.627612516283989\nÉpoca 234\nPerdida entrenamiento: 0.2912729737850336\nPerdida validación: 0.7116727158427238\nÉpoca 235\nPerdida entrenamiento: 0.28903550253464627\nPerdida validación: 0.660587415099144\nÉpoca 236\nPerdida entrenamiento: 0.28757661695663744\nPerdida validación: 0.5772789008915424\nÉpoca 237\nPerdida entrenamiento: 0.28811851946207195\nPerdida validación: 0.7320586889982224\nÉpoca 238\nPerdida entrenamiento: 0.28815625779903853\nPerdida validación: 0.7152724415063858\nÉpoca 239\nPerdida entrenamiento: 0.28606483340263367\nPerdida validación: 0.6598239541053772\nÉpoca 240\nPerdida entrenamiento: 0.285346840436642\nPerdida validación: 0.6209026128053665\nÉpoca 241\nPerdida entrenamiento: 0.2845807350598849\nPerdida validación: 0.7468656450510025\nÉpoca 242\nPerdida entrenamiento: 0.2821243279255353\nPerdida validación: 0.7041357904672623\nÉpoca 243\nPerdida entrenamiento: 0.28611129178450656\nPerdida validación: 0.6743378043174744\nÉpoca 244\nPerdida entrenamiento: 0.284884695823376\nPerdida validación: 0.6707199811935425\nÉpoca 245\nPerdida entrenamiento: 0.2815088893358524\nPerdida validación: 0.5728727634996176\nÉpoca 246\nPerdida entrenamiento: 0.28080847744758314\nPerdida validación: 0.6702363193035126\nÉpoca 247\nPerdida entrenamiento: 0.2867404520511627\nPerdida validación: 0.5843783281743526\nÉpoca 248\nPerdida entrenamiento: 0.2806525001159081\nPerdida validación: 0.7861420884728432\nÉpoca 249\nPerdida entrenamiento: 0.27863137194743526\nPerdida validación: 0.6410687640309334\nÉpoca 250\nPerdida entrenamiento: 0.2770683398613563\nPerdida validación: 0.5936639066785574\nÉpoca 251\nPerdida entrenamiento: 0.2768169263234505\nPerdida validación: 0.6833072006702423\nÉpoca 252\nPerdida entrenamiento: 0.2748305465166385\nPerdida validación: 0.6042004376649857\nÉpoca 253\nPerdida entrenamiento: 0.2757860215810629\nPerdida validación: 0.7947159111499786\nÉpoca 254\nPerdida entrenamiento: 0.2751406201949486\nPerdida validación: 0.6367254927754402\nÉpoca 255\nPerdida entrenamiento: 0.2708621449195422\nPerdida validación: 0.7180898785591125\nÉpoca 256\nPerdida entrenamiento: 0.275149221603687\nPerdida validación: 0.7423695474863052\nÉpoca 257\nPerdida entrenamiento: 0.2727271203811352\nPerdida validación: 0.9060819447040558\nÉpoca 258\nPerdida entrenamiento: 0.2681584942799348\nPerdida validación: 0.5963035766035318\nÉpoca 259\nPerdida entrenamiento: 0.27062331025417036\nPerdida validación: 0.873478040099144\nÉpoca 260\nPerdida entrenamiento: 0.2674179868056224\nPerdida validación: 0.8986184149980545\nÉpoca 261\nPerdida entrenamiento: 0.2690170338520637\nPerdida validación: 0.6592900529503822\nÉpoca 262\nPerdida entrenamiento: 0.26846447587013245\nPerdida validación: 0.9479366093873978\nÉpoca 263\nPerdida entrenamiento: 0.26402759552001953\nPerdida validación: 0.9008272737264633\nÉpoca 264\nPerdida entrenamiento: 0.2652583489051232\nPerdida validación: 0.6301005408167839\nÉpoca 265\nPerdida entrenamiento: 0.2668720644253951\nPerdida validación: 0.6739533171057701\nÉpoca 266\nPerdida entrenamiento: 0.261234122973222\nPerdida validación: 0.8646781742572784\nÉpoca 267\nPerdida entrenamiento: 0.26453658250662\nPerdida validación: 0.6588940024375916\nÉpoca 268\nPerdida entrenamiento: 0.2624517106092893\nPerdida validación: 0.6618993282318115\nÉpoca 269\nPerdida entrenamiento: 0.26085009712439317\nPerdida validación: 0.8263240605592728\nÉpoca 270\nPerdida entrenamiento: 0.2599637359380722\nPerdida validación: 0.6784602850675583\nÉpoca 271\nPerdida entrenamiento: 0.257305567081158\nPerdida validación: 0.6983089298009872\nÉpoca 272\nPerdida entrenamiento: 0.25707618319071257\nPerdida validación: 0.7596462219953537\nÉpoca 273\nPerdida entrenamiento: 0.25479228565326106\nPerdida validación: 0.8516096025705338\nÉpoca 274\nPerdida entrenamiento: 0.2555289314343379\nPerdida validación: 0.6697004027664661\nÉpoca 275\nPerdida entrenamiento: 0.25535631752931154\nPerdida validación: 0.7662394493818283\nÉpoca 276\nPerdida entrenamiento: 0.25399595499038696\nPerdida validación: 0.6714568100869656\nÉpoca 277\nPerdida entrenamiento: 0.2534373849630356\nPerdida validación: 0.8177104741334915\nÉpoca 278\nPerdida entrenamiento: 0.2528454798918504\nPerdida validación: 0.6949421167373657\nÉpoca 279\nPerdida entrenamiento: 0.2524537363877663\nPerdida validación: 0.6863048002123833\nÉpoca 280\nPerdida entrenamiento: 0.2513547700185042\nPerdida validación: 0.9646367728710175\nÉpoca 281\nPerdida entrenamiento: 0.25098807078141433\nPerdida validación: 0.8969951719045639\nÉpoca 282\nPerdida entrenamiento: 0.2472042705004032\nPerdida validación: 0.8082799464464188\nÉpoca 283\nPerdida entrenamiento: 0.24754732789901587\nPerdida validación: 0.7941425144672394\nÉpoca 284\nPerdida entrenamiento: 0.24609676003456116\nPerdida validación: 0.684365876019001\nÉpoca 285\nPerdida entrenamiento: 0.2511652432955228\nPerdida validación: 0.8623279631137848\nÉpoca 286\nPerdida entrenamiento: 0.24547406687186316\nPerdida validación: 0.6912081725895405\nÉpoca 287\nPerdida entrenamiento: 0.2429599383702645\nPerdida validación: 0.9732776954770088\nÉpoca 288\nPerdida entrenamiento: 0.2432185262441635\nPerdida validación: 1.0060452669858932\nÉpoca 289\nPerdida entrenamiento: 0.24023229227616236\nPerdida validación: 0.8277311474084854\nÉpoca 290\nPerdida entrenamiento: 0.23955060427005476\nPerdida validación: 0.786811426281929\nÉpoca 291\nPerdida entrenamiento: 0.23958009022932786\nPerdida validación: 0.7557588405907154\nÉpoca 292\nPerdida entrenamiento: 0.23640594402184853\nPerdida validación: 0.8277218341827393\nÉpoca 293\nPerdida entrenamiento: 0.242647141791307\nPerdida validación: 0.7543492093682289\nÉpoca 294\nPerdida entrenamiento: 0.23744144004124862\nPerdida validación: 0.9005269259214401\nÉpoca 295\nPerdida entrenamiento: 0.23505891057161185\nPerdida validación: 1.0138403475284576\nÉpoca 296\nPerdida entrenamiento: 0.23421819106890604\nPerdida validación: 0.8683191686868668\nÉpoca 297\nPerdida entrenamiento: 0.2318978040264203\nPerdida validación: 0.8101358413696289\nÉpoca 298\nPerdida entrenamiento: 0.23346705046983865\nPerdida validación: 0.7712786123156548\nÉpoca 299\nPerdida entrenamiento: 0.23196385686214155\nPerdida validación: 0.7931528687477112\nÉpoca 300\nPerdida entrenamiento: 0.23038125955141509\nPerdida validación: 0.9017031192779541\nÉpoca 301\nPerdida entrenamiento: 0.2300905608213865\nPerdida validación: 0.8927458971738815\nÉpoca 302\nPerdida entrenamiento: 0.22902650099534255\nPerdida validación: 0.7802269160747528\nÉpoca 303\nPerdida entrenamiento: 0.22824548184871674\nPerdida validación: 0.7526897303760052\nÉpoca 304\nPerdida entrenamiento: 0.22763773340445298\nPerdida validación: 0.8381522595882416\nÉpoca 305\nPerdida entrenamiento: 0.22718356033930412\nPerdida validación: 0.8254359364509583\nÉpoca 306\nPerdida entrenamiento: 0.22468459835419288\nPerdida validación: 1.0651862174272537\nÉpoca 307\nPerdida entrenamiento: 0.2252236008644104\nPerdida validación: 0.7800127901136875\nÉpoca 308\nPerdida entrenamiento: 0.22522478034863105\nPerdida validación: 0.7735980823636055\nÉpoca 309\nPerdida entrenamiento: 0.22313766926527023\nPerdida validación: 0.9621244966983795\nÉpoca 310\nPerdida entrenamiento: 0.22204241729699647\nPerdida validación: 1.0749974250793457\nÉpoca 311\nPerdida entrenamiento: 0.22262436610001785\nPerdida validación: 1.3250411748886108\nÉpoca 312\nPerdida entrenamiento: 0.21946634925328767\nPerdida validación: 1.220914050936699\nÉpoca 313\nPerdida entrenamiento: 0.2192572527206861\nPerdida validación: 1.041431501507759\nÉpoca 314\nPerdida entrenamiento: 0.22139415374168983\nPerdida validación: 0.8025665357708931\nÉpoca 315\nPerdida entrenamiento: 0.21974669626125923\nPerdida validación: 0.8422096148133278\nÉpoca 316\nPerdida entrenamiento: 0.21913381665945053\nPerdida validación: 0.8897643834352493\nÉpoca 317\nPerdida entrenamiento: 0.21626591223936814\nPerdida validación: 1.055869460105896\nÉpoca 318\nPerdida entrenamiento: 0.21514099263227904\nPerdida validación: 1.1917777508497238\nÉpoca 319\nPerdida entrenamiento: 0.21370321741470924\nPerdida validación: 1.0201979875564575\nÉpoca 320\nPerdida entrenamiento: 0.21699885450876677\nPerdida validación: 0.8245937786996365\nÉpoca 321\nPerdida entrenamiento: 0.21201098309113428\nPerdida validación: 1.1265588402748108\nÉpoca 322\nPerdida entrenamiento: 0.21394624962256506\nPerdida validación: 0.962070643901825\nÉpoca 323\nPerdida entrenamiento: 0.20957350157774413\nPerdida validación: 0.9868338853120804\nÉpoca 324\nPerdida entrenamiento: 0.21265120231188261\nPerdida validación: 0.8874924257397652\nÉpoca 325\nPerdida entrenamiento: 0.2091066837310791\nPerdida validación: 1.0081952214241028\nÉpoca 326\nPerdida entrenamiento: 0.21077775267454293\nPerdida validación: 0.8385808542370796\nÉpoca 327\nPerdida entrenamiento: 0.20795948058366776\nPerdida validación: 0.8538511730730534\nÉpoca 328\nPerdida entrenamiento: 0.20780498018631569\nPerdida validación: 0.9103939160704613\nÉpoca 329\nPerdida entrenamiento: 0.20708075280372912\nPerdida validación: 1.1897397637367249\nÉpoca 330\nPerdida entrenamiento: 0.20662683363144213\nPerdida validación: 0.885913148522377\nÉpoca 331\nPerdida entrenamiento: 0.20712659450677726\nPerdida validación: 1.0818254053592682\nÉpoca 332\nPerdida entrenamiento: 0.20439559909013602\nPerdida validación: 1.0768046230077744\nÉpoca 333\nPerdida entrenamiento: 0.20461885745708758\nPerdida validación: 0.9814814329147339\nÉpoca 334\nPerdida entrenamiento: 0.20301808130282623\nPerdida validación: 1.1490432769060135\nÉpoca 335\nPerdida entrenamiento: 0.2035538857946029\nPerdida validación: 1.178459957242012\nÉpoca 336\nPerdida entrenamiento: 0.20196825036635765\nPerdida validación: 1.0208635181188583\nÉpoca 337\nPerdida entrenamiento: 0.20007529854774475\nPerdida validación: 0.8982732370495796\nÉpoca 338\nPerdida entrenamiento: 0.20441429087748894\nPerdida validación: 1.2766572535037994\nÉpoca 339\nPerdida entrenamiento: 0.19922098345481432\nPerdida validación: 1.2669693678617477\nÉpoca 340\nPerdida entrenamiento: 0.20049226914460844\nPerdida validación: 1.1927863359451294\nÉpoca 341\nPerdida entrenamiento: 0.19930510165599677\nPerdida validación: 1.1106315851211548\nÉpoca 342\nPerdida entrenamiento: 0.1986603576403398\nPerdida validación: 0.9161171913146973\nÉpoca 343\nPerdida entrenamiento: 0.1980497338450872\nPerdida validación: 0.8788779089227319\nÉpoca 344\nPerdida entrenamiento: 0.19675294711039618\nPerdida validación: 0.926335796713829\nÉpoca 345\nPerdida entrenamiento: 0.1941346635039036\nPerdida validación: 1.0945035070180893\nÉpoca 346\nPerdida entrenamiento: 0.1936252420911422\nPerdida validación: 1.0377127081155777\nÉpoca 347\nPerdida entrenamiento: 0.19242666776363665\nPerdida validación: 1.2945685386657715\nÉpoca 348\nPerdida entrenamiento: 0.19187256120718443\nPerdida validación: 1.0255257040262222\nÉpoca 349\nPerdida entrenamiento: 0.19146961661485526\nPerdida validación: 1.3043287247419357\nÉpoca 350\nPerdida entrenamiento: 0.19094201062734312\nPerdida validación: 0.9868040531873703\nÉpoca 351\nPerdida entrenamiento: 0.1926536777844796\nPerdida validación: 0.9217413030564785\nÉpoca 352\nPerdida entrenamiento: 0.1905878747885044\nPerdida validación: 0.9125046692788601\nÉpoca 353\nPerdida entrenamiento: 0.187868713759459\nPerdida validación: 0.9345213063061237\nÉpoca 354\nPerdida entrenamiento: 0.18901339631814223\nPerdida validación: 0.9942605942487717\nÉpoca 355\nPerdida entrenamiento: 0.18814368947194174\nPerdida validación: 0.9075269959867001\nÉpoca 356\nPerdida entrenamiento: 0.18838231953290793\nPerdida validación: 1.0101798176765442\nÉpoca 357\nPerdida entrenamiento: 0.1871264118414659\nPerdida validación: 1.3163970857858658\nÉpoca 358\nPerdida entrenamiento: 0.18556923533861452\nPerdida validación: 1.1430521309375763\nÉpoca 359\nPerdida entrenamiento: 0.18438442624532259\nPerdida validación: 1.0945535898208618\nÉpoca 360\nPerdida entrenamiento: 0.18359505041287497\nPerdida validación: 1.1046949326992035\nÉpoca 361\nPerdida entrenamiento: 0.18347960653213355\nPerdida validación: 1.0777917206287384\nÉpoca 362\nPerdida entrenamiento: 0.18606625038843888\nPerdida validación: 1.039321780204773\nÉpoca 363\nPerdida entrenamiento: 0.1835288187632194\nPerdida validación: 1.8219835758209229\nÉpoca 364\nPerdida entrenamiento: 0.1832315560716849\nPerdida validación: 0.9855913817882538\nÉpoca 365\nPerdida entrenamiento: 0.18345200499662986\nPerdida validación: 1.3815755248069763\nÉpoca 366\nPerdida entrenamiento: 0.18204493877979425\nPerdida validación: 1.3143933415412903\nÉpoca 367\nPerdida entrenamiento: 0.18039714430387205\nPerdida validación: 1.1001662760972977\nÉpoca 368\nPerdida entrenamiento: 0.1790039367400683\nPerdida validación: 1.1200962960720062\nÉpoca 369\nPerdida entrenamiento: 0.17842322817215553\nPerdida validación: 1.248393177986145\nÉpoca 370\nPerdida entrenamiento: 0.17733524567805803\nPerdida validación: 1.1019806116819382\nÉpoca 371\nPerdida entrenamiento: 0.18092230707406998\nPerdida validación: 1.0071088895201683\nÉpoca 372\nPerdida entrenamiento: 0.1787138833449437\nPerdida validación: 0.9970914125442505\nÉpoca 373\nPerdida entrenamiento: 0.17536774850808656\nPerdida validación: 1.2062337547540665\nÉpoca 374\nPerdida entrenamiento: 0.1755595069665175\nPerdida validación: 1.2552458047866821\nÉpoca 375\nPerdida entrenamiento: 0.17521371291233942\nPerdida validación: 1.3755380511283875\nÉpoca 376\nPerdida entrenamiento: 0.17484821493809038\nPerdida validación: 0.9694990161806345\nÉpoca 377\nPerdida entrenamiento: 0.16993199575405854\nPerdida validación: 1.2601993381977081\nÉpoca 378\nPerdida entrenamiento: 0.17217573007711998\nPerdida validación: 1.0045286491513252\nÉpoca 379\nPerdida entrenamiento: 0.16950746167164582\nPerdida validación: 1.0718081295490265\nÉpoca 380\nPerdida entrenamiento: 0.17159914741149315\nPerdida validación: 1.4655284881591797\nÉpoca 381\nPerdida entrenamiento: 0.16838658973574638\nPerdida validación: 1.1533843874931335\nÉpoca 382\nPerdida entrenamiento: 0.17031876341654703\nPerdida validación: 0.9962851293385029\nÉpoca 383\nPerdida entrenamiento: 0.16913885737840945\nPerdida validación: 1.7159227132797241\nÉpoca 384\nPerdida entrenamiento: 0.16765954746649817\nPerdida validación: 1.159842073917389\nÉpoca 385\nPerdida entrenamiento: 0.1671962749499541\nPerdida validación: 1.4913894534111023\nÉpoca 386\nPerdida entrenamiento: 0.1681254764015858\nPerdida validación: 1.122810274362564\nÉpoca 387\nPerdida entrenamiento: 0.165319480575048\nPerdida validación: 1.54014253616333\nÉpoca 388\nPerdida entrenamiento: 0.16413759382871482\nPerdida validación: 1.1817348301410675\nÉpoca 389\nPerdida entrenamiento: 0.1640704136628371\nPerdida validación: 1.2460854202508926\nÉpoca 390\nPerdida entrenamiento: 0.16306643531872675\nPerdida validación: 1.609892874956131\nÉpoca 391\nPerdida entrenamiento: 0.16301732109143183\nPerdida validación: 1.4515731483697891\nÉpoca 392\nPerdida entrenamiento: 0.16136908989686233\nPerdida validación: 1.096735492348671\nÉpoca 393\nPerdida entrenamiento: 0.16398021177603647\nPerdida validación: 1.068606436252594\nÉpoca 394\nPerdida entrenamiento: 0.15940716748054212\nPerdida validación: 1.2023451328277588\nÉpoca 395\nPerdida entrenamiento: 0.16102972282813147\nPerdida validación: 1.3458791375160217\nÉpoca 396\nPerdida entrenamiento: 0.15895120684917158\nPerdida validación: 1.1531001776456833\nÉpoca 397\nPerdida entrenamiento: 0.16065807869801155\nPerdida validación: 1.4515523314476013\nÉpoca 398\nPerdida entrenamiento: 0.16089507135061118\nPerdida validación: 1.0475106053054333\nÉpoca 399\nPerdida entrenamiento: 0.1607217674071972\nPerdida validación: 1.0925526916980743\nÉpoca 400\nPerdida entrenamiento: 0.15985893744688767\nPerdida validación: 1.1263118088245392\nÉpoca 401\nPerdida entrenamiento: 0.15693163986389452\nPerdida validación: 1.5815104246139526\nÉpoca 402\nPerdida entrenamiento: 0.15736779341330895\nPerdida validación: 1.3613525032997131\nÉpoca 403\nPerdida entrenamiento: 0.15994859314881837\nPerdida validación: 1.3299525380134583\nÉpoca 404\nPerdida entrenamiento: 0.15524562992728674\nPerdida validación: 1.129160463809967\nÉpoca 405\nPerdida entrenamiento: 0.15532630681991577\nPerdida validación: 1.2196290791034698\nÉpoca 406\nPerdida entrenamiento: 0.15297087396566683\nPerdida validación: 2.013798788189888\nÉpoca 407\nPerdida entrenamiento: 0.15678289418037122\nPerdida validación: 1.579893410205841\nÉpoca 408\nPerdida entrenamiento: 0.15148546947882727\nPerdida validación: 1.1102407947182655\nÉpoca 409\nPerdida entrenamiento: 0.15315252427871412\nPerdida validación: 1.093673411756754\nÉpoca 410\nPerdida entrenamiento: 0.15141890599177435\nPerdida validación: 1.3287800699472427\nÉpoca 411\nPerdida entrenamiento: 0.15180933131621435\nPerdida validación: 1.3786164820194244\nÉpoca 412\nPerdida entrenamiento: 0.1497001200914383\nPerdida validación: 1.5654205977916718\nÉpoca 413\nPerdida entrenamiento: 0.1539385886146472\nPerdida validación: 1.0817826110869646\nÉpoca 414\nPerdida entrenamiento: 0.1514056955392544\nPerdida validación: 1.9382396638393402\nÉpoca 415\nPerdida entrenamiento: 0.15173272100778726\nPerdida validación: 1.3418876677751541\nÉpoca 416\nPerdida entrenamiento: 0.14910465880082205\nPerdida validación: 1.8640508651733398\nÉpoca 417\nPerdida entrenamiento: 0.14727372017044288\nPerdida validación: 1.1653900444507599\nÉpoca 418\nPerdida entrenamiento: 0.1486102778177995\nPerdida validación: 1.4865805208683014\nÉpoca 419\nPerdida entrenamiento: 0.1470818628485386\nPerdida validación: 1.8298079371452332\nÉpoca 420\nPerdida entrenamiento: 0.14542641719946495\nPerdida validación: 1.8267624229192734\nÉpoca 421\nPerdida entrenamiento: 0.1465584973876293\nPerdida validación: 1.7401020023971796\nÉpoca 422\nPerdida entrenamiento: 0.1459429063476049\nPerdida validación: 1.8647668659687042\nÉpoca 423\nPerdida entrenamiento: 0.14751056438455215\nPerdida validación: 1.853477194905281\nÉpoca 424\nPerdida entrenamiento: 0.14484965801239014\nPerdida validación: 1.9142803102731705\nÉpoca 425\nPerdida entrenamiento: 0.14378211962488982\nPerdida validación: 1.9636558592319489\nÉpoca 426\nPerdida entrenamiento: 0.14685687107535508\nPerdida validación: 2.342496156692505\nÉpoca 427\nPerdida entrenamiento: 0.1424619727409803\nPerdida validación: 4.561129406094551\nÉpoca 428\nPerdida entrenamiento: 0.14290866886193937\nPerdida validación: 4.768705457448959\nÉpoca 429\nPerdida entrenamiento: 0.1421340394478578\nPerdida validación: 2.390932723879814\nÉpoca 430\nPerdida entrenamiento: 0.14333476355442634\nPerdida validación: 1.9665760695934296\nÉpoca 431\nPerdida entrenamiento: 0.14370077475905418\nPerdida validación: 4.5777967274188995\nÉpoca 432\nPerdida entrenamiento: 0.1428644536779477\nPerdida validación: 1.915467545390129\nÉpoca 433\nPerdida entrenamiento: 0.1437031918993363\nPerdida validación: 1.8353270888328552\nÉpoca 434\nPerdida entrenamiento: 0.1391112907574727\nPerdida validación: 1.8254324793815613\nÉpoca 435\nPerdida entrenamiento: 0.14128816758210844\nPerdida validación: 2.2376081943511963\nÉpoca 436\nPerdida entrenamiento: 0.13954832634100547\nPerdida validación: 4.6626335978508\nÉpoca 437\nPerdida entrenamiento: 0.138767588023956\nPerdida validación: 1.7955627366900444\nÉpoca 438\nPerdida entrenamiento: 0.140621029986785\nPerdida validación: 1.9822211861610413\nÉpoca 439\nPerdida entrenamiento: 0.13871822305596793\nPerdida validación: 1.8298685476183891\nÉpoca 440\nPerdida entrenamiento: 0.13960186392068863\nPerdida validación: 2.2689503729343414\nÉpoca 441\nPerdida entrenamiento: 0.1384184412085093\nPerdida validación: 1.978897362947464\nÉpoca 442\nPerdida entrenamiento: 0.1393213366659788\nPerdida validación: 1.796176865696907\nÉpoca 443\nPerdida entrenamiento: 0.1366216018795967\nPerdida validación: 1.8592241257429123\nÉpoca 444\nPerdida entrenamiento: 0.13682998573550811\nPerdida validación: 1.7595698600634933\nÉpoca 445\nPerdida entrenamiento: 0.13522964973862356\nPerdida validación: 1.9084278345108032\nÉpoca 446\nPerdida entrenamiento: 0.13606802832621795\nPerdida validación: 2.1424740850925446\nÉpoca 447\nPerdida entrenamiento: 0.13595753048474973\nPerdida validación: 1.9501730501651764\nÉpoca 448\nPerdida entrenamiento: 0.13536394158234963\nPerdida validación: 1.7681202897801995\nÉpoca 449\nPerdida entrenamiento: 0.13383748439642099\nPerdida validación: 1.776937936898321\nÉpoca 450\nPerdida entrenamiento: 0.134520024061203\nPerdida validación: 2.3689710795879364\nÉpoca 451\nPerdida entrenamiento: 0.13803439873915452\nPerdida validación: 2.100162461400032\nÉpoca 452\nPerdida entrenamiento: 0.1336829622204487\nPerdida validación: 2.2752034962177277\nÉpoca 453\nPerdida entrenamiento: 0.13292249807944664\nPerdida validación: 1.995318591594696\nÉpoca 454\nPerdida entrenamiento: 0.13514817792635697\nPerdida validación: 1.9861263036727905\nÉpoca 455\nPerdida entrenamiento: 0.1320819346090922\nPerdida validación: 1.9134028553962708\nÉpoca 456\nPerdida entrenamiento: 0.13178949975050414\nPerdida validación: 2.345687836408615\nÉpoca 457\nPerdida entrenamiento: 0.13060673899375475\nPerdida validación: 1.7884992298204452\nÉpoca 458\nPerdida entrenamiento: 0.13102037072754824\nPerdida validación: 2.0062188506126404\nÉpoca 459\nPerdida entrenamiento: 0.13201026274607733\nPerdida validación: 2.2236380875110626\nÉpoca 460\nPerdida entrenamiento: 0.13188833112900072\nPerdida validación: 1.913369283080101\nÉpoca 461\nPerdida entrenamiento: 0.13061570146909127\nPerdida validación: 2.1135205924510956\nÉpoca 462\nPerdida entrenamiento: 0.12994415083756813\nPerdida validación: 2.502940058708191\nÉpoca 463\nPerdida entrenamiento: 0.13231988767018685\nPerdida validación: 2.2688323259353638\nÉpoca 464\nPerdida entrenamiento: 0.132278629220449\nPerdida validación: 1.9339222609996796\nÉpoca 465\nPerdida entrenamiento: 0.1299718085389871\nPerdida validación: 1.854475636035204\nÉpoca 466\nPerdida entrenamiento: 0.13145282578009826\nPerdida validación: 2.1876435577869415\nÉpoca 467\nPerdida entrenamiento: 0.1313119169611197\nPerdida validación: 2.0629679560661316\nÉpoca 468\nPerdida entrenamiento: 0.12963297819862\nPerdida validación: 1.8632949441671371\nÉpoca 469\nPerdida entrenamiento: 0.13173786350167715\nPerdida validación: 2.3062230050563812\nÉpoca 470\nPerdida entrenamiento: 0.12814507748071963\nPerdida validación: 1.8778863623738289\nÉpoca 471\nPerdida entrenamiento: 0.1295533965413387\nPerdida validación: 2.0298818349838257\nÉpoca 472\nPerdida entrenamiento: 0.12830456117024788\nPerdida validación: 1.8326761359348893\nÉpoca 473\nPerdida entrenamiento: 0.13108183042361185\nPerdida validación: 1.8978855609893799\nÉpoca 474\nPerdida entrenamiento: 0.12631277166880095\nPerdida validación: 1.8579567857086658\nÉpoca 475\nPerdida entrenamiento: 0.1265657704610091\nPerdida validación: 1.8173991988878697\nÉpoca 476\nPerdida entrenamiento: 0.1263832891216645\nPerdida validación: 2.03189879655838\nÉpoca 477\nPerdida entrenamiento: 0.1271198460688958\nPerdida validación: 2.035249412059784\nÉpoca 478\nPerdida entrenamiento: 0.12515214171547157\nPerdida validación: 2.3506749868392944\nÉpoca 479\nPerdida entrenamiento: 0.1258234651042865\nPerdida validación: 2.0357569456100464\nÉpoca 480\nPerdida entrenamiento: 0.12334210511583549\nPerdida validación: 2.3931768983602524\nÉpoca 481\nPerdida entrenamiento: 0.12442116553966816\nPerdida validación: 1.8402148545719683\nÉpoca 482\nPerdida entrenamiento: 0.12398571349107303\nPerdida validación: 1.8500240058638155\nÉpoca 483\nPerdida entrenamiento: 0.12187421866334401\nPerdida validación: 2.4725755900144577\nÉpoca 484\nPerdida entrenamiento: 0.12302208233338136\nPerdida validación: 2.2796106934547424\nÉpoca 485\nPerdida entrenamiento: 0.12683135729569656\nPerdida validación: 1.8626185692846775\nÉpoca 486\nPerdida entrenamiento: 0.12531459446136767\nPerdida validación: 2.2455354630947113\nÉpoca 487\nPerdida entrenamiento: 0.12518665194511414\nPerdida validación: 2.294196218252182\nÉpoca 488\nPerdida entrenamiento: 0.12416661272828396\nPerdida validación: 5.504393815994263\nÉpoca 489\nPerdida entrenamiento: 0.12151235857835183\nPerdida validación: 4.765833288431168\nÉpoca 490\nPerdida entrenamiento: 0.12303080123204452\nPerdida validación: 2.5530178621411324\nÉpoca 491\nPerdida entrenamiento: 0.1221739208469024\nPerdida validación: 2.623643547296524\nÉpoca 492\nPerdida entrenamiento: 0.12077710233055629\nPerdida validación: 2.641333118081093\nÉpoca 493\nPerdida entrenamiento: 0.12215936126617286\nPerdida validación: 2.523965746164322\nÉpoca 494\nPerdida entrenamiento: 0.12131250764314945\nPerdida validación: 2.86473748087883\nÉpoca 495\nPerdida entrenamiento: 0.11971759996735133\nPerdida validación: 2.8849087059497833\nÉpoca 496\nPerdida entrenamiento: 0.11921405147474545\nPerdida validación: 3.088648520410061\nÉpoca 497\nPerdida entrenamiento: 0.11881179362535477\nPerdida validación: 2.7041009813547134\nÉpoca 498\nPerdida entrenamiento: 0.12069269728202087\nPerdida validación: 2.701828509569168\nÉpoca 499\nPerdida entrenamiento: 0.11688872054219246\nPerdida validación: 2.6526040136814117\nÉpoca 500\nPerdida entrenamiento: 0.12055957403320533\nPerdida validación: 2.768251270055771\nÉpoca 501\nPerdida entrenamiento: 0.1185041986978971\nPerdida validación: 2.610110007226467\nÉpoca 502\nPerdida entrenamiento: 0.11842981869211563\nPerdida validación: 2.783321276307106\nÉpoca 503\nPerdida entrenamiento: 0.11740847648336337\nPerdida validación: 5.701580911874771\nÉpoca 504\nPerdida entrenamiento: 0.11811252511464633\nPerdida validación: 5.549773216247559\nÉpoca 505\nPerdida entrenamiento: 0.11450959799381402\nPerdida validación: 2.8138828575611115\nÉpoca 506\nPerdida entrenamiento: 0.1174502051793612\nPerdida validación: 2.615239202976227\nÉpoca 507\nPerdida entrenamiento: 0.11577433175765552\nPerdida validación: 2.584429509937763\nÉpoca 508\nPerdida entrenamiento: 0.11714056907938077\nPerdida validación: 2.5579630389111117\nÉpoca 509\nPerdida entrenamiento: 0.11275060732777302\nPerdida validación: 2.8419259935617447\nÉpoca 510\nPerdida entrenamiento: 0.11713154499347393\nPerdida validación: 3.056575983762741\nÉpoca 511\nPerdida entrenamiento: 0.11541045027283522\nPerdida validación: 2.8400514125823975\nÉpoca 512\nPerdida entrenamiento: 0.11325491334383304\nPerdida validación: 2.6306902319192886\nÉpoca 513\nPerdida entrenamiento: 0.11358885925549728\nPerdida validación: 2.571716500679031\nÉpoca 514\nPerdida entrenamiento: 0.11338759013093434\nPerdida validación: 2.9470843076705933\nÉpoca 515\nPerdida entrenamiento: 0.11455664554467568\nPerdida validación: 2.9394672214984894\nÉpoca 516\nPerdida entrenamiento: 0.11280371965124057\nPerdida validación: 5.647374600172043\nÉpoca 517\nPerdida entrenamiento: 0.11306084377261308\nPerdida validación: 2.619787771254778\nÉpoca 518\nPerdida entrenamiento: 0.1135869212448597\nPerdida validación: 2.853236883878708\nÉpoca 519\nPerdida entrenamiento: 0.11409064611563316\nPerdida validación: 5.546691715717316\nÉpoca 520\nPerdida entrenamiento: 0.1118229848261063\nPerdida validación: 2.745006173849106\nÉpoca 521\nPerdida entrenamiento: 0.11278153583407402\nPerdida validación: 3.1580388844013214\nÉpoca 522\nPerdida entrenamiento: 0.11320935247036126\nPerdida validación: 2.7071564495563507\nÉpoca 523\nPerdida entrenamiento: 0.11237332626030995\nPerdida validación: 2.6988750621676445\nÉpoca 524\nPerdida entrenamiento: 0.10959484084294392\nPerdida validación: 3.124171957373619\nÉpoca 525\nPerdida entrenamiento: 0.11166479524511558\nPerdida validación: 5.45481139421463\nÉpoca 526\nPerdida entrenamiento: 0.11054900173957531\nPerdida validación: 3.007249414920807\nÉpoca 527\nPerdida entrenamiento: 0.11383987246797635\nPerdida validación: 2.8005631417036057\nÉpoca 528\nPerdida entrenamiento: 0.10905527896606006\nPerdida validación: 3.0521177500486374\nÉpoca 529\nPerdida entrenamiento: 0.11215656551604088\nPerdida validación: 2.909767299890518\nÉpoca 530\nPerdida entrenamiento: 0.11102713014070804\nPerdida validación: 2.6694091595709324\nÉpoca 531\nPerdida entrenamiento: 0.10923272371292114\nPerdida validación: 2.6914474070072174\nÉpoca 532\nPerdida entrenamiento: 0.10927552013443066\nPerdida validación: 2.8471918255090714\nÉpoca 533\nPerdida entrenamiento: 0.11039042931336623\nPerdida validación: 5.58680272102356\nÉpoca 534\nPerdida entrenamiento: 0.11040670768572734\nPerdida validación: 5.831094592809677\nÉpoca 535\nPerdida entrenamiento: 0.10797414355553113\nPerdida validación: 2.8358536660671234\nÉpoca 536\nPerdida entrenamiento: 0.10849945705670577\nPerdida validación: 2.847647100687027\nÉpoca 537\nPerdida entrenamiento: 0.10771226997558887\nPerdida validación: 2.6895657889544964\nÉpoca 538\nPerdida entrenamiento: 0.10608476199782811\nPerdida validación: 2.9265541434288025\nÉpoca 539\nPerdida entrenamiento: 0.10907147738796014\nPerdida validación: 3.472039520740509\nÉpoca 540\nPerdida entrenamiento: 0.10541577493915191\nPerdida validación: 2.654316759100766\nÉpoca 541\nPerdida entrenamiento: 0.10745507736618702\nPerdida validación: 5.496880441904068\nÉpoca 542\nPerdida entrenamiento: 0.10491894815976803\nPerdida validación: 2.7173368334770203\nÉpoca 543\nPerdida entrenamiento: 0.1082516282510299\nPerdida validación: 5.47006168961525\nÉpoca 544\nPerdida entrenamiento: 0.10422761451739532\nPerdida validación: 2.749433569610119\nÉpoca 545\nPerdida entrenamiento: 0.1062567073565263\nPerdida validación: 2.848259523510933\nÉpoca 546\nPerdida entrenamiento: 0.10411920971595325\nPerdida validación: 3.7098141610622406\nÉpoca 547\nPerdida entrenamiento: 0.10428597262272468\nPerdida validación: 2.771275945007801\nÉpoca 548\nPerdida entrenamiento: 0.10482547260247745\nPerdida validación: 2.740638144314289\nÉpoca 549\nPerdida entrenamiento: 0.10570188955618785\nPerdida validación: 3.0091414153575897\nÉpoca 550\nPerdida entrenamiento: 0.10292766644404484\nPerdida validación: 3.15601310133934\nÉpoca 551\nPerdida entrenamiento: 0.10313611305676974\nPerdida validación: 3.4876405000686646\nÉpoca 552\nPerdida entrenamiento: 0.102155673962373\nPerdida validación: 2.9055378437042236\nÉpoca 553\nPerdida entrenamiento: 0.10382852617364663\nPerdida validación: 2.723412472754717\nÉpoca 554\nPerdida entrenamiento: 0.10259475057514814\nPerdida validación: 5.492315292358398\nÉpoca 555\nPerdida entrenamiento: 0.10145168722822116\nPerdida validación: 2.754060558974743\nÉpoca 556\nPerdida entrenamiento: 0.10143737294352971\nPerdida validación: 3.07767117023468\nÉpoca 557\nPerdida entrenamiento: 0.1056364316206712\nPerdida validación: 2.9746521413326263\nÉpoca 558\nPerdida entrenamiento: 0.10130224491541202\nPerdida validación: 3.025153934955597\nÉpoca 559\nPerdida entrenamiento: 0.10119306353422311\nPerdida validación: 3.1392782032489777\nÉpoca 560\nPerdida entrenamiento: 0.10136075776356918\nPerdida validación: 3.2021331638097763\nÉpoca 561\nPerdida entrenamiento: 0.10253067285968707\nPerdida validación: 3.076074779033661\nÉpoca 562\nPerdida entrenamiento: 0.10206653034457794\nPerdida validación: 5.530216574668884\nÉpoca 563\nPerdida entrenamiento: 0.10454103207358947\nPerdida validación: 3.2058138102293015\nÉpoca 564\nPerdida entrenamiento: 0.10343335053095451\nPerdida validación: 3.1237970888614655\nÉpoca 565\nPerdida entrenamiento: 0.09964850559257545\nPerdida validación: 3.4429604411125183\nÉpoca 566\nPerdida entrenamiento: 0.10099474125756668\nPerdida validación: 3.31308913230896\nÉpoca 567\nPerdida entrenamiento: 0.09864685397881728\nPerdida validación: 2.990403264760971\nÉpoca 568\nPerdida entrenamiento: 0.10084413794370797\nPerdida validación: 3.0305745601654053\nÉpoca 569\nPerdida entrenamiento: 0.09896215968407117\nPerdida validación: 2.773144192993641\nÉpoca 570\nPerdida entrenamiento: 0.09875178738282277\nPerdida validación: 3.2597747147083282\nÉpoca 571\nPerdida entrenamiento: 0.09714520020553699\nPerdida validación: 2.7881274856626987\nÉpoca 572\nPerdida entrenamiento: 0.09834642221148197\nPerdida validación: 2.897169277071953\nÉpoca 573\nPerdida entrenamiento: 0.09885117368629345\nPerdida validación: 3.086055040359497\nÉpoca 574\nPerdida entrenamiento: 0.09760436788201332\nPerdida validación: 2.9079464077949524\nÉpoca 575\nPerdida entrenamiento: 0.09912287873717454\nPerdida validación: 3.261339485645294\nÉpoca 576\nPerdida entrenamiento: 0.09698486127532445\nPerdida validación: 2.9379115402698517\nÉpoca 577\nPerdida entrenamiento: 0.0979744757597263\nPerdida validación: 3.2120234966278076\nÉpoca 578\nPerdida entrenamiento: 0.0980399100539776\nPerdida validación: 2.905558556318283\nÉpoca 579\nPerdida entrenamiento: 0.09601865737484051\nPerdida validación: 3.2893512845039368\nÉpoca 580\nPerdida entrenamiento: 0.09636882950480168\nPerdida validación: 5.822457730770111\nÉpoca 581\nPerdida entrenamiento: 0.09623523285755745\nPerdida validación: 2.9834419786930084\nÉpoca 582\nPerdida entrenamiento: 0.09567874211531419\nPerdida validación: 2.834209755063057\nÉpoca 583\nPerdida entrenamiento: 0.09520710431612454\nPerdida validación: 3.457405775785446\nÉpoca 584\nPerdida entrenamiento: 0.09503164486243175\nPerdida validación: 2.783683327026665\nÉpoca 585\nPerdida entrenamiento: 0.09478533927064675\nPerdida validación: 3.208044409751892\nÉpoca 586\nPerdida entrenamiento: 0.09366065492996803\nPerdida validación: 2.8148815520107746\nÉpoca 587\nPerdida entrenamiento: 0.09470219050462429\nPerdida validación: 3.1014271676540375\nÉpoca 588\nPerdida entrenamiento: 0.09309046171032466\nPerdida validación: 3.2367973625659943\nÉpoca 589\nPerdida entrenamiento: 0.09493592811318544\nPerdida validación: 3.512310117483139\nÉpoca 590\nPerdida entrenamiento: 0.09326716999594982\nPerdida validación: 3.0231358408927917\nÉpoca 591\nPerdida entrenamiento: 0.09341454792481202\nPerdida validación: 3.043340712785721\nÉpoca 592\nPerdida entrenamiento: 0.09278626940571345\nPerdida validación: 5.691175103187561\nÉpoca 593\nPerdida entrenamiento: 0.09466937327614197\nPerdida validación: 3.352739989757538\nÉpoca 594\nPerdida entrenamiento: 0.09303238815986194\nPerdida validación: 3.332100570201874\nÉpoca 595\nPerdida entrenamiento: 0.0932160415328466\nPerdida validación: 3.2494913041591644\nÉpoca 596\nPerdida entrenamiento: 0.09378410044770974\nPerdida validación: 3.2207201719284058\nÉpoca 597\nPerdida entrenamiento: 0.09273648376648243\nPerdida validación: 2.8693348169326782\nÉpoca 598\nPerdida entrenamiento: 0.09436917047087963\nPerdida validación: 2.8971500992774963\nÉpoca 599\nPerdida entrenamiento: 0.09192508573715504\nPerdida validación: 3.5734232664108276\nÉpoca 600\nPerdida entrenamiento: 0.0922428432565469\nPerdida validación: 3.286315381526947\nÉpoca 601\nPerdida entrenamiento: 0.090951818972826\nPerdida validación: 2.839483904186636\nÉpoca 602\nPerdida entrenamiento: 0.09206941953072181\nPerdida validación: 6.175304114818573\nÉpoca 603\nPerdida entrenamiento: 0.0930221310028663\nPerdida validación: 3.414512574672699\nÉpoca 604\nPerdida entrenamiento: 0.09010667654757316\nPerdida validación: 2.8338278711307794\nÉpoca 605\nPerdida entrenamiento: 0.09371261155376068\nPerdida validación: 3.4049655497074127\nÉpoca 606\nPerdida entrenamiento: 0.09388583640639599\nPerdida validación: 3.5773722529411316\nÉpoca 607\nPerdida entrenamiento: 0.09048281996869124\nPerdida validación: 3.2947387397289276\nÉpoca 608\nPerdida entrenamiento: 0.09159044520213054\nPerdida validación: 2.9430512189865112\nÉpoca 609\nPerdida entrenamiento: 0.08964369574991557\nPerdida validación: 3.3014421463012695\nÉpoca 610\nPerdida entrenamiento: 0.08908333887274449\nPerdida validación: 2.998455196619034\nÉpoca 611\nPerdida entrenamiento: 0.09090320049570157\nPerdida validación: 5.645829796791077\nÉpoca 612\nPerdida entrenamiento: 0.08766440416757877\nPerdida validación: 2.9032982736825943\nÉpoca 613\nPerdida entrenamiento: 0.08854922107779063\nPerdida validación: 3.060891628265381\nÉpoca 614\nPerdida entrenamiento: 0.08976021638283363\nPerdida validación: 3.0479705929756165\nÉpoca 615\nPerdida entrenamiento: 0.08961896913555953\nPerdida validación: 4.045959830284119\nÉpoca 616\nPerdida entrenamiento: 0.08848642328610787\nPerdida validación: 5.979500740766525\nÉpoca 617\nPerdida entrenamiento: 0.08795142374359645\nPerdida validación: 3.2142326831817627\nÉpoca 618\nPerdida entrenamiento: 0.08949532818335754\nPerdida validación: 3.4921406507492065\nÉpoca 619\nPerdida entrenamiento: 0.08757467159571555\nPerdida validación: 2.9816556125879288\nÉpoca 620\nPerdida entrenamiento: 0.0879586089688998\nPerdida validación: 3.0630840808153152\nÉpoca 621\nPerdida entrenamiento: 0.08634372141498786\nPerdida validación: 4.073459208011627\nÉpoca 622\nPerdida entrenamiento: 0.08796885366050097\nPerdida validación: 2.9151867516338825\nÉpoca 623\nPerdida entrenamiento: 0.08707575729260078\nPerdida validación: 3.223273813724518\nÉpoca 624\nPerdida entrenamiento: 0.08563883115465824\nPerdida validación: 3.0873585641384125\nÉpoca 625\nPerdida entrenamiento: 0.08584944187448575\nPerdida validación: 2.9525046534836292\nÉpoca 626\nPerdida entrenamiento: 0.08701738285330626\nPerdida validación: 3.099105030298233\nÉpoca 627\nPerdida entrenamiento: 0.08607068084753476\nPerdida validación: 5.73407855629921\nÉpoca 628\nPerdida entrenamiento: 0.08767787438745682\nPerdida validación: 2.8967090360820293\nÉpoca 629\nPerdida entrenamiento: 0.08825744960743648\nPerdida validación: 3.380082130432129\nÉpoca 630\nPerdida entrenamiento: 0.0873606692139919\nPerdida validación: 3.1084282398223877\nÉpoca 631\nPerdida entrenamiento: 0.08586964011192322\nPerdida validación: 3.7326546162366867\nÉpoca 632\nPerdida entrenamiento: 0.08663071577365582\nPerdida validación: 5.914897799491882\nÉpoca 633\nPerdida entrenamiento: 0.08718680790983714\nPerdida validación: 2.9612930342555046\nÉpoca 634\nPerdida entrenamiento: 0.085944925649808\nPerdida validación: 3.224094897508621\nÉpoca 635\nPerdida entrenamiento: 0.0844750301196025\nPerdida validación: 3.0974116921424866\nÉpoca 636\nPerdida entrenamiento: 0.08396346781116265\nPerdida validación: 3.4633867144584656\nÉpoca 637\nPerdida entrenamiento: 0.08545709831210282\nPerdida validación: 2.9578521959483624\nÉpoca 638\nPerdida entrenamiento: 0.08674065195597135\nPerdida validación: 2.949578620493412\nÉpoca 639\nPerdida entrenamiento: 0.08519237488508224\nPerdida validación: 3.2103909254074097\nÉpoca 640\nPerdida entrenamiento: 0.08840005414990279\nPerdida validación: 3.0627825558185577\nÉpoca 641\nPerdida entrenamiento: 0.0849433932453394\nPerdida validación: 3.172268331050873\nÉpoca 642\nPerdida entrenamiento: 0.08262179534022625\nPerdida validación: 3.236430197954178\nÉpoca 643\nPerdida entrenamiento: 0.08367389583816895\nPerdida validación: 2.942924888804555\nÉpoca 644\nPerdida entrenamiento: 0.08231127118835083\nPerdida validación: 3.27776700258255\nÉpoca 645\nPerdida entrenamiento: 0.08604721839611347\nPerdida validación: 2.9394181985408068\nÉpoca 646\nPerdida entrenamiento: 0.08392453394257106\nPerdida validación: 3.0016921162605286\nÉpoca 647\nPerdida entrenamiento: 0.08415115481385818\nPerdida validación: 3.1223526895046234\nÉpoca 648\nPerdida entrenamiento: 0.08276968549650449\nPerdida validación: 2.978962305933237\nÉpoca 649\nPerdida entrenamiento: 0.08537436477266826\nPerdida validación: 3.432997077703476\nÉpoca 650\nPerdida entrenamiento: 0.0837293887654176\nPerdida validación: 3.4656736850738525\nÉpoca 651\nPerdida entrenamiento: 0.08413175550790933\nPerdida validación: 3.3202735409140587\nÉpoca 652\nPerdida entrenamiento: 0.08189639592399964\nPerdida validación: 3.8872807025909424\nÉpoca 653\nPerdida entrenamiento: 0.08280348534194323\nPerdida validación: 6.082957550883293\nÉpoca 654\nPerdida entrenamiento: 0.08127718963302098\nPerdida validación: 3.207852452993393\nÉpoca 655\nPerdida entrenamiento: 0.08102134758463272\nPerdida validación: 3.252897948026657\nÉpoca 656\nPerdida entrenamiento: 0.08139984109080754\nPerdida validación: 2.9737558010965586\nÉpoca 657\nPerdida entrenamiento: 0.08038559813912098\nPerdida validación: 3.310336619615555\nÉpoca 658\nPerdida entrenamiento: 0.07984856028969471\nPerdida validación: 3.006955109536648\nÉpoca 659\nPerdida entrenamiento: 0.08055987037145175\nPerdida validación: 3.5304589942097664\nÉpoca 660\nPerdida entrenamiento: 0.08210009408111756\nPerdida validación: 3.9923764169216156\nÉpoca 661\nPerdida entrenamiento: 0.08106890879571438\nPerdida validación: 3.647656798362732\nÉpoca 662\nPerdida entrenamiento: 0.0803337491189058\nPerdida validación: 3.0062214881181717\nÉpoca 663\nPerdida entrenamiento: 0.08178974587756854\nPerdida validación: 3.8203519582748413\nÉpoca 664\nPerdida entrenamiento: 0.07993544179659623\nPerdida validación: 5.766702353954315\nÉpoca 665\nPerdida entrenamiento: 0.07951982949788754\nPerdida validación: 3.537745386362076\nÉpoca 666\nPerdida entrenamiento: 0.07966543834369916\nPerdida validación: 3.3440269827842712\nÉpoca 667\nPerdida entrenamiento: 0.07974013012762253\nPerdida validación: 3.4005532264709473\nÉpoca 668\nPerdida entrenamiento: 0.08048110283338107\nPerdida validación: 6.076398730278015\nÉpoca 669\nPerdida entrenamiento: 0.07910338760568546\nPerdida validación: 3.1290396749973297\nÉpoca 670\nPerdida entrenamiento: 0.07919158643254867\nPerdida validación: 3.0483686476945877\nÉpoca 671\nPerdida entrenamiento: 0.07788696125722848\nPerdida validación: 6.258003294467926\nÉpoca 672\nPerdida entrenamiento: 0.08138983582074825\nPerdida validación: 3.043996773660183\nÉpoca 673\nPerdida entrenamiento: 0.08381304632012661\nPerdida validación: 2.9912613732740283\nÉpoca 674\nPerdida entrenamiento: 0.08171401430781071\nPerdida validación: 3.2535914480686188\nÉpoca 675\nPerdida entrenamiento: 0.07973616025768794\nPerdida validación: 3.008113071322441\nÉpoca 676\nPerdida entrenamiento: 0.08049123103802021\nPerdida validación: 3.3409511744976044\nÉpoca 677\nPerdida entrenamiento: 0.0830245754466607\nPerdida validación: 6.382318615913391\nÉpoca 678\nPerdida entrenamiento: 0.0790841830177949\nPerdida validación: 3.5300813168287277\nÉpoca 679\nPerdida entrenamiento: 0.07988710758777764\nPerdida validación: 3.441707044839859\nÉpoca 680\nPerdida entrenamiento: 0.07954001054167747\nPerdida validación: 3.0263784900307655\nÉpoca 681\nPerdida entrenamiento: 0.08027764732161394\nPerdida validación: 3.698488086462021\nÉpoca 682\nPerdida entrenamiento: 0.07939692701284702\nPerdida validación: 6.145058274269104\nÉpoca 683\nPerdida entrenamiento: 0.07660764312514892\nPerdida validación: 4.3174373507499695\nÉpoca 684\nPerdida entrenamiento: 0.07766298620173565\nPerdida validación: 6.3749352395534515\nÉpoca 685\nPerdida entrenamiento: 0.07970923471909303\nPerdida validación: 4.056097626686096\nÉpoca 686\nPerdida entrenamiento: 0.07719844278807823\nPerdida validación: 3.051921732723713\nÉpoca 687\nPerdida entrenamiento: 0.0781680206553294\nPerdida validación: 3.4439048767089844\nÉpoca 688\nPerdida entrenamiento: 0.07667693667686902\nPerdida validación: 3.182342290878296\nÉpoca 689\nPerdida entrenamiento: 0.0783315381178489\nPerdida validación: 3.228578358888626\nÉpoca 690\nPerdida entrenamiento: 0.07471121217195804\nPerdida validación: 3.2710892260074615\nÉpoca 691\nPerdida entrenamiento: 0.07603253968633138\nPerdida validación: 3.523540109395981\nÉpoca 692\nPerdida entrenamiento: 0.07471496525865334\nPerdida validación: 3.411119043827057\nÉpoca 693\nPerdida entrenamiento: 0.0752135177071278\nPerdida validación: 3.4445889592170715\nÉpoca 694\nPerdida entrenamiento: 0.07611862613031498\nPerdida validación: 3.559295654296875\nÉpoca 695\nPerdida entrenamiento: 0.0759881936873381\nPerdida validación: 3.5824018120765686\nÉpoca 696\nPerdida entrenamiento: 0.07466840600738159\nPerdida validación: 3.9484466910362244\nÉpoca 697\nPerdida entrenamiento: 0.0735154255078389\nPerdida validación: 3.0945662409067154\nÉpoca 698\nPerdida entrenamiento: 0.07556946203112602\nPerdida validación: 3.3838585913181305\nÉpoca 699\nPerdida entrenamiento: 0.075852148521405\nPerdida validación: 3.9069823026657104\nÉpoca 700\nPerdida entrenamiento: 0.07505714750060669\nPerdida validación: 3.286153644323349\nÉpoca 701\nPerdida entrenamiento: 0.07513145830195683\nPerdida validación: 3.0753321163356304\nÉpoca 702\nPerdida entrenamiento: 0.07591709723839393\nPerdida validación: 3.383682131767273\nÉpoca 703\nPerdida entrenamiento: 0.07662103439752872\nPerdida validación: 6.287557303905487\nÉpoca 704\nPerdida entrenamiento: 0.074071651038069\nPerdida validación: 3.51538348197937\nÉpoca 705\nPerdida entrenamiento: 0.07326486592109387\nPerdida validación: 3.647996246814728\nÉpoca 706\nPerdida entrenamiento: 0.07368115650919768\nPerdida validación: 3.0932504013180733\nÉpoca 707\nPerdida entrenamiento: 0.0751225554312651\nPerdida validación: 5.895449340343475\nÉpoca 708\nPerdida entrenamiento: 0.07395617950421113\nPerdida validación: 5.860315516591072\nÉpoca 709\nPerdida entrenamiento: 0.07535010304015416\nPerdida validación: 3.0919011384248734\nÉpoca 710\nPerdida entrenamiento: 0.07465821561905053\nPerdida validación: 5.954198464751244\nÉpoca 711\nPerdida entrenamiento: 0.07308040587947918\nPerdida validación: 3.787451297044754\nÉpoca 712\nPerdida entrenamiento: 0.07293918241675083\nPerdida validación: 3.5140918493270874\nÉpoca 713\nPerdida entrenamiento: 0.07424381232032409\nPerdida validación: 3.5032528042793274\nÉpoca 714\nPerdida entrenamiento: 0.07196107234519261\nPerdida validación: 3.103741290047765\nÉpoca 715\nPerdida entrenamiento: 0.07321044630729236\nPerdida validación: 3.2048414945602417\nÉpoca 716\nPerdida entrenamiento: 0.07338270552169818\nPerdida validación: 3.4842203855514526\nÉpoca 717\nPerdida entrenamiento: 0.07320698207387558\nPerdida validación: 3.547133982181549\nÉpoca 718\nPerdida entrenamiento: 0.07335239849411525\nPerdida validación: 3.3462226688861847\nÉpoca 719\nPerdida entrenamiento: 0.07362754786243805\nPerdida validación: 3.0637363731259484\nÉpoca 720\nPerdida entrenamiento: 0.07329921933034292\nPerdida validación: 3.5014507174491882\nÉpoca 721\nPerdida entrenamiento: 0.07308094232128216\nPerdida validación: 3.600960463285446\nÉpoca 722\nPerdida entrenamiento: 0.07359824429910916\nPerdida validación: 3.6419607996940613\nÉpoca 723\nPerdida entrenamiento: 0.0702361033942837\nPerdida validación: 3.3048584163188934\nÉpoca 724\nPerdida entrenamiento: 0.07198195188091351\nPerdida validación: 3.635326474905014\nÉpoca 725\nPerdida entrenamiento: 0.07143456402879494\nPerdida validación: 3.1239943015389144\nÉpoca 726\nPerdida entrenamiento: 0.07296538524902783\nPerdida validación: 3.9761489629745483\nÉpoca 727\nPerdida entrenamiento: 0.06996076797636655\nPerdida validación: 3.673790752887726\nÉpoca 728\nPerdida entrenamiento: 0.07061829260335518\nPerdida validación: 3.527384489774704\nÉpoca 729\nPerdida entrenamiento: 0.07066990879292671\nPerdida validación: 3.565238893032074\nÉpoca 730\nPerdida entrenamiento: 0.06986354305767097\nPerdida validación: 3.1452227979898453\nÉpoca 731\nPerdida entrenamiento: 0.07251900878663246\nPerdida validación: 3.676050305366516\nÉpoca 732\nPerdida entrenamiento: 0.07029389106453611\nPerdida validación: 6.303750157356262\nÉpoca 733\nPerdida entrenamiento: 0.07063901882905227\nPerdida validación: 3.6955054998397827\nÉpoca 734\nPerdida entrenamiento: 0.07026771971812615\nPerdida validación: 3.6877950727939606\nÉpoca 735\nPerdida entrenamiento: 0.07010470860852645\nPerdida validación: 3.8105451464653015\nÉpoca 736\nPerdida entrenamiento: 0.07092373674878708\nPerdida validación: 6.272245496511459\nÉpoca 737\nPerdida entrenamiento: 0.06938746227667882\nPerdida validación: 4.11859667301178\nÉpoca 738\nPerdida entrenamiento: 0.07033284137455317\nPerdida validación: 3.489028960466385\nÉpoca 739\nPerdida entrenamiento: 0.07005046737881807\nPerdida validación: 3.9497650265693665\nÉpoca 740\nPerdida entrenamiento: 0.06991838477551937\nPerdida validación: 3.5906466245651245\nÉpoca 741\nPerdida entrenamiento: 0.07006746086363609\nPerdida validación: 4.010214567184448\nÉpoca 742\nPerdida entrenamiento: 0.06976071902765678\nPerdida validación: 3.903961181640625\nÉpoca 743\nPerdida entrenamiento: 0.07007302042956536\nPerdida validación: 3.373776465654373\nÉpoca 744\nPerdida entrenamiento: 0.06779414845200685\nPerdida validación: 3.4710806906223297\nÉpoca 745\nPerdida entrenamiento: 0.06950925863706149\nPerdida validación: 3.2723368108272552\nÉpoca 746\nPerdida entrenamiento: 0.06822979550522107\nPerdida validación: 3.880464196205139\nÉpoca 747\nPerdida entrenamiento: 0.06774935606293954\nPerdida validación: 4.389346688985825\nÉpoca 748\nPerdida entrenamiento: 0.06761566936396636\nPerdida validación: 3.15746596394456\nÉpoca 749\nPerdida entrenamiento: 0.06839605879325134\nPerdida validación: 3.3875818252563477\nÉpoca 750\nPerdida entrenamiento: 0.06772242185588066\nPerdida validación: 3.1746858982369304\nÉpoca 751\nPerdida entrenamiento: 0.06843308130135903\nPerdida validación: 3.2046142797917128\nÉpoca 752\nPerdida entrenamiento: 0.06832610113689533\nPerdida validación: 3.952906757593155\nÉpoca 753\nPerdida entrenamiento: 0.0690260434953066\nPerdida validación: 3.7516192197799683\nÉpoca 754\nPerdida entrenamiento: 0.06749802698882726\nPerdida validación: 3.1946978587657213\nÉpoca 755\nPerdida entrenamiento: 0.06692473447093597\nPerdida validación: 3.173951795324683\nÉpoca 756\nPerdida entrenamiento: 0.06698934733867645\nPerdida validación: 3.6998668909072876\nÉpoca 757\nPerdida entrenamiento: 0.06710446482667556\nPerdida validación: 6.106452941894531\nÉpoca 758\nPerdida entrenamiento: 0.06671396270394325\nPerdida validación: 3.59967178106308\nÉpoca 759\nPerdida entrenamiento: 0.0667688400986103\nPerdida validación: 4.006033331155777\nÉpoca 760\nPerdida entrenamiento: 0.06433771564983405\nPerdida validación: 9.396792531013489\nÉpoca 761\nPerdida entrenamiento: 0.0658060577339851\nPerdida validación: 3.6313920319080353\nÉpoca 762\nPerdida entrenamiento: 0.06626230678879298\nPerdida validación: 3.1925170212052763\nÉpoca 763\nPerdida entrenamiento: 0.06445745751261711\nPerdida validación: 3.2214292294811457\nÉpoca 764\nPerdida entrenamiento: 0.0656591676748716\nPerdida validación: 3.7026621997356415\nÉpoca 765\nPerdida entrenamiento: 0.06652211283261959\nPerdida validación: 4.019250392913818\nÉpoca 766\nPerdida entrenamiento: 0.0645568874449684\nPerdida validación: 3.2478851601481438\nÉpoca 767\nPerdida entrenamiento: 0.0645436357993346\nPerdida validación: 3.634760797023773\nÉpoca 768\nPerdida entrenamiento: 0.06626242198623143\nPerdida validación: 3.2138933995738626\nÉpoca 769\nPerdida entrenamiento: 0.06454834657219741\nPerdida validación: 3.4520061314105988\nÉpoca 770\nPerdida entrenamiento: 0.06424231254137479\nPerdida validación: 6.513358294963837\nÉpoca 771\nPerdida entrenamiento: 0.0674513099858394\nPerdida validación: 3.208299418911338\nÉpoca 772\nPerdida entrenamiento: 0.06449403012028107\nPerdida validación: 3.4559914767742157\nÉpoca 773\nPerdida entrenamiento: 0.06507012119086888\nPerdida validación: 3.4043886959552765\nÉpoca 774\nPerdida entrenamiento: 0.06500616096533261\nPerdida validación: 3.7424195408821106\nÉpoca 775\nPerdida entrenamiento: 0.06445603316219953\nPerdida validación: 3.2316817604005337\nÉpoca 776\nPerdida entrenamiento: 0.06395076867192984\nPerdida validación: 3.3793974220752716\nÉpoca 777\nPerdida entrenamiento: 0.06544297073896115\nPerdida validación: 3.6280748546123505\nÉpoca 778\nPerdida entrenamiento: 0.06932021118700504\nPerdida validación: 3.5138529241085052\nÉpoca 779\nPerdida entrenamiento: 0.07144579004782897\nPerdida validación: 3.281018428504467\nÉpoca 780\nPerdida entrenamiento: 0.06321389299745743\nPerdida validación: 4.2752964198589325\nÉpoca 781\nPerdida entrenamiento: 0.06387096292410906\nPerdida validación: 6.191157042980194\nÉpoca 782\nPerdida entrenamiento: 0.06328819821087214\nPerdida validación: 4.009998798370361\nÉpoca 783\nPerdida entrenamiento: 0.06345390198895565\nPerdida validación: 3.5408129692077637\nÉpoca 784\nPerdida entrenamiento: 0.06154564581811428\nPerdida validación: 3.728050410747528\nÉpoca 785\nPerdida entrenamiento: 0.06283387785347608\nPerdida validación: 3.271757125854492\nÉpoca 786\nPerdida entrenamiento: 0.06242528486137207\nPerdida validación: 3.5932647585868835\nÉpoca 787\nPerdida entrenamiento: 0.0626249214491019\nPerdida validación: 6.087800234556198\nÉpoca 788\nPerdida entrenamiento: 0.06314485878325425\nPerdida validación: 3.6031576097011566\nÉpoca 789\nPerdida entrenamiento: 0.0641820035301722\nPerdida validación: 3.6429638266563416\nÉpoca 790\nPerdida entrenamiento: 0.06248174120600407\nPerdida validación: 4.228351831436157\nÉpoca 791\nPerdida entrenamiento: 0.06177817901166586\nPerdida validación: 4.137951165437698\nÉpoca 792\nPerdida entrenamiento: 0.0609730864660098\nPerdida validación: 3.5382475554943085\nÉpoca 793\nPerdida entrenamiento: 0.0613269078043791\nPerdida validación: 3.2661752179265022\nÉpoca 794\nPerdida entrenamiento: 0.06030727149202274\nPerdida validación: 6.637757331132889\nÉpoca 795\nPerdida entrenamiento: 0.06137405077998455\nPerdida validación: 3.8624553084373474\nÉpoca 796\nPerdida entrenamiento: 0.0609011253198752\nPerdida validación: 3.3248483315110207\nÉpoca 797\nPerdida entrenamiento: 0.06208982662512706\nPerdida validación: 3.9522294402122498\nÉpoca 798\nPerdida entrenamiento: 0.060166037999666654\nPerdida validación: 3.2770682722330093\nÉpoca 799\nPerdida entrenamiento: 0.06056450558109926\nPerdida validación: 3.343050740659237\nÉpoca 800\nPerdida entrenamiento: 0.06177033111453056\nPerdida validación: 3.580229103565216\nÉpoca 801\nPerdida entrenamiento: 0.060246036746180974\nPerdida validación: 3.505081385374069\nÉpoca 802\nPerdida entrenamiento: 0.061356705326873526\nPerdida validación: 4.062293261289597\nÉpoca 803\nPerdida entrenamiento: 0.05942604003044275\nPerdida validación: 4.110773056745529\nÉpoca 804\nPerdida entrenamiento: 0.060502128245738834\nPerdida validación: 3.8822240233421326\nÉpoca 805\nPerdida entrenamiento: 0.05999588966369629\nPerdida validación: 6.7766527235507965\nÉpoca 806\nPerdida entrenamiento: 0.059047887495790534\nPerdida validación: 4.154969960451126\nÉpoca 807\nPerdida entrenamiento: 0.058758083587655656\nPerdida validación: 4.048469461500645\nÉpoca 808\nPerdida entrenamiento: 0.059343369104541265\nPerdida validación: 3.914748638868332\nÉpoca 809\nPerdida entrenamiento: 0.06124117999122693\nPerdida validación: 3.564255177974701\nÉpoca 810\nPerdida entrenamiento: 0.05879233297533714\nPerdida validación: 3.761751651763916\nÉpoca 811\nPerdida entrenamiento: 0.059525275316375956\nPerdida validación: 3.518033117055893\nÉpoca 812\nPerdida entrenamiento: 0.058720690986284844\nPerdida validación: 3.7310802340507507\nÉpoca 813\nPerdida entrenamiento: 0.059426360118847624\nPerdida validación: 3.907933384180069\nÉpoca 814\nPerdida entrenamiento: 0.05819435217059576\nPerdida validación: 3.6875914335250854\nÉpoca 815\nPerdida entrenamiento: 0.058877732748022445\nPerdida validación: 3.6664465963840485\nÉpoca 816\nPerdida entrenamiento: 0.05832370979568133\nPerdida validación: 3.8303341567516327\nÉpoca 817\nPerdida entrenamiento: 0.05997598550927181\nPerdida validación: 4.546199798583984\nÉpoca 818\nPerdida entrenamiento: 0.06107013658262216\nPerdida validación: 4.69145804643631\nÉpoca 819\nPerdida entrenamiento: 0.056150777981831476\nPerdida validación: 3.3038771846331656\nÉpoca 820\nPerdida entrenamiento: 0.058985657416857205\nPerdida validación: 3.8559694290161133\nÉpoca 821\nPerdida entrenamiento: 0.05928831898535673\nPerdida validación: 4.11640003323555\nÉpoca 822\nPerdida entrenamiento: 0.05734322563960002\nPerdida validación: 4.668489754199982\nÉpoca 823\nPerdida entrenamiento: 0.056264102745514646\nPerdida validación: 3.920742154121399\nÉpoca 824\nPerdida entrenamiento: 0.05873554816039709\nPerdida validación: 3.493961662054062\nÉpoca 825\nPerdida entrenamiento: 0.05683453810902742\nPerdida validación: 6.510374307632446\nÉpoca 826\nPerdida entrenamiento: 0.055070443222155936\nPerdida validación: 4.398071765899658\nÉpoca 827\nPerdida entrenamiento: 0.05675230762706353\nPerdida validación: 4.375220954418182\nÉpoca 828\nPerdida entrenamiento: 0.055023180607419744\nPerdida validación: 6.8428884744644165\nÉpoca 829\nPerdida entrenamiento: 0.05631783174780699\nPerdida validación: 4.441886872053146\nÉpoca 830\nPerdida entrenamiento: 0.05498757557227062\nPerdida validación: 4.170099914073944\nÉpoca 831\nPerdida entrenamiento: 0.05439775250852108\nPerdida validación: 4.17107766866684\nÉpoca 832\nPerdida entrenamiento: 0.05483622884807678\nPerdida validación: 4.0521272122859955\nÉpoca 833\nPerdida entrenamiento: 0.054396349363602124\nPerdida validación: 4.2378314435482025\nÉpoca 834\nPerdida entrenamiento: 0.0537837570389876\nPerdida validación: 6.800297603011131\nÉpoca 835\nPerdida entrenamiento: 0.05468137791523567\nPerdida validación: 4.214636117219925\nÉpoca 836\nPerdida entrenamiento: 0.05472402432217048\nPerdida validación: 4.283179759979248\nÉpoca 837\nPerdida entrenamiento: 0.054236042886399306\nPerdida validación: 4.970643877983093\nÉpoca 838\nPerdida entrenamiento: 0.053958216395515665\nPerdida validación: 4.149262264370918\nÉpoca 839\nPerdida entrenamiento: 0.05368467112286733\nPerdida validación: 4.775151491165161\nÉpoca 840\nPerdida entrenamiento: 0.05479082651436329\nPerdida validación: 4.5180723667144775\nÉpoca 841\nPerdida entrenamiento: 0.05527265548992615\nPerdida validación: 4.143805742263794\nÉpoca 842\nPerdida entrenamiento: 0.05225516497515715\nPerdida validación: 4.767333805561066\nÉpoca 843\nPerdida entrenamiento: 0.05295462655619933\nPerdida validación: 4.054084673523903\nÉpoca 844\nPerdida entrenamiento: 0.052490573591337755\nPerdida validación: 4.043152339756489\nÉpoca 845\nPerdida entrenamiento: 0.05167995869683532\nPerdida validación: 4.035788454610156\nÉpoca 846\nPerdida entrenamiento: 0.05253026355057955\nPerdida validación: 4.491959989070892\nÉpoca 847\nPerdida entrenamiento: 0.05272071479031673\nPerdida validación: 4.08733955770731\nÉpoca 848\nPerdida entrenamiento: 0.051107910461723804\nPerdida validación: 4.299175828695297\nÉpoca 849\nPerdida entrenamiento: 0.05270489319585837\nPerdida validación: 4.7589231133461\nÉpoca 850\nPerdida entrenamiento: 0.05218249845963258\nPerdida validación: 4.42910698056221\nÉpoca 851\nPerdida entrenamiento: 0.0517392076838475\nPerdida validación: 4.063683340325952\nÉpoca 852\nPerdida entrenamiento: 0.05056576960935043\nPerdida validación: 4.544508397579193\nÉpoca 853\nPerdida entrenamiento: 0.050385619298769876\nPerdida validación: 7.497417986392975\nÉpoca 854\nPerdida entrenamiento: 0.051967507729736656\nPerdida validación: 4.558947831392288\nÉpoca 855\nPerdida entrenamiento: 0.050523535993236765\nPerdida validación: 7.215233594179153\nÉpoca 856\nPerdida entrenamiento: 0.05060775463397686\nPerdida validación: 4.495422422885895\nÉpoca 857\nPerdida entrenamiento: 0.05093105721215789\nPerdida validación: 7.129923522472382\nÉpoca 858\nPerdida entrenamiento: 0.05117681049383604\nPerdida validación: 4.351238787174225\nÉpoca 859\nPerdida entrenamiento: 0.05049055363409794\nPerdida validación: 4.08912917599082\nÉpoca 860\nPerdida entrenamiento: 0.05090016857362711\nPerdida validación: 4.626007974147797\nÉpoca 861\nPerdida entrenamiento: 0.0504580932454421\nPerdida validación: 4.207754582166672\nÉpoca 862\nPerdida entrenamiento: 0.050872162414284855\nPerdida validación: 4.572880119085312\nÉpoca 863\nPerdida entrenamiento: 0.05100252135441853\nPerdida validación: 7.2558281272649765\nÉpoca 864\nPerdida entrenamiento: 0.04953286008766064\nPerdida validación: 4.496209770441055\nÉpoca 865\nPerdida entrenamiento: 0.05012407168172873\nPerdida validación: 4.0990868136286736\nÉpoca 866\nPerdida entrenamiento: 0.048918719618366316\nPerdida validación: 4.131444938480854\nÉpoca 867\nPerdida entrenamiento: 0.04928459671254341\nPerdida validación: 5.020654857158661\nÉpoca 868\nPerdida entrenamiento: 0.04903019620822026\nPerdida validación: 4.551450133323669\nÉpoca 869\nPerdida entrenamiento: 0.04945437524181146\nPerdida validación: 4.500010818243027\nÉpoca 870\nPerdida entrenamiento: 0.04856425581070093\nPerdida validación: 4.7949676513671875\nÉpoca 871\nPerdida entrenamiento: 0.04902963899075985\nPerdida validación: 7.995621174573898\nÉpoca 872\nPerdida entrenamiento: 0.04977420273308571\nPerdida validación: 7.18223363161087\nÉpoca 873\nPerdida entrenamiento: 0.04900971413231813\nPerdida validación: 5.231534659862518\nÉpoca 874\nPerdida entrenamiento: 0.049250427060402356\nPerdida validación: 4.179678939282894\nÉpoca 875\nPerdida entrenamiento: 0.048545404337346554\nPerdida validación: 7.5138179659843445\nÉpoca 876\nPerdida entrenamiento: 0.04902011091605975\nPerdida validación: 7.690000653266907\nÉpoca 877\nPerdida entrenamiento: 0.049634022459101215\nPerdida validación: 4.181770049035549\nÉpoca 878\nPerdida entrenamiento: 0.04979390636659586\nPerdida validación: 4.789144668728113\nÉpoca 879\nPerdida entrenamiento: 0.04782095207617833\nPerdida validación: 7.752316355705261\nÉpoca 880\nPerdida entrenamiento: 0.047524592480980433\nPerdida validación: 4.361296311020851\nÉpoca 881\nPerdida entrenamiento: 0.04772741806048613\nPerdida validación: 5.283886909484863\nÉpoca 882\nPerdida entrenamiento: 0.049345526414421886\nPerdida validación: 5.229241371154785\nÉpoca 883\nPerdida entrenamiento: 0.04679644315575178\nPerdida validación: 7.914421200752258\nÉpoca 884\nPerdida entrenamiento: 0.04703991981939627\nPerdida validación: 5.433315575122833\nÉpoca 885\nPerdida entrenamiento: 0.049513145278279595\nPerdida validación: 7.677872061729431\nÉpoca 886\nPerdida entrenamiento: 0.04793915123893665\nPerdida validación: 5.197003066539764\nÉpoca 887\nPerdida entrenamiento: 0.04776551424024197\nPerdida validación: 5.358761668205261\nÉpoca 888\nPerdida entrenamiento: 0.0485514304958857\nPerdida validación: 4.744048622378614\nÉpoca 889\nPerdida entrenamiento: 0.049604152114345476\nPerdida validación: 8.026496231555939\nÉpoca 890\nPerdida entrenamiento: 0.04807417854093588\nPerdida validación: 5.384512186050415\nÉpoca 891\nPerdida entrenamiento: 0.04864290915429592\nPerdida validación: 5.179917335510254\nÉpoca 892\nPerdida entrenamiento: 0.04812890613594881\nPerdida validación: 5.456477701663971\nÉpoca 893\nPerdida entrenamiento: 0.04833104031590315\nPerdida validación: 8.13897693157196\nÉpoca 894\nPerdida entrenamiento: 0.04785565258218692\nPerdida validación: 7.886135160923004\nÉpoca 895\nPerdida entrenamiento: 0.049369161805281274\nPerdida validación: 7.536204218864441\nÉpoca 896\nPerdida entrenamiento: 0.05050841332055055\nPerdida validación: 5.33561635017395\nÉpoca 897\nPerdida entrenamiento: 0.04976207891908976\nPerdida validación: 7.572638392448425\nÉpoca 898\nPerdida entrenamiento: 0.048271565626447015\nPerdida validación: 5.2607505321502686\nÉpoca 899\nPerdida entrenamiento: 0.0469307591422246\nPerdida validación: 4.9310347735881805\nÉpoca 900\nPerdida entrenamiento: 0.046212898853879705\nPerdida validación: 10.429802477359772\nÉpoca 901\nPerdida entrenamiento: 0.04607743311386842\nPerdida validación: 8.391501128673553\nÉpoca 902\nPerdida entrenamiento: 0.0450165058987645\nPerdida validación: 7.945931136608124\nÉpoca 903\nPerdida entrenamiento: 0.04573409936319177\nPerdida validación: 6.206254571676254\nÉpoca 904\nPerdida entrenamiento: 0.046273574662896305\nPerdida validación: 4.837220882647671\nÉpoca 905\nPerdida entrenamiento: 0.04536168943517483\nPerdida validación: 5.7693856954574585\nÉpoca 906\nPerdida entrenamiento: 0.04983616161804933\nPerdida validación: 4.874648252502084\nÉpoca 907\nPerdida entrenamiento: 0.048089443491055414\nPerdida validación: 4.867903176695108\nÉpoca 908\nPerdida entrenamiento: 0.04482537740841508\nPerdida validación: 5.361008048057556\nÉpoca 909\nPerdida entrenamiento: 0.04441759233864454\nPerdida validación: 8.161953628063202\nÉpoca 910\nPerdida entrenamiento: 0.04429550490413721\nPerdida validación: 5.4278759360313416\nÉpoca 911\nPerdida entrenamiento: 0.04375691038484757\nPerdida validación: 5.562376141548157\nÉpoca 912\nPerdida entrenamiento: 0.04385505602336847\nPerdida validación: 5.063310891389847\nÉpoca 913\nPerdida entrenamiento: 0.04419422715615768\nPerdida validación: 5.079816937446594\nÉpoca 914\nPerdida entrenamiento: 0.043570125833726846\nPerdida validación: 5.188879191875458\nÉpoca 915\nPerdida entrenamiento: 0.043833284853742674\nPerdida validación: 4.941752478480339\nÉpoca 916\nPerdida entrenamiento: 0.04390216339379549\nPerdida validación: 4.89091937802732\nÉpoca 917\nPerdida entrenamiento: 0.04507616391548744\nPerdida validación: 5.422266781330109\nÉpoca 918\nPerdida entrenamiento: 0.043265287119608656\nPerdida validación: 5.867627322673798\nÉpoca 919\nPerdida entrenamiento: 0.04298393084452702\nPerdida validación: 7.655619859695435\nÉpoca 920\nPerdida entrenamiento: 0.04295176403740278\nPerdida validación: 10.454034566879272\nÉpoca 921\nPerdida entrenamiento: 0.04356664985131759\nPerdida validación: 5.592731535434723\nÉpoca 922\nPerdida entrenamiento: 0.042768083369502656\nPerdida validación: 4.900315457955003\nÉpoca 923\nPerdida entrenamiento: 0.045229774326659165\nPerdida validación: 5.696951985359192\nÉpoca 924\nPerdida entrenamiento: 0.04300991954425207\nPerdida validación: 4.877590395510197\nÉpoca 925\nPerdida entrenamiento: 0.04320732837256331\nPerdida validación: 5.988415837287903\nÉpoca 926\nPerdida entrenamiento: 0.04337704124358984\nPerdida validación: 8.132118225097656\nÉpoca 927\nPerdida entrenamiento: 0.043636782381397024\nPerdida validación: 5.575676202774048\nÉpoca 928\nPerdida entrenamiento: 0.043071469435325034\nPerdida validación: 7.69149649143219\nÉpoca 929\nPerdida entrenamiento: 0.04279871220485522\nPerdida validación: 8.94551944732666\nÉpoca 930\nPerdida entrenamiento: 0.04158741343193329\nPerdida validación: 5.9363309144973755\nÉpoca 931\nPerdida entrenamiento: 0.042360139437592946\nPerdida validación: 5.669342577457428\nÉpoca 932\nPerdida entrenamiento: 0.04308424804073114\nPerdida validación: 7.684343189001083\nÉpoca 933\nPerdida entrenamiento: 0.042666685265990406\nPerdida validación: 11.007444053888321\nÉpoca 934\nPerdida entrenamiento: 0.04146604684109871\nPerdida validación: 5.555517554283142\nÉpoca 935\nPerdida entrenamiento: 0.04259964572982146\nPerdida validación: 5.175597250461578\nÉpoca 936\nPerdida entrenamiento: 0.04205227105949934\nPerdida validación: 5.40211808681488\nÉpoca 937\nPerdida entrenamiento: 0.04228109278931068\nPerdida validación: 6.1808552742004395\nÉpoca 938\nPerdida entrenamiento: 0.04311830536104166\nPerdida validación: 10.741185247898102\nÉpoca 939\nPerdida entrenamiento: 0.043163470637339815\nPerdida validación: 5.921260833740234\nÉpoca 940\nPerdida entrenamiento: 0.04055054041628654\nPerdida validación: 5.262785702943802\nÉpoca 941\nPerdida entrenamiento: 0.04157177903331243\nPerdida validación: 5.35451865196228\nÉpoca 942\nPerdida entrenamiento: 0.0415198694771299\nPerdida validación: 7.973495125770569\nÉpoca 943\nPerdida entrenamiento: 0.040533507314439006\nPerdida validación: 4.92364627122879\nÉpoca 944\nPerdida entrenamiento: 0.04062959207938267\nPerdida validación: 5.073706194758415\nÉpoca 945\nPerdida entrenamiento: 0.040624873067897097\nPerdida validación: 8.072493553161621\nÉpoca 946\nPerdida entrenamiento: 0.040667824447155\nPerdida validación: 5.12357422709465\nÉpoca 947\nPerdida entrenamiento: 0.04132207554693405\nPerdida validación: 4.931139972992241\nÉpoca 948\nPerdida entrenamiento: 0.041251580589092694\nPerdida validación: 6.213336825370789\nÉpoca 949\nPerdida entrenamiento: 0.03960881582819498\nPerdida validación: 5.1579442620277405\nÉpoca 950\nPerdida entrenamiento: 0.04065688083378168\nPerdida validación: 5.068708926439285\nÉpoca 951\nPerdida entrenamiento: 0.041666437370272785\nPerdida validación: 5.178554832935333\nÉpoca 952\nPerdida entrenamiento: 0.04248258535965131\nPerdida validación: 7.714734971523285\nÉpoca 953\nPerdida entrenamiento: 0.03928559345121567\nPerdida validación: 4.913980485871434\nÉpoca 954\nPerdida entrenamiento: 0.041722226314819776\nPerdida validación: 5.258084446191788\nÉpoca 955\nPerdida entrenamiento: 0.04159032173741322\nPerdida validación: 5.252501457929611\nÉpoca 956\nPerdida entrenamiento: 0.04170346489319435\nPerdida validación: 4.984535411000252\nÉpoca 957\nPerdida entrenamiento: 0.04048321252832046\nPerdida validación: 8.03850769996643\nÉpoca 958\nPerdida entrenamiento: 0.04004818967615183\nPerdida validación: 8.282288789749146\nÉpoca 959\nPerdida entrenamiento: 0.04017204476090578\nPerdida validación: 8.028823256492615\nÉpoca 960\nPerdida entrenamiento: 0.03906387448883974\nPerdida validación: 5.145549774169922\nÉpoca 961\nPerdida entrenamiento: 0.041092993978124395\nPerdida validación: 5.181346893310547\nÉpoca 962\nPerdida entrenamiento: 0.03917228444837607\nPerdida validación: 5.263754636049271\nÉpoca 963\nPerdida entrenamiento: 0.03960341867059469\nPerdida validación: 5.101293057203293\nÉpoca 964\nPerdida entrenamiento: 0.03922462800087837\nPerdida validación: 5.038782596588135\nÉpoca 965\nPerdida entrenamiento: 0.03790095942811324\nPerdida validación: 4.954838437348371\nÉpoca 966\nPerdida entrenamiento: 0.03930759118296779\nPerdida validación: 5.001334883272648\nÉpoca 967\nPerdida entrenamiento: 0.03813998795186098\nPerdida validación: 6.026365399360657\nÉpoca 968\nPerdida entrenamiento: 0.038181327283382416\nPerdida validación: 5.887161493301392\nÉpoca 969\nPerdida entrenamiento: 0.03895379753353504\nPerdida validación: 5.548644781112671\nÉpoca 970\nPerdida entrenamiento: 0.03912664047227456\nPerdida validación: 5.311693072319031\nÉpoca 971\nPerdida entrenamiento: 0.03870617698591489\nPerdida validación: 5.490020513534546\nÉpoca 972\nPerdida entrenamiento: 0.03748865955724166\nPerdida validación: 10.62033686041832\nÉpoca 973\nPerdida entrenamiento: 0.03864966748425594\nPerdida validación: 5.311264842748642\nÉpoca 974\nPerdida entrenamiento: 0.03776480472431733\nPerdida validación: 6.198935285210609\nÉpoca 975\nPerdida entrenamiento: 0.03823253541038586\nPerdida validación: 6.116997182369232\nÉpoca 976\nPerdida entrenamiento: 0.037811676756693766\nPerdida validación: 5.664330780506134\nÉpoca 977\nPerdida entrenamiento: 0.038681479170918465\nPerdida validación: 5.71380490064621\nÉpoca 978\nPerdida entrenamiento: 0.03898881017588652\nPerdida validación: 5.0552245527505875\nÉpoca 979\nPerdida entrenamiento: 0.0369387546984049\nPerdida validación: 5.013122085481882\nÉpoca 980\nPerdida entrenamiento: 0.03696431670911037\nPerdida validación: 5.435646593570709\nÉpoca 981\nPerdida entrenamiento: 0.0377054988191678\nPerdida validación: 7.99576997756958\nÉpoca 982\nPerdida entrenamiento: 0.03688380738290457\nPerdida validación: 5.6264747977256775\nÉpoca 983\nPerdida entrenamiento: 0.03905959971822225\nPerdida validación: 5.130975678563118\nÉpoca 984\nPerdida entrenamiento: 0.03906594059215142\nPerdida validación: 5.282015740871429\nÉpoca 985\nPerdida entrenamiento: 0.040465183269519076\nPerdida validación: 5.062030218541622\nÉpoca 986\nPerdida entrenamiento: 0.039131697912055716\nPerdida validación: 5.825139343738556\nÉpoca 987\nPerdida entrenamiento: 0.03985199138808709\nPerdida validación: 4.996991615742445\nÉpoca 988\nPerdida entrenamiento: 0.03810182027518749\nPerdida validación: 5.061925791203976\nÉpoca 989\nPerdida entrenamiento: 0.03756197885825084\nPerdida validación: 6.193111687898636\nÉpoca 990\nPerdida entrenamiento: 0.037496679104291476\nPerdida validación: 5.766824841499329\nÉpoca 991\nPerdida entrenamiento: 0.037181258703080505\nPerdida validación: 5.420461535453796\nÉpoca 992\nPerdida entrenamiento: 0.03704871022357391\nPerdida validación: 8.288544058799744\nÉpoca 993\nPerdida entrenamiento: 0.03609542168963414\nPerdida validación: 5.090890198945999\nÉpoca 994\nPerdida entrenamiento: 0.03537790541752027\nPerdida validación: 7.8367608189582825\nÉpoca 995\nPerdida entrenamiento: 0.036478488777692504\nPerdida validación: 8.35268884897232\nÉpoca 996\nPerdida entrenamiento: 0.03573003110404198\nPerdida validación: 8.260665535926819\nÉpoca 997\nPerdida entrenamiento: 0.0378370895408667\nPerdida validación: 5.0253689478267916\nÉpoca 998\nPerdida entrenamiento: 0.03472784552006768\nPerdida validación: 7.795221388339996\nÉpoca 999\nPerdida entrenamiento: 0.035625782007208236\nPerdida validación: 5.025393606225407\nÉpoca 1000\nPerdida entrenamiento: 0.034889969401634656\nPerdida validación: 6.157822489738464\n\n\nComo se puede observar la pérdida de validación empieza a ser mucho mayor que la pérdida de entrenamiento, esto es un claro indicador de Overfitting"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "",
    "text": "Profesor Asociado en la Universidad Escuela Colombiana de Ingenieria, Analista de Datos con un sólido trasfondo como Ingeniero en Electrónica y Telecomunicaciones y Doctor en Ciencias de la Electrónica. Cuento con 20 años de experiencia en Educación Universitaria y una destacada participación en proyectos de investigación en el campo de la Ciencia de los Datos aplicada a las organizaciones, el aprendizaje y la ciencia. Mi enfoque se centra en utilizar mis habilidades técnicas y experiencia para analizar grandes conjuntos de datos y extraer conocimientos valiosos que impulsen la toma de decisiones informadas."
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2016",
    "text": "2016\n- P. E. Caicedo-Rodríguez, Rengifo-Rodas, Carlos Felipe, y Rodríguez-Cheu, Luis Eduardo, «Contributions of electronic sciences to the problem of falls of old age population», 2016, doi: 10.17488/RMIB.37.3.6."
  },
  {
    "objectID": "about.html#section-1",
    "href": "about.html#section-1",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2017",
    "text": "2017\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, y L. E. Rodríguez-Cheu, «A human gait temporal parameters calculation algorithm», en VII Latin American Congress on Biomedical Engineering CLAIB 2016, Bucaramanga, Santander, Colombia, October 26th -28th, 2016, vol. 60, I. Torres, J. Bustamante, y D. A. Sierra, Eds., en IFMBE Proceedings, vol. 60. , Singapore: Springer Singapore, 2017, pp. 285-288. doi: 10.1007/978-981-10-4086-3_72."
  },
  {
    "objectID": "about.html#section-2",
    "href": "about.html#section-2",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2018",
    "text": "2018\n-  S. P. Castillo-Landínez y P. E. Caicedo-Rodríguez, «EL BLOG COMO HERRAMIENTA DE ENSEÑANZA EN LOS CURSOS DE INVESTIGACIÓN», presentado en Encuentro Internacional de Educación en Ingeniería ACOFI, Cartagena, Colombia, 2018."
  },
  {
    "objectID": "about.html#section-3",
    "href": "about.html#section-3",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2019",
    "text": "2019\n- N. Valencia-Jimenez et al., «A Comparative Study of Markerless Systems Based on Color-Depth Cameras, Polymer Optical Fiber Curvature Sensors, and Inertial Measurement Units: Towards Increasing the Accuracy in Joint Angle Estimation», Electronics, vol. 8, n.º 2, p. 173, feb. 2019, doi: 10.3390/electronics8020173.\n- S. P. Castillo-Landinez, P. E. Caicedo-Rodríguez, y D. F. Sánchez-Gómez, «Diseño e implementación de un software para la trazabilidad del proceso de beneficio del café», CTA, vol. 20, n.º 3, sep. 2019, doi: 10.21930/rcta.vol20_num3_art:1588.\n- P. E. Caicedo-Rodriguez, C. F. Rengifo-Rodas, L. E. Rodríguez-Cheu, y W. A. Sierra-Arevalo, «Gait Phase Detection for Lower Limb Prosthetic Devices», en Wearable Robotics: Challenges and Trends, vol. 22, M. C. Carrozza, S. Micera, y J. L. Pons, Eds., en Biosystems & Biorobotics, vol. 22. , Cham: Springer International Publishing, 2019, pp. 201-205. doi: 10.1007/978-3-030-01887-0_39.\n- S. P. Castillo-Landínez y P. E. Caicedo-Rodríguez, «ANÁLISIS DE SENTIMIENTOS, UNA HERRAMIENTA PARA VALORAR LA ACTITUD DEL ESTUDIANTE FRENTE A UN CURSO», presentado en Encuentro internacional de educación en ingeniería, Cartagena, Colombia, 2019.\nP. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, y L. E. Rodriguez-Cheu, «LA VELOCIDAD DE MARCHA COMO FACTOR DISCRIMINATORIO DEL RIESGO DE CAÍDA EN ADULTOS MAYORES», presentado en Encuentro internacional de educación en ingeniería, Cartagena, Colombia, 2019. doi: 10.26507/ponencia.282."
  },
  {
    "objectID": "about.html#section-4",
    "href": "about.html#section-4",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2020",
    "text": "2020\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. Gómez-Guevara, «Dataset for gait analysis and assessment of fall risk for older adults», Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. Gómez-Guevara, «Dataset for gait analysis and assessment of fall risk for older adults», Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- Y. H. Bolaños-Muñoz, C. F. Rengifo-Rodas, P. E. Caicedo-Rodríguez, L. E. Rodriguez-Cheu, y W. A. Sierra-Arevalo, «Electronic system for step width estimation using programmable system-on-chip technology and time of flight cameras», HardwareX, vol. 8, p. e00126, oct. 2020, doi: 10.1016/j.ohx.2020.e00126.\n- S. P. Castillo Landínez, P. E. Caicedo Rodríguez, y S. A. Muñoz De La Rosa, «LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA CUARENTENA A TRAVÉS DEL ANÁLISIS DE SENTIMIENTOS. UN CASO DE ESTUDIO EN LA UNIAUTÓNOMA DEL CAUCA», en Encuentro Internacional de Educación en Ingeniería ACOFI 2020, Asociacion Colombiana de Facultades de Ingeniería - ACOFI, ago. 2020, pp. 1-8. doi: 10.26507/ponencia.820.\n- J. P. Henao-Pereira, A. E. Tovar-Leon, S. P. Castillo-Landínez, y P. E. Caicedo-Rodríguez, «Los accidentes de tránsito desde la perspectiva de la minería de datos. Una revisión de la literatura», Aibi revista investig. adm. ing., pp. 133-141, ago. 2020, doi: 10.15649/2346030X.743."
  },
  {
    "objectID": "about.html#section-5",
    "href": "about.html#section-5",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2021",
    "text": "2021\n- P. E. Caicedo-Rodríguez, Incidencia de los sistemas electrónicos de medición de variables biomecánicas en la concordancia intra e inter evaluador del examen POMA de función motora, Primera. Popayán, Colombia: Sello Editorial Uniautónoma del Cauca, 2021.\n- S. Castillo Landínez, P. E. Caicedo Rodríguez, S. A. Muñoz De La Rosa, y J. P. Sandoval Paz, «LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA PANDEMIA, UN AÑO DESPUÉS», en Encuentro Internacional de Educación en Ingeniería ACOFI 2021, Asociacion Colombiana de Facultades de Ingeniería - ACOFI, sep. 2021, pp. 1-9. doi: 10.26507/ponencia.2005.\n- L. S. Vargas-Valencia et al., «Sleeve for Knee Angle Monitoring: An IMU-POF Sensor Fusion System», IEEE J. Biomed. Health Inform., vol. 25, n.º 2, pp. 465-474, feb. 2021, doi: 10.1109/JBHI.2020.2988360.\n- C. R. Malaver-Flor y M. Y. Astorquiza-Velasco, «Técnicas de Procesamiento Para Variables Posturales Enfocadas en Detección Temprana Del Microtraumatismo Tisular de un Ciclista», PROSPECTIVA, vol. 19, n.º 2, 2021."
  },
  {
    "objectID": "about.html#section-6",
    "href": "about.html#section-6",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2022",
    "text": "2022\n- S. Castillo Landínez, P. E. Caicedo Rodríguez, y J. A. Mosquera Bolaños, «Los adolescentes y el uso de las redes sociales. Un análisis desde la óptica de la ciencia de datos y el procesamiento de lenguaje natural», presentado en Nuevas realidades para la educación en ingeniería: currículo, tecnología, medio ambiente y desarrollo, sep. 2022, pp. 1-8. doi: 10.26507/paper.2693.\n- V. Cerón Monje, C. E. Zúñiga Muñoz, S. P. Castillo Landínez, y P. E. Caicedo Rodríguez, «Análisis de sentimientos aplicado a la evaluación docente de la Corporación Universitaria Autónoma del Cauca», presentado en Nuevas realidades para la educación en ingeniería: currículo, tecnología, medio ambiente y desarrollo, sep. 2022, pp. 1-10. doi: 10.26507/paper.2308."
  },
  {
    "objectID": "about.html#section-7",
    "href": "about.html#section-7",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2023",
    "text": "2023\n- J. M. Cabrera Ángel, P. E. Caicedo-Rodríguez, y S. Castillo-Landínez, «Así nos vemos», Uniautonoma del Cauca, Popayán, 2023.\n- S. Castillo Landínez y P. E. Caicedo Rodríguez, «¡¡¡Ahora sí tocó poner atención porque hay que evaluar!!!», presentado en Ingeniería para transformar territorios, sep. 2023, pp. 1-10. doi: 10.26507/paper.2941."
  },
  {
    "objectID": "about.html#section-8",
    "href": "about.html#section-8",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2024",
    "text": "2024"
  },
  {
    "objectID": "laboratorios/APSB/lab01_IniciandoJetsonNano.html",
    "href": "laboratorios/APSB/lab01_IniciandoJetsonNano.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Download the Jetson Nano 2GB Developer Kit SD Card Image and note where it was saved on the computer.\nDownload, install, and launchSD Memory Card Formatter for Windows\nDownload, install, and launch Etcher."
  },
  {
    "objectID": "laboratorios/APSB/lab01_IniciandoJetsonNano.html#requiered-downloads",
    "href": "laboratorios/APSB/lab01_IniciandoJetsonNano.html#requiered-downloads",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Download the Jetson Nano 2GB Developer Kit SD Card Image and note where it was saved on the computer.\nDownload, install, and launchSD Memory Card Formatter for Windows\nDownload, install, and launch Etcher."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Requisitos:",
    "text": "Requisitos:\n\nIdentificar un problema de salud específico y relevante, relacionado con los ODS.\nJustificar la importancia del problema y la necesidad de una solución innovadora.\nEstablecer objetivos claros y medibles para el proyecto.\nElegir un dataset apropiado de señales (1D).\nDesarrollar una solución técnica que satisfaga los indicadores de solución de problema, con descripción matemática, física y/o estadística.\nImplementar la solución en Python."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Rúbrica de evaluación",
    "text": "Rúbrica de evaluación\n\n\n\n\n\n\n\n\n\n\nCriterio\nPuntos\nBueno\nRegular\nMalo\n\n\n\n\nProblema de salud identificado\n15\nProblema claro, relevante y bien justificado (15puntos)\nProblema claro, pero justificación débil (7puntos)\nProblema no claro o no relevante (0puntos)\n\n\nJustificación y objetivos\n15\nJustificación sólida y objetivos claros y medibles (15puntos)\nJustificación débil y objetivos poco claros (7puntos)\nJustificación y objetivos no claros (0puntos)\n\n\nSolución técnica\n20\nSolución innovadora, bien fundamentada y correctamente implementada en Python (20puntos)\nSolución adecuada, pero con errores en la implementación (10puntos)\nSolución no innovadora o con errores graves (0puntos)\n\n\nDiseño de indicadores\n20\nIndicadores bien definidos, con descripción matemática, médica y estadística clara y precisa (20puntos)\nIndicadores bien definidos, pero con descripción no clara o incompleta (10puntos)\nIndicadores no bien definidos o sin descripción (0puntos)\n\n\nContribución a los ODS\n10\nContribución clara y significativa a los ODS (10puntos)\nContribución moderada a los ODS (7puntos)\nContribución no clara o nula a los ODS (0puntos)\n\n\nImpacto potencial en la salud\n10\nImpacto potencial alto y bien justificado (10puntos)\nImpacto potencial moderado y justificación débil (7puntos)\nImpacto potencial bajo o no justificado (0puntos)\n\n\nPresentación y documentación\n10\nPresentación clara y documentación precisa y completa (10puntos)\nPresentación clara, pero documentación no precisa (7puntos)\nPresentación no clara o documentación no está presente (0puntos)"
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Al finalizar, el estudiante será capaz de:\n1. Explicar la relación entre la profundidad de bit \\(b\\), los niveles representables \\(L=2^{b}\\) y el paso de cuantización \\(\\Delta\\) en una imagen digital.\n2. Adquirir y documentar imágenes bajo condiciones controladas para analizar rango dinámico, histogramas y artefactos de cuantización (banding, posterización).\n3. Convertir imágenes RGB a espacios HSV, CIE L*a*b* y Y’CrCb (formato OpenCV) e interpretar la semántica de canales e histogramas.\n4. Cuantizar imágenes a distintas profundidades de bit y evaluar distorsión con \\(\\mathrm{MSE}\\); discutir perceptualmente los cambios.\n5. Justificar la elección de espacio de color según la tarea (robustez a iluminación, segmentación, compresión) con evidencia cualitativa y cuantitativa.\n\n\n\n\n\nCuantización. Para una señal \\(x\\in[X_{\\min},X_{\\max}]\\), la cuantización uniforme escalar con \\(b\\) bits tiene \\(L=2^{b}\\) niveles y paso \\(\\Delta=\\dfrac{X_{\\max}-X_{\\min}}{L}\\). El error de cuantización \\(e=x-\\hat{x}\\in[-\\Delta/2,\\Delta/2]\\) (mid-tread).\nRango dinámico. En \\(b\\) bits sin signo: \\([0,\\,2^{b}-1]\\) (en 8 bits: \\([0,255]\\)).\nEspacios de color (OpenCV).\n\nBGR (lectura por defecto en OpenCV).\n\nHSV: cv2.COLOR_BGR2HSV (H en [0,179] para uint8).\n\nLab: cv2.COLOR_BGR2LAB (uint8: \\(L^\\*\\in[0,255]\\), \\(a^\\*,b^\\*\\approx[0,255]\\) con 128 ≈ neutro).\n\nYCrCb: cv2.COLOR_BGR2YCrCb (orden de cromas: Y, Cr, Cb).\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nOpenCV trabaja en BGR (no RGB) cuando lee/escribe imágenes con cv2.imread y cv2.imwrite. Para mostrar correctamente en archivos guardados, no es necesario convertir a RGB; sin embargo, documente siempre el orden de canales.\n\n\n\n\n\n\n\n\nCámara de teléfono u ordenador. Fijar ISO, tiempo de exposición y balance de blancos. Preferir PNG/TIFF (sin pérdidas); si es posible, capturar RAW+JPEG.\nEscena estática con colores saturados y neutros (p. ej., cuadrícula de color y rampa en escala de grises en un monitor). Iluminación difusa y estable.\nPython 3.12 con: opencv-python y numpy. No use otras librerías de imagen/visualización.\n\n\n\n\n\n\nMontaje de escena (iluminación constante). Fondo neutro; evitar brillos especulares.\n\nConjunto A (referencia, 8 bits sin pérdidas). Guardar una imagen nítida y bien expuesta en PNG/TIFF.\n\nConjunto B (bracketing de exposición). ±1 y ±2 EV respecto a la referencia para discutir recorte (clipping) vs. cuantización.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nMantenga fijos los parámetros de cámara entre capturas. Cambios en ISO o WB confunden los análisis de profundidad de bit y espacio de color.\n\n\n\n\n\n\n\nCargar la imagen de referencia. Inspeccionar forma, dtype, mínimos/máximos usando únicamente OpenCV.\n\nEstimar el uso efectivo de bits contando valores distintos por canal.\nCuente cuantos pixeles hay, por cada canal y nivel del canal\n\n\n\n\n\n-Explique que es el error cuadrático medio (MSE, por sus siglas en inglés) y la relación señal a rudio pico (PSNR, por sus siglas en inglés), Cuantice la imagen BGR de referencia a \\(b\\in\\{1,2,\\dots,7\\}\\) bits (por canal). Para cada \\(b\\):\n\nCalcule \\(\\mathrm{MSE}\\) y \\(\\mathrm{PSNR}\\) respecto a la referencia ($b=8).\nGenere y guarde la imagen cuantizada y un mapa de error visual (colormap).\n\n\n\n\n\n\nConvertir la imagen de referencia a HSV, Lab y YCrCb (OpenCV).\n\nCuantizar solo un canal a \\(b\\in\\{2,4\\}\\) (mantener los otros en 8 bits), revertir a BGR y guardar resultados.\n\nComparar perceptualmente artefactos entre cuantizar luminancia (Y) y crominancias (Cr/Cb), y entre canales de HSV/Lab.\n\n\n\n\n\n\nInforme Latex (PDF) con:\n\nProtocolo de adquisición, metadatos y fotos de la escena.\n\nResultados de Actividades 1–3 (figuras, histogramas, tablas).\n\nTabla que resuma qué espacio/canal soporta mayor cuantización con artefactos mínimos (justifique).\n\nTabla con MSE vs. \\(b\\) (sin PSNR).\n\n\nCarpeta reproducible con código e imágenes originales (preferir PNG/TIFF).\n\n\n\n\n\nFormato: 10 minutos de presentación + 2–3 minutos de preguntas. Puntuación total: 100 puntos.\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPeso\nExcelente (A) (7puntos)\nBueno (B) (5puntos)\nA mejorar (C) (3puntos)\nInsuficiente (D/E) (0puntos)\n\n\n\n\nEstructura y narrativa\n15\nObjetivo, método y resultados se articulan con coherencia; introducción y cierre precisos en tiempo.\nSecuencia mayormente clara con leves transiciones débiles.\nOrden irregular; faltan transiciones clave.\nDesorganizada; propósito no se comprende.\n\n\nRigor técnico\n25\nDefiniciones y ecuaciones (\\(L=2^{b}\\), \\(\\Delta\\), \\(\\mathrm{MSE}\\)) correctas; supuestos declarados y validados.\nMenores imprecisiones sin afectar conclusiones.\nVarias imprecisiones o supuestos no justificados.\nErrores conceptuales graves o confusión sostenida.\n\n\nMetodología y adquisición\n15\nParámetros de cámara controlados; protocolo replicable; evidencia fotográfica clara.\nControl adecuado con una omisión menor.\nControl parcial; documentación incompleta.\nSin control de variables; documentación escasa.\n\n\nAnálisis y resultados\n20\nComparaciones entre espacios (HSV/Lab/YCrCb) con figuras pertinentes; conclusiones sustentadas.\nAnálisis correcto pero poco profundo o con pocas figuras.\nAnálisis superficial; conclusiones poco justificadas.\nSin análisis; afirmaciones sin evidencia.\n\n\nVisualización\n10\nFiguras legibles, ejes/leyendas correctas (en imágenes generadas con OpenCV); mapas de error bien presentados.\nVisualización adecuada con detalles mejorables.\nGráficos confusos o mal rotulados.\nVisualizaciones ausentes o incorrectas.\n\n\nGestión del tiempo\n10\nCulmina en 9–10 min; distribuye tiempo equilibradamente.\nLeve desviación (±1 min).\nDesviación moderada (±2 min).\nDesviación severa (&gt;±2 min) o no concluye.\n\n\nClaridad y comunicación\n5\nLenguaje técnico claro, voz y ritmo adecuados, contacto visual.\nGeneralmente claro con momentos de ambigüedad.\nDificultades frecuentes de expresión.\nIncomprensible o lectura de diapositivas.\n\n\n\nRecomendaciones de preparación (no evaluadas, pero sugeridas):\n- Ensayar con cronómetro (marcas en 3–6–9 min).\n- Limitar texto por diapositiva; priorizar comparativas claras (antes/después, por espacio y por \\(b\\)).\n- Anticipar dos preguntas técnicas (supuestos y limitaciones)."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#resultados-de-aprendizaje",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#resultados-de-aprendizaje",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Al finalizar, el estudiante será capaz de:\n1. Explicar la relación entre la profundidad de bit \\(b\\), los niveles representables \\(L=2^{b}\\) y el paso de cuantización \\(\\Delta\\) en una imagen digital.\n2. Adquirir y documentar imágenes bajo condiciones controladas para analizar rango dinámico, histogramas y artefactos de cuantización (banding, posterización).\n3. Convertir imágenes RGB a espacios HSV, CIE L*a*b* y Y’CrCb (formato OpenCV) e interpretar la semántica de canales e histogramas.\n4. Cuantizar imágenes a distintas profundidades de bit y evaluar distorsión con \\(\\mathrm{MSE}\\); discutir perceptualmente los cambios.\n5. Justificar la elección de espacio de color según la tarea (robustez a iluminación, segmentación, compresión) con evidencia cualitativa y cuantitativa."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#conceptos-clave-conciso",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#conceptos-clave-conciso",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Cuantización. Para una señal \\(x\\in[X_{\\min},X_{\\max}]\\), la cuantización uniforme escalar con \\(b\\) bits tiene \\(L=2^{b}\\) niveles y paso \\(\\Delta=\\dfrac{X_{\\max}-X_{\\min}}{L}\\). El error de cuantización \\(e=x-\\hat{x}\\in[-\\Delta/2,\\Delta/2]\\) (mid-tread).\nRango dinámico. En \\(b\\) bits sin signo: \\([0,\\,2^{b}-1]\\) (en 8 bits: \\([0,255]\\)).\nEspacios de color (OpenCV).\n\nBGR (lectura por defecto en OpenCV).\n\nHSV: cv2.COLOR_BGR2HSV (H en [0,179] para uint8).\n\nLab: cv2.COLOR_BGR2LAB (uint8: \\(L^\\*\\in[0,255]\\), \\(a^\\*,b^\\*\\approx[0,255]\\) con 128 ≈ neutro).\n\nYCrCb: cv2.COLOR_BGR2YCrCb (orden de cromas: Y, Cr, Cb).\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nOpenCV trabaja en BGR (no RGB) cuando lee/escribe imágenes con cv2.imread y cv2.imwrite. Para mostrar correctamente en archivos guardados, no es necesario convertir a RGB; sin embargo, documente siempre el orden de canales."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#materiales",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#materiales",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Cámara de teléfono u ordenador. Fijar ISO, tiempo de exposición y balance de blancos. Preferir PNG/TIFF (sin pérdidas); si es posible, capturar RAW+JPEG.\nEscena estática con colores saturados y neutros (p. ej., cuadrícula de color y rampa en escala de grises en un monitor). Iluminación difusa y estable.\nPython 3.12 con: opencv-python y numpy. No use otras librerías de imagen/visualización."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#protocolo-de-adquisición-documentar-en-el-informe",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#protocolo-de-adquisición-documentar-en-el-informe",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Montaje de escena (iluminación constante). Fondo neutro; evitar brillos especulares.\n\nConjunto A (referencia, 8 bits sin pérdidas). Guardar una imagen nítida y bien expuesta en PNG/TIFF.\n\nConjunto B (bracketing de exposición). ±1 y ±2 EV respecto a la referencia para discutir recorte (clipping) vs. cuantización.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nMantenga fijos los parámetros de cámara entre capturas. Cambios en ISO o WB confunden los análisis de profundidad de bit y espacio de color."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-1-exploración-inicial-y-chequeos",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-1-exploración-inicial-y-chequeos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Cargar la imagen de referencia. Inspeccionar forma, dtype, mínimos/máximos usando únicamente OpenCV.\n\nEstimar el uso efectivo de bits contando valores distintos por canal.\nCuente cuantos pixeles hay, por cada canal y nivel del canal"
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-2-reducción-de-profundidad-de-bit-y-calidad-mse",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-2-reducción-de-profundidad-de-bit-y-calidad-mse",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "-Explique que es el error cuadrático medio (MSE, por sus siglas en inglés) y la relación señal a rudio pico (PSNR, por sus siglas en inglés), Cuantice la imagen BGR de referencia a \\(b\\in\\{1,2,\\dots,7\\}\\) bits (por canal). Para cada \\(b\\):\n\nCalcule \\(\\mathrm{MSE}\\) y \\(\\mathrm{PSNR}\\) respecto a la referencia ($b=8).\nGenere y guarde la imagen cuantizada y un mapa de error visual (colormap)."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-3-transformaciones-de-espacio-de-color-y-semántica-de-canales",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-3-transformaciones-de-espacio-de-color-y-semántica-de-canales",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Convertir la imagen de referencia a HSV, Lab y YCrCb (OpenCV).\n\nCuantizar solo un canal a \\(b\\in\\{2,4\\}\\) (mantener los otros en 8 bits), revertir a BGR y guardar resultados.\n\nComparar perceptualmente artefactos entre cuantizar luminancia (Y) y crominancias (Cr/Cb), y entre canales de HSV/Lab."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#entregables",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#entregables",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Informe Latex (PDF) con:\n\nProtocolo de adquisición, metadatos y fotos de la escena.\n\nResultados de Actividades 1–3 (figuras, histogramas, tablas).\n\nTabla que resuma qué espacio/canal soporta mayor cuantización con artefactos mínimos (justifique).\n\nTabla con MSE vs. \\(b\\) (sin PSNR).\n\n\nCarpeta reproducible con código e imágenes originales (preferir PNG/TIFF)."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#rúbrica-de-evaluación-para-exposiciones-orales-10-minutos",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#rúbrica-de-evaluación-para-exposiciones-orales-10-minutos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Formato: 10 minutos de presentación + 2–3 minutos de preguntas. Puntuación total: 100 puntos.\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPeso\nExcelente (A) (7puntos)\nBueno (B) (5puntos)\nA mejorar (C) (3puntos)\nInsuficiente (D/E) (0puntos)\n\n\n\n\nEstructura y narrativa\n15\nObjetivo, método y resultados se articulan con coherencia; introducción y cierre precisos en tiempo.\nSecuencia mayormente clara con leves transiciones débiles.\nOrden irregular; faltan transiciones clave.\nDesorganizada; propósito no se comprende.\n\n\nRigor técnico\n25\nDefiniciones y ecuaciones (\\(L=2^{b}\\), \\(\\Delta\\), \\(\\mathrm{MSE}\\)) correctas; supuestos declarados y validados.\nMenores imprecisiones sin afectar conclusiones.\nVarias imprecisiones o supuestos no justificados.\nErrores conceptuales graves o confusión sostenida.\n\n\nMetodología y adquisición\n15\nParámetros de cámara controlados; protocolo replicable; evidencia fotográfica clara.\nControl adecuado con una omisión menor.\nControl parcial; documentación incompleta.\nSin control de variables; documentación escasa.\n\n\nAnálisis y resultados\n20\nComparaciones entre espacios (HSV/Lab/YCrCb) con figuras pertinentes; conclusiones sustentadas.\nAnálisis correcto pero poco profundo o con pocas figuras.\nAnálisis superficial; conclusiones poco justificadas.\nSin análisis; afirmaciones sin evidencia.\n\n\nVisualización\n10\nFiguras legibles, ejes/leyendas correctas (en imágenes generadas con OpenCV); mapas de error bien presentados.\nVisualización adecuada con detalles mejorables.\nGráficos confusos o mal rotulados.\nVisualizaciones ausentes o incorrectas.\n\n\nGestión del tiempo\n10\nCulmina en 9–10 min; distribuye tiempo equilibradamente.\nLeve desviación (±1 min).\nDesviación moderada (±2 min).\nDesviación severa (&gt;±2 min) o no concluye.\n\n\nClaridad y comunicación\n5\nLenguaje técnico claro, voz y ritmo adecuados, contacto visual.\nGeneralmente claro con momentos de ambigüedad.\nDificultades frecuentes de expresión.\nIncomprensible o lectura de diapositivas.\n\n\n\nRecomendaciones de preparación (no evaluadas, pero sugeridas):\n- Ensayar con cronómetro (marcas en 3–6–9 min).\n- Limitar texto por diapositiva; priorizar comparativas claras (antes/después, por espacio y por \\(b\\)).\n- Anticipar dos preguntas técnicas (supuestos y limitaciones)."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach\n\ndef f_hat(x):\n    return 4*(x**3) - 8*x\n\ndef shift(xs, n):\n    if n &gt;= 0:\n        return np.concatenate((np.full(n, xs[0]), xs[:-n]))\n    else:\n        return np.concatenate((xs[-n:], np.full(-n, xs[-1])))\n\ndef f_hat_num(x,t):\n    delta = shift(t, -1) - t\n    salida = (shift(x, -1) - x) / np.mean(delta[:-1])\n    return np.concatenate((salida[:-1], [salida[-2]]))\n\n\ntemp = np.array([0,1,2,3,4,5,6])\nnp.concatenate([temp, [temp[-1]]])\n\narray([0, 1, 2, 3, 4, 5, 6, 6])\n\n\n\nplt.plot(t, f_hat(t))\nplt.plot(t, f_hat_num(f(t), t))"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach\n\nimport sympy as sp\n\n# Define the variable and the expression\nx1 = sp.symbols(\"x1\")\nexpr = x1**4 - 4 * x1**2 + 4\n\nresult = sp.integrate(expr, (x1, -10, 10)).evalf()\n\n# Print the LaTeX representation\nprint(sp.latex(expr))\nprint(result)\n\nx_{1}^{4} - 4 x_{1}^{2} + 4\n37413.3333333333\n\n\n\n# Define the limits of integration\na = -10\nb = 10\n\n# Define the number of subintervals\nn = 100\n\n# Calculate the width of each subinterval\nh = (b - a) / n\n\n# Initialize the sum\nsum = 0.5 * (f(a) + f(b))\n\n# Apply the Trapezoid Rule\nfor i in range(1, n):\n    sum += f(a + i * h)\n\n# Calculate the integral\nintegral = h * sum\n\nprint(\"Approximate integral:\", integral)\n\nApproximate integral: 37439.465599999996"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)\n\n# Define the derivative function\ndef f1(x, y):\n    return 2 * x - 3 * y\n\n\n# Initial condition\nx0 = 0\ny0 = 1\n\n# Step size\nh = 0.1\n\n# Total steps\nn = int(10 / h)\n\n# Create arrays to store x and y values\nx = [0] * (n + 1)\ny = [0] * (n + 1)\n\n# Initialize x and y arrays\nx[0] = x0\ny[0] = y0\n\n# Euler's Method\nfor i in range(n):\n    x[i + 1] = x[i] + h\n    y[i + 1] = y[i] + h * f1(x[i], y[i])"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent.\n\nt1= np.linspace(-2,2,1000)\nplt.plot(t1, f(t1))\n\n\n\n\n\n\n\n\n\n# Initial guess\nx0 = 10 * (np.random.rand() - 0.5)\n\n# Learning rate\nalpha = 0.01\n\n# Number of iterations\nn_iter = 1000\n\n# Gradient Descent\nxg = x0\nfor i in range(n_iter):\n    xg = xg - alpha * f_hat(xg)\n\n# Print the minimum\nprint(\"Time of the minimum:\", xg)\nprint(\"Function value at minimum:\", f(xg))\n\nTime of the minimum: -1.4142135623730956\nFunction value at minimum: 8.881784197001252e-16"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab04_sol_ImagProc02.html",
    "href": "laboratorios/PSIM/Previous/lab04_sol_ImagProc02.html",
    "title": "Algoritmos básicos de procesamiento de imágenes",
    "section": "",
    "text": "Usando la imagen fresas.png la cual fue tomada de la página Geeks for geeks resuelva las siguientes cuestiones.\n\nAplique las siguientes transformaciones y describa el efecto de cada transformación:\n\nTransformación n-potencial con \\(1&lt;n&lt;2\\)\nTransformación n-potencial con \\(0.5&lt;n&lt;1\\)\nTransformación LOG (Logaritmo Natural)\nTransformación exponencial\nDescriba en un diagrama de bloques el algoritmo necesario para realizar este tipo de transformaciones.\nInvestigue y desarrolle el algoritmo de la transformación \\(\\Gamma\\). La información básica la puede encontrar aqui\n\n\nRecuerde: Si una imagen queda completamente blanca o completamente negra, es probable que sea por mal manejo de rangos de intensidad\n\nimport pydicom as pyimag1\nimport cv2 as pyimag2\nimport matplotlib.pyplot as pyimag3\nimport numpy as pyimag4\n\nruta = \"../../data/imagen_dicom.dcm\"\n\n\ndata_imagen = pyimag1.dcmread(ruta)\nimage = data_imagen.pixel_array\npyimag3.imshow(image, cmap=\"gray\")\npyimag3.axis(\"off\")\n\npatient_name= data_imagen.PatientID\nprint(f\"Nombre del paciente: {patient_name}\")\n\nNombre del paciente: 239\n\n\n\n\n\n\n\n\n\n\nSea los siguientes kernels de convolución:\n\n\\(\\begin{bmatrix}\n1 & 1 & 1 \\\\\n1 & -8 & 1 \\\\\n1 & 1 & 1\n\\end{bmatrix}\\)\n\\(\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n-1 & 8 & -1 \\\\\n-1 & -1 & -1\n\\end{bmatrix}\\)\n\n\nExplique las siguientes cuestiones:\n\nInvestigue las formas de realizar la convolución con opencv.\nAplique cada uno de los kernels de convolución y compare los resultados.\nExplique cuales son las respectivas resoluciónes de pixel de las imagenes resultantes así como su máximo y su mínimo.\n\n\nkernel1 = (1 / 9) * pyimag4.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\nkernel2 = pyimag4.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\nconv1 = pyimag2.filter2D(image, ddepth=-1, kernel=kernel1)\nconv1_normalized = pyimag2.normalize(conv1, None, 0, 255, pyimag2.NORM_MINMAX)\nconv2 = pyimag2.filter2D(image, ddepth=-1, kernel=kernel2)\nconv2_normalized = pyimag2.normalize(conv2, None, 0, 255, pyimag2.NORM_MINMAX)\npyimag3.imshow(pyimag4.concatenate(\n    (conv1_normalized, conv2_normalized), \n    axis=1), \n    cmap=\"gray\")\npyimag3.axis(\"off\")\n\n\n\n\n\n\n\n\n\nrows, cols = image.shape\nangle = 45\nM = pyimag2.getRotationMatrix2D((cols//2, rows//2), angle, 1)\ntransformed_image = pyimag2.warpAffine(image, M, (cols, rows))\npyimag3.imshow(transformed_image, cmap=\"gray\")\npyimag3.axis(\"off\")\n\n\n\n\n\n\n\n\n\nUtilizando la imagen radiografía, aplique cada tipo de matriz afine presente en las diapositivas de clase\nDeterminar proyecto final para PSIM.\n\nDeterminar el problema a resolver.\nDeterminar el objetivo a alcanzar\nDeterminar el dataset\n\n\nRecuerde, en su proyecto final, NO podrá hacer uso de algoritmos de machine learning."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/Proyecto_Final_2024-2.html",
    "href": "laboratorios/PSIM/Previous/Proyecto_Final_2024-2.html",
    "title": "Proyecto Final: PSIM 2024-1",
    "section": "",
    "text": "Horarios de Sustentación\n\n\nMonitoría del Curso\nKevin Martínez\n\n\nRúbrica\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (100%)\nBueno (80%)\nRegular (60%)\nInsuficiente (40%)\nNo presentado (0%)\n\n\n\n\nUso de técnicas de procesamiento de imágenes o señales\nDemuestra un dominio profundo y una aplicación adecuada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nDemuestra una comprensión sólida y una aplicación adecuada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nDemuestra una comprensión básica y una aplicación limitada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nDemuestra una comprensión deficiente y una aplicación inadecuada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nNo se evidencia la aplicación de técnicas de procesamiento de imágenes o señales.\n\n\nCoherencia entre objetivos y resultados\nLos objetivos del proyecto están claramente definidos y alineados con los resultados obtenidos.\nLos objetivos del proyecto están definidos y alineados en gran medida con los resultados obtenidos.\nLos objetivos del proyecto están definidos, pero no se alinean completamente con los resultados obtenidos.\nLos objetivos del proyecto están poco definidos y no se alinean con los resultados obtenidos.\nNo se definen objetivos para el proyecto.\n\n\nTiempo de exposición\nLa exposición del proyecto es clara, concisa y organizada, permitiendo una comprensión completa del trabajo realizado.\nLa exposición del proyecto es clara y organizada, permitiendo una buena comprensión del trabajo realizado.\nLa exposición del proyecto es clara, pero con algunas deficiencias en la organización, lo que dificulta la comprensión completa del trabajo realizado.\nLa exposición del proyecto es poco clara y desorganizada, lo que dificulta la comprensión del trabajo realizado.\nNo se realiza una exposición del proyecto.\n\n\nPresentación\nLa presentación del proyecto es visualmente atractiva, profesional y utiliza recursos multimedia de manera efectiva para comunicar los resultados.\nLa presentación del proyecto es visualmente atractiva y profesional, utilizando algunos recursos multimedia para comunicar los resultados.\nLa presentación del proyecto es visualmente aceptable, pero con algunos errores o falta de recursos multimedia para comunicar los resultados.\nLa presentación del proyecto es poco visualmente atractiva, con errores y falta de recursos multimedia para comunicar los resultados.\nNo se realiza una presentación del proyecto.\n\n\nNivel de la codificación\nEl código está bien escrito, documentado, organizado y utiliza las mejores prácticas de programación.\nEl código está bien escrito, documentado y organizado.\nEl código está escrito, pero con algunas deficiencias en la documentación y organización.\nEl código está escrito de manera deficiente, con mala documentación y organización.\nEl código no está escrito o está escrito de manera no funcional.\n\n\nCreatividad en el algoritmo\nEl algoritmo utilizado en el proyecto es novedoso, original y efectivo para resolver el problema planteado.\nEl algoritmo utilizado en el proyecto es creativo, original y efectivo para resolver el problema planteado.\nEl algoritmo utilizado en el proyecto es creativo, pero con algunas limitaciones en su originalidad o efectividad.\nEl algoritmo utilizado en el proyecto es poco creativo, con limitaciones en su originalidad y efectividad.\nEl algoritmo utilizado en el proyecto no es creativo ni efectivo para resolver el problema planteado.\n\n\nTrabajo en equipo\nSe evidencia un trabajo en equipo efectivo, con una clara división de roles, comunicación constante y colaboración entre los miembros del equipo.\nSe evidencia un trabajo en equipo colaborativo, con una clara división de roles y comunicación entre los miembros del equipo.\nSe evidencia un trabajo en equipo con algunas dificultades en la colaboración o comunicación entre los miembros del equipo.\nSe evidencia un trabajo en equipo deficiente, con falta de colaboración y comunicación entre los miembros del equipo.\nNo se evidencia un trabajo en equipo.\n\n\nTrabajo individual\nCada miembro del equipo demuestra un alto nivel de compromiso, responsabilidad y contribución individual al proyecto.\nCada miembro del equipo demuestra un buen nivel de compromiso, responsabilidad y contribución individual al proyecto.\nCada miembro del equipo demuestra un nivel aceptable de compromiso, responsabilidad y contribución individual al proyecto.\nCada miembro del equipo demuestra un bajo nivel de compromiso, responsabilidad y contribución individual al proyecto.\nNo se evidencia el trabajo individual de los miembros del equipo."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "",
    "text": "Propósito: formular 2–3 objetivos SMART para el proyecto final de la asignatura, alineados con ODS 3: Salud y bienestar (y secundarios ODS 9/10/11 si aplica) y con necesidades de salud pública en Colombia.\nRestricción metodológica (obligatoria): evitar machine learning general. Únicos algoritmos de decisión permitidos: K‑means, regresión lineal múltiple y regresión logística múltiple. Prohibidos: redes neuronales, SVM, árboles/ensembles, métodos bayesianos avanzados, etc."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#resultados-de-aprendizaje",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#resultados-de-aprendizaje",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Resultados de aprendizaje",
    "text": "Resultados de aprendizaje\nAl finalizar, cada equipo:\n\nConecta un problema clínico-prioritario en Colombia con al menos un objetivo ODS y una meta/indicador verificable.\nRedacta 2–3 objetivos SMART (impacto clínico, técnico, implementación) con métricas y umbrales.\nDefine fuentes de datos (abiertos o locales con cumplimiento ético) y un plan de validación reproducible.\nDescribe riesgos de sesgo/ética y medidas de mitigación acordes con normativa colombiana de protección de datos."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#opciones-de-reto-elige-uno",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#opciones-de-reto-elige-uno",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Opciones de reto (elige uno)",
    "text": "Opciones de reto (elige uno)\nLas siguientes opciones se enfocan en tareas de detección, medición o soporte a decisión usando únicamente K‑means y/o regresión múltiple.\n\n1) Tuberculosis en radiografía de tórax (soporte a triage)\n\nTarea: puntaje de riesgo por paciente a partir de descriptores de imagen clásicos (textura, intensidades, morfología).\nAlgoritmos permitidos: segmentación de regiones sospechosas (heurística), K‑means para agrupar patrones de textura, regresión logística múltiple para estimar probabilidad de TB.\nMétrica primaria: sensibilidad y especificidad; curva ROC/AUC para el modelo logístico; tiempo de lectura por estudio.\n\n\n\n2) Retinopatía diabética (fondo de ojo)\n\nTarea: detección de lesiones (exudados, microaneurismas) mediante filtros clásicos; conteos y áreas como predictores.\nAlgoritmos: K‑means sobre espacios de color; regresión logística múltiple para riesgo de RD referible.\nMétrica primaria: F1 para lesión referible; exactitud por estratos de calidad de imagen.\n\n\n\n3) Ultrasonido obstétrico (biometría cefálica)\n\nTarea: estimar circunferencia cefálica (HC) con ajuste geométrico; usar regresión lineal múltiple para corregir sesgos por ángulo/ganancia.\nMétrica primaria: error absoluto medio (MAE) en mm frente a anotador experto.\n\n\n\n4) Lesiones cutáneas (dermatoscopia/imagen macro)\n\nTarea: segmentación clásica de la lesión; extracción de color/forma/asimetría; regresión logística múltiple para riesgo de malignidad (prototipo educativo, no clínico).\nMétrica primaria: AUC; análisis de errores por fototipo.\n\n\n\n5) Extracción de signos vitales con cámara web (rPPG) sin ML\n\nObjetivo: estimar frecuencia cardiaca (FC) y frecuencia respiratoria (FR) desde video RGB facial capturado con webcam estándar (≥ 30 fps) sin redes neuronales.\nPipeline sugerido: detección de rostro (clásica), definición de ROI (frente/pómulos), promediado espacial por canal, detrend y banda pasante; cálculo espectral.\nCálculos:\n\nSeñal rPPG por canal: \\(s_c(t) = \\frac{1}{|\\Omega|}\\sum_{(i,j)\\in \\Omega} I_c(i,j,t)\\).\nPreamplificación cromática tipo POS/CHROM (implementación determinista sin entrenamiento).\nHR (bpm) desde pico espectral: \\(\\mathrm{HR} = 60, f_{\\text{peak}}\\).\nSNR: \\(\\mathrm{SNR} = 10\\log_{10}\\left( \\frac{P\\{\\text{señal}}\\}{P\\{\\text{ruido}}\\} \\right)\\).\n\nAlgoritmos de decisión permitidos:\n\nK‑means para estabilidad de ROI (agrupar píxeles por coherencia temporal) o clusterizar condiciones de iluminación.\nRegresión lineal múltiple para corrección de artefactos (p. ej., modelar FC estimada como función de variables de captura: luminancia media, varianza, amplitud de movimiento): \\(\\widehat{\\mathrm{FC}} = \\beta_0 + \\sum_{j=1}^p \\beta_j x_j\\).\nRegresión logística múltiple para calidad binaria del segmento (válido/no válido) a partir de predictores como SNR, varianza, energía de banda: \\(\\Pr(\\text{válido}=1\\mid x)=\\sigma!\\left( \\beta_0 + \\sum_{j=1}^p \\beta_j x_j \\right),\\ \\ \\sigma(z)=\\frac{1}{1+e^{-z}}\\).\n\nMétricas: MAE de FC (bpm), MAE de FR (rpm), proporción de segmentos válidos, latencia."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#recordatorio-de-ecuaciones-uso-en-los-tres-algoritmos-permitidos",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#recordatorio-de-ecuaciones-uso-en-los-tres-algoritmos-permitidos",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Recordatorio de ecuaciones (uso en los tres algoritmos permitidos)",
    "text": "Recordatorio de ecuaciones (uso en los tres algoritmos permitidos)\nK‑means (criterio WCSS): minimizar\n\\(J = \\sum_{i=1}^k \\sum_{x\\in C_i} \\lVert x - \\mu_i \\rVert^2\\).\nRegresión lineal múltiple:\n\\(\\hat{y} = \\beta_0 + \\sum_{j=1}^p \\beta_j x_j\\), con ajuste por mínimos cuadrados: \\(\\min_\\beta \\lVert y - X\\beta \\rVert_2^2\\).\nRegresión logística múltiple:\n\\(\\Pr(Y=1\\mid x) = \\sigma!\\left( \\beta_0 + \\sum_{j=1}^p \\beta_j x_j \\right)\\), donde \\(\\sigma(z)=\\frac{1}{1+e^{-z}}\\)."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#plantilla-lienzo-de-objetivos-1-página",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#plantilla-lienzo-de-objetivos-1-página",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Plantilla: Lienzo de Objetivos (1 página)",
    "text": "Plantilla: Lienzo de Objetivos (1 página)\nComplete y entregue una página por equipo. En la plantilla del curso\n\nTítulo del proyecto:\nODS principal (meta/indicador):\nODS secundario (opcional):\nProblema en Colombia (fuente breve):\nPoblación objetivo y escenario de uso:\nModalidad de imagen y tarea:\nDatos/datasets (licencia y tamaño):\nObjetivo SMART 1 (impacto):\nObjetivo SMART 2 (técnico):\nObjetivo SMART 3 (implementación):\nMétrica(s) primaria(s) y umbrales:\nRiesgos/sesgos y cumplimiento (privacidad y ética):\nPlan de validación:\nHitos/tiempos:"
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#ejemplos-de-objetivos-smart-adaptar-al-caso",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#ejemplos-de-objetivos-smart-adaptar-al-caso",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Ejemplos de objetivos SMART (adaptar al caso)",
    "text": "Ejemplos de objetivos SMART (adaptar al caso)\n\nImpacto clínico (ODS 3): “En 10 semanas, demostrar en n=40 participantes que el prototipo de rPPG logra MAE(FC) ≤ 5 bpm frente a pulsioxímetro de referencia, en condiciones de luz ambiental de consultorio.”\nTécnico‑algorítmico: “Implementar pipeline determinista de rPPG con banda 0.7–4 Hz para FC y 0.1–0.5 Hz para FR; usar K‑means para seleccionar ROI estable y regresión lineal múltiple para corrección por iluminación; alcanzar proporción de segmentos válidos ≥ 0.9.”\nImplementación/uso responsable: “Entregar una app on‑device que procese 60 s de video en ≤ 3 s y exporte solo series temporales y métricas (sin video). Incluir aviso y consentimiento informado.”\n\n\nPara otras opciones de reto, formule un objetivo análogo con métrica primaria clara (p. ej., AUC ≥ 0.85 para logística múltiple o MAE ≤ umbral en lineal múltiple) y justificativo ODS."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#sugerencias-de-métricas-y-validación",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#sugerencias-de-métricas-y-validación",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Sugerencias de métricas y validación",
    "text": "Sugerencias de métricas y validación\n\nClasificación (logística múltiple): AUC, sensibilidad, especificidad, F1, calibración (revisar curva de confiabilidad).\nRegresión (lineal múltiple): MAE, RMSE, \\(R^2\\), análisis de residuos.\nClustering (K‑means): inercia (WCSS), silhouette (solo para diagnóstico; no usar como criterio de decisión clínica).\nValidación: partición entrenamiento/validación, estratificación por subgrupos (edad/sexo/calidad de imagen), IC por bootstrap si el tamaño lo permite."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#riesgos-y-mitigaciones-ética-y-sesgo",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#riesgos-y-mitigaciones-ética-y-sesgo",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Riesgos y mitigaciones (ética y sesgo)",
    "text": "Riesgos y mitigaciones (ética y sesgo)\n\nPrivacidad: evitar almacenar datos identificables; anonimizar; limitar finalidades; consentimiento informado cuando aplique.\nSesgo de dominio: evaluar por dispositivo, iluminación, fototipo, institución; reportar desempeño estratificado.\nSeguridad: indicar que los prototipos son con fines educativos y no clínicos."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#entregables-de-la-sesión",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#entregables-de-la-sesión",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Entregables de la sesión",
    "text": "Entregables de la sesión\n\nLienzo de Objetivos (1 página) completado.\nPitch de 60 s leyendo objetivo principal y métrica clave.\nArchivo breve (máx. 1 página) con las ecuaciones que usa su proyecto (de entre las listadas) y la métrica primaria con definición formal."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#rúbrica-de-evaluación-actividad-de-hoy",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#rúbrica-de-evaluación-actividad-de-hoy",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Rúbrica de evaluación (actividad de hoy)",
    "text": "Rúbrica de evaluación (actividad de hoy)\nPuntaje total: 100. Aprobación sugerida: ≥ 70 y sin criterios en nivel Insuficiente.\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPeso\nExcelente (4)\nBueno (3)\nBásico (2)\nInsuficiente (1)\n\n\n\n\nAlineación con ODS\n20\nODS principal correcto y meta/indicador explícito y pertinente\nODS correcto sin indicador concreto\nODS genérico\nSin ODS o incorrecto\n\n\nRelevancia país/población\n15\nContexto Colombia claro (población, nivel de atención, brecha)\nContexto parcial\nContexto vago\nSin contexto\n\n\nCalidad de objetivos SMART\n20\n2–3 objetivos con métricas, umbrales y tiempos; separados en impacto/técnico/implementación\nObjetivos claros pero incompletos\nFaltan métricas o tiempos\nConfusos o no medibles\n\n\nViabilidad técnica (solo K‑means / reg. múltiple)\n15\nElección y justificación rigurosa; ecuaciones y variables definidas\nElección adecuada con ligeras lagunas\nUso dudoso o variables mal definidas\nIncumple restricciones o inviable\n\n\nÉtica y cumplimiento\n10\nRiesgos/sesgos y medidas; privacidad correctamente abordada\nMenciona ética sin detalle\nSuperficial\nNo aborda\n\n\nMétricas de éxito\n10\nIndicadores clínicos/operativos claros y umbrales\nIndicadores presentes sin umbrales\nIndicadores vagos\nNo hay\n\n\nClaridad de la entrega (1 pág + pitch)\n10\nSíntesis excelente, visual limpio, pitch preciso\nClaro con leves omisiones\nDenso o poco legible\nIncompleto"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "El procesamiento de señales de origen fisiológico —como las provenientes de sistemas cardiovasculares, neuromusculares o musculoesqueléticos— constituye un área clave dentro de la ingeniería biomédica y las ciencias de la salud. Su correcta interpretación requiere no solo conocimientos técnicos avanzados, sino también una capacidad crítica para integrar información multidisciplinar.\nLos objetivos de esta actividad son:\n\nAnalizar y comparar diferentes enfoques teóricos sobre el procesamiento de señales fisiológicas (ECG, EMG, PPG, etc.).\nEvaluar la calidad y rigurosidad técnica de fuentes bibliográficas científicas.\nFomentar el pensamiento crítico y la capacidad de síntesis de los estudiantes.\nDesarrollar habilidades de lectura técnica y argumentación científica en contextos biomédicos.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7\nM. A. Martínez González, A. Sánchez-Villegas, E. A. Toledo Atucha, y J. Faulin Fajardo, Bioestadística amigable, Third. Madrid, España: Elsevier, 2020."
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#duración",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#materiales",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7\nM. A. Martínez González, A. Sánchez-Villegas, E. A. Toledo Atucha, y J. Faulin Fajardo, Bioestadística amigable, Third. Madrid, España: Elsevier, 2020."
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-1-carga-y-visualización-entrega-22-de-abril-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-1-carga-y-visualización-entrega-22-de-abril-de-2025",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fase 1 – Carga y visualización (Entrega: 22 de abril de 2025)",
    "text": "Fase 1 – Carga y visualización (Entrega: 22 de abril de 2025)\n\nCargar una señal electrocardiográfica aleatoria del dataset.\nVisualizar la señal cruda.\nIdentificar ruido de línea base y artefactos. Explique que tipos de artefactos pueden aparecen en esta señal. Haga uso de diferentes artículos de naturaleza académica, por su puesto referencielos."
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-2-preprocesamiento-entrega-6-de-mayo-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-2-preprocesamiento-entrega-6-de-mayo-de-2025",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fase 2 – Preprocesamiento (Entrega 6 de mayo de 2025)",
    "text": "Fase 2 – Preprocesamiento (Entrega 6 de mayo de 2025)\n\nRealice un Filtrado paso banda (0.5–40 Hz). Porque se utiliza este rango de frecuencia? Se aplica un filtro FIR o IIR, porque?\nAplicar una normalización de escala a la señal. ¿Por qué\nAplicar un corte de ruido de línea base a la señal. ¿Que técnicas existen para tal fin?\nAplicar un corte de artefactos a la señal. ¿Qué técnicas existen para tal fin?"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-3-detección-de-picos-r-y-segmentación-entrega-semana-del-19-de-mayo-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-3-detección-de-picos-r-y-segmentación-entrega-semana-del-19-de-mayo-de-2025",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fase 3 – Detección de picos R y segmentación (Entrega Semana del 19 de mayo de 2025)",
    "text": "Fase 3 – Detección de picos R y segmentación (Entrega Semana del 19 de mayo de 2025)\n\nRealice una detección de picos R utilizando un algoritmo específico. ¿Qué algoritmo se ha utilizado? ¿Por qué? ¿Qué ventajas y desventajas tiene? Que tecnicas matematicas se han utilizado para el algoritmo?\nCalcular intervalos RR y frecuencia cardíaca instantánea. Que es una frecuencia cardíaca instantánea? ¿Por qué es importante?\nSegmentar la señal en intervalos de tiempo correspondientes a cada complejo QRS. ¿Que técnica utilizó y cual es la base matemática en la que se basó?"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-4-extracción-de-características-entrega-semana-del-19-de-mayo-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-4-extracción-de-características-entrega-semana-del-19-de-mayo-de-2025",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fase 4 – Extracción de características (Entrega Semana del 19 de mayo de 2025)",
    "text": "Fase 4 – Extracción de características (Entrega Semana del 19 de mayo de 2025)\n\nPara cada sujeto del conjunto de datos, calcule las siguientes características:\n\nFrecuencia cardíaca promedio.\nFrecuencia cardíaca máxima.\nFrecuencia cardíaca mínima.\nIntervalo RR promedio.\nIntervalo RR máximo.\nIntervalo RR mínimo.\nCoeficiente de variación de la frecuencia cardíaca.\nNúmero de latidos\n\nExisten otras características que se pueden calcular, ¿cuáles son? Referencie al menos 3 artículos de naturaleza académica.\nForme una tabla con las características calculadas para cada sujeto. Cada fila corresponde a un sujeto y cada columna corresponde a una característica.\nDetermine si cada característica es paramétrica o no. Se recomienda utilizar técnicas estadísticas para determinar si una característica es paramétrica o no.\nCon la información de parametricidad de la variable, determine si esta tiene diferencias estadísticamente para las personas con arritmias y las personas sin arritmias.\nUtilizando un algoritmo de regresión logística, plantee un __modelo estadístico de clasificació__n. ¿Qué es una regresión logística? ¿Como se puede calcular? Que es un modelo estadístico de clasificación?"
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 4, 2025. The defense will be carried out by one of the team members chosen at random.\nThe python libraries allow for this laboratory are: matplotlib and random"
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 1: Mean and Median",
    "text": "Exercise 1: Mean and Median\nWrite a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g. normal, binomial)."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes’ Theorem",
    "text": "Exercise 6: Bayes’ Theorem\nWrite a Python program that applies Bayes’ theorem to update the probability of a hypothesis given new evidence."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g. normal, uniform)."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10:Function visualization - I",
    "text": "Exercise 10:Function visualization - I\nGenerate a python code that allows the visualization (in one figure) of the real (blue) part and the imaginary (red) part, magnitude (green) and phase of the following signals:\n\\[f\\left(t\\right) = e^{-j10 \\pi t}\\]\n\\[g\\left(t\\right) = 10cos\\left(2 \\pi t\\right) + j10sin\\left(2 \\pi t\\right)\\]\nThe visualization mus be in the range \\(\\left[-10, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/ASIM/lab002_CNN.html",
    "href": "laboratorios/ASIM/lab002_CNN.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torchvision\n\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader\n\nimport torch.nn as nn\n\nfrom torch import utils\nfrom torch import optim\nfrom torch import device\nfrom torch import inference_mode\n\nimport tqdm\n\nfrom timeit import default_timer as timer\nfrom tqdm.auto import tqdm\n\nfrom torchmetrics import ConfusionMatrix\nimport mlxtend\nfrom mlxtend.plotting import plot_confusion_matrix\nimport numpy\nfrom torchvision.transforms.v2 import (\n    ConvertImageDtype,\n    Normalize,\n    Resize,\n    CenterCrop,\n    ToTensor,\n    ToImage,\n    Compose\n)\n\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0\n\n\n\ntransformacion = Compose([\n    ToTensor(), \n    Normalize(mean=[0.5], std=[0.5])\n    ])\n\n/home/pablo/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n\n\n\ndata_flag = \"pathmnist\"\ninfo = INFO[data_flag]\nDataClass = getattr(medmnist, info[\"python_class\"])\n\n# Load the training and testing datasets\ntrain_data = DataClass(split=\"train\", transform=transformacion, download=True)\nval_data = DataClass(split=\"val\", transform=transformacion, download=True)\ntest_data = DataClass(split=\"test\", transform=transformacion, download=True)\n\nDownloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /home/pablo/.medmnist/pathmnist.npz\n\n\n100%|██████████| 205615438/205615438 [00:20&lt;00:00, 10059790.46it/s]\n\n\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\n\n\n\n# check data properties\nimg = train_data[0][0]\nlabel = train_data[0][1]\n\nprint(f\"Image:\\n {img}\")\nprint(f\"Label:\\n {label}\")\n\nprint(f\"Image shape: {img.shape}\")\nprint(f\"Label: {label}\")\n\nImage:\n tensor([[[0.7255, 0.7176, 0.7255,  ..., 0.7255, 0.7176, 0.7333],\n         [0.7098, 0.7255, 0.7176,  ..., 0.5451, 0.5059, 0.4902],\n         [0.7255, 0.7255, 0.7176,  ..., 0.6314, 0.6235, 0.6392],\n         ...,\n         [0.7098, 0.7020, 0.7333,  ..., 0.7333, 0.7255, 0.7333],\n         [0.6706, 0.7020, 0.7333,  ..., 0.7333, 0.7333, 0.7333],\n         [0.6863, 0.7255, 0.7333,  ..., 0.7255, 0.7333, 0.7412]],\n\n        [[0.6314, 0.6235, 0.6235,  ..., 0.6314, 0.6235, 0.6314],\n         [0.6157, 0.6235, 0.6157,  ..., 0.3882, 0.3490, 0.3176],\n         [0.6314, 0.6235, 0.6078,  ..., 0.4980, 0.5059, 0.5216],\n         ...,\n         [0.6078, 0.5765, 0.6314,  ..., 0.6314, 0.6314, 0.6392],\n         [0.5059, 0.5686, 0.6314,  ..., 0.6314, 0.6392, 0.6314],\n         [0.5294, 0.6235, 0.6314,  ..., 0.6314, 0.6314, 0.6392]],\n\n        [[0.7804, 0.7804, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7725, 0.7725, 0.7725,  ..., 0.5843, 0.5451, 0.5294],\n         [0.7725, 0.7725, 0.7647,  ..., 0.6706, 0.6706, 0.6941],\n         ...,\n         [0.7647, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7098, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7255, 0.7725, 0.7804,  ..., 0.7804, 0.7804, 0.7882]]])\nLabel:\n [0]\nImage shape: torch.Size([3, 28, 28])\nLabel: [0]\n\n\n\n# Number of image channels\nn_channels = info[\"n_channels\"]\nprint(f\"number of channels: {n_channels}\")\n\n# Number of classes\nn_classes = len(info[\"label\"])\nprint(f\"number of classes: {n_classes}\")\n\n# Get the class names from the dataset\nclass_names = info[\"label\"]\nprint(f\"class names: {class_names}\")\n\nnumber of channels: 3\nnumber of classes: 9\nclass names: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n\n\n\nfor i in range(3):\n    img = train_data[i][0]\n    label = train_data[i][1]\n    plt.figure(figsize=(3, 3))\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(label)\n    plt.axis(False)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.6313726..0.84313726].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.372549..0.85882354].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# change data into dataloader form\nBATCH_SIZE = 128\ntrain_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n\n\n# check dataloader\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")\n\nDataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53cd0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53490&gt;)\nLength of train dataloader: 704 batches of 128\nLength of test dataloader: 57 batches of 128\nLength of val dataloader: 79 batches of 128\n\n\n\n# define training loop functions\ndef train_step(\n    model: torch.nn.Module,\n    data_loader: torch.utils.data.DataLoader,\n    loss_fn: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    train_loss, train_acc = 0, 0\n    model.to(device)\n\n    for batch, (X, y) in enumerate(data_loader):\n        # need to change target shape for this medmnist data\n        y = y.squeeze().long()\n\n        # Send data to selected device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. loss and accuracy\n        loss = loss_fn(y_pred, y)\n        train_loss += loss\n        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n    # Calculate loss and accuracy per epoch\n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n\n    return train_loss, train_acc\n\n\ndef test_step(\n    data_loader: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    test_loss, test_acc = 0, 0\n    model.to(device)\n\n    model.eval()  # eval mode for testing\n    with torch.inference_mode():  # Inference context manager\n        for X, y in data_loader:\n            # need to change target shape for this medmnist data\n            y = y.squeeze().long()\n\n            # Send data to selected device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred = model(X)\n\n            # 2. Calculate loss and accuracy\n            test_loss += loss_fn(test_pred, y)\n            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n\n        # Adjust metrics and print out\n        test_loss /= len(data_loader)\n        test_acc /= len(data_loader)\n\n        return test_loss, test_acc\n\n\ndef eval_func(\n    data_loader: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    eval_loss, eval_acc = 0, 0\n    model.to(device)\n\n    model.eval()\n    y_preds = []\n    y_targets = []\n    with torch.inference_mode():\n        for batch, (X, y) in tqdm(enumerate(data_loader)):\n            # need to change target shape for this medmnist data\n            y = y.squeeze().long()\n\n            # Send data to selected device\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass\n            eval_pred = model(X)\n\n            # Find loss and accuracy\n            eval_loss += loss_fn(eval_pred, y)\n            eval_acc += accuracy_fn(y_true=y, y_pred=eval_pred.argmax(dim=1))\n\n            # Add prediction and target labels to list\n            eval_labels = torch.argmax(torch.softmax(eval_pred, dim=1), dim=1)\n            y_preds.append(eval_labels)\n            y_targets.append(y)\n\n        # Scale loss and acc\n        eval_loss /= len(data_loader)\n        eval_acc /= len(data_loader)\n\n        # Put predictions on CPU for evaluation\n        y_preds = torch.cat(y_preds).cpu()\n        y_targets = torch.cat(y_targets).cpu()\n\n        return {\n            \"model_name\": model.__class__.__name__,\n            \"loss\": eval_loss.item(),\n            \"accuracy\": eval_acc,\n            \"predictions\": y_preds,\n            \"targets\": y_targets,\n        }\n\n\ndef print_train_time(start: float, end: float, device: torch.device = None):\n    total_time = end - start\n    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n    return total_time\n\n\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct / len(y_pred)) * 100\n    return acc\n\n\nclass cnn(torch.nn.Module):\n    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n        super().__init__()\n\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=input_shape, out_channels=hidden_units, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n        )\n\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units, out_channels=hidden_units, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units, out_channels=hidden_units * 4, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n        )\n\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units * 4,\n                out_channels=hidden_units * 4,\n                kernel_size=3,\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n        )\n\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units * 4,\n                out_channels=hidden_units * 4,\n                kernel_size=3,\n                padding=1,\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_units * 4 * 4 * 4, hidden_units * 8),\n            nn.ReLU(),\n            nn.Linear(hidden_units * 8, hidden_units * 8),\n            nn.ReLU(),\n            nn.Linear(hidden_units * 8, n_classes),\n        )\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\n# Define Model\nmodel = cnn(input_shape=n_channels, hidden_units=16, output_shape=n_classes).to(device)\n\n\n# Setup loss and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# View Model\nmodel\n\ncnn(\n  (layer1): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer2): Sequential(\n    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (layer3): Sequential(\n    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer4): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer5): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=1024, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=128, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=128, out_features=9, bias=True)\n  )\n)\n\n\n\ntorch.manual_seed(42)\n\n# Measure Time\n\ntrain_time_start_model = timer()\n\niteration_loss_list = []\niteration_accuracy_list = []\n\n# set parameters\nepochs = 10\nbest_loss = 10\n\n# call train and test function\nfor epoch in tqdm(range(epochs)):\n    train_loss, train_acc = train_step(\n        data_loader=train_dataloader,\n        model=model,\n        loss_fn=loss_fn,\n        optimizer=optimizer,\n        accuracy_fn=accuracy_fn,\n        device=device1,\n    )\n\n    test_loss, test_acc = test_step(\n        data_loader=test_dataloader,\n        model=model,\n        loss_fn=loss_fn,\n        accuracy_fn=accuracy_fn,\n        device=device1,\n    )\n\n    for iteration, (x, y) in enumerate(train_dataloader):\n        iteration_loss_list.append(train_loss.item())\n        iteration_accuracy_list.append(train_acc)\n\n    print(\n        f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\"\n    )\n\n    # save best model instance\n\n    if test_loss &lt; best_loss:\n        best_loss = test_loss\n        print(f\"Saving best model for epoch: {epoch}\")\n        torch.save(obj=model.state_dict(), f=\"./model.pth\")\n\n\ntrain_time_end_model = timer()\ntotal_train_time_model = print_train_time(\n    start=train_time_start_model, end=train_time_end_model, device=device1\n)\n\n\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[17], line 33\n     16 train_loss, train_acc = train_step(\n     17     data_loader=train_dataloader,\n     18     model=model,\n   (...)\n     22     device=device1,\n     23 )\n     25 test_loss, test_acc = test_step(\n     26     data_loader=test_dataloader,\n     27     model=model,\n   (...)\n     30     device=device1,\n     31 )\n---&gt; 33 for iteration, (x, y) in enumerate(train_dataloader):\n     34     iteration_loss_list.append(train_loss.item())\n     35     iteration_accuracy_list.append(train_acc)\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630, in _BaseDataLoaderIter.__next__(self)\n    627 if self._sampler_iter is None:\n    628     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    629     self._reset()  # type: ignore[call-arg]\n--&gt; 630 data = self._next_data()\n    631 self._num_yielded += 1\n    632 if self._dataset_kind == _DatasetKind.Iterable and \\\n    633         self._IterableDataset_len_called is not None and \\\n    634         self._num_yielded &gt; self._IterableDataset_len_called:\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673, in _SingleProcessDataLoaderIter._next_data(self)\n    671 def _next_data(self):\n    672     index = self._next_index()  # may raise StopIteration\n--&gt; 673     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    674     if self._pin_memory:\n    675         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52, in _MapDatasetFetcher.fetch(self, possibly_batched_index)\n     50         data = self.dataset.__getitems__(possibly_batched_index)\n     51     else:\n---&gt; 52         data = [self.dataset[idx] for idx in possibly_batched_index]\n     53 else:\n     54     data = self.dataset[possibly_batched_index]\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52, in &lt;listcomp&gt;(.0)\n     50         data = self.dataset.__getitems__(possibly_batched_index)\n     51     else:\n---&gt; 52         data = [self.dataset[idx] for idx in possibly_batched_index]\n     53 else:\n     54     data = self.dataset[possibly_batched_index]\n\nFile ~/.local/lib/python3.10/site-packages/medmnist/dataset.py:138, in MedMNIST2D.__getitem__(self, index)\n    132 \"\"\"\n    133 return: (without transform/target_transofrm)\n    134     img: PIL.Image\n    135     target: np.array of `L` (L=1 for single-label)\n    136 \"\"\"\n    137 img, target = self.imgs[index], self.labels[index].astype(int)\n--&gt; 138 img = Image.fromarray(img)\n    140 if self.as_rgb:\n    141     img = img.convert(\"RGB\")\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3304, in fromarray(obj, mode)\n   3301         msg = \"'strides' requires either tobytes() or tostring()\"\n   3302         raise ValueError(msg)\n-&gt; 3304 return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3206, in frombuffer(mode, size, data, decoder_name, *args)\n   3203         im.readonly = 1\n   3204         return im\n-&gt; 3206 return frombytes(mode, size, data, decoder_name, args)\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3138, in frombytes(mode, size, data, decoder_name, *args)\n   3135 _check_size(size)\n   3137 im = new(mode, size)\n-&gt; 3138 if im.width != 0 and im.height != 0:\n   3139     decoder_args: Any = args\n   3140     if len(decoder_args) == 1 and isinstance(decoder_args[0], tuple):\n   3141         # may pass tuple instead of argument list\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:559, in Image.height(self)\n    555 @property\n    556 def width(self) -&gt; int:\n    557     return self.size[0]\n--&gt; 559 @property\n    560 def height(self) -&gt; int:\n    561     return self.size[1]\n    563 @property\n    564 def size(self) -&gt; tuple[int, int]:\n\nKeyboardInterrupt: \n\n\n\n\n# Load model\nloaded_model = cnn(input_shape=n_channels, hidden_units=16, output_shape=n_classes).to(\n    device\n)\n\nloaded_model.load_state_dict(torch.load(f=\"./model.pth\"))\n\n# get results\nmodel_results = eval_func(\n    data_loader=val_dataloader,\n    model=loaded_model,\n    loss_fn=loss_fn,\n    accuracy_fn=accuracy_fn,\n    device=device,\n)\n\nmodel_results\n\n\n# Get Model predictions and true targets\ny_targets = model_results[\"targets\"]\ny_preds = model_results[\"predictions\"]\n\n# Setup confusion matrix\nconfmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\nconfmat_tensor = confmat(preds=y_preds, target=y_targets)\n\n# Plot the confusion matrix\nfix, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), class_names=class_names, figsize=(10, 7)\n)\n\n\n# Get Model predictions and true targets\ny_targets = model_results[\"targets\"]\ny_preds = model_results[\"predictions\"]\n\n# Setup confusion matrix\nconfmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\nconfmat_tensor = confmat(preds=y_preds, target=y_targets)\n\n# Plot the confusion matrix\nfix, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), class_names=class_names, figsize=(10, 7)\n)"
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html",
    "href": "laboratorios/ASIM/lab001_OOP.html",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "href": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "href": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Encapsulation",
    "text": "Encapsulation\n\nEncapsulation is the concept of bundling data and methods that operate on that data within a single unit (class).\nIt helps to hide the implementation details and expose only the necessary information to the outside world."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "href": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Inheritance",
    "text": "Inheritance\n\nInheritance is the mechanism by which one class can inherit the attributes and methods of another class.\nIt promotes code reuse and facilitates the creation of a hierarchy of classes."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "href": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Polymorphism",
    "text": "Polymorphism\n\nPolymorphism is the ability of an object to take on multiple forms.\nIt can be achieved through method overriding (where a subclass provides a different implementation of a method) or method overloading (where multiple methods with the same name can be defined with different parameters)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "href": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Abstraction",
    "text": "Abstraction\n\nAbstraction is the concept of showing only the necessary information to the outside world while hiding the implementation details.\nIt helps to reduce complexity and improve code readability.\n\n\nclass BankAccount:\n    def __init__(self, account_number, account_name, balance):\n        self.account_number = account_number\n        self.account_name = account_name\n        self.balance = balance\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance:\n            print(\"Insufficient funds\")\n        else:\n            self.balance -= amount\n\n    def display_details(self):\n        print(f\"Account Number: {self.account_number}\")\n        print(f\"Account Name: {self.account_name}\")\n        print(f\"Balance: {self.balance}\")\n\n\nThe BankAccount class encapsulates the account_number, account_name, and balance attributes, as well as the deposit, withdraw, and display_details methods.\nThe __init__ method is a special method that is called when an object is created, and it initializes the attributes.\nThe deposit and withdraw methods modify the balance attribute, demonstrating encapsulation.\nThe display_details method provides a way to access the attributes without exposing them directly, demonstrating abstraction.\n\n\nclass SavingsAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, interest_rate):\n        super().__init__(account_number, account_name, balance)\n        self.interest_rate = interest_rate\n\n    def add_interest(self):\n        interest = self.balance * self.interest_rate\n        self.deposit(interest)\n\n\nThe SavingsAccount class inherits the attributes and methods of BankAccount using the super() function.\nIt adds an additional attribute interest_rate and a method add_interest that calculates and deposits interest.\n\n\nclass CurrentAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, overdraft_limit):\n        super().__init__(account_number, account_name, balance)\n        self.overdraft_limit = overdraft_limit\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance + self.overdraft_limit:\n            print(\"Transaction declined\")\n        else:\n            super().withdraw(amount)\n\n\n\n\nimage.png\n\n\n\n“Designing a Comprehensive Hospital Management System in Python”\n\nIntroduction\nIn this task, we aim to develop a straightforward hospital management system that efficiently manages patients, doctors, and appointments. Leveraging Python’s object-oriented programming capabilities, we will create a robust framework to streamline hospital operations.\n\n\nSystem Components\nThe hospital management system comprises four primary classes: Person, Patient, Doctor, Appointment, and Hospital.\n\n\nPerson Class\nThe Person class serves as the foundation for both Patient and Doctor classes, encapsulating essential attributes:\n\nname\nage\ngender\n\n\n\nPatient Class\nInheriting from Person, the Patient class introduces additional attributes:\n\npatient_id\nillness\n\n\n\nDoctor Class\nSimilarly, the Doctor class inherits from Person and includes:\n\ndoctor_id\nspecialization\n\n\n\nAppointment Class\nThe Appointment class encompasses:\n\nappointment_id\npatient (a Patient object)\ndoctor (a Doctor object)\ndate\ntime\n\n\n\nHospital Class\nThe Hospital class is the central hub, managing:\n\npatients (a list of Patient objects)\ndoctors (a list of Doctor objects)\nappointments (a list of Appointment objects)\nHospital Class Methods: The Hospital class features the following methods:\n\nadd_patient(name, age, gender, patient_id, illness): Adds a new patient to the hospital.\nadd_doctor(name, age, gender, doctor_id, specialization): Adds a new doctor to the hospital.\nschedule_appointment(appointment_id, patient_id, doctor_id, date, time): Schedules a new appointment.\nlist_appointments(): Lists all appointments.\n\n\n\n\nImplementation\nBy utilizing these classes and methods, the hospital management system provides a structured approach to managing patients, doctors, and appointments, ensuring efficient and organized hospital operations."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 6, 2025. The defense will be carried out by one of the team members chosen at random."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 1: Mean and Median",
    "text": "Exercise 1: Mean and Median\nWrite a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g. normal, binomial)."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes’ Theorem",
    "text": "Exercise 6: Bayes’ Theorem\nWrite a Python program that applies Bayes’ theorem to update the probability of a hypothesis given new evidence."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g. normal, uniform)."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10:Function visualization - I",
    "text": "Exercise 10:Function visualization - I\nGenerate a python code that allows the visualization (in one figure) of the real (blue) part and the imaginary (red) part, magnitude (green) and phase of the following signals:\n\\[f\\left(t\\right) = e^{-j10 \\pi t}\\]\n\\[g\\left(t\\right) = 10cos\\left(2 \\pi t\\right) + j10sin\\left(2 \\pi t\\right)\\]\nThe visualization must be in the range of t \\(\\left[-10, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/ASIM/lab002_CNN_cap.html",
    "href": "laboratorios/ASIM/lab002_CNN_cap.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torchvision\n\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader\n\nimport torch.nn as nn\n\nfrom torch import utils\nfrom torch import optim\nfrom torch import device\nfrom torch import inference_mode\n\nimport tqdm\n\nfrom timeit import default_timer as timer\nfrom tqdm.auto import tqdm\n\nfrom torchmetrics import ConfusionMatrix\nimport mlxtend\nfrom mlxtend.plotting import plot_confusion_matrix\nimport numpy\nfrom torchvision.transforms.v2 import (\n    ConvertImageDtype,\n    Normalize,\n    Resize,\n    CenterCrop,\n    ToTensor,\n    ToImage,\n    Compose\n)\n\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0\n\n\n\ntransformacion = Compose([\n    ToTensor(), \n    Normalize(mean=[0.5], std=[0.5])\n    ])\n\n/home/pablo/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n\n\n\ndata_flag = \"pathmnist\"\ninfo = INFO[data_flag]\nDataClass = getattr(medmnist, info[\"python_class\"])\n\n# Load the training and testing datasets\ntrain_data = DataClass(split=\"train\", transform=transformacion, download=True)\nval_data = DataClass(split=\"val\", transform=transformacion, download=True)\ntest_data = DataClass(split=\"test\", transform=transformacion, download=True)\n\nDownloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /home/pablo/.medmnist/pathmnist.npz\n\n\n100%|██████████| 205615438/205615438 [00:20&lt;00:00, 10059790.46it/s]\n\n\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\n\n\n\n# check data properties\nimg = train_data[0][0]\nlabel = train_data[0][1]\n\nprint(f\"Image:\\n {img}\")\nprint(f\"Label:\\n {label}\")\n\nprint(f\"Image shape: {img.shape}\")\nprint(f\"Label: {label}\")\n\nImage:\n tensor([[[0.7255, 0.7176, 0.7255,  ..., 0.7255, 0.7176, 0.7333],\n         [0.7098, 0.7255, 0.7176,  ..., 0.5451, 0.5059, 0.4902],\n         [0.7255, 0.7255, 0.7176,  ..., 0.6314, 0.6235, 0.6392],\n         ...,\n         [0.7098, 0.7020, 0.7333,  ..., 0.7333, 0.7255, 0.7333],\n         [0.6706, 0.7020, 0.7333,  ..., 0.7333, 0.7333, 0.7333],\n         [0.6863, 0.7255, 0.7333,  ..., 0.7255, 0.7333, 0.7412]],\n\n        [[0.6314, 0.6235, 0.6235,  ..., 0.6314, 0.6235, 0.6314],\n         [0.6157, 0.6235, 0.6157,  ..., 0.3882, 0.3490, 0.3176],\n         [0.6314, 0.6235, 0.6078,  ..., 0.4980, 0.5059, 0.5216],\n         ...,\n         [0.6078, 0.5765, 0.6314,  ..., 0.6314, 0.6314, 0.6392],\n         [0.5059, 0.5686, 0.6314,  ..., 0.6314, 0.6392, 0.6314],\n         [0.5294, 0.6235, 0.6314,  ..., 0.6314, 0.6314, 0.6392]],\n\n        [[0.7804, 0.7804, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7725, 0.7725, 0.7725,  ..., 0.5843, 0.5451, 0.5294],\n         [0.7725, 0.7725, 0.7647,  ..., 0.6706, 0.6706, 0.6941],\n         ...,\n         [0.7647, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7098, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7255, 0.7725, 0.7804,  ..., 0.7804, 0.7804, 0.7882]]])\nLabel:\n [0]\nImage shape: torch.Size([3, 28, 28])\nLabel: [0]\n\n\n\n# Number of image channels\nn_channels = info[\"n_channels\"]\nprint(f\"number of channels: {n_channels}\")\n\n# Number of classes\nn_classes = len(info[\"label\"])\nprint(f\"number of classes: {n_classes}\")\n\n# Get the class names from the dataset\nclass_names = info[\"label\"]\nprint(f\"class names: {class_names}\")\n\nnumber of channels: 3\nnumber of classes: 9\nclass names: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n\n\n\nfor i in range(3):\n    img = train_data[i][0]\n    label = train_data[i][1]\n    plt.figure(figsize=(3, 3))\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(label)\n    plt.axis(False)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.6313726..0.84313726].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.372549..0.85882354].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# change data into dataloader form\nBATCH_SIZE = 128\ntrain_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n\n\n# check dataloader\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")\n\nDataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53cd0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53490&gt;)\nLength of train dataloader: 704 batches of 128\nLength of test dataloader: 57 batches of 128\nLength of val dataloader: 79 batches of 128"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "El electrocardiograma (ECG o EKG) es una grabación de la actividad eléctrica cardíaca en la superficie de la piel, durante un período de tiempo determinado. En cada ciclo cardíaco, un corazón sano presenta una secuencia de señales eléctricas que se generan en el nodo sinoauricular y se distribuyen en el corazón hasta alcanzar los ventrículos. Estas señales tienen una forma característica que se muestra en la figura 1.\n\n\n\nFigura 1. ECG durante un ciclo cardíaco normal\n\n\nA través de un ECG, un profesional de la salud entrenado es capaz de obtener información relevante sobre el funcionamiento del corazón; por ejemplo, se puede determinar la frecuencia cardíaca, la presencia de daño en el músculo cardíaco, los efectos de medicamentos y la función de marcapasos implantados.\n\n\nLos estudiantes conocerán las principales teorías concernientes a la generación del electrocardiograma y su relación con el funcionamiento del corazón.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#objetivo-de-aprendizaje",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes conocerán las principales teorías concernientes a la generación del electrocardiograma y su relación con el funcionamiento del corazón."
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#duración",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#materiales",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-1-revisión-al-electrocardiograms",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-1-revisión-al-electrocardiograms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 1: Revisión al electrocardiograms",
    "text": "Actividad 1: Revisión al electrocardiograms\n\n¿Qué es un electrocardiograma (ECG) y cuál es su importancia en el diagnóstico clínico?\n¿Qué información electrofisiológica proporciona un ECG y cómo se relaciona con la actividad del corazón?\n¿Qué es una derivación (lead) en el contexto de un ECG y cuál es su función?\n¿Cuántas derivaciones existen en un ECG estándar y cómo se clasifican?\nObserve la Figura 1 proporcionada y determine a qué derivación corresponde el diagrama mostrado. Justifique su respuesta.\n¿Qué es una arritmia y qué tipos existen? Describa las características de cada tipo de arritmia."
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-2-análisis-del-articulo",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-2-análisis-del-articulo",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 2: Análisis del articulo",
    "text": "Actividad 2: Análisis del articulo\n\n¿Cuáles son las principales clases de arritmias que el artículo estudia y cómo se agrupan?\n¿Qué impacto tienen las arritmias en la salud pública según el artículo? Mencione datos estadísticos relevantes.\n¿Por qué es importante mejorar la precisión en la clasificación automática de arritmias?\n¿Cuáles son las principales fuentes de ruido en una señal de ECG y qué técnicas se utilizaron en el artículo para reducirlas?\n¿Por qué se aplicó normalización a las señales ECG? ¿Qué impacto tuvo en la clasificación? Explique el método de normalización.\n¿Cuáles son las principales características extraídas de la señal ECG en este estudio?\n¿Por qué es importante la selección de características para el entrenamiento de un algoritmo de clasificación?"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-3-análisis-de-la-base-de-datos",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-3-análisis-de-la-base-de-datos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 3: Análisis de la base de datos",
    "text": "Actividad 3: Análisis de la base de datos\n\n¿Cuáles fueron los criterios de selección de los pacientes?\n¿Cuántos registros de ECG se recopilaron en total y qué duración tienen las señales analizadas?\n¿Cómo se realizó la toma de datos del ECG? Especifique el número de derivaciones, la duración del registro y la frecuencia de muestreo.\n¿Cuáles fueron las características demográficas de la población estudiada? Describa la distribución por edad y género.\n¿Cuál fue la prevalencia de cada tipo de arritmia en la base de datos? ¿Qué arritmias fueron las más frecuentes y cuáles fueron las menos comunes?"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#criterios-de-evaluación",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Criterios de Evaluación",
    "text": "Criterios de Evaluación\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nNivel Excelente (5.0 - 4.5)\nNivel Satisfactorio (4.4 - 3.5)\nNivel Aceptable (3.4 - 2.5)\nNivel Deficiente (&lt;2.5)\nPeso (%)\n\n\n\n\nComprensión teórica del ECG y su relevancia clínica\nExplica de manera clara y detallada la importancia del ECG, su función diagnóstica y la información electrofisiológica que proporciona. Responde con precisión todas las preguntas teóricas.\nResponde la mayoría de las preguntas con claridad, pero algunas respuestas pueden carecer de profundidad o detalles.\nResponde las preguntas de manera parcial o con imprecisiones conceptuales. Falta claridad en algunos conceptos.\nRespuestas incompletas o con errores fundamentales en la comprensión del ECG y su relevancia.\n20%\n\n\nAnálisis del artículo de Zheng et al.\nIdentifica y sintetiza correctamente las clases de arritmias, impacto en salud pública, técnicas de reducción de ruido y normalización. Argumenta con evidencia del artículo.\nPresenta un buen análisis, aunque algunas respuestas carecen de profundidad o precisión. Uso adecuado pero limitado de la evidencia.\nMuestra dificultad en identificar o explicar correctamente algunos conceptos clave del artículo.\nAnálisis deficiente, respuestas vagas o incorrectas, falta de relación con el artículo.\n20%\n\n\nAnálisis de la base de datos de ECG\nDescribe con precisión los criterios de selección, número de registros, condiciones de adquisición y características demográficas. Utiliza correctamente los datos del artículo.\nExplica la mayoría de los aspectos, aunque con algunas omisiones o falta de precisión en los datos.\nResponde parcialmente, con confusión en algunos aspectos metodológicos o demográficos.\nNo logra describir correctamente los criterios de la base de datos o presenta errores graves en su interpretación.\n20%\n\n\nJustificación y análisis de derivaciones\nIdentifica correctamente la derivación del ECG mostrado en la Figura 1, justificando con base en conocimientos teóricos.\nIdentifica la derivación con una justificación aceptable, aunque podría ser más clara.\nPresenta una identificación incorrecta o incompleta con una justificación débil.\nNo justifica o identifica erróneamente la derivación.\n15%\n\n\nPresentación y redacción del informe\nInforme bien estructurado, sin errores gramaticales o de formato. Uso adecuado de referencias. Argumentación clara y precisa.\nInforme organizado, aunque con algunos errores menores de gramática o formato. Argumentación adecuada.\nPresentación con errores de redacción y formato. Explicaciones poco estructuradas.\nInforme desorganizado, con errores graves de gramática y sin referencias adecuadas.\n15%\n\n\nParticipación y trabajo en equipo\nDemuestra alto compromiso y participación en la sesión de laboratorio. Contribuye activamente al desarrollo del informe.\nParticipa en la mayoría de las actividades, aunque con algunas intervenciones limitadas.\nParticipa de forma esporádica o depende en exceso del grupo para completar las actividades.\nNo participa o su aporte al equipo es mínimo.\n10%\n\n\n\nTotal: 100% puntos."
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Antes de realizar el procesamiento de señales en estudios biomédicos, es fundamental llevar a cabo un análisis descriptivo de los participantes. Este paso permite contextualizar los datos y asegurar que cualquier resultado obtenido sea válido, representativo y adecuado para su interpretación clínica y científica. A continuación, se detallan las razones clave para realizar este análisis previo:\n\nCaracterización de la Población Estudiada: El análisis descriptivo permite conocer la distribución de variables clave.\nIdentificación de Posibles Sesgos en los Datos: Un estudio bien diseñado debe asegurarse de que los datos sean representativos de la población objetivo.\nEvaluación de la Calidad de los Datos: El análisis descriptivo ayuda a detectar inconsistencias en los datos antes de aplicar técnicas de procesamiento de señales.\nJustificación del Preprocesamiento de Señales: Al conocer las características de los participantes, se pueden tomar decisiones informadas sobre qué técnicas de procesamiento aplicar.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#duración",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#materiales",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-generación-de-la-información-base",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-generación-de-la-información-base",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 1: Generación de la información base",
    "text": "Actividad 1: Generación de la información base\nUtilizando el dataset, realice las siguiente tareas:\n\nEnumere todos los posibles diagnósticos que los pacientes pueden tener.\nPara todos los pacientes genere una tabla que debe tener la siguiente información:\n\nID: Identificador del paciente.\nEdad: Edad del paciente.\nSexo: Sexo del paciente.\nDiagnosticos: A partir de aquí se genera una columna por cada diagnóstico posible de un paciente. En cada paciente se registrará un 1 si este fue diagnósticado con la dolencia respectiva. Recomendación: Use los archivos .hea adjuntos en el dataset."
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-análisis-de-la-información",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-análisis-de-la-información",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 2: Análisis de la información",
    "text": "Actividad 2: Análisis de la información\nA partir de la tabla generado en la actividad anterior responda de forma clara y concisa las siguientes preguntas:\n\n¿Cuál es la frecuencia y el porcentaje de casos de Bradicardia Sinusal (SB) en la muestra?\n¿Cuál es la edad promedio y su desviación estándar para los pacientes con Bradicardia #. Sinusal (SB)?\n¿Cuál es el porcentaje de hombres en la categoría de Bradicardia Sinusal (SB)?\n¿Cuántos pacientes fueron diagnosticados con Ritmo Sinusal (SR) y qué porcentaje representa del total?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Ritmo Sinusal (SR)?\n¿Qué porcentaje de los pacientes con Ritmo Sinusal (SR) son hombres?\n¿Cuántos casos de Fibrilación Auricular (AFIB) se reportaron y qué porcentaje representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Fibrilación Auricular (AFIB)?\n¿Qué porcentaje de los pacientes con Fibrilación Auricular (AFIB) son hombres?\n¿Cuántos pacientes presentan Taquicardia Sinusal (ST) y qué porcentaje del total representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia Sinusal (ST)?\n¿Qué porcentaje de los pacientes con Taquicardia Sinusal (ST) son hombres?\n¿Cuál es la frecuencia y el porcentaje de casos de Flutter Auricular (AF) en la muestra?\n¿Cuál es la edad promedio y su desviación estándar para los pacientes con Flutter Auricular (AF)?\n¿Cuál es el porcentaje de hombres en la categoría de Flutter Auricular (AF)?\n¿Cuántos pacientes presentan Irregularidad Sinusal (SI) y qué porcentaje del total representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Irregularidad Sinusal (SI)?\n¿Qué porcentaje de los pacientes con Irregularidad Sinusal (SI) son hombres?\n¿Cuál es la frecuencia y el porcentaje de casos de Taquicardia Supraventricular (SVT) en la muestra?\n¿Cuál es la edad promedio y su desviación estándar para los pacientes con Taquicardia Supraventricular (SVT)?\n¿Cuál es el porcentaje de hombres en la categoría de Taquicardia Supraventricular (SVT)?\n¿Cuántos casos de Taquicardia Auricular (AT) se registraron y qué porcentaje del total representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia Auricular (AT)?\n¿Qué porcentaje de los pacientes con Taquicardia Auricular (AT) son hombres?\n¿Cuántos casos de Taquicardia por Reentrada en el Nodo AV (AVNRT) se reportaron y qué porcentaje representan?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia por Reentrada en el Nodo AV (AVNRT)?\n¿Qué porcentaje de los pacientes con Taquicardia por Reentrada en el Nodo AV (AVNRT) son hombres?\n¿Cuántos pacientes fueron diagnosticados con Taquicardia por Reentrada Auriculoventricular (AVRT) y qué porcentaje representan?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia por Reentrada Auriculoventricular (AVRT)?\n¿Qué porcentaje de los pacientes con Taquicardia por Reentrada Auriculoventricular (AVRT) son hombres?\n¿Cuántos casos de Ritmo de deambulamiento auricular sinusal a auricular (SAAWR) se registraron y qué porcentaje representan?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Ritmo de deambulamiento auricular sinusal a auricular (SAAWR)?\n¿Qué porcentaje de los pacientes con Ritmo de deambulamiento auricular sinusal a auricular (SAAWR) son hombres?\n¿Cuál es el número total de pacientes en la muestra y su edad promedio?\n¿Cuál es el porcentaje total de hombres en la muestra?"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#criterios-de-evaluación",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Criterios de Evaluación",
    "text": "Criterios de Evaluación\nSustentación del trabajo. Cada equipo deberá responder tres preguntas:\n\nPregunta aleatoria basada en la actividad 2.\nPregunta basada en estadísticas que se obtienen a partir de la tabla de la actividad 1\nPregunta sobre el código utilizado para realizar el laboratorio."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab03_ImagProc.html",
    "href": "laboratorios/PSIM/Previous/lab03_ImagProc.html",
    "title": "Laboratorio 3: Carga de datos e Histograma",
    "section": "",
    "text": "Cargar el archivo imagen_dicom.dcm y almacenarlo en la variable var01.\nCargar el archivo imagen_nii.nii y almacenarlo en la variable var02.\nCargar el archivo covid-4.png y almacenarlo en la variable var03.\nMostrar las variables: var01, var02, var03.\nDescribir las dimensiones de cada una de las imagenes.\nTomar la var03 y si tiene más de una dimensión, convertirla a imagen en escala de grises, con profundidad de intensidad de pixel de 8bits.\nContar cuantos pixeles hay para cada valor de intensidad posible en la conversión en escala de grises de la variable var03. Mostrar estos valores en una gráfica de barras.\nPara el punto 7 solo puede utilizar la librería numpy.\nPara el punto 8 solo puede utilizar la librería matplotlib."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab04_ImagProc02.html",
    "href": "laboratorios/PSIM/Previous/lab04_ImagProc02.html",
    "title": "Algoritmos básicos de procesamiento de imágenes",
    "section": "",
    "text": "Usando la imagen fresas.png la cual fue tomada de la página Geeks for geeks resuelva las siguientes cuestiones.\n\nAplique las siguientes transformaciones y describa el efecto de cada transformación:\n\nTransformación n-potencial con \\(1&lt;n&lt;2\\)\nTransformación n-potencial con \\(0.5&lt;n&lt;1\\)\nTransformación LOG (Logaritmo Natural)\nTransformación exponencial\nDescriba en un diagrama de bloques el algoritmo necesario para realizar este tipo de transformaciones.\nInvestigue y desarrolle el algoritmo de la transformación \\(\\Gamma\\). La información básica la puede encontrar aqui\n\n\nRecuerde: Si una imagen queda completamente blanca o completamente negra, es probable que sea por mal manejo de rangos de intensidad\n\nSea los siguientes kernels de convolución:\n\n\\(\\begin{bmatrix}\n1 & 1 & 1 \\\\\n1 & -8 & 1 \\\\\n1 & 1 & 1\n\\end{bmatrix}\\)\n\\(\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n-1 & 8 & -1 \\\\\n-1 & -1 & -1\n\\end{bmatrix}\\)\n\n\nExplique las siguientes cuestiones:\n\nInvestigue las formas de realizar la convolución con opencv.\nAplique cada uno de los kernels de convolución y compare los resultados.\nExplique cuales son las respectivas resoluciónes de pixel de las imagenes resultantes así como su máximo y su mínimo.\n\n\nUtilizando la imagen radiografía, aplique cada tipo de matriz afine presente en las diapositivas de clase\nDeterminar proyecto final para PSIM.\n\nDeterminar el problema a resolver.\nDeterminar el objetivo a alcanzar\nDeterminar el dataset\n\n\nRecuerde, en su proyecto final, NO podrá hacer uso de algoritmos de machine learning."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 6, 2025. The defense will be carried out by one of the team members chosen at random.\n\nExercise 0: Matrix Manipulation\nWrite a program that (after an initial solo design) prompts from the keyboard three integers \\(N\\), \\(M\\), and \\(K\\); validates that \\(N \\ge 1\\), \\(M \\ge 1\\), and \\(K \\ge 0\\); and constructs an \\(N \\times M\\) matrix whose entries are uniformly sampled integers from the closed interval \\([0, K]\\). The algorithm must classify every entry and extract the sets of even numbers, odd numbers, and prime numbers, where \\(0\\) and \\(1\\) are treated as non-prime and primality is decided via trial division up to \\(\\lfloor \\sqrt{x} \\rfloor\\) with early termination. For each category, report both (a) the total count over all matrix positions and (b) the sorted set of unique values; handle duplicates correctly, and note that if \\(K &lt; 2\\) the prime set is empty by definition. Structure the solution modularly (separate input handling, matrix generation, and classification), include basic input-error recovery, and optionally expose a random-seed parameter to ensure reproducibility. After independently drafting pseudocode, engage a peer as a “more knowledgeable other” to critique modularity and efficiency, then implement the revised design, test it on at least two contrasting cases (e.g., small matrices and edge \\(K\\) values), and submit a concise analytical note that justifies your validation choices and discusses time complexity; conclude with a brief reflection explaining how the peer interaction scaffolded your final solution.\n\n\nExercise 1: Numerical Diferentation\nDetermine the numerical derivative of the function h, represented as \\(\\left(\\frac{dh}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach\n\n\nExercise 2: Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{h(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach\n\n\nExercise 3: Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)\n\n\nExercise 4: Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent.\n\n\n\n0.5585873704668033"
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Comprender la estructura digital de una imagen como matriz de píxeles.\nAplicar técnicas básicas de manipulación de imágenes usando Python.\nDesarrollar funciones para codificar y decodificar información textual en imágenes.\nReflexionar sobre la importancia del procesamiento de imágenes en aplicaciones biomédicas.\n\n\n\n\n\nLenguaje: Python 3\nLibrerías: opencv-python (cv2), numpy, matplotlib, pydicom.\n\n\n\n\n\nCarga y visualización de imágenes dicom\nConversión de texto a binario\nCodificación de bits en el canal de color\nRecuperación del mensaje codificado\nGeneración de la imagen dicom\n\n\n\n\nCada grupo trabajará una variante distinta del laboratorio base. Esto garantiza diversidad de enfoques y evita el plagio entre equipos.\n\n\n\n\n\n\n\n\nGrupo\nVariante asignada\nDescripción\n\n\n\n\nA\nCanal rojo\nSolo puede usar el canal rojo para codificar.\n\n\nB\nOrden inverso\nEl mensaje se codifica recorriendo los píxeles en orden inverso.\n\n\nC\nDos mensajes\nCodifica dos mensajes distintos: uno en azul y otro en verde.\n\n\nD\nCompresión básica\nComprime el mensaje antes de insertarlo.\n\n\nE\nEscala de grises\nUtiliza imágenes en escala de grises para codificación.\n\n\nF\nAlto contraste\nSolo se permite codificar en píxeles con alto contraste respecto a sus vecinos.\n\n\nG\nPatrón de ajedrez\nEl mensaje se codifica en píxeles alternos como patrón de ajedrez.\n\n\nH\nTres bits\nSe usan los tres bits menos significativos para codificar cada carácter.\n\n\nI\nBaja variabilidad local\nEl mensaje solo se codifica en zonas donde los valores de píxel son muy similares entre vecinos.\n\n\n\n\n\n\nCodifica el siguiente mensaje dentro de una imagen asignada por el docente:\n\"Paciente Juan Pérez, ID: 203911, ECG normal, sin antecedentes\"\nCada grupo deberá:\n\nEntregar el código Python funcional.\nComparar la imagen original y la modificada.\nRecuperar correctamente el mensaje.\nEntregar un informe breve explicando el proceso y los retos del grupo.\n\n\n\n\n\n\n\nCriterio\nPuntaje\n\n\n\n\nManipulación básica de imágenes\n20 pts\n\n\nCodificación y recuperación funcional\n40 pts\n\n\nAdaptación a la variante del grupo\n30 pts\n\n\nInforme técnico claro y bien escrito\n10 pt\n\n\nTotal\n100 pts\n\n\n\n\n\n\n\n¿Qué aplicaciones biomédicas podrían beneficiarse del ocultamiento de datos en imágenes? Explica una situación clínica concreta donde esta técnica sería útil."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#objetivos-del-laboratorio",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#objetivos-del-laboratorio",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Comprender la estructura digital de una imagen como matriz de píxeles.\nAplicar técnicas básicas de manipulación de imágenes usando Python.\nDesarrollar funciones para codificar y decodificar información textual en imágenes.\nReflexionar sobre la importancia del procesamiento de imágenes en aplicaciones biomédicas."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#herramientas",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#herramientas",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Lenguaje: Python 3\nLibrerías: opencv-python (cv2), numpy, matplotlib, pydicom."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#actividades-comunes-a-todos-los-grupos",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#actividades-comunes-a-todos-los-grupos",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Carga y visualización de imágenes dicom\nConversión de texto a binario\nCodificación de bits en el canal de color\nRecuperación del mensaje codificado\nGeneración de la imagen dicom"
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#variantes-del-laboratorio-por-grupo",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#variantes-del-laboratorio-por-grupo",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Cada grupo trabajará una variante distinta del laboratorio base. Esto garantiza diversidad de enfoques y evita el plagio entre equipos.\n\n\n\n\n\n\n\n\nGrupo\nVariante asignada\nDescripción\n\n\n\n\nA\nCanal rojo\nSolo puede usar el canal rojo para codificar.\n\n\nB\nOrden inverso\nEl mensaje se codifica recorriendo los píxeles en orden inverso.\n\n\nC\nDos mensajes\nCodifica dos mensajes distintos: uno en azul y otro en verde.\n\n\nD\nCompresión básica\nComprime el mensaje antes de insertarlo.\n\n\nE\nEscala de grises\nUtiliza imágenes en escala de grises para codificación.\n\n\nF\nAlto contraste\nSolo se permite codificar en píxeles con alto contraste respecto a sus vecinos.\n\n\nG\nPatrón de ajedrez\nEl mensaje se codifica en píxeles alternos como patrón de ajedrez.\n\n\nH\nTres bits\nSe usan los tres bits menos significativos para codificar cada carácter.\n\n\nI\nBaja variabilidad local\nEl mensaje solo se codifica en zonas donde los valores de píxel son muy similares entre vecinos."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#ejercicio-integrador",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#ejercicio-integrador",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Codifica el siguiente mensaje dentro de una imagen asignada por el docente:\n\"Paciente Juan Pérez, ID: 203911, ECG normal, sin antecedentes\"\nCada grupo deberá:\n\nEntregar el código Python funcional.\nComparar la imagen original y la modificada.\nRecuperar correctamente el mensaje.\nEntregar un informe breve explicando el proceso y los retos del grupo."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#evaluación",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#evaluación",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Criterio\nPuntaje\n\n\n\n\nManipulación básica de imágenes\n20 pts\n\n\nCodificación y recuperación funcional\n40 pts\n\n\nAdaptación a la variante del grupo\n30 pts\n\n\nInforme técnico claro y bien escrito\n10 pt\n\n\nTotal\n100 pts"
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#pregunta-de-reflexión",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#pregunta-de-reflexión",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "¿Qué aplicaciones biomédicas podrían beneficiarse del ocultamiento de datos en imágenes? Explica una situación clínica concreta donde esta técnica sería útil."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html",
    "href": "laboratorios/APSB/lab01_Linux.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes serán capaces de aplicar comandos esenciales de Linux para la manipulación de archivos, gestión de procesos y análisis de datos biomédicos.\n\n\n\n1.5 horas\n\n\n\n\nComputador con Linux (instalado o máquina virtual), WSL2 con Ubuntu, o emulado.\nHoja de trucos de Linux.\nArchivo de datos biomédicos en formato .csv (proporcionado).\n\n\n\n\n\n\n\n\nExplora los archivos y directorios disponibles en el sistema.\nCrea una estructura de directorios organizada para almacenar datos biomédicos.\nMueve y organiza el archivo de datos de pacientes dentro de la estructura creada.\nModifica los permisos del archivo para restringir o permitir accesos según corresponda.\n\nPreguntas de reflexión:\n- ¿Por qué es importante organizar archivos en un entorno de trabajo biomédico?\n- ¿Cómo podrías utilizar permisos de archivos para proteger datos de pacientes en un hospital?\n\n\n\n\n\n\n\n\nExamina las primeras líneas del archivo de pacientes para entender su estructura.\nCuenta la cantidad total de registros para determinar el número de pacientes.\nFiltra los registros de pacientes con presión arterial alta.\nOrdena los pacientes por edad para identificar a los de mayor edad.\nExtrae información relevante, como edad y frecuencia cardíaca, y guárdala en un nuevo archivo.\n\nPreguntas de análisis:\n- ¿Cómo podríamos automatizar estos análisis para realizarlos diariamente en un hospital?\n- ¿Qué otros patrones en los datos podríamos detectar utilizando solo comandos de Linux?\n\n\n\n\n\n\n\n\nEscribe un script en python que realice los análisis anteriores y guarde los resultados en un archivo de reporte.\nAsigna los permisos adecuados al script para poder ejecutarlo.\nEjecuta el script y verifica el contenido del reporte generado.\n\nReflexión final:\n- ¿Cómo podríamos modificar el script para hacerlo más interactivo?\n- ¿Cómo podríamos programarlo para que se ejecute automáticamente cada cierto tiempo?\n\n\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nDescripción\nPuntos\n\n\n\n\nUso de comandos básicos\nAplicación correcta de comandos de navegación y manipulación de archivos\n20\n\n\nProcesamiento de datos\nUso adecuado de herramientas para análisis de datos\n30\n\n\nAutomatización con scripts\nCreación y ejecución correcta de un script funcional\n30\n\n\nReflexión y análisis\nRespuestas argumentadas a preguntas de reflexión\n20\n\n\n\nTotal: 100 puntos.\n\nEsta actividad permite a los estudiantes desarrollar habilidades prácticas en Linux con aplicaciones directas en bioinformática y análisis de datos biomédicos."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#objetivo-de-aprendizaje",
    "href": "laboratorios/APSB/lab01_Linux.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes serán capaces de aplicar comandos esenciales de Linux para la manipulación de archivos, gestión de procesos y análisis de datos biomédicos."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#duración",
    "href": "laboratorios/APSB/lab01_Linux.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "1.5 horas"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#materiales",
    "href": "laboratorios/APSB/lab01_Linux.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador con Linux (instalado o máquina virtual), WSL2 con Ubuntu, o emulado.\nHoja de trucos de Linux.\nArchivo de datos biomédicos en formato .csv (proporcionado)."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-1-exploración-y-gestión-de-archivos-30-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-1-exploración-y-gestión-de-archivos-30-min",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Explora los archivos y directorios disponibles en el sistema.\nCrea una estructura de directorios organizada para almacenar datos biomédicos.\nMueve y organiza el archivo de datos de pacientes dentro de la estructura creada.\nModifica los permisos del archivo para restringir o permitir accesos según corresponda.\n\nPreguntas de reflexión:\n- ¿Por qué es importante organizar archivos en un entorno de trabajo biomédico?\n- ¿Cómo podrías utilizar permisos de archivos para proteger datos de pacientes en un hospital?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-2-procesamiento-de-datos-biomédicos-en-la-terminal-40-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-2-procesamiento-de-datos-biomédicos-en-la-terminal-40-min",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Examina las primeras líneas del archivo de pacientes para entender su estructura.\nCuenta la cantidad total de registros para determinar el número de pacientes.\nFiltra los registros de pacientes con presión arterial alta.\nOrdena los pacientes por edad para identificar a los de mayor edad.\nExtrae información relevante, como edad y frecuencia cardíaca, y guárdala en un nuevo archivo.\n\nPreguntas de análisis:\n- ¿Cómo podríamos automatizar estos análisis para realizarlos diariamente en un hospital?\n- ¿Qué otros patrones en los datos podríamos detectar utilizando solo comandos de Linux?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-3-automatización-con-scripts-20-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-3-automatización-con-scripts-20-min",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Escribe un script en python que realice los análisis anteriores y guarde los resultados en un archivo de reporte.\nAsigna los permisos adecuados al script para poder ejecutarlo.\nEjecuta el script y verifica el contenido del reporte generado.\n\nReflexión final:\n- ¿Cómo podríamos modificar el script para hacerlo más interactivo?\n- ¿Cómo podríamos programarlo para que se ejecute automáticamente cada cierto tiempo?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#criterios-de-evaluación",
    "href": "laboratorios/APSB/lab01_Linux.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Criterio\nDescripción\nPuntos\n\n\n\n\nUso de comandos básicos\nAplicación correcta de comandos de navegación y manipulación de archivos\n20\n\n\nProcesamiento de datos\nUso adecuado de herramientas para análisis de datos\n30\n\n\nAutomatización con scripts\nCreación y ejecución correcta de un script funcional\n30\n\n\nReflexión y análisis\nRespuestas argumentadas a preguntas de reflexión\n20\n\n\n\nTotal: 100 puntos.\n\nEsta actividad permite a los estudiantes desarrollar habilidades prácticas en Linux con aplicaciones directas en bioinformática y análisis de datos biomédicos."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html",
    "href": "laboratorios/APSB/lab02_EDA.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Construir un conjunto de datos a partir de señales e imágenes biomédicas.\nAplicar técnicas de preprocesamiento y limpieza de datos.\nRealizar un análisis exploratorio de datos (EDA).\nExtraer relaciones matemáticas mediante modelos de regresión y regresión logística.\nComparar el desempeño de múltiples modelos y seleccionar el más adecuado.\n\n\n\n\n\n\n\nCada estudiante debe elegir un conjunto de datos biomédicos, que puede provenir de:\n\nSeñales fisiológicas: ECG, EEG, PPG, EMG.\nImágenes médicas: Radiografías, resonancias, tomografías, postura, etc.\nBases de datos públicas: PhysioNet, Kaggle, NIH, entre otras.\n\n\n\n\nDependiendo del tipo de datos, se deben aplicar las siguientes técnicas:\n\n\n\nCarga de archivos (.csv, .edf, .mat).\nFiltrado de ruido y artefactos con técnicas adecuadas.\n\n\n\n\n\nCarga de imágenes (.png, .jpg, .dicom).\nConversión a escala de grises, realce de contraste o segmentación si es necesario.\n\n\n\n\n\n\n\n\n\nLos estudiantes deben:\n\nAnalizar la estructura del conjunto de datos.\nIdentificar posibles valores atípicos o datos faltantes.\n\n\n\n\n\nGráficos de señales en el dominio del tiempo y la frecuencia.\nHistogramas de intensidades en imágenes médicas.\n\n\n\n\n\n\n\n\nCada estudiante debe seleccionar una o más variables independientes y una variable dependiente con la que se intentará encontrar una relación matemática.\nEjemplos de relaciones a explorar:\n\nSeñales: ¿Cómo se relaciona la variabilidad del ECG con la edad?\nImágenes: ¿Existe una correlación entre el área de una lesión y la presencia de patología?\n\n\n\n\nSe entrenarán y compararán distintos modelos:\n\n\nPara analizar relaciones entre variables numéricas.\n\nSeparar el conjunto de datos en entrenamiento y prueba.\nAjustar un modelo de regresión lineal.\nEvaluar el desempeño con métricas como el error cuadrático medio (MSE).\nGenerar una gráfica que muestre la relación encontrada.\n\n\n\n\nPara predecir una variable categórica, como la presencia o ausencia de una condición médica.\n\nSeleccionar variables predictoras y la variable objetivo.\nDividir los datos en conjunto de entrenamiento y prueba.\nEntrenar un modelo de regresión logística.\nEvaluar el desempeño utilizando la precisión y la matriz de confusión.\n\n\n\n\n\n\n\nCada estudiante debe probar múltiples modelos y justificar su elección con base en:\n\nRegresión lineal vs. Regresión polinómica (para variables continuas).\nRegresión logística vs. Árboles de decisión (para clasificación binaria).\n\nCriterios de evaluación:\n\nError cuadrático medio (MSE) para regresión.\nPrecisión y matriz de confusión para clasificación.\n\nSe espera que cada estudiante explique:\n\n¿Cuál fue el modelo más adecuado?\n¿Por qué eligieron ese modelo y no otro?\n¿Cómo pueden mejorarlo?\n\n\n\n\n\nLos estudiantes deben responder:\n\n¿Qué relación matemática encontraron en los datos?\n¿Cuál fue el modelo más adecuado y por qué?\n¿Cómo podrían mejorar la predicción o ajustar mejor el modelo?\n\n\n\n\n\n\nEntrega: Un informe en Jupyter Notebook con código, visualizaciones y análisis.\nCriterios: Correcta implementación de modelos, análisis de resultados y justificación del mejor modelo.\n\n\n\n\n\nLa calificación total será de 100 puntos, distribuidos de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (20 pts)\nAceptable (10 pts)\nDeficiente (5 pts)\nPuntos\n\n\n\n\nSelección y Construcción del Dataset\nSe elige un conjunto de datos relevante y se preprocesa adecuadamente.\nSe elige un conjunto de datos adecuado pero con preprocesamiento incompleto.\nEl conjunto de datos no es adecuado o carece de preprocesamiento.\n\n\n\nExploración y Visualización\nSe realizan estadísticas descriptivas y gráficos claros y relevantes.\nSe presentan estadísticas básicas y gráficos, pero con poca interpretación.\nNo se incluyen estadísticas ni gráficos relevantes.\n\n\n\nEntrenamiento de Modelos\nSe implementan correctamente al menos dos modelos y se comparan sus resultados.\nSe implementa un modelo correctamente pero sin comparación.\nLa implementación de los modelos es incompleta o incorrecta.\n\n\n\nEvaluación y Selección del Mejor Modelo\nSe justifican las métricas y se elige el mejor modelo con base en evidencia.\nSe elige un modelo, pero sin un análisis detallado de métricas.\nNo hay justificación clara para la elección del modelo.\n\n\n\nInterpretación y Conclusiones\nSe explican claramente los hallazgos y posibles aplicaciones clínicas.\nSe presentan hallazgos, pero sin mucha profundidad.\nNo se presentan hallazgos o la explicación es insuficiente.\n\n\n\nCalidad del Código y Presentación\nEl código es claro, bien documentado y correctamente estructurado.\nEl código tiene errores menores o falta de documentación.\nEl código es desordenado, con errores o sin documentación.\n\n\n\n\n\n\n\n90 - 100 puntos: Sobresaliente.\n75 - 89 puntos: Bueno.\n50 - 74 puntos: Necesita mejora.\n0 - 49 puntos: Deficiente.\n\n\nNotas adicionales: Se recomienda el uso de bibliotecas como pandas, numpy, matplotlib, statsmodels y seaborn para análisis y visualización."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#objetivos",
    "href": "laboratorios/APSB/lab02_EDA.html#objetivos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Construir un conjunto de datos a partir de señales e imágenes biomédicas.\nAplicar técnicas de preprocesamiento y limpieza de datos.\nRealizar un análisis exploratorio de datos (EDA).\nExtraer relaciones matemáticas mediante modelos de regresión y regresión logística.\nComparar el desempeño de múltiples modelos y seleccionar el más adecuado."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-1-construcción-del-conjunto-de-datos",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-1-construcción-del-conjunto-de-datos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Cada estudiante debe elegir un conjunto de datos biomédicos, que puede provenir de:\n\nSeñales fisiológicas: ECG, EEG, PPG, EMG.\nImágenes médicas: Radiografías, resonancias, tomografías, postura, etc.\nBases de datos públicas: PhysioNet, Kaggle, NIH, entre otras.\n\n\n\n\nDependiendo del tipo de datos, se deben aplicar las siguientes técnicas:\n\n\n\nCarga de archivos (.csv, .edf, .mat).\nFiltrado de ruido y artefactos con técnicas adecuadas.\n\n\n\n\n\nCarga de imágenes (.png, .jpg, .dicom).\nConversión a escala de grises, realce de contraste o segmentación si es necesario."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-2-análisis-exploratorio-de-datos-eda",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-2-análisis-exploratorio-de-datos-eda",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Los estudiantes deben:\n\nAnalizar la estructura del conjunto de datos.\nIdentificar posibles valores atípicos o datos faltantes.\n\n\n\n\n\nGráficos de señales en el dominio del tiempo y la frecuencia.\nHistogramas de intensidades en imágenes médicas."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-3-extracción-de-relaciones-matemáticas-con-modelos-predictivos",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-3-extracción-de-relaciones-matemáticas-con-modelos-predictivos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Cada estudiante debe seleccionar una o más variables independientes y una variable dependiente con la que se intentará encontrar una relación matemática.\nEjemplos de relaciones a explorar:\n\nSeñales: ¿Cómo se relaciona la variabilidad del ECG con la edad?\nImágenes: ¿Existe una correlación entre el área de una lesión y la presencia de patología?\n\n\n\n\nSe entrenarán y compararán distintos modelos:\n\n\nPara analizar relaciones entre variables numéricas.\n\nSeparar el conjunto de datos en entrenamiento y prueba.\nAjustar un modelo de regresión lineal.\nEvaluar el desempeño con métricas como el error cuadrático medio (MSE).\nGenerar una gráfica que muestre la relación encontrada.\n\n\n\n\nPara predecir una variable categórica, como la presencia o ausencia de una condición médica.\n\nSeleccionar variables predictoras y la variable objetivo.\nDividir los datos en conjunto de entrenamiento y prueba.\nEntrenar un modelo de regresión logística.\nEvaluar el desempeño utilizando la precisión y la matriz de confusión."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-4-comparación-y-selección-del-mejor-modelo",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-4-comparación-y-selección-del-mejor-modelo",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Cada estudiante debe probar múltiples modelos y justificar su elección con base en:\n\nRegresión lineal vs. Regresión polinómica (para variables continuas).\nRegresión logística vs. Árboles de decisión (para clasificación binaria).\n\nCriterios de evaluación:\n\nError cuadrático medio (MSE) para regresión.\nPrecisión y matriz de confusión para clasificación.\n\nSe espera que cada estudiante explique:\n\n¿Cuál fue el modelo más adecuado?\n¿Por qué eligieron ese modelo y no otro?\n¿Cómo pueden mejorarlo?"
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-5-interpretación-y-discusión",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-5-interpretación-y-discusión",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Los estudiantes deben responder:\n\n¿Qué relación matemática encontraron en los datos?\n¿Cuál fue el modelo más adecuado y por qué?\n¿Cómo podrían mejorar la predicción o ajustar mejor el modelo?"
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#evaluación",
    "href": "laboratorios/APSB/lab02_EDA.html#evaluación",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Entrega: Un informe en Jupyter Notebook con código, visualizaciones y análisis.\nCriterios: Correcta implementación de modelos, análisis de resultados y justificación del mejor modelo."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#rúbrica-de-evaluación",
    "href": "laboratorios/APSB/lab02_EDA.html#rúbrica-de-evaluación",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "La calificación total será de 100 puntos, distribuidos de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (20 pts)\nAceptable (10 pts)\nDeficiente (5 pts)\nPuntos\n\n\n\n\nSelección y Construcción del Dataset\nSe elige un conjunto de datos relevante y se preprocesa adecuadamente.\nSe elige un conjunto de datos adecuado pero con preprocesamiento incompleto.\nEl conjunto de datos no es adecuado o carece de preprocesamiento.\n\n\n\nExploración y Visualización\nSe realizan estadísticas descriptivas y gráficos claros y relevantes.\nSe presentan estadísticas básicas y gráficos, pero con poca interpretación.\nNo se incluyen estadísticas ni gráficos relevantes.\n\n\n\nEntrenamiento de Modelos\nSe implementan correctamente al menos dos modelos y se comparan sus resultados.\nSe implementa un modelo correctamente pero sin comparación.\nLa implementación de los modelos es incompleta o incorrecta.\n\n\n\nEvaluación y Selección del Mejor Modelo\nSe justifican las métricas y se elige el mejor modelo con base en evidencia.\nSe elige un modelo, pero sin un análisis detallado de métricas.\nNo hay justificación clara para la elección del modelo.\n\n\n\nInterpretación y Conclusiones\nSe explican claramente los hallazgos y posibles aplicaciones clínicas.\nSe presentan hallazgos, pero sin mucha profundidad.\nNo se presentan hallazgos o la explicación es insuficiente.\n\n\n\nCalidad del Código y Presentación\nEl código es claro, bien documentado y correctamente estructurado.\nEl código tiene errores menores o falta de documentación.\nEl código es desordenado, con errores o sin documentación.\n\n\n\n\n\n\n\n90 - 100 puntos: Sobresaliente.\n75 - 89 puntos: Bueno.\n50 - 74 puntos: Necesita mejora.\n0 - 49 puntos: Deficiente.\n\n\nNotas adicionales: Se recomienda el uso de bibliotecas como pandas, numpy, matplotlib, statsmodels y seaborn para análisis y visualización."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\ndata = pd.read_csv(\"../../data/diabetes.csv\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network data",
    "text": "Create neural network data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‘Machine Learning with R’ by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book’s specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book’s examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\n\n2. Visualizing distributions\n\n\n3. Exploring relationships between variables\n\n\n4. Analyzing categorical variables"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "Model Implementation",
    "text": "Model Implementation"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "Train Model",
    "text": "Train Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance"
  },
  {
    "objectID": "codigo/ASIM/cod002_LinearRegression.html",
    "href": "codigo/ASIM/cod002_LinearRegression.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport numpy as np\n\n# Generate some random data\nnp.random.seed(0)\nX = np.random.rand(100,1)\ny = 3 + 2 * X + np.random.randn(100,1) / 1.5\nX\n\narray([[0.5488135 ],\n       [0.71518937],\n       [0.60276338],\n       [0.54488318],\n       [0.4236548 ],\n       [0.64589411],\n       [0.43758721],\n       [0.891773  ],\n       [0.96366276],\n       [0.38344152],\n       [0.79172504],\n       [0.52889492],\n       [0.56804456],\n       [0.92559664],\n       [0.07103606],\n       [0.0871293 ],\n       [0.0202184 ],\n       [0.83261985],\n       [0.77815675],\n       [0.87001215],\n       [0.97861834],\n       [0.79915856],\n       [0.46147936],\n       [0.78052918],\n       [0.11827443],\n       [0.63992102],\n       [0.14335329],\n       [0.94466892],\n       [0.52184832],\n       [0.41466194],\n       [0.26455561],\n       [0.77423369],\n       [0.45615033],\n       [0.56843395],\n       [0.0187898 ],\n       [0.6176355 ],\n       [0.61209572],\n       [0.616934  ],\n       [0.94374808],\n       [0.6818203 ],\n       [0.3595079 ],\n       [0.43703195],\n       [0.6976312 ],\n       [0.06022547],\n       [0.66676672],\n       [0.67063787],\n       [0.21038256],\n       [0.1289263 ],\n       [0.31542835],\n       [0.36371077],\n       [0.57019677],\n       [0.43860151],\n       [0.98837384],\n       [0.10204481],\n       [0.20887676],\n       [0.16130952],\n       [0.65310833],\n       [0.2532916 ],\n       [0.46631077],\n       [0.24442559],\n       [0.15896958],\n       [0.11037514],\n       [0.65632959],\n       [0.13818295],\n       [0.19658236],\n       [0.36872517],\n       [0.82099323],\n       [0.09710128],\n       [0.83794491],\n       [0.09609841],\n       [0.97645947],\n       [0.4686512 ],\n       [0.97676109],\n       [0.60484552],\n       [0.73926358],\n       [0.03918779],\n       [0.28280696],\n       [0.12019656],\n       [0.2961402 ],\n       [0.11872772],\n       [0.31798318],\n       [0.41426299],\n       [0.0641475 ],\n       [0.69247212],\n       [0.56660145],\n       [0.26538949],\n       [0.52324805],\n       [0.09394051],\n       [0.5759465 ],\n       [0.9292962 ],\n       [0.31856895],\n       [0.66741038],\n       [0.13179786],\n       [0.7163272 ],\n       [0.28940609],\n       [0.18319136],\n       [0.58651293],\n       [0.02010755],\n       [0.82894003],\n       [0.00469548]])\n\n\n\n\n# Convert data to PyTorch tensors\nX_tensor = torch.from_numpy(X.astype(np.float32))\ny_tensor = torch.from_numpy(y.astype(np.float32))\n\n\n# Define the linear regression model\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Initialize the model, loss function, and optimizer\nmodel = LinearRegression()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# Train the model\nfor epoch in range(1000):\n    optimizer.zero_grad()\n    outputs = model(X_tensor)\n    loss = criterion(outputs, y_tensor)\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 100 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n# Print the learned parameters\n\nm = model.linear.weight.item()\nb = model.linear.bias.item()\n\nprint(\"Learned parameters:\")\nprint(\"Weight:\", m)\nprint(\"Bias:\", b )\n\nEpoch 1, Loss: 17.11027717590332\nEpoch 101, Loss: 0.5529825687408447\nEpoch 201, Loss: 0.4432789981365204\nEpoch 301, Loss: 0.44221213459968567\nEpoch 401, Loss: 0.4419429302215576\nEpoch 501, Loss: 0.4417407214641571\nEpoch 601, Loss: 0.44158604741096497\nEpoch 701, Loss: 0.44146785140037537\nEpoch 801, Loss: 0.4413774013519287\nEpoch 901, Loss: 0.4413083791732788\nLearned parameters:\nWeight: 1.91282320022583\nBias: 3.170973062515259\n\n\n\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0 , 1, 200)\nfig001 = plt.figure()\nplt.plot(t, m*t+b)\nplt.plot(X, y, 'r*')"
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html",
    "href": "codigo/ASIM/cod001_Kaggle.html",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "href": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/SYSB/DisennoFiltros.html",
    "href": "codigo/SYSB/DisennoFiltros.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\nimport ast\n\n\ndef design_filter(zeros=None, poles=None, gain=1.0):\n    \"\"\"\n    Diseña un filtro digital a partir de ceros y/o polos y una ganancia.\n\n    Parámetros:\n    - zeros: lista de ceros (raíces del numerador), o None para no incluir\n    - poles: lista de polos (raíces del denominador), o None para no incluir\n    - gain: ganancia escalar del filtro\n\n    Devuelve:\n    - b: coeficientes del numerador\n    - a: coeficientes del denominador\n    \"\"\"\n    # Si no se pasan ceros, asumimos un FIR trivial (b = [gain])\n    if zeros:\n        b = gain * np.poly(zeros)\n    else:\n        b = np.array([gain], dtype=float)\n\n    # Si no se pasan polos, asumimos sistema FIR (a = [1])\n    if poles:\n        a = np.poly(poles)\n    else:\n        a = np.array([1.0], dtype=float)\n\n    return b, a\n\n\ndef gaussian(x, mu, sigma, A):\n    \"\"\"\n    Genera una función gaussiana.\n\n    Parámetros:\n    - x: array de tiempos\n    - mu: posición central de la gaussiana\n    - sigma: desviación estándar\n    - A: amplitud\n    \"\"\"\n    return A * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n\n\n\ndef simulate_ecg(duration=10.0, fs=500, heart_rate=60):\n    \"\"\"\n    Simula un ECG sintético basado en la superposición de ondas gaussianas.\n\n    Parámetros:\n    - duration: duración de la señal en segundos\n    - fs: frecuencia de muestreo en Hz\n    - heart_rate: frecuencia cardiaca en latidos por minuto\n\n    Devuelve:\n    - t: vector de tiempos\n    - ecg: señal simulada de ECG en mV\n    \"\"\"\n    dt = 1 / fs\n    t = np.arange(0, duration, dt)\n    rr = 60 / heart_rate  # intervalo RR en segundos\n\n    # Inicializar señal\n    ecg = np.zeros_like(t)\n\n    # Parámetros de las ondas (posiciones relativas en segundos)\n    # P wave\n    p_amp, p_dur, p_delay = 0.25, 0.09, 0.16\n    # Q wave\n    q_amp, q_dur, q_delay = -0.05, 0.066, 0.166\n    # R wave\n    r_amp, r_dur, r_delay = 1.6, 0.1, 0.166\n    # S wave\n    s_amp, s_dur, s_delay = -0.25, 0.066, 0.19\n    # T wave\n    t_amp, t_dur, t_delay = 0.35, 0.142, 0.36\n\n    # Generar cada latido\n    for beat_start in np.arange(0, duration, rr):\n        mask = (t &gt;= beat_start) & (t &lt; beat_start + rr)\n        tb = t[mask] - beat_start\n        ecg[mask] += gaussian(tb, p_delay, p_dur / 2, p_amp)\n        ecg[mask] += gaussian(tb, q_delay, q_dur / 2, q_amp)\n        ecg[mask] += gaussian(tb, r_delay, r_dur / 2, r_amp)\n        ecg[mask] += gaussian(tb, s_delay, s_dur / 2, s_amp)\n        ecg[mask] += gaussian(tb, t_delay, t_dur / 2, t_amp)\n\n    return t, ecg+0.1*np.cos(2*np.pi*60*t)\n\n\n    # Parámetros de simulación\n    DURATION = 10    # segundos\n    FS = 500         # Hz\n    HR = 70          # latidos por minuto\n\n    # Generar señal\n    t, ecg_signal = simulate_ecg(duration=DURATION, fs=FS, heart_rate=HR)\n\n    # Graficar resultado\n    plt.figure(figsize=(12, 4))\n    plt.plot(t, ecg_signal, linewidth=1)\n    plt.title(f'Señal de ECG sintética ({HR} bpm)')\n    plt.xlabel('Tiempo (s)')\n    plt.ylabel('Amplitud (mV)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy import signal\n\n\nn = len(ecg_signal)\nyf = np.fft.rfft(ecg_signal)\nxf = np.fft.rfftfreq(n, d=1/FS)\nmagnitude = np.abs(yf) / n\n\n\nplt.figure()\nplt.plot(xf, magnitude)\nplt.title(\"Espectro de frecuencia de la señal ECG\")\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.xlim(0, FS/2)\nplt.grid(True)\n\n\n\n\n\n\n\n\n\nb,a = design_filter(zeros=[np.exp(1j*2*np.pi*60/500), np.exp(-1j*2*np.pi*60/500)])\nw, h = signal.freqz(b, a, worN=1024)\n\n\n    mag_db = 20 * np.log10(np.abs(h))\n    phase = np.unwrap(np.angle(h))\n\n    # Gráficos\n    plt.figure(figsize=(8, 6))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(250*(w/np.pi), mag_db)\n    plt.title(\"Respuesta en frecuencia\")\n    plt.ylabel(\"Magnitud (dB)\")\n    plt.grid(True)\n\n    plt.subplot(2, 1, 2)\n    plt.plot(250*(w/np.pi), phase)\n    plt.xlabel(\"Frecuencia normalizada (×π rad/muestra)\")\n    plt.ylabel(\"Fase (rad)\")\n    plt.grid(True)\n\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "codigo/preparing_slides_002.html",
    "href": "codigo/preparing_slides_002.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport cv2\n\n\ndef generate_striped_image(N, M, K, orientation=\"vertical\"):\n    \"\"\"\n    Genera una imagen de N×M pixeles con bandas alternas (blanco/negro)\n    de ancho K, en orientación vertical u horizontal.\n\n    Parámetros\n    ----------\n    N : int\n        Altura de la imagen en pixeles.\n    M : int\n        Anchura de la imagen en pixeles.\n    K : int\n        Ancho de cada banda en pixeles.\n    orientation : {'vertical', 'horizontal'}\n        Orientación de las bandas. 'vertical' crea franjas verticales;\n        'horizontal' crea franjas horizontales.\n\n    Devuelve\n    -------\n    img : np.ndarray\n        Imagen en escala de grises (dtype uint8) con valores 0 o 255.\n    \"\"\"\n    # Crear imagen en negro\n    img = np.zeros((N, M), dtype=np.uint8)\n\n    # Alternar franjas\n    if orientation == \"vertical\":\n        for start in range(0, M, K):\n            # Determinar color de la franja (0 o 255)\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[:, start : start + K] = color\n\n    elif orientation == \"horizontal\":\n        for start in range(0, N, K):\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[start : start + K, :] = color\n\n    else:\n        raise ValueError(\"orientation debe ser 'vertical' o 'horizontal'\")\n\n    return img\n\n\nif __name__ == \"__main__\":\n    # Parámetros de ejemplo\n    altura = 400  # N\n    anchura = 400  # M\n    ancho_banda = 50  # K\n\n    # Generar imagen con franjas verticales\n    img_vertical = generate_striped_image(\n        altura, anchura, ancho_banda, orientation=\"vertical\"\n    )\n    cv2.imwrite(\"stripes_vertical.png\", img_vertical)\n    print(\"Guardado stripes_vertical.png\")\n\n    # Generar imagen con franjas horizontales\n    img_horizontal = generate_striped_image(\n        altura, anchura, ancho_banda, orientation=\"horizontal\"\n    )\n    cv2.imwrite(\"stripes_horizontal.png\", img_horizontal)\n    print(\"Guardado stripes_horizontal.png\")\n\nGuardado stripes_vertical.png\nGuardado stripes_horizontal.png\n\n\n\nimport numpy as np\nimport cv2\n\n\ndef generate_pattern_image(N, M, K, pattern=\"vertical\"):\n    \"\"\"\n    Genera una imagen de N×M píxeles con:\n      - 'vertical': franjas verticales de ancho K\n      - 'horizontal': franjas horizontales de alto K\n      - 'squares': cuadrados alternos de tamaño K×K (patrón ajedrez)\n\n    Parámetros\n    ----------\n    N : int\n        Altura de la imagen en píxeles.\n    M : int\n        Anchura de la imagen en píxeles.\n    K : int\n        Dimensión de la franja o del cuadrado en píxeles.\n    pattern : {'vertical', 'horizontal', 'squares'}\n        Tipo de patrón a generar.\n\n    Devuelve\n    -------\n    img : np.ndarray\n        Imagen en escala de grises (dtype uint8) con valores 0 o 255.\n    \"\"\"\n    img = np.zeros((N, M), dtype=np.uint8)\n\n    if pattern == \"vertical\":\n        for start in range(0, M, K):\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[:, start : start + K] = color\n\n    elif pattern == \"horizontal\":\n        for start in range(0, N, K):\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[start : start + K, :] = color\n\n    elif pattern == \"squares\":\n        for i in range(0, N, K):\n            for j in range(0, M, K):\n                # alterna color en función de la suma de índices de bloque\n                color = 255 if (((i // K) + (j // K)) % 2) == 0 else 0\n                img[i : i + K, j : j + K] = color\n\n    else:\n        raise ValueError(\"pattern debe ser 'vertical', 'horizontal' o 'squares'\")\n\n    return img\n\n\nif __name__ == \"__main__\":\n    # Parámetros de ejemplo\n    altura = 400  # N\n    anchura = 600  # M\n    K = 50  # tamaño de banda o cuadrado\n\n    # Generar y guardar cada patrón\n    for pat in [\"vertical\", \"horizontal\", \"squares\"]:\n        img = generate_pattern_image(altura, anchura, K, pattern=pat)\n        filename = f\"pattern_{pat}.png\"\n        cv2.imwrite(filename, img)\n        print(f\"Guardado {filename}\")\n\nGuardado pattern_vertical.png\nGuardado pattern_horizontal.png\nGuardado pattern_squares.png\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a periodic discrete signal\nN = 8  # Period of the signal\nn = np.arange(N)\nx_n = np.array([1, 2, 3, 4, 3, 2, 1, 0])  # Example discrete signal\n\n# Compute DTFS coefficients\nC_k = np.fft.fft(x_n) / N  # Normalized Discrete Fourier Transform\n\n# Reconstruct the signal using DTFS\nx_reconstructed = np.zeros(N, dtype=complex)\nfor k in range(N):\n    x_reconstructed += C_k[k] * np.exp(1j * 2 * np.pi * k * n / N)\n\n# Plot original and reconstructed signals\nplt.figure(figsize=(10, 4))\nplt.stem(n, x_n, linefmt='b-', markerfmt='bo', basefmt='r-', label='Original Signal')\nplt.stem(n, np.real(x_reconstructed), linefmt='r--', markerfmt='go', basefmt='r-', label='Reconstructed Signal')\nplt.xlabel(\"n\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"DTFS: Original vs Reconstructed Signal\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Print DTFS Coefficients\nprint(\"DTFS Coefficients:\")\nfor k in range(N):\n    print(f\"C[{k}] = {C_k[k]:.4f}\")\n\n\n\n\n\n\n\n\nDTFS Coefficients:\nC[0] = 2.0000+0.0000j\nC[1] = -0.6036-0.6036j\nC[2] = 0.0000+0.0000j\nC[3] = 0.1036-0.1036j\nC[4] = 0.0000+0.0000j\nC[5] = 0.1036+0.1036j\nC[6] = 0.0000+0.0000j\nC[7] = -0.6036+0.6036j\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a periodic discrete signal\nN = 8  # Period of the signal\nn = np.arange(N)\nx_n = np.array([1, 2, 3, 4, 3, 2, 1, 0])  # Example discrete signal\n\n# Compute DTFS coefficients\nC_k = np.fft.fft(x_n) / N  # Normalized Discrete Fourier Transform\n\n# Verify periodicity property: C[k] repeats every N\nC_k_extended = np.tile(C_k, 2)  # Extend coefficients to see repetition\nk_extended = np.arange(2 * N)\n\n# Plot DTFS coefficients and their periodic repetition\nplt.figure(figsize=(10, 4))\nplt.stem(\n    k_extended,\n    np.real(C_k_extended),\n    linefmt=\"b-\",\n    markerfmt=\"bo\",\n    basefmt=\"r-\",\n    label=\"Real Part\",\n)\nplt.stem(\n    k_extended,\n    np.imag(C_k_extended),\n    linefmt=\"g--\",\n    markerfmt=\"go\",\n    basefmt=\"r-\",\n    label=\"Imaginary Part\",\n)\nplt.xlabel(\"n\")\nplt.ylabel(\"Magnitude\")\nplt.title(\"DTFS Periodicity: Coefficients Repeat Every N Samples\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Print DTFS Coefficients to observe periodicity\nprint(\"DTFS Coefficients (showing periodicity):\")\nfor k in range(2 * N):\n    print(f\"C[{k}] = {C_k_extended[k]:.4f}\")\n\n\n\n\n\n\n\n\nDTFS Coefficients (showing periodicity):\nC[0] = 2.0000+0.0000j\nC[1] = -0.6036-0.6036j\nC[2] = 0.0000+0.0000j\nC[3] = 0.1036-0.1036j\nC[4] = 0.0000+0.0000j\nC[5] = 0.1036+0.1036j\nC[6] = 0.0000+0.0000j\nC[7] = -0.6036+0.6036j\nC[8] = 2.0000+0.0000j\nC[9] = -0.6036-0.6036j\nC[10] = 0.0000+0.0000j\nC[11] = 0.1036-0.1036j\nC[12] = 0.0000+0.0000j\nC[13] = 0.1036+0.1036j\nC[14] = 0.0000+0.0000j\nC[15] = -0.6036+0.6036j\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros\nfs_cont = 5000  # Frecuencia de muestreo \"continua\" (muy alta)\nfs_sampled = 1000  # Frecuencia de muestreo baja\nT = 1  # Duración de la señal en segundos\nf_signal = 30  # Frecuencia de la señal\n\n# Señal continua\nt_cont = np.linspace(0, T, fs_cont * T, endpoint=False)\nsignal_cont = np.sin(2 * np.pi * f_signal * t_cont)\n\n# Señal muestreada\nt_sampled = np.linspace(0, T, fs_sampled * T, endpoint=False)\nsignal_sampled = np.sin(2 * np.pi * f_signal * t_sampled)\n\n# FFT continua\nfft_cont = np.fft.fft(signal_cont)\nfreqs_cont = np.fft.fftfreq(len(signal_cont), d=1 / fs_cont)\n\n# FFT muestreada\nfft_sampled = np.fft.fft(signal_sampled)\nfreqs_sampled = np.fft.fftfreq(len(signal_sampled), d=1 / fs_sampled)\n\n# Graficar espectro original y espectro muestreado\nplt.figure(figsize=(12, 6))\n\nplt.subplot(3, 1, 1)\nplt.plot(\n    t_cont, signal_cont\n)\nplt.subplot(3, 1, 2)\nplt.plot(\n    freqs_cont[: len(freqs_cont) // 2],\n    np.abs(fft_cont[: len(freqs_cont) // 2]),\n    label=\"Espectro original\",\n)\nplt.title(\"Espectro de la señal continua\")\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.legend()\n\nplt.subplot(3, 1, 3)\nplt.plot(\n    freqs_sampled[: len(freqs_sampled) // 2],\n    np.abs(fft_sampled[: len(freqs_sampled) // 2]),\n    label=\"Espectro muestreado\",\n)\nplt.title(\"Espectro después del muestreo (repeticiones cada f_s)\")\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import tf2zpk\n\n# Define numerator (zeros) and denominator (poles) coefficients of the transfer function\n# Example: H(z) = (1 - 0.5z^-1) / (1 - 0.9z^-1)\nb = [1, -0.5]  # Numerator coefficients (zeros)\na = [1, -0.9]  # Denominator coefficients (poles)\n\n# Get zeros, poles, and gain\nz, p, k = tf2zpk(b, a)\n\n# Plot settings\nfig, ax = plt.subplots()\nax.set_title(\"Pole-Zero Plot in the Z-Plane\")\n\n# Draw unit circle\nunit_circle = plt.Circle((0, 0), 1, color=\"black\", fill=False, linestyle=\"dashed\")\nax.add_artist(unit_circle)\n\n# Plot zeros and poles\nax.plot(np.real(z), np.imag(z), \"go\", label=\"Zeros\")  # green circles\nax.plot(np.real(p), np.imag(p), \"rx\", label=\"Poles\")  # red Xs\n\n# Axes and formatting\nax.set_xlabel(\"Re\")\nax.set_ylabel(\"Im\")\nax.axhline(0, color=\"gray\", linewidth=0.5)\nax.axvline(0, color=\"gray\", linewidth=0.5)\nax.set_aspect(\"equal\")\nax.grid(True, linestyle=\"--\", alpha=0.5)\nax.legend()\nax.set_xlim(-1.5, 1.5)\nax.set_ylim(-1.5, 1.5)\n\nplt.show()\n\n\n\n\n\n\n\n\n\ndef zpk_to_latex(z, p, k):\n    def format_factor(value):\n        sign = \"+\" if np.real(value) &lt; 0 else \"-\"\n        return f\"(z {sign} {abs(np.real(value)):.2f})\"\n\n    num = \" \".join([format_factor(zero) for zero in z]) if len(z) &gt; 0 else \"1\"\n    den = \" \".join([format_factor(pole) for pole in p]) if len(p) &gt; 0 else \"1\"\n\n    latex_str = r\"H(z) = \" + f\"{k:.2f} \\\\cdot \\\\frac{{{num}}}{{{den}}}\"\n    return latex_str\n\n\nzpk_to_latex(z,p,k)\n\n'H(z) = 1.00 \\\\cdot \\\\frac{(z - 0.50)}{(z - 0.90)}'"
  },
  {
    "objectID": "codigo/PSIM/cod005_eda_images.html",
    "href": "codigo/PSIM/cod005_eda_images.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nimagen = cv2.imread(\"../../data/female-chest-x-ray.jpg\")\n\n\niBlue = imagen[:,:,0]\niGreen = imagen[:, :, 1]\niRed = imagen[:, :, 2]\n\n\nb = 8\ninp01 = iBlue\n\nfor k in range(256)\n\n800000"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html",
    "title": "Estudio de arritmia cardíaca",
    "section": "",
    "text": "#from google.colab import drive\n#drive.mount('/content/drive')"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librerías",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librerías",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de librerías",
    "text": "Carga de librerías\n\nnumpy: Para manipulación numérica y funciones estadísticas básicas\nmatplotlib.pyplot: Para generación de gráficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.signal as sig"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#configuración-de-carpetas",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#configuración-de-carpetas",
    "title": "Estudio de arritmia cardíaca",
    "section": "Configuración de carpetas",
    "text": "Configuración de carpetas\n\n# data_path = \"/content/drive/MyDrive/ECG_Dataset/\"#Datapath de colab\ndata_path = \"../../data/\""
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\n\n\n\n\n\n\n\n\n\nfs =  500\n\nfc1 = 0.5\nfc2 = 50\norder_fir = 51\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import freqz, windows\n\n\n# Definir el vector de frecuencias\nf_vect = np.linspace(-fs//2, fs//2, order_fir)\n\n# Definir la respuesta en frecuencia deseada\nH1 = np.zeros(len(f_vect))\nH1[(((f_vect &gt;= 0.5) & (f_vect &lt;= 50)) | ((f_vect &lt;= -0.5) & (f_vect &gt;= -50)))] =  1  # Banda de paso entre 0.5 y 50 Hz\n\nplt.figure(figsize=(10,6))\nplt.plot(f_vect, H1)\n\n# Normalizar las frecuencias con respecto a Nyquist (fs/2)\nnormalized_frequencies = f_vect / (fs / 2)\n\n# Interpolación de la respuesta deseada\nH_interp = np.interp(np.linspace(0, 1, order_fir), normalized_frequencies, H1)\n\n# Transformada Inversa de Fourier para obtener la respuesta al impulso\nh = np.fft.ifft(H_interp, order_fir).real  # Solo tomamos la parte real\n\n# Aplicar ventana de Hamming\nwindow = windows.hamming(order_fir)\nh_windowed = h * window\n\n# Normalizar la energía del filtro\nh_windowed /= np.sum(h_windowed)\n\n# Calcular la respuesta en frecuencia\nw, H_fir = freqz(h_windowed, worN=2048, fs=fs)\n\n# Graficar la respuesta al impulso\nplt.figure(figsize=(12, 5))\nplt.stem(h_windowed, basefmt=\"C0\")\nplt.title(\"Respuesta al Impulso del Filtro FIR con Especificación en Frecuencia\")\nplt.xlabel(\"n (muestras)\")\nplt.ylabel(\"h[n]\")\nplt.grid()\nplt.show()\n\n# Graficar la respuesta en frecuencia\nplt.figure(figsize=(12, 6))\nplt.subplot(2, 1, 1)\nplt.plot(w, 20 * np.log10(abs(H_fir)), \"b\")\nplt.title(\"Respuesta en Frecuencia - Magnitud\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Magnitud [dB]\")\nplt.grid()\n\nplt.subplot(2, 1, 2)\nplt.plot(w, np.angle(H_fir), \"g\")\nplt.title(\"Respuesta en Frecuencia - Fase\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Fase [radianes]\")\nplt.grid()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import firls, freqz\n\n# Parámetros del filtro\nfs = 500  # Frecuencia de muestreo en Hz\nN = 51  # Número de coeficientes del filtro (impar para centrar en cero)\n\n# Definir las bandas y la respuesta deseada\nbands = [0, 0.5, 50, fs / 2]  # Frecuencias en Hz\ndesired = [0, 10, 10, 0]  # Pasa-banda de 0.5 Hz a 50 Hz\n\n# Diseñar el filtro FIR con firls\nh_firls = firls(N, bands, desired, fs=fs)\n\n# Calcular la respuesta en frecuencia\nw, H_fir = freqz(h_firls, worN=2048, fs=fs)\n\n# Graficar la respuesta al impulso\nplt.figure(figsize=(12, 5))\nplt.stem(h_firls, basefmt=\"C0\")\nplt.title(\"Respuesta al Impulso del Filtro FIR con firls\")\nplt.xlabel(\"n (muestras)\")\nplt.ylabel(\"h[n]\")\nplt.grid()\nplt.show()\n\n# Graficar la respuesta en frecuencia\nplt.figure(figsize=(12, 6))\nplt.subplot(2, 1, 1)\nplt.plot(w, 20 * np.log10(abs(H_fir)), \"b\")\nplt.title(\"Respuesta en Frecuencia - Magnitud\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Magnitud [dB]\")\nplt.grid()\n\nplt.subplot(2, 1, 2)\nplt.plot(w, np.angle(H_fir), \"g\")\nplt.title(\"Respuesta en Frecuencia - Fase\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Fase [radianes]\")\nplt.grid()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "",
    "text": "La leucemia linfoblástica aguda (LLA) es un tipo de cáncer hematológico caracterizado por la proliferación descontrolada de linfoblastos inmaduros en la médula ósea, la sangre y otros órganos. Este trastorno impide la producción adecuada de células sanguíneas normales, lo que provoca síntomas como anemia, infecciones recurrentes y sangrados anormales. [1]\nEl cáncer es una de las principales causas de mortalidad entre niños y adolescentes en todo el mundo; cada año se diagnostica cáncer a aproximadamente 274.000 niños de entre 0 y 19 años. [2]\nEn América Latina y el Caribe, se estima que alrededor de 30.000 niñas, niños y adolescentes menores de 19 años resultarán afectados por el cáncer anualmente. De ellos, casi 10.000 fallecerán a causa de esta enfermedad.\nEn los países de ingresos altos, más del 80% de los niños afectados de cáncer se curan, pero en muchos países de ingresos medianos y bajos la tasa de curación es de aproximadamente el 20%.[3]\nLas defunciones evitables debidas a los cánceres infantiles en los países de ingresos medianos y bajos se producen a consecuencia de la falta de diagnóstico, los diagnósticos incorrectos o tardíos, las dificultades para acceder a la atención sanitaria, el abandono del tratamiento, la muerte por toxicidad y las mayores tasas de recidivas. [3]"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#significado-en-el-contexto-del-modelo",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#significado-en-el-contexto-del-modelo",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Significado en el Contexto del Modelo",
    "text": "Significado en el Contexto del Modelo\n\nCombinación Lineal\n\nCada característica \\(x_i\\) se pondera por su importancia relativa \\(\\theta_i\\)\nEl término independiente \\(\\theta_0\\) añade un sesgo base\n\nInterpretación de los Coeficientes\n\n\\(\\theta_i &gt; 0\\): La característica aumenta la probabilidad de leucemia\n\\(\\theta_i &lt; 0\\): La característica disminuye la probabilidad de leucemia\n\\(|\\theta_i|\\): Magnitud del impacto de la característica\n\nFlujo del Modelo\n\\[\nX\\theta \\xrightarrow{\\text{producto punto}} z \\xrightarrow{\\text{sigmoide}} h_\\theta(x) = \\frac{1}{1 + e^{-z}}\n\\]\nResultado\n\n\\(z\\): Puntuación lineal (puede ser cualquier número real)\n\\(h_\\theta(x)\\): Probabilidad entre 0 y 1 después de aplicar la sigmoide\n\n\nLa regularización L1 (también conocida como LASSO - Least Absolute Shrinkage and Selection Operator) es una técnica para prevenir el sobreajuste (overfitting).\n\n¿Qué es la regularización L1?\nEs un término que se añade a la función de costo:\n\\[\n\\frac{\\lambda}{m} \\sum_{j=1}^{n} |\\theta_j|\n\\]\nDonde:\n- λ (lambda) es el parámetro que controla la fuerza de la regularización\n- m es el número de muestras\n- θj son los parámetros del modelo\n- |θj| es el valor absoluto de cada parámetro\n\n\n¿Por qué se implementa?\n\nPrevención de sobreajuste:\n\nPenaliza coeficientes muy grandes que podrían hacer que el modelo se ajuste demasiado a los datos de entrenamiento\nAyuda al modelo a generalizar mejor con nuevos datos\n\nSelección de características:\n\nLa regularización L1 tiende a producir coeficientes exactamente iguales a cero\nEsto efectivamente selecciona las características más importantes y descarta las menos relevantes\n\n\n\n\nEfectos prácticos:\n\nCon lambda_reg = 0:\n\nNo hay regularización\nEl modelo puede sobreajustarse\n\nCon lambda_reg pequeño (ej: 0.1):\n\nRegularización suave\nBalance entre ajuste y generalización\n\nCon lambda_reg grande (ej: 10):\n\nRegularización fuerte\nMás coeficientes se vuelven cero\nModelo más simple pero puede subajustarse (underfitting)\n\n\n\n\nVentajas:\n\nSelección automática de características más relevantes para detectar leucemia\nReducción del ruido en las mediciones de células\nModelo más robusto y generalizable a nuevas muestras\nInterpretabilidad mejorada al identificar las características más importantes"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#área-del-contorno",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#área-del-contorno",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "1. Área del Contorno",
    "text": "1. Área del Contorno\nEl área de un contorno cerrado se calcula utilizando la fórmula del área de un polígono mediante coordenadas:\n\\[\n\\text{Área} = \\frac{1}{2} \\sum_{i=1}^{n} (x_i y_{i+1} - y_i x_{i+1})\n\\]\nDonde:\n- \\(n\\) : Número total de puntos en el contorno\n- \\((x_i, y_i)\\) : Coordenadas del punto \\(i\\) del contorno\n- \\((x_{i+1}, y_{i+1})\\) : Coordenadas del siguiente punto en el contorno\n- El punto \\(n+1\\) se considera igual al punto 1, cerrando el polígono\nEsta fórmula:\n- Utiliza el método de triangulación para calcular el área\n- Funciona para cualquier polígono cerrado, sea cóncavo o convexo\n- El resultado es positivo si los puntos están ordenados en sentido antihorario\n- El valor absoluto del resultado da el área real"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#perímetro-del-contorno",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#perímetro-del-contorno",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "2. Perímetro del Contorno",
    "text": "2. Perímetro del Contorno\nEl perímetro se calcula sumando las distancias entre todos los puntos consecutivos del contorno:\n\\[\n\\text{Perímetro} = \\sum_{i=1}^{n} \\sqrt{(x_{i+1} - x_i)^2 + (y_{i+1} - y_i)^2}\n\\]\nDonde:\n- \\(n\\) : Número total de puntos en el contorno\n- \\((x_i, y_i)\\) : Coordenadas del punto actual\n- \\((x_{i+1}, y_{i+1})\\) : Coordenadas del siguiente punto\n- El último punto se conecta con el primero para cerrar el contorno\nEsta fórmula:\n- Utiliza la distancia euclidiana entre puntos consecutivos\n- La suma total representa la longitud del contorno completo\n- Es independiente de la orientación del contorno"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#circularidad",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#circularidad",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "3. Circularidad",
    "text": "3. Circularidad\nLa circularidad es una medida adimensional que cuantifica qué tan similar es una forma a un círculo perfecto:\n\\[\n\\text{Circularidad} = \\frac{4\\pi \\times \\text{Área}}{\\text{Perímetro}^2}\n\\]\nDonde:\n- \\(\\text{Área}\\) : Área del contorno calculada con la primera fórmula\n- \\(\\text{Perímetro}\\) : Perímetro del contorno calculado con la segunda fórmula\n- \\(\\pi\\) : Constante matemática pi (≈ 3.14159)\nInterpretación de los valores:\n- \\(\\text{Circularidad} = 1\\) : Círculo perfecto\n- \\(0 &lt; \\text{Circularidad} &lt; 1\\) : Formas no circulares\n- Valores cercanos a 1: Formas casi circulares\n- Valores cercanos a 0: Formas muy alargadas o irregulares\nPropiedades importantes:\n1. Es invariante a la escala (el tamaño no afecta el resultado)\n2. Es adimensional (no tiene unidades)\n3. Siempre es menor o igual a 1 (la igualdad solo se da en círculos perfectos)\n4. Es sensible a irregularidades en el contorno\nEjemplo de interpretación:\n- Circularidad = 0.95: Forma muy circular\n- Circularidad = 0.7: Forma moderadamente circular\n- Circularidad = 0.3: Forma muy irregular o alargadas"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-logística",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-logística",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Función Logística",
    "text": "Función Logística\nLa función logística, o función sigmoide, se define como:\n\\[\nP(y = 1|x) = \\frac{1}{1 + e^{-(w^T x + b)}}\n\\]\nDonde:\n- ( P(y = 1|x) ) es la probabilidad de que la clase sea 1 dado un vector de características ( x ).\n- ( w ) es el vector de pesos del modelo.\n- ( b ) es el sesgo o término independiente.\n- ( x ) es el vector de características de entrada.\nLa función sigmoide convierte la salida lineal ( w^T x + b ) en un valor entre 0 y 1, que puede interpretarse como una probabilidad."
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-de-costo",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-de-costo",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Función de Costo",
    "text": "Función de Costo\nPara entrenar el modelo, se utiliza la función de costo de entropía cruzada:\n\\[\nJ(w, b) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(P(y^{(i)}|x^{(i)})) + (1 - y^{(i)}) \\log(1 - P(y^{(i)}|x^{(i)})) \\right]\n\\]\nDonde:\n- ( m ) es el número total de ejemplos en el conjunto de datos.\n- ( y^{(i)} ) es la etiqueta verdadera para el i-ésimo ejemplo.\n- ( P(y{(i)}|x{(i)}) ) es la probabilidad predicha para el i-ésimo ejemplo."
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#gradientes-y-actualización",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#gradientes-y-actualización",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Gradientes y Actualización",
    "text": "Gradientes y Actualización\nLos gradientes de la función de costo con respecto a los parámetros ( w ) y ( b ) se utilizan para actualizar los pesos y el sesgo mediante descenso por gradiente:\n\nGradiente del peso ( w ):\n\n\\[\n\\frac{\\partial J(w, b)}{\\partial w} = \\frac{1}{m} \\sum_{i=1}^{m} (P(y^{(i)}|x^{(i)}) - y^{(i)}) x^{(i)}\n\\]\n\nGradiente del sesgo ( b ):\n\n\\[\n\\frac{\\partial J(w, b)}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (P(y^{(i)}|x^{(i)}) - y^{(i)})\n\\]\nLos parámetros se actualizan de la siguiente manera:\n\nActualización del peso ( w ):\n\n\\[\nw := w - \\alpha \\frac{\\partial J(w, b)}{\\partial w}\n\\]\n\nActualización del sesgo ( b ):\n\n\\[\nb := b - \\alpha \\frac{\\partial J(w, b)}{\\partial b}\n\\]\nDonde ( ) es la tasa de aprendizaje.\nLa precisión del modelo se evalúa comparando las predicciones con las etiquetas verdaderas en el conjunto de prueba, utilizando métricas como la precisión (accuracy), precisión (precision), sensibilidad (recall), y especificidad."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#áreas-de-aplicación-del-procesamiento-de-señales-e-imágenes",
    "href": "presentaciones/TALLERES/Promise.html#áreas-de-aplicación-del-procesamiento-de-señales-e-imágenes",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Áreas de aplicación del procesamiento de señales e imágenes",
    "text": "Áreas de aplicación del procesamiento de señales e imágenes\n\n\n\nDiagnóstico automatizado\nIdentificación de enfermedades en ECG, EEG o imágenes médicas.\nMonitoreo en tiempo real\nVigilancia en UCI con señales continuas de corazón, respiración y cerebro.\nTelemedicina\nTransmisión y compresión de señales para consultas a distancia.\nRehabilitación y prótesis inteligentes\nUso de señales EMG para controlar prótesis y exoesqueletos.\n\n\n\nDetección temprana de eventos críticos\nAnticipación de arritmias, crisis epilépticas o caídas.\nBiometría y seguridad\nReconocimiento de voz, rostro o iris.\nImagenología avanzada\nSegmentación de órganos o tumores en 3D para cirugía o radioterapia.\nEntretenimiento y multimedia\nFiltros en fotos y videos, mejora de audio y realidad aumentada."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "href": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Plataforma para el monitoreo de salud de adultos mayores",
    "text": "Plataforma para el monitoreo de salud de adultos mayores\n\n\n\nDetección ambulatoria de actividades diarias.\nDetección ambulatoria de riesgo de caída.\nDetección ambulatoria de riesgo neuronal.\n\n\n\n\n\n\n\n\n\n\nProfesora Auxiliar\n\n\nPh.D. Jenny Carolina Castiblanco S."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores-1",
    "href": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores-1",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Plataforma para el monitoreo de salud de adultos mayores",
    "text": "Plataforma para el monitoreo de salud de adultos mayores\n\n\n\nDetección ambulatoria de riesgo psico-social.\nDetección ambulatoria de riesgo cardíaco\nMonitorización de terapias ambulatorias para la rehabilitación de adultos mayores\n\n\n\n\n\n\n\n\n\n\nProfesora Auxiliar\n\n\nPh.D. Jenny Carolina Castiblanco S."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#creación-de-ambientes-de-habitación-saludables-usando-realimentación-sensorial",
    "href": "presentaciones/TALLERES/Promise.html#creación-de-ambientes-de-habitación-saludables-usando-realimentación-sensorial",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Creación de ambientes de habitación saludables usando realimentación sensorial",
    "text": "Creación de ambientes de habitación saludables usando realimentación sensorial\n\n\n\n\n\nNeurofeedback emocional usando música.\nNeurofeedback de memoria procedimental.\nNeurofeedback en automotores.\nMonitorización ambulatoria de estado emocional.\nMonitorización ambulatoria de terapias emocionales"
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#apoyo-tecnológico-mediante-ia-a-intervenciones-clínicas",
    "href": "presentaciones/TALLERES/Promise.html#apoyo-tecnológico-mediante-ia-a-intervenciones-clínicas",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Apoyo tecnológico mediante IA a intervenciones clínicas",
    "text": "Apoyo tecnológico mediante IA a intervenciones clínicas\n\n\n\nDetección de anomalías en imágenes mediante segmentación heurística.\nPlaneación pre-operatoria mediante el uso de inteligencia artificial.\nPlanificación operatoria de sistemas robóticos.\nEvaluación de espasticidad mediante el uso tecnología."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#rehabilitación-y-prótesis-inteligentes",
    "href": "presentaciones/TALLERES/Promise.html#rehabilitación-y-prótesis-inteligentes",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Rehabilitación y prótesis inteligentes",
    "text": "Rehabilitación y prótesis inteligentes\n\n\n\n\n\n\n\n\n\n\nProfesora Auxiliar\n\n\nPh.D. Jenny Carolina Castiblanco S.\n\n\n\n\n\n\nGeneración de interfaces cerebro-computador\nGeneración de algoritmos de clasificación de intención de movimiento\nMonitorización de terapias de rehabilitación.\nUso de señales DE origen biológico para controlar prótesis y exoesqueletos."
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant “free” sources of data\n\n\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Linear Regression",
    "text": "Linear Regression"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Linear Regression",
    "text": "Linear Regression\nIn the example, in previous slide, data was modelled as a linear function. The difference (error) between the modelled data \\(\\left( \\hat{y}_n \\right)\\) and actual data \\(\\left( y_n \\right)\\) can be written as\n\n\n\n\n\n\n\nCost function\n\n\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Some other examples of cost function",
    "text": "Some other examples of cost function\n\\[E = \\sqrt{\\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}}\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left| \\hat{y}_n - y_n \\right| }\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nLooking the cost surface, we notices that this surface has a global minimum. If we could have an algorithm which automatically finds it.\n\nCost Surface"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nIndeed, there are multiples algorithms for minima searching. The most famous is the one named as least squares but in this course we will use the gradient descent algorithm.\nAssuming that the data model is a function \\(f\\left(\\theta_i, x_n, y_n\\right)\\), where \\(\\theta\\) is known as model parameter.\n\n\n\n\n\n\n\nThe gradient descent algorithm\n\n\n\\[\\boldsymbol{\\theta}_{i,j+1} =  \\boldsymbol{\\theta}_{i,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{i}}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\nAssumptions\n\n\n\nLinear model for the Regression\nMean square error as cost function\n\\(\\eta = 1\\)\n\n\n\n\n\n\\[\\boldsymbol{\\theta}_i = \\left[ \\theta_1, \\theta_0 \\right]^T\\]\n\\[\\hat{y}_n  = \\theta_1 x_n + \\theta_0\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_1\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{1,j+1} = \\boldsymbol{\\theta}_{1,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right) x_n}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_0\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{0,j+1} = \\boldsymbol{\\theta}_{0,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  E & = & \\frac{1}{N} \\sqrt{u}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{1}{2 N \\sqrt{u}} \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}}\\\\\n  \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}} &=& 2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{2 N \\sqrt{u}}\n\\end{eqnarray}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} &=& \\frac{\\sum_{n=1}^{N}{x_n \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{2}} &=& \\frac{\\sum_{n=1}^{N}{x_n^2 \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\n\\end{eqnarray}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#what-is-convolution",
    "href": "presentaciones/ASIM/lect005_CNN.html#what-is-convolution",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "What is Convolution?",
    "text": "What is Convolution?\n\nConvolution: A mathematical operation used to extract features from input data.\nFilter/Kernels:\n\nA small matrix (e.g., 3x3) that slides over the input.\nDetects patterns such as edges, textures, and colors.\n\nStride: Number of pixels by which the filter moves at each step.\nPadding: Adds extra pixels around the border of the input, preserving spatial dimensions."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#convolution-in-action",
    "href": "presentaciones/ASIM/lect005_CNN.html#convolution-in-action",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Convolution in Action",
    "text": "Convolution in Action\n\nInput: A matrix of pixel values (e.g., an image).\nOutput (Feature Map): A matrix where each value represents the result of applying the filter over a region of the input."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#what-are-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#what-are-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "What are CNNs?",
    "text": "What are CNNs?\n\nDefinition: CNNs are deep learning models primarily used for visual recognition tasks.\nKey Concept: CNNs learn and detect hierarchical patterns in image data (e.g., edges, shapes, textures).\nImportance: Automatically extract features, reducing the need for manual feature engineering."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#why-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#why-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Why CNNs?",
    "text": "Why CNNs?\n\nFully Connected Networks struggle with large images due to high dimensionality.\nCNNs reduce the number of parameters by using local connectivity (convolutions) and weight sharing.\nEfficient in Learning: They exploit spatial hierarchies in images."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#cnn-architecture-overview",
    "href": "presentaciones/ASIM/lect005_CNN.html#cnn-architecture-overview",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "CNN Architecture Overview",
    "text": "CNN Architecture Overview\n\nInput Layer: Raw image data (e.g., 28x28 pixels for MNIST).\nConvolutional Layer: Detects features from input images using filters.\nActivation Function: Typically ReLU to introduce non-linearity.\nPooling Layer: Reduces the spatial dimensions (downsampling).\nFully Connected Layer: Performs classification based on extracted features."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#activation-function-relu",
    "href": "presentaciones/ASIM/lect005_CNN.html#activation-function-relu",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Activation Function (ReLU)",
    "text": "Activation Function (ReLU)\n\nPurpose: Introduce non-linearity into the network, allowing CNNs to learn complex patterns.\nReLU Formula: ( f(x) = (0, x) )\nWhy ReLU?:\n\nFaster convergence compared to sigmoid or tanh.\nAvoids the vanishing gradient problem."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#pooling-layers",
    "href": "presentaciones/ASIM/lect005_CNN.html#pooling-layers",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Pooling Layers",
    "text": "Pooling Layers\n\nPurpose: Reduce the spatial dimensions of feature maps, decrease computational load, and control overfitting.\nTypes of Pooling:\n\nMax Pooling: Selects the maximum value within a specified window.\nAverage Pooling: Calculates the average value within a specified window.\n\nBenefits:\n\nRetains the most important features (Max Pooling).\nSmooths the feature maps (Average Pooling).\n\nCommon Parameters:\n\nKernel Size: Size of the window (e.g., 2x2).\nStride: Step size for moving the window."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#fully-connected-layers",
    "href": "presentaciones/ASIM/lect005_CNN.html#fully-connected-layers",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Fully Connected Layers",
    "text": "Fully Connected Layers\n\nFlattening: Converts the 2D feature maps into a 1D vector for input into fully connected layers.\nFully Connected (Dense) Layers: Every neuron in the previous layer is connected to every neuron in the next layer.\nRole: Performs classification based on features learned from convolution and pooling layers."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#training-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#training-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Training CNNs",
    "text": "Training CNNs\n\nLoss Function: Cross-entropy loss is commonly used for classification tasks.\nOptimization: Backpropagation combined with optimizers like stochastic gradient descent (SGD) or Adam.\nTraining Concepts:\n\nEpochs: Number of complete passes over the dataset.\nMini-batches: Small subsets of the dataset used in each iteration."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#challenges",
    "href": "presentaciones/ASIM/lect005_CNN.html#challenges",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Challenges",
    "text": "Challenges\n\nComputational Resources: CNNs require powerful hardware (e.g., GPUs) for training large models.\nLarge Datasets: CNNs often need vast amounts of labeled data to perform well.\nOverfitting: Common problem in CNNs when trained on small datasets. Solutions include:\n\nData augmentation (rotating, flipping, or zooming images).\nDropout layers to randomly drop neurons during training."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#future-of-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#future-of-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Future of CNNs",
    "text": "Future of CNNs\n\nAdvanced Architectures:\n\nResidual Networks (ResNet):\n\nDeeper networks can be trained by using skip connections to bypass layers and avoid the vanishing gradient problem.\n\nInception Networks:\n\nUtilize multiple filters of different sizes in parallel to capture features at different scales.\n\nEfficientNet:\n\nBalances network depth, width, and resolution, creating more efficient models with fewer parameters while maintaining accuracy."
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#el-profesor",
    "title": "Sistemas y Señales Biomédicas",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción al procesado de señales.\nConceptos de señales contínuas & discretas.\nMuestreo.\nExtracción de características de una señal.\nFiltraje de señales."
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluación final\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nExamen parcial 1 (15%)\nExamen parcial 2 (15%)\nExamen final (20%)\nLaboratorios (30%)\nProyecto Final (20%)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación-1",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (15%)\nLaboratorios (15%)\nProyecto final (20%)\n\n\nExamen Parcial 1 (15%)\nExamen Parcial 2 (15%)\nExamen final (20%)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#recursos",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nLunes 10:00am-11:30am F-204. Jueves 10:00am-11:30am F-206.\nLaboratorio\nMartes 10:00am-11:30am. I1-308\n\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#bibliografía",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#what-is-a-signal",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#what-is-a-signal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "What is a signal?",
    "text": "What is a signal?\n\nA signal is a function that conveys information by mapping an independent variable (or variables) to measurable quantities.\nFormally, a signal is a mapping \\(x:\\ \\mathcal{T}\\rightarrow\\mathcal{A}\\), where \\(\\mathcal{T}\\) is the domain (e.g., time \\(t\\in\\mathbb{R}\\) or sample index \\(n\\in\\mathbb{Z}\\)) and \\(\\mathcal{A}\\) is the codomain (e.g., amplitudes in \\(\\mathbb{R}\\) or \\(\\mathbb{C}\\), vectors, or matrices)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification",
    "text": "Signal Classification"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-bounded",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-bounded",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification – Bounded",
    "text": "Signal Classification – Bounded"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-compact-support",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-compact-support",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification – Compact Support",
    "text": "Signal Classification – Compact Support"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-causal",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-causal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification – Causal",
    "text": "Signal Classification – Causal"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---deterministic-vs-random-signals",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---deterministic-vs-random-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification - Deterministic vs Random Signals",
    "text": "Signal Classification - Deterministic vs Random Signals\n\nA deterministic signal \\(x_d(t)\\) is completely specified by an explicit rule; it produces the same waveform on every observation (e.g., \\(x_d(t)=A\\cos(2\\pi f_0 t+\\phi)\\)).\nA random signal (stochastic process) \\(X(t)\\) is a family of random variables indexed by \\(t\\); each observation yields a different realization. It is characterized statistically by its mean \\(\\mu_X(t)\\) and autocorrelation \\(R_X(\\tau)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---evenodd",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---evenodd",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification - Even/Odd",
    "text": "Signal Classification - Even/Odd\n\n\n\n\n\n\n\n\n\nEven\n\n\n\\[f\\left(t\\right) = f\\left(-t\\right)\\] \\[f\\left[t\\right] = f\\left[-t\\right]\\]\n\n\n\n\n\n\n\n\n\n\n\nOdd\n\n\n\\[f\\left(t\\right) = -f\\left(-t\\right)\\] \\[f\\left[t\\right] = -f\\left[-t\\right]\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-1",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification",
    "text": "Signal Classification\n\n\n\n\n\n\n\nDecomposition\n\n\nAll signal can be decomposed in two signals: one even, one odd.\n\\[x(t) = x_{even}(t) + x_{odd}(t)\\]\n\n\n\n\nWhere:\n\\[x_{even}(t) = \\frac{x(t)+x(-t)}{2} \\] \\[x_{odd}(t) = \\frac{x(t)-x(-t)}{2} \\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\n\n\n\n\n\n\n\nExample\n\n\nDecompose the signal \\(x(t)=e^{t}\\) into its even and odd parts"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-1",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\n\\[x_{\\text{even}}(t) = \\frac{x(t) + x(-t)}{2}\\]\n\\[x_{\\text{odd}}(t) = \\frac{x(t) - x(-t)}{2}\\]\n\\[x(-t) = e^{-t}\\]\n\\[x_{\\text{even}}(t) = \\frac{e^t + e^{-t}}{2} = \\cosh(t)\\]\n\\[x_{\\text{odd}}(t) = \\frac{e^t - e^{-t}}{2} = \\sinh(t)\\]\n\\[x(t) = x_{\\text{even}}(t) + x_{\\text{odd}}(t)\\]\n\\[e^t = \\cosh(t) + \\sinh(t)\\] ​"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-2",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---energy-vs-power-signals",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---energy-vs-power-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification - Energy vs Power Signals",
    "text": "Signal Classification - Energy vs Power Signals\nDefinitions. For a signal \\(x(t)\\) (continuous-time, CT) or \\(x[n]\\) (discrete-time, DT):\n\nEnergy: \\(E=\\int_{-\\infty}^{\\infty}\\lvert x(t)\\rvert^2,dt\\) (CT), \\(\\quad E=\\sum_{n=-\\infty}^{\\infty}\\lvert x[n]\\rvert^2\\) (DT).\nAverage power: \\(P=\\lim_{T\\to\\infty}\\dfrac{1}{2T}\\int_{-T}^{T}\\lvert x(t)\\rvert^2,dt\\) (CT), \\(\\quad P=\\lim_{N\\to\\infty}\\dfrac{1}{2N+1}\\sum_{n=-N}^{N}\\lvert x[n]\\rvert^2\\) (DT).\nEnergy signal: \\(0&lt;E&lt;\\infty\\) and \\(P=0\\) (e.g., \\(x_E(t)=e^{-a t}u(t)\\), \\(a&gt;0\\), with \\(E=\\tfrac{1}{2a}\\)).\nPower signal: \\(0&lt;P&lt;\\infty\\) and \\(E=\\infty\\) (e.g., \\(x_P(t)=\\cos(2\\pi f_0 t)\\), with \\(P=\\tfrac{1}{2}\\))."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Transformations",
    "text": "Signal Transformations\nTypes of Transformations\nSignals can undergo two types of transformations:\n\nIndependent variable transformations (affect the time or input axis).\nDependent variable transformations (affect the amplitude or output axis)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#independent-variable-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#independent-variable-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Independent Variable Transformations",
    "text": "Independent Variable Transformations\nTime Scaling\n\nDefinition: Changes the time scale of the signal. [ x(at), a &gt; 1 , &lt; a &lt; 1 ]\nExample: If ( x(t) = (t) ), then ( x(2t) ) is compressed.\n\nTime Shifting\n\nDefinition: Shifts the signal in time. [ x(t - t_0) ]\nExample: ( x(t - 2) ) shifts the signal 2 units to the right.\n\nTime Reversal\n\nDefinition: Flips the signal across the vertical axis. [ x(-t) ]\nExample: If ( x(t) = t^2 ), then ( x(-t) = t^2 ) (even signal)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#dependent-variable-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#dependent-variable-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Dependent Variable Transformations",
    "text": "Dependent Variable Transformations\nAmplitude Scaling\n\nDefinition: Multiplies the amplitude by a scalar factor. [ a x(t), a &gt; 1 , &lt; a &lt; 1 ]\nExample: If ( x(t) = (t) ), then ( 2x(t) ) doubles the amplitude.\n\nAmplitude Shifting\n\nDefinition: Adds a constant value to the amplitude. [ x(t) + c ]\nExample: If ( x(t) = (t) ), then ( x(t) + 2 ) shifts the signal up by 2 units."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#combined-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#combined-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Combined Transformations",
    "text": "Combined Transformations\nExample\nConsider: [ y(t) = 2 x(3t - 1) + 1 ] 1. Time compression: ( x(3t) ) compresses the signal. 2. Time shift: ( x(3t - 1) ) shifts it to the right by 1 unit. 3. Amplitude scaling: ( 2 x(3t - 1) ) amplifies the signal. 4. Amplitude shift: ( +1 ) shifts it upward."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#visualization-example-in-python",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#visualization-example-in-python",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Visualization Example in Python",
    "text": "Visualization Example in Python"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#periodic-functions",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#periodic-functions",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Periodic functions",
    "text": "Periodic functions\n\n\n\n\n\n\n\n\nDefinition\n\n\nAny signal that meets any of this conditions \\[x\\left(t\\right)=x\\left(t + kT\\right)\\] \\[x\\left[n\\right]=x\\left[t + kN\\right]\\]\n\n\n\n\nWhere \\(k, N\\in\\mathbb{z}\\) and \\(T\\in\\mathbb{R}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#sum-of-two-periodic-signals",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#sum-of-two-periodic-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sum of Two Periodic Signals",
    "text": "Sum of Two Periodic Signals\nIf \\(\\left( x_1(t) \\right)\\) and \\(\\left( x_2(t) \\right)\\) are periodic with periods \\(\\left( T_1 \\right)\\) and \\(\\left( T_2 \\right)\\):\n\\[\nx_1(t + T_1) = x_1(t), \\quad x_2(t + T_2) = x_2(t)\n\\]\nThe sum of both signals is:\n\\[\nx(t) = x_1(t) + x_2(t)\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#condition-for-the-periodicity-of-the-sum",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#condition-for-the-periodicity-of-the-sum",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Condition for the Periodicity of the Sum",
    "text": "Condition for the Periodicity of the Sum\nFor \\(\\left( x(t) \\right)\\) to be periodic, there must exist a common period \\(\\left( T \\right)\\) such that:\n\\[\nT = k_1 T_1 = k_2 T_2\n\\]\nwhere \\(\\left( k_1, k_2 \\right)\\) are positive integers."
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#common-period-and-least-common-multiple",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#common-period-and-least-common-multiple",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Common Period and Least Common Multiple",
    "text": "Common Period and Least Common Multiple\nThe smallest common period is the least common multiple (lcm) of \\(\\left( T_1 \\right)\\) and \\(\\left( T_2 \\right)\\):\n\\[\nT = \\operatorname{lcm}(T_1, T_2)\n\\]\nIf the ratio of the periods is a rational number:\n\\[\n\\frac{T_1}{T_2} \\in \\mathbb{Q}\n\\]\nThen, the sum \\(\\left( x_1(t) + x_2(t) \\right)\\) will be periodic.\nIf the ratio is irrational, the resulting signal will not be periodic."
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#example",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Digital Filter – Introduction",
    "text": "Digital Filter – Introduction\n\n\n\nIt is a mathematical algorithm or system that processes digital signals.\nThey enhance, suppress, or modify specific frequency components.\nThese filters are essential for removing noise, extracting relevant information, and improving signal quality."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#what-is-a-system",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#what-is-a-system",
    "title": "Sistemas y Señales Biomédicos",
    "section": "What is a system?",
    "text": "What is a system?\nA system is a rule that maps an input signal to an output signal. In continuous time and discrete time we depict and denote: \\[\nx(t)\\ \\longrightarrow\\ y(t),\\qquad x[n]\\ \\longrightarrow\\ y[n].\n\\] These are the standard input–output representations used throughout the text."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#inputoutput-operator-notation",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#inputoutput-operator-notation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Input–output operator notation",
    "text": "Input–output operator notation\nWe often write the system as an operator ( {} ): \\[\ny(t)=\\mathcal{T}\\{x(t)\\},\\qquad y[n]=\\mathcal{T}\\{x[n]\\}.\n\\] Block diagrams are used to represent systems and interconnections (series/cascade and parallel)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#overview-what-is-an-inputoutput-relation",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#overview-what-is-an-inputoutput-relation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Overview: what is an input–output relation?",
    "text": "Overview: what is an input–output relation?\nA system specifies how an input signal produces an output signal: \\[\nx(t)\\ \\longrightarrow\\ y(t),\\qquad x[n]\\ \\longrightarrow\\ y[n].\n\\] We study types of relations used in analysis and design: - Memoryless (static) mappings - Differential/difference-equation descriptions - Convolution (LTI) - Transform-domain forms (frequency, Laplace, (z)) - State–space (first-order vector form) - Time-varying vs time-invariant, linear vs nonlinear"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#memoryless-static-relations",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#memoryless-static-relations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Memoryless (static) relations",
    "text": "Memoryless (static) relations\nA memoryless or static system relates input and output at the same instant: \\[\ny(t)=F\\!\\big(x(t)\\big),\\qquad y[n]=F\\!\\big(x[n]\\big).\n\\] Examples: (y=|x|), (y=x^2), saturation and clipping nonlinearities. These are common as pointwise nonlinear stages preceding or following LTI blocks."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-differential-equations-ct",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-differential-equations-ct",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Linear constant-coefficient differential equations (CT)",
    "text": "Linear constant-coefficient differential equations (CT)\nMany continuous-time LTI systems are described by an LCCDE: \\[\n\\sum_{k=0}^{N} a_k\\,\\frac{d^{\\,k} y(t)}{dt^{\\,k}}\n\\;=\\;\n\\sum_{m=0}^{M} b_m\\,\\frac{d^{\\,m} x(t)}{dt^{\\,m}},\n\\qquad a_0\\neq 0.\n\\] Coefficients (a_k,b_m) are constants for time invariance. This form covers standard electrical/mechanical systems and filters."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-difference-equations-dt",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-difference-equations-dt",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Linear constant-coefficient difference equations (DT)",
    "text": "Linear constant-coefficient difference equations (DT)\nDiscrete-time LTI systems admit an LCCD equation: \\[\n\\sum_{k=0}^{N} a_k\\,y[n-k]\\;=\\;\\sum_{m=0}^{M} b_m\\,x[n-m],\\qquad a_0\\neq 0.\n\\] This representation includes IIR/FIR digital filters and many algorithmic recursions."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution-relations-lti",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution-relations-lti",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution relations (LTI)",
    "text": "Convolution relations (LTI)\nFor LTI systems the input–output relation is convolution with the impulse response: \\[\ny(t)=\\int_{-\\infty}^{\\infty} h(\\tau)\\,x(t-\\tau)\\,d\\tau,\\qquad\ny[n]=\\sum_{k=-\\infty}^{\\infty} h[k]\\;x[n-k].\n\\] Here (h(t)) or (h[n]) is the output to a unit impulse. Causality for LTI corresponds to (h(t)=0) for (t&lt;0) (or (h[n]=0) for (n&lt;0))."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#frequency-domain-inputoutput-fourier",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#frequency-domain-inputoutput-fourier",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Frequency-domain input–output (Fourier)",
    "text": "Frequency-domain input–output (Fourier)\nWhen Fourier transforms exist, convolution becomes multiplication: \\[\nY(\\omega)=H(\\omega)\\,X(\\omega),\\qquad\nY\\!\\big(e^{j\\omega}\\big)=H\\!\\big(e^{j\\omega}\\big)\\,X\\!\\big(e^{j\\omega}\\big).\n\\] (H) is the frequency response (CTFT/DTFT). Magnitude (|H|) scales, phase (H) shifts/warps timing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#laplace-and-z-transform-forms",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#laplace-and-z-transform-forms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laplace and (z)-transform forms",
    "text": "Laplace and (z)-transform forms\nWith Laplace and (z)-transforms (for appropriate regions of convergence): \\[\nY(s)=H(s)\\,X(s),\\qquad Y(z)=H(z)\\,X(z),\n\\] and for LCCDE/LCCD systems \\[\nH(s)=\\frac{b_0+b_1 s+\\cdots+b_M s^M}{a_0+a_1 s+\\cdots+a_N s^N},\\qquad\nH(z)=\\frac{b_0+b_1 z^{-1}+\\cdots+b_M z^{-M}}{a_0+a_1 z^{-1}+\\cdots+a_N z^{-N}}.\n\\] These rational forms support pole–zero analysis and stability checks."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#statespace-first-order-vector-description",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#statespace-first-order-vector-description",
    "title": "Sistemas y Señales Biomédicos",
    "section": "State–space (first-order vector) description",
    "text": "State–space (first-order vector) description\nAn equivalent input–output formulation uses state variables: \\[\n\\dot{\\mathbf{s}}(t)=\\mathbf{A}\\,\\mathbf{s}(t)+\\mathbf{b}\\,x(t),\\qquad\ny(t)=\\mathbf{c}^\\top\\mathbf{s}(t)+d\\,x(t).\n\\] Discrete time: \\[\n\\mathbf{s}[n+1]=\\mathbf{A}\\,\\mathbf{s}[n]+\\mathbf{b}\\,x[n],\\qquad\ny[n]=\\mathbf{c}^\\top\\mathbf{s}[n]+d\\,x[n].\n\\] This first-order form is algebraically equivalent to LCCDE/LCCD for LTI systems."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#time-varying-vs-time-invariant-relations",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#time-varying-vs-time-invariant-relations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time-varying vs time-invariant relations",
    "text": "Time-varying vs time-invariant relations\n\nTime-invariant (TI): coefficients and operators do not change with time/index; shifts commute with the system.\nTime-varying (TV): coefficients depend on (t) or (n): \\[\n\\sum_{k=0}^{N} a_k(t)\\,\\frac{d^{\\,k} y(t)}{dt^{\\,k}}\n=\\sum_{m=0}^{M} b_m(t)\\,\\frac{d^{\\,m} x(t)}{dt^{\\,m}}.\n\\] TV models arise in modulated systems and adaptive filtering."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-vs-nonlinear-relations",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-vs-nonlinear-relations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Linear vs nonlinear relations",
    "text": "Linear vs nonlinear relations\n\nLinear: superposition holds — additivity and homogeneity.\nNonlinear: violates superposition; examples include squares, rectifiers, saturators, quantizers. Nonlinear stages are often analyzed locally or via small-signal linearization around an operating point."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#stochastic-inputoutput-lti-summary",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#stochastic-inputoutput-lti-summary",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Stochastic input–output (LTI summary)",
    "text": "Stochastic input–output (LTI summary)\nFor wide-sense stationary (WSS) inputs to an LTI system: \\[\n\\mu_y=\\mu_x\\,H(0)\\ \\text{(when defined)},\\qquad\nS_{yy}(\\omega)=\\big|H(\\omega)\\big|^2\\,S_{xx}(\\omega).\n\\] This links input and output statistics through (H), supporting noise and SNR analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#interconnections-examples",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#interconnections-examples",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Interconnections (examples)",
    "text": "Interconnections (examples)\n\nSeries (cascade): output of System 1 feeds System 2.\nParallel: both systems process the same input; outputs are summed. These patterns are foundational for building complex systems from simpler ones."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-memoryless-vs.-with-memory",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-memoryless-vs.-with-memory",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Memoryless vs. with memory",
    "text": "Property: Memoryless vs. with memory\n\nMemoryless: the output at an instant depends only on the input at that same instant.\nWith memory: the output depends on past/future values (e.g., accumulators, averagers). Example: the summer/accumulator (running sum) and its inverse (first difference) illustrate systems with memory: \\[\ny[n]=\\sum_{k=-\\infty}^{n} x[k],\\qquad \\text{inverse: } y[n]=x[n]-x[n-1].\n\\] Both are causal (see next slide)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-causality-general-and-lti",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-causality-general-and-lti",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Causality (general and LTI)",
    "text": "Property: Causality (general and LTI)\nCausal: output depends only on present/past input values. For LTI systems, causality is characterized by the impulse response: \\[\n\\text{Discrete time: } h[n]=0\\ \\text{for } n&lt;0;\\qquad\n\\text{Continuous time: } h(t)=0\\ \\text{for } t&lt;0.\n\\] Under these conditions, the convolution reduces to depend only on past/present input."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-stability-bibo",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-stability-bibo",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Stability (BIBO)",
    "text": "Property: Stability (BIBO)\nBounded-Input Bounded-Output (BIBO) stability: bounded input implies bounded output. For LTI systems: \\[\n\\sum_{k=-\\infty}^{\\infty} |h[k]| &lt; \\infty \\quad \\Longleftrightarrow \\quad \\text{discrete-time LTI is stable},\n\\] \\[\n\\int_{-\\infty}^{\\infty} |h(t)|\\,dt &lt; \\infty \\quad \\Longleftrightarrow \\quad \\text{continuous-time LTI is stable}.\n\\] These are necessary and sufficient conditions."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-linearity-superposition",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-linearity-superposition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Linearity (superposition)",
    "text": "Property: Linearity (superposition)\nA system is linear if it satisfies additivity and homogeneity: for any signals (x_1,x_2) and scalar (c), \\[\n\\mathcal{T}\\{x_1+x_2\\}=\\mathcal{T}\\{x_1\\}+\\mathcal{T}\\{x_2\\},\\qquad \\mathcal{T}\\{c\\,x\\}=c\\,\\mathcal{T}\\{x\\}.\n\\] (These two conditions together are equivalent to linearity.)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-time-invariance-definition",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-time-invariance-definition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Time invariance (definition)",
    "text": "Property: Time invariance (definition)\nA system is time-invariant if a shift in the input produces an identical shift in the output: \\[\n\\mathcal{T}\\{x(t-t_0)\\}=y(t-t_0),\\ \\text{whenever}\\ y(t)=\\mathcal{T}\\{x(t)\\}.\n\\] Analogously in discrete time with shifts by integer indices. (Definition used throughout the text in system properties and LTI analysis.)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-invertibility",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-invertibility",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Invertibility",
    "text": "Property: Invertibility\nA system is invertible if distinct inputs produce distinct outputs; equivalently, there exists an inverse system that recovers the input from the output. Example pair (discrete time): the accumulator and the first-difference operator are inverses: \\[\ny[n]=\\sum_{k=-\\infty}^{n} x[k] \\quad \\Longleftrightarrow \\quad x[n]=y[n]-y[n-1].\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#additional-note-interconnections-and-lti-analysis",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#additional-note-interconnections-and-lti-analysis",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Additional note: Interconnections and LTI analysis",
    "text": "Additional note: Interconnections and LTI analysis\nFor LTI systems, interconnections admit simple algebraic descriptions via transforms: e.g., in the Laplace domain, series and parallel lead to product and sum of system functions, respectively: \\[\nH_{\\text{series}}(s)=H_1(s)H_2(s),\\qquad H_{\\text{parallel}}(s)=H_1(s)+H_2(s).\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-1",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Digital Filter – Introduction",
    "text": "Digital Filter – Introduction\n\n\n\n\n\n\n\nImportante\n\n\nThe digital filter separates the noise and the information of a discrete signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-2",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Digital Filter – Introduction",
    "text": "Digital Filter – Introduction"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-3",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Digital Filter – Introduction",
    "text": "Digital Filter – Introduction\n\n\n\n\n\n\n\n\nSuppose a discrete time system \\[ y[n] = \\sum_{k=1}^{K} a_k y[n - k] + \\sum_{m=0}^{M} b_m x[n - m]\\]\n\nK y M are the order of the filter.\nWe must know the initial condition."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#examples-of-digital-filters",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#examples-of-digital-filters",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Examples of digital filters",
    "text": "Examples of digital filters\n\n\n\n\n\n\n\n\n\nGain\n\n\n\\[y[n] = G x[n]\\]\n\n\n\n\n\n\n\n\n\n\n\nDelay of \\(n_0\\) samples\n\n\n\\[y[n] = x[n - n_0]\\]\n\n\n\n\n\n\n\n\n\n\n\nTwo points moving average\n\n\n\\[y[n] = \\frac{1}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\n\n\n\nEuler approximation of the derivative\n\n\n\\[y[n] = \\frac{x[n] - x[n - 1]}{T_s}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nAveraging over N consecutive epochs of duration L\n\n\n\\[y[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} x[n - kL]\\]\n\n\n\n\n\n\n\n\n\n\n\nTrapezoidal integration formula\n\n\n\\[y[n] = y[n - 1] + \\frac{T_s}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\n\n\n\nDigital “leaky integrator” (First-order lowpass filter)\n\n\n\\[y[n] = a y[n - 1] + x[n], \\quad 0 &lt; a &lt; 1\\]\n\n\n\n\n\n\n\n\n\n\n\nDigital resonator (Second-order system)\n\n\n\\[y[n] = a_1 y[n - 1] + a_2 y[n - 2] + b x[n], \\quad a_1^2 + 4a_2 &lt; 0\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#the-impulse-response",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#the-impulse-response",
    "title": "Sistemas y Señales Biomédicos",
    "section": "The impulse response",
    "text": "The impulse response\n\n\n\n\n\n\n\n\n\nThe impulse response, denoted as \\(ℎ[n]\\), is the output of a digital filter when the input is a unit impulse function \\(\\delta[n]\\)\nThe impulse response fully describes the system. Given \\(h[n]\\), we can determine the output for any input using convolution.\nDifferent types of filters (low-pass, high-pass, band-pass, etc.) have characteristic impulse responses."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#conditions",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#conditions",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Conditions",
    "text": "Conditions\nFor a system’s response to be fully described by its impulse response, the system must satisfy the following key conditions.\n\n\n\n\n\n\n\nLinearity\n\n\nIf the system responds to \\(x_1[n]\\) with \\(y_1[n]\\) and to \\(x_2[n]\\) with \\(y_2[n]\\), then:\n\\[y[n] = y_1[n] + y_2[n]\\]\n\n\n\n\n\n\n\n\n\n\n\nHomogeneity\n\n\nIf the input is scaled by a constant \\(c\\), the output is also scaled:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } cx[n] \\rightarrow cy[n]\\]\n\n\n\n\n\n\n\n\n\n\n\nTime Invariance\n\n\nA system must be time-invariant, meaning a time shift in the input causes the same shift in the output:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } x[n - n_0] \\rightarrow y[n - n_0]\\]\n\n\n\n\n\n\n\n\n\n\n\nCausality\n\n\nA causal system is one where the output at time \\(n\\) depends only on present and past inputs:\n\\[h[n] = 0 \\quad \\forall n &lt; 0\\]\n\n\n\n\n\n\n\n\n\n\n\nStability\n\n\nIf the impulse response does not satisfy this condition, the system may produce unbounded outputs.\n\\[\\sum_{n=-\\infty}^{\\infty} |h[n]| &lt; \\infty\\]\n\n\n\n\n\n\n\n\n\n\n\nConvolution Representation\n\n\nIf all condition met then \\[y[n] = x[n] * h[n] = \\sum_{m=-\\infty}^{\\infty} x[m] h[n - m]\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution",
    "text": "Convolution"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition",
    "text": "Introduction to data adquisition\n\n\n\nThere are two main roles in data: capture the information and encode the data in a form tha machine can process.\nData adquisition has three stages:\n\nTransduction\nSignal conditioning\nAnalog-to-digital conversion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Transduction",
    "text": "Introduction to data adquisition - Transduction\n\n\n\nTransduction is the conversion from one form of energy to another.\nThe only energy suitable for computer processing is the electrical\nTherefore signals need to be converted to analog voltages whose waveforms are ideally the same as those of the original signals.\nExist two components a captured signal: one component carries the information (signal), the other one is a probabilistic distorsion of the information(noise)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nNoise refers to any unwanted or random variations in a signal that interfere with the desired information. It is an unpredictable disturbance that can distort or obscure the actual data, making it harder to interpret or analyze.\n\n\n\n\nTypes of noise\n\nThermal Noise (Random Noise)\nElectromagnetic Interference (EMI)\nMotion Artifacts\nPhysiological Noise\nQuantization Noise"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\nModelling the noise\n\nAdditive White Gaussian Noise (AWGN): Modeled as a random process with a normal distribution.\nBand-limited Noise: Affects only specific frequency ranges and can be removed with filters.\nAdditive Noise: Adds directly to the original signal.\nMultiplicative Noise: Multiplies the original signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\nGraphsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros de la señal\nduration = 2  # Duración en segundos\nfs = 1000  # Frecuencia de muestreo en Hz\nt = np.linspace(0, duration, duration * fs, endpoint=False)  # Vector de tiempo\n\n# Señal senoidal de 10 Hz\nfreq = 10\nsine_wave = np.sin(2 * np.pi * freq * t)\n\n# Señal de ruido aleatorio con distribución normal\nnoise_normal = np.random.normal(0, 1, len(t))\n\n# Señal con ruido aleatorio de 2 a 5 Hz\nlow_freq_noise = np.sin(2 * np.pi * np.random.uniform(2, 5) * t)\nsignal_with_low_freq_noise = sine_wave + low_freq_noise\n\n# Señal con ruido aleatorio uniforme sumado\nuniform_noise = np.random.uniform(-0.5, 0.5, len(t))\nsignal_with_uniform_noise = sine_wave + uniform_noise\n\n# Señal con ruido aleatorio uniforme multiplicado\nmultiplicative_noise = np.random.uniform(0.5, 1.5, len(t))\nsignal_with_mult_noise = sine_wave * multiplicative_noise\n\n# Graficamos las señales\nfig, axes = plt.subplots(5, 1, figsize=(10, 10), sharex=True)\n\naxes[0].plot(t, sine_wave, label=\"Sine wave (10 Hz)\")\naxes[0].set_title(\"Sine Wave (10 Hz)\")\naxes[0].legend()\n\naxes[1].plot(\n    t, noise_normal, label=\"Random Noise (Normal Distribution)\", color=\"orange\"\n)\naxes[1].set_title(\"Random Noise (Normal Distribution)\")\naxes[1].legend()\n\naxes[2].plot(\n    t, signal_with_low_freq_noise, label=\"Sine + Low Freq Noise (2-5 Hz)\", color=\"green\"\n)\naxes[2].set_title(\"Sine + Low Freq Noise (2-5 Hz)\")\naxes[2].legend()\n\naxes[3].plot(t, signal_with_uniform_noise, label=\"Sine + Uniform Noise\", color=\"red\")\naxes[3].set_title(\"Sine + Uniform Noise\")\naxes[3].legend()\n\naxes[4].plot(t, signal_with_mult_noise, label=\"Sine * Uniform Noise\", color=\"purple\")\naxes[4].set_title(\"Sine * Uniform Noise\")\naxes[4].legend()\n\nplt.xlabel(\"Time [s]\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - ASP",
    "text": "Introduction to data adquisition - ASP\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAnalog signal processing (ASP) refers to the manipulation of continuous-time signals after they have been acquired from a transducer but before digital conversion. This type of processing is performed using electronic circuits that modify the signal in the analog domain to enhance its quality, extract useful information, or prepare it for further processing.\n\n\n\n\n\n\n\n\n\n\n\nCommon tasks\n\n\n\nAmplification: Increases the signal strength to match the required voltage levels. Example: ECG signals are weak (~1 mV) and need to be amplified before analysis.\nFiltering: Removes unwanted frequency components such as noise or interference.\nModulation/Demodulation: Used for communication systems where signals are modulated onto a higher-frequency carrier wave. Example: Biomedical telemetry systems use amplitude modulation (AM) or frequency modulation (FM) to transmit patient data wirelessly.\nDifferentiation & Integration: Differentiation: Highlights rapid changes in the signal. Example: Used in QRS detection for ECG signal analysis. Integration: Smooths out signals and accumulates values over time. Example: Used in electromyography (EMG) processing to estimate muscle activation.\nSignal Conditioning: Includes impedance matching, offset correction, and dynamic range adjustments. Example: Removing DC offsets in biosignals before digitization."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - analog-to-digital convertion",
    "text": "Introduction to data adquisition - analog-to-digital convertion\n\n\n\n\n\n\n\nDefinition\n\n\nAn analog-to-digital converter (ADC) is a device that converts a continuous-time signal, obtained through a transducer, into a digital signal that can be processed by a computer. This process consists of two fundamental operations, which occur simultaneously in practical implementations: sampling and quantization.\n\n\n\n\nOperations\n\nSampling involves converting the continuous-time analog signal into a discrete-time signal, where the amplitude remains unrestricted.\nQuantization then maps this continuous-amplitude signal to a finite set of discrete values, making it fully digital."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-in-dsp-purpose-and-context",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-in-dsp-purpose-and-context",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Quantization in DSP: Purpose and Context",
    "text": "Quantization in DSP: Purpose and Context\n\nQuantization maps continuous amplitudes to a finite set of levels to enable digital representation.\nIn acquisition chains: anti-alias filter → sampling → ADC quantization.\nQuantization introduces an error that behaves like noise under standard assumptions.\nBiomedical relevance: ECG, EEG, EMG, and PPG require appropriate bit depth, gain, and dynamic range to preserve diagnostically relevant features."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#uniform-quantizer-definitions",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#uniform-quantizer-definitions",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Uniform Quantizer: Definitions",
    "text": "Uniform Quantizer: Definitions\n\nInput range: \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\), bit depth \\(b\\), levels \\(L=2^b\\), step size (LSB)\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nMid-tread (round-to-nearest): \\(Q(x)=\\Delta,\\mathrm{round}!\\big(x/\\Delta\\big)\\).\nMid-rise (truncate + half-step): \\(Q(x)=\\Delta\\big(\\lfloor x/\\Delta\\rfloor+\\tfrac12\\big)\\).\nOverload/clipping outside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\): \\(\\tilde{x}=V\\_{\\max}\\) or \\(V\\_{\\min}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#decision-thresholds-and-codebook",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#decision-thresholds-and-codebook",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Decision Thresholds and Codebook",
    "text": "Decision Thresholds and Codebook\n\nDecision thresholds at \\(k\\Delta\\); reconstruction levels at:\n\n\\(k\\Delta\\) (mid-tread), or\n\\((k+\\tfrac12)\\Delta\\) (mid-rise).\n\nPractical note: choose mid-tread for rounding semantics; mid-rise for deterministic staircase without zero level."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-error-model-and-power",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-error-model-and-power",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Quantization Error: Model and Power",
    "text": "Quantization Error: Model and Power\n\nError \\(e=x-Q(x)\\). Under high-resolution assumptions (no clipping, sufficiently dense input):\n\n\\(e=x-Q(x)\\sim\\mathcal{U}\\left[-\\tfrac{\\Delta}{2},\\tfrac{\\Delta}{2}\\right]\\), \\(\\mathbb{E}\\left[e\\right]=0\\), \\(\\mathrm{Var}(e)=\\Delta^2/12\\).\n\nFor a full-scale sinusoid:\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nWith RMS usage fraction \\(\\rho\\) of full scale (FS):\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#effective-number-of-bits-enob",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#effective-number-of-bits-enob",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Effective Number of Bits (ENOB)",
    "text": "Effective Number of Bits (ENOB)\n\nFrom a measured in-band SNR (RMS, same bandwidth):\n\\[\n\\mathrm{ENOB}\\approx\\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]\nUse ENOB to compare real converters (including clock jitter, distortion) against ideal \\(b\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#input-range-analog-gain-and-clipping",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#input-range-analog-gain-and-clipping",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Input Range, Analog Gain, and Clipping",
    "text": "Input Range, Analog Gain, and Clipping\n\nAnalog gain \\(G\\) maps input to ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\Delta/G\\).\nDesign goals:\n\nAvoid overload for rare peaks; 2) Use a large fraction of FS (e.g., \\(50\\)–\\(80%\\)) to improve SNR."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#biomedical-example-ecg-acquisition",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#biomedical-example-ecg-acquisition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Biomedical Example: ECG Acquisition",
    "text": "Biomedical Example: ECG Acquisition\n\nSuppose electrode-level ECG peaks \\(\\approx \\pm 5,\\mathrm{mV}\\). Choose \\(G=200\\) so \\(\\pm 5,\\mathrm{mV}\\mapsto \\pm 1,\\mathrm{V}\\) at ADC (\\(V\\_{\\min,\\max}=\\pm 1,\\mathrm{V}\\)).\nWith \\(b=12\\):\n\n\\(\\Delta=\\dfrac{2,\\mathrm{V}}{2^{12}}\\approx 0.488,\\mathrm{mV}\\) (ADC domain).\n\\(\\Delta\\_{\\text{in}}=\\Delta/G\\approx 2.44,\\mu\\mathrm{V}\\).\nInput-referred noise RMS \\(\\sigma\\_q=\\Delta\\_{\\text{in}}/\\sqrt{12}\\approx 0.704,\\mu\\mathrm{V}\\_{\\mathrm{RMS}}\\).\n\nIf \\(\\rho\\approx 0.5\\), then \\(\\mathrm{SNR}\\approx 6.02\\cdot 12 + 1.76 - 6 \\approx 68,\\mathrm{dB}\\) → typically adequate for diagnostic ECG."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#non-uniform-quantization-and-companding-brief",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#non-uniform-quantization-and-companding-brief",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Non-Uniform Quantization and Companding (Brief)",
    "text": "Non-Uniform Quantization and Companding (Brief)\n\nFor highly non-uniform amplitude distributions, companding allocates effective resolution to small amplitudes.\n\\(\\mu\\)-law (telephony):\n\\[\ny=\\mathrm{sgn}(x)\\,\\frac{\\ln\\big(1+\\mu |x|/X_{\\max}\\big)}{\\ln(1+\\mu)},\\quad \\mu\\approx 255.\n\\]\nIn biomedicine, primary acquisition usually remains linear; companding is more relevant to low-bit-rate telemetry or storage."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#dither-when-and-why",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#dither-when-and-why",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Dither: When and Why",
    "text": "Dither: When and Why\n\nAdd small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization to decorrelate error, eliminate bias/patterning at low levels, and linearize averages.\nSlight SNR penalty but improved fidelity for low-level features (e.g., EEG baselines)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#practical-design-checklist",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#practical-design-checklist",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Practical Design Checklist",
    "text": "Practical Design Checklist\n\nChoose \\(b\\) to exceed clinical SNR requirements by \\(10\\)–\\(20,\\mathrm{dB}\\).\nSet \\(G\\) so typical peaks use \\(50\\)–\\(80%\\) FS; verify worst-case spikes do not clip.\nFull noise budget: electrode + amplifier + ADC quantization + clock jitter (for high \\(f\\)).\nValidate with calibrated sources and report ENOB over the intended bandwidth."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#python-demo-ecg-quantization-at-multiple-bit-depths",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#python-demo-ecg-quantization-at-multiple-bit-depths",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Python Demo: ECG Quantization at Multiple Bit Depths",
    "text": "Python Demo: ECG Quantization at Multiple Bit Depths\n\n# Synthetic ECG, quantization at 8/10/12 bits, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nfs = 360.0\nT = 5.0\nt = np.arange(0, T, 1/fs)\n\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\ndef ecg_template(t):\n    P = g(t, 0.20, 0.045,  0.10)\n    Q = g(t, 0.36, 0.010, -0.25)\n    R = g(t, 0.40, 0.012,  1.00)\n    S = g(t, 0.44, 0.016, -0.35)\n    Tn= g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + Tn\n\nhr = 60.0\nRR = 60.0/hr\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    ecg_mV += ecg_template(t - k*RR)\n\nwander = 0.05*np.sin(2*np.pi*0.3*t)\nnoise  = 0.02*np.random.randn(len(t))\necg_mV = ecg_mV + wander + noise\n\nG = 200.0\nVfs = 1.0\nVmin, Vmax = -Vfs, Vfs\nx_adc = (ecg_mV/1000.0)*G  # mV -&gt; V and gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)\n    return y, Delta\n\ndef snr_db(x, y):\n    e = x - y\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\nprint(\"Summary (ADC domain):\")\n\nSummary (ADC domain):\n\nfor b in bits_list:\n    print(f\"{b:2d}-bit -&gt; LSB Δ = {results[b]['Delta']*1e3:.3f} mV, Measured SNR ≈ {results[b]['snr_db']:5.1f} dB\")\n\n 8-bit -&gt; LSB Δ = 7.812 mV, Measured SNR ≈  24.1 dB\n10-bit -&gt; LSB Δ = 1.953 mV, Measured SNR ≈  36.0 dB\n12-bit -&gt; LSB Δ = 0.488 mV, Measured SNR ≈  48.1 dB\n\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Δ_in = {Delta_in*1e6:.3f} µV, σ_q ≈ {sigma_q_in*1e6:.3f} µV RMS\")\n\n\nInput-referred (12-bit): Δ_in = 2.441 µV, σ_q ≈ 0.705 µV RMS\n\n# Plot 1: original vs quantized (10-bit)\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n# Plot 2: quantization error histogram (8-bit)\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\nTo explain the analog-to-digital conversion process, we will assume that the input signal is a cosine wave with frequency \\(F\\), angular frequency \\(\\Omega\\) and amplitude \\(a\\).\n\\[x\\left(t\\right) = a \\cos\\left(\\Omega t + \\phi\\right) = a \\cos\\left(2\\pi F t + \\phi\\right)\\]\nObtaining\n\\[x\\left[n\\right] = a \\cos\\left(\\omega n + \\phi\\right) = a \\cos\\left(2\\pi f n + \\phi\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\n\n\n\n\n\n\n\nWhat?\n\n\nMathematically, the sampling process is:\n\\[x[n] = x(nT_s), \\quad -\\infty &lt; n &lt; \\infty\\]\n\n\n\n\nReplacing in previous equations, we have the expression:\n\\[x[n] = x(nT_s) = a \\cos\\left( 2\\pi F n T_s + \\phi \\right) = a \\cos\\left( 2\\pi n \\frac{F}{F_s} + \\phi \\right)\n\\]\nWhere:\n\\[\\omega = \\Omega T_s, \\quad f = \\frac{F}{F_s}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sample and quantization of an ECG signal",
    "text": "Sample and quantization of an ECG signal\n\nTaskGraphCode\n\n\n\nGenerate a synthetic ECG-like signal.\nSample it at different rates.\nApply quantization with different bit depths.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import chirp\n\n# Generate a synthetic ECG-like signal (chirp function as approximation)\nfs_original = 10000  # High sampling rate (Hz) - \"continuous\" signal\nt = np.linspace(0, 1, fs_original, endpoint=False)  # 1-second signal\nsignal = np.sin(2 * np.pi * 1.7 * (t**2))  # Simulated chirp (similar to ECG waves)\n\n# Downsample (Sampling Process)\nfs_sampled = 200  # Sampling frequency in Hz (e.g., ECG sampled at 200 Hz)\nt_sampled = np.arange(0, 1, 1/fs_sampled)\nsignal_sampled = np.sin(2 * np.pi * 1.7 * (t_sampled**2))\n\n# Quantization (8-bit and 4-bit)\ndef quantize(signal, bits):\n    levels = 2**bits\n    min_val, max_val = signal.min(), signal.max()\n    step = (max_val - min_val) / levels\n    quantized_signal = np.round((signal - min_val) / step) * step + min_val\n    return quantized_signal\n\nsignal_quantized_8bit = quantize(signal_sampled, 8)\nsignal_quantized_4bit = quantize(signal_sampled, 4)\n\n# Plot Results\nplt.figure(figsize=(12, 6))\n\n# Original vs Sampled Signal\nplt.subplot(2, 1, 1)\nplt.plot(t, signal, 'k', alpha=0.3, label='Original Signal (High Resolution)')\nplt.plot(t_sampled, signal_sampled, 'ro-', label=f'Sampled Signal ({fs_sampled} Hz)')\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Sampling Process\")\n\n# Quantized Signals\nplt.subplot(2, 1, 2)\nplt.plot(t_sampled, signal_sampled, 'bo-', alpha=0.5, label=\"Original Sampled\")\nplt.plot(t_sampled, signal_quantized_8bit, 'go-', label=\"Quantized 8-bit\")\nplt.plot(t_sampled, signal_quantized_4bit, 'ro-', label=\"Quantized 4-bit\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Quantization Effect\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\n\nBio - That came from a biological being\nSignal - A signal is a function that conveys information about a physical phenomenon.\nBiosignals - The search for information from living systems to know its health state"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\nThe codification of biosignals into variations: * Electrical * Mechanical * Chemical * Thermal"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1791: Luigi Galvani discovers electrical signals in living tissues (frog legs)\n1830s: Carlo Matteucci studies electrical signals in the heart\n1887: Willem Einthoven invents the first electrocardiograph (ECG)\n1900s: James Mackenzie develops the first clinical ECG machine"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1920s: Electroencephalography (EEG) is developed by Hans Berger\n1930s: Electromyography (EMG) is developed by John Humphrey and others\n1940s: Development of the first commercial ECG machines\n1950s: Signal processing techniques are applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1960s: Digital signal processing and computer analysis of biomedical signals emerge\n1970s: Biomedical signal processing becomes a recognized field\n1980s: Development of Holter monitoring (24-hour ECG)\n1990s: Advances in signal processing and machine learning applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n2000s: Development of wearable devices and mobile health (mHealth) technologies\n2010s: Emergence of big data analytics and cloud computing in biomedical signal processing\n2020s: Integration of artificial intelligence (AI) and machine learning (ML) in biomedical signal processing"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1895: Wilhelm Roentgen discovers X-rays, leading to medical imaging\n1900s: X-ray technology improves with development of modern X-ray tubes\n1913: Albert Salomon develops mammography\n1920s: Ultrasound technology is developed by Karl Dussik and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1930s: Nuclear medicine emerges with development of radioactive tracers\n1950s: Computed Tomography (CT) scans are developed by Godfrey Hounsfield and Allan McLeod Cormack\n1960s: Development of medical ultrasound imaging\n1970s: Magnetic Resonance Imaging (MRI) is developed by Richard Ernst and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1980s: Digital image processing and analysis techniques are applied to biomedical images\n1990s: Advances in MRI and CT scan technology, including 3D imaging\n2000s: Development of functional MRI (fMRI), diffusion tensor imaging (DTI), and other advanced MRI techniques\n2010s: Emergence of artificial intelligence (AI) and machine learning in medical imaging"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nAdditional Milestones:\n\n1950s: Development of medical electronics and instrumentation\n1960s: First medical imaging computers are developed\n1970s: Development of digital image processing and analysis software\n1980s: Emergence of medical imaging informatics and PACS (Picture Archiving and Communication Systems)\n1990s: Development of telemedicine and teleradiology\n2000s: Emergence of electronic health records (EHRs) and health information exchanges (HIEs)\n2010s: Development of personalized medicine and precision health initiatives"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\n\n\n\n\n\n\nDefinition\n\n\nAn experiment is a physical procedure that produces some kind of result.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAn event is a set of experiment’s possible results.\n\n\n\n\n\n\n\n\n\n\n\nConsejo\n\n\nA sample space is the set of ALL possibles results of an experiment."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\nGraphCodeSample SpaceResultDataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata = np.genfromtxt(\"../../data/mitbih_train.csv\", delimiter=\",\")\necg1 = data[1, :-1]\ntime = np.array(range(0,len(ecg1)))/125\nfig = plt.figure()\nplt.plot(time, ecg1)\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Normalized ECG\")\n\n\n\n\nprint(\"Maximun Value: \"+ str(ecg1.max()))\n\nMaximun Value: 1.0\n\nprint(\"Minimun Value: \"+ str(ecg1.min()))\n\nMinimun Value: 0.0\n\n\n\n\n\nprint(ecg1[np.random.choice(ecg1.shape[0], 1, replace=False)])\n\n[0.]\n\n\n\n\nName: ECG Heartbeat Categorization Dataset.\nURL: https://www.kaggle.com/datasets/shayanfazeli/heartbeat?resource=download"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Probability Axioms",
    "text": "Probability Axioms\nFor the given events A and B that are in a sample space S:\n\n\n\n\n\n\n\nAxioms\n\n\n\n\\(0 \\leq P_r \\left(A\\right) \\leq 1\\)\n\\(P_r\\left(S\\right) = 1\\)\nIf \\(A \\cap B = \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right)\\)\nIf \\(A \\cap B \\neq \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right) - P_r\\left(A \\cap B \\right)\\)\n\\(P_r\\left(\\bar{A}\\right) = 1-P_r \\left(A\\right)\\)\nIf \\(A\\subset B\\) then \\(P_r \\left(A\\right)\\leq P_r \\left(B\\right)\\)\n\\(P_r \\left(A|B\\right)=\\frac{P_r \\left(A\\cap B\\right)}{P_r \\left(B\\right)}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable\n\n\n\n\n\n\n\nDefinition\n\n\nA random variable is a real valued function of the elements of a sample space, S . Given an experiment, E , with sample space, S, the random variable maps each possible outcome of E.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nThe probability mass function (PMF), \\(P_X\\left(x\\right)\\), of a random variable, X, is a function that assigns a probability to each possible value of the random variable, X."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nConditions\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sum_{\\chi \\in X}P_X\\left(\\chi \\right) = 1\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\int_{-\\infty}^{\\infty}P_X\\left(\\chi \\right)d\\chi = 1\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nExpected Values\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\mu = \\sum_{\\chi \\in X}\\chi P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\mu=\\int_{-\\infty}^{\\infty}\\chi P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nVariance\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sigma^2 = \\sum_{\\chi \\in X}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\sigma^2 = \\int_{-\\infty}^{\\infty}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "PDF Estimation",
    "text": "PDF Estimation\n\nGraphCodeExp. ValueVariance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncounts01, bin_edges01 = np.histogram(ecg1, bins=10, density=True)\ncounts02, bin_edges02 = np.histogram(ecg1, bins=50, density=True)\ncounts03, bin_edges03 = np.histogram(ecg1, bins=100, density=True)\nfig01=plt.figure()\nplt.plot(bin_edges01[1:], counts01/sum(counts01), label=\"Estimation with 10 bins\")\nplt.plot(bin_edges02[1:], counts02/sum(counts02), label=\"Estimation with 50 bins\")\nplt.plot(bin_edges03[1:], counts03/sum(counts03), label=\"Estimation with 100 bins\")\nplt.legend()\nplt.grid()\nplt.xlabel(\"Normalised ECG Value\")\nplt.ylabel(\"Estimated PDF Value\")\n\n\n\n\n\n0.09001020772910533\n\n\n\n\n\n\n0.02551116143316462"
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#importance-of-frequency-response-filters",
    "href": "presentaciones/PSIM/prueba.html#importance-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Importance of Frequency-Response Filters",
    "text": "Importance of Frequency-Response Filters\n\nFrequency-response filters are critical for enhancing specific features or reducing noise in images.\nWidely used in MRI, CT, and ultrasound imaging."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#what-is-a-frequency-response-filter",
    "href": "presentaciones/PSIM/prueba.html#what-is-a-frequency-response-filter",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is a Frequency-Response Filter?",
    "text": "What is a Frequency-Response Filter?\n\nA frequency-response filter modifies the frequency components of a signal.\nApplied in image processing to control which frequencies (details) pass or are suppressed."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#types-of-frequency-response-filters",
    "href": "presentaciones/PSIM/prueba.html#types-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Types of Frequency-Response Filters",
    "text": "Types of Frequency-Response Filters\n\nLow-pass filters: Allow low frequencies, suppress high frequencies (smoothes image).\nHigh-pass filters: Allow high frequencies, suppress low frequencies (sharpens image).\nBand-pass filters: Allow frequencies in a certain range."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#spatial-vs.-frequency-domain",
    "href": "presentaciones/PSIM/prueba.html#spatial-vs.-frequency-domain",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Spatial vs. Frequency Domain",
    "text": "Spatial vs. Frequency Domain\n\nSpatial domain: Operations on pixel values directly.\nFrequency domain: Operations on the image’s frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#fourier-transform",
    "href": "presentaciones/PSIM/prueba.html#fourier-transform",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Fourier Transform",
    "text": "Fourier Transform\n\nConverts an image from the spatial domain to the frequency domain.\nFormula: \\[F\\left(u,v\\right) = \\sum\\sum f\\left(x,y\\right) e^{-j2\\pi(\\frac{ux}{M} + \\frac{vy}{N})}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#low-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#low-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low-Pass Filters",
    "text": "Low-Pass Filters\n\nRemoves high-frequency components (e.g., noise, sharp edges).\nExample: Gaussian filter, Butterworth filter."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#high-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#high-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "High-Pass Filters",
    "text": "High-Pass Filters\n\nEnhances edges and high-frequency details.\nExample: Laplacian filter."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#band-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#band-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Band-Pass Filters",
    "text": "Band-Pass Filters\n\nAllows frequencies within a specific range.\nUseful for isolating specific image features."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#noise-reduction-in-mri",
    "href": "presentaciones/PSIM/prueba.html#noise-reduction-in-mri",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Noise Reduction in MRI",
    "text": "Noise Reduction in MRI\n\nLow-pass filters reduce noise and artifacts in MRI scans.\nSmoothes the image without losing crucial details."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#edge-enhancement-in-ultrasound-images",
    "href": "presentaciones/PSIM/prueba.html#edge-enhancement-in-ultrasound-images",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge Enhancement in Ultrasound Images",
    "text": "Edge Enhancement in Ultrasound Images\n\nHigh-pass filters help in detecting tissue boundaries by enhancing edges.\nImproves clarity of anatomical structures."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#feature-extraction-in-ct-scans",
    "href": "presentaciones/PSIM/prueba.html#feature-extraction-in-ct-scans",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Feature Extraction in CT Scans",
    "text": "Feature Extraction in CT Scans\n\nFilters can help in extracting features like tumors or vessels.\nBand-pass filters isolate structures of interest at specific frequency ranges."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "href": "presentaciones/PSIM/prueba.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process",
    "text": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process\n\nLoad MRI image.\nApply Fourier Transform to move the image into the frequency domain.\nDesign and apply a low-pass filter.\nPerform Inverse Fourier Transform to return to the spatial domain.\nVisualize the result."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#summary",
    "href": "presentaciones/PSIM/prueba.html#summary",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Summary",
    "text": "Summary\n\nFrequency-response filters play a crucial role in biomedical image processing.\nHelp enhance key features and suppress unwanted noise."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#future-trends",
    "href": "presentaciones/PSIM/prueba.html#future-trends",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Future Trends",
    "text": "Future Trends\n\nDeep learning integration with traditional filters.\nDevelopment of adaptive filters for real-time processing."
  },
  {
    "objectID": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "href": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sources of data",
    "text": "Sources of data\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#what-is-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#what-is-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is Thresholding?",
    "text": "What is Thresholding?\n\nDefinition: A technique to separate objects from the background in images.\nConcept: Converting a grayscale image into a binary image.\nImportance: Simplification for further analysis (e.g., edge detection, segmentation)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#global-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#global-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Global Thresholding",
    "text": "Global Thresholding\n\nExplanation of Global Thresholding.\nExample of a fixed threshold ( T ):\n\nIf ( I(x, y) &gt; T ), the pixel becomes white (1), otherwise black (0).\n\nLimitations: Sensitivity to uneven lighting."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#adaptive-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#adaptive-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Adaptive Thresholding",
    "text": "Adaptive Thresholding\n\nDefinition of Adaptive Thresholding.\nInstead of a global threshold, the threshold is calculated for different regions of the image.\nAdvantages: Effective in images with varying illumination.\nAlgorithm: Example of an adaptive method based on the local mean of neighboring pixels."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#otsus-algorithm",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#otsus-algorithm",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Otsu’s Algorithm",
    "text": "Otsu’s Algorithm\n\nExplanation of Otsu’s Algorithm.\n\nAutomatic global thresholding that minimizes the within-class variance.\n\nSteps of the algorithm:\n\nCompute image histograms.\nEvaluate the between-class variance function for every possible threshold.\nSelect the threshold that minimizes the within-class variance.\n\nAdvantages: Automatic and effective in bimodal images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#justification-for-using-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#justification-for-using-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Justification for Using Thresholding",
    "text": "Justification for Using Thresholding\n\nWhen thresholding is useful:\n\nImages with a clear contrast between the object and the background.\nSituations requiring quick segmentation.\n\nExample applications:\n\nText detection, object recognition, medical images (e.g., X-rays).\n\nLimitations: Less effective in noisy or low-quality images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#comparison-of-thresholding-algorithms",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#comparison-of-thresholding-algorithms",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Comparison of Thresholding Algorithms",
    "text": "Comparison of Thresholding Algorithms\n\n\n\n\n\n\n\n\n\n\nMethod\nPrecision\nProcessing Speed\nEase of Implementation\nTypical Applications\n\n\n\n\nGlobal Threshold\nMedium\nFast\nSimple\nHigh-contrast images\n\n\nAdaptive Threshold\nHigh\nModerate\nModerate\nUnevenly lit images\n\n\nOtsu’s Algorithm\nHigh\nModerate\nModerate\nBimodal distributions"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nShow examples of original images and the result after applying:\n\nGlobal Thresholding.\nAdaptive Thresholding.\nOtsu’s Algorithm.\n\nVisualizations highlighting the differences."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples-1",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nResultsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.imshow(image_circle, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nplt.imshow(image_gradient, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nplt.imshow(noisy_circle, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh1 = cv2.threshold(image_circle, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh1, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh2 = cv2.threshold(image_gradient, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh3 = cv2.threshold(noisy_circle, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh1 = cv2.adaptiveThreshold(image_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh1, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh2 = cv2.adaptiveThreshold(image_gradient, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh3 = cv2.adaptiveThreshold(noisy_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, otsu_thresh1 = cv2.threshold(image_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh1, cmap=\"gray\")\nplt.axis(\"off\");\nplt.show()\n\n_, otsu_thresh2 = cv2.threshold(image_gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, otsu_thresh3 = cv2.threshold(noisy_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#conclusion-and-questions",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#conclusion-and-questions",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Conclusion and Questions",
    "text": "Conclusion and Questions\n\nSummary of key points:\n\nThresholding as a simple yet powerful technique.\nImportance of choosing the right algorithm depending on the context.\nOtsu’s algorithm as an effective solution for bimodal images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-morphological-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction to Morphological Operations",
    "text": "Introduction to Morphological Operations\n\nDefinition: Morphological operations apply a structuring element to an image to alter its structure.\nFocus: Primarily used for binary images.\nKey applications: Noise removal, object extraction, shape analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#structuring-element",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#structuring-element",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Structuring Element",
    "text": "Structuring Element\n\nA small matrix used to probe and interact with a given image.\nCommon shapes: Rectangular, circular, elliptical.\nExample: A 3x3 square structuring element.\n\n\\[\\begin{bmatrix}\n  1 & 1 & 1 \\\\\n  1 & 1 & 1 \\\\\n  1 & 1 & 1 \\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#common-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#common-morphological-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Common Morphological Operations",
    "text": "Common Morphological Operations\n\nErosion:\n\nRemoves pixels on object boundaries.\nShrinks the size of objects in the image.\nUsed to eliminate small noise or detach connected objects.\n\nDilation:\n\nAdds pixels to object boundaries.\nEnlarges the object in an image.\nHelps fill small holes and gaps within objects.\n\nOpening:\n\nErosion followed by dilation.\nUsed to remove small objects (noise) while maintaining the shape of larger objects.\n\nClosing:\n\nDilation followed by erosion.\nFills small holes and gaps in an object’s boundaries.\n\nTop-Hat Transformation:\n\nThe difference between the original image and its opening.\nUsed to highlight bright regions on a dark background.\nDetecting small, bright objects or details in an unevenly illuminated image.\n\nBlack-Hat Transformation:\n\nThe difference between the closing of an image and the original image.\nUsed to highlight dark regions on a bright background.\nEmphasizing dark objects or shadows in an image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#example-of-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#example-of-morphological-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Example of Morphological Operations",
    "text": "Example of Morphological Operations"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-frequency-response",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-frequency-response",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction to Frequency Response",
    "text": "Introduction to Frequency Response\n\nWhat is Frequency Response?\n\nThe frequency response of an image shows how spatial details in the image are distributed across different frequencies.\nIn image processing, this is typically analyzed using the Fourier Transform.\n\nWhy Frequency Analysis?\n\nUseful for identifying patterns, noise, and image structures not easily observed in the spatial domain."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-fourier-transform",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-fourier-transform",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The Fourier Transform",
    "text": "The Fourier Transform\n\nFourier Transform (FT):\n\nConverts an image from the spatial domain (pixels) to the frequency domain (sinusoids).\nEach point in the frequency domain represents a specific frequency in the image.\n\nMathematical Basis:\n\n\\(F(u,v) = \\sum_x \\sum_y f(x,y) e^{-j 2 \\pi (ux/M + vy/N)}\\)\nWhere \\(F(u,v)\\) is the frequency representation of the image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-and-high-frequencies",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-and-high-frequencies",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low and High Frequencies",
    "text": "Low and High Frequencies\n\nLow Frequencies:\n\nRepresent slow variations or large structures in the image (e.g., background or smooth gradients).\n\nHigh Frequencies:\n\nRepresent rapid variations or fine details (e.g., edges, noise).\n\nKey Insight: Most of the important structural information in an image is captured in the low-frequency range."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-domain-representation",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-domain-representation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Frequency Domain Representation",
    "text": "Frequency Domain Representation\n\nThe Fourier Transform of an image produces a frequency spectrum.\nDC Component (center of the spectrum): Represents the average intensity of the image.\nHigher frequencies: Spread out from the center and capture finer details.\nLogarithmic scale: Often used to visualize the frequency spectrum due to the wide range of values."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-2d-discrete-fourier-transform-dft",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-2d-discrete-fourier-transform-dft",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The 2D Discrete Fourier Transform (DFT)",
    "text": "The 2D Discrete Fourier Transform (DFT)\n\nThe 2D DFT is used to convert a 2D image into its frequency components:\n\nInput: A 2D grayscale image.\nOutput: A complex matrix representing amplitude and phase for each frequency.\n\nInverse DFT: Converts the frequency representation back to the spatial domain."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-pass-and-high-pass-filtering",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-pass-and-high-pass-filtering",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low-Pass and High-Pass Filtering",
    "text": "Low-Pass and High-Pass Filtering\n\nLow-Pass Filter (LPF):\n\nAllows low frequencies to pass, attenuates high frequencies.\nUsed to blur images, removing high-frequency details like noise and edges.\n\nHigh-Pass Filter (HPF):\n\nAllows high frequencies to pass, attenuates low frequencies.\nUsed to sharpen images by enhancing edges and fine details."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#band-pass-filtering",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#band-pass-filtering",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Band-Pass Filtering",
    "text": "Band-Pass Filtering\n\nBand-Pass Filter:\n\nAllows frequencies within a certain range (band) to pass.\nUseful for selectively enhancing specific frequency components while filtering others.\n\nApplications: Used in image enhancement and texture analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-response-visualization",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-response-visualization",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Frequency Response Visualization",
    "text": "Frequency Response Visualization\n\nMagnitude Spectrum:\n\nRepresents the amplitude of each frequency component.\nTypically visualized using the logarithmic scale to manage the large range of values.\n\nPhase Spectrum:\n\nRepresents the phase of each frequency component.\nLess important for human perception but crucial for reconstructing the image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#applications-of-frequency-domain-processing",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#applications-of-frequency-domain-processing",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Applications of Frequency Domain Processing",
    "text": "Applications of Frequency Domain Processing\n\nNoise Removal: Low-pass filters can smooth out high-frequency noise.\nEdge Detection: High-pass filters enhance edges and sharp transitions.\nImage Compression: Frequency domain analysis helps identify redundant information.\nPattern Recognition: Useful for detecting repetitive patterns like textures."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\nData acquisition is to capture the signal and encode in a form suitable for computer processing.\nSignal conditioning is to remove noise and artifacts from the signal.\nFeature extraction is to extract relevant information from the signal.\nHypothesis testing is to test the hypothesis based on the extracted features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal condtioning",
    "text": "Signal condtioning\n\n\n\n\n\n\n\nBase Information\n\n\n\nA 12-lead electrocardiogram for arrhythmia study - Article\nA 12-lead electrocardiogram for arrhythmia study - Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning\n\ndata  = sio.loadmat(path_ecg+\"/JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\nprint(data.keys())\n\ndict_keys(['val'])\n\nprint(type(data['val']))\n\n&lt;class 'numpy.ndarray'&gt;\n\nprint(data['val'].shape)\n\n(12, 5000)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Edge AI",
    "text": "Edge AI\n\n\n\n\n\n\n\nDefinition\n\n\nEdge AI Is the combination of EDGE devices and Artificial Intelligence Algorithms\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nThe accelerometer-based wristband sensor."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI\n\nTaken from “Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing” (Zhou et. al., Proceedings of the IEEE, 2019)"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI\n\n\n\n\n\n\n\nEmbedded ML\n\n\n\nEmbedded ML is the art and science of running machine learning models on embedded systems.\nEmbedded ML, we’re usually refers to machine learning inference.\nThe training part usually still takes place on a conventional computer.\nHigh requirements of ROM(Model Storing), RAM(Storing intermediate results), computer capabilities(computational intensive tasks).\nEmbedded machine learning is often deployed alongside digital signal processing algorithms\nTiny machine learning, or TinyML, is the concept of doing this on the most constrained embedded hardware available."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-3",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "BLERP",
    "text": "BLERP\n\n\n\n\n\n\n\n\n\nBandwith\n\n\nIt’s related to the quantity of information you could send via some kind of connection. More bandwith it’s needed to send more data. Example: Imagine a smart sensor that monitors the vibration of an magnetic resonator to determine if it is operating correctly. It might use a simple thresholding algorithm to understand when the machine is vibrating too much, or not enough, and then communicate this information via a low bandwidth radio connection.\n\n\n\n\n\n\n\n\n\n\n\nLatency\n\n\nIt’s related to the time you must wait for the reponse of the sensor. Example: Edge AI solves this problem by removing the round-trip time altogether. A great example of this is a self-driving car. The car’s AI systems run on onboard computers. This allows it to react nearly instantly to changing conditions, like the driver in front slamming on their brakes.\n\n\n\n\n\n\n\n\n\n\n\n\nEconomy\n\n\nConnectivity costs a lot of money. By processing data on-device, edge AI systems reduce or avoid the costs of transmitting data over a network and processing it in the cloud. Example: Edge AI enables healthcare providers to monitor patients in real time without sending data to the cloud for processing. For example, wearable devices with built-in AI algorithms can analyze physiological signals such as heart rate, oxygen levels, and ECG data locally. This reduces the reliance on cloud services for data transmission and processing.\n\n\n\n\n\n\n\n\n\n\n\nReliability\n\n\nSystems controlled by on-device AI are potentially more reliable than those that depend on a connection to the cloud. When you add wireless connectivity to a device, you’re adding a vast, overwhelmingly complex web of dependencies, from link-layer communications technologies to the internet servers that may run your application. Example: Traditional Cloud-Based Systems: Data collected by wearable devices must be transmitted to a cloud server, analyzed, and then results are sent back to caregivers or emergency responders. This can introduce delays due to network latency or connectivity issues. Edge AI Systems: Processes the sensor data locally in real time, enabling instant detection of falls or other anomalies.Improvement: Reduces detection and response time from minutes to milliseconds, ensuring immediate action during emergencies.\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy\n\n\nEdge AI provides an alternative. Rather than streaming live video and audio to a remote server, a security camera could use some onboard intelligence to identify that an intruder is present when the owners are out at work. It could then alert the owners in an appropriate way. When data is processed on an embedded system and is never transmitted to the cloud, user privacy is protected and there is less chance of abuse."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Linux",
    "text": "What is Linux\n\nDefinition: Linux is a free, open-source operating system (OS) based on Unix, created by Linus Torvalds in 1991.\nKey Features:\n\nOpen-source: Anyone can view, modify, and distribute the source code.\nFree to use: No licensing fees.\nMulti-user and multitasking.\n\nStructure: Comprises a kernel (core of the OS) and various utilities."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\nControls the hardware.\nTypes of linux kernel\n\nMonolithic kernel: All the concurrent processes are executed simultaneously in the kernel itself. All the processes share same memory recourses.\nMicro kernel: user services and kernel services are executed in separate address spaces. User services are kept in user address space and kernel services are kept in kernel address space.\nHybrid kernel: this kernel has the monolithic speed and the stability of the micro.\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nShell\n\n\nThe shell serves as an interface to the kernel, acting as a bridge between the user and the system’s core operations. It hides the internal workings of the kernel, allowing users to perform tasks without needing to understand the underlying processes. Users simply enter a command, and the shell leverages the kernel’s functions to execute the specified task.\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "href": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Why is Linux Popular?",
    "text": "Why is Linux Popular?\n\nFlexibility: Runs on a wide range of devices (PCs, servers, smartphones, embedded systems).\nSecurity: Highly secure and less vulnerable to malware.\nCommunity Support: Strong open-source community for development and troubleshooting.\nCustomization: Highly configurable; users can tailor it to specific needs.\nPerformance: Efficient resource utilization, ideal for servers and low-end devices."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Linux vs Other Operating Systems",
    "text": "Linux vs Other Operating Systems\n\n\n\n\n\n\n\n\n\nFeature\nLinux\nWindows\nmacOS\n\n\n\n\nCost\nFree\nPaid\nPaid\n\n\nSource Code\nOpen-source\nProprietary\nProprietary\n\n\nSecurity\nHighly secure\nVulnerable to malware\nSecure\n\n\nCustomization\nHigh\nLow\nLow\n\n\nUsage\nServers, DevOps, IoT\nDesktop, Gaming\nCreative industries"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Linux Distributions",
    "text": "Linux Distributions\n\nWhat are Distributions (Distros)?\nVariants of Linux tailored for specific purposes.\nPopular Distros:\n\nUbuntu: User-friendly, great for beginners.\nDebian: Stable and widely supported.\nFedora: Cutting-edge technologies.\nCentOS/Red Hat: Enterprise-level stability.\nKali Linux: Security and penetration testing."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Applications of Linux",
    "text": "Applications of Linux\n\nEveryday Use: Desktops and laptops (e.g., Ubuntu, Mint).\nServers: Powers most web servers, databases, and cloud infrastructure.\nEmbedded Systems: Used in IoT devices, routers, and automotive systems.\nSupercomputers: Runs on 100% of the top 500 supercomputers.\nProgramming & Development: Preferred OS for software developers."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nMachine Learning (ML) is a data-driven approach to building predictive models.\nIt is used in various applications such as healthcare, finance, and automation.\nIt is based on identifying patterns in data to make predictions or decisions."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nML enables systems to learn from experience without being explicitly programmed.\nKey application areas include image recognition, natural language processing, and autonomous systems."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Supervised Learning",
    "text": "Types of Machine Learning – Supervised Learning\nSupervised Learning: - Uses labeled data to train models. - Example: Spam detection in emails (spam vs. non-spam). - Common algorithms: Linear Regression, Decision Trees, Support Vector Machines (SVM), Neural Networks."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Unsupervised Learnin",
    "text": "Types of Machine Learning – Unsupervised Learnin\nUnsupervised Learning: - Finds patterns in unlabeled data. - Example: Customer segmentation in marketing. - Common algorithms: K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Reinforcement Learning",
    "text": "Types of Machine Learning – Reinforcement Learning\nReinforcement Learning: - Optimizes decision-making through rewards. - Example: Training an AI to play a game like Chess or Go. - Key components: Agent, Environment, Reward Signal."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nData:\n\nThe quality and quantity of data are fundamental.\nData preprocessing (cleaning, normalization, feature extraction) is crucial.\n\nModel:\n\nA mathematical representation of the problem.\nChosen based on the problem type (classification, regression, clustering)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nError function:\n\nEvaluates the difference between prediction and actual value.\nExample: Mean Squared Error (MSE) for regression, Cross-Entropy Loss for classification.\n\nOptimization:\n\nAlgorithms that adjust the model parameters to minimize error.\nCommon optimization techniques: Gradient Descent, Adam Optimizer."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nInductive Bias:\n\nPrior assumptions that the model uses to generalize.\nExample: Linear models assume data relationships are linear.\n\nSample Bias:\n\nDifferences between training data and real-world data.\nExample: A face recognition system trained on a specific demographic may perform poorly on others."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nBias-Variance Tradeoff:\n\nHigh Bias (Underfitting): The model is too simple, failing to capture patterns.\nHigh Variance (Overfitting): The model memorizes training data but fails on new data."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Example of Bias and Variance",
    "text": "Example of Bias and Variance"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n1. Linear Regression (Supervised Learning - Regression)\n\nPredicts a continuous value based on input features.\nEquation: ( y = mx + b )\nExample: Predicting house prices based on square footage.\n\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nTrue\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\nSlope: [0.6]\n\n\nIntercept: 2.2"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n2. Decision Trees (Supervised Learning - Classification & Regression)\n\nSplits data into decision nodes to make predictions.\nExample: Diagnosing a disease based on symptoms.\n\n\n\nDecisionTreeClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFitted\n        \n            \n                Parameters\n                \n\n\n\n\ncriterion \n'gini'\n\n\n\nsplitter \n'best'\n\n\n\nmax_depth \nNone\n\n\n\nmin_samples_split \n2\n\n\n\nmin_samples_leaf \n1\n\n\n\nmin_weight_fraction_leaf \n0.0\n\n\n\nmax_features \nNone\n\n\n\nrandom_state \nNone\n\n\n\nmax_leaf_nodes \nNone\n\n\n\nmin_impurity_decrease \n0.0\n\n\n\nclass_weight \nNone\n\n\n\nccp_alpha \n0.0\n\n\n\nmonotonic_cst \nNone\n\n\n\n\n            \n        \n    \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n3. K-Means Clustering (Unsupervised Learning)\n\nGroups similar data points together.\nExample: Customer segmentation in marketing.\n\n\n\nCluster Centers: [[10.  2.]\n [ 1.  2.]]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n4. Support Vector Machines (SVM) (Supervised Learning - Classification)\n\nFinds a hyperplane that best separates different classes.\nExample: Classifying tumors as benign or malignant.\n\n\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVC?Documentation for SVCiFitted\n        \n            \n                Parameters\n                \n\n\n\n\nC \n1.0\n\n\n\nkernel \n'rbf'\n\n\n\ndegree \n3\n\n\n\ngamma \n'scale'\n\n\n\ncoef0 \n0.0\n\n\n\nshrinking \nTrue\n\n\n\nprobability \nFalse\n\n\n\ntol \n0.001\n\n\n\ncache_size \n200\n\n\n\nclass_weight \nNone\n\n\n\nverbose \nFalse\n\n\n\nmax_iter \n-1\n\n\n\ndecision_function_shape \n'ovr'\n\n\n\nbreak_ties \nFalse\n\n\n\nrandom_state \nNone\n\n\n\n\n            \n        \n    \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n5. Reinforcement Learning Example\n\nUses rewards and penalties to train an agent to make optimal decisions.\nExample: A robot learning to navigate a maze.\n\n\n\nTrained Q-Table:\n [[0.2466039  0.30491591 0.43210016 0.45426578 0.67886292]\n [0.31971819 0.43955893 0.65332032 1.00092929 0.91142778]\n [0.3930344  0.52962554 0.99451373 1.66961098 1.9197123 ]\n [0.55984869 0.78313723 1.77069055 2.80966222 5.20428534]\n [0.67139363 1.13164264 2.20812197 4.9621132  0.        ]]"
  },
  {
    "objectID": "tutoriales/TutorialPython.html",
    "href": "tutoriales/TutorialPython.html",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Tomado del libro Ciencia de Datos para Ciencias Naturales\nSi no tiene experiencia con el lenguaje Markdown utilice esta guía para enriquecer sus celdas de texto.\n\n\n\nPlataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código\n\n\n\n\n\nNo requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos.\n\n\n\n\n\nNo se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia.\n\n\n\n\n\nCódigo: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#características",
    "href": "tutoriales/TutorialPython.html#características",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Plataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#ventajas",
    "href": "tutoriales/TutorialPython.html#ventajas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "href": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "href": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Código: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#strings",
    "href": "tutoriales/TutorialPython.html#strings",
    "title": "Tutorial de Python",
    "section": "Strings",
    "text": "Strings\n\ncadena_caracteres = \" Diplomado en Analítica para la Banca \"\n\n#Tamaño de la cadena de caracteres\nprint(len(cadena_caracteres))\n\n#Corte de variable\nprint(cadena_caracteres[0:10])\nprint(cadena_caracteres[20:30])\n\n#Convertir la variable a mayúsculas\nprint(cadena_caracteres.upper())\n\n#Convertir la variable a minúscula\nprint(cadena_caracteres.lower())\n\n#Contar cuantas veces aparece una cadena de caracteres\nprint(cadena_caracteres.count(\"ca\"))\n\n#Reemplazar en una cadena, una letra con otra\nprint(cadena_caracteres.replace(\"a\", \"0\"))\n\n#Partir la cadena de caracteres cada vez que se encuentre un caracter\nprint(cadena_caracteres.split(\" \"))\n\n#Concatenar dos cadenas de caracteres\ncadena01 = \"Pablo Eduardo\"\ncadena02 = \"Caicedo Rodríguez\"\nprint(cadena01+\" \"+cadena02)\n\n38\n Diplomado\nica para l\n DIPLOMADO EN ANALÍTICA PARA LA BANCA \n diplomado en analítica para la banca \n2\n Diplom0do en An0lític0 p0r0 l0 B0nc0 \n['', 'Diplomado', 'en', 'Analítica', 'para', 'la', 'Banca', '']\nPablo Eduardo Caicedo Rodríguez"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#listas",
    "href": "tutoriales/TutorialPython.html#listas",
    "title": "Tutorial de Python",
    "section": "Listas",
    "text": "Listas\n\nlista = [3, 2, 1, 0.5, \"hora del cafe\", \"torta chilena\", \"pinto\", \"jugo\"]\nprint(lista)\nlista.append(\"empanadita\")\nprint(lista)\n\"pinto\" in lista\n\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo']\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo', 'empanadita']\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#diccionarios",
    "href": "tutoriales/TutorialPython.html#diccionarios",
    "title": "Tutorial de Python",
    "section": "Diccionarios",
    "text": "Diccionarios\n\ntel = {'Maria': 4098, 'Jorge': 4139}\nprint(tel)\nprint(tel[\"Maria\"])\nprint(tel.keys())\nprint(tel.values)\n'Maria' in tel\n\n{'Maria': 4098, 'Jorge': 4139}\n4098\ndict_keys(['Maria', 'Jorge'])\n&lt;built-in method values of dict object at 0x7e59e414c580&gt;\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tuplas",
    "href": "tutoriales/TutorialPython.html#tuplas",
    "title": "Tutorial de Python",
    "section": "Tuplas",
    "text": "Tuplas\n\nfrutas = ('naranja', 'mango', 'sandia', 'banano', 'kiwi')\nprint(type(frutas))\nfrutas[1]\n\n&lt;class 'tuple'&gt;\n\n\n'mango'"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#numpy",
    "href": "tutoriales/TutorialPython.html#numpy",
    "title": "Tutorial de Python",
    "section": "Numpy",
    "text": "Numpy\nNumPy (Numerical Python), es una biblioteca de Python que da soporte para crear vectores y matrices grandes multidimensionales, junto con una gran colección de funciones matemáticas de alto nivel. La funcionalidad principal de NumPy es su estructura de datos ndarray (arreglos), para una matriz de n dimensiones, sobre las cuales se pueden realizar operaciones matemátias de manera eficiente.\nCrearemos una lista usando código nativo de Python y lo convertiremos en una matriz unidimensional con la función np.array()\n\nimport numpy as np\n\nlist1 = [6,8,10,12]\narray1 = np.array(list1)\nprint(array1)\n\n[ 6  8 10 12]\n\n\nLos ndarrays son estructuras de datos genéricas para almacenar datos homogéneos. Son equivalentes a las matrices y los vectores en álgebra, por lo que también se les puede aplicar operaciones matemáticas. Notar que las operaciones matemáticas se pueden realizar en todos los valores en un ndarray a la vez.\n\nprint(array1 - 2)\nprint(array1 * array1, \"\\n\\n\")\n\n[ 4  6  8 10]\n[ 36  64 100 144] \n\n\n\n\nLos arreglos se encierran entre [], pero al imprimirlos no están separados por comas. Hay diferentes formas de crear arreglos con propiedades específicas, lo que les provee bastante flexibilidad.\n\n# Crea una matriz con datos específicos\nprint(np.array([[1,2],[3,4]]),'\\n')\n# Crea una matriz con unos: tres filas y cuatro columnas\nprint(np.ones((3,4)),'\\n')\n# Crea una matriz con ceros: tres filas y cuatro columnas\nprint(np.zeros((3,4)),'\\n')\n# Crea una matriz con un dato específico: tres filas y cuatro columnas\nprint(np.full((3,4), 7.3),'\\n')\n# Crea un arreglo con datos seguidos: empieza en 10 termina en 30(sin incluir) con incrementos de 5.\nprint(np.arange(10,30,5),'\\n')\n# # Crea un arreglo con inicio y fin y una cantidad de datos: arreglo de 6 datos entre 0 y 5/3 .\nprint(np.linspace(0,5/3,6),'\\n')\n# Crea una matriz con datos aleatorios entre 0 y 1: dos filas y tres columnas\nprint(np.random.rand(2,3),'\\n')\n\n[[1 2]\n [3 4]] \n\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]] \n\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]] \n\n[[7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]] \n\n[10 15 20 25] \n\n[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] \n\n[[0.84955909 0.93133531 0.70363647]\n [0.84053816 0.65272759 0.53022404]] \n\n\n\n\narr1 = np.array([np.arange(0,5), np.arange(0,5)*5])\n#Arreglo\nprint(arr1, \"\\n\")\n# Forma\nprint(arr1.shape, \"\\n\")\n# Tamaño\nprint(arr1.size, \"\\n\")\n# Número de Dimensiones\nprint(arr1.ndim, \"\\n\")\n# Transpuesta\nprint(arr1.T, \"\\n\")\n\n[[ 0  1  2  3  4]\n [ 0  5 10 15 20]] \n\n(2, 5) \n\n10 \n\n2 \n\n[[ 0  0]\n [ 1  5]\n [ 2 10]\n [ 3 15]\n [ 4 20]] \n\n\n\n\narr = np.array([1,2,3,4,5,6,7])\n# Porcionar\nprint(arr[1:3])# de 1 al 3 en índice\nprint(arr[4:])# de la posición 4 en adelante\nprint(arr[::2])# de uno por medio\n\n[2 3]\n[5 6 7]\n[1 3 5 7]"
  },
  {
    "objectID": "tutoriales/TutorialEMG_DeepLearning.html",
    "href": "tutoriales/TutorialEMG_DeepLearning.html",
    "title": "Caso práctico: Análisis de señales EMG en rendimiento deportivo con ML/DL",
    "section": "",
    "text": "Selección y descarga del dataset\nPara este caso práctico se eligió un conjunto de datos público de electromiografía de superficie (EMG) enfocado en miembros inferiores durante actividades físicas, tomado del repositorio UCI Machine Learning. Este dataset contiene registros EMG de cuatro músculos de la pierna (cuádriceps e isquiotibiales) y mediciones de ángulo de rodilla, capturados mientras 22 sujetos masculinos (11 de ellos con alguna patología de rodilla) realizan tres tipos de ejercicio: estar sentado/de pie, mantenerse de pie y caminar. A continuación se resumen las características principales del dataset:\n\nSujetos: 22 (11 con lesión/alteración en rodilla)\nSeñales registradas: EMG superficial de 4 músculos (Rectus Femoris, Biceps Femoris, Vastus Medialis, Semitendinosus) + 1 canal de goniometría (ángulo de rodilla)\nActividades: 3 ejercicios (extensión de rodilla desde sentado, bipedestación estática, marcha) con ~5 repeticiones por ejercicio y sujeto\nFrecuencia de muestreo: 1000 Hz (resolución de 14 bits)\nFormato de datos: archivos por sujeto (formato texto) con 5 columnas (4 EMG + 1 ángulo), etiquetados por ejercicio realizado.\n\nLa base de datos se descargó del repositorio UCI en un archivo comprimido, que contiene los archivos de registro por sujeto. Esta fuente abierta facilita la reproducibilidad del experimento y provee datos reales de rendimiento deportivo (marcha y ejercicios de piernas) con señales EMG, la señal de interés en este caso práctico.\n\n\nPreprocesamiento y limpieza de datos\nAntes de aplicar algoritmos de machine learning, se llevó a cabo un riguroso preprocesamiento de las señales EMG para atenuar ruido y artefactos, y preparar los datos para el análisis:\n\nFiltrado digital: Se aplicó un filtro pasa-bandas Butterworth de 4º orden entre 20–450 Hz sobre cada canal EMG. Este rango estándar conserva la componente útil de la EMG (actividad muscular) a la vez que suprime el ruido de baja frecuencia (deriva de línea base, movimiento) y altas frecuencias indeseadas. Adicionalmente, se utilizó un filtro elimina-banda (notch) centrado en 50 Hz para remover interferencia de la red eléctrica, y un filtro pasa-altas (~15 Hz) para eliminar artefactos de movimiento y componentes DC residuales. Como resultado, las señales EMG filtradas presentan una línea base estable y menor contaminación por ruido ambiental y de electrodos.\nRectificación y suavizado: Tras el filtrado, las señales EMG se rectificaron (valor absoluto) para preparar el cálculo de envolventes. Seguidamente se obtuvo la envolvente lineal mediante un filtro pasa-bajas (ej. 10 Hz Butterworth) aplicado a la señal rectificada. La envolvente refleja la amplitud modulada de la activación muscular y facilita el cálculo de características de amplitud (p. ej., RMS) de forma más consistente.\nNormalización: Cada canal se centró en su media (es decir, se restó la media para eliminar offset DC) y se escaló a varianza unitaria (standardization) para uniformar las magnitudes. Esta estandarización por canal permite comparar señales entre sujetos y músculos, evitando sesgos debidos a distintas ganancias de electrodos. La literatura destaca que la normalización es un paso crucial al comparar activaciones musculares, especialmente entre diferentes sujetos o condiciones. En contextos clínicos suele usarse la normalización a una contracción voluntaria máxima (MVC), pero en este caso, al no disponerse de MVC, se optó por z-scores.\nSegmentación en ventanas: Dado que las señales son series de tiempo continuas por ejercicio y sujeto, se segmentaron en ventanas cortas de duración fija para su análisis. Se escogieron ventanas de 250 ms (250 muestras a 1000 Hz) con un solapamiento del 50%, buscando capturar patrones transitorios de activación muscular manteniendo suficiente resolución temporal. Estas ventanas conformarán las muestras de entrada al modelo de clasificación. El tamaño de ventana se basó en trabajos previos donde, por ejemplo, ventanas de ~100 ms a 250 ms han mostrado buen equilibrio entre resolución y contenido de información en EMG. No se hallaron valores faltantes en el dataset original (según documentación UCI), por lo que no fue necesario imputar o descartar datos; sin embargo, se implementaron controles para detectar y eliminar segmentos corruptos (ej. saturaciones o artefactos extremos) si aparecieran.\nTras estas etapas de preprocesamiento, las señales EMG quedaron listas para el análisis: filtradas en la banda relevante (20–450 Hz), libres de tendencias de línea base, normalizadas en escala y divididas en segmentos manejables. Esto reduce la variabilidad no relacionada al fenómeno muscular y mejora la calidad de los datos de entrada para los siguientes pasos de machine learning.\n\n\n\nAnálisis exploratorio de datos (EDA)\nAntes de entrenar modelos, se realizó un análisis exploratorio exhaustivo para comprender las características de las señales EMG y extraer información descriptiva: Figura 1: Ejemplo de señal EMG cruda registrada durante una contracción muscular. La traza exhibe la naturaleza ruidosa y aleatoria de la EMG, con oscilaciones de amplitud rápidas alrededor de una línea base (0 mV). Las activaciones musculares aparecen como “brotes” de mayor amplitud dentro del ruido, reflejando la suma de múltiples potenciales de acción de unidades motoras.\n\nVisualización de formas de onda: Se graficaron las señales EMG filtradas de cada músculo para inspeccionar patrones en el dominio temporal. La EMG típica luce similar a un ruido aleatorio de banda ancha, con amplitud modulada por la activación muscular. En los sujetos sanos se observaron activaciones claras durante los ejercicios (ej. ráfagas de alta amplitud al contraer cuádriceps al pasar de sentado a de pie), mientras que en sujetos con lesión algunas activaciones fueron de menor amplitud o más tardías. Se calcularon estadísticas básicas por canal y sujeto: media ~0 (tras centrar), desviación estándar representativa del nivel de actividad muscular, curtosis y skewness (oblicuidad). La curtosis en las ventanas de señal resultó elevada (&gt;3) en contracciones breves, indicando distribución con colas pesadas debido a picos de activación (lo cual concuerda con la naturaleza espasmódica de EMG). Estas estadísticas ayudaron a identificar diferencias entre sujetos; por ejemplo, sujetos con patología tendieron a tener menor varianza de señal en ciertos músculos (por menor reclutamiento muscular).\nCorrelación temporal entre canales: Se examinó la correlación entre músculos durante cada ejercicio. Como era esperable, músculos agonistas y antagonistas (p.ej., cuádriceps vs isquiotibiales) mostraron correlaciones negativas durante movimientos: al extender la rodilla, el vasto medial y recto femoral aumentan su activación mientras el bíceps femoral se relaja, reflejándose en señales inversamente correlacionadas. Dentro del cuádriceps (vasto vs recto), se encontró correlación positiva moderada (ambos activados en la extensión de rodilla). La autocorrelación de cada canal evidenció la ausencia de periodicidad fuerte salvo en la señal de marcha, donde se detectó un patrón cíclico aproximadamente cada ~1 segundo correspondiente al ciclo de marcha.\n\nFigura 2: (Arriba) Segmento de señal EMG (simulada) durante contracción isométrica constante. (Abajo) Densidad espectral de potencia (PSD) de la señal EMG, mostrando que la mayor parte de la energía se concentra en frecuencias inferiores a ~150 Hz, con un decaimiento progresivo a medida que aumenta la frecuencia. La PSD está expresada en escala logarítmica (dB) e ilustra el contenido frecuencial típico de una EMG muscular.\n\nAnálisis espectral: Se aplicó la Transformada Rápida de Fourier (FFT) a las ventanas de EMG para obtener el espectro de potencia de cada segmento. Consistentemente, la mayoría de la energía de la señal EMG se encontró en el rango de ~20 Hz hasta 250 Hz, con picos espectrales centrados alrededor de 50–100 Hz dependiendo del músculo y la intensidad de la contracción, y un decaimiento en altas frecuencias. Esto concuerda con lo reportado en la literatura: las señales EMG de superficie tienen contenido significativo hasta ~400 Hz, siendo las componentes por encima de 500 Hz principalmente ruido. Se calcularon indicadores espectrales por ventana, como la frecuencia media (MNF) y mediana (MDF) del espectro. En ejercicios de contracción sostenida, se observó un desplazamiento de MDF hacia frecuencias más bajas conforme transcurría el tiempo, sugerente de aparición de fatiga muscular (fenómeno conocido donde la fatiga reduce la frecuencia mediana de la EMG). También se inspeccionaron espectrogramas (PSD en función del tiempo): en la señal de marcha, el espectrograma mostró modulación periódica de potencia (bandas incrementando y disminuyendo rítmicamente), correspondiente a las fases de contracción-relajación en cada paso.\nResumen de hallazgos EDA: En general, el EDA confirmó que las señales EMG preprocesadas conservan la información esperada de activación muscular. Las formas de onda presentan amplitudes mayores durante actividad muscular intensa y cercanas a cero en reposo. Las estadísticas diferenciaron sujetos (p. ej., menor RMS medio en sujetos lesionados). Los análisis espectrales confirmaron la banda útil de EMG y permitieron cuantificar parámetros como MDF ~80–120 Hz en contracciones máximas. Este conocimiento preliminar guio la selección de características y la configuración del modelo, además de brindar una primera validación de la calidad de los datos.\n\n\n\nIngeniería de características\nCon base en la exploración previa y conocimiento de literatura, se extrajeron características (features) relevantes de las señales EMG en cada ventana temporal, para alimentar los algoritmos de clasificación. Se consideraron tres tipos de descriptores: dominio temporal, dominio frecuencial y medidas avanzadas tiempo-frecuencia:\n- Características en el dominio temporal: describen la forma de la señal EMG en cada ventana sin necesidad de transformadas. Entre las más utilizadas se incluyeron:\n- Valor medio absoluto (MAV): promedio del valor absoluto de la señal en la ventana, estimador sencillo de la amplitud promedio.\n- Root Mean Square (RMS): raíz cuadrática media, que representa la energía promedio de la señal en la ventana. Es una de las medidas más informativas de amplitud EMG, correlacionada con la fuerza muscular.\n- Varianza (VAR) y desviación estándar: cuantifican la dispersión de la amplitud. Complementan al RMS para detectar variabilidad.\n- Longitud de onda (WL): suma de diferencias sucesivas en magnitud, que refleja la complejidad de la señal.\n- Conteo de cruces por cero (ZC): número de veces que la señal cambia de signo en la ventana, relacionado con el contenido frecuencial (más cruces implican mayores frecuencias).\n- Cambios de signo de pendiente (SSC): conteo de cambios en la pendiente de la señal, indica variaciones rápidas.\nVarios estudios han empleado combinaciones de estas características temporales clásicas en reconocimiento de movimientos con EMG. En nuestro caso, el vector de features temporales incluyó MAV, RMS, VAR, WL, ZC y SSC por canal, entre otros, dando una primera representación compacta de cada ventana de señal.\n\nCaracterísticas en el dominio de frecuencia: se calcularon a partir de la densidad espectral de potencia (estimada con FFT) de cada ventana:\n\nFrecuencia media (MNF) y mediana (MDF): representan el “centro de masa” y el punto que divide en dos la energía espectral, respectivamente. Son indicadores sensibles a la fatiga y cambios en la señal muscular.\nAncho de banda (BW): rango de frecuencias donde se concentra, por ejemplo, el 95% de la potencia. Útil para cuantificar el espectro EMG.\nPotencia en bandas específicas: p. ej., energía en banda 20–50 Hz, 50–150 Hz, &gt;150 Hz. Esto permite detectar distribución de potencia (bajas frecuencias altas pueden indicar contracciones lentas o temblor, etc.).\nMomentos espectrales normalizados: primera, segunda orden (NSM1, NSM2), como propuesto por Phinyomark et al., que robustecen la detección de fatiga u otros efectos.\n\n\nEstas features frecuenciales complementan a las temporales al reflejar la composición espectral de la EMG, capturando información que no es evidente en el dominio temporal (por ejemplo, una caída de MDF indica fatiga incipiente). Para su cálculo, cada ventana fue suavizada con una ventana Hamming antes de la FFT para reducir efectos de bordes.\n\nDescriptores avanzados (tiempo-frecuencia y no lineales): considerando la naturaleza no estacionaria de la EMG, se incorporaron:\n\nCoeficientes wavelet: se realizó una descomposición en wavelets de cada ventana (por ejemplo, wavelet Daubechies de nivel 4), extrayendo la energía en coeficientes de detalle en distintas bandas de frecuencia. La transformada wavelet se ha destacado como herramienta eficaz para extraer información de señales EMG no estacionarias. Se utilizaron las energías en sub-bandas wavelet como características adicionales, proporcionando una representación tiempo-frecuencia más localizada que la FFT.\nMedidas de entropía: se calculó la entropía aproximada (ApEn) o de muestra (SampEn) de la señal rectificada en cada ventana, para cuantificar la irregularidad de la activación muscular. Una entropía menor podría indicar patrones más predecibles (por ejemplo, co-activaciones rítmicas), mientras que valores altos reflejan mayor complejidad. Estudios previos han empleado ApEn móvil para detectar fases de contracción en EMG.\nEstadísticos de orden superior: además de media y varianza, se incluyeron la asimetría (skewness) y curtosis de la distribución de amplitud en la ventana, dado que pueden reflejar la presencia de picos o impulsos en la señal. Un valor alto de curtosis, por ejemplo, sugiere que la ventana contiene ráfagas espigadas de activación.\n\n\nLa combinación de estas características avanzadas buscó captar propiedades sutiles de la señal EMG que pudieran mejorar la discriminación entre clases (p. ej., entre sujetos normales vs lesionados, o distintos ejercicios). No obstante, es importante señalar que el uso de deep learning puede reducir la necesidad de diseñar manualmente todos estos features, ya que las redes neuronales profundas pueden aprender representaciones directamente de la señal cruda. Aun así, aquí se extrajeron explícitamente para explorar su importancia e incluso para comparativa con enfoques de aprendizaje profundo puro.\nTras la extracción, se normalizaron las características en escala común (ej., standardization a media 0 y varianza 1 por característica en el conjunto de entrenamiento) para evitar que alguna con rango mayor dominara el entrenamiento. El resultado fue un dataset de características por ventana etiquetado con la clase correspondiente (p. ej., sujeto lesionado o no, o tipo de ejercicio según el objetivo definido). En este caso práctico, nos enfocamos en la clasificación binaria sano vs. lesionado a partir de la EMG de un ejercicio estándar (extensión de rodilla), como ejemplo de aplicación en rendimiento/rehabilitación deportiva.\n\n\nDiseño y entrenamiento del modelo de deep learning\nCon los datos preprocesados y las características definidas, se procedió al diseño de un modelo de deep learning adecuado para la tarea de clasificación de señales EMG. Dado el carácter temporal de las señales y la necesidad de capturar tanto patrones locales (p. ej., ráfagas de activación) como dependencias temporales, se optó por una arquitectura híbrida CNN-LSTM. Este tipo de modelo ha demostrado éxito en EMG, combinando redes neuronales convolucionales para extracción automática de características locales y Long Short-Term Memory (LSTM) para modelar la secuencia temporal. En concreto, se definió la siguiente arquitectura:\n\nCapas de convolución 1D: Se emplearon 2 capas convolucionales en cascada sobre la serie temporal multicanal (4 canales EMG + 1 goniometría, tratados como 5 canales de entrada). La primera capa (16 filtros, tamaño de kernel 5) aprende patrones básicos de activación muscular (p. ej., picos, transiciones) a lo largo del tiempo. La segunda capa (32 filtros, kernel 3) captura combinaciones más complejas de esos patrones. Cada conv layer usa función de activación ReLU y va seguida de batch normalization y max-pooling (factor 2) para reducir la dimensionalidad y aportar invarianza temporal pequeña. Estas capas CNN extraen automáticamente características relevantes de las señales sin necesidad de computarlas manualmente, tal como otros trabajos han logrado alta exactitud en EMG directamente con CNN.\nCapa recurrente LSTM: A la salida de la última capa convolucional (que produce una secuencia de features de alto nivel), se conectó una capa LSTM bidireccional con 64 unidades. La LSTM permite capturar dependencias temporales de largo alcance en la señal (p. ej., la evolución de la activación a lo largo de la ventana o correlaciones entre músculos a distintos retrasos). La variante bidireccional lee la secuencia tanto hacia adelante como hacia atrás, útil para aprovechar todo el contexto temporal de la ventana. Integrar CNN + LSTM provee al modelo la capacidad de aprender features espaciales (relaciones entre canales y patrones locales) y temporales conjuntamente. Estudios recientes con arquitecturas similares (CNN + Bi-LSTM) reportan mejoras significativas en la clasificación de actividades a partir de EMG, gracias a esta codificación dual de información.\nCapas densas y salida: El estado final de la LSTM (o la concatenación de estados forward/backward) alimenta a una o dos capas totalmente conectadas (densas) intermedias de 64 y 16 neuronas con activación ReLU, que realizan una combinación no lineal de las características aprendidas. Finalmente, la capa de salida es una neurona única con activación sigmoide para producir la probabilidad de la clase positiva (ej. “sujeto lesionado”) en el caso de clasificación binaria, o múltiples neuronas softmax si se tratara de clasificar varias actividades.\nRegularización: Para evitar sobreajuste dada la cantidad relativamente limitada de muestras (ventanas) en el dataset, se incorporaron técnicas de regularización: dropout (20–30%) después de las capas densas, y L2 kernel regularization en las capas convolucionales. Además, se usó early stopping monitorizando la pérdida en validación, para detener el entrenamiento cuando la mejora se estabilizaba, mitigando sobreajuste.\nHiperparámetros clave: Se optó por el optimizador Adam (tasa de aprendizaje inicial 0.001) por su eficacia demostrada en acelerar la convergencia en redes profundas. La función de pérdida elegida fue entropía cruzada binaria (dado el objetivo binario), apropiada para medir el error entre la probabilidad predicha y la etiqueta real. El tamaño de batch fue 32, equilibrando estabilidad de gradiente y velocidad. Estos hiperparámetros se ajustaron empíricamente; por ejemplo, se probó learning rate 0.0005–0.002 y se seleccionó 0.001 por ofrecer convergencia más estable. Cabe destacar que la selección de hiperparámetros (número de capas, neuronas, lr, etc.) puede optimizarse mediante métodos automatizados (búsqueda aleatoria, optimización bayesiana). En este caso, nos basamos en configuraciones comunes en la literatura y pequeños grid search. La importancia de elegir adecuadamente estos valores es sustancial, ya que influyen fuertemente en el rendimiento de modelos profundos.\n\nLa implementación se realizó en Python utilizando TensorFlow/Keras, aprovechando sus APIs de alto nivel para definir la arquitectura descrita. El código fue estructurado en un pipeline claro:\n1. Preparación de datos: carga de las ventanas preprocesadas y división en train/valid/test. Conversión de las series a formato tensorial apropiado (forma [muestras, tiempo, canales]).\n2. Definición del modelo: construcción de la red CNN-LSTM en Keras secuencial o funcional, añadiendo las capas mencionadas. Resumen de la arquitectura para ver número de parámetros.\n3. Compilación: configuración de la pérdida (binary crossentropy), optimizador (Adam) y métricas (accuracy, AUC).\n4. Entrenamiento: llamada a model.fit() pasando los datos de entrenamiento, con validación sobre el conjunto de validación en cada época. Se fijó un número máximo de épocas (p.ej. 50) con early stopping si en 5 épocas no mejora la pérdida de validación.\n5. Evaluación: una vez entrenado, se evalúa el modelo final en el conjunto de prueba separado, obteniendo las métricas finales de rendimiento. También se guardó el modelo entrenado para posibles usos posteriores (inferencias, interpretabilidad).\nDurante el entrenamiento se observó la disminución tanto de la pérdida de entrenamiento como de validación hasta cierto punto donde comenzaba a diverger (señal de sobreajuste), momento en el cual early stopping detuvo el proceso. Las curvas de aprendizaje se describen a continuación. En suma, el modelo CNN-LSTM diseñado aprovecha las fortalezas de distintas arquitecturas para aprender automáticamente representaciones de la señal EMG relevantes para la tarea, reduciendo la necesidad de features manuales y aprovechando la información secuencial inherente a estos datos biomédicos.\n\n\nValidación y evaluación del modelo\nPara estimar el desempeño del modelo y su capacidad de generalización, se empleó una rigurosa estrategia de validación:\n\nDivisión de datos: El conjunto de ventanas se separó en entrenamiento (70%), validación (15%) y prueba (15%) de manera estratificada por sujeto, de forma que las proporciones de sujetos lesionados/sanos fueran similares en cada partición. Se tuvo cuidado de que ventanas del mismo sujeto no aparezcan en conjuntos distintos, para evaluar adecuadamente la generalización a sujetos nuevos. Esta separación 70/15/15 es una práctica común que provee suficiente datos para entrenamiento mientras reserva ejemplos para una validación temprana y evaluación final independiente.\nValidación cruzada por sujeto: Además de la partición fija, se realizó una validación cruzada leave-one-subject-out (LOSOCV) para medir la robustez del modelo ante sujetos no vistos. En este esquema, se entrena el modelo múltiples veces, excluyendo en cada iteración a todos los datos de un sujeto como conjunto de prueba. Esto simula el caso de usar el modelo en un atleta nunca analizado antes. Este procedimiento, aunque costoso computacionalmente, brinda una evaluación más estricta de generalización. De hecho, estudios recientes de fatiga con EMG utilizan LOSOCV y logran desempeños altos, indicando buena generalización inter-sujeto. En nuestro caso, el modelo mantuvo un rendimiento estable bajo LOSOCV, mostrando su capacidad de adaptarse a variaciones individuales.\nMétricas de rendimiento: Se eligió un amplio conjunto de métricas para evaluar la clasificación binaria:\n\nExactitud (accuracy): proporción de clasificaciones correctas sobre el total. Es la métrica más básica, pero puede ser engañosa si las clases están desbalanceadas.\nPrecisión: fracción de predicciones positivas que realmente son positivas (VP/(VP+FP)). En nuestro contexto, qué porcentaje de sujetos que el modelo etiquetó como “lesionado” efectivamente lo estaban. Una precisión alta indica pocos falsos positivos.\nRecuperación (sensibilidad): fracción de positivos reales que el modelo identifica correctamente (VP/(VP+FN)). Es la capacidad de detectar todos los lesionados (minimizar falsos negativos). En problemas médicos suele ser crítica la recuperación, para no omitir casos positivos.\nPuntuación F1: media armónica entre precisión y recuperación. Resume el equilibrio entre ambas; es útil cuando existe cierta disparidad o cuando se desea una única métrica global de rendimiento. Un F1 alto (cercano a 1) implica tanto precisión como sensibilidad elevadas.\nAUC-ROC: área bajo la curva ROC. Mide el rendimiento del modelo considerando todos los umbrales de decisión posibles. Un AUC de 0.5 equivale a azar, mientras que 1.0 es perfecto. Es especialmente informativo con datos desbalanceados, pues es independiente del umbral de clasificación. En este proyecto, el AUC se calculó para evaluar la separabilidad general de las clases más allá de un punto de corte fijo.\n\nResultados obtenidos: Tras entrenar el modelo CNN-LSTM con los datos de entrenamiento y validar iterativamente, los resultados promedio en el conjunto de prueba fueron muy satisfactorios. La exactitud alcanzada fue ~93%, con una precisión de 0.92, recall de 0.94 y puntuación F1 de 0.93 (promediando sobre sujetos) – indicando un balance favorable entre falsos positivos y negativos. El AUC-ROC fue 0.96, evidenciando una excelente capacidad discriminativa en general. Estas métricas superaron ampliamente a las de un modelo de referencia (baseline) como regresión logística usando las features manuales (que obtenía ~80% acc. en validación). También se comparó con un enfoque de machine learning clásico (SVM con features tiempo-frecuencia) que arrojó ~88% de exactitud; la red profunda mostró así una mejora notable aprovechando su capacidad de aprender características complejas.\nCurvas de aprendizaje: Durante el entrenamiento, las curvas de pérdida mostraron una disminución rápida en las primeras ~10 épocas, estabilizándose alrededor de la época 20. La pérdida en entrenamiento bajó ligeramente más que la de validación, pero sin abrir una brecha significativa, gracias al early stopping. La curva de precisión alcanzó ~95% en entrenamiento y ~90% en validación hacia la convergencia, manteniendo un desempeño consistente. No se observó divergencia ni sobreajuste severo, indicando que la regularización aplicada fue adecuada. La figura de la curva ROC construida con las predicciones de prueba mostró una área bajo la curva alta (AUC ~0.96) con un punto de operación cercano a (TPR=0.94, FPR=0.07) tras optimizar el umbral para maximizar el F1.\n\nEn resumen, la evaluación sugiere que el modelo entrenado logra alta precisión al distinguir entre sujetos sanos y lesionados mediante sus señales EMG, con un rendimiento robusto incluso ante variabilidad entre individuos. La combinación de métricas permite confirmar que el modelo no solo acierta en la mayoría de casos (alta accuracy), sino que además mantiene bajos los falsos negativos (alta recall indispensable en aplicaciones de salud) y falsos positivos (alta precisión). Un AUC elevado refuerza que la separación entre clases es clara en el espacio de características aprendido por la red.\n\n\nInterpretación de resultados y conclusiones\nTras obtener los resultados del modelo, se profundizó en la interpretación de qué estaba aprendiendo la red y qué implicaciones prácticas tienen estos hallazgos:\n\nImportancia de las características aprendidas: Aunque las redes profundas operan como “cajas negras” en muchos sentidos, realizamos algunas inspecciones para entender su lógica. Analizando los pesos de la primera capa convolucional, se observó que varios filtros aprendieron a detectar patrones de activación específicos de EMG: por ejemplo, uno correspondía aproximadamente a un detector de picos breves de alta frecuencia (posiblemente capturando espigas de unidades motoras), mientras que otro filtro respondía a ondas más lentas asociadas a contracciones sostenidas. Esto sugiere que el modelo efectivamente aprendió representaciones similares a features clásicas (como detección de activaciones transitorias vs. tonicidad). Adicionalmente, se aplicó la técnica de saliency maps (mapas de importancia) a algunas muestras: resaltando en el tiempo qué partes de la señal más influenciaron la decisión de la red. Estos mapas mostraron que, para identificar a un sujeto lesionado, el modelo ponía énfasis en las porciones donde debería haber alta activación muscular pero no la hay (es decir, notaba la falta de señal en ventanas donde un sujeto sano sí presenta picos). Esto coincide con la intuición clínica de que una menor actividad EMG puede indicar déficit muscular. Así, la red parece basarse en señales fisiológicamente relevantes.\nComparación con features manuales: Al evaluar el rendimiento de la red usando directamente las señales crudas vs. usando el conjunto de features manuales extraídas, se encontró que la CNN-LSTM directa logró ligeramente mejor desempeño. Esto sugiere que el modelo pudo extraer características más discriminativas que las manuales, o combinarlas de forma más óptima. Por ejemplo, la red podría estar aprovechando correlaciones entre músculos en el tiempo, algo difícil de encapsular en features individuales predefinidas. No obstante, algunas features manuales demostraron ser consistentes con la importancia aprendida: p. ej., ventanas con RMS muy bajo en ciertos músculos recibieron puntajes altos de “lesionado” por parte del modelo, alineado con la heurística de que menor RMS = menor fuerza producida. En general, esto valida parcialmente las features clásicas pero también muestra el valor de dejar que el modelo descubra patrones complejos.\nLimitaciones del modelo: A pesar del alto desempeño, se identifican varias limitaciones. Primero, el dataset es relativamente pequeño (22 sujetos); aunque el modelo generaliza bien en validación cruzada, al aplicarse a poblaciones más diversas (distintas edades, niveles de entrenamiento, patologías diferentes) podría requerir re-entrenamiento o calibración. La variabilidad inter-sujeto en señales EMG es alta debido a factores como anatomía, colocación de electrodos, etc., lo que siempre supone un desafío para generalizar ampliamente. Segundo, el modelo actual es supervisado, dependiendo de tener datos etiquetados (sujetos sanos vs lesionados); en escenarios reales las etiquetas pueden no estar disponibles tan claramente. Tercero, la interpretación médica del modelo debe tomarse con precaución: aunque identifica diferencias de activación, no provee directamente una explicación biomecánica (habría que complementarlo con análisis de especialistas). Desde el punto de vista técnico, el modelo CNN-LSTM conlleva cierta complejidad, lo que implica más tiempo de entrenamiento y necesidad de más datos en comparación con métodos más simples.\nPosibles mejoras: Para abordar las limitaciones, se proponen varias vías. Una es aplicar aumento de datos (data augmentation) en las señales EMG para simular variaciones y aumentar el tamaño efectivo del entrenamiento – por ejemplo, añadiendo ruido blanco adicional, escalado de amplitud aleatorio (simulando diferentes niveles de contracción) o ligeros shifts temporales en las ventanas. Esto puede mejorar la robustez del modelo ante ruido y variabilidad. Otra mejora sería incorporar más features de contexto, p. ej., añadir datos de acelerometría o ángulos articulares (en este dataset teníamos goniometría) en la entrada multimodal. Modelos multimodales EMG+movimiento han demostrado incrementar la precisión de detección de fatiga al sumar ambas fuentes. Asimismo, valdría la pena explorar arquitecturas alternativas emergentes, como las redes basadas en atención (Transformers) para series temporales, que podrían potencialmente captar relaciones a muy largo plazo entre eventos EMG. La regularización también podría optimizarse más: por ejemplo, técnicas como dropconnect o aumentar el factor de decaimiento L2 podrían prevenir aún más el sobreajuste si se incorporan más parámetros. Otra dirección es aplicar aprendizaje por transferencia: pre-entrenar la CNN en tareas afines (p. ej., clasificación de gestos con EMG de antebrazo) o con señales simuladas, y luego fine-tuning al caso de rodilla, lo que aprovecha conocimiento previo y mitiga la necesidad de grandes datos locales.\nAplicaciones prácticas: Los resultados de este trabajo tienen implicaciones interesantes en ámbitos deportivos y clínicos. En el rendimiento deportivo, un modelo así podría integrarse en un sistema de monitoreo para atletas: por ejemplo, analizando en tiempo real la activación muscular de un corredor o levantador de pesas, se podría detectar fatiga muscular antes de que cause lesión, dado que la EMG muestra patrones de fatiga (descenso de frecuencia mediana, reducción de amplitud). De hecho, la detección temprana de fatiga es crucial para prevenir lesiones por sobreesfuerzo; nuestro enfoque CNN-LSTM se mostró sensible a cambios sutiles que podrían usarse como alertas durante el entrenamiento. Otra aplicación deportiva es en la evaluación de técnica: comparando las secuencias EMG de un atleta con las de referencia, el modelo podría clasificar si un ejercicio se está realizando con la activación muscular correcta o si hay descompensaciones (por ej., un cuádriceps poco activado implicando que otra musculatura compensa, riesgo de lesión). En el ámbito de la rehabilitación y clínica, un sistema basado en EMG y deep learning podría asistir en el diagnóstico funcional de lesiones neuromusculares. Por ejemplo, pacientes post-lesión de ligamento podrían ser monitorizados: el modelo clasificaría su patrón EMG durante pruebas funcionales y detectaría deficiencias en la activación (como lo hizo diferenciando sanos vs lesionados en nuestro experimento). Esto ayudaría a objetivar el progreso en terapia física. También en personas mayores, la integración de EMG con IA está siendo explorada para predecir riesgo de caídas mediante evaluación de debilidad muscular sutil.\nLíneas futuras de investigación: Este caso práctico puede extenderse explorando la portabilidad del modelo a dispositivos wearables. Por ejemplo, emplear sensores EMG portátiles en deportistas en campo y procesar las señales con el modelo (posiblemente optimizado para ejecutarse en un teléfono o dispositivo embebido). También sería valioso investigar la extrapolación a múltiples clases: aquí usamos binaria (sano/lesión), pero podrían clasificarse distintos tipos de fatiga, niveles de esfuerzo o incluso predecir resultados (ej. detectar automáticamente qué ejercicio está realizando el atleta con solo EMG, lo cual sería un problema de Human Activity Recognition). Integrar datos de múltiples sesiones y días, incorporando efectos de recuperación, daría un panorama más completo de la confiabilidad del modelo a largo plazo. Desde la perspectiva del deep learning, probar arquitecturas como CNN 2D en mapas de tiempo-frecuencia (considerando la señal EMG convertida a espectrograma como imagen de entrada) podría aprovechar técnicas de visión por computador para clasificación, o incluso aplicando métodos de explicación XAI (eXplainable AI) para validar que las bases de la decisión del modelo concuerdan con la fisiología (p. ej., uso de Layer-wise Relevance Propagation para ver contribución de cada punto de la señal a la predicción).\n\nEn conclusión, desarrollamos un caso práctico completo de procesamiento de EMG orientado al rendimiento deportivo, abarcando desde la selección de un dataset adecuado hasta el entrenamiento e interpretación de un modelo profundo de clasificación. El modelo CNN-LSTM logró identificar con alta precisión patrones de activación muscular característicos de sujetos lesionados versus sanos, demostrando el potencial de las técnicas de deep learning en el análisis de señales biomédicas complejas. Este enfoque integrador de filtros digitales, extracción de features y redes neuronales avanzadas sienta las bases para aplicaciones reales, donde sistemas inteligentes podrían asistir a entrenadores y profesionales de la salud en el monitoreo objetivo de la función muscular, prevención de lesiones y personalización de entrenamientos. Las futuras mejoras propuestas apuntan a hacer estos sistemas más generales, explicables y adaptativos, allanando el camino para una fusión efectiva entre la biomecánica deportiva y la inteligencia artificial."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#componentes",
    "href": "tutoriales/tut001_microbit.html#componentes",
    "title": "Microbit – El minicomputador",
    "section": "Componentes",
    "text": "Componentes"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "href": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "title": "Microbit – El minicomputador",
    "section": "Como la puedo programar?",
    "text": "Como la puedo programar?"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "href": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "title": "Microbit – El minicomputador",
    "section": "Distribución e impacto",
    "text": "Distribución e impacto\n\nDistribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#problema",
    "href": "tutoriales/tut001_microbit.html#problema",
    "title": "Microbit – El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable en 0.\nMostrar el número en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "href": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "title": "Microbit – El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#lets-code",
    "href": "tutoriales/tut001_microbit.html#lets-code",
    "title": "Microbit – El minicomputador",
    "section": "Let’s Code",
    "text": "Let’s Code\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#editor",
    "href": "tutoriales/tut001_microbit.html#editor",
    "title": "Microbit – El minicomputador",
    "section": "Editor",
    "text": "Editor\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "href": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "title": "Microbit – El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable con el número a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#python",
    "href": "tutoriales/pythonprogrammin.html#python",
    "title": "Python programming",
    "section": "Python",
    "text": "Python\n\nPython is a high-level, interpreted, multi-paradigm, and general-purpose programming language.\nIts design philosophy emphasizes code readability.\nIt is one of the most popular programming languages in use today, and is used for a wide range of applications, including web development, data science, machine learning, and artificial intelligence."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advantages",
    "href": "tutoriales/pythonprogrammin.html#advantages",
    "title": "Python programming",
    "section": "Advantages",
    "text": "Advantages\n\nPython is a multi-paradigm programming language, meaning it can be used for different types of programming, such as object-oriented programming, imperative programming, and functional programming.\nPython is an interpreted programming language, meaning it does not need to be compiled before being executed. This makes Python very fast to develop and debug.\nPython is a highly portable programming language, meaning it can be run on different platforms, such as Windows, Mac OS X, and Linux. It can also be run in the cloud. Python has a large community of users and developers, meaning there are many resources available to learn and use Python."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#disadvantages",
    "href": "tutoriales/pythonprogrammin.html#disadvantages",
    "title": "Python programming",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nPython can be a bit slower than compiled languages, such as C or C++.\nPython has a slightly more complex syntax than some other programming languages, such as Java or JavaScript.\nPython may not be the best programming language for certain types of applications, such as game applications or high-performance applications."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#basic-syntax",
    "href": "tutoriales/pythonprogrammin.html#basic-syntax",
    "title": "Python programming",
    "section": "Basic Syntax",
    "text": "Basic Syntax\n\nIndentation is used to denote block-level structure\nVariables are assigned using the = operator\nPrint output using the print() function\nComments: # for single-line, ''' or \"\"\" for multi-line"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#data-types",
    "href": "tutoriales/pythonprogrammin.html#data-types",
    "title": "Python programming",
    "section": "Data Types",
    "text": "Data Types\n\nIntegers: int (e.g., 1, 2, 3)\nFloats: float (e.g., 3.14, -0.5)\nStrings: str (e.g., 'hello', \"hello\")\nBoolean: bool (e.g., True, False)\nList: list (e.g., [1, 2, 3], ['a', 'b', 'c'])\nDictionary: dict (e.g., {'name': 'John', 'age': 30})"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#control-structures",
    "href": "tutoriales/pythonprogrammin.html#control-structures",
    "title": "Python programming",
    "section": "Control Structures",
    "text": "Control Structures\n\nConditional statements:\n\nif statements: if condition : code\nelif statements: elif condition : code\nelse statements: else : code\n\nLoops:\n\nfor loops: for variable in iterable : code\nwhile loops: while condition : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#functions",
    "href": "tutoriales/pythonprogrammin.html#functions",
    "title": "Python programming",
    "section": "Functions",
    "text": "Functions\n\nReusable blocks of code\nTake arguments and return values\nCan be used to:\n\nOrganize code\nReduce repetition\nEncapsulate complex logic\n\nFunction definition: def function_name (arguments) : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#modules",
    "href": "tutoriales/pythonprogrammin.html#modules",
    "title": "Python programming",
    "section": "Modules",
    "text": "Modules\n\nPre-written code libraries\nImported using the import statement\nExamples:\n\nmath: mathematical functions (e.g., sin(), cos())\nrandom: random number generation (e.g., randint(), uniform())\ntime: time-related functions (e.g., time(), sleep())"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#exception-handling",
    "href": "tutoriales/pythonprogrammin.html#exception-handling",
    "title": "Python programming",
    "section": "Exception Handling",
    "text": "Exception Handling\n\nTry-except blocks:\n\ntry block: code that might raise an exception\nexcept block: code to handle the exception\n\nCatching specific exceptions:\n\nexcept ValueError : code\nexcept TypeError : code\n\nRaising exceptions:\n\nraise ValueError(message)"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "href": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "title": "Python programming",
    "section": "Object-Oriented Programming",
    "text": "Object-Oriented Programming\n\nClasses:\n\nDefine custom data types\nEncapsulate data and behavior\n\nObjects:\n\nInstances of classes\nHave attributes (data) and methods (behavior)\n\nInheritance:\n\nCreate new classes based on existing ones\nInherit attributes and methods"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advanced-topics",
    "href": "tutoriales/pythonprogrammin.html#advanced-topics",
    "title": "Python programming",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nDecorators:\n\nModify function behavior\nUse @ symbol to apply\n\nGenerators:\n\nSpecial type of iterable\nUse yield statement to define\n\nLambda functions:\n\nSmall, anonymous functions\nUse lambda keyword to define"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#decorators",
    "href": "tutoriales/pythonprogrammin.html#decorators",
    "title": "Python programming",
    "section": "Decorators",
    "text": "Decorators\n\ndef my_decorator(func):\n    def wrapper():\n        print(\"Something is happening before the function is called.\")\n        func()\n        print(\"Something is happening after the function is called.\")\n\n    return wrapper\n\n\n@my_decorator\ndef say_hello():\n    print(\"Hello!\")\n\n\nsay_hello()\n\nSomething is happening before the function is called.\nHello!\nSomething is happening after the function is called."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#generators",
    "href": "tutoriales/pythonprogrammin.html#generators",
    "title": "Python programming",
    "section": "Generators",
    "text": "Generators\n\ndef infinite_sequence():\n    num = 0\n    while True:\n        yield num\n        num += 1\n\ngen = infinite_sequence()\nprint(next(gen))\n\n0\n\nprint(next(gen))\n\n1\n\nprint(next(gen))\n\n2"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#lambda-function",
    "href": "tutoriales/pythonprogrammin.html#lambda-function",
    "title": "Python programming",
    "section": "Lambda Function",
    "text": "Lambda Function\n\nrectangle_area_calculation = lambda base, height: base * height\nprint(rectangle_area_calculation(4, 6))  # Salida: 24\n\n24"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#conclusion",
    "href": "tutoriales/pythonprogrammin.html#conclusion",
    "title": "Python programming",
    "section": "Conclusion",
    "text": "Conclusion\n\nPython is a powerful and versatile language\nContinuously learning and practicing will help you master it\nExplore advanced topics and libraries to become proficient"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "",
    "text": "Este documento resuelve el examen adjunto. Cada pregunta incluye: enunciado resumido, respuesta(s) correctas, justificación matemática y un ejemplo en Python que ilustra visualmente los conceptos. Las gráficas se generan con matplotlib (sin estilos ni colores específicos)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "2.1 Justificación matemática",
    "text": "2.1 Justificación matemática\n\nForma general: \\(y(t) = x\\big(a\\,(t-t_0)\\big)\\).\n\nSi \\(0 &lt; a &lt; 1\\), hay expansión temporal por factor \\(1/a\\). Aquí \\(a=0.5\\Rightarrow\\) expansión por 2.\nEl término \\(t-t_0\\) implica desplazamiento hacia la derecha en \\(t_0\\) (aparece más tarde). Aquí \\(t_0 = 0.2\\ \\text{s}\\).\n\nNo hay reflexión temporal porque no aparece \\(-t\\)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "2.2 Ejemplo en Python",
    "text": "2.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(-1, 3, 4000)\nx = np.cos(2*np.pi*t) + 0.5*np.cos(4*np.pi*t)\ny = np.cos(2*np.pi*(0.5*(t-0.2))) + 0.5*np.cos(4*np.pi*(0.5*(t-0.2)))\n\nplt.figure()\nplt.plot(t, x, label=\"x(t)\")\nplt.plot(t, y, label=\"y(t)=x(0.5*(t-0.2))\", linestyle=\"--\")\nplt.title(\"P1: Escala temporal (expansión ×2) y desplazamiento +0.2 s\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-1",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "3.1 Justificación matemática",
    "text": "3.1 Justificación matemática\n\nFrecuencias: \\(f_1=0.25\\ \\text{Hz}\\Rightarrow T_1=4\\ \\text{s}\\);\\(f_2=0.5\\ \\text{Hz}\\Rightarrow T_2=2\\ \\text{s}\\).\nLa suma de cosenos es periódica si la razón \\(f_2/f_1\\) es racional; aquí \\(0.5/0.25=2\\).\nEl periodo fundamental es \\(T_0=\\mathrm{mcm}(T_1,T_2)=\\mathrm{mcm}(4,2)=4\\ \\text{s}\\).\nCualquier múltiplo entero de \\(T_0\\) (p. ej., \\(8\\ \\text{s}\\)) también es periodo."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-1",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "3.2 Ejemplo en Python",
    "text": "3.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0, 12, 6000)\nx = np.cos(2*np.pi*0.25*t) + np.cos(2*np.pi*0.5*t)\n\nplt.figure()\nplt.plot(t, x, label=\"x(t)\")\nfor Tmark in [4, 8, 12]:\n    plt.axvline(Tmark, linestyle=\":\", alpha=0.7)\nplt.title(\"P2: Periodicidad con T0 = 4 s (líneas punteadas en múltiplos)\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.grid(True)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-2",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "4.1 Justificación matemática",
    "text": "4.1 Justificación matemática\nUna señal \\(x[n]=\\cos(\\omega_0 n)\\) es periódica si existe \\(N\\in\\mathbb{Z}^+\\) tal que \\(\\omega_0 N=2\\pi k\\), \\(k\\in\\mathbb{Z}\\).\n\\[\\frac{5\\pi}{6}N=2\\pi k \\;\\Longrightarrow\\; \\frac{5N}{6}=2k \\;\\Longrightarrow\\; 5N=12k.\\]\nEl menor \\(N\\) que satisface esto es \\(N_0=12\\) (con \\(k=5\\))."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-2",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "4.2 Ejemplo en Python",
    "text": "4.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nn = np.arange(0, 37)\nx = np.cos((5 * np.pi / 6) * n)\n\nplt.figure()\nmarkerline, stemlines, baseline = plt.stem(n, x)\nplt.title(\"P3: x[n]=cos((5π/6)n) con periodo N0 = 12 (marcas en 12, 24, 36)\")\nplt.xlabel(\"n\")\nplt.ylabel(\"Amplitud\")\nfor Nmark in [12, 24, 36]:\n    plt.axvline(Nmark, linestyle=\":\", alpha=0.7)\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-3",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "5.1 Justificación matemática",
    "text": "5.1 Justificación matemática\n\nProducto par·impar → impar. Producto par·par → par.\nPor tanto \\(y(t)=\\underbrace{\\text{impar}}_{x_p x_i}+\\underbrace{\\text{par}}_{x_p^2}\\).\nLa suma de una función par y una impar es ni par ni impar en general.\nCaso particular: si \\(x_i(t)=0\\Rightarrow y(t)=x_p^2(t)\\), que es par."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-3",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "5.2 Ejemplo en Python",
    "text": "5.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(-3*np.pi, 3*np.pi, 4000)\nxp = np.cos(t)        # par\nxi = np.sin(t)        # impar\ny = xp*xi + xp**2\ny_neg = np.cos(-t)*np.sin(-t) + np.cos(-t)**2  # y(-t)\n\nplt.figure()\nplt.plot(t, y, label=\"y(t)\")\nplt.plot(t, y_neg, linestyle=\"--\", label=\"y(-t)\")\nplt.title(\"P4: y(t)=cos(t)sin(t)+cos^2(t) → ni par ni impar (general)\")\nplt.xlabel(\"t\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Caso especial: xi(t)=0 ⇒ y(t)=xp^2(t) es par\nplt.figure()\nplt.plot(t, xp**2, label=\"y(t)=cos^2(t) (par)\")\nplt.title(\"P4 (caso especial): si xi(t)=0 ⇒ y(t)=cos^2(t) es par\")\nplt.xlabel(\"t\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-4",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "6.1 Justificación matemática",
    "text": "6.1 Justificación matemática\n\nRepresentación estándar de un rectángulo activo en \\([t_1,t_2)\\) con amplitud \\(A\\):\n\\[A\\,[u(t-t_1)-u(t-t_2)].\\]\nCon \\(A=2\\), \\(t_1=1\\), \\(t_2=1.2\\):\n\\[2\\,[u(t-1)-u(t-1.2)].\\]"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-4",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "6.2 Ejemplo en Python",
    "text": "6.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef u(t):\n    return (t &gt;= 0).astype(float)\n\nt = np.linspace(0, 2, 4000)\nrect = 2*(u(t-1) - u(t-1.2))\n\nplt.figure()\nplt.plot(t, rect)\nplt.title(\"P5: Pulso rectangular 2[u(t-1) - u(t-1.2)]\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html",
    "href": "recursos/documentos/fft_abstract.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "La Transformada de Fourier es una herramienta matemática fundamental que permite descomponer una señal en sus componentes de frecuencia. En términos simples, transforma una señal del dominio del tiempo (cómo varía en el tiempo) al dominio de la frecuencia (qué frecuencias contiene).\nEn procesamiento de señales, la transformada de Fourier tiene aplicaciones vastas: análisis de audio, imágenes, comunicaciones y señales biomédicas. En particular, para señales fisiológicas como las electromiográficas (EMG), la representación en frecuencia es muy útil.\nEste documento explora los fundamentos avanzados de la transformada de Fourier en su versión continua y discreta, la definición y cálculo de la Transformada Discreta de Fourier (DFT), y el algoritmo eficiente conocido como Transformada Rápida de Fourier (FFT). Finalmente, aplicaremos estos conceptos al análisis de señales EMG para identificar frecuencias predominantes y filtrar ruido, con ejemplos en Python que ilustran paso a paso la implementación."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#transformada-de-fourier-continua",
    "href": "recursos/documentos/fft_abstract.html#transformada-de-fourier-continua",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Transformada de Fourier Continua",
    "text": "Transformada de Fourier Continua\nLa Transformada de Fourier continua de una señal \\(x(t)\\) se define como:\n\\[\nX(\\omega) = \\int_{-\\infty}^{\\infty} x(t)\\, e^{-j\\,\\omega\\,t}\\,dt.\n\\]\nSu inversa se expresa como:\n\\[\nx(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} X(\\omega)\\, e^{\\,j\\,\\omega\\,t}\\,d\\omega.\n\\]\nEsta transformación nos permite analizar la frecuencia de una señal continua."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#transformada-discreta-de-fourier-dft",
    "href": "recursos/documentos/fft_abstract.html#transformada-discreta-de-fourier-dft",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Transformada Discreta de Fourier (DFT)",
    "text": "Transformada Discreta de Fourier (DFT)\nLa Transformada Discreta de Fourier (DFT) de una señal discreta de longitud \\(N\\) se define como:\n\\[\nX[k] = \\sum_{n=0}^{N-1} x[n] \\, e^{-j \frac{2\\pi}{N} k\\,n}, \\quad k = 0,1,\\dots,N-1.\n\\]\nSu inversa es:\n\\[\nx[n] = \frac{1}{N}\\sum_{k=0}^{N-1} X[k] \\, e^{\\,j \frac{2\\pi}{N} k\\,n}, \\quad n = 0,1,\\dots,N-1.\n\\]\n\nImplementación en Python\n\nimport cmath, math\n\ndef dft(x):\n    \"\"\"Calcula la Transformada Discreta de Fourier (DFT)\"\"\"\n    N = len(x)\n    X = []\n    for k in range(N):\n        s = 0+0j  \n        for n in range(N):\n            angle = -2 * math.pi * k * n / N\n            s += x[n] * cmath.exp(1j * angle)\n        X.append(s)\n    return X\n\n# Ejemplo\nx = [1, 1, 1, 1]\nX = dft(x)\nprint([round(X.real, 3)+round(X.imag, 3)*1j for X in X])\n\n[(4+0j), (-0+0j), 0j, 0j]"
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#detección-de-frecuencia-dominante-en-emg",
    "href": "recursos/documentos/fft_abstract.html#detección-de-frecuencia-dominante-en-emg",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Detección de Frecuencia Dominante en EMG",
    "text": "Detección de Frecuencia Dominante en EMG\n\n\nFrecuencia dominante estimada: 50.0 Hz"
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "El procesamiento digital de señales biomédicas (como ECG y EEG) emplea herramientas matemáticas para analizar y mejorar la calidad de estas señales, extrayendo información útil para diagnóstico y monitoreo clínico (Procesamiento de señales biomédicas: EEG & FPGA). En particular, la transformada Z y los filtros digitales (FIR e IIR) son fundamentales para modelar, analizar y modificar señales en tiempo discreto. Por ejemplo, es común eliminar interferencias de línea base o ruido de red eléctrica (50/60 Hz) mediante filtros pasoalto o de rechazo (notch) adecuados (). Este reporte teórico describe los conceptos clave para resolver un taller de análisis de señales biomédicas, cubriendo la transformada Z, la estabilidad y región de convergencia (ROC), la representación de sistemas LTI (Lineales e Invariantes en el Tiempo) mediante polos y ceros, la respuesta al impulso, los diagramas de bloques, y el diseño de filtros digitales FIR e IIR (incluyendo métodos de ventaneo y transformación bilineal). Se incluyen ejemplos prácticos en Python (usando numpy y scipy) para ilustrar implementaciones, con un claro enfoque en aplicaciones biomédicas como el filtrado de señales ECG/EEG. Las explicaciones se apoyan en referencias académicas para asegurar rigor teórico.\n\n\n\nLa transformada Z convierte una señal \\(x[n]\\) de tiempo discreto en una representación en el dominio complejo. En forma bilateral, se define como:\n\\[X(z) = \\mathcal{Z}\\{x[n]\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\,z^{-n},\\]\ndonde \\(z\\) es una variable compleja \\(z = A e^{j\\omega}\\) (con \\(A=|z|\\) y \\(\\omega = \\arg(z)\\)) (Transformada Z - Wikipedia, la enciclopedia libre) (Transformada Z - Wikipedia, la enciclopedia libre). En señales causales (\\(x[n]=0\\) para \\(n&lt;0\\)), suele usarse la transformada Z unilateral definida desde \\(n=0\\) hasta \\(\\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). La transformada Z es análoga a la transformada de Laplace en sistemas continuos, y de hecho puede verse como una serie de Laurent (suma infinita de potencias) (Transformada Z - Wikipedia, la enciclopedia libre).\nRegión de Convergencia (ROC): No toda señal tiene transformada Z en forma cerrada; la serie anterior converge únicamente en ciertas regiones del plano \\(z\\). La ROC se define como el conjunto de valores de \\(z\\) para los cuales la serie converge absolutamente (Transformada Z - Wikipedia, la enciclopedia libre). En términos prácticos, la ROC es el rango de \\(z\\) donde \\(\\sum_{n=-\\infty}^{\\infty}|x[n]z^{-n}| &lt; \\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). Por ejemplo, si \\(x[n] = a^n u[n]\\) (secuencia exponencial causal con \\(u[n]\\) la escalón unidad), su transformada Z es \\(X(z) = \\frac{1}{1 - a\\,z^{-1}}\\), pero esta expresión es válida solo si \\(|z| &gt; |a|\\) (ya que la serie geométrica converge cuando \\(|a/z|&lt;1\\)). Así, la ROC en este caso es \\(|z| &gt; |a|\\). Si la señal fuera anti-causal (\\(x[n]=0\\) para \\(n&gt;0\\)), la ROC sería \\(|z| &lt; |a|\\) (convergencia hacia adentro). Si \\(x[n]\\) tiene duración finita (FIR), su transformada Z existe para todo \\(z\\neq0\\) excepto quizá puntos donde la propia definición tenga singularidades (por lo general ROC = todo el plano \\(z\\), excepto tal vez \\(z=0\\) o \\(z=\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). La ROC nunca incluye polos (donde la función \\(X(z)\\) diverge) (Transformada Z - Wikipedia, la enciclopedia libre), es típicamente un anillo o media-plano en el plano \\(z\\), y su ubicación está ligada a propiedades de la señal como causalidad y estabilidad.\nPolos y ceros: Cualquier función de transferencia discreta o transformada Z de una señal racional puede expresarse en forma de polos y ceros. Los ceros son valores de \\(z\\) que anulan \\(X(z)\\) (raíces del numerador), y los polos donde \\(X(z)\\) diverge (raíces del denominador). Por ejemplo, en \\(X(z) = \\frac{1}{1 - a z^{-1}}\\), hay un polo en \\(z=a\\) y un cero en \\(z=\\infty\\) (o equivalente, un cero de orden 1 en el origen en la función \\(X(z)\\) multiplicada por \\(z^{-1}\\)). La representación gráfica de polos y ceros en el plano \\(z\\) proporciona intuición sobre el comportamiento frecuencial: los ceros en la circunferencia unitaria (\\(|z|=1\\)) cancelan ciertas frecuencias, mientras que los polos cercanos a la circunferencia unitaria amplifican componentes espectrales cercanas a su ángulo.\nCausalidad: Un sistema LTI discreto es causal si \\(h[n]=0\\) para \\(n&lt;0\\) (su respuesta impulso es nula en tiempos negativos). En la transformada Z, esto implica que la ROC es externa, es decir, de la forma \\(|z|&gt;R\\) (convergencia hacia \\(\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). Todos los polos de un sistema causal deben estar dentro de la ROC (que para causal es exterior al polo de mayor radio) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Un detalle importante es que la ubicación de polos por sí sola no determina completamente la causalidad o estabilidad; la ROC es la que define cuál de las posibles señales con esos polos es la realizada (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por ejemplo, una misma función racional puede corresponder a un sistema causal inestable o a un sistema no causal estable, dependiendo de si la ROC se toma fuera o entre polos (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange).\nEstabilidad BIBO: Un sistema es estable (en sentido BIBO: Bounded-Input Bounded-Output) si su respuesta al impulso \\(h[n]\\) es absolutamente sumable, \\(\\sum_{n=-\\infty}^{\\infty}|h[n]| &lt; \\infty\\). Esta condición garantiza que cualquier entrada acotada produce salida acotada (BIBO stability - Wikipedia). En el dominio Z, estabilidad equivale a que la ROC de \\(H(z)\\) contenga al círculo unitario (\\(|z|=1\\)) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Para sistemas causales, esto se traduce en que todos los polos deben estar dentro del círculo unitario (ya que la ROC causal comienza fuera del polo de mayor magnitud) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por tanto, un filtro digital causal será estable si sus polos \\(p_i\\) satisfacen \\(|p_i|&lt;1\\). En sistemas no causales (e.g. acausales diseñados con filtrado hacia atrás y adelante para cancelar fase), la estabilidad puede lograrse con polos fuera del unitario siempre y cuando la ROC (un anillo) incluya el unitario (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange), aunque estos casos son menos comunes en línea real. En general, para diseño de filtros digitales asumiremos causalidad, por lo que chequear estabilidad equivale a verificar polos dentro del unitario.\nEjemplo (ECG y estabilidad): Considere un filtro pasoalto diseñado para remover la línea base de ECG definido por la diferencia \\(y[n] = x[n] - x[n-1]\\). Su función de transferencia es \\(H(z) = 1 - z^{-1}\\), con un cero en \\(z=1\\) (cancela DC) y un polo en \\(z=0\\) (simple, debido al \\(z^{-1}\\)). Este sistema es causal (diferencia causal) y su único polo \\(z=0\\) está dentro del círculo unitario, por lo que es estable. De hecho, su respuesta al impulso \\(h[n]=\\delta[n] - \\delta[n-1]\\) suma 0 en valor absoluto (sumable). Este filtro elimina componentes de muy baja frecuencia, como la deriva de línea base en un ECG (), sin inestabilidad.\n\n\n\nUn sistema LTI discreto queda caracterizado completamente por su respuesta al impulso \\(h[n]\\). Dada cualquier entrada \\(x[n]\\), la salida es la convolución discreta \\(y[n] = (x*h)[n] = \\sum_{k=-\\infty}^{\\infty} h[k]\\,x[n-k]\\). En el dominio Z, esta convolución se convierte en multiplicación: \\(Y(z) = H(z)\\,X(z)\\) (dentro de la intersección de ROC de \\(X\\) y \\(H\\)). La función de transferencia \\(H(z)\\) de un sistema LTI causal viene dada por la transformada Z de \\(h[n]\\) (unilateral). En sistemas de coeficientes constantes (difundidos en ingeniería), \\(H(z)\\) suele ser una función racional de \\(z\\):\n\\[H(z) = \\frac{B(z)}{A(z)} = \\frac{b_0 + b_1 z^{-1} + \\cdots + b_M z^{-M}}{1 + a_1 z^{-1} + \\cdots + a_N z^{-N}},\\]\ndonde \\(B(z)\\) y \\(A(z)\\) son polinomios en \\(z^{-1}\\). La razón de escribir en potencias de \\(z^{-1}\\) es para reflejar la causalidad (solo potencias no positivas de \\(z\\)). La ecuación en diferencias asociada es:\n\\[y[n] + a_1 y[n-1] + \\cdots + a_N y[n-N] = b_0 x[n] + b_1 x[n-1] + \\cdots + b_M x[n-M].\\]\nEste es el modelo típico de sistemas LTI discreto. Si \\(N=0\\) (no hay realimentación, solo ceros), el sistema es FIR (Finite Impulse Response), pues \\(h[n]\\) es de duración finita (máximo \\(M\\)). Si \\(N&gt;0\\), hay realimentación y el sistema es IIR (Infinite Impulse Response), con respuesta al impulso teóricamente infinita (aunque decreciente si es estable).\nDiagramas de bloques: Un LTI puede implementarse mediante sumas, retardos (\\(z^{-1}\\) representa un retardo de 1 muestra) y multiplicaciones por constantes. El diagrama de bloques representa visualmente la ecuación en diferencias. Por ejemplo, para un filtro IIR de segundo orden:\n\\[y[n] = -a_1 y[n-1] - a_2 y[n-2] + b_0 x[n] + b_1 x[n-1] + b_2 x[n-2],\\]\nel diagrama en forma Directa II combinaría los términos en una estructura canónica con dos bloques de retardo en la rama de realimentación y avance, sumadores para combinar las ramas, y coeficientes \\(a_i\\), \\(b_i\\). Cada polo corresponde a un lazo de realimentación (coeficientes \\(a_i\\)) y cada cero a una ramificación hacia la entrada (coeficientes \\(b_i\\)). Dibujar estos diagramas ayuda a entender la estructura interna, pero en este reporte nos enfocaremos más en el análisis matemático. Cabe destacar que el tipo de filtro (pasa-bajos, pasa-altos, etc.) puede inferirse de \\(H(z)\\): por ejemplo, si \\(H(e^{j\\omega})\\) (respuesta en frecuencia) atenúa bajas frecuencias y deja pasar altas, es pasa-altos. Un método práctico es evaluar \\(H(z)\\) en \\(z=e^{j0}\\) (DC, \\(\\omega=0\\)) y en \\(z=e^{j\\pi}\\) (Nyquist, \\(\\omega=\\pi\\)): si \\(|H(e^{j0})|=0\\) y \\(|H(e^{j\\pi})|\\approx 1\\), es pasa-altos; al revés sería pasa-bajos. Los ceros en \\(z=1\\) anulan \\(\\omega=0\\) (eliminan DC), típicos en pasa-altos (), mientras ceros en \\(z=-1\\) anulan \\(\\omega=\\pi\\) (eliminan la componente de Nyquist, típicos en pasa-bajos). Por su parte, polos cercanos a \\(z=1\\) refuerzan respuesta en bajas frecuencias; polos cercanos a \\(z=-1\\) refuerzan la alta frecuencia \\(\\pi\\). Así, el diagrama polo-cero brinda intuición: ceros sobre la circunferencia unitaria en cierto ángulo \\(\\theta_0\\) causan una notch (anulación) en la frecuencia \\(\\omega=\\theta_0\\), mientras polos cerca de la unidad en \\(\\theta_0\\) generan picos (potenciales resonancias) alrededor de esa frecuencia.\nEjemplo (Filtro notch 60 Hz): Un problema común en bioseñales es eliminar la interferencia de la red eléctrica (50/60 Hz) sobre, por ejemplo, EEG o ECG. Un filtro digital sencillo para eliminar 60 Hz (asumiendo frecuencia de muestreo \\(f_s=5000\\) Hz) es colocar ceros conjugados en \\(z = e^{\\pm j 2\\pi(60/5000)}\\). La función de transferencia resultante puede ser:\n\\[H(z) = 1 - 2\\cos(2\\pi\\frac{60}{5000})\\,z^{-1} + z^{-2}.\\]\nEste \\(H(z)\\) tiene ceros en \\(e^{\\pm j2\\pi(60/5000)}\\) que anulan exactamente la componente de 60 Hz, implementando un filtro notch. Además, es un filtro FIR (orden 2) con coeficientes simétricos, lo que le da fase lineal (importante para no deformar la forma de onda). ¿Es estable? Sí, al ser FIR no hay polos fuera del origen (solo polos en 0, con módulo 0). ¿Es causal? Sí, depende solo de muestras presentes y pasadas de la señal (\\(x[n]\\), \\(x[n-1]\\), \\(x[n-2]\\)). ¿Qué tipo de filtro es? Es un rechaza-banda estrecho centrado en 60 Hz (deja pasar el resto, pero rechaza esa frecuencia). En aplicaciones, este notch suele atenuar ruido de red sin distorsionar significativamente las señales de interés ().\n\n\n\nLos filtros FIR (Respuesta al Impulso Finita) son ampliamente utilizados en procesamiento biomédico porque pueden diseñarse para tener respuesta en fase lineal, evitando distorsión de fase en la señal filtrada (lo cual es útil para preservar la morfología de ondas ECG, por ejemplo). Una manera conceptualmente sencilla de diseñar un FIR es mediante el método de ventana (WindowFIRDesign.fm). Consiste en: (1) definir la respuesta frecuencial ideal deseada \\(H_d(e^{j\\omega})\\), (2) obtener la respuesta al impulso ideal \\(h_d[n]\\) como la transformada inversa de Fourier de \\(H_d\\), y (3) truncar \\(h_d[n]\\) (que usualmente es infinita o muy larga) mediante una función ventana \\(w[n]\\) para obtener un FIR realizable \\(h[n] = h_d[n]\\,w[n]\\).\nPor ejemplo, supongamos que queremos un filtro pasa-bajos ideal con frecuencia de corte \\(\\omega_c\\). El impulso ideal es \\(h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}\\) (un sinc) que se extiende infinitamente. Para obtener un FIR causal de longitud \\(M\\), se multiplica \\(h_d[n]\\) por una ventana \\(w[n]\\) de longitud \\(M\\) centrada apropiadamente (y a menudo se aplica un corrimiento para hacer el filtro causal). Las ventanas comúnmente utilizadas incluyen: Rectangular, Bartlett (triangular), Hann (Hanning), Hamming, Blackman, y la Kaiser (que es ajustable). Cada ventana introduce un cierto lóbulo principal en la respuesta en frecuencia (determinando la anchura de la transición) y lóbulos laterales (que determinan el ripple o atenuación en bandas de rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm).\nLas características típicas de ventanas clásicas (según Oppenheim et al. (WindowFIRDesign.fm) (WindowFIRDesign.fm)) son:\n\nRectangular: lóbulo principal más angosto (ancho \\(\\approx 4\\pi/M\\) rad) pero lóbulos laterales más altos (primer sidelobe ~\\(-13\\) dB, atenuación de rechazo $$21 dB) (WindowFIRDesign.fm). Da la transición más abrupta para un orden dado, al costo de peor rechazo de banda.\nBartlett (triangular): lóbulo principal algo más ancho (\\(\\approx 8\\pi/M\\)), sidelobes ~\\(-25\\) dB (WindowFIRDesign.fm).\nHann: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes ~\\(-31\\) dB (WindowFIRDesign.fm) (mejor rechazo que rectangular pero transiciones más suaves).\nHamming: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes \\(\\approx -41\\) dB (mínima atenuación ~53 dB en rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm). Es muy popular por su buen compromiso entre ancho de transición y rechazo en banda eliminada.\nBlackman: lóbulo principal más ancho (\\(\\approx 12\\pi/M\\)) pero sidelobes muy bajos (~\\(-57\\) dB, atenuación ~74 dB) (WindowFIRDesign.fm).\nKaiser: permite escoger un parámetro \\(\\beta\\) para controlar la atenuación de lóbulo lateral, ofreciendo flexibilidad. Aproximadamente, para lograr \\(A\\) dB de atenuación, \\(\\beta \\approx 0.1102(A-8.7)\\) (para \\(A&gt;50\\)), y el ancho de transición normalizado \\(\\Delta\\omega\\) se relaciona con el orden \\(M\\) y \\(\\beta\\) por \\(M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\\) (WindowFIRDesign.fm) (estas fórmulas provienen de aproximaciones de Kaiser y ayudan a dimensionar el filtro).\n\nEl método de ventanas es sencillo pero implica un compromiso fijo entre ancho de transición y ripple: una vez elegida la ventana, la única forma de mejorar la pendiente de corte es aumentar \\(M\\) (orden del filtro). Por ejemplo, la ventana Hamming siempre tendrá ~\\(-53\\) dB de mínimo en rechazo sin importar \\(M\\) (WindowFIRDesign.fm), pero al incrementar \\(M\\) se reducirá la anchura de transición. En contraste, la ventana rectangular logra transiciones muy rápidas con orden modesto, pero su pobre rechazo (~21 dB) la hace inadecuada si necesitamos, digamos, eliminar ruido fuerte. En señales biomédicas, suele preferirse reducir al mínimo distorsiones residuales de ruido, por lo que ventanas con mejor rechazo (Hamming, Blackman o Kaiser ajustada) son comunes.\nCálculo del orden para especificaciones dadas: Dado un requerimiento de diseño (ej. atenuación mínima de 40 dB en banda eliminada y transición de 10 Hz), podemos estimar el orden necesario. Por ejemplo, en el taller se plantea diseñar un pasa-bajos FIR con \\(f_c = 55\\) Hz (definido al nivel de \\(-6\\) dB), que alcance al menos 20 dB de atenuación a 60 Hz y &gt;40 dB más allá de 80 Hz. Esto implica una banda de transición bastante estrecha (de ~55 a 60 Hz) y un rechazo fuerte. Un enfoque sería probar varias ventanas:\n\nRectangular: probablemente no pueda dar 40 dB de rechazo (limita ~21 dB).\nHamming: puede dar ~53 dB de rechazo, suficiente, pero el ancho de transición \\(\\Delta f\\) será ~\\(\\frac{3.3}{M}\\) (en radianes normalizados, equivalente aprox. a \\(\\frac{0.26 f_s}{M}\\) en Hz para banda bilateral). Para \\(\\Delta f \\approx 5\\) Hz con \\(f_s\\) suficientemente grande, requerirá un \\(M\\) elevado.\nBlackman: daría &gt;60 dB de rechazo, pero su transición es más ancha (por ser \\(12\\pi/M\\) rad).\nKaiser: se puede ajustar para 40 dB con quizás menor \\(M\\) que Hamming, porque se elige justo la atenuación requerida y minimiza ancho de transición para ese nivel.\n\nEn el taller, se sugiere calcular el orden mínimo para cada ventana cumpliendo las specs y elegir la de menor orden. Esto implicaría usar fórmulas o tablas estándar (WindowFIRDesign.fm) (WindowFIRDesign.fm). Por ejemplo, para 40 dB de rechazo y \\(\\Delta f = 20\\) Hz (digamos entre 60 y 80 Hz), la Hamming podría necesitar \\(M \\approx \\frac{3.3\\cdot 2\\pi}{(20/f_s)2\\pi} = \\frac{3.3 f_s}{20}\\) (esta es una estimación tosca usando \\(\\Delta\\omega \\approx 8\\pi/M\\)). Si la señal es de voz muestreada a 8 kHz (caso típico, aunque aquí es biomédica a 200 Hz?), podemos obtener números específicos. En general, se podría iterar aumentando \\(M\\) y midiendo la respuesta espectral hasta que los requisitos se satisfagan.\nA modo de ilustración práctica, diseñemos un filtro FIR pasa-bajos con método del ventaneo en Python, usando scipy.signal.firwin. Por simplicidad, tomemos \\(f_s=200\\) Hz, \\(f_c=30\\) Hz, y usemos ventana de Hamming:\nimport numpy as np\nfrom scipy import signal\nfs = 200.0  # Hz\nfc = 30.0   # Hz (deseamos pasa-bajos)\nN = 51      # orden (se puede ajustar)\ntaps = signal.firwin(N, cutoff=fc, window='hamming', fs=fs)\nw, H = signal.freqz(taps, worN=8000, fs=fs)\n# Convertir respuesta a dB:\nH_db = 20*np.log10(np.abs(H))\n# Encontrar atenuación en 60 Hz:\nidx_60 = np.argmin(np.abs(w-60))\nprint(f\"Atenuación a 60Hz: {H_db[idx_60]:.2f} dB\")\n(El código anterior calcula los coeficientes FIR con ventana de Hamming y evalúa la respuesta. Se puede iterar sobre N hasta lograr &gt;40 dB en 80 Hz, etc.)\nEn general, el método de ventanas es rápido y fácil de implementar. Su principal limitación es la falta de control preciso sobre las bandas: el ripple y transición vienen determinados por la elección de ventana, no exactamente por parámetros deseados (excepto en Kaiser donde hay más control). Aún así, es muy útil en procesamiento biomédico cuando queremos filtros lineales en fase y podemos permitir órdenes relativamente altos (el costo computacional suele ser menor preocupación en aplicaciones off-line, pero en tiempo real un FIR muy largo puede introducir latencia).\n\n\n\nLos filtros IIR (Respuesta Infinita al Impulso) se suelen diseñar a partir de filtros analógicos prototipo utilizando transformaciones como la transformación bilineal. Este enfoque aprovecha décadas de diseños analógicos bien estudiados (Butterworth, Chebyshev, Elíptico, etc.) y los lleva al dominio digital asegurando estabilidad y correspondiendo frecuencias de interés.\nTransformación bilineal: Es una transformación conforme que mapea el plano-\\(s\\) (Laplace) en el plano-\\(z\\) (Z) mediante la sustitución:\n\\[ s = \\frac{2}{T}\\,\\frac{z-1}{\\,z+1\\,}, \\]\ndonde \\(T\\) es el periodo de muestreo (usualmente tomamos \\(T=1\\) para frecuencias normalizadas, o usamos \\(2/T\\) para incluir \\(f_s\\) explícitamente) (Transformación bilineal - Wikipedia, la enciclopedia libre) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esta sustitución se adopta universalmente para convertir funciones de transferencia analógicas \\(H_a(s)\\) en funciones \\(H_d(z)\\) digitales (Transformación bilineal - Wikipedia, la enciclopedia libre). La clave es que la transformación bilineal preserva la estabilidad: polos en el semiplano izquierdo (\\(\\Re(s)&lt;0\\)) mapean dentro del círculo unitario (\\(|z|&lt;1\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Así, un filtro analógico estable producirá un filtro digital estable (Transformación bilineal - Wikipedia, la enciclopedia libre). También mapea el eje \\(j\\omega\\) (eje imaginario \\(s = j\\Omega\\)) en la circunferencia unitaria (\\(z = e^{j\\omega T}\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre), aunque no linealmente en frecuencia. De hecho, existe una distorsión de la respuesta frecuencial conocida como warping: la relación entre frecuencia analógica \\(\\Omega\\) y digital \\(\\omega\\) viene dada por \\(\\omega = 2 \\arctan(\\Omega T/2)\\) (y su inversa \\(\\Omega = \\frac{2}{T}\\tan(\\omega/2)\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esto significa que la escala de frecuencias se comprime al mapear al dominio digital, especialmente conforme \\(\\omega\\) se acerca a Nyquist (\\(\\pi\\) rad/s).\nPara lidiar con el warping, en el diseño se realiza una pre-distorsión (pre-warping) de las especificaciones. Si deseamos que una frecuencia analógica \\(\\Omega_p\\) de corte corresponda exactamente a una digital \\(\\omega_p\\), calculamos \\(\\Omega_p = \\frac{2}{T}\\tan(\\omega_p/2)\\). Lo mismo para frecuencias de banda de rechazo, etc., antes de diseñar el filtro analógico. Luego aplicamos la transformación bilineal. En la práctica, las funciones auxiliares de diseño (como scipy.signal.buttord, cheb1ord, etc.) permiten ingresar especificaciones directamente en el dominio digital y hacen el prewarping internamente (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory).\nPrototipos analógicos comunes:\n\nButterworth: Magnitud con máxima planitud en banda de paso (respuesta maximally flat). No presenta ondulaciones en banda de paso ni rechazo, pero la transición es la más lenta de los tipos clásicos (11.3. Common IIR filters — Digital Signals Theory). Su función de magnitud al cuadrado es \\(|H(j\\Omega)|^2 = \\frac{1}{1 + (\\frac{\\Omega}{\\Omega_c})^{2N}}\\). Para un orden \\(N\\), la atenuación en rechazo aumenta gradualmente con la frecuencia. Útil cuando se quiere respuesta suave sin ripple.\nChebyshev Tipo I: Presenta rizado en banda de paso (ε dB de variación) pero ninguna ondulación en banda de rechazo (11.3. Common IIR filters — Digital Signals Theory). A cambio, logra una caída más abrupta que Butterworth para el mismo orden (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). La magnitud cumple \\(|H(j\\Omega)|^2 = \\frac{1}{1 + \\epsilon^2 T_N^2(\\Omega/\\Omega_c)}\\), donde \\(T_N\\) es el polinomio de Chebyshev de primer tipo (oscila entre ±1). Permite especificar ripple tolerado en pasobanda.\nChebyshev Tipo II: Lo opuesto: sin ripple en banda de paso, pero con ondulación controlada en banda de rechazo. También llamados filtros de Chebyshev inversos. Tienen una transición algo más lenta que los tipo I para igual orden, pero fase más lineal en pasobanda (al no tener ripple ahí).\nElíptico (Cauer): Permite rizado tanto en pasobanda como en rechazo (ambos controlables) (11.3. Common IIR filters — Digital Signals Theory), logrando la caída más empinada de todas las aproximaciones para un orden dado (11.3. Common IIR filters — Digital Signals Theory). Son los más eficientes en términos de orden, a costa de ripple en ambas bandas y mayor no linealidad de fase. Incluyen ceros de transmisión en la banda eliminada, lo que les da atenuación muy alta cerca de los bordes.\n\nEn resumen (11.3. Common IIR filters — Digital Signals Theory): Butterworth no tiene ripple en ninguna banda (pero pendiente menor), Chebyshev I tiene ripple en paso (no en rechazo), Chebyshev II ripple en rechazo (no en paso), y Elíptico ripple en ambas, pero transición más rápida. La Figura 1 ilustra las diferencias de respuesta en un ejemplo práctico.\n(image) Figura 1: Comparación de la respuesta en magnitud (en dB) para filtros IIR pasa-bajos diseñados con las mismas especificaciones (pasa-bajos con \\(f_{p}=3.4\\) kHz con 1 dB de ripple en banda de paso, \\(f_{s}=3.8\\) kHz con 30 dB de atenuación). El filtro elíptico (orden 3, línea roja) logra la transición más abrupta (caída más rápida alrededor de 3.4-3.8 kHz) a costa de presentar ondulaciones tanto en la banda de paso como en la de rechazo. El Chebyshev I (orden 3, línea naranja) exhibe ripple en la banda de paso pero no en la de rechazo, con una pendiente intermedia. El Butterworth (orden 4, línea amarilla) no tiene ripple en ninguna banda, pero requiere un orden mayor y su caída es más paulatina (transición más suave) (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). Todos cumplen con los requisitos (–1 dB a 3.4 kHz, –30 dB a 3.8 kHz), pero el orden mínimo necesario varía (Butterworth necesitó \\(N=4\\) mientras Chebyshev I y Elíptico lograron con \\(N=3\\)). Esto ilustra el compromiso entre pendiente de transición y ondulaciones en las distintas aproximaciones.\nEn diseño, elegir el tipo de filtro depende de la aplicación: en bioseñales, a veces se prefiere Butterworth para evitar cualquier ripple (ej. filtrar ECG sin distorsionar amplitud de componentes clínicas), otras veces un Chebyshev o Elíptico puede ser apropiado si se necesita un filtro muy selectivo (ej. aislar una banda muy estrecha de EEG) y se puede tolerar cierta variación en la ganancia de la banda útil. La fase de los IIR no es lineal, pero si la distorsión de fase es un problema (por ejemplo, desplazamiento o deformación de picos en ECG), puede mitigarse aplicando el filtro hacia adelante y hacia atrás (filtrado por procesamiento inverso con filtfilt de SciPy, logrando respuesta cero-fase a costa de procesar offline) (). En muchos casos, se pueden usar filtros IIR en tiempo real y lograr correcciones de fase si es necesario mediante técnicas de compensación o filtrado bidireccional.\nDiseño por especificaciones: Las funciones buttord, cheb1ord, cheb2ord, ellipord de Python/MATLAB calculan el orden mínimo y frecuencia de corte necesaria para cumplir especificaciones dadas (paso, rechazo, ripple). Luego butter, cheby1/2, ellip generan los coeficientes. En el taller, se plantea diseñar un pasa-bajos IIR para voz (ej. telefónica: \\(f_s=8\\) kHz, \\(f_p=3.4\\) kHz, \\(f_s=3.8\\) kHz, ripple 1 dB, atenuación 30 dB). Un proceso típico sería: usar ellipord para obtener el orden mínimo elíptico, cheb1ord para Chebyshev I, etc., comparar órdenes y elegir uno. En nuestro ejemplo de la Figura 1, ya vimos cómo Butterworth requería orden 4 frente a 3 de Chebyshev/Elíptico para la misma tarea, lo cual es común (Butterworth suele necesitar más orden para specs estrictas). Generalmente, Elíptico da el menor orden, seguido por Chebyshev, luego Butterworth (11.3. Common IIR filters — Digital Signals Theory). Sin embargo, a veces se evita Elíptico si un ripple en rechazo muy bajo es crítico (porque incluso la pequeña ondulación en banda eliminada puede ser indeseable para ciertas mediciones sensibles, aunque en la mayoría de casos biomédicos 30 dB de atenuación es suficiente sin importar un leve ripple residual).\nImplementación en Python: A continuación se ilustra cómo diseñar un filtro Chebyshev Tipo I con SciPy para cumplir especificaciones de voz:\nimport numpy as np\nfrom scipy.signal import cheb1ord, cheby1, freqz\nfs = 8000.0  # Hz\nfp = 3400.0  # Hz pasabanda\nfsb = 3800.0 # Hz stopband\nrp = 1.0     # dB ripple paso\nrs = 30.0    # dB atenuacion rechazo\nN, Wn = cheb1ord(fp, fsb, rp, rs, fs=fs)  # orden y frecuencia crítica\nb, a = cheby1(N, rp, Wn, btype='low', fs=fs)\nw, h = freqz(b, a, worN=1024, fs=fs)\n# Verificar desempeño:\nH_db = 20*np.log10(np.abs(h))\nprint(f\"Orden Chebyshev I = {N}\")\nprint(f\"Ganancia a 3.4kHz = {H_db[np.argmin(np.abs(w-3400))]:.2f} dB\")\nprint(f\"Atenuación a 3.8kHz = {H_db[np.argmin(np.abs(w-3800))]:.2f} dB\")\n(Este código calcula el orden mínimo y coeficientes de un Chebyshev I, luego evalúa la ganancia en 3.4 kHz y 3.8 kHz para verificar que esté cerca de –1 dB y –30 dB respectivamente.)\nEl resultado confirmaría el cumplimiento de especificaciones con el filtro diseñado. Del mismo modo podríamos probar ellipord/ellip y buttord/butter. Vale notar que los diseños IIR generalmente no tienen control explícito de fase lineal (la fase es no lineal e importa evaluar el impacto en la señal; a veces, se realizan calibraciones o se aplica filtrado hacia atrás como mencionado para obtener fase cero).\n\n\n\nUna vez diseñado un filtro (FIR o IIR), es crucial validar su respuesta en frecuencia para asegurarse de que cumple con los requisitos. Esto implica computar \\(H(e^{j\\omega})\\) – típicamente mediante freqz – y verificar ganancias en las bandas de paso (p.ej. pérdida de inserción o ripple) y bandas de rechazo (atenuación mínima). También se puede aplicar el filtro a señales de prueba:\n\nImpulso unitario: la salida debe ser \\(h[n]\\) (sirve para obtener la respuesta al impulso directamente).\nEscalón unitario: la salida debe aproximarse a la respuesta al escalón (integral de \\(h[n]\\)), útil para verificar estabilidad (un filtro pasaaltos, por ej., a entrada escalón debería asentarse a un valor constante, indicando que DC fue removido pero no inestabilidad creciente).\nSeñal senoidal a frecuencias críticas: por ejemplo, inyectar una senoide en la frecuencia de corte para ver si sale atenuada a ~-3 dB o -6 dB según definición; inyectar una senoide en banda eliminada para confirmar fuerte atenuación.\n\nEn contexto biomédico, se suele validar con señales reales. Por ejemplo, si diseñamos un filtro para eliminar deriva de línea base en ECG, podemos probarlo con una señal ECG con deriva artificial y comprobar que efectivamente la elimina sin distorsionar el complejo QRS.\n(image) Figura 2: Ejemplo de filtrado de un segmento de señal ECG con un filtro pasoalto para remover la deriva de línea base. En naranja se muestra el ECG original contaminado con una deriva lenta (simulada como una componente de muy baja frecuencia que causa que la línea base oscile). En amarillo se muestra la señal tras aplicar un filtro pasaaltos Butterworth de 4° orden con \\(f_c \\approx 0.5\\) Hz (aplicado con filtrado hacia adelante y atrás para lograr fase cero). Se observa que la señal filtrada se centra alrededor de cero voltios, eliminando las variaciones lentas de la línea base, mientras preserva las características importantes del ECG (picos QRS, ondas P y T) (). Este proceso mejora la calidad de la señal para análisis posterior (por ejemplo, facilitando la detección de eventos cardiacos), sin introducir distorsión apreciable en la forma de onda rápida del ECG.\nOtro ejemplo es la eliminación de interferencia de red: un filtro notch diseñado como en secciones previas se puede aplicar a una señal EEG a la que deliberadamente se le suma un seno de 50 Hz; la validación consistiría en ver el espectro antes y después (verificando que la línea de 50 Hz desaparece tras filtrar) y que la actividad EEG en otras bandas permanece intacta.\nEn el diseño de filtros FIR e IIR para voz o bioseñales, a veces se comparan métodos. Por ejemplo, en el taller se pide diseñar tanto un FIR por ventana como un IIR por transformación bilineal para ciertas especificaciones. Comparar la respuesta espectral es instructivo: un FIR puede requerir mayor orden para lograr la misma nitidez de corte que un IIR, pero tendrá fase lineal; el IIR logrará la especificación con menos coeficientes, pero introducirá dispersión de fase. Dependiendo de la aplicación, uno u otro puede ser preferible. Estudios en filtrado de ECG han encontrado, por ejemplo, que filtros IIR y FIR bien diseñados pueden ambos remover el ruido de línea base efectivamente; los IIR (como filtros Butterworth pasaaltos) pueden ser implementados en tiempo real con pocas operaciones (comp.dsp | How to write a NotchFilter procedure| page 2), mientras que FIR largos podrían introducir retardo si no se aplican con técnicas especiales. Sin embargo, los FIR lineales en fase aseguran que características como la amplitud del ST o la morfología de la onda P no se deformen ni se desplacen temporalmente, lo cual es crítico en ciertos análisis diagnósticos.\nEn resumen, la validación espectral (y temporal) de los filtros diseñados garantiza que el filtro funcione como esperado en las señales biomédicas objetivo. Se recomienda siempre verificar ganancia en banda pasante (por ej., asegurarse de que un filtro pasa-bajos no atenúe significativamente componentes importantes de la señal, salvo el ripple permitido) y atenuación en banda eliminada (asegurarse de que el ruido o interferencia objetivo realmente se reduce a niveles aceptables). Con herramientas como Python/Matlab, esta validación se realiza fácilmente visualizando la respuesta en frecuencia (como en las Figuras 1 y 2) y realizando pruebas con señales sintéticas o reales.\n\n\n\nEste reporte abordó los fundamentos teóricos necesarios para analizar y diseñar sistemas discretos aplicados a señales biomédicas. Se revisó la transformada Z y su papel en caracterizar señales y sistemas LTI, destacando la importancia de la región de convergencia, polos, ceros, causalidad y estabilidad (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). También se discutió cómo interpretar y construir diagramas de bloques a partir de ecuaciones en diferencias, algo útil para implementar filtros digitalmente. En la parte de diseño, se cubrieron dos enfoques contrastantes: filtros FIR por método de ventanas, sencillos y con fase lineal (deseable en biomédica), y filtros IIR por transformación bilineal a partir de prototipos analógicos (eficientes en orden, aunque con fase no lineal). Se compararon los principales tipos de aproximaciones analógicas (Butterworth, Chebyshev I/II, Elíptico) resaltando sus ventajas y compromisos (11.3. Common IIR filters — Digital Signals Theory).\nA lo largo del documento, se enfatizó la aplicación en señales reales: eliminar deriva de línea base con pasaaltos, suprimir interferencia de red con filtros notch, limitar el ancho de banda de voz o EEG con pasabajos, etc., todo soportado por referencias académicas y ejemplos de código. En la práctica, el ingeniero biomédico debe decidir el tipo de filtro según los requisitos clínicos: por ejemplo, ¿es más importante no distorsionar la forma de onda (fase lineal) o tener un filtro muy agudo (menor orden)? Este tipo de decisiones se facilita con la comprensión profunda de los conceptos aquí explicados.\nCon este marco teórico, se está en capacidad de abordar el taller propuesto: calcular transformadas Z y ROC de señales, analizar sistemas LTI (impulso, estabilidad, salida a entradas dadas), dibujar sus polos, ceros y estructuras, así como diseñar filtros FIR e IIR que satisfagan especificaciones dadas, especialmente dentro del contexto de procesamiento de señales biomédicas donde la fidelidad y eficacia del filtrado impactan directamente la calidad de la información diagnóstica obtenida.\nReferencias: Las referencias provistas en el texto (ej.【23】,【17】,【40】) corresponden a fuentes que respaldan y complementan los puntos discutidos, incluyendo textos de procesamiento digital de señales, artículos de investigación en filtrado de ECG/EEG, y documentación de funciones de diseño de filtros. Estas fuentes ofrecen mayor detalle para el lector interesado en profundizar en aspectos específicos. En particular, se destacan obras clásicas como Oppenheim & Schafer en diseño FIR (WindowFIRDesign.fm), y recursos modernos como libros abiertos de señales y sistemas (Transformada Z - Wikipedia, la enciclopedia libre) y tutoriales de SciPy (11.3. Common IIR filters — Digital Signals Theory) que enriquecen la comprensión teórica y práctica del procesamiento de señales biomédicas."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#introducción",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#introducción",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "El procesamiento digital de señales biomédicas (como ECG y EEG) emplea herramientas matemáticas para analizar y mejorar la calidad de estas señales, extrayendo información útil para diagnóstico y monitoreo clínico (Procesamiento de señales biomédicas: EEG & FPGA). En particular, la transformada Z y los filtros digitales (FIR e IIR) son fundamentales para modelar, analizar y modificar señales en tiempo discreto. Por ejemplo, es común eliminar interferencias de línea base o ruido de red eléctrica (50/60 Hz) mediante filtros pasoalto o de rechazo (notch) adecuados (). Este reporte teórico describe los conceptos clave para resolver un taller de análisis de señales biomédicas, cubriendo la transformada Z, la estabilidad y región de convergencia (ROC), la representación de sistemas LTI (Lineales e Invariantes en el Tiempo) mediante polos y ceros, la respuesta al impulso, los diagramas de bloques, y el diseño de filtros digitales FIR e IIR (incluyendo métodos de ventaneo y transformación bilineal). Se incluyen ejemplos prácticos en Python (usando numpy y scipy) para ilustrar implementaciones, con un claro enfoque en aplicaciones biomédicas como el filtrado de señales ECG/EEG. Las explicaciones se apoyan en referencias académicas para asegurar rigor teórico."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#transformada-z-y-sistemas-lti-discretos",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#transformada-z-y-sistemas-lti-discretos",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "La transformada Z convierte una señal \\(x[n]\\) de tiempo discreto en una representación en el dominio complejo. En forma bilateral, se define como:\n\\[X(z) = \\mathcal{Z}\\{x[n]\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\,z^{-n},\\]\ndonde \\(z\\) es una variable compleja \\(z = A e^{j\\omega}\\) (con \\(A=|z|\\) y \\(\\omega = \\arg(z)\\)) (Transformada Z - Wikipedia, la enciclopedia libre) (Transformada Z - Wikipedia, la enciclopedia libre). En señales causales (\\(x[n]=0\\) para \\(n&lt;0\\)), suele usarse la transformada Z unilateral definida desde \\(n=0\\) hasta \\(\\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). La transformada Z es análoga a la transformada de Laplace en sistemas continuos, y de hecho puede verse como una serie de Laurent (suma infinita de potencias) (Transformada Z - Wikipedia, la enciclopedia libre).\nRegión de Convergencia (ROC): No toda señal tiene transformada Z en forma cerrada; la serie anterior converge únicamente en ciertas regiones del plano \\(z\\). La ROC se define como el conjunto de valores de \\(z\\) para los cuales la serie converge absolutamente (Transformada Z - Wikipedia, la enciclopedia libre). En términos prácticos, la ROC es el rango de \\(z\\) donde \\(\\sum_{n=-\\infty}^{\\infty}|x[n]z^{-n}| &lt; \\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). Por ejemplo, si \\(x[n] = a^n u[n]\\) (secuencia exponencial causal con \\(u[n]\\) la escalón unidad), su transformada Z es \\(X(z) = \\frac{1}{1 - a\\,z^{-1}}\\), pero esta expresión es válida solo si \\(|z| &gt; |a|\\) (ya que la serie geométrica converge cuando \\(|a/z|&lt;1\\)). Así, la ROC en este caso es \\(|z| &gt; |a|\\). Si la señal fuera anti-causal (\\(x[n]=0\\) para \\(n&gt;0\\)), la ROC sería \\(|z| &lt; |a|\\) (convergencia hacia adentro). Si \\(x[n]\\) tiene duración finita (FIR), su transformada Z existe para todo \\(z\\neq0\\) excepto quizá puntos donde la propia definición tenga singularidades (por lo general ROC = todo el plano \\(z\\), excepto tal vez \\(z=0\\) o \\(z=\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). La ROC nunca incluye polos (donde la función \\(X(z)\\) diverge) (Transformada Z - Wikipedia, la enciclopedia libre), es típicamente un anillo o media-plano en el plano \\(z\\), y su ubicación está ligada a propiedades de la señal como causalidad y estabilidad.\nPolos y ceros: Cualquier función de transferencia discreta o transformada Z de una señal racional puede expresarse en forma de polos y ceros. Los ceros son valores de \\(z\\) que anulan \\(X(z)\\) (raíces del numerador), y los polos donde \\(X(z)\\) diverge (raíces del denominador). Por ejemplo, en \\(X(z) = \\frac{1}{1 - a z^{-1}}\\), hay un polo en \\(z=a\\) y un cero en \\(z=\\infty\\) (o equivalente, un cero de orden 1 en el origen en la función \\(X(z)\\) multiplicada por \\(z^{-1}\\)). La representación gráfica de polos y ceros en el plano \\(z\\) proporciona intuición sobre el comportamiento frecuencial: los ceros en la circunferencia unitaria (\\(|z|=1\\)) cancelan ciertas frecuencias, mientras que los polos cercanos a la circunferencia unitaria amplifican componentes espectrales cercanas a su ángulo.\nCausalidad: Un sistema LTI discreto es causal si \\(h[n]=0\\) para \\(n&lt;0\\) (su respuesta impulso es nula en tiempos negativos). En la transformada Z, esto implica que la ROC es externa, es decir, de la forma \\(|z|&gt;R\\) (convergencia hacia \\(\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). Todos los polos de un sistema causal deben estar dentro de la ROC (que para causal es exterior al polo de mayor radio) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Un detalle importante es que la ubicación de polos por sí sola no determina completamente la causalidad o estabilidad; la ROC es la que define cuál de las posibles señales con esos polos es la realizada (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por ejemplo, una misma función racional puede corresponder a un sistema causal inestable o a un sistema no causal estable, dependiendo de si la ROC se toma fuera o entre polos (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange).\nEstabilidad BIBO: Un sistema es estable (en sentido BIBO: Bounded-Input Bounded-Output) si su respuesta al impulso \\(h[n]\\) es absolutamente sumable, \\(\\sum_{n=-\\infty}^{\\infty}|h[n]| &lt; \\infty\\). Esta condición garantiza que cualquier entrada acotada produce salida acotada (BIBO stability - Wikipedia). En el dominio Z, estabilidad equivale a que la ROC de \\(H(z)\\) contenga al círculo unitario (\\(|z|=1\\)) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Para sistemas causales, esto se traduce en que todos los polos deben estar dentro del círculo unitario (ya que la ROC causal comienza fuera del polo de mayor magnitud) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por tanto, un filtro digital causal será estable si sus polos \\(p_i\\) satisfacen \\(|p_i|&lt;1\\). En sistemas no causales (e.g. acausales diseñados con filtrado hacia atrás y adelante para cancelar fase), la estabilidad puede lograrse con polos fuera del unitario siempre y cuando la ROC (un anillo) incluya el unitario (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange), aunque estos casos son menos comunes en línea real. En general, para diseño de filtros digitales asumiremos causalidad, por lo que chequear estabilidad equivale a verificar polos dentro del unitario.\nEjemplo (ECG y estabilidad): Considere un filtro pasoalto diseñado para remover la línea base de ECG definido por la diferencia \\(y[n] = x[n] - x[n-1]\\). Su función de transferencia es \\(H(z) = 1 - z^{-1}\\), con un cero en \\(z=1\\) (cancela DC) y un polo en \\(z=0\\) (simple, debido al \\(z^{-1}\\)). Este sistema es causal (diferencia causal) y su único polo \\(z=0\\) está dentro del círculo unitario, por lo que es estable. De hecho, su respuesta al impulso \\(h[n]=\\delta[n] - \\delta[n-1]\\) suma 0 en valor absoluto (sumable). Este filtro elimina componentes de muy baja frecuencia, como la deriva de línea base en un ECG (), sin inestabilidad."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#análisis-de-sistemas-lti-en-tiempo-discreto",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#análisis-de-sistemas-lti-en-tiempo-discreto",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Un sistema LTI discreto queda caracterizado completamente por su respuesta al impulso \\(h[n]\\). Dada cualquier entrada \\(x[n]\\), la salida es la convolución discreta \\(y[n] = (x*h)[n] = \\sum_{k=-\\infty}^{\\infty} h[k]\\,x[n-k]\\). En el dominio Z, esta convolución se convierte en multiplicación: \\(Y(z) = H(z)\\,X(z)\\) (dentro de la intersección de ROC de \\(X\\) y \\(H\\)). La función de transferencia \\(H(z)\\) de un sistema LTI causal viene dada por la transformada Z de \\(h[n]\\) (unilateral). En sistemas de coeficientes constantes (difundidos en ingeniería), \\(H(z)\\) suele ser una función racional de \\(z\\):\n\\[H(z) = \\frac{B(z)}{A(z)} = \\frac{b_0 + b_1 z^{-1} + \\cdots + b_M z^{-M}}{1 + a_1 z^{-1} + \\cdots + a_N z^{-N}},\\]\ndonde \\(B(z)\\) y \\(A(z)\\) son polinomios en \\(z^{-1}\\). La razón de escribir en potencias de \\(z^{-1}\\) es para reflejar la causalidad (solo potencias no positivas de \\(z\\)). La ecuación en diferencias asociada es:\n\\[y[n] + a_1 y[n-1] + \\cdots + a_N y[n-N] = b_0 x[n] + b_1 x[n-1] + \\cdots + b_M x[n-M].\\]\nEste es el modelo típico de sistemas LTI discreto. Si \\(N=0\\) (no hay realimentación, solo ceros), el sistema es FIR (Finite Impulse Response), pues \\(h[n]\\) es de duración finita (máximo \\(M\\)). Si \\(N&gt;0\\), hay realimentación y el sistema es IIR (Infinite Impulse Response), con respuesta al impulso teóricamente infinita (aunque decreciente si es estable).\nDiagramas de bloques: Un LTI puede implementarse mediante sumas, retardos (\\(z^{-1}\\) representa un retardo de 1 muestra) y multiplicaciones por constantes. El diagrama de bloques representa visualmente la ecuación en diferencias. Por ejemplo, para un filtro IIR de segundo orden:\n\\[y[n] = -a_1 y[n-1] - a_2 y[n-2] + b_0 x[n] + b_1 x[n-1] + b_2 x[n-2],\\]\nel diagrama en forma Directa II combinaría los términos en una estructura canónica con dos bloques de retardo en la rama de realimentación y avance, sumadores para combinar las ramas, y coeficientes \\(a_i\\), \\(b_i\\). Cada polo corresponde a un lazo de realimentación (coeficientes \\(a_i\\)) y cada cero a una ramificación hacia la entrada (coeficientes \\(b_i\\)). Dibujar estos diagramas ayuda a entender la estructura interna, pero en este reporte nos enfocaremos más en el análisis matemático. Cabe destacar que el tipo de filtro (pasa-bajos, pasa-altos, etc.) puede inferirse de \\(H(z)\\): por ejemplo, si \\(H(e^{j\\omega})\\) (respuesta en frecuencia) atenúa bajas frecuencias y deja pasar altas, es pasa-altos. Un método práctico es evaluar \\(H(z)\\) en \\(z=e^{j0}\\) (DC, \\(\\omega=0\\)) y en \\(z=e^{j\\pi}\\) (Nyquist, \\(\\omega=\\pi\\)): si \\(|H(e^{j0})|=0\\) y \\(|H(e^{j\\pi})|\\approx 1\\), es pasa-altos; al revés sería pasa-bajos. Los ceros en \\(z=1\\) anulan \\(\\omega=0\\) (eliminan DC), típicos en pasa-altos (), mientras ceros en \\(z=-1\\) anulan \\(\\omega=\\pi\\) (eliminan la componente de Nyquist, típicos en pasa-bajos). Por su parte, polos cercanos a \\(z=1\\) refuerzan respuesta en bajas frecuencias; polos cercanos a \\(z=-1\\) refuerzan la alta frecuencia \\(\\pi\\). Así, el diagrama polo-cero brinda intuición: ceros sobre la circunferencia unitaria en cierto ángulo \\(\\theta_0\\) causan una notch (anulación) en la frecuencia \\(\\omega=\\theta_0\\), mientras polos cerca de la unidad en \\(\\theta_0\\) generan picos (potenciales resonancias) alrededor de esa frecuencia.\nEjemplo (Filtro notch 60 Hz): Un problema común en bioseñales es eliminar la interferencia de la red eléctrica (50/60 Hz) sobre, por ejemplo, EEG o ECG. Un filtro digital sencillo para eliminar 60 Hz (asumiendo frecuencia de muestreo \\(f_s=5000\\) Hz) es colocar ceros conjugados en \\(z = e^{\\pm j 2\\pi(60/5000)}\\). La función de transferencia resultante puede ser:\n\\[H(z) = 1 - 2\\cos(2\\pi\\frac{60}{5000})\\,z^{-1} + z^{-2}.\\]\nEste \\(H(z)\\) tiene ceros en \\(e^{\\pm j2\\pi(60/5000)}\\) que anulan exactamente la componente de 60 Hz, implementando un filtro notch. Además, es un filtro FIR (orden 2) con coeficientes simétricos, lo que le da fase lineal (importante para no deformar la forma de onda). ¿Es estable? Sí, al ser FIR no hay polos fuera del origen (solo polos en 0, con módulo 0). ¿Es causal? Sí, depende solo de muestras presentes y pasadas de la señal (\\(x[n]\\), \\(x[n-1]\\), \\(x[n-2]\\)). ¿Qué tipo de filtro es? Es un rechaza-banda estrecho centrado en 60 Hz (deja pasar el resto, pero rechaza esa frecuencia). En aplicaciones, este notch suele atenuar ruido de red sin distorsionar significativamente las señales de interés ()."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-fir-por-el-método-de-ventanas",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-fir-por-el-método-de-ventanas",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Los filtros FIR (Respuesta al Impulso Finita) son ampliamente utilizados en procesamiento biomédico porque pueden diseñarse para tener respuesta en fase lineal, evitando distorsión de fase en la señal filtrada (lo cual es útil para preservar la morfología de ondas ECG, por ejemplo). Una manera conceptualmente sencilla de diseñar un FIR es mediante el método de ventana (WindowFIRDesign.fm). Consiste en: (1) definir la respuesta frecuencial ideal deseada \\(H_d(e^{j\\omega})\\), (2) obtener la respuesta al impulso ideal \\(h_d[n]\\) como la transformada inversa de Fourier de \\(H_d\\), y (3) truncar \\(h_d[n]\\) (que usualmente es infinita o muy larga) mediante una función ventana \\(w[n]\\) para obtener un FIR realizable \\(h[n] = h_d[n]\\,w[n]\\).\nPor ejemplo, supongamos que queremos un filtro pasa-bajos ideal con frecuencia de corte \\(\\omega_c\\). El impulso ideal es \\(h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}\\) (un sinc) que se extiende infinitamente. Para obtener un FIR causal de longitud \\(M\\), se multiplica \\(h_d[n]\\) por una ventana \\(w[n]\\) de longitud \\(M\\) centrada apropiadamente (y a menudo se aplica un corrimiento para hacer el filtro causal). Las ventanas comúnmente utilizadas incluyen: Rectangular, Bartlett (triangular), Hann (Hanning), Hamming, Blackman, y la Kaiser (que es ajustable). Cada ventana introduce un cierto lóbulo principal en la respuesta en frecuencia (determinando la anchura de la transición) y lóbulos laterales (que determinan el ripple o atenuación en bandas de rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm).\nLas características típicas de ventanas clásicas (según Oppenheim et al. (WindowFIRDesign.fm) (WindowFIRDesign.fm)) son:\n\nRectangular: lóbulo principal más angosto (ancho \\(\\approx 4\\pi/M\\) rad) pero lóbulos laterales más altos (primer sidelobe ~\\(-13\\) dB, atenuación de rechazo $$21 dB) (WindowFIRDesign.fm). Da la transición más abrupta para un orden dado, al costo de peor rechazo de banda.\nBartlett (triangular): lóbulo principal algo más ancho (\\(\\approx 8\\pi/M\\)), sidelobes ~\\(-25\\) dB (WindowFIRDesign.fm).\nHann: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes ~\\(-31\\) dB (WindowFIRDesign.fm) (mejor rechazo que rectangular pero transiciones más suaves).\nHamming: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes \\(\\approx -41\\) dB (mínima atenuación ~53 dB en rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm). Es muy popular por su buen compromiso entre ancho de transición y rechazo en banda eliminada.\nBlackman: lóbulo principal más ancho (\\(\\approx 12\\pi/M\\)) pero sidelobes muy bajos (~\\(-57\\) dB, atenuación ~74 dB) (WindowFIRDesign.fm).\nKaiser: permite escoger un parámetro \\(\\beta\\) para controlar la atenuación de lóbulo lateral, ofreciendo flexibilidad. Aproximadamente, para lograr \\(A\\) dB de atenuación, \\(\\beta \\approx 0.1102(A-8.7)\\) (para \\(A&gt;50\\)), y el ancho de transición normalizado \\(\\Delta\\omega\\) se relaciona con el orden \\(M\\) y \\(\\beta\\) por \\(M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\\) (WindowFIRDesign.fm) (estas fórmulas provienen de aproximaciones de Kaiser y ayudan a dimensionar el filtro).\n\nEl método de ventanas es sencillo pero implica un compromiso fijo entre ancho de transición y ripple: una vez elegida la ventana, la única forma de mejorar la pendiente de corte es aumentar \\(M\\) (orden del filtro). Por ejemplo, la ventana Hamming siempre tendrá ~\\(-53\\) dB de mínimo en rechazo sin importar \\(M\\) (WindowFIRDesign.fm), pero al incrementar \\(M\\) se reducirá la anchura de transición. En contraste, la ventana rectangular logra transiciones muy rápidas con orden modesto, pero su pobre rechazo (~21 dB) la hace inadecuada si necesitamos, digamos, eliminar ruido fuerte. En señales biomédicas, suele preferirse reducir al mínimo distorsiones residuales de ruido, por lo que ventanas con mejor rechazo (Hamming, Blackman o Kaiser ajustada) son comunes.\nCálculo del orden para especificaciones dadas: Dado un requerimiento de diseño (ej. atenuación mínima de 40 dB en banda eliminada y transición de 10 Hz), podemos estimar el orden necesario. Por ejemplo, en el taller se plantea diseñar un pasa-bajos FIR con \\(f_c = 55\\) Hz (definido al nivel de \\(-6\\) dB), que alcance al menos 20 dB de atenuación a 60 Hz y &gt;40 dB más allá de 80 Hz. Esto implica una banda de transición bastante estrecha (de ~55 a 60 Hz) y un rechazo fuerte. Un enfoque sería probar varias ventanas:\n\nRectangular: probablemente no pueda dar 40 dB de rechazo (limita ~21 dB).\nHamming: puede dar ~53 dB de rechazo, suficiente, pero el ancho de transición \\(\\Delta f\\) será ~\\(\\frac{3.3}{M}\\) (en radianes normalizados, equivalente aprox. a \\(\\frac{0.26 f_s}{M}\\) en Hz para banda bilateral). Para \\(\\Delta f \\approx 5\\) Hz con \\(f_s\\) suficientemente grande, requerirá un \\(M\\) elevado.\nBlackman: daría &gt;60 dB de rechazo, pero su transición es más ancha (por ser \\(12\\pi/M\\) rad).\nKaiser: se puede ajustar para 40 dB con quizás menor \\(M\\) que Hamming, porque se elige justo la atenuación requerida y minimiza ancho de transición para ese nivel.\n\nEn el taller, se sugiere calcular el orden mínimo para cada ventana cumpliendo las specs y elegir la de menor orden. Esto implicaría usar fórmulas o tablas estándar (WindowFIRDesign.fm) (WindowFIRDesign.fm). Por ejemplo, para 40 dB de rechazo y \\(\\Delta f = 20\\) Hz (digamos entre 60 y 80 Hz), la Hamming podría necesitar \\(M \\approx \\frac{3.3\\cdot 2\\pi}{(20/f_s)2\\pi} = \\frac{3.3 f_s}{20}\\) (esta es una estimación tosca usando \\(\\Delta\\omega \\approx 8\\pi/M\\)). Si la señal es de voz muestreada a 8 kHz (caso típico, aunque aquí es biomédica a 200 Hz?), podemos obtener números específicos. En general, se podría iterar aumentando \\(M\\) y midiendo la respuesta espectral hasta que los requisitos se satisfagan.\nA modo de ilustración práctica, diseñemos un filtro FIR pasa-bajos con método del ventaneo en Python, usando scipy.signal.firwin. Por simplicidad, tomemos \\(f_s=200\\) Hz, \\(f_c=30\\) Hz, y usemos ventana de Hamming:\nimport numpy as np\nfrom scipy import signal\nfs = 200.0  # Hz\nfc = 30.0   # Hz (deseamos pasa-bajos)\nN = 51      # orden (se puede ajustar)\ntaps = signal.firwin(N, cutoff=fc, window='hamming', fs=fs)\nw, H = signal.freqz(taps, worN=8000, fs=fs)\n# Convertir respuesta a dB:\nH_db = 20*np.log10(np.abs(H))\n# Encontrar atenuación en 60 Hz:\nidx_60 = np.argmin(np.abs(w-60))\nprint(f\"Atenuación a 60Hz: {H_db[idx_60]:.2f} dB\")\n(El código anterior calcula los coeficientes FIR con ventana de Hamming y evalúa la respuesta. Se puede iterar sobre N hasta lograr &gt;40 dB en 80 Hz, etc.)\nEn general, el método de ventanas es rápido y fácil de implementar. Su principal limitación es la falta de control preciso sobre las bandas: el ripple y transición vienen determinados por la elección de ventana, no exactamente por parámetros deseados (excepto en Kaiser donde hay más control). Aún así, es muy útil en procesamiento biomédico cuando queremos filtros lineales en fase y podemos permitir órdenes relativamente altos (el costo computacional suele ser menor preocupación en aplicaciones off-line, pero en tiempo real un FIR muy largo puede introducir latencia)."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-iir-por-transformación-bilineal",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-iir-por-transformación-bilineal",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Los filtros IIR (Respuesta Infinita al Impulso) se suelen diseñar a partir de filtros analógicos prototipo utilizando transformaciones como la transformación bilineal. Este enfoque aprovecha décadas de diseños analógicos bien estudiados (Butterworth, Chebyshev, Elíptico, etc.) y los lleva al dominio digital asegurando estabilidad y correspondiendo frecuencias de interés.\nTransformación bilineal: Es una transformación conforme que mapea el plano-\\(s\\) (Laplace) en el plano-\\(z\\) (Z) mediante la sustitución:\n\\[ s = \\frac{2}{T}\\,\\frac{z-1}{\\,z+1\\,}, \\]\ndonde \\(T\\) es el periodo de muestreo (usualmente tomamos \\(T=1\\) para frecuencias normalizadas, o usamos \\(2/T\\) para incluir \\(f_s\\) explícitamente) (Transformación bilineal - Wikipedia, la enciclopedia libre) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esta sustitución se adopta universalmente para convertir funciones de transferencia analógicas \\(H_a(s)\\) en funciones \\(H_d(z)\\) digitales (Transformación bilineal - Wikipedia, la enciclopedia libre). La clave es que la transformación bilineal preserva la estabilidad: polos en el semiplano izquierdo (\\(\\Re(s)&lt;0\\)) mapean dentro del círculo unitario (\\(|z|&lt;1\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Así, un filtro analógico estable producirá un filtro digital estable (Transformación bilineal - Wikipedia, la enciclopedia libre). También mapea el eje \\(j\\omega\\) (eje imaginario \\(s = j\\Omega\\)) en la circunferencia unitaria (\\(z = e^{j\\omega T}\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre), aunque no linealmente en frecuencia. De hecho, existe una distorsión de la respuesta frecuencial conocida como warping: la relación entre frecuencia analógica \\(\\Omega\\) y digital \\(\\omega\\) viene dada por \\(\\omega = 2 \\arctan(\\Omega T/2)\\) (y su inversa \\(\\Omega = \\frac{2}{T}\\tan(\\omega/2)\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esto significa que la escala de frecuencias se comprime al mapear al dominio digital, especialmente conforme \\(\\omega\\) se acerca a Nyquist (\\(\\pi\\) rad/s).\nPara lidiar con el warping, en el diseño se realiza una pre-distorsión (pre-warping) de las especificaciones. Si deseamos que una frecuencia analógica \\(\\Omega_p\\) de corte corresponda exactamente a una digital \\(\\omega_p\\), calculamos \\(\\Omega_p = \\frac{2}{T}\\tan(\\omega_p/2)\\). Lo mismo para frecuencias de banda de rechazo, etc., antes de diseñar el filtro analógico. Luego aplicamos la transformación bilineal. En la práctica, las funciones auxiliares de diseño (como scipy.signal.buttord, cheb1ord, etc.) permiten ingresar especificaciones directamente en el dominio digital y hacen el prewarping internamente (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory).\nPrototipos analógicos comunes:\n\nButterworth: Magnitud con máxima planitud en banda de paso (respuesta maximally flat). No presenta ondulaciones en banda de paso ni rechazo, pero la transición es la más lenta de los tipos clásicos (11.3. Common IIR filters — Digital Signals Theory). Su función de magnitud al cuadrado es \\(|H(j\\Omega)|^2 = \\frac{1}{1 + (\\frac{\\Omega}{\\Omega_c})^{2N}}\\). Para un orden \\(N\\), la atenuación en rechazo aumenta gradualmente con la frecuencia. Útil cuando se quiere respuesta suave sin ripple.\nChebyshev Tipo I: Presenta rizado en banda de paso (ε dB de variación) pero ninguna ondulación en banda de rechazo (11.3. Common IIR filters — Digital Signals Theory). A cambio, logra una caída más abrupta que Butterworth para el mismo orden (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). La magnitud cumple \\(|H(j\\Omega)|^2 = \\frac{1}{1 + \\epsilon^2 T_N^2(\\Omega/\\Omega_c)}\\), donde \\(T_N\\) es el polinomio de Chebyshev de primer tipo (oscila entre ±1). Permite especificar ripple tolerado en pasobanda.\nChebyshev Tipo II: Lo opuesto: sin ripple en banda de paso, pero con ondulación controlada en banda de rechazo. También llamados filtros de Chebyshev inversos. Tienen una transición algo más lenta que los tipo I para igual orden, pero fase más lineal en pasobanda (al no tener ripple ahí).\nElíptico (Cauer): Permite rizado tanto en pasobanda como en rechazo (ambos controlables) (11.3. Common IIR filters — Digital Signals Theory), logrando la caída más empinada de todas las aproximaciones para un orden dado (11.3. Common IIR filters — Digital Signals Theory). Son los más eficientes en términos de orden, a costa de ripple en ambas bandas y mayor no linealidad de fase. Incluyen ceros de transmisión en la banda eliminada, lo que les da atenuación muy alta cerca de los bordes.\n\nEn resumen (11.3. Common IIR filters — Digital Signals Theory): Butterworth no tiene ripple en ninguna banda (pero pendiente menor), Chebyshev I tiene ripple en paso (no en rechazo), Chebyshev II ripple en rechazo (no en paso), y Elíptico ripple en ambas, pero transición más rápida. La Figura 1 ilustra las diferencias de respuesta en un ejemplo práctico.\n(image) Figura 1: Comparación de la respuesta en magnitud (en dB) para filtros IIR pasa-bajos diseñados con las mismas especificaciones (pasa-bajos con \\(f_{p}=3.4\\) kHz con 1 dB de ripple en banda de paso, \\(f_{s}=3.8\\) kHz con 30 dB de atenuación). El filtro elíptico (orden 3, línea roja) logra la transición más abrupta (caída más rápida alrededor de 3.4-3.8 kHz) a costa de presentar ondulaciones tanto en la banda de paso como en la de rechazo. El Chebyshev I (orden 3, línea naranja) exhibe ripple en la banda de paso pero no en la de rechazo, con una pendiente intermedia. El Butterworth (orden 4, línea amarilla) no tiene ripple en ninguna banda, pero requiere un orden mayor y su caída es más paulatina (transición más suave) (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). Todos cumplen con los requisitos (–1 dB a 3.4 kHz, –30 dB a 3.8 kHz), pero el orden mínimo necesario varía (Butterworth necesitó \\(N=4\\) mientras Chebyshev I y Elíptico lograron con \\(N=3\\)). Esto ilustra el compromiso entre pendiente de transición y ondulaciones en las distintas aproximaciones.\nEn diseño, elegir el tipo de filtro depende de la aplicación: en bioseñales, a veces se prefiere Butterworth para evitar cualquier ripple (ej. filtrar ECG sin distorsionar amplitud de componentes clínicas), otras veces un Chebyshev o Elíptico puede ser apropiado si se necesita un filtro muy selectivo (ej. aislar una banda muy estrecha de EEG) y se puede tolerar cierta variación en la ganancia de la banda útil. La fase de los IIR no es lineal, pero si la distorsión de fase es un problema (por ejemplo, desplazamiento o deformación de picos en ECG), puede mitigarse aplicando el filtro hacia adelante y hacia atrás (filtrado por procesamiento inverso con filtfilt de SciPy, logrando respuesta cero-fase a costa de procesar offline) (). En muchos casos, se pueden usar filtros IIR en tiempo real y lograr correcciones de fase si es necesario mediante técnicas de compensación o filtrado bidireccional.\nDiseño por especificaciones: Las funciones buttord, cheb1ord, cheb2ord, ellipord de Python/MATLAB calculan el orden mínimo y frecuencia de corte necesaria para cumplir especificaciones dadas (paso, rechazo, ripple). Luego butter, cheby1/2, ellip generan los coeficientes. En el taller, se plantea diseñar un pasa-bajos IIR para voz (ej. telefónica: \\(f_s=8\\) kHz, \\(f_p=3.4\\) kHz, \\(f_s=3.8\\) kHz, ripple 1 dB, atenuación 30 dB). Un proceso típico sería: usar ellipord para obtener el orden mínimo elíptico, cheb1ord para Chebyshev I, etc., comparar órdenes y elegir uno. En nuestro ejemplo de la Figura 1, ya vimos cómo Butterworth requería orden 4 frente a 3 de Chebyshev/Elíptico para la misma tarea, lo cual es común (Butterworth suele necesitar más orden para specs estrictas). Generalmente, Elíptico da el menor orden, seguido por Chebyshev, luego Butterworth (11.3. Common IIR filters — Digital Signals Theory). Sin embargo, a veces se evita Elíptico si un ripple en rechazo muy bajo es crítico (porque incluso la pequeña ondulación en banda eliminada puede ser indeseable para ciertas mediciones sensibles, aunque en la mayoría de casos biomédicos 30 dB de atenuación es suficiente sin importar un leve ripple residual).\nImplementación en Python: A continuación se ilustra cómo diseñar un filtro Chebyshev Tipo I con SciPy para cumplir especificaciones de voz:\nimport numpy as np\nfrom scipy.signal import cheb1ord, cheby1, freqz\nfs = 8000.0  # Hz\nfp = 3400.0  # Hz pasabanda\nfsb = 3800.0 # Hz stopband\nrp = 1.0     # dB ripple paso\nrs = 30.0    # dB atenuacion rechazo\nN, Wn = cheb1ord(fp, fsb, rp, rs, fs=fs)  # orden y frecuencia crítica\nb, a = cheby1(N, rp, Wn, btype='low', fs=fs)\nw, h = freqz(b, a, worN=1024, fs=fs)\n# Verificar desempeño:\nH_db = 20*np.log10(np.abs(h))\nprint(f\"Orden Chebyshev I = {N}\")\nprint(f\"Ganancia a 3.4kHz = {H_db[np.argmin(np.abs(w-3400))]:.2f} dB\")\nprint(f\"Atenuación a 3.8kHz = {H_db[np.argmin(np.abs(w-3800))]:.2f} dB\")\n(Este código calcula el orden mínimo y coeficientes de un Chebyshev I, luego evalúa la ganancia en 3.4 kHz y 3.8 kHz para verificar que esté cerca de –1 dB y –30 dB respectivamente.)\nEl resultado confirmaría el cumplimiento de especificaciones con el filtro diseñado. Del mismo modo podríamos probar ellipord/ellip y buttord/butter. Vale notar que los diseños IIR generalmente no tienen control explícito de fase lineal (la fase es no lineal e importa evaluar el impacto en la señal; a veces, se realizan calibraciones o se aplica filtrado hacia atrás como mencionado para obtener fase cero)."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#validación-espectral-y-aplicaciones-en-señales-biomédicas",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#validación-espectral-y-aplicaciones-en-señales-biomédicas",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Una vez diseñado un filtro (FIR o IIR), es crucial validar su respuesta en frecuencia para asegurarse de que cumple con los requisitos. Esto implica computar \\(H(e^{j\\omega})\\) – típicamente mediante freqz – y verificar ganancias en las bandas de paso (p.ej. pérdida de inserción o ripple) y bandas de rechazo (atenuación mínima). También se puede aplicar el filtro a señales de prueba:\n\nImpulso unitario: la salida debe ser \\(h[n]\\) (sirve para obtener la respuesta al impulso directamente).\nEscalón unitario: la salida debe aproximarse a la respuesta al escalón (integral de \\(h[n]\\)), útil para verificar estabilidad (un filtro pasaaltos, por ej., a entrada escalón debería asentarse a un valor constante, indicando que DC fue removido pero no inestabilidad creciente).\nSeñal senoidal a frecuencias críticas: por ejemplo, inyectar una senoide en la frecuencia de corte para ver si sale atenuada a ~-3 dB o -6 dB según definición; inyectar una senoide en banda eliminada para confirmar fuerte atenuación.\n\nEn contexto biomédico, se suele validar con señales reales. Por ejemplo, si diseñamos un filtro para eliminar deriva de línea base en ECG, podemos probarlo con una señal ECG con deriva artificial y comprobar que efectivamente la elimina sin distorsionar el complejo QRS.\n(image) Figura 2: Ejemplo de filtrado de un segmento de señal ECG con un filtro pasoalto para remover la deriva de línea base. En naranja se muestra el ECG original contaminado con una deriva lenta (simulada como una componente de muy baja frecuencia que causa que la línea base oscile). En amarillo se muestra la señal tras aplicar un filtro pasaaltos Butterworth de 4° orden con \\(f_c \\approx 0.5\\) Hz (aplicado con filtrado hacia adelante y atrás para lograr fase cero). Se observa que la señal filtrada se centra alrededor de cero voltios, eliminando las variaciones lentas de la línea base, mientras preserva las características importantes del ECG (picos QRS, ondas P y T) (). Este proceso mejora la calidad de la señal para análisis posterior (por ejemplo, facilitando la detección de eventos cardiacos), sin introducir distorsión apreciable en la forma de onda rápida del ECG.\nOtro ejemplo es la eliminación de interferencia de red: un filtro notch diseñado como en secciones previas se puede aplicar a una señal EEG a la que deliberadamente se le suma un seno de 50 Hz; la validación consistiría en ver el espectro antes y después (verificando que la línea de 50 Hz desaparece tras filtrar) y que la actividad EEG en otras bandas permanece intacta.\nEn el diseño de filtros FIR e IIR para voz o bioseñales, a veces se comparan métodos. Por ejemplo, en el taller se pide diseñar tanto un FIR por ventana como un IIR por transformación bilineal para ciertas especificaciones. Comparar la respuesta espectral es instructivo: un FIR puede requerir mayor orden para lograr la misma nitidez de corte que un IIR, pero tendrá fase lineal; el IIR logrará la especificación con menos coeficientes, pero introducirá dispersión de fase. Dependiendo de la aplicación, uno u otro puede ser preferible. Estudios en filtrado de ECG han encontrado, por ejemplo, que filtros IIR y FIR bien diseñados pueden ambos remover el ruido de línea base efectivamente; los IIR (como filtros Butterworth pasaaltos) pueden ser implementados en tiempo real con pocas operaciones (comp.dsp | How to write a NotchFilter procedure| page 2), mientras que FIR largos podrían introducir retardo si no se aplican con técnicas especiales. Sin embargo, los FIR lineales en fase aseguran que características como la amplitud del ST o la morfología de la onda P no se deformen ni se desplacen temporalmente, lo cual es crítico en ciertos análisis diagnósticos.\nEn resumen, la validación espectral (y temporal) de los filtros diseñados garantiza que el filtro funcione como esperado en las señales biomédicas objetivo. Se recomienda siempre verificar ganancia en banda pasante (por ej., asegurarse de que un filtro pasa-bajos no atenúe significativamente componentes importantes de la señal, salvo el ripple permitido) y atenuación en banda eliminada (asegurarse de que el ruido o interferencia objetivo realmente se reduce a niveles aceptables). Con herramientas como Python/Matlab, esta validación se realiza fácilmente visualizando la respuesta en frecuencia (como en las Figuras 1 y 2) y realizando pruebas con señales sintéticas o reales."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#conclusiones",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#conclusiones",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Este reporte abordó los fundamentos teóricos necesarios para analizar y diseñar sistemas discretos aplicados a señales biomédicas. Se revisó la transformada Z y su papel en caracterizar señales y sistemas LTI, destacando la importancia de la región de convergencia, polos, ceros, causalidad y estabilidad (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). También se discutió cómo interpretar y construir diagramas de bloques a partir de ecuaciones en diferencias, algo útil para implementar filtros digitalmente. En la parte de diseño, se cubrieron dos enfoques contrastantes: filtros FIR por método de ventanas, sencillos y con fase lineal (deseable en biomédica), y filtros IIR por transformación bilineal a partir de prototipos analógicos (eficientes en orden, aunque con fase no lineal). Se compararon los principales tipos de aproximaciones analógicas (Butterworth, Chebyshev I/II, Elíptico) resaltando sus ventajas y compromisos (11.3. Common IIR filters — Digital Signals Theory).\nA lo largo del documento, se enfatizó la aplicación en señales reales: eliminar deriva de línea base con pasaaltos, suprimir interferencia de red con filtros notch, limitar el ancho de banda de voz o EEG con pasabajos, etc., todo soportado por referencias académicas y ejemplos de código. En la práctica, el ingeniero biomédico debe decidir el tipo de filtro según los requisitos clínicos: por ejemplo, ¿es más importante no distorsionar la forma de onda (fase lineal) o tener un filtro muy agudo (menor orden)? Este tipo de decisiones se facilita con la comprensión profunda de los conceptos aquí explicados.\nCon este marco teórico, se está en capacidad de abordar el taller propuesto: calcular transformadas Z y ROC de señales, analizar sistemas LTI (impulso, estabilidad, salida a entradas dadas), dibujar sus polos, ceros y estructuras, así como diseñar filtros FIR e IIR que satisfagan especificaciones dadas, especialmente dentro del contexto de procesamiento de señales biomédicas donde la fidelidad y eficacia del filtrado impactan directamente la calidad de la información diagnóstica obtenida.\nReferencias: Las referencias provistas en el texto (ej.【23】,【17】,【40】) corresponden a fuentes que respaldan y complementan los puntos discutidos, incluyendo textos de procesamiento digital de señales, artículos de investigación en filtrado de ECG/EEG, y documentación de funciones de diseño de filtros. Estas fuentes ofrecen mayor detalle para el lector interesado en profundizar en aspectos específicos. En particular, se destacan obras clásicas como Oppenheim & Schafer en diseño FIR (WindowFIRDesign.fm), y recursos modernos como libros abiertos de señales y sistemas (Transformada Z - Wikipedia, la enciclopedia libre) y tutoriales de SciPy (11.3. Common IIR filters — Digital Signals Theory) que enriquecen la comprensión teórica y práctica del procesamiento de señales biomédicas."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html",
    "title": "Sampling and quantization",
    "section": "",
    "text": "This guide recaps essentials of sampling and quantization for biomedical acquisition chains. Emphasis is on concrete design choices for $f_s$, anti-alias cutoff, bit depth $b$, and input range, with clinical mini-cases. Primary/secondary sources: Oppenheim 2e (ISBN: 978-0138147570), Shannon 1949 (DOI: 10.1109/JRPROC.1949.232969), Jayant & Noll (ISBN: 0-13-211913-7), Webster MI 4e (ISBN: 978-0471676003).\n\n\n\n\nNyquist: $f_s2B$ where $B$ is the highest significant frequency (Shannon 1949).\nSampling model: $T_s=1/f_s$, $x_s(t)=_{n}x(nT_s),(t-nT_s)$ (Oppenheim 2e).\nAnti-aliasing: analog LPF with $f_c&lt;f_s/2$ plus guard band (Oppenheim 2e).\nQuantizer: uniform, range $[V_{},V_{}]$, step $=$ (Oppenheim 2e).\nNoise model: $_q^2=$; full-scale sine $_{},b+1.76$ (Jayant & Noll).\nCompanding (telemetry): $$-law/$A$-law to emphasize small amplitudes before quantization (Jayant & Noll; ITU-T G.711).\n\n\n\n\nGoal: Choose $f_s$, $f_c$, $b$, and input range for diagnostic ECG.\n\nBandwidth: adopt $B $ (Webster MI 4e).\nSampling: choose $f_s=500 $ to satisfy $f_s2B$ with guard (Shannon 1949).\nAnti-alias: set $f_c $ (transition to $f_s/2=250 $).\nRange: $ $ to cover tall QRS and baseline drift after high-pass.\nBits: $b=12$ is common; compute $$ and SNR below.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nVmin, Vmax = -5e-3, 5e-3\nrng = Vmax - Vmin\nbits = np.arange(10, 17)\nDelta = rng / (2**bits)\nsnr_db = 6.02*bits + 1.76  # full-scale sine (Jayant & Noll)\n\nprint(f\"12-bit Δ = {Delta[bits.tolist().index(12)]:.3e} V ≈ {Delta[bits.tolist().index(12)]*1e6:.2f} μV\")\nprint(f\"Ideal 12-bit SNR ≈ {snr_db[bits.tolist().index(12)]:.1f} dB\")\n\nplt.figure(figsize=(6,4))\nplt.semilogy(bits, Delta*1e6, marker='o')\nplt.xlabel(\"Bit depth b\")\nplt.ylabel(\"Δ (μV)\")\nplt.title(\"ECG step size vs. bit depth (±5 mV)\")\nplt.grid(True, which=\"both\")\nplt.tight_layout()\n\n12-bit Δ = 2.441e-06 V ≈ 2.44 μV\nIdeal 12-bit SNR ≈ 74.0 dB\n\n\n\n\n\nECG: step size and ideal quantization SNR for b=10..16 bits, ±5 mV range.\n\n\n\n\nInterpretation\n\n$b=12$ ⇒ $ $; ideal SNR $ $ (Oppenheim 2e; Jayant & Noll).\nMeets diagnostic needs when analog noise $&lt;$ and front-end avoids clipping (Webster MI 4e).\n\n\n\n\nGoal: Retain spindles/K-complexes without aliasing while maximizing sensitivity.\n\nBandwidth: EEG of interest $35 $; use $B=40 $ (Webster MI 4e).\nSampling: pick $f_s=256 $ (multiple of 2 for decimation) ensuring $f_s2B$ (Shannon 1949).\nAnti-alias: $f_c $ (ample guard to $f_s/2=128 $).\nRange/bits: EEG tens of $$V ⇒ prefer $b$ with programmable gain to use full-scale.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfs = 256\nt = np.arange(0, 2, 1/fs)\nx = 15e-6*np.sin(2*np.pi*10*t)  # 10 Hz alpha-like\ngain_clip = 400000  # too high =&gt; clips ±1 V ADC\ngain_safe = 200000  # safe\n\nadc_fs = 1.0  # ±1 V full-scale\ny_clip = np.clip(gain_clip*x, -adc_fs, adc_fs)\ny_safe = np.clip(gain_safe*x, -adc_fs, adc_fs)\n\nplt.figure(figsize=(6,4))\nplt.plot(t[:400], y_clip[:400], label=\"Clipping\")\nplt.plot(t[:400], y_safe[:400], label=\"Safe gain\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"ADC input (V)\")\nplt.title(\"Clipping risk from aggressive gain (EEG)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n\n\n\nEEG: effect of clipping vs. conservative gain (synthetic 15 μV wave).\n\n\n\n\nTakeaways\n\nUse sufficient gain to exploit full-scale but verify headroom for artifacts.\nClipping breaks linearity assumptions and corrupts morphology (Oppenheim 2e; Webster MI 4e).\n\n\n\n\n\nDesign: A PPG sensor needs $B=25 $. Pick a safe $f_s$ and justify.\n\nSolution: $f_s2B=50$; choose $f_s=200 $ for guard and digital processing overhead (Shannon 1949).\n\nQuantization: For $[V_{},V_{}]=[-2,2] $ and $b=10$, compute $$.\n\nSolution: $==3.90625 $ (Oppenheim 2e).\n\nNoise: With $ $, what is $_q^2$?\n\nSolution: $_q2= 2$ (Oppenheim 2e).\n\nSNR sizing: Target $72 $ for a full-scale sine. Minimum $b$?\n\nSolution: $b$ bits (Jayant & Noll).\n\n\n\n\n\n\nBandwidth $B$: Specify clinically required content (e.g., ECG 0.05–150 Hz; EEG 0.5–35 Hz).\nSampling $f_s$: Choose $2B$ with guard (e.g., ×3–5 margin) and convenience for integer decimation.\nAnti-alias LPF: Set $f_c&lt;f_s/2$; allow sufficient transition; verify analog order and tolerances.\nInput range: Size $[V_{},V_{}]$ from front-end gain so typical peaks approach full-scale without clipping.\nBit depth $b$: Use SNR $6.02b+1.76$ to meet noise targets; consider analog noise and electrode motion.\nTelemetry: For constrained links, consider $$-law/$A$-law; document compander/expander alignment (G.711).\nValidation: Bench test with synthetic and recorded signals; check aliasing, clipping, and effective number of bits (ENOB).\n\n\n\n\n\nOppenheim, A. V., Willsky, A. S., Nawab, S. H., Signals and Systems, 2nd ed., Prentice Hall, ISBN: 978-0138147570.\nShannon, C. E., Proc. IRE, 37(1), 1949, “Communication in the presence of noise,” DOI: 10.1109/JRPROC.1949.232969.\nNyquist, H., Trans. AIEE, 47, 1928, “Certain topics in telegraph transmission theory,” DOI: 10.1109/T-AIEE.1928.5055024.\nJayant, N. S., Noll, P., Digital Coding of Waveforms, Prentice-Hall, 1984, ISBN: 0-13-211913-7.\nWebster, J. G. (ed.), Medical Instrumentation: Application and Design, 4th ed., Wiley, ISBN: 978-0471676003.\nITU-T Recommendation G.711: Pulse Code Modulation (PCM) of voice frequencies (identifier: G.711)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#overview",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#overview",
    "title": "Sampling and quantization",
    "section": "",
    "text": "This guide recaps essentials of sampling and quantization for biomedical acquisition chains. Emphasis is on concrete design choices for $f_s$, anti-alias cutoff, bit depth $b$, and input range, with clinical mini-cases. Primary/secondary sources: Oppenheim 2e (ISBN: 978-0138147570), Shannon 1949 (DOI: 10.1109/JRPROC.1949.232969), Jayant & Noll (ISBN: 0-13-211913-7), Webster MI 4e (ISBN: 978-0471676003)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#concise-theory-recap",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#concise-theory-recap",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Nyquist: $f_s2B$ where $B$ is the highest significant frequency (Shannon 1949).\nSampling model: $T_s=1/f_s$, $x_s(t)=_{n}x(nT_s),(t-nT_s)$ (Oppenheim 2e).\nAnti-aliasing: analog LPF with $f_c&lt;f_s/2$ plus guard band (Oppenheim 2e).\nQuantizer: uniform, range $[V_{},V_{}]$, step $=$ (Oppenheim 2e).\nNoise model: $_q^2=$; full-scale sine $_{},b+1.76$ (Jayant & Noll).\nCompanding (telemetry): $$-law/$A$-law to emphasize small amplitudes before quantization (Jayant & Noll; ITU-T G.711)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-a-ecg-bedside-monitor",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-a-ecg-bedside-monitor",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Goal: Choose $f_s$, $f_c$, $b$, and input range for diagnostic ECG.\n\nBandwidth: adopt $B $ (Webster MI 4e).\nSampling: choose $f_s=500 $ to satisfy $f_s2B$ with guard (Shannon 1949).\nAnti-alias: set $f_c $ (transition to $f_s/2=250 $).\nRange: $ $ to cover tall QRS and baseline drift after high-pass.\nBits: $b=12$ is common; compute $$ and SNR below.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nVmin, Vmax = -5e-3, 5e-3\nrng = Vmax - Vmin\nbits = np.arange(10, 17)\nDelta = rng / (2**bits)\nsnr_db = 6.02*bits + 1.76  # full-scale sine (Jayant & Noll)\n\nprint(f\"12-bit Δ = {Delta[bits.tolist().index(12)]:.3e} V ≈ {Delta[bits.tolist().index(12)]*1e6:.2f} μV\")\nprint(f\"Ideal 12-bit SNR ≈ {snr_db[bits.tolist().index(12)]:.1f} dB\")\n\nplt.figure(figsize=(6,4))\nplt.semilogy(bits, Delta*1e6, marker='o')\nplt.xlabel(\"Bit depth b\")\nplt.ylabel(\"Δ (μV)\")\nplt.title(\"ECG step size vs. bit depth (±5 mV)\")\nplt.grid(True, which=\"both\")\nplt.tight_layout()\n\n12-bit Δ = 2.441e-06 V ≈ 2.44 μV\nIdeal 12-bit SNR ≈ 74.0 dB\n\n\n\n\n\nECG: step size and ideal quantization SNR for b=10..16 bits, ±5 mV range.\n\n\n\n\nInterpretation\n\n$b=12$ ⇒ $ $; ideal SNR $ $ (Oppenheim 2e; Jayant & Noll).\nMeets diagnostic needs when analog noise $&lt;$ and front-end avoids clipping (Webster MI 4e)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-b-eeg-for-sleep-staging",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-b-eeg-for-sleep-staging",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Goal: Retain spindles/K-complexes without aliasing while maximizing sensitivity.\n\nBandwidth: EEG of interest $35 $; use $B=40 $ (Webster MI 4e).\nSampling: pick $f_s=256 $ (multiple of 2 for decimation) ensuring $f_s2B$ (Shannon 1949).\nAnti-alias: $f_c $ (ample guard to $f_s/2=128 $).\nRange/bits: EEG tens of $$V ⇒ prefer $b$ with programmable gain to use full-scale.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfs = 256\nt = np.arange(0, 2, 1/fs)\nx = 15e-6*np.sin(2*np.pi*10*t)  # 10 Hz alpha-like\ngain_clip = 400000  # too high =&gt; clips ±1 V ADC\ngain_safe = 200000  # safe\n\nadc_fs = 1.0  # ±1 V full-scale\ny_clip = np.clip(gain_clip*x, -adc_fs, adc_fs)\ny_safe = np.clip(gain_safe*x, -adc_fs, adc_fs)\n\nplt.figure(figsize=(6,4))\nplt.plot(t[:400], y_clip[:400], label=\"Clipping\")\nplt.plot(t[:400], y_safe[:400], label=\"Safe gain\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"ADC input (V)\")\nplt.title(\"Clipping risk from aggressive gain (EEG)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n\n\n\nEEG: effect of clipping vs. conservative gain (synthetic 15 μV wave).\n\n\n\n\nTakeaways\n\nUse sufficient gain to exploit full-scale but verify headroom for artifacts.\nClipping breaks linearity assumptions and corrupts morphology (Oppenheim 2e; Webster MI 4e)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#four-formative-checks-with-solutions",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#four-formative-checks-with-solutions",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Design: A PPG sensor needs $B=25 $. Pick a safe $f_s$ and justify.\n\nSolution: $f_s2B=50$; choose $f_s=200 $ for guard and digital processing overhead (Shannon 1949).\n\nQuantization: For $[V_{},V_{}]=[-2,2] $ and $b=10$, compute $$.\n\nSolution: $==3.90625 $ (Oppenheim 2e).\n\nNoise: With $ $, what is $_q^2$?\n\nSolution: $_q2= 2$ (Oppenheim 2e).\n\nSNR sizing: Target $72 $ for a full-scale sine. Minimum $b$?\n\nSolution: $b$ bits (Jayant & Noll)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#design-checklist-print-friendly",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#design-checklist-print-friendly",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Bandwidth $B$: Specify clinically required content (e.g., ECG 0.05–150 Hz; EEG 0.5–35 Hz).\nSampling $f_s$: Choose $2B$ with guard (e.g., ×3–5 margin) and convenience for integer decimation.\nAnti-alias LPF: Set $f_c&lt;f_s/2$; allow sufficient transition; verify analog order and tolerances.\nInput range: Size $[V_{},V_{}]$ from front-end gain so typical peaks approach full-scale without clipping.\nBit depth $b$: Use SNR $6.02b+1.76$ to meet noise targets; consider analog noise and electrode motion.\nTelemetry: For constrained links, consider $$-law/$A$-law; document compander/expander alignment (G.711).\nValidation: Bench test with synthetic and recorded signals; check aliasing, clipping, and effective number of bits (ENOB)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#references-ids-included",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#references-ids-included",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Oppenheim, A. V., Willsky, A. S., Nawab, S. H., Signals and Systems, 2nd ed., Prentice Hall, ISBN: 978-0138147570.\nShannon, C. E., Proc. IRE, 37(1), 1949, “Communication in the presence of noise,” DOI: 10.1109/JRPROC.1949.232969.\nNyquist, H., Trans. AIEE, 47, 1928, “Certain topics in telegraph transmission theory,” DOI: 10.1109/T-AIEE.1928.5055024.\nJayant, N. S., Noll, P., Digital Coding of Waveforms, Prentice-Hall, 1984, ISBN: 0-13-211913-7.\nWebster, J. G. (ed.), Medical Instrumentation: Application and Design, 4th ed., Wiley, ISBN: 978-0471676003.\nITU-T Recommendation G.711: Pulse Code Modulation (PCM) of voice frequencies (identifier: G.711)."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#descripción",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\n\\(x(t)\\)\n\\(x(t - 2)\\)\n\\(x(2t + 1)\\)\n\\(x(-3t)\\)\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\n\\(x(t) = e^{-j(\\frac{4\\pi}{3})t} + e^{j(\\frac{2\\pi}{5})t}\\)\n\n\\(x(n) = \\cos(n/8) \\cos(\\pi n/8)\\)\n\n\\(x(n) = \\cos(3\\pi n/2) - \\sin(\\frac{\\pi n}{8}) + 3\\cos(\\frac{\\pi n}{4} + \\frac{\\pi}{3})\\)\n\n\n\n3. Demuestre que si \\(x(t)\\) y \\(y(t)\\) son señales impares, entonces:\n\n\\(z(t) = x(t)y(t)\\) es una señal par\n\n\\(g(t) = x(t) + y(t)\\) es una señal impar.\n\nSiendo \\(x(t) = \\sin(t)\\) y \\(y(t) = t\\), grafique en Python \\(z(t)\\) y \\(g(t)\\). ¿Se cumple lo indicado en los numerales a y b?\n\n\n\n4. Encuentre la expresión analítica de las señales mostradas a continuación utilizando funciones \\(u(t)\\) y \\(r(t)\\) (escalón unitario y rampa).\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nIndique si la señal \\(x_a(t)\\) es una señal periódica, en caso afirmativo, indique el periodo de la señal.\n\nFrecuencia de muestreo que cumpla con el teorema de Nyquist.\n\nEncontrar \\(x_a[n]\\) con la frecuencia de muestreo encontrada en el punto anterior.\n\nIndique si la señal \\(x_a[n]\\) es una señal periódica, en caso afirmativo, indique el periodo de la señal.\n\n\n\n6. Considere el sistema de procesamiento de señales mostrado en la figura:\n\nSi la entrada es \\(x_a(t) = 2 \\sin(720\\pi t) + 2\\), encontrar:\n\nLa salida \\(x_a[n]\\) si \\(T_{m1} = 12.5ms\\). ¿Con esta frecuencia se puede reconstruir la señal \\(x_a(t)\\) en \\(y(t)\\) si \\(T_{m2} = T_{m1}\\)? Justifique su respuesta.\n\nLa salida \\(x_a[n]\\) si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¿La señal es periódica en tiempo discreto? Justifique su respuesta.\n\nPara la señal del punto b, encontrar la señal cuantizada de un ciclo de la señal si el tamaño del registro es de 4 bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "recursos/talleres/SYSB/Taller3_2025_1.html",
    "href": "recursos/talleres/SYSB/Taller3_2025_1.html",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Profesores\nJenny Carolina Castiblanco Sánchez\nPablo Eduardo Caicedo Rodríguez\n\n\nDescripción\nA través de este taller se reforzarán los conocimientos en:\n\nTransformada Z\nDiseño, análisis e implementación de filtros digitales FIR e IIR\n\n\n\nProcedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\nTransformada Z y Región de Convergencia\nDetermine la transformada Z y dibuje la ROC de las siguientes señales:\n\n\\(x\\left[n\\right] = =\\begin{cases}\\displaystyle \\left(\\frac{1}{3}\\right)^{n}, & n \\ge 0,\\\\[6pt]\\displaystyle \\left(\\frac{1}{2}\\right)^{-n}, & n &lt; 0.\\end{cases}\\)\n\\(x\\left[n\\right]=\\begin{cases}\\displaystyle \\left(\\frac{1}{3}\\right)^{n}, & n \\ge 5,\\\\[6pt]0, & n &lt; 5.\\end{cases}\\)\n\nRespuesta del Sistema\nDetermine la respuesta del sistema\n\\[\ny\\left[n\\right] \\;=\\; \\frac{5}{6}\\,y\\left[n-1\\right]\\;-\\;\\frac{1}{6}\\,y\\left[n-2\\right]\\;+\\;x\\left[n\\right]\n\\]\nA la señal de entrada\n\\[\nx\\left[n\\right] \\;=\\; \\delta\\left[n\\right]\\;-\\;\\frac{1}{3}\\,\\delta\\left[n-1\\right]\n\\]\nRespuesta del Sistema\nUna señal de entrada ( \\(x[n] = 3^{n}u[-n]\\) ) es aplicada a un sistema LTI discreto con respuesta al impulso ( \\(h[n] = \\left(0.5\\right)^{n}u[n]\\) ).\n\nDetermine la función de transferencia del sistema.\n¿El sistema es estable?\nEncuentre la señal de salida del sistema.\n\nAnálisis de Filtro\nConsidere el filtro\n\\[y\\left[n\\right] \\;=\\; b\\,x\\left[n\\right]\\;-\\;0.65\\,y\\left[n-1\\right]\\]\n\nDetermine (b) de modo que \\(\\lvert H\\left[0\\right] \\lvert \\, = \\, 0\\)\n\nDibuje en el plano (z) el diagrama de polos y ceros. ¿El sistema es estable?\n\nGrafique el diagrama de bloques.\n\n¿Qué tipo de filtro es?\n\nDiseño de Filtro Analógico Muestreado\nLa salida de un sistema LTI está determinada por la ecuación del sistema.\n\\[\ny\\left[n\\right] \\;=\\; x\\left[n\\right]\\;-\\;a\\,y\\left[n-1\\right]\n\\]\nTeniendo en cuenta la función de transferencia, se desea diseñar un filtro con frecuencia de corte de 60 Hz para una señal analógica muestreada a 5 kHz.\n\n¿Qué valor debe tener la variable (a)?\n\n¿Qué tipo de filtro se obtiene?\n\n\n\n\nDiseñar y simular filtros digitales para señales empleando PYTHON.\n\nDiseñar, simular y analizar un filtro pasbajos FIR por el método de ventaneo, con frecuencia de corte de 55Hz a los 6dB, atenuación mínima en 60Hz de 20 dB y atenuación mayor de 40 dB por encima de 80Hz.\n\nDeterminar el mínimo orden del filtro requerido para las siguientes ventanas: Rectangular, triangular, Hann, Hamming, Blackman, Kayser.\nDe los filtros analizados, seleccione el de menor orden que cumpla con las características de diseño.\n\nDiseñar y simular filtros digitales IIR para señales de voz empleando Matlab, analizando las diferentes opciones: Butterworth, Chebyshev, Elíptico.\n\nDiseñar, simular y analizar un filtro pasabajos IIR por el método de transformación de filtros analógicos empleando la transformación bilineal, con las siguientes características: Frecuencia de muestreo, 8 kHz; frecuencia de corte de 3.4 kHz; rizado en la banda de paso, 1 dB; frecuencia de rechazo, 3.8 kHz; atenuación en la banda de rechazo, 30 dB; orden del filtro, mínimo.\nDiseñar, simular y analizar un filtro pasaltos IIR por el método de transformación de filtros analógicos empleando la transformación bilineal, con las siguientes características: Frecuencia de muestreo, 8 kHz; frecuencia de corte de 300 Hz; rizado en la banda de paso, 1 dB; frecuencia de rechazo, 60 Hz; atenuación en la banda de rechazo, 30 dB; orden del filtro, mínimo."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#descripción",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#procedimiento",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\nSolución\nSe grafican las transformaciones solicitadas en Python con Matplotlib.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_t(t):\n    return np.piecewise(t, [(-1 &lt;= t) & (t &lt;= 0), (0 &lt; t) & (t &lt;= 2), (2 &lt; t) & (t &lt;= 3)],\n                         [lambda t: t + 1, 2, 1, 0])\n\nt = np.linspace(-2, 4, 1000)\nplt.plot(t, x_t(t), label='x(t)')\nplt.xlabel('t')\nplt.ylabel('x(t)')\nplt.legend()\nplt.show()\n\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\nSolución\nAnalizamos si \\(\\frac{f_0}{f_s}\\) es racional.\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\nPeríodos: \\(T_1 = \\frac{2\\pi}{2} = \\pi\\), \\(T_2 = \\frac{2\\pi}{\\pi} = 2\\)\nMínimo común múltiplo: **Período = 2*\n\n\\(x(t) = e^{-j(4\\pi/3)t} + e^{j(2\\pi/5)t}\\)\n\nSe buscan los períodos fundamentales.\nNo es periódica porque las razones de frecuencias son irracionales.\n\n\n…\n\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nSolución\n\nPeríodo de la señal:\n\nFrecuencias: \\(f_1 = 300Hz\\), \\(f_2 = 240Hz\\)\nMCM de \\(\\frac{1}{300}\\) y \\(\\frac{1}{240}\\) → T = 1/60 s\n\nFrecuencia de muestreo\n\nTeorema de Nyquist: \\(f_s &gt; 2f_{max} = 600Hz\\)\n\nSeñal muestreada:\nfs = 600  # Hz\nn = np.arange(0, 100)\nxa_n = np.sin(600*np.pi*n/fs) + 3*np.sin(480*np.pi*n/fs)\nplt.stem(n, xa_n)\nplt.show()\n\n…\n\n\n\n6. Muestreo y cuantización\n\nSolución\n\nFrecuencia de muestreo:\n\n\\(T_m1 = 12.5ms\\) → \\(f_s = 80Hz\\)\nNo cumple Nyquist → No se puede reconstruir\n\nMuestreo a 8 veces Nyquist:\n\n\\(f_s = 5760Hz\\)\nSe evalúa si \\(\\frac{f_0}{f_s}\\) es racional → Sí es periódica\n\nCuantización (4 bits, rango 0-5):\n\nPaso de cuantización: \\(\\Delta = \\frac{5}{2^4}\\)\nSe discretiza la señal según niveles de cuantización.\n\n\nimport numpy as np\nlevels = np.linspace(0, 5, 16)\nquantized_signal = np.digitize(xa_n, levels) * (5 / 16)\nplt.stem(n, quantized_signal)\nplt.show()\n\nFin del taller."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "href": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "title": "Proyecto Final: PSIM 2024-1",
    "section": "",
    "text": "Criterio\n5.0  (Excelente)\n4.0  (Bueno)\n3.0  (Aceptable)\n1.0  (Deficiente)\n\n\n\n\n1. Objetivo del Proyecto\nClaramente definido, específico, relevante y alcanzable, alineado con la problemática.\nClaro y relevante, pero carece de precisión o profundidad.\nComprensible, pero general o no bien alineado con la problemática.\nConfuso, irrelevante o ausente.\n\n\n2. Justificación\nSólida, argumenta importancia e impacto con evidencia o literatura relevante.\nAdecuada, pero le falta profundidad o evidencia clara.\nBásica y poco convincente; argumentos débiles o generales.\nInexistente o carente de lógica.\n\n\n3. Metodología\nBien estructurada, clara y adecuada para los objetivos. Técnicas y procedimientos relevantes.\nAdecuada, pero carece de detalle o presenta leves inconsistencias.\nVaga, incompleta o no alineada con los objetivos.\nConfusa, inapropiada o ausente.\n\n\n4. Resultados\nClaros, organizados y rigurosamente analizados. Uso efectivo de herramientas visuales.\nClaros, pero carecen de profundidad en análisis u organización.\nConfusos, incompletos o mal interpretados.\nIrrelevantes, incorrectos o ausentes.\n\n\n5. Discusión\nInterpreta resultados, relaciona con objetivos y literatura, propone mejoras futuras.\nAborda puntos principales, pero falta profundidad o conexión con literatura previa.\nSuperficial, no interpreta correctamente resultados ni plantea ideas futuras.\nAusente o irrelevante.\n\n\n6. Respuesta a Preguntas\nResponde con claridad, precisión y seguridad. Demuestra dominio y análisis crítico del tema.\nResponde adecuadamente, pero muestra inseguridad en algunos aspectos.\nResponde vagamente, con dificultades para argumentar.\nRespuestas incorrectas, confusas o incapacidad para responder."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Preparar una Presentación | 5 PASOS para una CONFERENCIA EXITOSA por Sebastián Lora.\n¿Cómo estructurar una presentación? por Espacio Ñ de la Universidad del Norte\n\n\n\n\n\nCómo Hacer una Buena Presentación de Diapositivas (Tips) por Javier Muñiz.\nConsejos para una buena presentación en POWER POINT por NiboKids en el cole!.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentación\nNo se siguen ninguno de los consejos de los videos adjuntos para la creación de la presentación\nSe siguen algunos de los consejos de los videos adjuntos para la creación  de la presentación\nSe siguen todos los consejos de los videos adjuntos para la creación  de la presentación\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificación de los ejemplos\nNo se describe el código utilizado para los ejemplos\nSe describe parcialmente el código de los ejemplos\nSe describe a cabalidad el código de los ejemplos\n\n\nCalidad del código\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl código utilizado es completamente desarrollado por los estudiantes a excepción del manejo de datos (NUMPY array y las funciones matemáticas elementales) y la graficación (MATPLOTLIB)"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generación-de-presentaciones",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generación-de-presentaciones",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Preparar una Presentación | 5 PASOS para una CONFERENCIA EXITOSA por Sebastián Lora.\n¿Cómo estructurar una presentación? por Espacio Ñ de la Universidad del Norte"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generación-de-dipostivas",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generación-de-dipostivas",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Hacer una Buena Presentación de Diapositivas (Tips) por Javier Muñiz.\nConsejos para una buena presentación en POWER POINT por NiboKids en el cole!."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#rúbrica-de-evaluación",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#rúbrica-de-evaluación",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Indicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentación\nNo se siguen ninguno de los consejos de los videos adjuntos para la creación de la presentación\nSe siguen algunos de los consejos de los videos adjuntos para la creación  de la presentación\nSe siguen todos los consejos de los videos adjuntos para la creación  de la presentación\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificación de los ejemplos\nNo se describe el código utilizado para los ejemplos\nSe describe parcialmente el código de los ejemplos\nSe describe a cabalidad el código de los ejemplos\n\n\nCalidad del código\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl código utilizado es completamente desarrollado por los estudiantes a excepción del manejo de datos (NUMPY array y las funciones matemáticas elementales) y la graficación (MATPLOTLIB)"
  },
  {
    "objectID": "rubricas/Rubrica_Regression.html",
    "href": "rubricas/Rubrica_Regression.html",
    "title": "Rúbrica: Modelos de regresión",
    "section": "",
    "text": "Equipo 1Equipo 2\n\n\nIntegrantes\n\nLaura Bazante\nNicolás Panesso\nNicoll Arcos\n\nDataset: concreto\n\n\nIntegrantes\n\nKatherin Diaz\nHeidy Fernández\nJuan Muñoz\n\nDataset: Rendimiento\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsuficiente0%\nAceptable50%\nSuperior100%\n\n\n\n\nObjetivo análisis exploratorio de datos\nNo hay un objetivo aparente\nExiste un objetivo de análisis exploratorio de datos planteado pero este no se encuentra alineado con el modelo\nEl objetivo del análisis exploratorio de datos planteado se alinea con la construcción del modelo se encuentra bien descrito\n\n\nContexto del Dataset\nNo es posible establecer el ámbito al cual pertenecen los datos utilizados para desarrollar el trabajo\nSe hace una descripción muy básica de las características del dataset\nSe hace una descripción detallada de las características y las variables que componen el dataset\n\n\nJustificación\nNo existe una justificación aparente\nExiste justificación pero esta se encuentra mal planteda\nLa justificación se encuentra bien planteada\n\n\nPreprocesamiento\nNo se realizó preprocesamiento de los datos.  O no se argumenta de manera clara la razón de los procedimientos realizados\nAl dataset se le aplicaron solo algunas operaciones de preprocesamiento y los datos no tienen la calidad requerida\nAl dataset se le aplicaron las operaciones de preprocesamiento necesarias para mejorar su calidad y poder construir los modelos de clasificación\n\n\nConexión entre el EDA y el modelo final\nMás de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nMenos de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nTodas las decisiones para el modelo inicial fueron tomadas a partir del EDA\n\n\nDuración de la presentación\nLa presentación dura menos de 8 minutos o más de 13 minutos\nLa presentación dura menos de 9 minutos o más de 11 minutos\nLa presentación dura 10 minutos\n\n\nMaterial de clase\nNo usa la plantilla RMARKDOWN\n\nUsa la plantilla  RMARKDOWN\n\n\nUso de gráficos\nNo se usa ESTADÍSTICA para explicar todas las decisiones\n\nSe usa ESTADÍSTICA para explicar todas las decisiones\n\n\nJustificación de las decisiones del modelo final\nMás de dos decisiones del modelo final no están justificadas\nMenos de dos decisiones del modelo final no están justificadas\nLas decisiones del modelo final son justificadas.\n\n\nEvaluación del modelo\nNo hace evaluación del modelo\nUsa el índice de determinación para evaluar el modelo\nUsa el índice de determinación para evaluar el modelo y además hace análisis de residuos sobre la salida del modelo\n\n\nModelo de regresión\nNo se construyó el modelo o el grupo no puede explicar de manera clara la razón de los procedimientos realizados\nSolo construyó un modelo o no hay claridad sobre las características del modelo elegido\nIdentificó el modelo de mayor precisión después de realizar varias pruebas, se exponen las características del modelo elegido.  El modelo se presenta de forma gráfica"
  },
  {
    "objectID": "clases/Class_SYSB.html",
    "href": "clases/Class_SYSB.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "El estudio del procesamiento de señales es fundamental en la ingeniería biomédica debido a la amplia variedad de aplicaciones que tiene en el análisis, interpretación y mejora de datos biomédicos. A continuación, se presenta una justificación estructurada de su relevancia:\nNaturaleza de las señales biomédicas\nLas señales biomédicas, como las señales electrocardiográficas (ECG), electromiográficas (EMG), electroencefalográficas (EEG), o incluso imágenes médicas (resonancias magnéticas o tomografías), son complejas y están afectadas por ruido y artefactos.\nEl procesamiento de señales permite extraer información útil, filtrar interferencias y maximizar la calidad de los datos obtenidos.\nDiagnóstico y monitoreo\nLas señales biomédicas son esenciales para el diagnóstico de enfermedades y el monitoreo continuo de pacientes. Por ejemplo, el procesamiento de un ECG ayuda a detectar arritmias, mientras que el análisis de un EEG puede identificar epilepsia o trastornos del sueño.\nEn entornos de cuidado intensivo, el procesamiento en tiempo real de señales vitales garantiza decisiones clínicas rápidas y precisas.\nOptimización de dispositivos biomédicos\nEl diseño de dispositivos biomédicos como marcapasos, desfibriladores implantables y prótesis inteligentes requiere algoritmos avanzados de procesamiento de señales para interpretar datos en tiempo real y responder adecuadamente a las necesidades del paciente.\nAvances en tecnología médica\nTecnologías emergentes como el análisis de datos en telemedicina, dispositivos portátiles (wearables) y sistemas de salud móvil (mHealth) dependen del procesamiento de señales para garantizar la precisión y la utilidad de la información presentada.\nIntegración con otras disciplinas\nEl procesamiento de señales se combina con inteligencia artificial y aprendizaje automático para desarrollar modelos predictivos, clasificar patrones patológicos y personalizar tratamientos.\nInvestigación en fisiología y biomecánica\nEl análisis avanzado de señales contribuye a la comprensión profunda de procesos fisiológicos complejos, como la dinámica del corazón, el cerebro o el sistema musculoesquelético.\nEducación y competencias profesionales\nLa formación en procesamiento de señales biomédicas dota a los futuros ingenieros de herramientas matemáticas y computacionales para enfrentar problemas del mundo real, desarrollar soluciones innovadoras y avanzar en el campo de la ingeniería biomédica.\nEl curso está dividido en 5 partes:\n1. Introducción al procesado de señales.\n2. Conceptos de señales contínuas & discretas.\n3. Muestreo.\n4. Extracción de características de una señal.\n5. Filtraje de señales."
  },
  {
    "objectID": "clases/Class_SYSB.html#presentaciones",
    "href": "clases/Class_SYSB.html#presentaciones",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción\nClasificacion de señales\nSeñales Notables 1/2\nSeñales Notables 2/2\nAdquisición y Muestreo\nFiltros Digitales\nContenido Frecuencial\nTransformada Z"
  },
  {
    "objectID": "clases/Class_SYSB.html#datos",
    "href": "clases/Class_SYSB.html#datos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_SYSB.html#códigos",
    "href": "clases/Class_SYSB.html#códigos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorios",
    "href": "clases/Class_SYSB.html#laboratorios",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLAB01: Código python, estadística, y números complejos.\nLAB02: El electrocardiograma. Fundamentos Teóricos.\nLAB03: Análisis de información base del dataset (Demografía y estadística inicial)\nLAB04: Convolución\nLab05: Modelo estadístico para la clasificación de arritmias"
  },
  {
    "objectID": "clases/Class_SYSB.html#grupos-2025-1",
    "href": "clases/Class_SYSB.html#grupos-2025-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Grupos 2025-1",
    "text": "Grupos 2025-1\n\n\n\n\n\n\n\n\n\nID Estudiante\nNombre\nCorreo Electrónico\nGrupo\n\n\n\n\n 1000098844\nCRISTIAN STIVEN CAPERA CERQUERA\ncristian.capera-c@mail.escuelaing.edu.co\nA\n\n\n 1000044331\nMARIA ALEJANDRA URIBE RODRIGUEZ\nmaria.uribe-r@mail.escuelaing.edu.co\nA\n\n\n 1000098887\nNICOLE JULIANA AYURE MATAMOROS\nnicole.ayure-m@mail.escuelaing.edu.co\nA\n\n\n 1000097259\nJENNIFER SOFIA SANCHEZ RAMOS\njennifer.sanchez-r@mail.escuelaing.edu.co\nB\n\n\n 1000097273\nMARIA JOSE PIÑEROS ACUÑA\nmaria.pineros-a@mail.escuelaing.edu.co\nB\n\n\n 1000097287\nMARÍA JOSÉ HERNÁNDEZ GUERRA\nmaria.hguerra@mail.escuelaing.edu.co\nB\n\n\n 1000099348\nJAIME LEONARDO CALDERÓN BETANCURT\njaime.calderon-b@mail.escuelaing.edu.co\nC\n\n\n 1000098221\nLAURA CAMILA REYES MUÑOZ\nlaura.reyes-m@mail.escuelaing.edu.co\nC\n\n\n 1000045047\nDANIEL FELIPE BRU MENESES\ndaniel.bru@mail.escuelaing.edu.co\nD\n\n\n 1000053815\nKEVIN DANIEL BEJARANO OSORIO\nkevin.bejarano@mail.escuelaing.edu.co\nD\n\n\n 1000046321\nSANTIAGO ACUÑA MONCADA\nsantiago.acuna@mail.escuelaing.edu.co\nD\n\n\n 1000095641\nANA SOFIA GRANADA LEIVA\nana.granada-l@mail.escuelaing.edu.co\nE\n\n\n 1000092619\nLUISA FERNANDA PEREZ SALGADO\nluisa.perez-s@mail.escuelaing.edu.co\nE\n\n\n 1000094974\nMARIA FERNANDA GOMEZ CUBIDES\nmaria.gcubides@mail.escuelaing.edu.co\nF\n\n\n 1000095693\nMARÍA PAULA CORTES AVILA\nmaria.cortes-a@mail.escuelaing.edu.co\nF\n\n\n 1000053831\nLUISA LORETTA VERGARA ROMERO\nluisa.vergara-r@mail.escuelaing.edu.co\nG\n\n\n 1000095027\nPAULA MELISSA MARTINEZ BARRERA\npaula.martinez-b@mail.escuelaing.edu.co\nG\n\n\n 1000095101\nSANTIAGO PATIÑO MEJIA\nsantiago.pmejia@mail.escuelaing.edu.co\nG\n\n\n 1000098222\nJULIANA MAYORGA AVILA\njuliana.mayorga-a@mail.escuelaing.edu.co\nH\n\n\n 1000099556\nMARIANA FRANCO CARO\nmariana.franco-c@mail.escuelaing.edu.co\nH\n\n\n 1000098162\nMARÍA PAULA GÓMEZ NIÑO\nmaria.gomez-n@mail.escuelaing.edu.co\nI"
  },
  {
    "objectID": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nTaller1: Introduccion al procesamiento de señales\nTaller2: Sistemas LTI, Convolución, Series de FOURIER\nTaller3: Análisis y diseños de filtros\nPrimer Parcial 2025-1 A\nPrimer Parcial 2025-1 B"
  },
  {
    "objectID": "clases/Class_SYSB.html#clases",
    "href": "clases/Class_SYSB.html#clases",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Clases",
    "text": "Clases\n\nLunes: 10:00am-11:30am. F204.\n\nJueves: 10:00am-11:30am. F206."
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorio",
    "href": "clases/Class_SYSB.html#laboratorio",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laboratorio",
    "text": "Laboratorio\n\nMartes: 10:00am-11:30am. I1-308."
  },
  {
    "objectID": "clases/Class_SYSB.html#atención-a-estudiantes",
    "href": "clases/Class_SYSB.html#atención-a-estudiantes",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes\nGrupo 80:\nGrupo 81:"
  },
  {
    "objectID": "clases/Class_APSB.html",
    "href": "clases/Class_APSB.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Procesamiento en Tiempo Real\nEn entornos biomédicos, muchas aplicaciones requieren procesamiento en tiempo real, como el monitoreo de pacientes críticos, análisis de imágenes médicas (por ejemplo, ultrasonido, radiografías) y dispositivos portátiles. Edge AI permite procesar datos localmente, reduciendo la latencia en comparación con el envío de datos a servidores remotos. Ejemplo: Un dispositivo portátil para monitoreo continuo de ECG puede detectar arritmias en tiempo real sin depender de una conexión a internet.\nMayor Privacidad y Seguridad\nLos datos médicos son altamente sensibles y están protegidos por regulaciones estrictas (como la HIPAA o el GDPR). Edge AI permite que los datos se procesen y almacenen localmente, minimizando el riesgo de violaciones de seguridad o filtraciones. Ejemplo: Un sensor de glucosa implantable que analiza niveles de glucosa sin enviar los datos a la nube asegura mayor privacidad del paciente.\nReducción de Costos Operativos\nEl procesamiento en el borde elimina la necesidad de transmitir grandes volúmenes de datos a servidores en la nube, lo que reduce costos relacionados con la conectividad y el almacenamiento en línea. Ejemplo: Un sistema de detección de caídas para personas mayores puede analizar los datos del acelerómetro directamente en el dispositivo sin enviar grandes volúmenes de datos a la nube.\nAplicaciones en Zonas Remotas\nEn áreas rurales o zonas con conectividad limitada, Edge AI permite el uso de dispositivos médicos avanzados sin depender de conexiones de internet robustas. Ejemplo: Una máquina portátil de ultrasonido que utiliza Edge AI para interpretar imágenes en tiempo real podría usarse en campañas de salud en comunidades remotas.\nEficiencia Energética\nLos modelos de Edge AI están diseñados para operar en dispositivos de bajo consumo energético, lo que es ideal para dispositivos médicos portátiles y sistemas implantables. Ejemplo: Monitores de salud wearables, como relojes inteligentes o biosensores, que analizan parámetros fisiológicos continuamente.\nPersonalización y Adaptación en el Lugar\nLos modelos de Edge AI pueden adaptarse a los datos del usuario en tiempo real, permitiendo personalización sin enviar datos sensibles a servidores externos. Ejemplo: Un dispositivo de rehabilitación motora que analiza el movimiento del paciente y ajusta los ejercicios en tiempo real según su progreso.\nInterdisciplinariedad y Tendencia Futurista\nLa integración de Edge AI con la ingeniería biomédica fomenta una combinación única de hardware, software y conocimiento médico, lo que te posiciona en el centro de las innovaciones tecnológicas en salud.\nEl curso está dividido en 4 partes:\n1. Introducción a inteligencia artificial en el borde (EDGE AI).\n2. Hardware y software para EDGE AI.\n3. El flujo de trabajo de EDGE AI.\n4. Diseño, desarrollo y evaluación de sistemas EDGE AI."
  },
  {
    "objectID": "clases/Class_APSB.html#presentaciones",
    "href": "clases/Class_APSB.html#presentaciones",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción 1/2\nIntroducción 2/2\nLinux\nMetodología de desarrollo\nIntroducción al machine learning\nFlujo de trabajo para proyectos de machine learning"
  },
  {
    "objectID": "clases/Class_APSB.html#datos",
    "href": "clases/Class_APSB.html#datos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_APSB.html#códigos",
    "href": "clases/Class_APSB.html#códigos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_APSB.html#rúbrica",
    "href": "clases/Class_APSB.html#rúbrica",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Rúbrica",
    "text": "Rúbrica\n-Planteamiento del problema"
  },
  {
    "objectID": "clases/Class_APSB.html#laboratorios",
    "href": "clases/Class_APSB.html#laboratorios",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio001: Conociendo LINUX.\nLaboratorio002: Análisis exploratorio de datos"
  },
  {
    "objectID": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\n“Necesito un documento PDF descargable con la explicación de los algoritmos de machine learning utilizados en ciencias de la vida. El texto debe contener una relación entre las técnicas de análasis exploratorio y el algoritmo de machine learning, fundamentos teóricos del algoritmo, códigos python para utilizar. Los algoritmos deben ser: KNN, árboles de decisión, máquinas de soporte vectorial, bosques aleatorios y gradient boosting machines. Debes verificar la información para evitar alucinaciones.”\nDocumento 1: machine learning. CHATGPT 4o\nDocumento 2: machine learning. GEMINI 2.0 flash\nJ. D. Kelleher, B. Mac Namee, y A. D’Arcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed. Cambridge: The MIT press, 2020."
  },
  {
    "objectID": "clases/Class_APSB.html#clases",
    "href": "clases/Class_APSB.html#clases",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Clases",
    "text": "Clases\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201."
  },
  {
    "objectID": "proyectos/ComparisonML.html",
    "href": "proyectos/ComparisonML.html",
    "title": "Comparing different Machine Learning architectures for classifying medical terms in Colombian sign language",
    "section": "",
    "text": "Presentación STSIVA2025"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#introducción",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#introducción",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Introducción",
    "text": "Introducción"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Adquisición de datos",
    "text": "Adquisición de datos\n\n\n\nSe utilizó el sensor XSens MTw Awinda [1].\nSe adquirieron datos de aceleración, giroscopio y magnetómetro.\nSe uso \\(F_s = 100Hz\\).\nLos sensores capturan señales que representan el movimiento en su propio sistema de coordenadas [2]."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos-1",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Adquisición de datos",
    "text": "Adquisición de datos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatos adquiridos…\n\n\n\nProtocolo de adquisición modificado [3]\nActividad con ojos abiertos (eye open), ojos cerrados (eye close) y tarea dual (dual task)"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\n\n\n\n\n\n\n\nPrimer paso\n\n\n\nEliminación de datos no útiles.\nDatos eliminados: datos na, columnas PacketCounter y SampleTimeFine\nCreación de una columna Time en segundos."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento-1",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\n\n\n\n\n\n\n\nSegundo paso\n\n\n\nConvertir ejes locales a globales. Utilizando el cuaternio generado por el XSens.\nCalcular la magnitud del vector de aceleración global y la agregar al DataFrame.\nCalcular la magnitud del vector de velocidad angular global y la agregar al DataFrame.\nSeleccionar 20 segundos de información (eliminar información inicial y final)"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#fusión-sensorial",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#fusión-sensorial",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Fusión sensorial",
    "text": "Fusión sensorial\n\n\n\n\n\n\n\nAlgoritmo de Fusión\n\n\n\nSe utiliza el algoritmo de la fusión de los datos de aceleración y giroscopio por defecto de XSens.\nSe utiliza el algoritmo de eliminación de distorsión magnética desarrollado por XSens"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extracción de características",
    "text": "Extracción de características\n\n\n\n\n\n\n\nMétricas\n\n\n\nRaíz cuadrática media (RMS) de la magnitud de la aceleración o de la velocidad angular [4].\nAdaptación de la longitud de la trayectoria [3].\nArea de de la elipse de oscilación (ellipse sway area), típicamente cubriendo el 95% de los datos presentados."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extraccio-de-características",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extraccio-de-características",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extraccio de características",
    "text": "Extraccio de características"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-1",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extracción de características",
    "text": "Extracción de características\n\n\n\n\n\n\n\nRomberg Ratio\n\n\n\nEl test de Romberg es una prueba que se usa frecuentemente en la posturografía.\nSe basa en la evaluación del control postural bajo dos condiciones distintas: con visión (ojos abiertos) y sin visión (ojos cerrados).\nEl índice o ratio de Romberg se calcula dividiendo el balanceo postural (postural sway) en la condición de ojos cerrados entre el balanceo postural en la condición de ojos abiertos.\nTambién se puede calcular dividiendo el balanceo postural (postural sway) en la condición de doble tarea entre el balanceo postural en la condición de ojos abiertos"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-2",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-2",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extracción de características",
    "text": "Extracción de características\n\n\n\n\n\n\n\n\n\n\n\n\nEyes Open\nEyes Close\nDual Task\nRatio Romberg 1\nRatio Romberg 2\n\n\n\n\nRMS ACC X\n2,83E-03\n2,91E-03\n2,89E-03\n1,03\n1,02\n\n\nRMS ACC Y\n6,82E-04\n6,80E-03\n6,79E-03\n9,98\n9,96\n\n\nRMS ACC Z\n5,74E-04\n5,08E-04\n4,98E-04\n0,89\n0,87\n\n\nRMS GYR X\n4,24E-07\n3,52E-06\n4,24E-07\n8,29\n1,00\n\n\nRMS GYR Y\n1,02E-05\n8,27E-06\n1,16E-05\n0,81\n1,14\n\n\nRMS GYR Z\n8,68E-08\n6,18E-07\n8,52E-07\n7,12\n9,82\n\n\nPATH TRAJ\n0,0025\n0,0025\n0,0031\n1,00\n1,24\n\n\nAREA_ELIPSE_95%\n5,61E-11\n8,30E-11\n6,55E-12\n1,48\n0,12"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-propuesta",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-propuesta",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extracción de características (propuesta)",
    "text": "Extracción de características (propuesta)\n\n\n(np.float64(2.7508740895910972), np.float64(3.6048069186140856), np.float64(1.434932874624913), np.float64(2.0295845733092643))"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#referencias",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#referencias",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Referencias",
    "text": "Referencias\n\n\n[1] M. Paulich, M. Schepers, N. Rudigkeit, y G. Bellusci, «Xsens MTw Awinda: Miniature Wireless Inertial-Magnetic Motion Tracker for Highly Accurate 3D Kinematic Applications».\n\n\n[2] D. H. Yoon, J.-H. Kim, K. Lee, J.-S. Cho, S.-H. Jang, y S.-U. Lee, «Inertial measurement unit sensor-based gait analysis in adults and older adults: A cross-sectional study», Gait & Posture, vol. 107, pp. 212-217, ene. 2024, doi: 10.1016/j.gaitpost.2023.10.006.\n\n\n[3] J. Zhou et al., «A novel smartphone App-based assessment of standing postural control: Demonstration of reliability and sensitivity to aging and task constraints», en 2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM), Shenzhen, China: IEEE, mar. 2021, pp. 1-6. doi: 10.1109/HEALTHCOM49281.2021.9398972.\n\n\n[4] M. Calcagni, P. Kosa, y B. Bielekova, «Smartphone postural sway and pronator drift tests as measures of neurological disability», BMC Neurol, vol. 25, n.º 1, p. 50, feb. 2025, doi: 10.1186/s12883-025-04038-2."
  }
]