[
  {
    "objectID": "tutoriales/TutorialPython.html",
    "href": "tutoriales/TutorialPython.html",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Tomado del libro Ciencia de Datos para Ciencias Naturales\nSi no tiene experiencia con el lenguaje Markdown utilice esta guía para enriquecer sus celdas de texto.\n\n\n\nPlataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código\n\n\n\n\n\nNo requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos.\n\n\n\n\n\nNo se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia.\n\n\n\n\n\nCódigo: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#características",
    "href": "tutoriales/TutorialPython.html#características",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Plataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#ventajas",
    "href": "tutoriales/TutorialPython.html#ventajas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "href": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "href": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Código: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#strings",
    "href": "tutoriales/TutorialPython.html#strings",
    "title": "Tutorial de Python",
    "section": "Strings",
    "text": "Strings\n\ncadena_caracteres = \" Diplomado en Analítica para la Banca \"\n\n#Tamaño de la cadena de caracteres\nprint(len(cadena_caracteres))\n\n#Corte de variable\nprint(cadena_caracteres[0:10])\nprint(cadena_caracteres[20:30])\n\n#Convertir la variable a mayúsculas\nprint(cadena_caracteres.upper())\n\n#Convertir la variable a minúscula\nprint(cadena_caracteres.lower())\n\n#Contar cuantas veces aparece una cadena de caracteres\nprint(cadena_caracteres.count(\"ca\"))\n\n#Reemplazar en una cadena, una letra con otra\nprint(cadena_caracteres.replace(\"a\", \"0\"))\n\n#Partir la cadena de caracteres cada vez que se encuentre un caracter\nprint(cadena_caracteres.split(\" \"))\n\n#Concatenar dos cadenas de caracteres\ncadena01 = \"Pablo Eduardo\"\ncadena02 = \"Caicedo Rodríguez\"\nprint(cadena01+\" \"+cadena02)\n\n38\n Diplomado\nica para l\n DIPLOMADO EN ANALÍTICA PARA LA BANCA \n diplomado en analítica para la banca \n2\n Diplom0do en An0lític0 p0r0 l0 B0nc0 \n['', 'Diplomado', 'en', 'Analítica', 'para', 'la', 'Banca', '']\nPablo Eduardo Caicedo Rodríguez"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#listas",
    "href": "tutoriales/TutorialPython.html#listas",
    "title": "Tutorial de Python",
    "section": "Listas",
    "text": "Listas\n\nlista = [3, 2, 1, 0.5, \"hora del cafe\", \"torta chilena\", \"pinto\", \"jugo\"]\nprint(lista)\nlista.append(\"empanadita\")\nprint(lista)\n\"pinto\" in lista\n\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo']\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo', 'empanadita']\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#diccionarios",
    "href": "tutoriales/TutorialPython.html#diccionarios",
    "title": "Tutorial de Python",
    "section": "Diccionarios",
    "text": "Diccionarios\n\ntel = {'Maria': 4098, 'Jorge': 4139}\nprint(tel)\nprint(tel[\"Maria\"])\nprint(tel.keys())\nprint(tel.values)\n'Maria' in tel\n\n{'Maria': 4098, 'Jorge': 4139}\n4098\ndict_keys(['Maria', 'Jorge'])\n&lt;built-in method values of dict object at 0x7fda616f83c0&gt;\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tuplas",
    "href": "tutoriales/TutorialPython.html#tuplas",
    "title": "Tutorial de Python",
    "section": "Tuplas",
    "text": "Tuplas\n\nfrutas = ('naranja', 'mango', 'sandia', 'banano', 'kiwi')\nprint(type(frutas))\nfrutas[1]\n\n&lt;class 'tuple'&gt;\n\n\n'mango'"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#numpy",
    "href": "tutoriales/TutorialPython.html#numpy",
    "title": "Tutorial de Python",
    "section": "Numpy",
    "text": "Numpy\nNumPy (Numerical Python), es una biblioteca de Python que da soporte para crear vectores y matrices grandes multidimensionales, junto con una gran colección de funciones matemáticas de alto nivel. La funcionalidad principal de NumPy es su estructura de datos ndarray (arreglos), para una matriz de n dimensiones, sobre las cuales se pueden realizar operaciones matemátias de manera eficiente.\nCrearemos una lista usando código nativo de Python y lo convertiremos en una matriz unidimensional con la función np.array()\n\nimport numpy as np\n\nlist1 = [6,8,10,12]\narray1 = np.array(list1)\nprint(array1)\n\n[ 6  8 10 12]\n\n\nLos ndarrays son estructuras de datos genéricas para almacenar datos homogéneos. Son equivalentes a las matrices y los vectores en álgebra, por lo que también se les puede aplicar operaciones matemáticas. Notar que las operaciones matemáticas se pueden realizar en todos los valores en un ndarray a la vez.\n\nprint(array1 - 2)\nprint(array1 * array1, \"\\n\\n\")\n\n[ 4  6  8 10]\n[ 36  64 100 144] \n\n\n\n\nLos arreglos se encierran entre [], pero al imprimirlos no están separados por comas. Hay diferentes formas de crear arreglos con propiedades específicas, lo que les provee bastante flexibilidad.\n\n# Crea una matriz con datos específicos\nprint(np.array([[1,2],[3,4]]),'\\n')\n# Crea una matriz con unos: tres filas y cuatro columnas\nprint(np.ones((3,4)),'\\n')\n# Crea una matriz con ceros: tres filas y cuatro columnas\nprint(np.zeros((3,4)),'\\n')\n# Crea una matriz con un dato específico: tres filas y cuatro columnas\nprint(np.full((3,4), 7.3),'\\n')\n# Crea un arreglo con datos seguidos: empieza en 10 termina en 30(sin incluir) con incrementos de 5.\nprint(np.arange(10,30,5),'\\n')\n# # Crea un arreglo con inicio y fin y una cantidad de datos: arreglo de 6 datos entre 0 y 5/3 .\nprint(np.linspace(0,5/3,6),'\\n')\n# Crea una matriz con datos aleatorios entre 0 y 1: dos filas y tres columnas\nprint(np.random.rand(2,3),'\\n')\n\n[[1 2]\n [3 4]] \n\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]] \n\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]] \n\n[[7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]] \n\n[10 15 20 25] \n\n[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] \n\n[[0.16774198 0.78456432 0.55645227]\n [0.93379479 0.31797551 0.93596839]] \n\n\n\n\narr1 = np.array([np.arange(0,5), np.arange(0,5)*5])\n#Arreglo\nprint(arr1, \"\\n\")\n# Forma\nprint(arr1.shape, \"\\n\")\n# Tamaño\nprint(arr1.size, \"\\n\")\n# Número de Dimensiones\nprint(arr1.ndim, \"\\n\")\n# Transpuesta\nprint(arr1.T, \"\\n\")\n\n[[ 0  1  2  3  4]\n [ 0  5 10 15 20]] \n\n(2, 5) \n\n10 \n\n2 \n\n[[ 0  0]\n [ 1  5]\n [ 2 10]\n [ 3 15]\n [ 4 20]] \n\n\n\n\narr = np.array([1,2,3,4,5,6,7])\n# Porcionar\nprint(arr[1:3])# de 1 al 3 en índice\nprint(arr[4:])# de la posición 4 en adelante\nprint(arr[::2])# de uno por medio\n\n[2 3]\n[5 6 7]\n[1 3 5 7]"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#python",
    "href": "tutoriales/pythonprogrammin.html#python",
    "title": "Python programming",
    "section": "Python",
    "text": "Python\n\nPython is a high-level, interpreted, multi-paradigm, and general-purpose programming language.\nIts design philosophy emphasizes code readability.\nIt is one of the most popular programming languages in use today, and is used for a wide range of applications, including web development, data science, machine learning, and artificial intelligence."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advantages",
    "href": "tutoriales/pythonprogrammin.html#advantages",
    "title": "Python programming",
    "section": "Advantages",
    "text": "Advantages\n\nPython is a multi-paradigm programming language, meaning it can be used for different types of programming, such as object-oriented programming, imperative programming, and functional programming.\nPython is an interpreted programming language, meaning it does not need to be compiled before being executed. This makes Python very fast to develop and debug.\nPython is a highly portable programming language, meaning it can be run on different platforms, such as Windows, Mac OS X, and Linux. It can also be run in the cloud. Python has a large community of users and developers, meaning there are many resources available to learn and use Python."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#disadvantages",
    "href": "tutoriales/pythonprogrammin.html#disadvantages",
    "title": "Python programming",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nPython can be a bit slower than compiled languages, such as C or C++.\nPython has a slightly more complex syntax than some other programming languages, such as Java or JavaScript.\nPython may not be the best programming language for certain types of applications, such as game applications or high-performance applications."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#basic-syntax",
    "href": "tutoriales/pythonprogrammin.html#basic-syntax",
    "title": "Python programming",
    "section": "Basic Syntax",
    "text": "Basic Syntax\n\nIndentation is used to denote block-level structure\nVariables are assigned using the = operator\nPrint output using the print() function\nComments: # for single-line, ''' or \"\"\" for multi-line"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#data-types",
    "href": "tutoriales/pythonprogrammin.html#data-types",
    "title": "Python programming",
    "section": "Data Types",
    "text": "Data Types\n\nIntegers: int (e.g., 1, 2, 3)\nFloats: float (e.g., 3.14, -0.5)\nStrings: str (e.g., 'hello', \"hello\")\nBoolean: bool (e.g., True, False)\nList: list (e.g., [1, 2, 3], ['a', 'b', 'c'])\nDictionary: dict (e.g., {'name': 'John', 'age': 30})"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#control-structures",
    "href": "tutoriales/pythonprogrammin.html#control-structures",
    "title": "Python programming",
    "section": "Control Structures",
    "text": "Control Structures\n\nConditional statements:\n\nif statements: if condition : code\nelif statements: elif condition : code\nelse statements: else : code\n\nLoops:\n\nfor loops: for variable in iterable : code\nwhile loops: while condition : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#functions",
    "href": "tutoriales/pythonprogrammin.html#functions",
    "title": "Python programming",
    "section": "Functions",
    "text": "Functions\n\nReusable blocks of code\nTake arguments and return values\nCan be used to:\n\nOrganize code\nReduce repetition\nEncapsulate complex logic\n\nFunction definition: def function_name (arguments) : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#modules",
    "href": "tutoriales/pythonprogrammin.html#modules",
    "title": "Python programming",
    "section": "Modules",
    "text": "Modules\n\nPre-written code libraries\nImported using the import statement\nExamples:\n\nmath: mathematical functions (e.g., sin(), cos())\nrandom: random number generation (e.g., randint(), uniform())\ntime: time-related functions (e.g., time(), sleep())"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#exception-handling",
    "href": "tutoriales/pythonprogrammin.html#exception-handling",
    "title": "Python programming",
    "section": "Exception Handling",
    "text": "Exception Handling\n\nTry-except blocks:\n\ntry block: code that might raise an exception\nexcept block: code to handle the exception\n\nCatching specific exceptions:\n\nexcept ValueError : code\nexcept TypeError : code\n\nRaising exceptions:\n\nraise ValueError(message)"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "href": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "title": "Python programming",
    "section": "Object-Oriented Programming",
    "text": "Object-Oriented Programming\n\nClasses:\n\nDefine custom data types\nEncapsulate data and behavior\n\nObjects:\n\nInstances of classes\nHave attributes (data) and methods (behavior)\n\nInheritance:\n\nCreate new classes based on existing ones\nInherit attributes and methods"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advanced-topics",
    "href": "tutoriales/pythonprogrammin.html#advanced-topics",
    "title": "Python programming",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nDecorators:\n\nModify function behavior\nUse @ symbol to apply\n\nGenerators:\n\nSpecial type of iterable\nUse yield statement to define\n\nLambda functions:\n\nSmall, anonymous functions\nUse lambda keyword to define"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#decorators",
    "href": "tutoriales/pythonprogrammin.html#decorators",
    "title": "Python programming",
    "section": "Decorators",
    "text": "Decorators\n\ndef my_decorator(func):\n    def wrapper():\n        print(\"Something is happening before the function is called.\")\n        func()\n        print(\"Something is happening after the function is called.\")\n\n    return wrapper\n\n\n@my_decorator\ndef say_hello():\n    print(\"Hello!\")\n\n\nsay_hello()\n\nSomething is happening before the function is called.\nHello!\nSomething is happening after the function is called."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#generators",
    "href": "tutoriales/pythonprogrammin.html#generators",
    "title": "Python programming",
    "section": "Generators",
    "text": "Generators\n\ndef infinite_sequence():\n    num = 0\n    while True:\n        yield num\n        num += 1\n\ngen = infinite_sequence()\nprint(next(gen))\n\n0\n\nprint(next(gen))\n\n1\n\nprint(next(gen))\n\n2"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#lambda-function",
    "href": "tutoriales/pythonprogrammin.html#lambda-function",
    "title": "Python programming",
    "section": "Lambda Function",
    "text": "Lambda Function\n\nrectangle_area_calculation = lambda base, height: base * height\nprint(rectangle_area_calculation(4, 6))  # Salida: 24\n\n24"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#conclusion",
    "href": "tutoriales/pythonprogrammin.html#conclusion",
    "title": "Python programming",
    "section": "Conclusion",
    "text": "Conclusion\n\nPython is a powerful and versatile language\nContinuously learning and practicing will help you master it\nExplore advanced topics and libraries to become proficient\n\n\n\n\n\nhttps://pablocaicedor.github.io/"
  },
  {
    "objectID": "clases/Class_ASIM.html",
    "href": "clases/Class_ASIM.html",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "",
    "text": "Aprender procesamiento de señales e imágenes con aprendizaje automático en medicina es crucial para mejorar la precisión y eficiencia en el diagnóstico y tratamiento de enfermedades. El aprendizaje automático permite analizar grandes cantidades de datos de imágenes médicas y señales biomédicas, como rayos X, tomografías computarizadas, resonancia magnética, ECG, EEG y EMG, para identificar patrones y anomalías que pueden indicar la presencia de enfermedades. Esto puede llevar a un diagnóstico más preciso y temprano, lo que a su vez puede mejorar los resultados para los pacientes y reducir la morbilidad y mortalidad.\nAdemás, el aprendizaje automático puede ayudar a personalizar tratamientos para pacientes individuales según sus características únicas de imágenes médicas y señales. También puede automatizar tareas clínicas rutinarias, como segmentación de imágenes, extracción de características y análisis de datos, lo que permite a los médicos centrarse en la toma de decisiones de alto nivel.\nLa aplicación del aprendizaje automático en medicina también puede facilitar la investigación médica, analizando grandes conjuntos de datos para identificar tendencias y patrones que pueden revelar nuevos conocimientos sobre enfermedades y tratamientos. Además, puede permitir la monitorización remota de pacientes y la telemedicina, ampliando el acceso a servicios de atención médica."
  },
  {
    "objectID": "clases/Class_ASIM.html#presentaciones",
    "href": "clases/Class_ASIM.html#presentaciones",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nLect002: Introducción al Machine Learning\nLect003: Introducción al Machine Learning\nLect004: Neural Network"
  },
  {
    "objectID": "clases/Class_ASIM.html#laboratorios",
    "href": "clases/Class_ASIM.html#laboratorios",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLab00: Conducta de entrada\nLab01: Programación orientada a objetos\nSolución Lab01: Programación orientada a objetos\nLab02: Regresión lineal"
  },
  {
    "objectID": "clases/Class_ASIM.html#clases",
    "href": "clases/Class_ASIM.html#clases",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Clases",
    "text": "Clases\nSábado 7:00am-8:30am I1-304."
  },
  {
    "objectID": "clases/Class_ASIM.html#laboratorio",
    "href": "clases/Class_ASIM.html#laboratorio",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Laboratorio",
    "text": "Laboratorio\nSábado 8:30am-10:00am I1-304."
  },
  {
    "objectID": "clases/Class_ASIM.html#atención-a-estudiantes",
    "href": "clases/Class_ASIM.html#atención-a-estudiantes",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes"
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html",
    "href": "clases/Class_NumericalAnalysis.html",
    "title": "Análisis Numérico",
    "section": "",
    "text": "El análisis numérico es una rama de las matemáticas y la ciencia computacional que se enfoca en desarrollar algoritmos y técnicas para resolver problemas matemáticos mediante aproximaciones numéricas. Su objetivo es encontrar soluciones aproximadas a problemas que pueden ser difíciles o imposibles de resolver de manera exacta debido a su complejidad o naturaleza continua."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#física",
    "href": "clases/Class_NumericalAnalysis.html#física",
    "title": "Análisis Numérico",
    "section": "Física",
    "text": "Física\n\nSimulación de sistemas dinámicos\nMuchos sistemas físicos son gobernados por ecuaciones diferenciales que describen su comportamiento en el tiempo. Sin embargo, en muchos casos, estas ecuaciones son demasiado complejas para obtener soluciones analíticas. Aquí es donde entra en juego el análisis numérico, que permite simular el comportamiento de estos sistemas mediante la resolución numérica de las ecuaciones diferenciales. Por ejemplo, en la mecánica clásica, se pueden simular sistemas de partículas bajo la influencia de fuerzas gravitacionales o electromagnéticas para estudiar movimientos planetarios, trayectorias de proyectiles, etc. También en la mecánica cuántica, se pueden simular sistemas de partículas subatómicas para comprender su comportamiento y propiedades.\n\n\nResolución de problemas de transferencia de calor y fluidos\nEn la física, es común enfrentarse a problemas que involucran la transferencia de calor o el flujo de fluidos en sistemas complejos, como en la termodinámica, la hidrodinámica o la aerodinámica. Estos problemas a menudo están representados por ecuaciones diferenciales parciales, las cuales son difíciles o imposibles de resolver analíticamente. Aquí, el análisis numérico se convierte en una herramienta esencial para resolver estas ecuaciones y obtener soluciones aproximadas. Mediante técnicas como la simulación de Monte Carlo o los métodos de elementos finitos, es posible estudiar el comportamiento térmico y fluido de sistemas complejos, como la distribución de temperatura en un motor o la aerodinámica de un avión, lo que es crucial para el diseño y la optimización de muchos dispositivos y sistemas en la ingeniería y la industria."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#ingeniería",
    "href": "clases/Class_NumericalAnalysis.html#ingeniería",
    "title": "Análisis Numérico",
    "section": "Ingeniería",
    "text": "Ingeniería\n\nAnálisis estructural y diseño de ingeniería\nEn la ingeniería civil y mecánica, el análisis numérico es fundamental para el análisis y diseño de estructuras como puentes, edificios, presas, aviones, automóviles, entre otros. El método de elementos finitos (MEF) es una de las técnicas más utilizadas en esta área. Permite dividir estructuras complejas en elementos más pequeños, como triángulos o tetraedros, y aproximadamente resolver las ecuaciones de equilibrio y comportamiento mecánico de cada elemento. Estos métodos numéricos permiten calcular deformaciones, tensiones y cargas en las estructuras, así como determinar su resistencia, estabilidad y seguridad, lo que es crucial para garantizar que las construcciones sean seguras y eficientes.\n\n\nSimulación y modelado en ingeniería\nOtra aplicación importante del análisis numérico en la ingeniería es la simulación y modelado de sistemas complejos. Por ejemplo, en la ingeniería aeroespacial, se utilizan técnicas numéricas para simular el flujo de aire alrededor de aviones o cohetes, lo que permite estudiar la aerodinámica y optimizar el diseño de las aeronaves. En la ingeniería eléctrica, el análisis numérico se emplea para simular circuitos electrónicos complejos y analizar su comportamiento en diferentes condiciones. En la ingeniería química, se utilizan métodos numéricos para simular procesos de transporte de masa y calor en reactores y separadores. Estas simulaciones numéricas permiten a los ingenieros comprender mejor el comportamiento de sistemas complejos, realizar experimentos virtuales y realizar cambios de diseño de manera más rápida y económica antes de pasar a la fase de construcción y producción."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#economía",
    "href": "clases/Class_NumericalAnalysis.html#economía",
    "title": "Análisis Numérico",
    "section": "Economía",
    "text": "Economía\n\nModelado y simulación económica\nEl análisis numérico se utiliza extensamente para modelar y simular sistemas económicos complejos. Por ejemplo, en macroeconomía, se pueden desarrollar modelos computacionales que representen la interacción de múltiples variables económicas, como la inversión, el consumo, la inflación y el crecimiento económico. Estos modelos pueden ser sistemas de ecuaciones diferenciales o de diferencia que describen la dinámica de la economía a lo largo del tiempo. Mediante técnicas numéricas, como el método de Euler o métodos más sofisticados de resolución de ecuaciones diferenciales, se pueden realizar simulaciones para estudiar el comportamiento del sistema económico bajo diferentes condiciones y escenarios, lo que ayuda a los economistas a tomar decisiones informadas y entender mejor las implicaciones de las políticas económicas.\n\n\nValoración de activos financieros\nEn el ámbito financiero, el análisis numérico es esencial para la valoración de activos, como opciones, bonos y otros instrumentos financieros. Por ejemplo, en el mercado de opciones, los modelos de valoración de opciones, como el modelo Black-Scholes, implican resolver ecuaciones diferenciales parciales complejas. El análisis numérico permite calcular de manera eficiente los precios de las opciones y otros derivados financieros, lo que es crucial para los inversores, gestores de fondos y compañías que utilizan estos instrumentos para gestionar riesgos y tomar decisiones de inversión. Además, el análisis numérico es útil para calcular métricas financieras como el valor actual neto (VAN) y la tasa interna de retorno (TIR), que son fundamentales para la toma de decisiones en proyectos de inversión y evaluación de negocios."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#biología",
    "href": "clases/Class_NumericalAnalysis.html#biología",
    "title": "Análisis Numérico",
    "section": "Biología",
    "text": "Biología\n\nModelado de sistemas biológicos\nEl análisis numérico se utiliza para desarrollar modelos matemáticos que describen el comportamiento y la dinámica de sistemas biológicos. Por ejemplo, en la ecología, se pueden crear modelos que describan las interacciones entre diferentes especies en un ecosistema, incluidas las tasas de crecimiento, la competencia por recursos y la depredación. Estos modelos pueden ser representados mediante ecuaciones diferenciales o sistemas de ecuaciones que reflejen las relaciones entre las variables biológicas relevantes. El análisis numérico permite simular el comportamiento de estos sistemas y estudiar cómo cambian con el tiempo o en respuesta a cambios en las condiciones ambientales. Además, en la biología molecular, se utilizan modelos numéricos para simular la dinámica de sistemas bioquímicos, como redes de reacciones enzimáticas o interacciones entre moléculas, lo que es crucial para comprender los mecanismos subyacentes de procesos biológicos complejos.\n\n\nAnálisis de datos biológicos\nEn biología, se generan grandes cantidades de datos a partir de técnicas experimentales como la secuenciación genética, la microscopía y otros métodos de análisis molecular. El análisis numérico es esencial para procesar y analizar estos datos de manera eficiente y extraer información relevante. Por ejemplo, en bioinformática, se utilizan algoritmos numéricos para analizar secuencias de ADN y proteínas, identificar genes importantes, realizar análisis de expresión génica y buscar similitudes entre secuencias biológicas. Además, el análisis numérico se aplica en la imagenología médica para procesar imágenes de resonancia magnética (IRM), tomografía computarizada (TC) o imágenes microscópicas, lo que permite detectar patrones y características específicas en las imágenes que son relevantes para el diagnóstico y la investigación en biología y medicina."
  },
  {
    "objectID": "clases/Class_NumericalAnalysis.html#ciencia-de-datos",
    "href": "clases/Class_NumericalAnalysis.html#ciencia-de-datos",
    "title": "Análisis Numérico",
    "section": "Ciencia de datos",
    "text": "Ciencia de datos\n\nAprendizaje automático (Machine Learning)\nEl análisis numérico es esencial en el campo del aprendizaje automático, donde se utilizan algoritmos para entrenar modelos y hacer predicciones a partir de datos. En el aprendizaje supervisado, se utilizan técnicas numéricas para ajustar los parámetros de los modelos y minimizar la diferencia entre las predicciones y las salidas reales. Ejemplos de algoritmos de aprendizaje supervisado son las máquinas de soporte vectorial (SVM), regresión lineal, regresión logística, árboles de decisión, etc. Además, en el aprendizaje no supervisado, como el clustering y la reducción de dimensionalidad, se emplean técnicas numéricas para agrupar datos y encontrar estructuras ocultas en ellos. El análisis numérico permite realizar estos cálculos complejos de manera eficiente y precisa, lo que es crucial para el desarrollo y despliegue de modelos de aprendizaje automático en aplicaciones prácticas.\n\n\nAnálisis exploratorio de datos y visualización\nEn el análisis de datos, es común realizar tareas de exploración y visualización para entender mejor las características y patrones presentes en los conjuntos de datos. El análisis numérico es esencial para calcular resúmenes estadísticos, como promedios, medianas, desviaciones estándar y cuartiles, que proporcionan información valiosa sobre la distribución de los datos. Además, las técnicas de visualización de datos, como gráficos y diagramas, también se basan en el análisis numérico para representar de manera efectiva la información contenida en los datos. Algoritmos numéricos como el muestreo, la interpolación y la aproximación se utilizan para generar gráficos y visualizaciones informativas que facilitan la comprensión y toma de decisiones basadas en datos."
  },
  {
    "objectID": "clases/Class_Statistics.html",
    "href": "clases/Class_Statistics.html",
    "title": "Probabilidad Computacional & Estadística",
    "section": "",
    "text": "Introducción\nLa Estadística es una disciplina que se ocupa de la recopilación, organización, análisis, interpretación y presentación de datos. En la aplicación de estadísticas a un problema científico, industrial o social, es convencional comenzar con una población estadística o un modelo estadístico a ser estudiado.\nLas poblaciones pueden ser grupos diversos de personas u objetos como “todas las personas que viven en un país” o “cada átomo que compone un cristal”. La estadística se ocupa de todos los aspectos de los datos, incluyendo la planificación de la recopilación de datos en términos del diseño de encuestas y experimentos.\nCuando no se pueden recopilar datos del censo, los estadísticos recopilan datos desarrollando diseños experimentales específicos y muestras de encuestas. La muestra representativa asegura que las inferencias y conclusiones pueden extenderse razonablemente de la muestra a la población en general.\nUn estudio experimental implica tomar medidas del sistema bajo estudio, manipular el sistema y luego tomar medidas adicionales utilizando el mismo procedimiento para determinar si la manipulación ha modificado los valores de las medidas. En contraste, un estudio observacional no implica manipulación experimental.\nLos dos métodos estadísticos principales utilizados en el análisis de datos son:\n- Estadísticas descriptivas, que resumen los datos de una muestra utilizando índices como la media o la desviación estándar.\n- Estadísticas inferenciales, que extraen conclusiones a partir de datos que están sujetos a variación aleatoria (por ejemplo, errores observacionales, variación de muestreo).\nLas inferencias en estadísticas matemáticas se hacen bajo el marco de la teoría de probabilidad, que se ocupa del análisis de fenómenos aleatorios. Un procedimiento estadístico estándar implica la recopilación de datos que conducen a una prueba de la relación entre dos conjuntos de datos estadísticos, o un conjunto de datos y datos sintéticos extraídos de un modelo idealizado.\n\n\nObjetivo de la clase\nLa Estadística Descriptiva es una rama de la estadística que se ocupa de resumir, organizar y presentar los datos de manera significativa y concisa. Se centra en describir y analizar las características principales de un conjunto de datos sin hacer generalizaciones o inferencias a una población más grande.\nLas estadísticas descriptivas suelen incluir medidas como la tendencia central (por ejemplo, media, mediana, moda), la dispersión (por ejemplo, rango, varianza, desviación estándar) y la forma de la distribución (por ejemplo, asimetría, curtosis).\nAdemás, las estadísticas descriptivas implican una representación gráfica de los datos a través de gráficos, gráficas y tablas, que pueden ayudar aún más en la visualización e interpretación de la información.\n\n\nAplicaciones de la Estadística Descriptiva\nLa Estadística Descriptiva se utiliza en diversas aplicaciones:\n\nInformes de Tráfico y Compromiso: Un ejemplo de análisis descriptivo es la generación de informes.\nAnálisis de Estados Financieros: Otro ejemplo familiar de análisis descriptivo es el análisis de estados financieros.\nTendencias de Demanda: Las estadísticas descriptivas pueden ayudar a identificar y analizar las tendencias de demanda.\nResultados Agregados de Encuestas: Los resultados agregados de las encuestas pueden ser resumidos y presentados utilizando estadísticas descriptivas.\nProgreso hacia Metas: Las estadísticas descriptivas pueden ser útiles para rastrear y presentar el progreso hacia las metas establecidas.\n\nEn resumen, las estadísticas descriptivas proporcionan un resumen claro y conciso de los datos, permitiendo a los investigadores o analistas obtener información y comprender patrones, tendencias y distribuciones dentro del conjunto de datos. Esto facilita una mejor comprensión de los datos y proporciona una base para un análisis estadístico más profundo o procesos de toma de decisiones.\n\n\nMaterial del curso\nPresentacion"
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Requisitos:",
    "text": "Requisitos:\n\nIdentificar un problema de salud específico y relevante, relacionado con los ODS.\nJustificar la importancia del problema y la necesidad de una solución innovadora.\nEstablecer objetivos claros y medibles para el proyecto.\nElegir un dataset apropiado de señales (1D).\nDesarrollar una solución técnica que satisfaga los indicadores de solución de problema, con descripción matemática, física y/o estadística.\nImplementar la solución en Python."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Rúbrica de evaluación",
    "text": "Rúbrica de evaluación\n\n\n\n\n\n\n\n\n\n\nCriterio\nPuntos\nBueno\nRegular\nMalo\n\n\n\n\nProblema de salud identificado\n15\nProblema claro, relevante y bien justificado (15puntos)\nProblema claro, pero justificación débil (7puntos)\nProblema no claro o no relevante (0puntos)\n\n\nJustificación y objetivos\n15\nJustificación sólida y objetivos claros y medibles (15puntos)\nJustificación débil y objetivos poco claros (7puntos)\nJustificación y objetivos no claros (0puntos)\n\n\nSolución técnica\n20\nSolución innovadora, bien fundamentada y correctamente implementada en Python (20puntos)\nSolución adecuada, pero con errores en la implementación (10puntos)\nSolución no innovadora o con errores graves (0puntos)\n\n\nDiseño de indicadores\n20\nIndicadores bien definidos, con descripción matemática, médica y estadística clara y precisa (20puntos)\nIndicadores bien definidos, pero con descripción no clara o incompleta (10puntos)\nIndicadores no bien definidos o sin descripción (0puntos)\n\n\nContribución a los ODS\n10\nContribución clara y significativa a los ODS (10puntos)\nContribución moderada a los ODS (7puntos)\nContribución no clara o nula a los ODS (0puntos)\n\n\nImpacto potencial en la salud\n10\nImpacto potencial alto y bien justificado (10puntos)\nImpacto potencial moderado y justificación débil (7puntos)\nImpacto potencial bajo o no justificado (0puntos)\n\n\nPresentación y documentación\n10\nPresentación clara y documentación precisa y completa (10puntos)\nPresentación clara, pero documentación no precisa (7puntos)\nPresentación no clara o documentación no está presente (0puntos)"
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html",
    "href": "laboratorios/ASIM/lab001_OOP.html",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "href": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "href": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Encapsulation",
    "text": "Encapsulation\n\nEncapsulation is the concept of bundling data and methods that operate on that data within a single unit (class).\nIt helps to hide the implementation details and expose only the necessary information to the outside world."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "href": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Inheritance",
    "text": "Inheritance\n\nInheritance is the mechanism by which one class can inherit the attributes and methods of another class.\nIt promotes code reuse and facilitates the creation of a hierarchy of classes."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "href": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Polymorphism",
    "text": "Polymorphism\n\nPolymorphism is the ability of an object to take on multiple forms.\nIt can be achieved through method overriding (where a subclass provides a different implementation of a method) or method overloading (where multiple methods with the same name can be defined with different parameters)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "href": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Abstraction",
    "text": "Abstraction\n\nAbstraction is the concept of showing only the necessary information to the outside world while hiding the implementation details.\nIt helps to reduce complexity and improve code readability.\n\n\nclass BankAccount:\n    def __init__(self, account_number, account_name, balance):\n        self.account_number = account_number\n        self.account_name = account_name\n        self.balance = balance\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance:\n            print(\"Insufficient funds\")\n        else:\n            self.balance -= amount\n\n    def display_details(self):\n        print(f\"Account Number: {self.account_number}\")\n        print(f\"Account Name: {self.account_name}\")\n        print(f\"Balance: {self.balance}\")\n\n\nThe BankAccount class encapsulates the account_number, account_name, and balance attributes, as well as the deposit, withdraw, and display_details methods.\nThe __init__ method is a special method that is called when an object is created, and it initializes the attributes.\nThe deposit and withdraw methods modify the balance attribute, demonstrating encapsulation.\nThe display_details method provides a way to access the attributes without exposing them directly, demonstrating abstraction.\n\n\nclass SavingsAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, interest_rate):\n        super().__init__(account_number, account_name, balance)\n        self.interest_rate = interest_rate\n\n    def add_interest(self):\n        interest = self.balance * self.interest_rate\n        self.deposit(interest)\n\n\nThe SavingsAccount class inherits the attributes and methods of BankAccount using the super() function.\nIt adds an additional attribute interest_rate and a method add_interest that calculates and deposits interest.\n\n\nclass CurrentAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, overdraft_limit):\n        super().__init__(account_number, account_name, balance)\n        self.overdraft_limit = overdraft_limit\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance + self.overdraft_limit:\n            print(\"Transaction declined\")\n        else:\n            super().withdraw(amount)\n\n\n\n\nimage.png\n\n\n\n“Designing a Comprehensive Hospital Management System in Python”\n\nIntroduction\nIn this task, we aim to develop a straightforward hospital management system that efficiently manages patients, doctors, and appointments. Leveraging Python’s object-oriented programming capabilities, we will create a robust framework to streamline hospital operations.\n\n\nSystem Components\nThe hospital management system comprises four primary classes: Person, Patient, Doctor, Appointment, and Hospital.\n\n\nPerson Class\nThe Person class serves as the foundation for both Patient and Doctor classes, encapsulating essential attributes:\n\nname\nage\ngender\n\n\n\nPatient Class\nInheriting from Person, the Patient class introduces additional attributes:\n\npatient_id\nillness\n\n\n\nDoctor Class\nSimilarly, the Doctor class inherits from Person and includes:\n\ndoctor_id\nspecialization\n\n\n\nAppointment Class\nThe Appointment class encompasses:\n\nappointment_id\npatient (a Patient object)\ndoctor (a Doctor object)\ndate\ntime\n\n\n\nHospital Class\nThe Hospital class is the central hub, managing:\n\npatients (a list of Patient objects)\ndoctors (a list of Doctor objects)\nappointments (a list of Appointment objects)\nHospital Class Methods: The Hospital class features the following methods:\n\nadd_patient(name, age, gender, patient_id, illness): Adds a new patient to the hospital.\nadd_doctor(name, age, gender, doctor_id, specialization): Adds a new doctor to the hospital.\nschedule_appointment(appointment_id, patient_id, doctor_id, date, time): Schedules a new appointment.\nlist_appointments(): Lists all appointments.\n\n\n\n\nImplementation\nBy utilizing these classes and methods, the hospital management system provides a structured approach to managing patients, doctors, and appointments, ensuring efficient and organized hospital operations."
  },
  {
    "objectID": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "href": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sources of data",
    "text": "Sources of data\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data\n\n\n\n\n\nhttps://pablocaicedor.github.io/"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\n\nIntroducción al procesado de señales e imágenes biomédicas.\nFundamentos procesado de señales e imágenes biomédicas\nExtracción de características de señales biomédicas.\nExtracción de características de imágenes biomédicas."
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluación final\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nExamen parcial 1 (15%)\nExamen parcial 2 (15%)\nExamen final (20%)\nLaboratorios (16%)\nProyecto Final (15%)\nTalleres y Quices (14%)\nPresentaciones (5%)\nBonos (Sin porcentaje definido)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nTalleres y Quices (7%)\nTalleres y Quices (7%)\nPresentación (5%)\n\n\nLaboratorios (8%)\nLaboratorios (8%)\nProyecto final (15%)\n\n\nExamen Parcial 1 (15%)\nExamen Parcial 2 (15%)\nExamen final (20%)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nGrupo 80: Martes 7:00am-8:30am F-210. Jueves 7:00am-8:30am C6-202.\nGrupo 81: Martes 11:30am-1:30pm D-302. Jueves 11:30am-1:30pm D-302.\nLaboratorio\nGrupo 8001: Lunes 8:30am - 10:00am. I1-304\nGrupo 8101: Lunes 1:00pm - 2:30pm. I1-304\nGrupo 8102: Lunes 11:30am - 1:00pm. I1-308\n\nSoftware\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#bibliografía",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#como-estamos",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#como-estamos",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Como estamos?",
    "text": "Como estamos?\n\nQue es media?\nQue es mediana?\nQue es moda?\nQue es la varianza?\nQue es un histograma?\nQue es un valor atípico?\nQue es una variable aleatoria?\nQue es un espacio muestral?\nQue es un experimento aleatorio?\nQue es ruido blanco?\nComo se detecta el ruido blanco?\n\n\n\n\n\nhttps://pablocaicedor.github.io/"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant “free” sources of data\n\n\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\nhttps://pablocaicedor.github.io/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n17 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n22 ene 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura análisis numérico.\n\n\n\n1 jul 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso de Probabilidad computacional y estadística.\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#clases",
    "href": "index.html#clases",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n17 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n22 ene 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura análisis numérico.\n\n\n\n1 jul 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurso de Probabilidad computacional y estadística.\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#tutoriales",
    "href": "index.html#tutoriales",
    "title": "PECR Knowledge Hub",
    "section": "Tutoriales",
    "text": "Tutoriales\n\n\n\n\n\n\n\n\n\n\nPython programming\n\n\nA small tutorial in python in slides\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMicrobit – El minicomputador\n\n\nTutorial: Electrónica Básica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial de Python\n\n\nBreve Tutorial de Python\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputación de seno y coseno usando expansión de Taylor\n\n\nUn ejemplo de clase del cálculo de una serie de Taylor sin uso de librerías especiales de Python – En construcción –\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#proyectos",
    "href": "index.html#proyectos",
    "title": "PECR Knowledge Hub",
    "section": "Proyectos",
    "text": "Proyectos\n\n\n\n\n\n\n\n\n\n\nPredictive modeling for seizure detection in pharmacoresistant epilepsy: a machine learning approach\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html",
    "href": "codigo/PSIM/cod001_signal_conditioning.html",
    "title": "Estudio de arritmia cardíaca",
    "section": "",
    "text": "from google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librerías",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librerías",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de librerías",
    "text": "Carga de librerías\n\nnumpy: Para manipulación numérica y funciones estadísticas básicas\nmatplotlib.pyplot: Para generación de gráficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\nscipy.signal: Para análisis de señales de la librería SCIPY\nscipy.optimize: Para realizar el ajuste de curva\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.signal as signal\nfrom scipy.optimize import curve_fit"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#configuración-de-carpetas",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#configuración-de-carpetas",
    "title": "Estudio de arritmia cardíaca",
    "section": "Configuración de carpetas",
    "text": "Configuración de carpetas\n\ndata_path = \"/content/drive/MyDrive/ECG_Dataset/\""
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\nplt.plot(f_vect1, mag_ecg_fft1**2)\nplt.grid()\n\n\n\n\n\n\n\n\n\nfs = 500\nfcut = 50\norder = 4\n\nf_corte = fcut/(fs/2)\n\nb, a = signal.butter(order, f_corte, \"lowpass\")\n\n\necg_filt_1 = signal.lfilter(b, a, lead_10)\necg_filt_2 = signal.filtfilt(b, a, lead_10) # No causal.\n\n\nplt.plot(t, ecg_filt_1)\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nmag_ecg_filt = np.abs(np.fft.fft(ecg_filt_2))[:np.uint(N/2)]\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.plot(f_vect1, mag_ecg_filt)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\ndef modelo_artefacto(time, p0, p1, p2, p3, p4):\n  return p0+p1*np.sin(p2*time)+p3*np.cos(p4*time)\n\n\npopt, pcov = curve_fit(modelo_artefacto, t, ecg_filt_2)\n\n\npopt[1]\n\n152.2437794044702\n\n\n\nplt.plot(t, modelo_artefacto(t, *popt))\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2-modelo_artefacto(t, *popt))"
  },
  {
    "objectID": "codigo/ASIM/cod002_LinearRegression.html",
    "href": "codigo/ASIM/cod002_LinearRegression.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport numpy as np\n\n# Generate some random data\nnp.random.seed(0)\nX = np.random.rand(100,1)\ny = 3 + 2 * X + np.random.randn(100,1) / 1.5\nX\n\narray([[0.5488135 ],\n       [0.71518937],\n       [0.60276338],\n       [0.54488318],\n       [0.4236548 ],\n       [0.64589411],\n       [0.43758721],\n       [0.891773  ],\n       [0.96366276],\n       [0.38344152],\n       [0.79172504],\n       [0.52889492],\n       [0.56804456],\n       [0.92559664],\n       [0.07103606],\n       [0.0871293 ],\n       [0.0202184 ],\n       [0.83261985],\n       [0.77815675],\n       [0.87001215],\n       [0.97861834],\n       [0.79915856],\n       [0.46147936],\n       [0.78052918],\n       [0.11827443],\n       [0.63992102],\n       [0.14335329],\n       [0.94466892],\n       [0.52184832],\n       [0.41466194],\n       [0.26455561],\n       [0.77423369],\n       [0.45615033],\n       [0.56843395],\n       [0.0187898 ],\n       [0.6176355 ],\n       [0.61209572],\n       [0.616934  ],\n       [0.94374808],\n       [0.6818203 ],\n       [0.3595079 ],\n       [0.43703195],\n       [0.6976312 ],\n       [0.06022547],\n       [0.66676672],\n       [0.67063787],\n       [0.21038256],\n       [0.1289263 ],\n       [0.31542835],\n       [0.36371077],\n       [0.57019677],\n       [0.43860151],\n       [0.98837384],\n       [0.10204481],\n       [0.20887676],\n       [0.16130952],\n       [0.65310833],\n       [0.2532916 ],\n       [0.46631077],\n       [0.24442559],\n       [0.15896958],\n       [0.11037514],\n       [0.65632959],\n       [0.13818295],\n       [0.19658236],\n       [0.36872517],\n       [0.82099323],\n       [0.09710128],\n       [0.83794491],\n       [0.09609841],\n       [0.97645947],\n       [0.4686512 ],\n       [0.97676109],\n       [0.60484552],\n       [0.73926358],\n       [0.03918779],\n       [0.28280696],\n       [0.12019656],\n       [0.2961402 ],\n       [0.11872772],\n       [0.31798318],\n       [0.41426299],\n       [0.0641475 ],\n       [0.69247212],\n       [0.56660145],\n       [0.26538949],\n       [0.52324805],\n       [0.09394051],\n       [0.5759465 ],\n       [0.9292962 ],\n       [0.31856895],\n       [0.66741038],\n       [0.13179786],\n       [0.7163272 ],\n       [0.28940609],\n       [0.18319136],\n       [0.58651293],\n       [0.02010755],\n       [0.82894003],\n       [0.00469548]])\n\n\n\n\n# Convert data to PyTorch tensors\nX_tensor = torch.from_numpy(X.astype(np.float32))\ny_tensor = torch.from_numpy(y.astype(np.float32))\n\n\n# Define the linear regression model\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Initialize the model, loss function, and optimizer\nmodel = LinearRegression()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# Train the model\nfor epoch in range(1000):\n    optimizer.zero_grad()\n    outputs = model(X_tensor)\n    loss = criterion(outputs, y_tensor)\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 100 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n# Print the learned parameters\n\nm = model.linear.weight.item()\nb = model.linear.bias.item()\n\nprint(\"Learned parameters:\")\nprint(\"Weight:\", m)\nprint(\"Bias:\", b )\n\nEpoch 1, Loss: 17.11027717590332\nEpoch 101, Loss: 0.5529825687408447\nEpoch 201, Loss: 0.4432789981365204\nEpoch 301, Loss: 0.44221213459968567\nEpoch 401, Loss: 0.4419429302215576\nEpoch 501, Loss: 0.4417407214641571\nEpoch 601, Loss: 0.44158604741096497\nEpoch 701, Loss: 0.44146785140037537\nEpoch 801, Loss: 0.4413774013519287\nEpoch 901, Loss: 0.4413083791732788\nLearned parameters:\nWeight: 1.91282320022583\nBias: 3.170973062515259\n\n\n\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0 , 1, 200)\nfig001 = plt.figure()\nplt.plot(t, m*t+b)\nplt.plot(X, y, 'r*')"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\ndata = pd.read_csv(\"../../data/diabetes.csv\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network data",
    "text": "Create neural network data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Write a Python program that calculates the mean and median of a list of numbers.\n\nimport statistics\n\nnumbers = [1, 2, 3, 4, 5]\nmean = statistics.mean(numbers)\nmedian = statistics.median(numbers)\nprint(\"Mean:\", mean)\nprint(\"Median:\", median)"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-1-mean-and-median",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Write a Python program that calculates the mean and median of a list of numbers.\n\nimport statistics\n\nnumbers = [1, 2, 3, 4, 5]\nmean = statistics.mean(numbers)\nmedian = statistics.median(numbers)\nprint(\"Mean:\", mean)\nprint(\"Median:\", median)"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-2-standard-deviation",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers.\n\nimport statistics\n\nnumbers = [1, 2, 3, 4, 5]\nstd_dev = statistics.stdev(numbers)\nprint(\"Standard Deviation:\", std_dev)"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-3-data-visualization",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers.\n\nimport matplotlib.pyplot as plt\n\nnumbers = [1, 2, 3, 4, 5]\nplt.hist(numbers, bins=5)\nplt.show()"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-4-probability-distribution",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g. normal, binomial).\n\nimport scipy.stats as stats\n\n# Normal distribution\nmean, std_dev = 0, 1\nx = stats.norm.rvs(mean, std_dev, size=1000)\nprint(\"Normal Distribution:\", x)\n\n# Binomial distribution\nn, p = 10, 0.5\nx = stats.binom.rvs(n, p, size=1000)\nprint(\"Binomial Distribution:\", x)"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-5-conditional-probability",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event.\n\nimport scipy.stats as stats\n\n# Conditional probability of A given B\np_A_given_B = stats.norm.cdf(1, loc=0, scale=1, conditional=True)\nprint(\"Conditional Probability:\", p_A_given_B)"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-6-bayes-theorem",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes’ Theorem",
    "text": "Exercise 6: Bayes’ Theorem\nWrite a Python program that applies Bayes’ theorem to update the probability of a hypothesis given new evidence.\n\nimport scipy.stats as stats\n\n# Prior probability\nprior = stats.norm.pdf(0, loc=0, scale=1)\n\n# Likelihood\nlikelihood = stats.norm.pdf(1, loc=0, scale=1)\n\n# Posterior probability\nposterior = prior * likelihood\nprint(\"Posterior Probability:\", posterior)"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-7-correlation-coefficient",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers.\n\nimport numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 3, 5, 7, 11])\ncorr_coef = np.corrcoef(x, y)[0, 1]\nprint(\"Correlation Coefficient:\", corr_coef)"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-8-regression-analysis",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset.\n\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nx = np.array([1, 2, 3, 4, 5]).reshape((-1, 1))\ny = np.array([2, 3, 5, 7, 11])\n\nmodel = LinearRegression().fit(x, y)\nprint(\"Regression Coefficient:\", model.coef_)\nprint(\"Intercept:\", model.intercept_)\n\nRegression Coefficient: [2.2]\nIntercept: -1.0000000000000018"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-9-random-number-generation",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g. normal, uniform).\n\nimport numpy as np\n\n# Uniform distribution\nuniform = np.random.uniform(0, 1, size=10)\nprint(\"Uniform Distribution:\", uniform)\n\n# Normal distribution\nnormal = np.random.normal(0, 1, size=10)\nprint(\"Normal Distribution:\", normal)"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-10-monte-carlo-simulation",
    "href": "evaluaciones/eval001_ConductaEntrada_solution.html#exercise-10-monte-carlo-simulation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10: Monte Carlo Simulation",
    "text": "Exercise 10: Monte Carlo Simulation\nWrite a Python program that uses Monte Carlo simulation to estimate the value of pi.\n\nimport numpy as np\n\n\ndef estimate_pi(num_samples):\n    x = np.random.uniform(-1, 1, size=num_samples)\n    y = np.random.uniform(-1, 1, size=num_samples)\n    inside_circle = x**2 + y**2 &lt;= 1\n    return 4 * np.mean(inside_circle)\n\n\nnum_samples = 1000000\npi_estimate = estimate_pi(num_samples)\nprint(\"Estimated Pi:\", pi_estimate)"
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0003.html",
    "href": "evaluaciones/Examen0001/Examen0003.html",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "",
    "text": "Marque la(s) opción(es) correcta(s)\n\n(2puntos) ¿En el dominio de la frecuencia, Cuál es el efecto de la convolución entre una señal y un kernel?\n\nSe convierte en una multiplicación entre el kernel y la señal\nSiempre se introduce un retraso en la señal en el dominio del tiempo\nCrea un efecto de periodicidad en la señal\nElimina las componentes de alta frecuencia dependiendo del kernel\n\n(2puntos) ¿Cuál es la relación entre la frecuencia de muestreo y la frecuencia de Nyquist en un sistema de muestreo?\n\nLa frecuencia de muestreo debe ser igual a la frecuencia de Nyquist\nLa frecuencia de muestreo debe ser el doble de la frecuencia de Nyquist\nLa frecuencia de muestreo puede ser menor que la frecuencia de Nyquist\nLa frecuencia de muestreo no tiene relación con la frecuencia de Nyquist\n\n(2puntos) ¿Cuál(es) es(son) (los) propósito(s) general(es) del procesamiento de una señal temporal?\n\nExtraer la convolución de la señal\nExtraer información relativa al proceso descrito por la señal\nAsociar las características de la señal con las características del proceso\nDeterminar que kernel de convolución es necesario para eliminar la frecuencia de 60Hz\n\n(2puntos) ¿Cuáles de las siguientes afirmaciones sobre la transformada rápida de Fourier son correctas?\n\nGenera la representación de la señal en el dominio de la frecuencia.\nGenera la representación de la señal en el dominio del tiempo.\nGenera la representación de la señal en el dominio de la amplitud.\nEs un algoritmo computacional.\n\n(2puntos) A continuación marque las afirmaciones que considere correctas:\n\nUn filtro tipo Butterworth no puede tener respuesta pasabanda.\nLos filtros FIR (finite impulse response) siempre son estables.\nLos filtros Butterworth se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante.\nLos filtros Chebyshev no se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante."
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0003.html#primera-sección-10-puntos",
    "href": "evaluaciones/Examen0001/Examen0003.html#primera-sección-10-puntos",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "",
    "text": "Marque la(s) opción(es) correcta(s)\n\n(2puntos) ¿En el dominio de la frecuencia, Cuál es el efecto de la convolución entre una señal y un kernel?\n\nSe convierte en una multiplicación entre el kernel y la señal\nSiempre se introduce un retraso en la señal en el dominio del tiempo\nCrea un efecto de periodicidad en la señal\nElimina las componentes de alta frecuencia dependiendo del kernel\n\n(2puntos) ¿Cuál es la relación entre la frecuencia de muestreo y la frecuencia de Nyquist en un sistema de muestreo?\n\nLa frecuencia de muestreo debe ser igual a la frecuencia de Nyquist\nLa frecuencia de muestreo debe ser el doble de la frecuencia de Nyquist\nLa frecuencia de muestreo puede ser menor que la frecuencia de Nyquist\nLa frecuencia de muestreo no tiene relación con la frecuencia de Nyquist\n\n(2puntos) ¿Cuál(es) es(son) (los) propósito(s) general(es) del procesamiento de una señal temporal?\n\nExtraer la convolución de la señal\nExtraer información relativa al proceso descrito por la señal\nAsociar las características de la señal con las características del proceso\nDeterminar que kernel de convolución es necesario para eliminar la frecuencia de 60Hz\n\n(2puntos) ¿Cuáles de las siguientes afirmaciones sobre la transformada rápida de Fourier son correctas?\n\nGenera la representación de la señal en el dominio de la frecuencia.\nGenera la representación de la señal en el dominio del tiempo.\nGenera la representación de la señal en el dominio de la amplitud.\nEs un algoritmo computacional.\n\n(2puntos) A continuación marque las afirmaciones que considere correctas:\n\nUn filtro tipo Butterworth no puede tener respuesta pasabanda.\nLos filtros FIR (finite impulse response) siempre son estables.\nLos filtros Butterworth se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante.\nLos filtros Chebyshev no se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante."
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0003.html#segunda-sección-20-puntos",
    "href": "evaluaciones/Examen0001/Examen0003.html#segunda-sección-20-puntos",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "Segunda sección (20 puntos)",
    "text": "Segunda sección (20 puntos)\n\nMarque las opciones que considere correctas\nLas preguntas de esta sección se basan en Figura 1.\n\n\n\n\n\n\n\n\n\nFigura 1: Posible función de densidad de probabilidad.\n\n\n\n\n\n\n(20 puntos) ¿Cuáles de las siguientes afirmaciones considera correcta?\n\nLa función descrita en la Figura adjunta tiene naturaleza contínua.\nLa función descrita en la figura representa a una función de densidad de probabilidad.\nLa función se definió a trozos. Entre 0 y 2 la función vale 0. Entre 2 y 6 la función vale \\(0.25x - 0.5\\). Finalmente, entre 6 y 10 la función vale 0.\nEl valor esperado de la función de densidad de probabilidad es 4.6667. Sugerencia tome 4 decimales y realice el redondeo."
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0003.html#tercer-sección20-puntos",
    "href": "evaluaciones/Examen0001/Examen0003.html#tercer-sección20-puntos",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "Tercer sección(20 puntos)",
    "text": "Tercer sección(20 puntos)\n\n\n\n\n\n\n\n\nFigura 2: Señal Temporal\n\n\n\n\n\n\nSe tiene que la señal f(t) está descrita por la ecuación \\(f\\left(t\\right) = 10sin\\left(2\\pi t\\right) - 5sin\\left(4\\pi t\\right)+6sin\\left(6\\pi t\\right)\\). Ver Figura 2.\n\n\n\n\n\n\n\n\n\nFigura 3: Proceso de muestreo\n\n\n\n\n\n\nMarque las opciones que considere correctas\n\n(10 puntos) ¿Cuáles de las siguientes afirmaciones considera correcta?\n\nLa frecuencia de Nyquist es 4Hz\nMuestrear a 3Hz esta bien porque la máxima frecuencia de la señal es 1.5Hz\nSi se sabe que se muestrea a 10Hz, la señal resultante tiene 50 muestras.\nEl espectro de magnitud de Fourier presenta 3 picos en 1Hz, 2Hz, 4Hz.\n\n(10 puntos) Si se tiene el proceso de muestreo visto en Figura 3, marque las afirmaciones que considere correctas.\n\nLa frecuencia de muestreo es de 5Hz.\nExiste aliasing.\nLa frecuencia de muestreo es de 10Hz\nNo existe aliasing"
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0001.html",
    "href": "evaluaciones/Examen0001/Examen0001.html",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "",
    "text": "Marque la(s) opción(es) correcta(s)\n\n(2puntos) ¿En el dominio de la frecuencia, Cuál es el efecto de la convolución entre una señal y un kernel?\n\nSe convierte en una multiplicación entre el kernel y la señal\nSiempre se introduce un retraso en la señal en el dominio del tiempo\nCrea un efecto de periodicidad en la señal\nElimina las componentes de alta frecuencia dependiendo del kernel\n\n(2puntos) ¿Cuál es la relación entre la frecuencia de muestreo y la frecuencia de Nyquist en un sistema de muestreo?\n\nLa frecuencia de muestreo debe ser igual a la frecuencia de Nyquist\nLa frecuencia de muestreo debe ser el doble de la frecuencia de Nyquist\nLa frecuencia de muestreo puede ser menor que la frecuencia de Nyquist\nLa frecuencia de muestreo no tiene relación con la frecuencia de Nyquist\n\n(2puntos) ¿Cuál es el tipo de filtro que utiliza una función de transferencia con polos y ceros para eliminar frecuencias específicas?\n\nFiltro FIR (Finite Impulse Response)\nFiltro IIR (Infinite Impulse Response)\nFiltro adaptativo\nFiltro Kalman\n\n(2puntos) ¿Cuáles de las siguientes afirmaciones sobre la transformada rápida de Fourier son correctas?\n\nGenera la representación de la señal en el dominio de la frecuencia.\nGenera la representación de la señal en el dominio del tiempo.\nGenera la representación de la señal en el dominio de la amplitud.\nEs un algoritmo computacional.\n\n(2puntos) A continuación marque las afirmaciones que considere correctas:\n\nUn filtro tipo Butterworth no puede tener respuesta pasabanda.\nLos filtros FIR (finite impulse response) siempre son estables.\nLos filtros Butterworth se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante.\nLos filtros Chebyshev no se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante."
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0001.html#primera-sección-10-puntos",
    "href": "evaluaciones/Examen0001/Examen0001.html#primera-sección-10-puntos",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "",
    "text": "Marque la(s) opción(es) correcta(s)\n\n(2puntos) ¿En el dominio de la frecuencia, Cuál es el efecto de la convolución entre una señal y un kernel?\n\nSe convierte en una multiplicación entre el kernel y la señal\nSiempre se introduce un retraso en la señal en el dominio del tiempo\nCrea un efecto de periodicidad en la señal\nElimina las componentes de alta frecuencia dependiendo del kernel\n\n(2puntos) ¿Cuál es la relación entre la frecuencia de muestreo y la frecuencia de Nyquist en un sistema de muestreo?\n\nLa frecuencia de muestreo debe ser igual a la frecuencia de Nyquist\nLa frecuencia de muestreo debe ser el doble de la frecuencia de Nyquist\nLa frecuencia de muestreo puede ser menor que la frecuencia de Nyquist\nLa frecuencia de muestreo no tiene relación con la frecuencia de Nyquist\n\n(2puntos) ¿Cuál es el tipo de filtro que utiliza una función de transferencia con polos y ceros para eliminar frecuencias específicas?\n\nFiltro FIR (Finite Impulse Response)\nFiltro IIR (Infinite Impulse Response)\nFiltro adaptativo\nFiltro Kalman\n\n(2puntos) ¿Cuáles de las siguientes afirmaciones sobre la transformada rápida de Fourier son correctas?\n\nGenera la representación de la señal en el dominio de la frecuencia.\nGenera la representación de la señal en el dominio del tiempo.\nGenera la representación de la señal en el dominio de la amplitud.\nEs un algoritmo computacional.\n\n(2puntos) A continuación marque las afirmaciones que considere correctas:\n\nUn filtro tipo Butterworth no puede tener respuesta pasabanda.\nLos filtros FIR (finite impulse response) siempre son estables.\nLos filtros Butterworth se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante.\nLos filtros Chebyshev no se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante."
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0001.html#segunda-sección-20-puntos",
    "href": "evaluaciones/Examen0001/Examen0001.html#segunda-sección-20-puntos",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "Segunda sección (20 puntos)",
    "text": "Segunda sección (20 puntos)\n\nMarque las opciones que considere correctas\nLas preguntas de esta sección se basan en la siguiente Figura.\n\n\n\nFigura sección 2\n\n\n\n(20 puntos) ¿Cuáles de las siguientes afirmaciones considera correcta?\n\nLa función descrita en la Figura adjunta tiene naturaleza contínua.\nLa función descrita en la figura representa a una función de densidad de probabilidad.\nLa función se definió a trozos. Entre 0 y 2 la función vale 0. Entre 2 y 4 la función vale \\(0.25x - 0.5\\). Finalmente, entre 4 y 5 la función vale 0.\nEl valor esperado de la función de densidad de probabilidad es 3."
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0001.html#tercer-sección20-puntos",
    "href": "evaluaciones/Examen0001/Examen0001.html#tercer-sección20-puntos",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "Tercer sección(20 puntos)",
    "text": "Tercer sección(20 puntos)\n::: {#cell-tercer seccion .cell execution_count=1}\n\n\n\n\n\n\n\n:::\n\nSe tiene que la señal f(t) está descrita por la ecuación \\(f\\left(t\\right) = 10sin\\left(2\\pi t\\right) - 5sin\\left(3\\pi t\\right)+6sin\\left(4\\pi t\\right)\\)\nMarque las opciones que considere correctas\n\n(10 puntos) ¿Cuáles de las siguientes afirmaciones considera correcta?\n\nLa frecuencia de Nyquist es 4Hz\nMuestrear a 3Hz esta bien porque la máxima frecuencia de la señal es 1.5Hz\nSi se sabe que se muestrea a 10Hz, la señal resultante tiene 50 muestras.\nEl espectro de magnitud de Fourier presenta 3 picos en 1Hz, 2Hz, 4Hz.\n\n(10 puntos) ¿Cuáles es el espectro de magnitud correcto?"
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html",
    "href": "evaluaciones/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Write a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Write a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g. normal, binomial)."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes’ Theorem",
    "text": "Exercise 6: Bayes’ Theorem\nWrite a Python program that applies Bayes’ theorem to update the probability of a hypothesis given new evidence."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g. normal, uniform)."
  },
  {
    "objectID": "evaluaciones/eval001_ConductaEntrada.html#exercise-10-monte-carlo-simulation",
    "href": "evaluaciones/eval001_ConductaEntrada.html#exercise-10-monte-carlo-simulation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10: Monte Carlo Simulation",
    "text": "Exercise 10: Monte Carlo Simulation\nWrite a Python program that uses Monte Carlo simulation to estimate the value of pi."
  },
  {
    "objectID": "evaluaciones/Examen0001/codigo.html",
    "href": "evaluaciones/Examen0001/codigo.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0.0, 10.0, 1000)\nx = 0.125*t-0.25\nx[t &lt;= 2] = 0\nx[t &gt;=6] = 0\nplt.plot(t, x)\nplt.grid()\nplt.xlabel(\"X\")\nplt.ylabel(\"f(X)\")\n1/8\n\n0.125\n\n\n\n\n\n\n\n\n\n\nt = np.linspace(0, 5, 1000)\nx = (\n    10 * np.sin(2 * np.pi * t)\n    - 5 * np.sin(2 * np.pi * 2 * t)\n    + 6 * np.sin(2 * np.pi * 3 * t)\n)\nt1 = np.linspace(0, 5, 25)\nx1 = (\n    10 * np.sin(2 * np.pi * t1)\n    - 5 * np.sin(2 * np.pi * 2 * t1)\n    + 6 * np.sin(2 * np.pi * 3 * t1)\n)\nplt.plot(t,x)\nplt.stem(t1,x1, 'ro')\nplt.grid()\n\n\n\n\n\n\n\n\n\nt1 = np.linspace(0, 5, 75)\nx1 = (\n    10 * np.sin(2 * np.pi * t1)\n    - 5 * np.sin(2 * np.pi * 2 * t1)\n    + 6 * np.sin(2 * np.pi * 3 * t1)\n)\nfs = 12\necg_fft = np.fft.fft(x1)\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\nN = len(mag_ecg_fft)\nf_vect1 =  f_vect\nmag_ecg_fft1 = mag_ecg_fft\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\nplt.xlabel(\"Frecuencia Normalizada\")\n\nText(0.5, 0, 'Frecuencia Normalizada')\n\n\n\n\n\n\n\n\n\n\nimport sympy\n\nx = sympy.symbols('x')\n\nf = 0.125 * (x**2) - 0.25*x\n\nsympy.integrate(f, (x, 2, 6))\n\n\\(\\displaystyle 4.66666666666667\\)"
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0002.html",
    "href": "evaluaciones/Examen0001/Examen0002.html",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "",
    "text": "Marque la(s) opción(es) correcta(s)\n\n(2puntos) ¿En el dominio de la frecuencia, Cuál es el efecto de la convolución entre una señal y un kernel?\n\nSe convierte en una multiplicación entre el kernel y la señal\nSiempre se introduce un retraso en la señal en el dominio del tiempo\nCrea un efecto de periodicidad en la señal\nElimina las componentes de alta frecuencia dependiendo del kernel\n\n(2puntos) ¿Cuál es la relación entre la frecuencia de muestreo y la frecuencia de Nyquist en un sistema de muestreo?\n\nLa frecuencia de muestreo debe ser igual a la frecuencia de Nyquist\nLa frecuencia de muestreo debe ser el doble de la frecuencia de Nyquist\nLa frecuencia de muestreo puede ser menor que la frecuencia de Nyquist\nLa frecuencia de muestreo no tiene relación con la frecuencia de Nyquist\n\n(2puntos) ¿Cuál(es) es(son) (los) propósito(s) general(es) del procesamiento de una señal temporal?\n\nExtraer la convolución de la señal\nExtraer información relativa al proceso descrito por la señal\nAsociar las características de la señal con las características del proceso\nDeterminar que kernel de convolución es necesario para eliminar la frecuencia de 60Hz\n\n(2puntos) ¿Cuáles de las siguientes afirmaciones sobre la transformada rápida de Fourier son correctas?\n\nGenera la representación de la señal en el dominio de la frecuencia.\nGenera la representación de la señal en el dominio del tiempo.\nGenera la representación de la señal en el dominio de la amplitud.\nEs un algoritmo computacional.\n\n(2puntos) A continuación marque las afirmaciones que considere correctas:\n\nUn filtro tipo Butterworth no puede tener respuesta pasabanda.\nLos filtros FIR (finite impulse response) siempre son estables.\nLos filtros Butterworth se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante.\nLos filtros Chebyshev no se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante."
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0002.html#primera-sección-10-puntos",
    "href": "evaluaciones/Examen0001/Examen0002.html#primera-sección-10-puntos",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "",
    "text": "Marque la(s) opción(es) correcta(s)\n\n(2puntos) ¿En el dominio de la frecuencia, Cuál es el efecto de la convolución entre una señal y un kernel?\n\nSe convierte en una multiplicación entre el kernel y la señal\nSiempre se introduce un retraso en la señal en el dominio del tiempo\nCrea un efecto de periodicidad en la señal\nElimina las componentes de alta frecuencia dependiendo del kernel\n\n(2puntos) ¿Cuál es la relación entre la frecuencia de muestreo y la frecuencia de Nyquist en un sistema de muestreo?\n\nLa frecuencia de muestreo debe ser igual a la frecuencia de Nyquist\nLa frecuencia de muestreo debe ser el doble de la frecuencia de Nyquist\nLa frecuencia de muestreo puede ser menor que la frecuencia de Nyquist\nLa frecuencia de muestreo no tiene relación con la frecuencia de Nyquist\n\n(2puntos) ¿Cuál(es) es(son) (los) propósito(s) general(es) del procesamiento de una señal temporal?\n\nExtraer la convolución de la señal\nExtraer información relativa al proceso descrito por la señal\nAsociar las características de la señal con las características del proceso\nDeterminar que kernel de convolución es necesario para eliminar la frecuencia de 60Hz\n\n(2puntos) ¿Cuáles de las siguientes afirmaciones sobre la transformada rápida de Fourier son correctas?\n\nGenera la representación de la señal en el dominio de la frecuencia.\nGenera la representación de la señal en el dominio del tiempo.\nGenera la representación de la señal en el dominio de la amplitud.\nEs un algoritmo computacional.\n\n(2puntos) A continuación marque las afirmaciones que considere correctas:\n\nUn filtro tipo Butterworth no puede tener respuesta pasabanda.\nLos filtros FIR (finite impulse response) siempre son estables.\nLos filtros Butterworth se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante.\nLos filtros Chebyshev no se utilizan a menudo en aplicaciones de biomedicina porque tienen un rizado en la banda pasante."
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0002.html#segunda-sección-20-puntos",
    "href": "evaluaciones/Examen0001/Examen0002.html#segunda-sección-20-puntos",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "Segunda sección (20 puntos)",
    "text": "Segunda sección (20 puntos)\n\nMarque las opciones que considere correctas\nLas preguntas de esta sección se basan en Figura 1.\n\n\n\n\n\n\n\n\n\nFigura 1: Posible función de densidad de probabilidad.\n\n\n\n\n\n\n(20 puntos) ¿Cuáles de las siguientes afirmaciones considera correcta?\n\nLa función descrita en la Figura adjunta tiene naturaleza contínua.\nLa función descrita en la figura representa a una función de densidad de probabilidad.\nLa función se definió a trozos. Entre 0 y 2 la función vale 0. Entre 2 y 6 la función vale \\(0.25x - 0.5\\). Finalmente, entre 6 y 10 la función vale 0.\nEl valor esperado de la función de densidad de probabilidad es 3."
  },
  {
    "objectID": "evaluaciones/Examen0001/Examen0002.html#tercer-sección20-puntos",
    "href": "evaluaciones/Examen0001/Examen0002.html#tercer-sección20-puntos",
    "title": "Procesamiento de Señales e Imágenes Médicas",
    "section": "Tercer sección(20 puntos)",
    "text": "Tercer sección(20 puntos)\n\n\n\n\n\n\n\n\nFigura 2: Señal Temporal\n\n\n\n\n\n\nSe tiene que la señal f(t) está descrita por la ecuación \\(f\\left(t\\right) = 10sin\\left(2\\pi t\\right) - 5sin\\left(4\\pi t\\right)+6sin\\left(6\\pi t\\right)\\). Ver Figura 2.\n\n\n\n\n\n\n\n\n\nFigura 3: Proceso de muestreo\n\n\n\n\n\n\nMarque las opciones que considere correctas\n\n(10 puntos) ¿Cuáles de las siguientes afirmaciones considera correcta?\n\nLa frecuencia de Nyquist es 4Hz\nMuestrear a 3Hz esta bien porque la máxima frecuencia de la señal es 1.5Hz\nSi se sabe que se muestrea a 10Hz, la señal resultante tiene 50 muestras.\nEl espectro de magnitud de Fourier presenta 3 picos en 1Hz, 2Hz, 4Hz.\n\n(10 puntos) Si se tiene el proceso de muestreo visto en Figura 3, marque las afirmaciones que considere correctas.\n\nLa frecuencia de muestreo es de 5Hz.\nExiste aliasing.\nLa frecuencia de muestreo es de 10Hz\nNo existe aliasing"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‘Machine Learning with R’ by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book’s specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book’s examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\n\n2. Visualizing distributions\n\n\n3. Exploring relationships between variables\n\n\n4. Analyzing categorical variables"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "Model Implementation",
    "text": "Model Implementation"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "Train Model",
    "text": "Train Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance"
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html",
    "href": "codigo/ASIM/cod001_Kaggle.html",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "href": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‘Machine Learning with R’ by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book’s specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book’s examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution\n\ndata_path = \"../../data/\""
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load\n\ndata = pd.read_csv(data_path+\"insurance_2.csv\")\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\nNumber of GPUs available: 1\nGPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   salary    1338 non-null   float64\n 6   region    1338 non-null   object \n 7   charges   1338 non-null   float64\ndtypes: float64(3), int64(2), object(3)\nmemory usage: 83.8+ KB\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\ncount\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n\n\nmean\n39.207025\n30.663397\n1.094918\n159064.411451\n13270.422265\n\n\nstd\n14.049960\n6.098187\n1.205493\n41741.994963\n12110.011237\n\n\nmin\n18.000000\n15.960000\n0.000000\n104622.922023\n1121.873900\n\n\n25%\n27.000000\n26.296250\n0.000000\n130087.161933\n4740.287150\n\n\n50%\n39.000000\n30.400000\n1.000000\n146740.897257\n9382.033000\n\n\n75%\n51.000000\n34.693750\n2.000000\n171897.191284\n16639.912515\n\n\nmax\n64.000000\n53.130000\n5.000000\n338460.517246\n63770.428010\n\n\n\n\n\n\n\n\ndata.select_dtypes(\"object\")\n\n\n\n\n\n\n\n\nsex\nsmoker\nregion\n\n\n\n\n0\nfemale\nyes\nsouthwest\n\n\n1\nmale\nno\nsoutheast\n\n\n2\nmale\nno\nsoutheast\n\n\n3\nmale\nno\nnorthwest\n\n\n4\nmale\nno\nnorthwest\n\n\n...\n...\n...\n...\n\n\n1333\nmale\nno\nnorthwest\n\n\n1334\nfemale\nno\nnortheast\n\n\n1335\nfemale\nno\nsoutheast\n\n\n1336\nfemale\nno\nsouthwest\n\n\n1337\nfemale\nyes\nnorthwest\n\n\n\n\n1338 rows × 3 columns\n\n\n\n\ndata[\"sex\"] = data[\"sex\"].astype(\"category\")\ndata[\"smoker\"] = data[\"smoker\"].astype(\"category\")\ndata[\"region\"] = data[\"region\"].astype(\"category\")\n\n\ndata.select_dtypes(\"number\")\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\n0\n19\n27.900\n0\n159272.812482\n16884.92400\n\n\n1\n18\n33.770\n1\n117088.625944\n1725.55230\n\n\n2\n28\n33.000\n3\n129043.852213\n4449.46200\n\n\n3\n33\n22.705\n0\n194635.486180\n21984.47061\n\n\n4\n32\n28.880\n0\n113585.904592\n3866.85520\n\n\n...\n...\n...\n...\n...\n...\n\n\n1333\n50\n30.970\n3\n145933.927725\n10600.54830\n\n\n1334\n18\n31.920\n0\n117665.917758\n2205.98080\n\n\n1335\n18\n36.850\n0\n133402.353115\n1629.83350\n\n\n1336\n21\n25.800\n0\n133975.682996\n2007.94500\n\n\n1337\n61\n29.070\n0\n216658.755628\n29141.36030\n\n\n\n\n1338 rows × 5 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   age       1338 non-null   int64   \n 1   sex       1338 non-null   category\n 2   bmi       1338 non-null   float64 \n 3   children  1338 non-null   int64   \n 4   smoker    1338 non-null   category\n 5   salary    1338 non-null   float64 \n 6   region    1338 non-null   category\n 7   charges   1338 non-null   float64 \ndtypes: category(3), float64(3), int64(2)\nmemory usage: 56.8 KB\n\n\n\n\n2. Visualizing distributions\n\nsns.histplot(data[\"bmi\"], stat=\"probability\")\n\n\n\n\n\n\n\n\n\n\n3. Exploring relationships between variables\n\nsns.scatterplot(data=data, x=\"bmi\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\n\n4. Analyzing categorical variables\n\nsns.countplot(data=data, x=\"smoker\", stat=\"probability\")\n\n\n\n\n\n\n\n\n\nsns.boxplot(data=data, y=\"charges\", x=\"smoker\")\n\n\n\n\n\n\n\n\n\nsns.pointplot(data=data, x=\"sex\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\ng001 = sns.FacetGrid(data=data, col=\"smoker\", row=\"sex\")\ng001.map(plt.scatter, \"bmi\", \"charges\")\n\n\n\n\n\n\n\n\n\nsns.regplot(data=data, x=\"salary\", y=\"charges\",\n            scatter_kws={\"color\": \"blue\"},  # Color de los puntos\n            line_kws={\"color\": \"red\"})"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "title": "Health Care Cost Predictor",
    "section": "5. Checking availability of GPU",
    "text": "5. Checking availability of GPU\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\ndevice1\n\nUsing device: cuda:0\n\n\ndevice(type='cuda', index=0)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "title": "Health Care Cost Predictor",
    "section": "6. Splitting data",
    "text": "6. Splitting data\n\nentrada = data[\"salary\"].to_numpy().reshape(-1, 1)\nsalida = data[\"charges\"].to_numpy().reshape(-1, 1)\n\n\nstandarScaler_features = StandardScaler().fit(entrada)\nstandarScaler_output = StandardScaler().fit(salida)\n\n\nsalary_train, salary_test, charges_train, charges_test = train_test_split(\n    standarScaler_features.transform(entrada),\n    standarScaler_output.transform(salida),\n    train_size=0.7,\n    shuffle=True,\n)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "title": "Health Care Cost Predictor",
    "section": "7. Converting Data To Tensor",
    "text": "7. Converting Data To Tensor\n\nt_salary_train = torch.tensor(salary_train, dtype=torch.float32, device=device1)\nt_salary_test = torch.tensor(salary_test, dtype=torch.float32, device=device1)\nt_charges_train = torch.tensor(charges_train, dtype=torch.float32, device=device1)\nt_charges_test = torch.tensor(charges_test, dtype=torch.float32, device=device1)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "8. Model Implementation",
    "text": "8. Model Implementation\n\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\nmodel = LinearRegression().to(device1)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "10. Train Model",
    "text": "10. Train Model\n\nnum_epochs = 1000\nfor epoch in range(num_epochs):\n\n     # Fordward Pass and loss\n\n     charges_predicted = model(t_salary_train)\n     loss = criterion(charges_predicted, t_charges_train)\n\n     # Backward pass\n     loss.backward()\n\n     #wweights update\n     optimizer.step()\n     optimizer.zero_grad()\n\n     # Progress tracking\n\n     if (epoch+1)%10 ==0:\n          print(f\"Epoch: {epoch+1}, loss={loss.item():.4f}\")\n\nEpoch: 10, loss=1.2763\nEpoch: 20, loss=0.8460\nEpoch: 30, loss=0.5655\nEpoch: 40, loss=0.3828\nEpoch: 50, loss=0.2637\nEpoch: 60, loss=0.1861\nEpoch: 70, loss=0.1355\nEpoch: 80, loss=0.1026\nEpoch: 90, loss=0.0811\nEpoch: 100, loss=0.0671\nEpoch: 110, loss=0.0579\nEpoch: 120, loss=0.0520\nEpoch: 130, loss=0.0481\nEpoch: 140, loss=0.0456\nEpoch: 150, loss=0.0439\nEpoch: 160, loss=0.0428\nEpoch: 170, loss=0.0421\nEpoch: 180, loss=0.0417\nEpoch: 190, loss=0.0414\nEpoch: 200, loss=0.0412\nEpoch: 210, loss=0.0411\nEpoch: 220, loss=0.0410\nEpoch: 230, loss=0.0409\nEpoch: 240, loss=0.0409\nEpoch: 250, loss=0.0409\nEpoch: 260, loss=0.0408\nEpoch: 270, loss=0.0408\nEpoch: 280, loss=0.0408\nEpoch: 290, loss=0.0408\nEpoch: 300, loss=0.0408\nEpoch: 310, loss=0.0408\nEpoch: 320, loss=0.0408\nEpoch: 330, loss=0.0408\nEpoch: 340, loss=0.0408\nEpoch: 350, loss=0.0408\nEpoch: 360, loss=0.0408\nEpoch: 370, loss=0.0408\nEpoch: 380, loss=0.0408\nEpoch: 390, loss=0.0408\nEpoch: 400, loss=0.0408\nEpoch: 410, loss=0.0408\nEpoch: 420, loss=0.0408\nEpoch: 430, loss=0.0408\nEpoch: 440, loss=0.0408\nEpoch: 450, loss=0.0408\nEpoch: 460, loss=0.0408\nEpoch: 470, loss=0.0408\nEpoch: 480, loss=0.0408\nEpoch: 490, loss=0.0408\nEpoch: 500, loss=0.0408\nEpoch: 510, loss=0.0408\nEpoch: 520, loss=0.0408\nEpoch: 530, loss=0.0408\nEpoch: 540, loss=0.0408\nEpoch: 550, loss=0.0408\nEpoch: 560, loss=0.0408\nEpoch: 570, loss=0.0408\nEpoch: 580, loss=0.0408\nEpoch: 590, loss=0.0408\nEpoch: 600, loss=0.0408\nEpoch: 610, loss=0.0408\nEpoch: 620, loss=0.0408\nEpoch: 630, loss=0.0408\nEpoch: 640, loss=0.0408\nEpoch: 650, loss=0.0408\nEpoch: 660, loss=0.0408\nEpoch: 670, loss=0.0408\nEpoch: 680, loss=0.0408\nEpoch: 690, loss=0.0408\nEpoch: 700, loss=0.0408\nEpoch: 710, loss=0.0408\nEpoch: 720, loss=0.0408\nEpoch: 730, loss=0.0408\nEpoch: 740, loss=0.0408\nEpoch: 750, loss=0.0408\nEpoch: 760, loss=0.0408\nEpoch: 770, loss=0.0408\nEpoch: 780, loss=0.0408\nEpoch: 790, loss=0.0408\nEpoch: 800, loss=0.0408\nEpoch: 810, loss=0.0408\nEpoch: 820, loss=0.0408\nEpoch: 830, loss=0.0408\nEpoch: 840, loss=0.0408\nEpoch: 850, loss=0.0408\nEpoch: 860, loss=0.0408\nEpoch: 870, loss=0.0408\nEpoch: 880, loss=0.0408\nEpoch: 890, loss=0.0408\nEpoch: 900, loss=0.0408\nEpoch: 910, loss=0.0408\nEpoch: 920, loss=0.0408\nEpoch: 930, loss=0.0408\nEpoch: 940, loss=0.0408\nEpoch: 950, loss=0.0408\nEpoch: 960, loss=0.0408\nEpoch: 970, loss=0.0408\nEpoch: 980, loss=0.0408\nEpoch: 990, loss=0.0408\nEpoch: 1000, loss=0.0408\n\n\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )\n\n\n\n\n\n\n\n\n\ns_predicha = standarScaler_output.inverse_transform(prediction.cpu().numpy())\ns_real = standarScaler_output.inverse_transform(charges_test)\n\nresiduos = s_real- s_predicha\n\nsm.graphics.tsa.plot_acf(residuos, lags=100)"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html",
    "title": "Estudio de arritmia cardíaca",
    "section": "",
    "text": "from google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librerías",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librerías",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de librerías",
    "text": "Carga de librerías\n\nnumpy: Para manipulación numérica y funciones estadísticas básicas\nmatplotlib.pyplot: Para generación de gráficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#configuración-de-carpetas",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#configuración-de-carpetas",
    "title": "Estudio de arritmia cardíaca",
    "section": "Configuración de carpetas",
    "text": "Configuración de carpetas\n\ndata_path = \"/content/drive/MyDrive/ECG_Dataset/\""
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nSuposse…\n\n\nA dataset of M tuples \\((\\mathbf{x}_i, \\mathbf{y}_i)\\) with i = 1, …, M.\n\n\\(\\mathbf{x}_i\\): Inputs\n\\(\\mathbf{y}_i\\): Outputs\n\n\n\n\n\n\n\n\n\n\n\n\nWhat it is a neural network\n\n\nIs a mathematical function (sometimes called a network function) that takes some kind of input (typically multi-dimensional) called x iand generate some output."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nNetwork function\n\n\n\nThe output generated by the network function is called \\(\\hat{y}_i\\)\nThe network function normally depends on a certain number N of parameters, which we will indicate with \\(\\mathbf{\\theta}_k\\) \\[ \\mathbf{\\hat{y}}_i = f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), where, k=0,1,2,\\ldots,N \\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nImportante\n\n\nA neural network is nothing more than a mathematical function that depends on a set of parameters that are tuned, hopefully in some smart way, to make the network output as close as possible to some expected output.\n\n\n\n\n\n\n\n\\(\\mathbf{x}_i \\in \\mathbb{R}^n\\)\n\\(\\mathbf{y}_i \\in \\mathbb{R}^k\\)\n\\(i = 0,1,2,\\ldots,M\\)\n\\(\\mathbf{\\theta}_k \\in \\mathbb{R}^N\\)\n\\(k = 0,1,2,\\ldots,N\\)\n\n\n\nLoss function \\(L \\left( \\mathbf{\\hat{y}}_i, \\mathbf{y}_i \\right) = L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\)\nLoss function measures how close are \\(\\mathbf{\\hat{y}}_i\\) and \\(\\mathbf{y}_i\\)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nLearning\n\n\n\n$ _{_k ^N} L ( f ( _k, _i ), _i ) $\n\\(\\min_{\\mathbf{\\theta}_k \\in \\mathbb{R}^N} L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\) subject to \\(c_q, q=1,2,3,\\ldots,Q\\) with \\(Q \\in \\mathbb{N}\\)\nThe learning process is the search of a minima. However, most of the algorithms can search only a “local” minima.\nIn principle, we want to find the global minimum or, in other words, the point for which the function value is the smallest between all possible points.\n\n\n\n\n\n\nIdentifying if the minimum is a local or a global minimum is impossible, due to the network function complexity.\nThis is one (albeit not the only one) of the reasons that training large neural networks is such a challenging numerical problem."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "A single neuron",
    "text": "A single neuron"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Neural Network",
    "text": "Neural Network"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Neural Network",
    "text": "Neural Network\n\nTaken from GeeksforGeeks"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\nNeural Networks have a great number of internal parameters for learning; which varying in a vast range of values.\nThis number of parameters is fundamental for neural network knowledge representation\n\n\n\n\n\n\n\nProblem\n\n\nBut if this number increases too much the neural network is prone to overfitting"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\n\n\n\n\n\n\nDefinition\n\n\nRegularization techniques reduce the possibility of a neural network overfitting by constraining the range of values that the weight values within the network hold.\n\n\n\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\nRegularization works on assumption that smaller weights generate simpler model and thus helps avoid overfitting.\nThe simpler model is less prone to overfitting.\nAdding the regularization term to the sum of squared differences between the actual value and predicted value."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k\n\\end{eqnarray}\\]\n\n\n\n\n\n\n\nNota\n\n\n\\(\\lambda\\) is the penalty term or regularization parameter which determines how much to penalizes the weights."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Types of Regularization",
    "text": "Types of Regularization\n\n\nL1 Regularization or Lasso or L1 norm\n\nL1 penalizes sum of absolute value of weights.\nL1 has a sparse solution.\nL1 has multiple solutions.\nL1 has built in feature selection.\nL1 is robust to outliers.\nL1 generates model that are simple and interpretable but cannot learn complex patterns.\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\lvert \\theta_k \\rvert\n\\end{eqnarray}\\]\n\nL2 Regularization or Ridge Regularization\n\nL2 regularization penalizes sum of square weights.\nL2 has a non sparse solution\nL2 has one solution\nL2 has no feature selection\nL2 is not robust to outliers\nL2 gives better prediction when output variable is a function of all input features\nL2 regularization is able to learn complex data patterns\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation",
    "text": "Evaluation\n\n\n\n\n\n\n\nRegression\n\n\n\n\\(R^2\\)\nResidual graph\nAutocorrelation analysis\n\n\n\n\n\n\n\n\n\n\n\n\nClassification\n\n\n\nConfusion Matrix(Matriz de Confusión)\nPrecision(Precisión)\nRecall(Exhaustividad)\nF1-score(Valor-F)\nAccuracy(Exactitud)\nTrue Positive(Positivos Verdaderos)\nTrue Negative(Negativos Verdaderos)\nFalse Positive(Positivos Falsos)\nFalse Negative(Negativos Falsos)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nConfusion Matrix\n\n\n“Also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one.”"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nTrue Negative\n\n\nValues that being negative have been classified as negative\n\n\n\n\n\n\n\n\n\n\n\nTrue Positive\n\n\nValues that being positive have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Positive\n\n\nValues that being negative have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Negative\n\n\nValues that being negative have been classified as positive"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nSensitivity\n\n\nHow good is my classifier at detecting positive cases? \\[ \\frac{TP}{TP+FN} \\]\n\n\n\n\n\n\n\n\n\n\n\nSpecificity\n\n\nHow good is my classifier at avoiding negative cases? \\[ \\frac{TN}{TN+FP} \\]\n\n\n\n\n\n\n\n\n\n\n\n\nPrecision\n\n\nHow credible is my classifier when it detects a positive case? \\[\\frac{TP}{TP+FP}\\]\n\n\n\n\n\n\n\n\n\n\n\nAccuracy and Balance Accuracy\n\n\nHow many cases the classifier correctly identifies? \\[Accuracy = \\frac{TP+TN}{TP+FP+FN+TN}\\] \\[BalancedAccuracy = \\frac{Specificity+Sensitivity}{2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nPrevalence\n\n\nHow often does the positive condition actually occur in our sample? \\[\\frac{TP+FN}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nDetection Rate\n\n\nPercentage of true positives \\[\\frac{TP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nDetection Prevalence\n\n\nPercentage of positives \\[\\frac{TP+FP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nHarmonic mean of recall and precision.\n\n\n\\[2\\frac{\\left( Precision \\right) \\left( Sensitivity \\right)}{Precision+Sensitivity}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 1"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 2"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\n\n\nFor Class 3\n\n\n\n\n\n\nhttps://pablocaicedor.github.io/"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Linear Regression",
    "text": "Linear Regression"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Linear Regression",
    "text": "Linear Regression\nIn the example, in previous slide, data was modelled as a linear function. The difference (error) between the modelled data \\(\\left( \\hat{y}_n \\right)\\) and actual data \\(\\left( y_n \\right)\\) can be written as\n\n\n\n\n\n\n\nCost function\n\n\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Some other examples of cost function",
    "text": "Some other examples of cost function\n\\[E = \\sqrt{\\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}}\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left| \\hat{y}_n - y_n \\right| }\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nLooking the cost surface, we notices that this surface has a global minimum. If we could have an algorithm which automatically finds it.\n\nCost Surface"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nIndeed, there are multiples algorithms for minima searching. The most famous is the one named as least squares but in this course we will use the gradient descent algorithm.\nAssuming that the data model is a function \\(f\\left(\\theta_i, x_n, y_n\\right)\\), where \\(\\theta\\) is known as model parameter.\n\n\n\n\n\n\n\nThe gradient descent algorithm\n\n\n\\[\\boldsymbol{\\theta}_{i,j+1} =  \\boldsymbol{\\theta}_{i,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{i}}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\nAssumptions\n\n\n\nLinear model for the Regression\nMean square error as cost function\n\\(\\eta = 1\\)\n\n\n\n\n\n\\[\\boldsymbol{\\theta}_i = \\left[ \\theta_1, \\theta_0 \\right]^T\\]\n\\[\\hat{y}_n  = \\theta_1 x_n + \\theta_0\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_1\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{1,j+1} = \\boldsymbol{\\theta}_{1,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right) x_n}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_0\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{0,j+1} = \\boldsymbol{\\theta}_{0,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  E & = & \\frac{1}{N} \\sqrt{u}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{1}{2 N \\sqrt{u}} \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}}\\\\\n  \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}} &=& 2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{2 N \\sqrt{u}}\n\\end{eqnarray}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} &=& \\frac{\\sum_{n=1}^{N}{x_n \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{2}} &=& \\frac{\\sum_{n=1}^{N}{x_n^2 \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\n\\end{eqnarray}\n\\]\n\n\n\n\nhttps://pablocaicedor.github.io/"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\nDefinition\n\n\n\nTwo-dimensional function, f(x, y)\nWhere x and y are spatial coordinates.\nThe amplitude of f at any pair of coordinates (x, y) is called the intensity.\n\n\n\n\n\n\n\n\n\n\n\n\nThe digital image\n\n\nIf the coordinates and the intensity are discrete quantities the image turns into a digital image."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\nDefinition\n\n\nA digital image is composed by a finite number of elements called PIXEL.\n\n\n\n\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\n\nDepth\n\n\n\nA digital image is composed by a finite number of elements called PIXEL. Bpp( Bits per pixel)\n\n1bpp. B/W image, monochrome.\n2bpp. CGA Image.\n4bpp. Minimun for VGA standard.\n8bpp. Super-VGA image.\n24bpp. Truecolor image.\n48bpp. Professional-level images."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\n\nColor Space\n\n\nHow can i represent the color\n\nRGB.\nCMYK.\nHSV.\nAmong others."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "What is Digital Image Processing?",
    "text": "What is Digital Image Processing?\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"image01.tif\")\nfig001 = plt.figure()\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"lena.tif\")\nRGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig002 = plt.figure()\nplt.imshow(RGB_img)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nThe paradigm surrounding the conceptualization of light and perception has undergone significant evolution.\nInitially, the prevailing understanding within humanity posited that visual stimuli emanated from the eye itself.\nHowever, contemporary knowledge has elucidated that light originates from external sources, undergoes reflection from objects within the environment, and is subsequently captured by the eye."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nImportant\n\n\nWe also understand that light is a type of electromagnetic radiation, and its wavelength falls within a range from 400 nanometers to 700 nanometers.\n\n\n\n\n\nTaken from Corke 2023"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nImportant\n\n\n\nThe most common way light is made is by something getting really hot. This makes energy that comes out as light.\nSome important term are:\n\nAbsortion: It is the fraction of light which a body absorbs depending on the wavelength.\nReflectance: It is the fraction of the incoming light which a body reflects. It’s a number between 0 to 1 and also depends on wavelength.\nLuminance: It is the fraction of the incoming light which a surface reflects. It’s a function of absortion and reflectance, and because of that luminance depends on wavelength."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nThe eye\n\n\n\nOur eye has two types of cells. Cones and Rods.\nCones are the most sensitive cells but above all these are color sensitive.\nRods responds only two intensity and they used on night, mostly.\nHumans, like most primates, are trichomats. This means that humans have three types of cones (Long, Medium and shorts).\n\n65% of longs (Sense red)\n33% of mediums (Sense green)\n2% of shortsv(Sense blue)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\n\n\n\n\n\n\nThe artificial eye\n\n\n\n\n\nTaken from Corke 2023\n\n\n\n\n\n\nThe currents from each sensor are function of the luminance and the spectral response filter."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Images and vision",
    "text": "Images and vision\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\n\n\n\n\n\n\nDefinition\n\n\nSampling: Digitalization of the spatial coordinates.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nQuantiazation: Digitalization of the light intensity (amplitude)."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1bit\n\n\n\n\n\n\n\n\n\n2bit\n\n\n\n\n\n\n\n\n\n3bit\n\n\n\n\n\n\n\n\n\n4bit\n\n\n\n\n\n\n\n\n\n\n\n5bit\n\n\n\n\n\n\n\n\n\n6bit\n\n\n\n\n\n\n\n\n\n7bit\n\n\n\n\n\n\n\n\n\n8bit"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Linear indexing",
    "text": "Linear indexing\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\nFrom normal to linear\n\n\n\\[\\alpha = My+x\\]\n\n\n\n\n\n\n\n\n\n\n\n\nFrom linear to normal\n\n\n\\[x = \\alpha \\bmod M\\]\n\\[y = \\frac{\\alpha - x}{M}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Spatial resolution",
    "text": "Spatial resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Intensity resolution",
    "text": "Intensity resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Intensity resolution",
    "text": "Intensity resolution\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "“A simple problem”",
    "text": "“A simple problem”\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "“A simple problem”",
    "text": "“A simple problem”\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\nNeighborhood\n\n\n\n\n\n\n\n\n\n\nN4\n\n\n\n\n\n\n\nND\n\n\n\n\n\n\n\nN8\n\n\n\n\n\n\nFigura 1"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Neighborhood",
    "text": "Relationships between pixels – Neighborhood\n\n\n\n\n\n\n\nNeighborhood\n\n\n\n\n\n\n\n\n\n\nN4-\\(N_4\\left(p\\right)\\)\n\n\n\n\n\n\n\nND-\\(N_D\\left(p\\right)\\)\n\n\n\n\n\n\n\nN8-\\(N_8\\left(p\\right)\\)\n\n\n\n\n\n\nFigura 2: Neighborhoods"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Adjacency",
    "text": "Relationships between pixels – Adjacency\n\n\n\n\n\n\n\nRules for adjecency\n\n\n\n4-Adjecncy: Two pixels p and q with values from V are 4-adjacent if q is in the set \\(N_4\\left(p\\right)\\)\n8-adjacency. Two pixels p and q with values from V are 8-adjacent if q is in the set \\(N_8\\left(p\\right)\\)\nm-adjacency (also called mixed adjacency). Two pixels p and q with values from V are m-adjacent if:\n\nq is in \\(N_4\\left(p\\right)\\).\nq is in \\(N_D\\left(p\\right)\\) and the set \\(N_4\\left(p\\right) \\cap N_4\\left(q\\right)\\) has no pixels whose values are from V."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\nAdjacency"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\n\n\n\n\n\n\nA4\n\n\n\n\n\n\n\n\n\n\n\nA8\n\n\n\n\n\n\n\n\n\n\n\n\n\nA-m"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Path",
    "text": "Relationships between pixels – Path\n\n\n\n\n\n\n\nDigital path\n\n\nIt is a sequence of adjacent pixels.\n\\[\\left(x_0, y_0\\right), \\left(x_1, y_1\\right), \\left(x_2, y_2\\right), \\dots \\left(x_n, y_n\\right)\\]\nIf \\(\\left(x_0, y_0\\right)=\\left(x_n, y_n\\right)\\) the path is known as closed path\nLet S represent a subset of pixels in an image. Two pixels p and q are said to be connected in S if there exists a path between them consisting entirely of pixels in S."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Path, Connected Subset",
    "text": "Relationships between pixels – Path, Connected Subset"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Regions",
    "text": "Relationships between pixels – Regions"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Boundary",
    "text": "Relationships between pixels – Boundary"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Distance",
    "text": "Relationships between pixels – Distance\n\n\n\n\n\n\n\nDistance\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels",
    "text": "Relationships between pixels\n\n\n\n\n\n\n\nDistance\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)\n\n\n\n\n\n\n\n\n\n\nhttps://pablocaicedor.github.io/"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\n\nBio - That came from a biological being\nSignal - A signal is a function that conveys information about a physical phenomenon.\nBiosignals - The search for information from living systems to know its health state"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\nThe codification of biosignals into variations: * Electrical * Mechanical * Chemical * Thermal"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1791: Luigi Galvani discovers electrical signals in living tissues (frog legs)\n1830s: Carlo Matteucci studies electrical signals in the heart\n1887: Willem Einthoven invents the first electrocardiograph (ECG)\n1900s: James Mackenzie develops the first clinical ECG machine"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1920s: Electroencephalography (EEG) is developed by Hans Berger\n1930s: Electromyography (EMG) is developed by John Humphrey and others\n1940s: Development of the first commercial ECG machines\n1950s: Signal processing techniques are applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1960s: Digital signal processing and computer analysis of biomedical signals emerge\n1970s: Biomedical signal processing becomes a recognized field\n1980s: Development of Holter monitoring (24-hour ECG)\n1990s: Advances in signal processing and machine learning applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n2000s: Development of wearable devices and mobile health (mHealth) technologies\n2010s: Emergence of big data analytics and cloud computing in biomedical signal processing\n2020s: Integration of artificial intelligence (AI) and machine learning (ML) in biomedical signal processing"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1895: Wilhelm Roentgen discovers X-rays, leading to medical imaging\n1900s: X-ray technology improves with development of modern X-ray tubes\n1913: Albert Salomon develops mammography\n1920s: Ultrasound technology is developed by Karl Dussik and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1930s: Nuclear medicine emerges with development of radioactive tracers\n1950s: Computed Tomography (CT) scans are developed by Godfrey Hounsfield and Allan McLeod Cormack\n1960s: Development of medical ultrasound imaging\n1970s: Magnetic Resonance Imaging (MRI) is developed by Richard Ernst and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1980s: Digital image processing and analysis techniques are applied to biomedical images\n1990s: Advances in MRI and CT scan technology, including 3D imaging\n2000s: Development of functional MRI (fMRI), diffusion tensor imaging (DTI), and other advanced MRI techniques\n2010s: Emergence of artificial intelligence (AI) and machine learning in medical imaging"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nAdditional Milestones:\n\n1950s: Development of medical electronics and instrumentation\n1960s: First medical imaging computers are developed\n1970s: Development of digital image processing and analysis software\n1980s: Emergence of medical imaging informatics and PACS (Picture Archiving and Communication Systems)\n1990s: Development of telemedicine and teleradiology\n2000s: Emergence of electronic health records (EHRs) and health information exchanges (HIEs)\n2010s: Development of personalized medicine and precision health initiatives"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\n\n\n\n\n\n\nDefinition\n\n\nAn experiment is a physical procedure that produces some kind of result.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAn event is a set of experiment’s possible results.\n\n\n\n\n\n\n\n\n\n\n\nConsejo\n\n\nA sample space is the set of ALL possibles results of an experiment."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\nGraphCodeSample SpaceResultDataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata = np.genfromtxt(\"../../data/mitbih_train.csv\", delimiter=\",\")\necg1 = data[1, :-1]\ntime = np.array(range(0,len(ecg1)))/125\nfig = plt.figure()\nplt.plot(time, ecg1)\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Normalized ECG\")\n\n\n\n\nprint(\"Maximun Value: \"+ str(ecg1.max()))\n\nMaximun Value: 1.0\n\nprint(\"Minimun Value: \"+ str(ecg1.min()))\n\nMinimun Value: 0.0\n\n\n\n\n\nprint(ecg1[np.random.choice(ecg1.shape[0], 1, replace=False)])\n\n[0.03133903]\n\n\n\n\nName: ECG Heartbeat Categorization Dataset.\nURL: https://www.kaggle.com/datasets/shayanfazeli/heartbeat?resource=download"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Probability Axioms",
    "text": "Probability Axioms\nFor the given events A and B that are in a sample space S:\n\n\n\n\n\n\n\nAxioms\n\n\n\n\\(0 \\leq P_r \\left(A\\right) \\leq 1\\)\n\\(P_r\\left(S\\right) = 1\\)\nIf \\(A \\cap B = \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right)\\)\nIf \\(A \\cap B \\neq \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right) - P_r\\left(A \\cap B \\right)\\)\n\\(P_r\\left(\\bar{A}\\right) = 1-P_r \\left(A\\right)\\)\nIf \\(A\\subset B\\) then \\(P_r \\left(A\\right)\\leq P_r \\left(B\\right)\\)\n\\(P_r \\left(A|B\\right)=\\frac{P_r \\left(A\\cap B\\right)}{P_r \\left(B\\right)}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable\n\n\n\n\n\n\n\nDefinition\n\n\nA random variable is a real valued function of the elements of a sample space, S . Given an experiment, E , with sample space, S, the random variable maps each possible outcome of E.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nThe probability mass function (PMF), \\(P_X\\left(x\\right)\\), of a random variable, X, is a function that assigns a probability to each possible value of the random variable, X."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nConditions\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sum_{\\chi \\in X}P_X\\left(\\chi \\right) = 1\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\int_{-\\infty}^{\\infty}P_X\\left(\\chi \\right)d\\chi = 1\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nExpected Values\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\mu = \\sum_{\\chi \\in X}\\chi P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\mu=\\int_{-\\infty}^{\\infty}\\chi P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nVariance\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sigma^2 = \\sum_{\\chi \\in X}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\sigma^2 = \\int_{-\\infty}^{\\infty}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "PDF Estimation",
    "text": "PDF Estimation\n\nGraphCodeExp. ValueVariance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncounts01, bin_edges01 = np.histogram(ecg1, bins=10, density=True)\ncounts02, bin_edges02 = np.histogram(ecg1, bins=50, density=True)\ncounts03, bin_edges03 = np.histogram(ecg1, bins=100, density=True)\nfig01=plt.figure()\nplt.plot(bin_edges01[1:], counts01/sum(counts01), label=\"Estimation with 10 bins\")\nplt.plot(bin_edges02[1:], counts02/sum(counts02), label=\"Estimation with 50 bins\")\nplt.plot(bin_edges03[1:], counts03/sum(counts03), label=\"Estimation with 100 bins\")\nplt.legend()\nplt.grid()\nplt.xlabel(\"Normalised ECG Value\")\nplt.ylabel(\"Estimated PDF Value\")\n\n\n\n\n\n0.09001020772910533\n\n\n\n\n\n\n0.02551116143316462\n\n\n\n\n\n\n\n\n\nhttps://pablocaicedor.github.io/"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\nData  AcquisitionSignal  conditioningFeature  ExtractionHypothesis  Testing\n\nData acquisition is to capture the signal and encode in a form suitable for computer processing.\nSignal conditioning is to remove noise and artifacts from the signal.\nFeature extraction is to extract relevant information from the signal.\nHypothesis testing is to test the hypothesis based on the extracted features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal condtioning",
    "text": "Signal condtioning\n\n\n\n\n\n\n\nBase Information\n\n\n\nA 12-lead electrocardiogram for arrhythmia study - Article\nA 12-lead electrocardiogram for arrhythmia study - Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning\n\ndata  = sio.loadmat(path_ecg+\"/JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\nprint(data.keys())\n\ndict_keys(['val'])\n\nprint(type(data['val']))\n\n&lt;class 'numpy.ndarray'&gt;\n\nprint(data['val'].shape)\n\n(12, 5000)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning\n\n\n\n\nhttps://pablocaicedor.github.io/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "",
    "text": "Profesor Asociado en la Universidad Escuela Colombiana de Ingenieria, Analista de Datos con un sólido trasfondo como Ingeniero en Electrónica y Telecomunicaciones y Doctor en Ciencias de la Electrónica. Cuento con 20 años de experiencia en Educación Universitaria y una destacada participación en proyectos de investigación en el campo de la Ciencia de los Datos aplicada a las organizaciones, el aprendizaje y la ciencia. Mi enfoque se centra en utilizar mis habilidades técnicas y experiencia para analizar grandes conjuntos de datos y extraer conocimientos valiosos que impulsen la toma de decisiones informadas."
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2016",
    "text": "2016\n- P. E. Caicedo-Rodríguez, Rengifo-Rodas, Carlos Felipe, y Rodríguez-Cheu, Luis Eduardo, «Contributions of electronic sciences to the problem of falls of old age population», 2016, doi: 10.17488/RMIB.37.3.6."
  },
  {
    "objectID": "about.html#section-1",
    "href": "about.html#section-1",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2017",
    "text": "2017\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, y L. E. Rodríguez-Cheu, «A human gait temporal parameters calculation algorithm», en VII Latin American Congress on Biomedical Engineering CLAIB 2016, Bucaramanga, Santander, Colombia, October 26th -28th, 2016, vol. 60, I. Torres, J. Bustamante, y D. A. Sierra, Eds., en IFMBE Proceedings, vol. 60. , Singapore: Springer Singapore, 2017, pp. 285-288. doi: 10.1007/978-981-10-4086-3_72."
  },
  {
    "objectID": "about.html#section-2",
    "href": "about.html#section-2",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2018",
    "text": "2018\n-  S. P. Castillo-Landínez y P. E. Caicedo-Rodríguez, «EL BLOG COMO HERRAMIENTA DE ENSEÑANZA EN LOS CURSOS DE INVESTIGACIÓN», presentado en Encuentro Internacional de Educación en Ingeniería ACOFI, Cartagena, Colombia, 2018."
  },
  {
    "objectID": "about.html#section-3",
    "href": "about.html#section-3",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2019",
    "text": "2019\n- N. Valencia-Jimenez et al., «A Comparative Study of Markerless Systems Based on Color-Depth Cameras, Polymer Optical Fiber Curvature Sensors, and Inertial Measurement Units: Towards Increasing the Accuracy in Joint Angle Estimation», Electronics, vol. 8, n.º 2, p. 173, feb. 2019, doi: 10.3390/electronics8020173.\n- S. P. Castillo-Landinez, P. E. Caicedo-Rodríguez, y D. F. Sánchez-Gómez, «Diseño e implementación de un software para la trazabilidad del proceso de beneficio del café», CTA, vol. 20, n.º 3, sep. 2019, doi: 10.21930/rcta.vol20_num3_art:1588.\n- P. E. Caicedo-Rodriguez, C. F. Rengifo-Rodas, L. E. Rodríguez-Cheu, y W. A. Sierra-Arevalo, «Gait Phase Detection for Lower Limb Prosthetic Devices», en Wearable Robotics: Challenges and Trends, vol. 22, M. C. Carrozza, S. Micera, y J. L. Pons, Eds., en Biosystems & Biorobotics, vol. 22. , Cham: Springer International Publishing, 2019, pp. 201-205. doi: 10.1007/978-3-030-01887-0_39.\n- S. P. Castillo-Landínez y P. E. Caicedo-Rodríguez, «ANÁLISIS DE SENTIMIENTOS, UNA HERRAMIENTA PARA VALORAR LA ACTITUD DEL ESTUDIANTE FRENTE A UN CURSO», presentado en Encuentro internacional de educación en ingeniería, Cartagena, Colombia, 2019.\nP. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, y L. E. Rodriguez-Cheu, «LA VELOCIDAD DE MARCHA COMO FACTOR DISCRIMINATORIO DEL RIESGO DE CAÍDA EN ADULTOS MAYORES», presentado en Encuentro internacional de educación en ingeniería, Cartagena, Colombia, 2019. doi: 10.26507/ponencia.282."
  },
  {
    "objectID": "about.html#section-4",
    "href": "about.html#section-4",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2020",
    "text": "2020\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. Gómez-Guevara, «Dataset for gait analysis and assessment of fall risk for older adults», Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. Gómez-Guevara, «Dataset for gait analysis and assessment of fall risk for older adults», Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- Y. H. Bolaños-Muñoz, C. F. Rengifo-Rodas, P. E. Caicedo-Rodríguez, L. E. Rodriguez-Cheu, y W. A. Sierra-Arevalo, «Electronic system for step width estimation using programmable system-on-chip technology and time of flight cameras», HardwareX, vol. 8, p. e00126, oct. 2020, doi: 10.1016/j.ohx.2020.e00126.\n- S. P. Castillo Landínez, P. E. Caicedo Rodríguez, y S. A. Muñoz De La Rosa, «LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA CUARENTENA A TRAVÉS DEL ANÁLISIS DE SENTIMIENTOS. UN CASO DE ESTUDIO EN LA UNIAUTÓNOMA DEL CAUCA», en Encuentro Internacional de Educación en Ingeniería ACOFI 2020, Asociacion Colombiana de Facultades de Ingeniería - ACOFI, ago. 2020, pp. 1-8. doi: 10.26507/ponencia.820.\n- J. P. Henao-Pereira, A. E. Tovar-Leon, S. P. Castillo-Landínez, y P. E. Caicedo-Rodríguez, «Los accidentes de tránsito desde la perspectiva de la minería de datos. Una revisión de la literatura», Aibi revista investig. adm. ing., pp. 133-141, ago. 2020, doi: 10.15649/2346030X.743."
  },
  {
    "objectID": "about.html#section-5",
    "href": "about.html#section-5",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2021",
    "text": "2021\n- P. E. Caicedo-Rodríguez, Incidencia de los sistemas electrónicos de medición de variables biomecánicas en la concordancia intra e inter evaluador del examen POMA de función motora, Primera. Popayán, Colombia: Sello Editorial Uniautónoma del Cauca, 2021.\n- S. Castillo Landínez, P. E. Caicedo Rodríguez, S. A. Muñoz De La Rosa, y J. P. Sandoval Paz, «LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA PANDEMIA, UN AÑO DESPUÉS», en Encuentro Internacional de Educación en Ingeniería ACOFI 2021, Asociacion Colombiana de Facultades de Ingeniería - ACOFI, sep. 2021, pp. 1-9. doi: 10.26507/ponencia.2005.\n- L. S. Vargas-Valencia et al., «Sleeve for Knee Angle Monitoring: An IMU-POF Sensor Fusion System», IEEE J. Biomed. Health Inform., vol. 25, n.º 2, pp. 465-474, feb. 2021, doi: 10.1109/JBHI.2020.2988360.\n- C. R. Malaver-Flor y M. Y. Astorquiza-Velasco, «Técnicas de Procesamiento Para Variables Posturales Enfocadas en Detección Temprana Del Microtraumatismo Tisular de un Ciclista», PROSPECTIVA, vol. 19, n.º 2, 2021."
  },
  {
    "objectID": "about.html#section-6",
    "href": "about.html#section-6",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2022",
    "text": "2022\n- S. Castillo Landínez, P. E. Caicedo Rodríguez, y J. A. Mosquera Bolaños, «Los adolescentes y el uso de las redes sociales. Un análisis desde la óptica de la ciencia de datos y el procesamiento de lenguaje natural», presentado en Nuevas realidades para la educación en ingeniería: currículo, tecnología, medio ambiente y desarrollo, sep. 2022, pp. 1-8. doi: 10.26507/paper.2693.\n- V. Cerón Monje, C. E. Zúñiga Muñoz, S. P. Castillo Landínez, y P. E. Caicedo Rodríguez, «Análisis de sentimientos aplicado a la evaluación docente de la Corporación Universitaria Autónoma del Cauca», presentado en Nuevas realidades para la educación en ingeniería: currículo, tecnología, medio ambiente y desarrollo, sep. 2022, pp. 1-10. doi: 10.26507/paper.2308."
  },
  {
    "objectID": "about.html#section-7",
    "href": "about.html#section-7",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2023",
    "text": "2023\n- J. M. Cabrera Ángel, P. E. Caicedo-Rodríguez, y S. Castillo-Landínez, «Así nos vemos», Uniautonoma del Cauca, Popayán, 2023.\n- S. Castillo Landínez y P. E. Caicedo Rodríguez, «¡¡¡Ahora sí tocó poner atención porque hay que evaluar!!!», presentado en Ingeniería para transformar territorios, sep. 2023, pp. 1-10. doi: 10.26507/paper.2941."
  },
  {
    "objectID": "about.html#section-8",
    "href": "about.html#section-8",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2024",
    "text": "2024"
  },
  {
    "objectID": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent."
  },
  {
    "objectID": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach\n\ndef f_hat(x):\n    return 4*(x**3) - 8*x\n\ndef shift(xs, n):\n    if n &gt;= 0:\n        return np.concatenate((np.full(n, xs[0]), xs[:-n]))\n    else:\n        return np.concatenate((xs[-n:], np.full(-n, xs[-1])))\n\ndef f_hat_num(x,t):\n    delta = shift(t, -1) - t\n    salida = (shift(x, -1) - x) / np.mean(delta[:-1])\n    return np.concatenate((salida[:-1], [salida[-2]]))\n\n\ntemp = np.array([0,1,2,3,4,5,6])\nnp.concatenate([temp, [temp[-1]]])\n\narray([0, 1, 2, 3, 4, 5, 6, 6])\n\n\n\nplt.plot(t, f_hat(t))\nplt.plot(t, f_hat_num(f(t), t))"
  },
  {
    "objectID": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach\n\nimport sympy as sp\n\n# Define the variable and the expression\nx1 = sp.symbols(\"x1\")\nexpr = x1**4 - 4 * x1**2 + 4\n\nresult = sp.integrate(expr, (x1, -10, 10)).evalf()\n\n# Print the LaTeX representation\nprint(sp.latex(expr))\nprint(result)\n\nx_{1}^{4} - 4 x_{1}^{2} + 4\n37413.3333333333\n\n\n\n# Define the limits of integration\na = -10\nb = 10\n\n# Define the number of subintervals\nn = 100\n\n# Calculate the width of each subinterval\nh = (b - a) / n\n\n# Initialize the sum\nsum = 0.5 * (f(a) + f(b))\n\n# Apply the Trapezoid Rule\nfor i in range(1, n):\n    sum += f(a + i * h)\n\n# Calculate the integral\nintegral = h * sum\n\nprint(\"Approximate integral:\", integral)\n\nApproximate integral: 37439.465599999996"
  },
  {
    "objectID": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)\n\n# Define the derivative function\ndef f1(x, y):\n    return 2 * x - 3 * y\n\n\n# Initial condition\nx0 = 0\ny0 = 1\n\n# Step size\nh = 0.1\n\n# Total steps\nn = int(10 / h)\n\n# Create arrays to store x and y values\nx = [0] * (n + 1)\ny = [0] * (n + 1)\n\n# Initialize x and y arrays\nx[0] = x0\ny[0] = y0\n\n# Euler's Method\nfor i in range(n):\n    x[i + 1] = x[i] + h\n    y[i + 1] = y[i] + h * f1(x[i], y[i])"
  },
  {
    "objectID": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent.\n\nt1= np.linspace(-2,2,1000)\nplt.plot(t1, f(t1))\n\n\n\n\n\n\n\n\n\n# Initial guess\nx0 = 10 * (np.random.rand() - 0.5)\n\n# Learning rate\nalpha = 0.01\n\n# Number of iterations\nn_iter = 1000\n\n# Gradient Descent\nxg = x0\nfor i in range(n_iter):\n    xg = xg - alpha * f_hat(xg)\n\n# Print the minimum\nprint(\"Time of the minimum:\", xg)\nprint(\"Function value at minimum:\", f(xg))\n\nTime of the minimum: -1.4142135623730956\nFunction value at minimum: 8.881784197001252e-16"
  },
  {
    "objectID": "clases/Class_ML.html",
    "href": "clases/Class_ML.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Que es ?\nEl aprendizaje automático (machine learning) es una rama de la inteligencia artificial que permite a los sistemas aprender y mejorar de la experiencia sin ser explícitamente programados. Esto significa que los sistemas de aprendizaje automático pueden identificar patrones en los datos y usar esos patrones para hacer predicciones o tomar decisiones.\nHay muchos tipos diferentes de algoritmos de aprendizaje automático, pero todos ellos funcionan de manera similar. Primero, el algoritmo se “entrena” con un conjunto de datos. Este conjunto de datos contiene ejemplos de los tipos de problemas que el algoritmo debe resolver. Por ejemplo, si el algoritmo está diseñado para clasificar imágenes, el conjunto de datos podría contener imágenes de gatos y perros.\nUna vez que el algoritmo está entrenado, puede usar los patrones que ha aprendido para hacer predicciones sobre nuevos datos. Por ejemplo, si se le muestra una nueva imagen de un animal, el algoritmo podría predecir si es un gato o un perro.\nEl aprendizaje automático es una tecnología muy poderosa que se puede aplicar a una amplia gama de problemas. Algunos ejemplos de aplicaciones de aprendizaje automático incluyen:\n\nClasificación de imágenes\nReconocimiento de voz\nDetección de fraudes\nRecomendación de productos\nOptimización de rutas\n\nEl aprendizaje automático es una tecnología en constante evolución, y se espera que se use cada vez más en los próximos años.\n\n\nMaterial del curso\nPresentación\n\n\nReferencias\n\nB. Boehmke y B. M. Greenwell, Hands-on machine learning with R. Boca Raton: CRC Press, 2019.\nG. Bonaccorso, Mastering machine learning algorithms: expert techniques to implement popular machine learning algorithms and fine-tune your models. 2018.\nM. Fenner, Machine learning in python for everyone. Boston, MA: Addison-Wesley, 2019.\nK. Kolodiazhnyi, Hands-On Machine Learning with C++ Build, Train, and Deploy End-To-end Machine Learning and Deep Learning Pipelines. Birmingham: Packt Publishing, Limited, 2020. Accedido: 28 de septiembre de 2021.\nM. Kubat, An Introduction to Machine Learning. Cham: Springer International Publishing, 2017. doi: 10.1007/978-3-319-63913-0.\nS. Raschka y V. Mirjalili, Python machine learning: machine learning and deep learning with Python, scikit-learn, and TensorFlow, Second edition, Fourth release,[fully revised and Updated]. Birmingham Mumbai: Packt Publishing, 04.\nS. Skansi, Introduction to Deep Learning: From Logical Calculus to Artificial Intelligence. Cham: Springer International Publishing, 2018. doi: 10.1007/978-3-319-73004-2."
  },
  {
    "objectID": "clases/Class_PSIM.html",
    "href": "clases/Class_PSIM.html",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "“Un área de rápido crecimiento y variedad de aplicaciones en la ingeniería biomédica a nivel nacional y global es el procesamiento digital de señales e imágenes médicas. Es por eso, que a través de este curso se desea dar las herramientas necesarias para los graduados del programa puedan tener competencias básicas en las técnicas clásicas y algunas técnicas modernas de procesamiento de señales e imágenes. La primera parte del curso se encuentra enfocada al desarrollo de técnicas de procesamiento para señales biomédicas unidimensionales, exponiendo primero su origen fisiológico y siguiendo con la presentación de las principales técnicas para su análisis y procesamiento. La segunda parte del curso hace énfasis en el estudio de imágenes médicas, partiendo de una explicación de los principales métodos computacionales utilizados para procesamiento digital de imágenes y luego exponiendo brevemente el proceso de su formación. A través de prácticas de laboratorio con señales e imágenes médicas (reales o simuladas), el estudiante podrá aplicar y reforzar los conocimientos aprendidos en el curso” fragmento tomado del microcurriculo de la asignatura.\nEl curso está dividido en 43 partes:\n1. Introducción al procesado de señales e imágenes biomédicas.\n2. Fundamentos procesado de señales e imágenes biomédicas\n3. Extracción de características de señales biomédicas.\n4. Extracción de características de imágenes biomédicas."
  },
  {
    "objectID": "clases/Class_PSIM.html#presentaciones",
    "href": "clases/Class_PSIM.html#presentaciones",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción\nAcondicionamiento de señal\nProcesamiento de imágenes (1/2)\nProcesamiento de imágenes (2/2)"
  },
  {
    "objectID": "clases/Class_PSIM.html#datos",
    "href": "clases/Class_PSIM.html#datos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Datos",
    "text": "Datos\n\nECG Heartbeat Categorization Dataset Example\nData Sources"
  },
  {
    "objectID": "clases/Class_PSIM.html#códigos",
    "href": "clases/Class_PSIM.html#códigos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Códigos",
    "text": "Códigos\n\nCódigo 01: Acondicionamiento de señal\nCódigo 02: Transformada de Fourier"
  },
  {
    "objectID": "clases/Class_PSIM.html#laboratorios",
    "href": "clases/Class_PSIM.html#laboratorios",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio 001. Revision conceptos. Sin calificación. Evaluación 19 de agosto de 2024.\nSol laboratorio 001. Revision conceptos. Sin calificación. Evaluación 19 de agosto de 2024.\nLaboratorio 002. Generación de productos de procesamiento de señales (1D). Evaluación 16 de septiembre de 2024."
  },
  {
    "objectID": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "href": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nPrimer Parcial 2024-I"
  },
  {
    "objectID": "clases/Class_PSIM.html#clases",
    "href": "clases/Class_PSIM.html#clases",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Clases",
    "text": "Clases\nGrupo 80: Martes 7:00am-8:30am F-210. Jueves 7:00am-8:30am C6-202.\nGrupo 81: Martes 11:30am-1:30pm D-302. Jueves 11:30am-1:30pm D-302."
  },
  {
    "objectID": "clases/Class_PSIM.html#laboratorio",
    "href": "clases/Class_PSIM.html#laboratorio",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Laboratorio",
    "text": "Laboratorio\nGrupo 8001: Lunes 8:30am - 10:00am. I1-304\nGrupo 8101: Lunes 1:00pm - 2:30pm. I1-304\nGrupo 8102: Lunes 11:30am - 1:00pm. I1-308"
  },
  {
    "objectID": "clases/Class_PSIM.html#atención-a-estudiantes",
    "href": "clases/Class_PSIM.html#atención-a-estudiantes",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes\nGrupo 80:\nGrupo 81:"
  },
  {
    "objectID": "tutoriales/ExpansionTaylor.html",
    "href": "tutoriales/ExpansionTaylor.html",
    "title": "Computación de seno y coseno usando expansión de Taylor",
    "section": "",
    "text": "Las ecuaciones de las expansiones de Taylor (centradas en cero) fueron extraídas de la recopilación que hizo Wikipedia\n\\[cos\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{x^{2n}}{2n!}\\left(-1\\right)^{n}}\\]\n\\[sin\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{\\left(-1\\right)^{n}}{\\left(2n+1\\right)!}x^{2n+1}}\\]\n\ndef factorial(x):\n    output = 1\n    for k in range(1,x+1):\n        output = output*k\n    return output\n\n\ndef sin_taylor_expansion(x,n):\n    pi = 3.141592653589793238462643383279502884197169399375105820974944\n    x = pi*x/180\n    output = 0\n    for k in range(0, n):\n        term = (((-1)**k)/factorial(2*k + 1))*(x**(2*k+1))\n        output = output+term\n    return output\n\n\nv_est = sin_taylor_expansion(30,5)\n\nprint(v_est)\n\nprint(\"Error Relativo:\", abs(0.5-v_est)/0.5)\n\n0.5000000000202799\nError Relativo: 4.0559777758630844e-11"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#componentes",
    "href": "tutoriales/tut001_microbit.html#componentes",
    "title": "Microbit – El minicomputador",
    "section": "Componentes",
    "text": "Componentes"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "href": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "title": "Microbit – El minicomputador",
    "section": "Como la puedo programar?",
    "text": "Como la puedo programar?"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "href": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "title": "Microbit – El minicomputador",
    "section": "Distribución e impacto",
    "text": "Distribución e impacto\n\nDistribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#problema",
    "href": "tutoriales/tut001_microbit.html#problema",
    "title": "Microbit – El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable en 0.\nMostrar el número en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "href": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "title": "Microbit – El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#lets-code",
    "href": "tutoriales/tut001_microbit.html#lets-code",
    "title": "Microbit – El minicomputador",
    "section": "Let’s Code",
    "text": "Let’s Code\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#editor",
    "href": "tutoriales/tut001_microbit.html#editor",
    "title": "Microbit – El minicomputador",
    "section": "Editor",
    "text": "Editor\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "href": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "title": "Microbit – El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable con el número a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10.\n\n\n\n\n\n\n\n\n\nhttps://pablocaicedor.github.io/"
  }
]