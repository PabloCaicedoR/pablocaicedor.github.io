[
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#introducción",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#introducción",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Introducción",
    "text": "Introducción"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Adquisición de datos",
    "text": "Adquisición de datos\n\n\n\nSe utilizó el sensor XSens MTw Awinda [1].\nSe adquirieron datos de aceleración, giroscopio y magnetómetro.\nSe uso \\(F_s = 100Hz\\).\nLos sensores capturan señales que representan el movimiento en su propio sistema de coordenadas [2]."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos-1",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Adquisición de datos",
    "text": "Adquisición de datos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatos adquiridos…\n\n\n\nProtocolo de adquisición modificado [3]\nActividad con ojos abiertos (eye open), ojos cerrados (eye close) y tarea dual (dual task)"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\n\n\n\n\n\n\n\nPrimer paso\n\n\n\nEliminación de datos no útiles.\nDatos eliminados: datos na, columnas PacketCounter y SampleTimeFine\nCreación de una columna Time en segundos."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento-1",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\n\n\n\n\n\n\n\nSegundo paso\n\n\n\nConvertir ejes locales a globales. Utilizando el cuaternio generado por el XSens.\nCalcular la magnitud del vector de aceleración global y la agregar al DataFrame.\nCalcular la magnitud del vector de velocidad angular global y la agregar al DataFrame.\nSeleccionar 20 segundos de información (eliminar información inicial y final)"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#fusión-sensorial",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#fusión-sensorial",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Fusión sensorial",
    "text": "Fusión sensorial\n\n\n\n\n\n\n\nAlgoritmo de Fusión\n\n\n\nSe utiliza el algoritmo de la fusión de los datos de aceleración y giroscopio por defecto de XSens.\nSe utiliza el algoritmo de eliminación de distorsión magnética desarrollado por XSens"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extracción de características",
    "text": "Extracción de características\n\n\n\n\n\n\n\nMétricas\n\n\n\nRaíz cuadrática media (RMS) de la magnitud de la aceleración o de la velocidad angular [4].\nAdaptación de la longitud de la trayectoria [3].\nArea de de la elipse de oscilación (ellipse sway area), típicamente cubriendo el 95% de los datos presentados."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extraccio-de-características",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extraccio-de-características",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extraccio de características",
    "text": "Extraccio de características"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-1",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extracción de características",
    "text": "Extracción de características\n\n\n\n\n\n\n\nRomberg Ratio\n\n\n\nEl test de Romberg es una prueba que se usa frecuentemente en la posturografía.\nSe basa en la evaluación del control postural bajo dos condiciones distintas: con visión (ojos abiertos) y sin visión (ojos cerrados).\nEl índice o ratio de Romberg se calcula dividiendo el balanceo postural (postural sway) en la condición de ojos cerrados entre el balanceo postural en la condición de ojos abiertos.\nTambién se puede calcular dividiendo el balanceo postural (postural sway) en la condición de doble tarea entre el balanceo postural en la condición de ojos abiertos"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-2",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-2",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extracción de características",
    "text": "Extracción de características\n\n\n\n\n\n\n\n\n\n\n\n\nEyes Open\nEyes Close\nDual Task\nRatio Romberg 1\nRatio Romberg 2\n\n\n\n\nRMS ACC X\n2,83E-03\n2,91E-03\n2,89E-03\n1,03\n1,02\n\n\nRMS ACC Y\n6,82E-04\n6,80E-03\n6,79E-03\n9,98\n9,96\n\n\nRMS ACC Z\n5,74E-04\n5,08E-04\n4,98E-04\n0,89\n0,87\n\n\nRMS GYR X\n4,24E-07\n3,52E-06\n4,24E-07\n8,29\n1,00\n\n\nRMS GYR Y\n1,02E-05\n8,27E-06\n1,16E-05\n0,81\n1,14\n\n\nRMS GYR Z\n8,68E-08\n6,18E-07\n8,52E-07\n7,12\n9,82\n\n\nPATH TRAJ\n0,0025\n0,0025\n0,0031\n1,00\n1,24\n\n\nAREA_ELIPSE_95%\n5,61E-11\n8,30E-11\n6,55E-12\n1,48\n0,12"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-propuesta",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-propuesta",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Extracción de características (propuesta)",
    "text": "Extracción de características (propuesta)\n\n\n(np.float64(2.7508740895910972), np.float64(3.6048069186140856), np.float64(1.434932874624913), np.float64(2.0295845733092643))"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#referencias",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#referencias",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "Referencias",
    "text": "Referencias\n\n\n[1] M. Paulich, M. Schepers, N. Rudigkeit, y G. Bellusci, «Xsens MTw Awinda: Miniature Wireless Inertial-Magnetic Motion Tracker for Highly Accurate 3D Kinematic Applications».\n\n\n[2] D. H. Yoon, J.-H. Kim, K. Lee, J.-S. Cho, S.-H. Jang, y S.-U. Lee, «Inertial measurement unit sensor-based gait analysis in adults and older adults: A cross-sectional study», Gait & Posture, vol. 107, pp. 212-217, ene. 2024, doi: 10.1016/j.gaitpost.2023.10.006.\n\n\n[3] J. Zhou et al., «A novel smartphone App-based assessment of standing postural control: Demonstration of reliability and sensitivity to aging and task constraints», en 2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM), Shenzhen, China: IEEE, mar. 2021, pp. 1-6. doi: 10.1109/HEALTHCOM49281.2021.9398972.\n\n\n[4] M. Calcagni, P. Kosa, y B. Bielekova, «Smartphone postural sway and pronator drift tests as measures of neurological disability», BMC Neurol, vol. 25, n.º 1, p. 50, feb. 2025, doi: 10.1186/s12883-025-04038-2."
  },
  {
    "objectID": "proyectos/ComparisonML.html",
    "href": "proyectos/ComparisonML.html",
    "title": "Comparing different Machine Learning architectures for classifying medical terms in Colombian sign language",
    "section": "",
    "text": "Presentación STSIVA2025"
  },
  {
    "objectID": "tutoriales/EvaluacionEducativa.html#introducción",
    "href": "tutoriales/EvaluacionEducativa.html#introducción",
    "title": "Evaluación del aprendizaje",
    "section": "Introducción",
    "text": "Introducción\n\nObjetivo: fijar una definición operacional y el marco de referencia que justifica su valor.\n\n\n\n\n\n\n\n\nDefinición\n\n\nUn aprendizaje que perdura es un proceso activo, profundamente conectado y estratégicamente practicado que produce cambio conceptual estable, dominio de habilidades y transferencia a contextos nuevos.\n\n\n\n\n\nGenerada mediante CHATGPT"
  },
  {
    "objectID": "tutoriales/EvaluacionEducativa.html#introducción-1",
    "href": "tutoriales/EvaluacionEducativa.html#introducción-1",
    "title": "Evaluación del aprendizaje",
    "section": "Introducción",
    "text": "Introducción\n\n\n\n\n\n\n\nTres pilares\n\n\n\nComprensión profunda y organización significativa del conocimiento: integración con conocimientos previos y estructuras ricas (no listas de hechos aislados).\nPrácticas con “dificultades deseables”: especialmente recuperación, espaciado e entrelazado.\nEvaluación formativa y retroalimentación orientadora: ciclos breves y frecuentes que guían el ajuste de estrategias."
  },
  {
    "objectID": "tutoriales/EvaluacionEducativa.html#introducción-2",
    "href": "tutoriales/EvaluacionEducativa.html#introducción-2",
    "title": "Evaluación del aprendizaje",
    "section": "Introducción",
    "text": "Introducción\n\nComprensión profunda y organización significativa del conocimiento es la capacidad del estudiante para construir, relacionar y usar ideas de forma coherente y transferible, anclándolas en su conocimiento previo y estructurándolas en redes conceptuales ricas (no como listas de datos aislados\n\n\n\n\n\n\n\n\n\n\nTres pilares\n\n\n\nComprensión profunda y organización significativa del conocimiento.\nPrácticas con “dificultades deseables”.\nEvaluación formativa y retroalimentación orientadora.\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplicaciones\n\n\n\nEstructura: conceptos, principios y procedimientos interconectados (mapas mentales densos, no “ítems sueltos”).\nSentido: las nuevas ideas se integran con experiencias y saberes previos mediante analogías, contraejemplos, límites de validez.\nUso: el alumno explica, predice y resuelve en contextos nuevos, justificando por qué un método aplica y otro no."
  },
  {
    "objectID": "tutoriales/EvaluacionEducativa.html#una-rúbrica-muy-básica",
    "href": "tutoriales/EvaluacionEducativa.html#una-rúbrica-muy-básica",
    "title": "Evaluación del aprendizaje",
    "section": "Una rúbrica muy básica",
    "text": "Una rúbrica muy básica\n\n\n\n\n\n\n\n\n\n\nCriterio\n4 Excelente\n3 Adecuado\n2 Básico\n1 Insuficiente\n\n\n\n\nEstructura conceptual\nRed de conceptos y relaciones correctas y no triviales; incluye condiciones y límites\nMapa correcto con algunas relaciones clave\nLista de conceptos con pocas conexiones\nDatos sueltos, conexiones erróneas\n\n\nJustificación\nSelecciona y defiende el método por principio\nSelecciona y justifica parcialmente\nSelecciona por “receta”\nSelección arbitraria\n\n\nTransferencia\nResuelve nuevos contextos y explica analogías/diferencias\nResuelve variaciones cercanas\nSolo contextos vistos\nNo transfiere\n\n\nRevisión de ideas\nIdentifica y repara concepciones previas\nReconoce algunas inconsistencias\nMinimiza o ignora conflictos\nMantiene ideas erróneas"
  },
  {
    "objectID": "tutoriales/EvaluacionEducativa.html#introducción-3",
    "href": "tutoriales/EvaluacionEducativa.html#introducción-3",
    "title": "Evaluación del aprendizaje",
    "section": "Introducción",
    "text": "Introducción\n\n\n\n\n\n\n\n\n\nTres pilares\n\n\n\nComprensión profunda y organización significativa del conocimiento.\nPrácticas con “dificultades deseables”.\nEvaluación formativa y retroalimentación orientadora.\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplicaciones\n\n\nLas prácticas con “dificultades deseables” son retos cognitivos intencionalmente introducidos en la práctica que aumentan el esfuerzo de procesamiento y recuperación sin impedir el progreso. Ese esfuerzo óptimo provoca mejor retención, transferencia y discriminación que las prácticas fáciles (p. ej., relectura pasiva).\nEn términos instructivos: diseñar actividades que obliguen a reconstruir, recuperar, variar y decidir, en lugar de reconocer o repetir."
  },
  {
    "objectID": "tutoriales/EvaluacionEducativa.html#introducción-4",
    "href": "tutoriales/EvaluacionEducativa.html#introducción-4",
    "title": "Evaluación del aprendizaje",
    "section": "Introducción",
    "text": "Introducción\n\n\n\n\n\n\n\n\n\nTres pilares\n\n\n\nComprensión profunda y organización significativa del conocimiento.\nPrácticas con “dificultades deseables”.\nEvaluación formativa y retroalimentación orientadora.\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplicaciones\n\n\nEvaluación formativa es el proceso continuo y planificado de recoger evidencias del aprendizaje durante la enseñanza para tomar decisiones inmediatas (docente y estudiantes) que mejoren el rendimiento y la comprensión.\nLa retroalimentación orientadora es la información que, a partir de esas evidencias, ubica al estudiante frente a criterios explícitos (dónde está), explica la brecha (qué falta) y señala próximos pasos concretos (cómo mejorar), en el momento oportuno para que pueda actuar.\n\n\n\n\n\n\n\n\n\n\n\n\nRegla de oro\n\n\nSi la “evaluación” no cambia decisiones inmediatas de enseñanza-aprendizaje, no es formativa."
  },
  {
    "objectID": "tutoriales/EvaluacionEducativa.html#ciclo-operativo-docente-y-estudiante",
    "href": "tutoriales/EvaluacionEducativa.html#ciclo-operativo-docente-y-estudiante",
    "title": "Evaluación del aprendizaje",
    "section": "Ciclo operativo (docente y estudiante)",
    "text": "Ciclo operativo (docente y estudiante)\n\nClarificar metas/criterios (ejemplos, rubricas).\nElicitar evidencia breve (actividad/quiz/producción).\nAnalizar rápidamente contra criterios (errores típicos, patrones).\nRetroalimentar (específica, oportuna, accionable).\nCerrar el ciclo: reintentos, revisión, práctica adicional (espaciada/entrelazada)."
  },
  {
    "objectID": "tutoriales/EvaluacionEducativa.html#marco-de-diseño",
    "href": "tutoriales/EvaluacionEducativa.html#marco-de-diseño",
    "title": "Evaluación del aprendizaje",
    "section": "Marco de diseño",
    "text": "Marco de diseño\n\n\n\n\n\n\n\nAlineacion\n\n\ncluster_core\n\n \n\n\n\nEP\n\nEnfoques profundos\nde aprendizaje\n\n\n\nR\n\nResultados de aprendizaje\n(Qué se espera que el estudiante haga)\n\n\n\nR-&gt;EP\n\n\ndefinen\ncriterios\n\n\n\nA\n\nActividades\n(Cómo lo van a aprender)\n\n\n\nR-&gt;A\n\n\noperacionalizan\nlos ILOs\n\n\n\nR-&gt;A\n\n\n\n\n\nA-&gt;EP\n\n\ninducen\nprocesamiento\n\n\n\nE\n\nEvaluaciones\n(Cómo evidenciamos el logro)\n\n\n\nA-&gt;E\n\n\ngeneran evidencia\nválida\n\n\n\nA-&gt;E\n\n\n\n\n\nE-&gt;EP\n\n\nretroalimentan\nmejora\n\n\n\nE-&gt;R\n\n\ninforman y afinan\ncriterios\n\n\n\nE-&gt;R"
  },
  {
    "objectID": "tutoriales/EvaluacionEducativa.html#referencias",
    "href": "tutoriales/EvaluacionEducativa.html#referencias",
    "title": "Evaluación del aprendizaje",
    "section": "Referencias",
    "text": "Referencias\n\nAngelo, T. A., & Cross, K. P. (1993). Classroom assessment techniques: A handbook for college teachers (2. ed). Jossey-Bass.\nBiggs, J. B., & Tang, C. S. (with Society for Research into Higher Education). (2011). Teaching for quality learning at university: What the student does (4th edition). McGraw-Hill/Society for Research into Higher Education/Open University Press.\nBrookhart, S. M. (s. f.). How to Create and Use Rubrics for Formative Assessment and Grading.\nFelder, R. M., & Brent, R. (2016). Teaching and learning STEM: A practical guide (First edition). Jossey-Bass, A Wiley Brand.\nHughes, C. (2025). Changing Assessment: How to Design Curriculum for Human Flourishing. BRILL. https://doi.org/10.1163/9789004714205\nLang, J. M. (2021). Small teaching: Everyday lessons from the science of learning (Second edition). Jossey-Bass, a Wiley Brand.\nLovett, M. C. (with Bridges, M. W., DiPietro, M., Ambrose, S. A., & Norman, M. K.). (2023). How Learning Works: Eight Research-Based Principles for Smart Teaching (2nd ed). John Wiley & Sons, Incorporated.\nMcMillan, J. H. (2024). Classroom assessment: Principles and practice that enhance student learning and motivation (Eighth edition). Pearson Education, Inc."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#python",
    "href": "tutoriales/pythonprogrammin.html#python",
    "title": "Python programming",
    "section": "Python",
    "text": "Python\n\nPython is a high-level, interpreted, multi-paradigm, and general-purpose programming language.\nIts design philosophy emphasizes code readability.\nIt is one of the most popular programming languages in use today, and is used for a wide range of applications, including web development, data science, machine learning, and artificial intelligence."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advantages",
    "href": "tutoriales/pythonprogrammin.html#advantages",
    "title": "Python programming",
    "section": "Advantages",
    "text": "Advantages\n\nPython is a multi-paradigm programming language, meaning it can be used for different types of programming, such as object-oriented programming, imperative programming, and functional programming.\nPython is an interpreted programming language, meaning it does not need to be compiled before being executed. This makes Python very fast to develop and debug.\nPython is a highly portable programming language, meaning it can be run on different platforms, such as Windows, Mac OS X, and Linux. It can also be run in the cloud. Python has a large community of users and developers, meaning there are many resources available to learn and use Python."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#disadvantages",
    "href": "tutoriales/pythonprogrammin.html#disadvantages",
    "title": "Python programming",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nPython can be a bit slower than compiled languages, such as C or C++.\nPython has a slightly more complex syntax than some other programming languages, such as Java or JavaScript.\nPython may not be the best programming language for certain types of applications, such as game applications or high-performance applications."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#basic-syntax",
    "href": "tutoriales/pythonprogrammin.html#basic-syntax",
    "title": "Python programming",
    "section": "Basic Syntax",
    "text": "Basic Syntax\n\nIndentation is used to denote block-level structure\nVariables are assigned using the = operator\nPrint output using the print() function\nComments: # for single-line, ''' or \"\"\" for multi-line"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#data-types",
    "href": "tutoriales/pythonprogrammin.html#data-types",
    "title": "Python programming",
    "section": "Data Types",
    "text": "Data Types\n\nIntegers: int (e.g., 1, 2, 3)\nFloats: float (e.g., 3.14, -0.5)\nStrings: str (e.g., 'hello', \"hello\")\nBoolean: bool (e.g., True, False)\nList: list (e.g., [1, 2, 3], ['a', 'b', 'c'])\nDictionary: dict (e.g., {'name': 'John', 'age': 30})"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#control-structures",
    "href": "tutoriales/pythonprogrammin.html#control-structures",
    "title": "Python programming",
    "section": "Control Structures",
    "text": "Control Structures\n\nConditional statements:\n\nif statements: if condition : code\nelif statements: elif condition : code\nelse statements: else : code\n\nLoops:\n\nfor loops: for variable in iterable : code\nwhile loops: while condition : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#functions",
    "href": "tutoriales/pythonprogrammin.html#functions",
    "title": "Python programming",
    "section": "Functions",
    "text": "Functions\n\nReusable blocks of code\nTake arguments and return values\nCan be used to:\n\nOrganize code\nReduce repetition\nEncapsulate complex logic\n\nFunction definition: def function_name (arguments) : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#modules",
    "href": "tutoriales/pythonprogrammin.html#modules",
    "title": "Python programming",
    "section": "Modules",
    "text": "Modules\n\nPre-written code libraries\nImported using the import statement\nExamples:\n\nmath: mathematical functions (e.g., sin(), cos())\nrandom: random number generation (e.g., randint(), uniform())\ntime: time-related functions (e.g., time(), sleep())"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#exception-handling",
    "href": "tutoriales/pythonprogrammin.html#exception-handling",
    "title": "Python programming",
    "section": "Exception Handling",
    "text": "Exception Handling\n\nTry-except blocks:\n\ntry block: code that might raise an exception\nexcept block: code to handle the exception\n\nCatching specific exceptions:\n\nexcept ValueError : code\nexcept TypeError : code\n\nRaising exceptions:\n\nraise ValueError(message)"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "href": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "title": "Python programming",
    "section": "Object-Oriented Programming",
    "text": "Object-Oriented Programming\n\nClasses:\n\nDefine custom data types\nEncapsulate data and behavior\n\nObjects:\n\nInstances of classes\nHave attributes (data) and methods (behavior)\n\nInheritance:\n\nCreate new classes based on existing ones\nInherit attributes and methods"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advanced-topics",
    "href": "tutoriales/pythonprogrammin.html#advanced-topics",
    "title": "Python programming",
    "section": "Advanced Topics",
    "text": "Advanced Topics\n\nDecorators:\n\nModify function behavior\nUse @ symbol to apply\n\nGenerators:\n\nSpecial type of iterable\nUse yield statement to define\n\nLambda functions:\n\nSmall, anonymous functions\nUse lambda keyword to define"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#decorators",
    "href": "tutoriales/pythonprogrammin.html#decorators",
    "title": "Python programming",
    "section": "Decorators",
    "text": "Decorators\n\ndef my_decorator(func):\n    def wrapper():\n        print(\"Something is happening before the function is called.\")\n        func()\n        print(\"Something is happening after the function is called.\")\n\n    return wrapper\n\n\n@my_decorator\ndef say_hello():\n    print(\"Hello!\")\n\n\nsay_hello()\n\nSomething is happening before the function is called.\nHello!\nSomething is happening after the function is called."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#generators",
    "href": "tutoriales/pythonprogrammin.html#generators",
    "title": "Python programming",
    "section": "Generators",
    "text": "Generators\n\ndef infinite_sequence():\n    num = 0\n    while True:\n        yield num\n        num += 1\n\ngen = infinite_sequence()\nprint(next(gen))\n\n0\n\nprint(next(gen))\n\n1\n\nprint(next(gen))\n\n2"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#lambda-function",
    "href": "tutoriales/pythonprogrammin.html#lambda-function",
    "title": "Python programming",
    "section": "Lambda Function",
    "text": "Lambda Function\n\nrectangle_area_calculation = lambda base, height: base * height\nprint(rectangle_area_calculation(4, 6))  # Salida: 24\n\n24"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#conclusion",
    "href": "tutoriales/pythonprogrammin.html#conclusion",
    "title": "Python programming",
    "section": "Conclusion",
    "text": "Conclusion\n\nPython is a powerful and versatile language\nContinuously learning and practicing will help you master it\nExplore advanced topics and libraries to become proficient"
  },
  {
    "objectID": "tutoriales/TutorialEMG_DeepLearning.html",
    "href": "tutoriales/TutorialEMG_DeepLearning.html",
    "title": "Caso práctico: Análisis de señales EMG en rendimiento deportivo con ML/DL",
    "section": "",
    "text": "Selección y descarga del dataset\nPara este caso práctico se eligió un conjunto de datos público de electromiografía de superficie (EMG) enfocado en miembros inferiores durante actividades físicas, tomado del repositorio UCI Machine Learning. Este dataset contiene registros EMG de cuatro músculos de la pierna (cuádriceps e isquiotibiales) y mediciones de ángulo de rodilla, capturados mientras 22 sujetos masculinos (11 de ellos con alguna patología de rodilla) realizan tres tipos de ejercicio: estar sentado/de pie, mantenerse de pie y caminar. A continuación se resumen las características principales del dataset:\n\nSujetos: 22 (11 con lesión/alteración en rodilla)\nSeñales registradas: EMG superficial de 4 músculos (Rectus Femoris, Biceps Femoris, Vastus Medialis, Semitendinosus) + 1 canal de goniometría (ángulo de rodilla)\nActividades: 3 ejercicios (extensión de rodilla desde sentado, bipedestación estática, marcha) con ~5 repeticiones por ejercicio y sujeto\nFrecuencia de muestreo: 1000 Hz (resolución de 14 bits)\nFormato de datos: archivos por sujeto (formato texto) con 5 columnas (4 EMG + 1 ángulo), etiquetados por ejercicio realizado.\n\nLa base de datos se descargó del repositorio UCI en un archivo comprimido, que contiene los archivos de registro por sujeto. Esta fuente abierta facilita la reproducibilidad del experimento y provee datos reales de rendimiento deportivo (marcha y ejercicios de piernas) con señales EMG, la señal de interés en este caso práctico.\n\n\nPreprocesamiento y limpieza de datos\nAntes de aplicar algoritmos de machine learning, se llevó a cabo un riguroso preprocesamiento de las señales EMG para atenuar ruido y artefactos, y preparar los datos para el análisis:\n\nFiltrado digital: Se aplicó un filtro pasa-bandas Butterworth de 4º orden entre 20–450 Hz sobre cada canal EMG. Este rango estándar conserva la componente útil de la EMG (actividad muscular) a la vez que suprime el ruido de baja frecuencia (deriva de línea base, movimiento) y altas frecuencias indeseadas. Adicionalmente, se utilizó un filtro elimina-banda (notch) centrado en 50 Hz para remover interferencia de la red eléctrica, y un filtro pasa-altas (~15 Hz) para eliminar artefactos de movimiento y componentes DC residuales. Como resultado, las señales EMG filtradas presentan una línea base estable y menor contaminación por ruido ambiental y de electrodos.\nRectificación y suavizado: Tras el filtrado, las señales EMG se rectificaron (valor absoluto) para preparar el cálculo de envolventes. Seguidamente se obtuvo la envolvente lineal mediante un filtro pasa-bajas (ej. 10 Hz Butterworth) aplicado a la señal rectificada. La envolvente refleja la amplitud modulada de la activación muscular y facilita el cálculo de características de amplitud (p. ej., RMS) de forma más consistente.\nNormalización: Cada canal se centró en su media (es decir, se restó la media para eliminar offset DC) y se escaló a varianza unitaria (standardization) para uniformar las magnitudes. Esta estandarización por canal permite comparar señales entre sujetos y músculos, evitando sesgos debidos a distintas ganancias de electrodos. La literatura destaca que la normalización es un paso crucial al comparar activaciones musculares, especialmente entre diferentes sujetos o condiciones. En contextos clínicos suele usarse la normalización a una contracción voluntaria máxima (MVC), pero en este caso, al no disponerse de MVC, se optó por z-scores.\nSegmentación en ventanas: Dado que las señales son series de tiempo continuas por ejercicio y sujeto, se segmentaron en ventanas cortas de duración fija para su análisis. Se escogieron ventanas de 250 ms (250 muestras a 1000 Hz) con un solapamiento del 50%, buscando capturar patrones transitorios de activación muscular manteniendo suficiente resolución temporal. Estas ventanas conformarán las muestras de entrada al modelo de clasificación. El tamaño de ventana se basó en trabajos previos donde, por ejemplo, ventanas de ~100 ms a 250 ms han mostrado buen equilibrio entre resolución y contenido de información en EMG. No se hallaron valores faltantes en el dataset original (según documentación UCI), por lo que no fue necesario imputar o descartar datos; sin embargo, se implementaron controles para detectar y eliminar segmentos corruptos (ej. saturaciones o artefactos extremos) si aparecieran.\nTras estas etapas de preprocesamiento, las señales EMG quedaron listas para el análisis: filtradas en la banda relevante (20–450 Hz), libres de tendencias de línea base, normalizadas en escala y divididas en segmentos manejables. Esto reduce la variabilidad no relacionada al fenómeno muscular y mejora la calidad de los datos de entrada para los siguientes pasos de machine learning.\n\n\n\nAnálisis exploratorio de datos (EDA)\nAntes de entrenar modelos, se realizó un análisis exploratorio exhaustivo para comprender las características de las señales EMG y extraer información descriptiva: Figura 1: Ejemplo de señal EMG cruda registrada durante una contracción muscular. La traza exhibe la naturaleza ruidosa y aleatoria de la EMG, con oscilaciones de amplitud rápidas alrededor de una línea base (0 mV). Las activaciones musculares aparecen como “brotes” de mayor amplitud dentro del ruido, reflejando la suma de múltiples potenciales de acción de unidades motoras.\n\nVisualización de formas de onda: Se graficaron las señales EMG filtradas de cada músculo para inspeccionar patrones en el dominio temporal. La EMG típica luce similar a un ruido aleatorio de banda ancha, con amplitud modulada por la activación muscular. En los sujetos sanos se observaron activaciones claras durante los ejercicios (ej. ráfagas de alta amplitud al contraer cuádriceps al pasar de sentado a de pie), mientras que en sujetos con lesión algunas activaciones fueron de menor amplitud o más tardías. Se calcularon estadísticas básicas por canal y sujeto: media ~0 (tras centrar), desviación estándar representativa del nivel de actividad muscular, curtosis y skewness (oblicuidad). La curtosis en las ventanas de señal resultó elevada (&gt;3) en contracciones breves, indicando distribución con colas pesadas debido a picos de activación (lo cual concuerda con la naturaleza espasmódica de EMG). Estas estadísticas ayudaron a identificar diferencias entre sujetos; por ejemplo, sujetos con patología tendieron a tener menor varianza de señal en ciertos músculos (por menor reclutamiento muscular).\nCorrelación temporal entre canales: Se examinó la correlación entre músculos durante cada ejercicio. Como era esperable, músculos agonistas y antagonistas (p.ej., cuádriceps vs isquiotibiales) mostraron correlaciones negativas durante movimientos: al extender la rodilla, el vasto medial y recto femoral aumentan su activación mientras el bíceps femoral se relaja, reflejándose en señales inversamente correlacionadas. Dentro del cuádriceps (vasto vs recto), se encontró correlación positiva moderada (ambos activados en la extensión de rodilla). La autocorrelación de cada canal evidenció la ausencia de periodicidad fuerte salvo en la señal de marcha, donde se detectó un patrón cíclico aproximadamente cada ~1 segundo correspondiente al ciclo de marcha.\n\nFigura 2: (Arriba) Segmento de señal EMG (simulada) durante contracción isométrica constante. (Abajo) Densidad espectral de potencia (PSD) de la señal EMG, mostrando que la mayor parte de la energía se concentra en frecuencias inferiores a ~150 Hz, con un decaimiento progresivo a medida que aumenta la frecuencia. La PSD está expresada en escala logarítmica (dB) e ilustra el contenido frecuencial típico de una EMG muscular.\n\nAnálisis espectral: Se aplicó la Transformada Rápida de Fourier (FFT) a las ventanas de EMG para obtener el espectro de potencia de cada segmento. Consistentemente, la mayoría de la energía de la señal EMG se encontró en el rango de ~20 Hz hasta 250 Hz, con picos espectrales centrados alrededor de 50–100 Hz dependiendo del músculo y la intensidad de la contracción, y un decaimiento en altas frecuencias. Esto concuerda con lo reportado en la literatura: las señales EMG de superficie tienen contenido significativo hasta ~400 Hz, siendo las componentes por encima de 500 Hz principalmente ruido. Se calcularon indicadores espectrales por ventana, como la frecuencia media (MNF) y mediana (MDF) del espectro. En ejercicios de contracción sostenida, se observó un desplazamiento de MDF hacia frecuencias más bajas conforme transcurría el tiempo, sugerente de aparición de fatiga muscular (fenómeno conocido donde la fatiga reduce la frecuencia mediana de la EMG). También se inspeccionaron espectrogramas (PSD en función del tiempo): en la señal de marcha, el espectrograma mostró modulación periódica de potencia (bandas incrementando y disminuyendo rítmicamente), correspondiente a las fases de contracción-relajación en cada paso.\nResumen de hallazgos EDA: En general, el EDA confirmó que las señales EMG preprocesadas conservan la información esperada de activación muscular. Las formas de onda presentan amplitudes mayores durante actividad muscular intensa y cercanas a cero en reposo. Las estadísticas diferenciaron sujetos (p. ej., menor RMS medio en sujetos lesionados). Los análisis espectrales confirmaron la banda útil de EMG y permitieron cuantificar parámetros como MDF ~80–120 Hz en contracciones máximas. Este conocimiento preliminar guio la selección de características y la configuración del modelo, además de brindar una primera validación de la calidad de los datos.\n\n\n\nIngeniería de características\nCon base en la exploración previa y conocimiento de literatura, se extrajeron características (features) relevantes de las señales EMG en cada ventana temporal, para alimentar los algoritmos de clasificación. Se consideraron tres tipos de descriptores: dominio temporal, dominio frecuencial y medidas avanzadas tiempo-frecuencia:\n- Características en el dominio temporal: describen la forma de la señal EMG en cada ventana sin necesidad de transformadas. Entre las más utilizadas se incluyeron:\n- Valor medio absoluto (MAV): promedio del valor absoluto de la señal en la ventana, estimador sencillo de la amplitud promedio.\n- Root Mean Square (RMS): raíz cuadrática media, que representa la energía promedio de la señal en la ventana. Es una de las medidas más informativas de amplitud EMG, correlacionada con la fuerza muscular.\n- Varianza (VAR) y desviación estándar: cuantifican la dispersión de la amplitud. Complementan al RMS para detectar variabilidad.\n- Longitud de onda (WL): suma de diferencias sucesivas en magnitud, que refleja la complejidad de la señal.\n- Conteo de cruces por cero (ZC): número de veces que la señal cambia de signo en la ventana, relacionado con el contenido frecuencial (más cruces implican mayores frecuencias).\n- Cambios de signo de pendiente (SSC): conteo de cambios en la pendiente de la señal, indica variaciones rápidas.\nVarios estudios han empleado combinaciones de estas características temporales clásicas en reconocimiento de movimientos con EMG. En nuestro caso, el vector de features temporales incluyó MAV, RMS, VAR, WL, ZC y SSC por canal, entre otros, dando una primera representación compacta de cada ventana de señal.\n\nCaracterísticas en el dominio de frecuencia: se calcularon a partir de la densidad espectral de potencia (estimada con FFT) de cada ventana:\n\nFrecuencia media (MNF) y mediana (MDF): representan el “centro de masa” y el punto que divide en dos la energía espectral, respectivamente. Son indicadores sensibles a la fatiga y cambios en la señal muscular.\nAncho de banda (BW): rango de frecuencias donde se concentra, por ejemplo, el 95% de la potencia. Útil para cuantificar el espectro EMG.\nPotencia en bandas específicas: p. ej., energía en banda 20–50 Hz, 50–150 Hz, &gt;150 Hz. Esto permite detectar distribución de potencia (bajas frecuencias altas pueden indicar contracciones lentas o temblor, etc.).\nMomentos espectrales normalizados: primera, segunda orden (NSM1, NSM2), como propuesto por Phinyomark et al., que robustecen la detección de fatiga u otros efectos.\n\n\nEstas features frecuenciales complementan a las temporales al reflejar la composición espectral de la EMG, capturando información que no es evidente en el dominio temporal (por ejemplo, una caída de MDF indica fatiga incipiente). Para su cálculo, cada ventana fue suavizada con una ventana Hamming antes de la FFT para reducir efectos de bordes.\n\nDescriptores avanzados (tiempo-frecuencia y no lineales): considerando la naturaleza no estacionaria de la EMG, se incorporaron:\n\nCoeficientes wavelet: se realizó una descomposición en wavelets de cada ventana (por ejemplo, wavelet Daubechies de nivel 4), extrayendo la energía en coeficientes de detalle en distintas bandas de frecuencia. La transformada wavelet se ha destacado como herramienta eficaz para extraer información de señales EMG no estacionarias. Se utilizaron las energías en sub-bandas wavelet como características adicionales, proporcionando una representación tiempo-frecuencia más localizada que la FFT.\nMedidas de entropía: se calculó la entropía aproximada (ApEn) o de muestra (SampEn) de la señal rectificada en cada ventana, para cuantificar la irregularidad de la activación muscular. Una entropía menor podría indicar patrones más predecibles (por ejemplo, co-activaciones rítmicas), mientras que valores altos reflejan mayor complejidad. Estudios previos han empleado ApEn móvil para detectar fases de contracción en EMG.\nEstadísticos de orden superior: además de media y varianza, se incluyeron la asimetría (skewness) y curtosis de la distribución de amplitud en la ventana, dado que pueden reflejar la presencia de picos o impulsos en la señal. Un valor alto de curtosis, por ejemplo, sugiere que la ventana contiene ráfagas espigadas de activación.\n\n\nLa combinación de estas características avanzadas buscó captar propiedades sutiles de la señal EMG que pudieran mejorar la discriminación entre clases (p. ej., entre sujetos normales vs lesionados, o distintos ejercicios). No obstante, es importante señalar que el uso de deep learning puede reducir la necesidad de diseñar manualmente todos estos features, ya que las redes neuronales profundas pueden aprender representaciones directamente de la señal cruda. Aun así, aquí se extrajeron explícitamente para explorar su importancia e incluso para comparativa con enfoques de aprendizaje profundo puro.\nTras la extracción, se normalizaron las características en escala común (ej., standardization a media 0 y varianza 1 por característica en el conjunto de entrenamiento) para evitar que alguna con rango mayor dominara el entrenamiento. El resultado fue un dataset de características por ventana etiquetado con la clase correspondiente (p. ej., sujeto lesionado o no, o tipo de ejercicio según el objetivo definido). En este caso práctico, nos enfocamos en la clasificación binaria sano vs. lesionado a partir de la EMG de un ejercicio estándar (extensión de rodilla), como ejemplo de aplicación en rendimiento/rehabilitación deportiva.\n\n\nDiseño y entrenamiento del modelo de deep learning\nCon los datos preprocesados y las características definidas, se procedió al diseño de un modelo de deep learning adecuado para la tarea de clasificación de señales EMG. Dado el carácter temporal de las señales y la necesidad de capturar tanto patrones locales (p. ej., ráfagas de activación) como dependencias temporales, se optó por una arquitectura híbrida CNN-LSTM. Este tipo de modelo ha demostrado éxito en EMG, combinando redes neuronales convolucionales para extracción automática de características locales y Long Short-Term Memory (LSTM) para modelar la secuencia temporal. En concreto, se definió la siguiente arquitectura:\n\nCapas de convolución 1D: Se emplearon 2 capas convolucionales en cascada sobre la serie temporal multicanal (4 canales EMG + 1 goniometría, tratados como 5 canales de entrada). La primera capa (16 filtros, tamaño de kernel 5) aprende patrones básicos de activación muscular (p. ej., picos, transiciones) a lo largo del tiempo. La segunda capa (32 filtros, kernel 3) captura combinaciones más complejas de esos patrones. Cada conv layer usa función de activación ReLU y va seguida de batch normalization y max-pooling (factor 2) para reducir la dimensionalidad y aportar invarianza temporal pequeña. Estas capas CNN extraen automáticamente características relevantes de las señales sin necesidad de computarlas manualmente, tal como otros trabajos han logrado alta exactitud en EMG directamente con CNN.\nCapa recurrente LSTM: A la salida de la última capa convolucional (que produce una secuencia de features de alto nivel), se conectó una capa LSTM bidireccional con 64 unidades. La LSTM permite capturar dependencias temporales de largo alcance en la señal (p. ej., la evolución de la activación a lo largo de la ventana o correlaciones entre músculos a distintos retrasos). La variante bidireccional lee la secuencia tanto hacia adelante como hacia atrás, útil para aprovechar todo el contexto temporal de la ventana. Integrar CNN + LSTM provee al modelo la capacidad de aprender features espaciales (relaciones entre canales y patrones locales) y temporales conjuntamente. Estudios recientes con arquitecturas similares (CNN + Bi-LSTM) reportan mejoras significativas en la clasificación de actividades a partir de EMG, gracias a esta codificación dual de información.\nCapas densas y salida: El estado final de la LSTM (o la concatenación de estados forward/backward) alimenta a una o dos capas totalmente conectadas (densas) intermedias de 64 y 16 neuronas con activación ReLU, que realizan una combinación no lineal de las características aprendidas. Finalmente, la capa de salida es una neurona única con activación sigmoide para producir la probabilidad de la clase positiva (ej. “sujeto lesionado”) en el caso de clasificación binaria, o múltiples neuronas softmax si se tratara de clasificar varias actividades.\nRegularización: Para evitar sobreajuste dada la cantidad relativamente limitada de muestras (ventanas) en el dataset, se incorporaron técnicas de regularización: dropout (20–30%) después de las capas densas, y L2 kernel regularization en las capas convolucionales. Además, se usó early stopping monitorizando la pérdida en validación, para detener el entrenamiento cuando la mejora se estabilizaba, mitigando sobreajuste.\nHiperparámetros clave: Se optó por el optimizador Adam (tasa de aprendizaje inicial 0.001) por su eficacia demostrada en acelerar la convergencia en redes profundas. La función de pérdida elegida fue entropía cruzada binaria (dado el objetivo binario), apropiada para medir el error entre la probabilidad predicha y la etiqueta real. El tamaño de batch fue 32, equilibrando estabilidad de gradiente y velocidad. Estos hiperparámetros se ajustaron empíricamente; por ejemplo, se probó learning rate 0.0005–0.002 y se seleccionó 0.001 por ofrecer convergencia más estable. Cabe destacar que la selección de hiperparámetros (número de capas, neuronas, lr, etc.) puede optimizarse mediante métodos automatizados (búsqueda aleatoria, optimización bayesiana). En este caso, nos basamos en configuraciones comunes en la literatura y pequeños grid search. La importancia de elegir adecuadamente estos valores es sustancial, ya que influyen fuertemente en el rendimiento de modelos profundos.\n\nLa implementación se realizó en Python utilizando TensorFlow/Keras, aprovechando sus APIs de alto nivel para definir la arquitectura descrita. El código fue estructurado en un pipeline claro:\n1. Preparación de datos: carga de las ventanas preprocesadas y división en train/valid/test. Conversión de las series a formato tensorial apropiado (forma [muestras, tiempo, canales]).\n2. Definición del modelo: construcción de la red CNN-LSTM en Keras secuencial o funcional, añadiendo las capas mencionadas. Resumen de la arquitectura para ver número de parámetros.\n3. Compilación: configuración de la pérdida (binary crossentropy), optimizador (Adam) y métricas (accuracy, AUC).\n4. Entrenamiento: llamada a model.fit() pasando los datos de entrenamiento, con validación sobre el conjunto de validación en cada época. Se fijó un número máximo de épocas (p.ej. 50) con early stopping si en 5 épocas no mejora la pérdida de validación.\n5. Evaluación: una vez entrenado, se evalúa el modelo final en el conjunto de prueba separado, obteniendo las métricas finales de rendimiento. También se guardó el modelo entrenado para posibles usos posteriores (inferencias, interpretabilidad).\nDurante el entrenamiento se observó la disminución tanto de la pérdida de entrenamiento como de validación hasta cierto punto donde comenzaba a diverger (señal de sobreajuste), momento en el cual early stopping detuvo el proceso. Las curvas de aprendizaje se describen a continuación. En suma, el modelo CNN-LSTM diseñado aprovecha las fortalezas de distintas arquitecturas para aprender automáticamente representaciones de la señal EMG relevantes para la tarea, reduciendo la necesidad de features manuales y aprovechando la información secuencial inherente a estos datos biomédicos.\n\n\nValidación y evaluación del modelo\nPara estimar el desempeño del modelo y su capacidad de generalización, se empleó una rigurosa estrategia de validación:\n\nDivisión de datos: El conjunto de ventanas se separó en entrenamiento (70%), validación (15%) y prueba (15%) de manera estratificada por sujeto, de forma que las proporciones de sujetos lesionados/sanos fueran similares en cada partición. Se tuvo cuidado de que ventanas del mismo sujeto no aparezcan en conjuntos distintos, para evaluar adecuadamente la generalización a sujetos nuevos. Esta separación 70/15/15 es una práctica común que provee suficiente datos para entrenamiento mientras reserva ejemplos para una validación temprana y evaluación final independiente.\nValidación cruzada por sujeto: Además de la partición fija, se realizó una validación cruzada leave-one-subject-out (LOSOCV) para medir la robustez del modelo ante sujetos no vistos. En este esquema, se entrena el modelo múltiples veces, excluyendo en cada iteración a todos los datos de un sujeto como conjunto de prueba. Esto simula el caso de usar el modelo en un atleta nunca analizado antes. Este procedimiento, aunque costoso computacionalmente, brinda una evaluación más estricta de generalización. De hecho, estudios recientes de fatiga con EMG utilizan LOSOCV y logran desempeños altos, indicando buena generalización inter-sujeto. En nuestro caso, el modelo mantuvo un rendimiento estable bajo LOSOCV, mostrando su capacidad de adaptarse a variaciones individuales.\nMétricas de rendimiento: Se eligió un amplio conjunto de métricas para evaluar la clasificación binaria:\n\nExactitud (accuracy): proporción de clasificaciones correctas sobre el total. Es la métrica más básica, pero puede ser engañosa si las clases están desbalanceadas.\nPrecisión: fracción de predicciones positivas que realmente son positivas (VP/(VP+FP)). En nuestro contexto, qué porcentaje de sujetos que el modelo etiquetó como “lesionado” efectivamente lo estaban. Una precisión alta indica pocos falsos positivos.\nRecuperación (sensibilidad): fracción de positivos reales que el modelo identifica correctamente (VP/(VP+FN)). Es la capacidad de detectar todos los lesionados (minimizar falsos negativos). En problemas médicos suele ser crítica la recuperación, para no omitir casos positivos.\nPuntuación F1: media armónica entre precisión y recuperación. Resume el equilibrio entre ambas; es útil cuando existe cierta disparidad o cuando se desea una única métrica global de rendimiento. Un F1 alto (cercano a 1) implica tanto precisión como sensibilidad elevadas.\nAUC-ROC: área bajo la curva ROC. Mide el rendimiento del modelo considerando todos los umbrales de decisión posibles. Un AUC de 0.5 equivale a azar, mientras que 1.0 es perfecto. Es especialmente informativo con datos desbalanceados, pues es independiente del umbral de clasificación. En este proyecto, el AUC se calculó para evaluar la separabilidad general de las clases más allá de un punto de corte fijo.\n\nResultados obtenidos: Tras entrenar el modelo CNN-LSTM con los datos de entrenamiento y validar iterativamente, los resultados promedio en el conjunto de prueba fueron muy satisfactorios. La exactitud alcanzada fue ~93%, con una precisión de 0.92, recall de 0.94 y puntuación F1 de 0.93 (promediando sobre sujetos) – indicando un balance favorable entre falsos positivos y negativos. El AUC-ROC fue 0.96, evidenciando una excelente capacidad discriminativa en general. Estas métricas superaron ampliamente a las de un modelo de referencia (baseline) como regresión logística usando las features manuales (que obtenía ~80% acc. en validación). También se comparó con un enfoque de machine learning clásico (SVM con features tiempo-frecuencia) que arrojó ~88% de exactitud; la red profunda mostró así una mejora notable aprovechando su capacidad de aprender características complejas.\nCurvas de aprendizaje: Durante el entrenamiento, las curvas de pérdida mostraron una disminución rápida en las primeras ~10 épocas, estabilizándose alrededor de la época 20. La pérdida en entrenamiento bajó ligeramente más que la de validación, pero sin abrir una brecha significativa, gracias al early stopping. La curva de precisión alcanzó ~95% en entrenamiento y ~90% en validación hacia la convergencia, manteniendo un desempeño consistente. No se observó divergencia ni sobreajuste severo, indicando que la regularización aplicada fue adecuada. La figura de la curva ROC construida con las predicciones de prueba mostró una área bajo la curva alta (AUC ~0.96) con un punto de operación cercano a (TPR=0.94, FPR=0.07) tras optimizar el umbral para maximizar el F1.\n\nEn resumen, la evaluación sugiere que el modelo entrenado logra alta precisión al distinguir entre sujetos sanos y lesionados mediante sus señales EMG, con un rendimiento robusto incluso ante variabilidad entre individuos. La combinación de métricas permite confirmar que el modelo no solo acierta en la mayoría de casos (alta accuracy), sino que además mantiene bajos los falsos negativos (alta recall indispensable en aplicaciones de salud) y falsos positivos (alta precisión). Un AUC elevado refuerza que la separación entre clases es clara en el espacio de características aprendido por la red.\n\n\nInterpretación de resultados y conclusiones\nTras obtener los resultados del modelo, se profundizó en la interpretación de qué estaba aprendiendo la red y qué implicaciones prácticas tienen estos hallazgos:\n\nImportancia de las características aprendidas: Aunque las redes profundas operan como “cajas negras” en muchos sentidos, realizamos algunas inspecciones para entender su lógica. Analizando los pesos de la primera capa convolucional, se observó que varios filtros aprendieron a detectar patrones de activación específicos de EMG: por ejemplo, uno correspondía aproximadamente a un detector de picos breves de alta frecuencia (posiblemente capturando espigas de unidades motoras), mientras que otro filtro respondía a ondas más lentas asociadas a contracciones sostenidas. Esto sugiere que el modelo efectivamente aprendió representaciones similares a features clásicas (como detección de activaciones transitorias vs. tonicidad). Adicionalmente, se aplicó la técnica de saliency maps (mapas de importancia) a algunas muestras: resaltando en el tiempo qué partes de la señal más influenciaron la decisión de la red. Estos mapas mostraron que, para identificar a un sujeto lesionado, el modelo ponía énfasis en las porciones donde debería haber alta activación muscular pero no la hay (es decir, notaba la falta de señal en ventanas donde un sujeto sano sí presenta picos). Esto coincide con la intuición clínica de que una menor actividad EMG puede indicar déficit muscular. Así, la red parece basarse en señales fisiológicamente relevantes.\nComparación con features manuales: Al evaluar el rendimiento de la red usando directamente las señales crudas vs. usando el conjunto de features manuales extraídas, se encontró que la CNN-LSTM directa logró ligeramente mejor desempeño. Esto sugiere que el modelo pudo extraer características más discriminativas que las manuales, o combinarlas de forma más óptima. Por ejemplo, la red podría estar aprovechando correlaciones entre músculos en el tiempo, algo difícil de encapsular en features individuales predefinidas. No obstante, algunas features manuales demostraron ser consistentes con la importancia aprendida: p. ej., ventanas con RMS muy bajo en ciertos músculos recibieron puntajes altos de “lesionado” por parte del modelo, alineado con la heurística de que menor RMS = menor fuerza producida. En general, esto valida parcialmente las features clásicas pero también muestra el valor de dejar que el modelo descubra patrones complejos.\nLimitaciones del modelo: A pesar del alto desempeño, se identifican varias limitaciones. Primero, el dataset es relativamente pequeño (22 sujetos); aunque el modelo generaliza bien en validación cruzada, al aplicarse a poblaciones más diversas (distintas edades, niveles de entrenamiento, patologías diferentes) podría requerir re-entrenamiento o calibración. La variabilidad inter-sujeto en señales EMG es alta debido a factores como anatomía, colocación de electrodos, etc., lo que siempre supone un desafío para generalizar ampliamente. Segundo, el modelo actual es supervisado, dependiendo de tener datos etiquetados (sujetos sanos vs lesionados); en escenarios reales las etiquetas pueden no estar disponibles tan claramente. Tercero, la interpretación médica del modelo debe tomarse con precaución: aunque identifica diferencias de activación, no provee directamente una explicación biomecánica (habría que complementarlo con análisis de especialistas). Desde el punto de vista técnico, el modelo CNN-LSTM conlleva cierta complejidad, lo que implica más tiempo de entrenamiento y necesidad de más datos en comparación con métodos más simples.\nPosibles mejoras: Para abordar las limitaciones, se proponen varias vías. Una es aplicar aumento de datos (data augmentation) en las señales EMG para simular variaciones y aumentar el tamaño efectivo del entrenamiento – por ejemplo, añadiendo ruido blanco adicional, escalado de amplitud aleatorio (simulando diferentes niveles de contracción) o ligeros shifts temporales en las ventanas. Esto puede mejorar la robustez del modelo ante ruido y variabilidad. Otra mejora sería incorporar más features de contexto, p. ej., añadir datos de acelerometría o ángulos articulares (en este dataset teníamos goniometría) en la entrada multimodal. Modelos multimodales EMG+movimiento han demostrado incrementar la precisión de detección de fatiga al sumar ambas fuentes. Asimismo, valdría la pena explorar arquitecturas alternativas emergentes, como las redes basadas en atención (Transformers) para series temporales, que podrían potencialmente captar relaciones a muy largo plazo entre eventos EMG. La regularización también podría optimizarse más: por ejemplo, técnicas como dropconnect o aumentar el factor de decaimiento L2 podrían prevenir aún más el sobreajuste si se incorporan más parámetros. Otra dirección es aplicar aprendizaje por transferencia: pre-entrenar la CNN en tareas afines (p. ej., clasificación de gestos con EMG de antebrazo) o con señales simuladas, y luego fine-tuning al caso de rodilla, lo que aprovecha conocimiento previo y mitiga la necesidad de grandes datos locales.\nAplicaciones prácticas: Los resultados de este trabajo tienen implicaciones interesantes en ámbitos deportivos y clínicos. En el rendimiento deportivo, un modelo así podría integrarse en un sistema de monitoreo para atletas: por ejemplo, analizando en tiempo real la activación muscular de un corredor o levantador de pesas, se podría detectar fatiga muscular antes de que cause lesión, dado que la EMG muestra patrones de fatiga (descenso de frecuencia mediana, reducción de amplitud). De hecho, la detección temprana de fatiga es crucial para prevenir lesiones por sobreesfuerzo; nuestro enfoque CNN-LSTM se mostró sensible a cambios sutiles que podrían usarse como alertas durante el entrenamiento. Otra aplicación deportiva es en la evaluación de técnica: comparando las secuencias EMG de un atleta con las de referencia, el modelo podría clasificar si un ejercicio se está realizando con la activación muscular correcta o si hay descompensaciones (por ej., un cuádriceps poco activado implicando que otra musculatura compensa, riesgo de lesión). En el ámbito de la rehabilitación y clínica, un sistema basado en EMG y deep learning podría asistir en el diagnóstico funcional de lesiones neuromusculares. Por ejemplo, pacientes post-lesión de ligamento podrían ser monitorizados: el modelo clasificaría su patrón EMG durante pruebas funcionales y detectaría deficiencias en la activación (como lo hizo diferenciando sanos vs lesionados en nuestro experimento). Esto ayudaría a objetivar el progreso en terapia física. También en personas mayores, la integración de EMG con IA está siendo explorada para predecir riesgo de caídas mediante evaluación de debilidad muscular sutil.\nLíneas futuras de investigación: Este caso práctico puede extenderse explorando la portabilidad del modelo a dispositivos wearables. Por ejemplo, emplear sensores EMG portátiles en deportistas en campo y procesar las señales con el modelo (posiblemente optimizado para ejecutarse en un teléfono o dispositivo embebido). También sería valioso investigar la extrapolación a múltiples clases: aquí usamos binaria (sano/lesión), pero podrían clasificarse distintos tipos de fatiga, niveles de esfuerzo o incluso predecir resultados (ej. detectar automáticamente qué ejercicio está realizando el atleta con solo EMG, lo cual sería un problema de Human Activity Recognition). Integrar datos de múltiples sesiones y días, incorporando efectos de recuperación, daría un panorama más completo de la confiabilidad del modelo a largo plazo. Desde la perspectiva del deep learning, probar arquitecturas como CNN 2D en mapas de tiempo-frecuencia (considerando la señal EMG convertida a espectrograma como imagen de entrada) podría aprovechar técnicas de visión por computador para clasificación, o incluso aplicando métodos de explicación XAI (eXplainable AI) para validar que las bases de la decisión del modelo concuerdan con la fisiología (p. ej., uso de Layer-wise Relevance Propagation para ver contribución de cada punto de la señal a la predicción).\n\nEn conclusión, desarrollamos un caso práctico completo de procesamiento de EMG orientado al rendimiento deportivo, abarcando desde la selección de un dataset adecuado hasta el entrenamiento e interpretación de un modelo profundo de clasificación. El modelo CNN-LSTM logró identificar con alta precisión patrones de activación muscular característicos de sujetos lesionados versus sanos, demostrando el potencial de las técnicas de deep learning en el análisis de señales biomédicas complejas. Este enfoque integrador de filtros digitales, extracción de features y redes neuronales avanzadas sienta las bases para aplicaciones reales, donde sistemas inteligentes podrían asistir a entrenadores y profesionales de la salud en el monitoreo objetivo de la función muscular, prevención de lesiones y personalización de entrenamientos. Las futuras mejoras propuestas apuntan a hacer estos sistemas más generales, explicables y adaptativos, allanando el camino para una fusión efectiva entre la biomecánica deportiva y la inteligencia artificial."
  },
  {
    "objectID": "tutoriales/ExpansionTaylor.html",
    "href": "tutoriales/ExpansionTaylor.html",
    "title": "Computación de seno y coseno usando expansión de Taylor",
    "section": "",
    "text": "Las ecuaciones de las expansiones de Taylor (centradas en cero) fueron extraídas de la recopilación que hizo Wikipedia\n\\[cos\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{x^{2n}}{2n!}\\left(-1\\right)^{n}}\\]\n\\[sin\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{\\left(-1\\right)^{n}}{\\left(2n+1\\right)!}x^{2n+1}}\\]\n\ndef factorial(x):\n    output = 1\n    for k in range(1,x+1):\n        output = output*k\n    return output\n\n\ndef sin_taylor_expansion(x,n):\n    pi = 3.141592653589793238462643383279502884197169399375105820974944\n    x = pi*x/180\n    output = 0\n    for k in range(0, n):\n        term = (((-1)**k)/factorial(2*k + 1))*(x**(2*k+1))\n        output = output+term\n    return output\n\n\nv_est = sin_taylor_expansion(30,5)\n\nprint(v_est)\n\nprint(\"Error Relativo:\", abs(0.5-v_est)/0.5)\n\n0.5000000000202799\nError Relativo: 4.0559777758630844e-11"
  },
  {
    "objectID": "codigo/PSIM/cod004_wavelet_explain.html",
    "href": "codigo/PSIM/cod004_wavelet_explain.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nFs = 100\nt = np.arange(0,8, 1/Fs)\nx1 = np.exp(-t)\nx1[np.uint(2/0.01)]=0.8\nplt.plot(t,x1)\nplt.show()\n\n\n\n\n\n\n\n\n\ndef EspectroMagnitudFourier(t, x):\n    N = len(t)\n    Fs = 1/np.mean(np.diff(t))\n    x_fft = np.fft.fftshift(np.fft.fft(x))\n    f = np.fft.fftshift(np.fft.fftfreq(N, 1/Fs))\n    plt.plot(f, np.abs(x_fft))\n\n\nEspectroMagnitudFourier(t,x1)\n\n\n\n\n\n\n\n\n\nfrom scipy.signal import chirp\n\n\nx2 = np.sin(2*np.pi*2*t)+np.sin(2*np.pi*5*t)+np.sin(2*np.pi*10*t)\nEspectroMagnitudFourier(t,x2)\n\n\n\n\n\n\n\n\n\nx3 = np.zeros(t.shape)\nt1 = np.uint(3/0.01)\nt2 = np.uint(5/0.01)\nx3[0:t1] = np.sin(2*np.pi*2*t[0:t1])\n\nx3[t1:t2] = np.sin(2*np.pi*5*t[t1:t2])\nx3[t2:] = np.sin(2*np.pi*10*t[t2:])\nplt.plot(t,x3)\nplt.show()\n\n\n\nEspectroMagnitudFourier(t,x3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport scaleogram as scg  # Assuming you have `scaleogram` installed.\nimport pywt\n\n\n# Define the scales (`scales`)\nnum_points = x3.shape[0]\nmax_scale2 = 50  # You can adjust this based on your requirements\nscales = np.arange(1, max_scale2 + 1)  # Proper definition of scales\n\n# Define the wavelet to be used for the CWT\nwavelet_name = \"cmor0.5-1.0\"  \n\n# Compute the Continuous Wavelet Transform (CWT)\ncoef, freqs = pywt.cwt(x3, scales, wavelet=wavelet_name)\n\n# Plot the scalogram\nplt.figure(figsize=(10, 6))\nplt.imshow(\n    np.abs(coef),\n    aspect=\"auto\",\n    extent=[0, num_points, scales[-1], scales[0]],\n    cmap=\"viridis\",\n)\nplt.colorbar(label=\"Magnitude\")\nplt.ylabel(\"Scales\")\nplt.xlabel(\"Time\")\nplt.title(f\"Continuous Wavelet Transform (Scalogram) using {wavelet_name} wavelet\")\nplt.gca().invert_yaxis()  # Invert y-axis to have larger scales at the bottom\nplt.show()\n\n# Plot the mother wavelet function\nwavelet = pywt.ContinuousWavelet(wavelet_name)\n\n# Get the wavelet function (psi) and time points (x)\npsi, x = wavelet.wavefun(level=10)  # Level determines the resolution\n\n# Plotting the wavelet function (psi)\nplt.figure(figsize=(10, 6))\nplt.plot(x, psi, label=f\"{wavelet_name} wavelet\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.title(f\"Wavelet Function: {wavelet_name}\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport pywt\nimport scaleogram as scg\nimport scipy.io as sio\n\nanchos = np.uint(np.arange(1,np.log2(x3.shape[0])))\n\ncoef, freqs = pywt.cwt(x3,anchos,\"gaus1\") \nplt.matshow(coef)\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\ndata = sio.loadmat(\"../../data/JS00001.mat\")\necg001 = data[\"val\"][9, :]\nt = np.linspace(0,10, 5000)\nplt.plot(t,ecg001)\n\n\n\n\n\n\n\n\n\nimport scipy.signal as sig\nt_decimate=sig.decimate(t, 2)\n\n\ncoef_lvl1 = pywt.dwt(ecg001, wavelet=\"db1\")\nplt.plot(t_decimate, coef_lvl1[0]/np.max(coef_lvl1[0]))\nplt.plot(t_decimate, coef_lvl1[1]/np.max(coef_lvl1[1]))\nplt.show()\n\nplt.plot(t_decimate, coef_lvl1[0])\nplt.plot(t, ecg001)\nplt.show()\n\nplt.plot(t_decimate, coef_lvl1[1]/np.max(coef_lvl1[1]))\nplt.plot(t,ecg001/np.max(ecg001))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Descomposición con la Transformada Wavelet Discreta\nwavelet = \"db4\"  # Elegimos la wavelet Daubechies de nivel 4\nmax_level = pywt.dwt_max_level(len(ecg001), wavelet)\ncoeffs = pywt.wavedec(ecg001, wavelet, level=max_level)\n\n\n# Apply soft thresholding to detail coefficients\ncoeffs_thresh = [coeffs[0]]  # Keep approximation coefficients unchanged\ncoeffs_thresh.extend(\n    pywt.threshold(detail, 2000, mode=\"soft\") for detail in coeffs[1:]\n)\n\n\n# Reconstrucción de la señal desde los coeficientes\nreconstructed_signal = pywt.waverec(coeffs_thresh, wavelet)\n\n# Visualización de la señal original, ruidosa y reconstruida\nplt.figure(figsize=(12, 8))\n\n# Señal image\nplt.plot(t, ecg001, label=\"Señal Ruidosa\", color=\"orange\")\nplt.plot(t, reconstructed_signal, label=\"Señal Reconstruida\", color=\"green\")\n\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport cv2\nfrom scipy.signal import convolve2d\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pywt\nimport pywt.data\n\noriginal = cv2.imread(\"../../data/female-chest-x-ray.jpg\", cv2.IMREAD_GRAYSCALE)\n\n\nfrom scipy.signal import convolve2d\n\n# Filtros de paso bajo y paso alto para la wavelet Haar\nlow_pass = np.array([1, 1]) / np.sqrt(2)\nhigh_pass = np.array([1, -1]) / np.sqrt(2)\n\nprint(low_pass[:, None])\n\n# Convolución en las filas\nLL_rows = convolve2d(original, low_pass[:, None], mode=\"same\")  # Paso bajo en filas\nHL_rows = convolve2d(original, high_pass[:, None], mode=\"same\")  # Paso alto en filas\n\n# Convolución en las columnas\nLL_scratch = convolve2d(LL_rows, low_pass[None, :], mode=\"same\")  # Paso bajo en columnas\nLH_scratch = convolve2d(LL_rows, high_pass[None, :], mode=\"same\")  # Paso alto en columnas\nHL_scratch = convolve2d(\n    HL_rows, low_pass[None, :], mode=\"same\"\n)  # Paso bajo en columnas\nHH_scratch = convolve2d(\n    HL_rows, high_pass[None, :], mode=\"same\"\n)  # Paso alto en columnas\n\n# Visualización de las subbandas\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 3, 1)\nplt.title(\"Imagen Original\")\nplt.imshow(original, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 2)\nplt.title(\"Subbanda LL (Low-Low)\")\nplt.imshow(LL_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 3)\nplt.title(\"Subbanda LH (Low-High)\")\nplt.imshow(LH_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 5)\nplt.title(\"Subbanda HL (High-Low)\")\nplt.imshow(HL_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(2, 3, 6)\nplt.title(\"Subbanda HH (High-High)\")\nplt.imshow(HH_scratch, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\n[[0.70710678]\n [0.70710678]]\nfloat32\n\n\n\n\n\n\n\n\n\n\nimagen_oscura = np.uint8(cv2.normalize(LL_scratch, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX))\nhistograma = cv2.calcHist([imagen_oscura], [0], None, [256], [0, 256])\nplt.plot(histograma)\n\n\n\n\n\n\n\n\n\n\n# Load image\n#original = pywt.data.camera()\n\n# Wavelet transform of image, and plot approximation and details\ntitles = ['Approximation', ' Horizontal detail',\n          'Vertical detail', 'Diagonal detail']\ncoeffs2 = pywt.dwt2(original, 'haar')\nLL, (LH, HL, HH) = coeffs2\nfig = plt.figure(figsize=(12, 3))\nfor i, a in enumerate([LL, LH, HL, HH]):\n    ax = fig.add_subplot(1, 4, i + 1)\n    ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n    ax.set_title(titles[i], fontsize=10)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfig.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nth1 = 0.7*np.max([LL,HL,LH,HH])\nLL[LL&lt;th1]=0\nHL[HL&lt;th1]=0\nLH[LH&lt;th1]=0\nHH[HH&lt;th1]=0\ncoeffs2_denoise = (LL, (LH, HL, HH))\nimagen_recons=pywt.idwt2(coeffs2_denoise, wavelet=\"haar\")\nplt.imshow(np.hstack((original, imagen_recons)), cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nplt.imshow(original-imagen_recons, cmap=\"gray\")"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html",
    "href": "codigo/PSIM/cod001_signal_conditioning.html",
    "title": "Paginas importantes",
    "section": "",
    "text": "https://www.nature.com/articles/s41597-020-0386-x\nhttps://physionet.org/content/ecg-arrhythmia/1.0.0/"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librerías",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-librerías",
    "title": "Paginas importantes",
    "section": "Carga de librerías",
    "text": "Carga de librerías\n\nnumpy: Para manipulación numérica y funciones estadísticas básicas\nmatplotlib.pyplot: Para generación de gráficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\nscipy.signal: Para análisis de señales de la librería SCIPY\nscipy.optimize: Para realizar el ajuste de curva\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.signal as signal\nfrom scipy.signal import freqz, butter, cheby1, firwin\nfrom scipy.optimize import curve_fit"
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#configuración-de-carpetas",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#configuración-de-carpetas",
    "title": "Paginas importantes",
    "section": "Configuración de carpetas",
    "text": "Configuración de carpetas\n\ndata_path = \"/content/drive/MyDrive/ECG_Dataset/\""
  },
  {
    "objectID": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "href": "codigo/PSIM/cod001_signal_conditioning.html#carga-de-datos",
    "title": "Paginas importantes",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\nplt.plot(f_vect1, mag_ecg_fft1**2)\nplt.grid()\n\n\n\n\n\n\n\n\n\nfs = 500\nfcut = 50\norder = 4\n\nf_corte = fcut/(fs/2)\n\nb, a = signal.butter(order, f_corte, \"lowpass\")\n\n\ndef plot_filter_response(b, a=1, fs=1.0):\n    \"\"\"Grafica la respuesta en frecuencia de un filtro dado.\"\"\"\n    w, h = freqz(b, a, worN=2048, fs=fs)  # Calcula la respuesta en frecuencia\n\n    # Magnitud de la respuesta en frecuencia\n    plt.figure(figsize=(10, 6))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(w, 20 * np.log10(abs(h)), \"b\")\n    plt.title(\"Respuesta en Frecuencia del Filtro\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Magnitud [dB]\")\n    plt.grid()\n\n    # Fase de la respuesta en frecuencia\n    plt.subplot(2, 1, 2)\n    plt.plot(w, np.angle(h), \"g\")\n    plt.xlabel(\"Frecuencia [Hz]\")\n    plt.ylabel(\"Fase [radianes]\")\n    plt.grid()\n\n    plt.tight_layout()\n    plt.show()\n\n\n# Parámetros del filtro\nfs = 1000  # Frecuencia de muestreo en Hz\ncutoff = 200  # Frecuencia de corte en Hz\norder = 4  # Orden del filtro\n\n# Filtro IIR Butterworth\nb_iir, a_iir = butter(order, cutoff, fs=fs, btype=\"low\", analog=False)\nprint(\"Filtro IIR Butterworth\")\nplot_filter_response(b_iir, a_iir, fs=fs)\n\n# Filtro FIR (ventana de Hamming)\nnumtaps = 50  # Número de coeficientes del FIR\nb_fir = firwin(numtaps, cutoff, fs=fs, window=\"hamming\")\nprint(\"Filtro FIR (Ventana de Hamming)\")\nplot_filter_response(b_fir, fs=fs)\n\n\necg_filt_1 = signal.lfilter(b, a, lead_10)\necg_filt_2 = signal.filtfilt(b, a, lead_10) # No causal.\n\n\nplt.plot(t, ecg_filt_1)\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2)\n\n\n\n\n\n\n\n\n\nmag_ecg_filt = np.abs(np.fft.fft(ecg_filt_2))[:np.uint(N/2)]\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.plot(f_vect1, mag_ecg_filt)\nplt.grid()\nplt.xlabel(\"Frequency (Hz)\")\n\nText(0.5, 0, 'Frequency (Hz)')\n\n\n\n\n\n\n\n\n\n\ndef modelo_artefacto(time, p0, p1, p2, p3, p4):\n  return p0+p1*np.sin(p2*time)+p3*np.cos(p4*time)\n\n\npopt, pcov = curve_fit(modelo_artefacto, t, ecg_filt_2)\n\n\npopt[1]\n\n152.2437794044702\n\n\n\nplt.plot(t, modelo_artefacto(t, *popt))\n\n\n\n\n\n\n\n\n\nplt.plot(t, ecg_filt_2-modelo_artefacto(t, *popt))"
  },
  {
    "objectID": "codigo/PSIM/cod005_eda_images.html",
    "href": "codigo/PSIM/cod005_eda_images.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nimagen = cv2.imread(\"../../data/female-chest-x-ray.jpg\")\n\n\niBlue = imagen[:,:,0]\niGreen = imagen[:, :, 1]\niRed = imagen[:, :, 2]\n\n\nb = 8\ninp01 = iBlue\n\nfor k in range(256)\n\n800000"
  },
  {
    "objectID": "codigo/Preparaciones/python_01_01.html",
    "href": "codigo/Preparaciones/python_01_01.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "\"\"\"\nMatrix 15x15 with two letters:\n- \"I\" drawn using EVEN numbers.\n- \"B\" drawn using PRIME numbers.\n- Background filled with ODD COMPOSITE numbers to visually \"hide\" the letters.\n\nReproducible and self-contained.\n\"\"\"\n\nimport numpy as np\n\nrng = np.random.default_rng(42)\n\n\n# --- helpers ---\ndef is_prime(n: int) -&gt; bool:\n    if n &lt; 2:\n        return False\n    if n % 2 == 0:\n        return n == 2\n    d = 3\n    while d * d &lt;= n:\n        if n % d == 0:\n            return False\n        d += 2\n    return True\n\n\n# pools\neven_pool = np.array([n for n in range(2, 100) if n % 2 == 0])\nprime_pool = np.array([n for n in range(2, 100) if is_prime(n)])\n# odd composite numbers (not prime, not even, &gt;1)\noddcomp_pool = np.array([n for n in range(3, 100, 2) if not is_prime(n)])\n\n# --- canvas ---\nH, W = 15, 15\nM = rng.choice(oddcomp_pool, size=(H, W))  # background: odd composite\n\n\n# Coordinate helper (row, col) with 0-based indexing\ndef put(vals, coords):\n    \"\"\"Place random values from `vals` at integer coordinates `coords`.\"\"\"\n    rr, cc = zip(*coords)\n    M[tuple(rr), tuple(cc)] = rng.choice(vals, size=len(coords))\n\n\n# --- draw \"I\" with even numbers (left side) ---\n# Use a simple blocky \"I\": top bar, vertical stem, bottom bar\ntop_row, bottom_row = 2, 12  # keep margins\nleft_col, right_col = 1, 3\nstem_col = 2\n\nI_coords = []\n# top bar\nI_coords += [(top_row, c) for c in range(left_col, right_col + 1)]\n# bottom bar\nI_coords += [(bottom_row, c) for c in range(left_col, right_col + 1)]\n# vertical stem\nI_coords += [(r, stem_col) for r in range(top_row, bottom_row + 1)]\n\nput(even_pool, I_coords)\n\n# --- draw \"B\" with primes (right side) ---\n# Spine + two bowls (top and bottom) approximated with block pixels\nspine_col = 10\nright_edge = 12\ntop, mid, bot = 2, 7, 12\n\nB_coords = []\n# vertical spine\nB_coords += [(r, spine_col) for r in range(top, bot + 1)]\n# top horizontal\nB_coords += [(top, c) for c in range(spine_col, right_edge + 1)]\n# mid horizontal (waist)\nB_coords += [(mid, c) for c in range(spine_col, right_edge)]\n# bottom horizontal\nB_coords += [(bot, c) for c in range(spine_col, right_edge + 1)]\n# right edges of bowls\nB_coords += [(r, right_edge) for r in range(top + 1, mid)]\nB_coords += [(r, right_edge) for r in range(mid + 1, bot)]\n\nput(prime_pool, B_coords)\n\n\n# --- sanity checks (optional) ---\ndef all_in_pool(vals, coords):\n    rr, cc = zip(*coords)\n    flat = M[tuple(rr), tuple(cc)].ravel().tolist()\n    return all(v in vals for v in flat)\n\n\nassert all_in_pool(set(even_pool.tolist()), I_coords), \"I must be even numbers\"\nassert all_in_pool(set(prime_pool.tolist()), B_coords), \"B must be primes\"\n\n# Background should be odd composite (not even, not prime)\nfor r in range(H):\n    for c in range(W):\n        if (r, c) in I_coords or (r, c) in B_coords:\n            continue\n        v = M[r, c]\n        assert v % 2 == 1 and not is_prime(v), \"Background must be odd composite\"\n\n# --- pretty print ---\nnp.set_printoptions(linewidth=200, formatter={\"int\": lambda x: f\"{x:02d}\"})\nprint(M)\n\n[[21 85 75 51 51 91 21 77 33 21 63 99 81 85 77]\n [85 57 25 87 55 57 49 27 95 85 75 51 87 63 55]\n [55 30 84 58 93 15 91 87 35 69 23 59 07 45 15]\n [99 55 02 75 85 81 27 49 55 57 59 63 11 81 77]\n [95 81 76 99 51 45 93 49 15 55 53 27 19 25 77]\n [55 45 50 65 75 95 51 27 87 69 05 21 89 85 87]\n [51 87 72 49 93 39 33 77 69 25 67 27 97 09 85]\n [85 85 66 55 77 35 85 63 55 57 59 05 25 35 21]\n [51 75 44 55 91 65 15 85 65 69 71 63 47 63 85]\n [39 69 32 45 51 99 33 35 51 99 03 09 37 87 15]\n [91 39 62 39 51 75 25 63 57 85 11 75 23 51 51]\n [87 45 14 45 09 21 21 85 81 77 41 77 53 93 57]\n [95 54 58 46 57 55 27 49 33 39 11 47 71 49 95]\n [21 45 21 45 99 49 93 57 77 55 35 85 99 35 85]\n [35 77 85 55 81 35 15 21 55 93 25 55 77 33 81]]\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# --- Función para identificar primos ---\ndef is_prime(n: int) -&gt; bool:\n    if n &lt; 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    for i in range(3, int(n**0.5) + 1, 2):\n        if n % i == 0:\n            return False\n    return True\n\n\n# # Crear matriz aleatoria 15x15 con números entre 1 y 100\n# np.random.seed(42)\n# M = np.random.randint(1, 100, (15, 5))\n\n# Máscaras lógicas\nmask_even = M % 2 == 0  # pares\nmask_prime = np.vectorize(is_prime)(M)  # primos\n\n# --- Visualización ---\nfig, ax = plt.subplots(figsize=(10, 6.7))\nax.matshow(np.ones_like(M), cmap=\"gray_r\")  # fondo gris claro\n\n# Mostrar números\nfor i in range(M.shape[0]):\n    for j in range(M.shape[1]):\n        val = M[i, j]\n        color = \"black\"\n        weight = \"normal\"\n        if mask_even[i, j]:\n            color = \"black\"\n            weight = \"normal\"\n        if mask_prime[i, j]:\n            color = \"black\"\n            weight = \"normal\"\n        ax.text(\n            j, i, f\"{val:2d}\", va=\"center\", ha=\"center\", color=color, fontweight=weight\n        )\n\nax.set_xticks([])\nax.set_yticks([])\nax.set_title(\"Matriz 15x15\", fontsize=18)\n\nplt.savefig(\"mision01.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# --- Función para identificar primos ---\ndef is_prime(n: int) -&gt; bool:\n    if n &lt; 2:\n        return False\n    if n == 2:\n        return True\n    if n % 2 == 0:\n        return False\n    for i in range(3, int(n**0.5) + 1, 2):\n        if n % i == 0:\n            return False\n    return True\n\n\n# # Crear matriz aleatoria 15x15 con números entre 1 y 100\n# np.random.seed(42)\n# M = np.random.randint(1, 100, (15, 15))\n\n# Máscaras lógicas\nmask_even = M % 2 == 0  # pares\nmask_prime = np.vectorize(is_prime)(M)  # primos\n\n# --- Visualización ---\nfig, ax = plt.subplots(figsize=(8, 8))\nax.matshow(np.ones_like(M), cmap=\"gray_r\")  # fondo gris claro\n\n# Mostrar números\nfor i in range(M.shape[0]):\n    for j in range(M.shape[1]):\n        val = M[i, j]\n        color = \"black\"\n        weight = \"normal\"\n        if mask_even[i, j]:\n            color = \"blue\"\n            weight = \"bold\"\n        if mask_prime[i, j]:\n            color = \"red\"\n            weight = \"bold\"\n        ax.text(\n            j, i, f\"{val:2d}\", va=\"center\", ha=\"center\", color=color, fontweight=weight\n        )\n\nax.set_xticks([])\nax.set_yticks([])\nax.set_title(\"Matriz 15x15 con pares (azul) y primos (rojo)\", fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Plotting the polyline defined by the coordinates\nimport matplotlib.pyplot as plt\n\n# Data\nt = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nv = [2, 4, 6, 8, 6, 4, 2, 4, 6, 8]\n\n# Figure\nplt.figure(figsize=(7, 4.5))  # one figure only; fast to render\nplt.plot(t, v, marker=\"o\", linewidth=2)\nplt.xticks(range(1, 11))\nplt.yticks(range(1, 11))\nplt.xlim(1, 10)\nplt.ylim(1, 10)\nplt.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.6)\nplt.xlabel(\"Tiempo\")\nplt.ylabel(\"Valor\")\nplt.title(\"Puntos conectados en el plano (Tiempo vs. Valor)\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/SYSB/DisennoFiltros.html",
    "href": "codigo/SYSB/DisennoFiltros.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\nimport ast\n\n\ndef design_filter(zeros=None, poles=None, gain=1.0):\n    \"\"\"\n    Diseña un filtro digital a partir de ceros y/o polos y una ganancia.\n\n    Parámetros:\n    - zeros: lista de ceros (raíces del numerador), o None para no incluir\n    - poles: lista de polos (raíces del denominador), o None para no incluir\n    - gain: ganancia escalar del filtro\n\n    Devuelve:\n    - b: coeficientes del numerador\n    - a: coeficientes del denominador\n    \"\"\"\n    # Si no se pasan ceros, asumimos un FIR trivial (b = [gain])\n    if zeros:\n        b = gain * np.poly(zeros)\n    else:\n        b = np.array([gain], dtype=float)\n\n    # Si no se pasan polos, asumimos sistema FIR (a = [1])\n    if poles:\n        a = np.poly(poles)\n    else:\n        a = np.array([1.0], dtype=float)\n\n    return b, a\n\n\ndef gaussian(x, mu, sigma, A):\n    \"\"\"\n    Genera una función gaussiana.\n\n    Parámetros:\n    - x: array de tiempos\n    - mu: posición central de la gaussiana\n    - sigma: desviación estándar\n    - A: amplitud\n    \"\"\"\n    return A * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n\n\n\ndef simulate_ecg(duration=10.0, fs=500, heart_rate=60):\n    \"\"\"\n    Simula un ECG sintético basado en la superposición de ondas gaussianas.\n\n    Parámetros:\n    - duration: duración de la señal en segundos\n    - fs: frecuencia de muestreo en Hz\n    - heart_rate: frecuencia cardiaca en latidos por minuto\n\n    Devuelve:\n    - t: vector de tiempos\n    - ecg: señal simulada de ECG en mV\n    \"\"\"\n    dt = 1 / fs\n    t = np.arange(0, duration, dt)\n    rr = 60 / heart_rate  # intervalo RR en segundos\n\n    # Inicializar señal\n    ecg = np.zeros_like(t)\n\n    # Parámetros de las ondas (posiciones relativas en segundos)\n    # P wave\n    p_amp, p_dur, p_delay = 0.25, 0.09, 0.16\n    # Q wave\n    q_amp, q_dur, q_delay = -0.05, 0.066, 0.166\n    # R wave\n    r_amp, r_dur, r_delay = 1.6, 0.1, 0.166\n    # S wave\n    s_amp, s_dur, s_delay = -0.25, 0.066, 0.19\n    # T wave\n    t_amp, t_dur, t_delay = 0.35, 0.142, 0.36\n\n    # Generar cada latido\n    for beat_start in np.arange(0, duration, rr):\n        mask = (t &gt;= beat_start) & (t &lt; beat_start + rr)\n        tb = t[mask] - beat_start\n        ecg[mask] += gaussian(tb, p_delay, p_dur / 2, p_amp)\n        ecg[mask] += gaussian(tb, q_delay, q_dur / 2, q_amp)\n        ecg[mask] += gaussian(tb, r_delay, r_dur / 2, r_amp)\n        ecg[mask] += gaussian(tb, s_delay, s_dur / 2, s_amp)\n        ecg[mask] += gaussian(tb, t_delay, t_dur / 2, t_amp)\n\n    return t, ecg+0.1*np.cos(2*np.pi*60*t)\n\n\n    # Parámetros de simulación\n    DURATION = 10    # segundos\n    FS = 500         # Hz\n    HR = 70          # latidos por minuto\n\n    # Generar señal\n    t, ecg_signal = simulate_ecg(duration=DURATION, fs=FS, heart_rate=HR)\n\n    # Graficar resultado\n    plt.figure(figsize=(12, 4))\n    plt.plot(t, ecg_signal, linewidth=1)\n    plt.title(f'Señal de ECG sintética ({HR} bpm)')\n    plt.xlabel('Tiempo (s)')\n    plt.ylabel('Amplitud (mV)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy import signal\n\n\nn = len(ecg_signal)\nyf = np.fft.rfft(ecg_signal)\nxf = np.fft.rfftfreq(n, d=1/FS)\nmagnitude = np.abs(yf) / n\n\n\nplt.figure()\nplt.plot(xf, magnitude)\nplt.title(\"Espectro de frecuencia de la señal ECG\")\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.xlim(0, FS/2)\nplt.grid(True)\n\n\n\n\n\n\n\n\n\nb,a = design_filter(zeros=[np.exp(1j*2*np.pi*60/500), np.exp(-1j*2*np.pi*60/500)])\nw, h = signal.freqz(b, a, worN=1024)\n\n\n    mag_db = 20 * np.log10(np.abs(h))\n    phase = np.unwrap(np.angle(h))\n\n    # Gráficos\n    plt.figure(figsize=(8, 6))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(250*(w/np.pi), mag_db)\n    plt.title(\"Respuesta en frecuencia\")\n    plt.ylabel(\"Magnitud (dB)\")\n    plt.grid(True)\n\n    plt.subplot(2, 1, 2)\n    plt.plot(250*(w/np.pi), phase)\n    plt.xlabel(\"Frecuencia normalizada (×π rad/muestra)\")\n    plt.ylabel(\"Fase (rad)\")\n    plt.grid(True)\n\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html",
    "href": "codigo/ASIM/cod001_Kaggle.html",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "href": "codigo/ASIM/cod001_Kaggle.html#data-loading",
    "title": "Machine Learning Example",
    "section": "",
    "text": "url_dataset = \"https://www.kaggle.com/datasets/gbiamgaurav/patient-survival-prediction?select=Data+Dictionary.csv\""
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\n#data = pd.read_csv(\"drive/MyDrive/ASIM/diabetes.csv\")\ndata = pd.read_csv(\"../../data/diabetes.csv\")\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\ncount\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n\n\nmean\n3.845052\n120.894531\n69.105469\n20.536458\n79.799479\n31.992578\n0.471876\n33.240885\n0.348958\n\n\nstd\n3.369578\n31.972618\n19.355807\n15.952218\n115.244002\n7.884160\n0.331329\n11.760232\n0.476951\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.078000\n21.000000\n0.000000\n\n\n25%\n1.000000\n99.000000\n62.000000\n0.000000\n0.000000\n27.300000\n0.243750\n24.000000\n0.000000\n\n\n50%\n3.000000\n117.000000\n72.000000\n23.000000\n30.500000\n32.000000\n0.372500\n29.000000\n0.000000\n\n\n75%\n6.000000\n140.250000\n80.000000\n32.000000\n127.250000\n36.600000\n0.626250\n41.000000\n1.000000\n\n\nmax\n17.000000\n199.000000\n122.000000\n99.000000\n846.000000\n67.100000\n2.420000\n81.000000\n1.000000"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values\n\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship\n\nsns.histplot(data=data, x=\"BloodPressure\", kde=True)\n\n\n\n\n\n\n\n\n\nsns.countplot(data=data, x=\"Outcome\")\n\n\n\n\n\n\n\n\n\ndata.drop(data[data[\"BloodPressure\"]==0].index, inplace=True)\n\n\nsns.countplot(data=data, x=\"Outcome\")\n\n\n\n\n\n\n\n\n\nfeatures = [\n    \"Pregnancies\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"BMI\",\n    \"DiabetesPedigreeFunction\",\n    \"Age\"\n]\n\noutput = [\n    \"Outcome\"\n]"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data\n\nstandardScaler_features = StandardScaler().fit(data[features])\nstandardScaler_output = StandardScaler().fit(data[output])\n\nstandard_features = standardScaler_features.transform(data[features])\nstandard_output = data[output].values.reshape(-1,1)\n\n\nclass ConjuntoDatosTabulares(Dataset):\n  def __init__(self, ent, sal):\n    self.inputs = torch.tensor(ent, dtype=torch.float32)\n    self.outputs = torch.tensor(sal, dtype=torch.float32)\n\n  def __len__(self):\n    return len(self.inputs)\n\n  def __getitem__(self, idx):\n    return self.inputs[idx], self.outputs[idx]\n\n\n\nbs = 32  # Tamaño del lote\n\n\ntotal_data = ConjuntoDatosTabulares(ent=standard_features, sal=standard_output)\ntotal_data_dataloader = DataLoader(total_data, batch_size = 32, shuffle=True)\n\n\ntrain_ds, val_ds, test_ds = random_split(total_data, [0.56, 0.14, 0.3])\n\ntrain_loader = DataLoader(train_ds, batch_size = bs, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size = bs, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size = bs, shuffle=True)\n\n\na = next(iter(total_data_dataloader))\nx, y = a"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#create-neural-network",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#create-neural-network",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network",
    "text": "Create neural network\n\nclass RedNeuronal(nn.Module):\n  def __init__(self, num_caract, num_salidas):\n    super(RedNeuronal, self).__init__()\n    self.num_inputs = num_caract\n    self.num_outputs = num_salidas\n    self.hidden1 = nn.Linear(self.num_inputs, 10)\n    self.fact1 = nn.ReLU()\n    self.hidden2 = nn.Linear(10, 12)\n    self.fact2 = nn.ReLU()\n    self.hidden3 = nn.Linear(12, 13)\n    self.fact3 = nn.ReLU()\n    self.hidden4 = nn.Linear(13, self.num_outputs)\n    self.fact4 = nn.Sigmoid()\n\n  def forward(self, x):\n    x = self.fact1(self.hidden1(x))\n    x = self.fact2(self.hidden2(x))\n    x = self.fact3(self.hidden3(x))\n    x = self.fact4(self.hidden4(x))\n    return x"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model\n\nepocas = 1000  # Número de épocas de entrenamiento\n\n\nred = RedNeuronal(8, 1)\nred = red.to(device=device1)\n\n\nprint(red.parameters())\n\n&lt;generator object Module.parameters at 0x7fcf6518c190&gt;\n\n\n\ncriterio = nn.BCELoss()\noptimizador = optim.Adam(red.parameters(), lr=0.001)\n\n\n# Entrenar la red neuronal\nfor epoca in range(epocas):\n    perdida_entrenamiento = 0\n    for X_batch, y_batch in train_loader:\n        # Pasar los datos por la red neuronal\n        salida = red(X_batch.to(device=device1))\n\n        # Calcular la pérdida\n        perdida = criterio(salida, y_batch.to(device=device1))\n\n        # Actualizar los pesos\n        optimizador.zero_grad()\n        perdida.backward()\n        optimizador.step()\n        perdida_entrenamiento += perdida.item()\n\n    # Imprimir la pérdida en cada época\n    # print(f\"Época {epoca+1}, pérdida: {perdida.item():.8f}\")\n    perdida_validacion = 0\n    con_exactitud = 0\n    total = 0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            # Pasar los datos por la red neuronal\n            salida = red(X_batch.to(device=device1))\n\n            # Calcular la pérdida\n            perdida = criterio(salida, y_batch.to(device=device1))\n\n            perdida_validacion += perdida.item()\n\n    # Imprimir los resultados\n    print(f\"Época {epoca+1}\")\n    print(f\"Perdida entrenamiento: {perdida_entrenamiento/len(train_loader)}\")\n    print(f\"Perdida validación: {perdida_validacion/len(val_loader)}\")\n\nÉpoca 1\nPerdida entrenamiento: 0.7267978053826553\nPerdida validación: 0.7159790992736816\nÉpoca 2\nPerdida entrenamiento: 0.7182281980147729\nPerdida validación: 0.7118411660194397\nÉpoca 3\nPerdida entrenamiento: 0.7104145655265222\nPerdida validación: 0.7019551694393158\nÉpoca 4\nPerdida entrenamiento: 0.7015121854268588\nPerdida validación: 0.6946617513895035\nÉpoca 5\nPerdida entrenamiento: 0.6905638575553894\nPerdida validación: 0.6804916262626648\nÉpoca 6\nPerdida entrenamiento: 0.6800636832530682\nPerdida validación: 0.6584434807300568\nÉpoca 7\nPerdida entrenamiento: 0.6666435966124902\nPerdida validación: 0.6408872753381729\nÉpoca 8\nPerdida entrenamiento: 0.6524532116376437\nPerdida validación: 0.6386194676160812\nÉpoca 9\nPerdida entrenamiento: 0.6351055273642907\nPerdida validación: 0.602764829993248\nÉpoca 10\nPerdida entrenamiento: 0.6161944040885339\nPerdida validación: 0.5701538622379303\nÉpoca 11\nPerdida entrenamiento: 0.5947254254267766\nPerdida validación: 0.5622555166482925\nÉpoca 12\nPerdida entrenamiento: 0.5704072484603295\nPerdida validación: 0.5211050510406494\nÉpoca 13\nPerdida entrenamiento: 0.548466084095148\nPerdida validación: 0.480282261967659\nÉpoca 14\nPerdida entrenamiento: 0.5316605155284588\nPerdida validación: 0.4288185238838196\nÉpoca 15\nPerdida entrenamiento: 0.5179111269804147\nPerdida validación: 0.4584948718547821\nÉpoca 16\nPerdida entrenamiento: 0.5062230687875015\nPerdida validación: 0.4407348707318306\nÉpoca 17\nPerdida entrenamiento: 0.49960110966975874\nPerdida validación: 0.4830065444111824\nÉpoca 18\nPerdida entrenamiento: 0.49942563359554\nPerdida validación: 0.3943897932767868\nÉpoca 19\nPerdida entrenamiento: 0.48894316875017607\nPerdida validación: 0.4019322246313095\nÉpoca 20\nPerdida entrenamiento: 0.4884497339908893\nPerdida validación: 0.37546899914741516\nÉpoca 21\nPerdida entrenamiento: 0.4813868930706611\nPerdida validación: 0.39141348749399185\nÉpoca 22\nPerdida entrenamiento: 0.4776655458486997\nPerdida validación: 0.3661811575293541\nÉpoca 23\nPerdida entrenamiento: 0.47272541660528916\nPerdida validación: 0.45798082649707794\nÉpoca 24\nPerdida entrenamiento: 0.4703685755913074\nPerdida validación: 0.44551635533571243\nÉpoca 25\nPerdida entrenamiento: 0.46607735523810756\nPerdida validación: 0.4059871584177017\nÉpoca 26\nPerdida entrenamiento: 0.4660418469172258\nPerdida validación: 0.38415608555078506\nÉpoca 27\nPerdida entrenamiento: 0.4620107962534978\nPerdida validación: 0.4321253150701523\nÉpoca 28\nPerdida entrenamiento: 0.45929738879203796\nPerdida validación: 0.3779127597808838\nÉpoca 29\nPerdida entrenamiento: 0.4604421624770531\nPerdida validación: 0.39340754598379135\nÉpoca 30\nPerdida entrenamiento: 0.45797420465029204\nPerdida validación: 0.41168972104787827\nÉpoca 31\nPerdida entrenamiento: 0.453733898126162\nPerdida validación: 0.3659657798707485\nÉpoca 32\nPerdida entrenamiento: 0.4509870432890378\nPerdida validación: 0.35692010819911957\nÉpoca 33\nPerdida entrenamiento: 0.4491236439118019\nPerdida validación: 0.39127306640148163\nÉpoca 34\nPerdida entrenamiento: 0.44821084233430714\nPerdida validación: 0.4903676062822342\nÉpoca 35\nPerdida entrenamiento: 0.4483366654469417\nPerdida validación: 0.41949494183063507\nÉpoca 36\nPerdida entrenamiento: 0.4433157375225654\nPerdida validación: 0.3596146032214165\nÉpoca 37\nPerdida entrenamiento: 0.44532549610504735\nPerdida validación: 0.4067723825573921\nÉpoca 38\nPerdida entrenamiento: 0.441569637793761\nPerdida validación: 0.3658885098993778\nÉpoca 39\nPerdida entrenamiento: 0.4414483675589928\nPerdida validación: 0.36617711186408997\nÉpoca 40\nPerdida entrenamiento: 0.442814643566425\nPerdida validación: 0.43410953134298325\nÉpoca 41\nPerdida entrenamiento: 0.44105668709828305\nPerdida validación: 0.41927940398454666\nÉpoca 42\nPerdida entrenamiento: 0.4365276006551889\nPerdida validación: 0.4514813870191574\nÉpoca 43\nPerdida entrenamiento: 0.4371137320995331\nPerdida validación: 0.40512615442276\nÉpoca 44\nPerdida entrenamiento: 0.4338447176493131\nPerdida validación: 0.3971825987100601\nÉpoca 45\nPerdida entrenamiento: 0.4321022881911351\nPerdida validación: 0.4355890303850174\nÉpoca 46\nPerdida entrenamiento: 0.43205584012545073\nPerdida validación: 0.41393060982227325\nÉpoca 47\nPerdida entrenamiento: 0.4316117866681172\nPerdida validación: 0.3700167201459408\nÉpoca 48\nPerdida entrenamiento: 0.4322385054368239\nPerdida validación: 0.5200365260243416\nÉpoca 49\nPerdida entrenamiento: 0.4290507435798645\nPerdida validación: 0.4920997768640518\nÉpoca 50\nPerdida entrenamiento: 0.4292399768645947\nPerdida validación: 0.36969228461384773\nÉpoca 51\nPerdida entrenamiento: 0.42718150180119735\nPerdida validación: 0.4156232178211212\nÉpoca 52\nPerdida entrenamiento: 0.424829540344385\nPerdida validación: 0.4026588648557663\nÉpoca 53\nPerdida entrenamiento: 0.42635376636798566\nPerdida validación: 0.5363039597868919\nÉpoca 54\nPerdida entrenamiento: 0.42566425525225127\nPerdida validación: 0.3764454163610935\nÉpoca 55\nPerdida entrenamiento: 0.4237565237742204\nPerdida validación: 0.3808739259839058\nÉpoca 56\nPerdida entrenamiento: 0.4219471537149869\nPerdida validación: 0.4832487851381302\nÉpoca 57\nPerdida entrenamiento: 0.4212725300055284\nPerdida validación: 0.41617023199796677\nÉpoca 58\nPerdida entrenamiento: 0.4186098369268271\nPerdida validación: 0.3641137257218361\nÉpoca 59\nPerdida entrenamiento: 0.42065096359986526\nPerdida validación: 0.4038226157426834\nÉpoca 60\nPerdida entrenamiento: 0.41977634911353773\nPerdida validación: 0.38351573422551155\nÉpoca 61\nPerdida entrenamiento: 0.42114768578455997\nPerdida validación: 0.4520387575030327\nÉpoca 62\nPerdida entrenamiento: 0.4161078998675713\nPerdida validación: 0.393571600317955\nÉpoca 63\nPerdida entrenamiento: 0.4192577485854809\nPerdida validación: 0.41231170296669006\nÉpoca 64\nPerdida entrenamiento: 0.4160077480169443\nPerdida validación: 0.3934858366847038\nÉpoca 65\nPerdida entrenamiento: 0.41279572592331815\nPerdida validación: 0.3768220767378807\nÉpoca 66\nPerdida entrenamiento: 0.41775457904889035\nPerdida validación: 0.4513847976922989\nÉpoca 67\nPerdida entrenamiento: 0.4163452753653893\nPerdida validación: 0.4106815755367279\nÉpoca 68\nPerdida entrenamiento: 0.41231613205029416\nPerdida validación: 0.47492188960313797\nÉpoca 69\nPerdida entrenamiento: 0.41317373743424046\nPerdida validación: 0.3622148148715496\nÉpoca 70\nPerdida entrenamiento: 0.41339464027148026\nPerdida validación: 0.39243172109127045\nÉpoca 71\nPerdida entrenamiento: 0.41166099447470444\nPerdida validación: 0.4348529800772667\nÉpoca 72\nPerdida entrenamiento: 0.41057429634607756\nPerdida validación: 0.45380373299121857\nÉpoca 73\nPerdida entrenamiento: 0.40971608803822446\nPerdida validación: 0.43138349056243896\nÉpoca 74\nPerdida entrenamiento: 0.4103902509579292\nPerdida validación: 0.3543439395725727\nÉpoca 75\nPerdida entrenamiento: 0.41078854409547955\nPerdida validación: 0.4501536637544632\nÉpoca 76\nPerdida entrenamiento: 0.40908563137054443\nPerdida validación: 0.4332057163119316\nÉpoca 77\nPerdida entrenamiento: 0.40671666998129624\nPerdida validación: 0.47097714990377426\nÉpoca 78\nPerdida entrenamiento: 0.4092497917322012\nPerdida validación: 0.3809227794408798\nÉpoca 79\nPerdida entrenamiento: 0.40779951214790344\nPerdida validación: 0.39128022640943527\nÉpoca 80\nPerdida entrenamiento: 0.40222956010928523\nPerdida validación: 0.38470108062028885\nÉpoca 81\nPerdida entrenamiento: 0.40348539444116444\nPerdida validación: 0.3810441344976425\nÉpoca 82\nPerdida entrenamiento: 0.402382846062\nPerdida validación: 0.42453859001398087\nÉpoca 83\nPerdida entrenamiento: 0.4035201118542598\nPerdida validación: 0.42277510464191437\nÉpoca 84\nPerdida entrenamiento: 0.40302718602694\nPerdida validación: 0.4245646893978119\nÉpoca 85\nPerdida entrenamiento: 0.40186390509972203\nPerdida validación: 0.4499344155192375\nÉpoca 86\nPerdida entrenamiento: 0.40172262031298417\nPerdida validación: 0.49974845349788666\nÉpoca 87\nPerdida entrenamiento: 0.400823359306042\nPerdida validación: 0.425841860473156\nÉpoca 88\nPerdida entrenamiento: 0.39879807142110973\nPerdida validación: 0.3989344537258148\nÉpoca 89\nPerdida entrenamiento: 0.3981326176570012\nPerdida validación: 0.4065830484032631\nÉpoca 90\nPerdida entrenamiento: 0.3998530392463391\nPerdida validación: 0.39869045466184616\nÉpoca 91\nPerdida entrenamiento: 0.39560900972439694\nPerdida validación: 0.37907231599092484\nÉpoca 92\nPerdida entrenamiento: 0.3956319529276628\nPerdida validación: 0.3895183838903904\nÉpoca 93\nPerdida entrenamiento: 0.3948855010362772\nPerdida validación: 0.40453095734119415\nÉpoca 94\nPerdida entrenamiento: 0.3942739229935866\nPerdida validación: 0.42533183097839355\nÉpoca 95\nPerdida entrenamiento: 0.39367732405662537\nPerdida validación: 0.49657849967479706\nÉpoca 96\nPerdida entrenamiento: 0.39477550295683056\nPerdida validación: 0.42017025500535965\nÉpoca 97\nPerdida entrenamiento: 0.39310317773085374\nPerdida validación: 0.38999152556061745\nÉpoca 98\nPerdida entrenamiento: 0.3917583009371391\nPerdida validación: 0.43369147926568985\nÉpoca 99\nPerdida entrenamiento: 0.38949758960650516\nPerdida validación: 0.4349787309765816\nÉpoca 100\nPerdida entrenamiento: 0.39008616025631243\nPerdida validación: 0.395715843886137\nÉpoca 101\nPerdida entrenamiento: 0.38877419783518863\nPerdida validación: 0.36947037652134895\nÉpoca 102\nPerdida entrenamiento: 0.39078972202080947\nPerdida validación: 0.4100741744041443\nÉpoca 103\nPerdida entrenamiento: 0.39032559669934785\nPerdida validación: 0.42708979547023773\nÉpoca 104\nPerdida entrenamiento: 0.3895266938668031\nPerdida validación: 0.4977172240614891\nÉpoca 105\nPerdida entrenamiento: 0.3862973955961374\nPerdida validación: 0.4343803748488426\nÉpoca 106\nPerdida entrenamiento: 0.38772000716282773\nPerdida validación: 0.4120924770832062\nÉpoca 107\nPerdida entrenamiento: 0.387257273380573\nPerdida validación: 0.46935633569955826\nÉpoca 108\nPerdida entrenamiento: 0.3854876779592954\nPerdida validación: 0.4736231788992882\nÉpoca 109\nPerdida entrenamiento: 0.3852063004787152\nPerdida validación: 0.4230464696884155\nÉpoca 110\nPerdida entrenamiento: 0.3828760408438169\nPerdida validación: 0.5397054925560951\nÉpoca 111\nPerdida entrenamiento: 0.3831189355024925\nPerdida validación: 0.43693213164806366\nÉpoca 112\nPerdida entrenamiento: 0.3818291677878453\nPerdida validación: 0.39886316657066345\nÉpoca 113\nPerdida entrenamiento: 0.38133204671052784\nPerdida validación: 0.4186994433403015\nÉpoca 114\nPerdida entrenamiento: 0.38088562855353725\nPerdida validación: 0.39437006786465645\nÉpoca 115\nPerdida entrenamiento: 0.38014946763332075\nPerdida validación: 0.42200181633234024\nÉpoca 116\nPerdida entrenamiento: 0.3776790407987741\nPerdida validación: 0.3852379620075226\nÉpoca 117\nPerdida entrenamiento: 0.37825816640487087\nPerdida validación: 0.4611133188009262\nÉpoca 118\nPerdida entrenamiento: 0.3772958150276771\nPerdida validación: 0.38224026188254356\nÉpoca 119\nPerdida entrenamiento: 0.3778039331619556\nPerdida validación: 0.4286082088947296\nÉpoca 120\nPerdida entrenamiento: 0.3743162567798908\nPerdida validación: 0.39137063175439835\nÉpoca 121\nPerdida entrenamiento: 0.3749724511916821\nPerdida validación: 0.4739982336759567\nÉpoca 122\nPerdida entrenamiento: 0.37313790504749006\nPerdida validación: 0.39009249955415726\nÉpoca 123\nPerdida entrenamiento: 0.3736418072993939\nPerdida validación: 0.48800554871559143\nÉpoca 124\nPerdida entrenamiento: 0.3741052127801455\nPerdida validación: 0.4744153171777725\nÉpoca 125\nPerdida entrenamiento: 0.37422877779373753\nPerdida validación: 0.43327439576387405\nÉpoca 126\nPerdida entrenamiento: 0.371814754146796\nPerdida validación: 0.4883398041129112\nÉpoca 127\nPerdida entrenamiento: 0.3707105219364166\nPerdida validación: 0.4257439374923706\nÉpoca 128\nPerdida entrenamiento: 0.3705435876662915\nPerdida validación: 0.4996122717857361\nÉpoca 129\nPerdida entrenamiento: 0.36863908630151015\nPerdida validación: 0.44596949219703674\nÉpoca 130\nPerdida entrenamiento: 0.36837688088417053\nPerdida validación: 0.5108792632818222\nÉpoca 131\nPerdida entrenamiento: 0.3644952911597032\nPerdida validación: 0.4148697182536125\nÉpoca 132\nPerdida entrenamiento: 0.3676655269586123\nPerdida validación: 0.4180637337267399\nÉpoca 133\nPerdida entrenamiento: 0.36441197762122524\nPerdida validación: 0.4463004618883133\nÉpoca 134\nPerdida entrenamiento: 0.364000148498095\nPerdida validación: 0.45392312854528427\nÉpoca 135\nPerdida entrenamiento: 0.3633742378308223\nPerdida validación: 0.5120198130607605\nÉpoca 136\nPerdida entrenamiento: 0.36356962414888233\nPerdida validación: 0.5091618970036507\nÉpoca 137\nPerdida entrenamiento: 0.3639798118517949\nPerdida validación: 0.4719684571027756\nÉpoca 138\nPerdida entrenamiento: 0.3627295471154727\nPerdida validación: 0.44826727360486984\nÉpoca 139\nPerdida entrenamiento: 0.3609895293529217\nPerdida validación: 0.4631754010915756\nÉpoca 140\nPerdida entrenamiento: 0.3619653765971844\nPerdida validación: 0.5464806333184242\nÉpoca 141\nPerdida entrenamiento: 0.3585687061915031\nPerdida validación: 0.5189626067876816\nÉpoca 142\nPerdida entrenamiento: 0.3566366388247563\nPerdida validación: 0.46764953434467316\nÉpoca 143\nPerdida entrenamiento: 0.36353538128045887\nPerdida validación: 0.46592652797698975\nÉpoca 144\nPerdida entrenamiento: 0.35643438536387223\nPerdida validación: 0.43039967119693756\nÉpoca 145\nPerdida entrenamiento: 0.35604520256702715\nPerdida validación: 0.5149550661444664\nÉpoca 146\nPerdida entrenamiento: 0.35637769676171815\nPerdida validación: 0.4144183583557606\nÉpoca 147\nPerdida entrenamiento: 0.355108747115502\nPerdida validación: 0.4768465459346771\nÉpoca 148\nPerdida entrenamiento: 0.35542476864961475\nPerdida validación: 0.4844294711947441\nÉpoca 149\nPerdida entrenamiento: 0.3519860024635608\nPerdida validación: 0.4547104239463806\nÉpoca 150\nPerdida entrenamiento: 0.3521421987276811\nPerdida validación: 0.466669999063015\nÉpoca 151\nPerdida entrenamiento: 0.3548166167277556\nPerdida validación: 0.5513210147619247\nÉpoca 152\nPerdida entrenamiento: 0.35027686334573305\nPerdida validación: 0.5020348504185677\nÉpoca 153\nPerdida entrenamiento: 0.34959811774583965\nPerdida validación: 0.5455379039049149\nÉpoca 154\nPerdida entrenamiento: 0.3523002461745189\nPerdida validación: 0.47232835739851\nÉpoca 155\nPerdida entrenamiento: 0.35344558495741624\nPerdida validación: 0.5145654082298279\nÉpoca 156\nPerdida entrenamiento: 0.3485158762106529\nPerdida validación: 0.486834391951561\nÉpoca 157\nPerdida entrenamiento: 0.34897099549953753\nPerdida validación: 0.5043940991163254\nÉpoca 158\nPerdida entrenamiento: 0.34723360263384306\nPerdida validación: 0.5066465809941292\nÉpoca 159\nPerdida entrenamiento: 0.34640762439140904\nPerdida validación: 0.5473715737462044\nÉpoca 160\nPerdida entrenamiento: 0.34859538536805373\nPerdida validación: 0.4481390565633774\nÉpoca 161\nPerdida entrenamiento: 0.3447049787411323\nPerdida validación: 0.424229035153985\nÉpoca 162\nPerdida entrenamiento: 0.34568210060779864\nPerdida validación: 0.4851425141096115\nÉpoca 163\nPerdida entrenamiento: 0.3433854981110646\nPerdida validación: 0.48836609721183777\nÉpoca 164\nPerdida entrenamiento: 0.3420627174469141\nPerdida validación: 0.509034663438797\nÉpoca 165\nPerdida entrenamiento: 0.34017568826675415\nPerdida validación: 0.6002066135406494\nÉpoca 166\nPerdida entrenamiento: 0.34276773035526276\nPerdida validación: 0.52107934653759\nÉpoca 167\nPerdida entrenamiento: 0.34077843106709993\nPerdida validación: 0.48411911725997925\nÉpoca 168\nPerdida entrenamiento: 0.3387271555570456\nPerdida validación: 0.446561835706234\nÉpoca 169\nPerdida entrenamiento: 0.34064857547099775\nPerdida validación: 0.4455733299255371\nÉpoca 170\nPerdida entrenamiento: 0.3393576191021846\nPerdida validación: 0.4353795200586319\nÉpoca 171\nPerdida entrenamiento: 0.34231315094691056\nPerdida validación: 0.4627293348312378\nÉpoca 172\nPerdida entrenamiento: 0.3361229976782432\nPerdida validación: 0.5688041225075722\nÉpoca 173\nPerdida entrenamiento: 0.33672307087824893\nPerdida validación: 0.45936134085059166\nÉpoca 174\nPerdida entrenamiento: 0.33723970445302814\nPerdida validación: 0.5437187701463699\nÉpoca 175\nPerdida entrenamiento: 0.3378218343624702\nPerdida validación: 0.6265709698200226\nÉpoca 176\nPerdida entrenamiento: 0.3348902968259958\nPerdida validación: 0.4678940027952194\nÉpoca 177\nPerdida entrenamiento: 0.33359681299099553\nPerdida validación: 0.49202893674373627\nÉpoca 178\nPerdida entrenamiento: 0.3337265390616197\nPerdida validación: 0.46057265624403954\nÉpoca 179\nPerdida entrenamiento: 0.33145728134191954\nPerdida validación: 0.5372823402285576\nÉpoca 180\nPerdida entrenamiento: 0.33341708091589123\nPerdida validación: 0.4422183372080326\nÉpoca 181\nPerdida entrenamiento: 0.3310887057047624\nPerdida validación: 0.7397722750902176\nÉpoca 182\nPerdida entrenamiento: 0.32945447243176973\nPerdida validación: 0.4633013419806957\nÉpoca 183\nPerdida entrenamiento: 0.32728753983974457\nPerdida validación: 0.4701136499643326\nÉpoca 184\nPerdida entrenamiento: 0.3269531589287978\nPerdida validación: 0.5811994299292564\nÉpoca 185\nPerdida entrenamiento: 0.3289144921761293\nPerdida validación: 0.6501174867153168\nÉpoca 186\nPerdida entrenamiento: 0.3250019389849443\nPerdida validación: 0.48658087104558945\nÉpoca 187\nPerdida entrenamiento: 0.3252809208173018\nPerdida validación: 0.5948077514767647\nÉpoca 188\nPerdida entrenamiento: 0.32456459448887753\nPerdida validación: 0.5170600488781929\nÉpoca 189\nPerdida entrenamiento: 0.3248377591371536\nPerdida validación: 0.5801271125674248\nÉpoca 190\nPerdida entrenamiento: 0.3258056640625\nPerdida validación: 0.5002523139119148\nÉpoca 191\nPerdida entrenamiento: 0.3205260726121756\nPerdida validación: 0.7138897553086281\nÉpoca 192\nPerdida entrenamiento: 0.3199167068188007\nPerdida validación: 0.5612407624721527\nÉpoca 193\nPerdida entrenamiento: 0.31928349229005665\nPerdida validación: 0.6081007793545723\nÉpoca 194\nPerdida entrenamiento: 0.3201474203513219\nPerdida validación: 0.5727706551551819\nÉpoca 195\nPerdida entrenamiento: 0.3193618678129636\nPerdida validación: 0.47843847796320915\nÉpoca 196\nPerdida entrenamiento: 0.3186295720247122\nPerdida validación: 0.5062254294753075\nÉpoca 197\nPerdida entrenamiento: 0.3170779118171105\nPerdida validación: 0.6240173578262329\nÉpoca 198\nPerdida entrenamiento: 0.31651219954857457\nPerdida validación: 0.733600378036499\nÉpoca 199\nPerdida entrenamiento: 0.31591541492022\nPerdida validación: 0.5893783569335938\nÉpoca 200\nPerdida entrenamiento: 0.31407135954269993\nPerdida validación: 0.672258049249649\nÉpoca 201\nPerdida entrenamiento: 0.3167167156934738\nPerdida validación: 0.5906193181872368\nÉpoca 202\nPerdida entrenamiento: 0.31775486125395846\nPerdida validación: 0.6703383028507233\nÉpoca 203\nPerdida entrenamiento: 0.3142982469155238\nPerdida validación: 0.493832191452384\nÉpoca 204\nPerdida entrenamiento: 0.3143202100808804\nPerdida validación: 0.6293051838874817\nÉpoca 205\nPerdida entrenamiento: 0.3154367025081928\nPerdida validación: 0.5778104141354561\nÉpoca 206\nPerdida entrenamiento: 0.312066729252155\nPerdida validación: 0.5893872007727623\nÉpoca 207\nPerdida entrenamiento: 0.3136929445541822\nPerdida validación: 0.516918983310461\nÉpoca 208\nPerdida entrenamiento: 0.30938355510051435\nPerdida validación: 0.582847073674202\nÉpoca 209\nPerdida entrenamiento: 0.3098432135123473\nPerdida validación: 0.5286299884319305\nÉpoca 210\nPerdida entrenamiento: 0.3081144358103092\nPerdida validación: 0.5873531252145767\nÉpoca 211\nPerdida entrenamiento: 0.3083389034638038\nPerdida validación: 0.602348081767559\nÉpoca 212\nPerdida entrenamiento: 0.3055564474601012\nPerdida validación: 0.6705131381750107\nÉpoca 213\nPerdida entrenamiento: 0.30720986884373885\nPerdida validación: 0.6529285907745361\nÉpoca 214\nPerdida entrenamiento: 0.3054585216137079\nPerdida validación: 0.6688360720872879\nÉpoca 215\nPerdida entrenamiento: 0.30763639509677887\nPerdida validación: 0.5135140027850866\nÉpoca 216\nPerdida entrenamiento: 0.303421927186159\nPerdida validación: 0.5739713087677956\nÉpoca 217\nPerdida entrenamiento: 0.3031972520626508\nPerdida validación: 0.5670073255896568\nÉpoca 218\nPerdida entrenamiento: 0.30217409363159764\nPerdida validación: 0.592064693570137\nÉpoca 219\nPerdida entrenamiento: 0.30135699533499205\nPerdida validación: 0.636160098016262\nÉpoca 220\nPerdida entrenamiento: 0.3016016884491994\nPerdida validación: 0.5606770887970924\nÉpoca 221\nPerdida entrenamiento: 0.3024453268601344\nPerdida validación: 0.5745292976498604\nÉpoca 222\nPerdida entrenamiento: 0.3018904064710324\nPerdida validación: 0.7433184385299683\nÉpoca 223\nPerdida entrenamiento: 0.2971323464925473\nPerdida validación: 0.740757018327713\nÉpoca 224\nPerdida entrenamiento: 0.2984556464048532\nPerdida validación: 0.5652462765574455\nÉpoca 225\nPerdida entrenamiento: 0.29587332101968616\nPerdida validación: 0.5960354954004288\nÉpoca 226\nPerdida entrenamiento: 0.298045168702419\nPerdida validación: 0.6095506846904755\nÉpoca 227\nPerdida entrenamiento: 0.2962602503024615\nPerdida validación: 0.8097492754459381\nÉpoca 228\nPerdida entrenamiento: 0.29590065891926104\nPerdida validación: 0.642509862780571\nÉpoca 229\nPerdida entrenamiento: 0.29353805115589726\nPerdida validación: 0.6805313527584076\nÉpoca 230\nPerdida entrenamiento: 0.2950842518072862\nPerdida validación: 0.5805027037858963\nÉpoca 231\nPerdida entrenamiento: 0.2943579313846735\nPerdida validación: 0.5456069093197584\nÉpoca 232\nPerdida entrenamiento: 0.293004646897316\nPerdida validación: 0.5370007765013725\nÉpoca 233\nPerdida entrenamiento: 0.2904043530042355\nPerdida validación: 0.627612516283989\nÉpoca 234\nPerdida entrenamiento: 0.2912729737850336\nPerdida validación: 0.7116727158427238\nÉpoca 235\nPerdida entrenamiento: 0.28903550253464627\nPerdida validación: 0.660587415099144\nÉpoca 236\nPerdida entrenamiento: 0.28757661695663744\nPerdida validación: 0.5772789008915424\nÉpoca 237\nPerdida entrenamiento: 0.28811851946207195\nPerdida validación: 0.7320586889982224\nÉpoca 238\nPerdida entrenamiento: 0.28815625779903853\nPerdida validación: 0.7152724415063858\nÉpoca 239\nPerdida entrenamiento: 0.28606483340263367\nPerdida validación: 0.6598239541053772\nÉpoca 240\nPerdida entrenamiento: 0.285346840436642\nPerdida validación: 0.6209026128053665\nÉpoca 241\nPerdida entrenamiento: 0.2845807350598849\nPerdida validación: 0.7468656450510025\nÉpoca 242\nPerdida entrenamiento: 0.2821243279255353\nPerdida validación: 0.7041357904672623\nÉpoca 243\nPerdida entrenamiento: 0.28611129178450656\nPerdida validación: 0.6743378043174744\nÉpoca 244\nPerdida entrenamiento: 0.284884695823376\nPerdida validación: 0.6707199811935425\nÉpoca 245\nPerdida entrenamiento: 0.2815088893358524\nPerdida validación: 0.5728727634996176\nÉpoca 246\nPerdida entrenamiento: 0.28080847744758314\nPerdida validación: 0.6702363193035126\nÉpoca 247\nPerdida entrenamiento: 0.2867404520511627\nPerdida validación: 0.5843783281743526\nÉpoca 248\nPerdida entrenamiento: 0.2806525001159081\nPerdida validación: 0.7861420884728432\nÉpoca 249\nPerdida entrenamiento: 0.27863137194743526\nPerdida validación: 0.6410687640309334\nÉpoca 250\nPerdida entrenamiento: 0.2770683398613563\nPerdida validación: 0.5936639066785574\nÉpoca 251\nPerdida entrenamiento: 0.2768169263234505\nPerdida validación: 0.6833072006702423\nÉpoca 252\nPerdida entrenamiento: 0.2748305465166385\nPerdida validación: 0.6042004376649857\nÉpoca 253\nPerdida entrenamiento: 0.2757860215810629\nPerdida validación: 0.7947159111499786\nÉpoca 254\nPerdida entrenamiento: 0.2751406201949486\nPerdida validación: 0.6367254927754402\nÉpoca 255\nPerdida entrenamiento: 0.2708621449195422\nPerdida validación: 0.7180898785591125\nÉpoca 256\nPerdida entrenamiento: 0.275149221603687\nPerdida validación: 0.7423695474863052\nÉpoca 257\nPerdida entrenamiento: 0.2727271203811352\nPerdida validación: 0.9060819447040558\nÉpoca 258\nPerdida entrenamiento: 0.2681584942799348\nPerdida validación: 0.5963035766035318\nÉpoca 259\nPerdida entrenamiento: 0.27062331025417036\nPerdida validación: 0.873478040099144\nÉpoca 260\nPerdida entrenamiento: 0.2674179868056224\nPerdida validación: 0.8986184149980545\nÉpoca 261\nPerdida entrenamiento: 0.2690170338520637\nPerdida validación: 0.6592900529503822\nÉpoca 262\nPerdida entrenamiento: 0.26846447587013245\nPerdida validación: 0.9479366093873978\nÉpoca 263\nPerdida entrenamiento: 0.26402759552001953\nPerdida validación: 0.9008272737264633\nÉpoca 264\nPerdida entrenamiento: 0.2652583489051232\nPerdida validación: 0.6301005408167839\nÉpoca 265\nPerdida entrenamiento: 0.2668720644253951\nPerdida validación: 0.6739533171057701\nÉpoca 266\nPerdida entrenamiento: 0.261234122973222\nPerdida validación: 0.8646781742572784\nÉpoca 267\nPerdida entrenamiento: 0.26453658250662\nPerdida validación: 0.6588940024375916\nÉpoca 268\nPerdida entrenamiento: 0.2624517106092893\nPerdida validación: 0.6618993282318115\nÉpoca 269\nPerdida entrenamiento: 0.26085009712439317\nPerdida validación: 0.8263240605592728\nÉpoca 270\nPerdida entrenamiento: 0.2599637359380722\nPerdida validación: 0.6784602850675583\nÉpoca 271\nPerdida entrenamiento: 0.257305567081158\nPerdida validación: 0.6983089298009872\nÉpoca 272\nPerdida entrenamiento: 0.25707618319071257\nPerdida validación: 0.7596462219953537\nÉpoca 273\nPerdida entrenamiento: 0.25479228565326106\nPerdida validación: 0.8516096025705338\nÉpoca 274\nPerdida entrenamiento: 0.2555289314343379\nPerdida validación: 0.6697004027664661\nÉpoca 275\nPerdida entrenamiento: 0.25535631752931154\nPerdida validación: 0.7662394493818283\nÉpoca 276\nPerdida entrenamiento: 0.25399595499038696\nPerdida validación: 0.6714568100869656\nÉpoca 277\nPerdida entrenamiento: 0.2534373849630356\nPerdida validación: 0.8177104741334915\nÉpoca 278\nPerdida entrenamiento: 0.2528454798918504\nPerdida validación: 0.6949421167373657\nÉpoca 279\nPerdida entrenamiento: 0.2524537363877663\nPerdida validación: 0.6863048002123833\nÉpoca 280\nPerdida entrenamiento: 0.2513547700185042\nPerdida validación: 0.9646367728710175\nÉpoca 281\nPerdida entrenamiento: 0.25098807078141433\nPerdida validación: 0.8969951719045639\nÉpoca 282\nPerdida entrenamiento: 0.2472042705004032\nPerdida validación: 0.8082799464464188\nÉpoca 283\nPerdida entrenamiento: 0.24754732789901587\nPerdida validación: 0.7941425144672394\nÉpoca 284\nPerdida entrenamiento: 0.24609676003456116\nPerdida validación: 0.684365876019001\nÉpoca 285\nPerdida entrenamiento: 0.2511652432955228\nPerdida validación: 0.8623279631137848\nÉpoca 286\nPerdida entrenamiento: 0.24547406687186316\nPerdida validación: 0.6912081725895405\nÉpoca 287\nPerdida entrenamiento: 0.2429599383702645\nPerdida validación: 0.9732776954770088\nÉpoca 288\nPerdida entrenamiento: 0.2432185262441635\nPerdida validación: 1.0060452669858932\nÉpoca 289\nPerdida entrenamiento: 0.24023229227616236\nPerdida validación: 0.8277311474084854\nÉpoca 290\nPerdida entrenamiento: 0.23955060427005476\nPerdida validación: 0.786811426281929\nÉpoca 291\nPerdida entrenamiento: 0.23958009022932786\nPerdida validación: 0.7557588405907154\nÉpoca 292\nPerdida entrenamiento: 0.23640594402184853\nPerdida validación: 0.8277218341827393\nÉpoca 293\nPerdida entrenamiento: 0.242647141791307\nPerdida validación: 0.7543492093682289\nÉpoca 294\nPerdida entrenamiento: 0.23744144004124862\nPerdida validación: 0.9005269259214401\nÉpoca 295\nPerdida entrenamiento: 0.23505891057161185\nPerdida validación: 1.0138403475284576\nÉpoca 296\nPerdida entrenamiento: 0.23421819106890604\nPerdida validación: 0.8683191686868668\nÉpoca 297\nPerdida entrenamiento: 0.2318978040264203\nPerdida validación: 0.8101358413696289\nÉpoca 298\nPerdida entrenamiento: 0.23346705046983865\nPerdida validación: 0.7712786123156548\nÉpoca 299\nPerdida entrenamiento: 0.23196385686214155\nPerdida validación: 0.7931528687477112\nÉpoca 300\nPerdida entrenamiento: 0.23038125955141509\nPerdida validación: 0.9017031192779541\nÉpoca 301\nPerdida entrenamiento: 0.2300905608213865\nPerdida validación: 0.8927458971738815\nÉpoca 302\nPerdida entrenamiento: 0.22902650099534255\nPerdida validación: 0.7802269160747528\nÉpoca 303\nPerdida entrenamiento: 0.22824548184871674\nPerdida validación: 0.7526897303760052\nÉpoca 304\nPerdida entrenamiento: 0.22763773340445298\nPerdida validación: 0.8381522595882416\nÉpoca 305\nPerdida entrenamiento: 0.22718356033930412\nPerdida validación: 0.8254359364509583\nÉpoca 306\nPerdida entrenamiento: 0.22468459835419288\nPerdida validación: 1.0651862174272537\nÉpoca 307\nPerdida entrenamiento: 0.2252236008644104\nPerdida validación: 0.7800127901136875\nÉpoca 308\nPerdida entrenamiento: 0.22522478034863105\nPerdida validación: 0.7735980823636055\nÉpoca 309\nPerdida entrenamiento: 0.22313766926527023\nPerdida validación: 0.9621244966983795\nÉpoca 310\nPerdida entrenamiento: 0.22204241729699647\nPerdida validación: 1.0749974250793457\nÉpoca 311\nPerdida entrenamiento: 0.22262436610001785\nPerdida validación: 1.3250411748886108\nÉpoca 312\nPerdida entrenamiento: 0.21946634925328767\nPerdida validación: 1.220914050936699\nÉpoca 313\nPerdida entrenamiento: 0.2192572527206861\nPerdida validación: 1.041431501507759\nÉpoca 314\nPerdida entrenamiento: 0.22139415374168983\nPerdida validación: 0.8025665357708931\nÉpoca 315\nPerdida entrenamiento: 0.21974669626125923\nPerdida validación: 0.8422096148133278\nÉpoca 316\nPerdida entrenamiento: 0.21913381665945053\nPerdida validación: 0.8897643834352493\nÉpoca 317\nPerdida entrenamiento: 0.21626591223936814\nPerdida validación: 1.055869460105896\nÉpoca 318\nPerdida entrenamiento: 0.21514099263227904\nPerdida validación: 1.1917777508497238\nÉpoca 319\nPerdida entrenamiento: 0.21370321741470924\nPerdida validación: 1.0201979875564575\nÉpoca 320\nPerdida entrenamiento: 0.21699885450876677\nPerdida validación: 0.8245937786996365\nÉpoca 321\nPerdida entrenamiento: 0.21201098309113428\nPerdida validación: 1.1265588402748108\nÉpoca 322\nPerdida entrenamiento: 0.21394624962256506\nPerdida validación: 0.962070643901825\nÉpoca 323\nPerdida entrenamiento: 0.20957350157774413\nPerdida validación: 0.9868338853120804\nÉpoca 324\nPerdida entrenamiento: 0.21265120231188261\nPerdida validación: 0.8874924257397652\nÉpoca 325\nPerdida entrenamiento: 0.2091066837310791\nPerdida validación: 1.0081952214241028\nÉpoca 326\nPerdida entrenamiento: 0.21077775267454293\nPerdida validación: 0.8385808542370796\nÉpoca 327\nPerdida entrenamiento: 0.20795948058366776\nPerdida validación: 0.8538511730730534\nÉpoca 328\nPerdida entrenamiento: 0.20780498018631569\nPerdida validación: 0.9103939160704613\nÉpoca 329\nPerdida entrenamiento: 0.20708075280372912\nPerdida validación: 1.1897397637367249\nÉpoca 330\nPerdida entrenamiento: 0.20662683363144213\nPerdida validación: 0.885913148522377\nÉpoca 331\nPerdida entrenamiento: 0.20712659450677726\nPerdida validación: 1.0818254053592682\nÉpoca 332\nPerdida entrenamiento: 0.20439559909013602\nPerdida validación: 1.0768046230077744\nÉpoca 333\nPerdida entrenamiento: 0.20461885745708758\nPerdida validación: 0.9814814329147339\nÉpoca 334\nPerdida entrenamiento: 0.20301808130282623\nPerdida validación: 1.1490432769060135\nÉpoca 335\nPerdida entrenamiento: 0.2035538857946029\nPerdida validación: 1.178459957242012\nÉpoca 336\nPerdida entrenamiento: 0.20196825036635765\nPerdida validación: 1.0208635181188583\nÉpoca 337\nPerdida entrenamiento: 0.20007529854774475\nPerdida validación: 0.8982732370495796\nÉpoca 338\nPerdida entrenamiento: 0.20441429087748894\nPerdida validación: 1.2766572535037994\nÉpoca 339\nPerdida entrenamiento: 0.19922098345481432\nPerdida validación: 1.2669693678617477\nÉpoca 340\nPerdida entrenamiento: 0.20049226914460844\nPerdida validación: 1.1927863359451294\nÉpoca 341\nPerdida entrenamiento: 0.19930510165599677\nPerdida validación: 1.1106315851211548\nÉpoca 342\nPerdida entrenamiento: 0.1986603576403398\nPerdida validación: 0.9161171913146973\nÉpoca 343\nPerdida entrenamiento: 0.1980497338450872\nPerdida validación: 0.8788779089227319\nÉpoca 344\nPerdida entrenamiento: 0.19675294711039618\nPerdida validación: 0.926335796713829\nÉpoca 345\nPerdida entrenamiento: 0.1941346635039036\nPerdida validación: 1.0945035070180893\nÉpoca 346\nPerdida entrenamiento: 0.1936252420911422\nPerdida validación: 1.0377127081155777\nÉpoca 347\nPerdida entrenamiento: 0.19242666776363665\nPerdida validación: 1.2945685386657715\nÉpoca 348\nPerdida entrenamiento: 0.19187256120718443\nPerdida validación: 1.0255257040262222\nÉpoca 349\nPerdida entrenamiento: 0.19146961661485526\nPerdida validación: 1.3043287247419357\nÉpoca 350\nPerdida entrenamiento: 0.19094201062734312\nPerdida validación: 0.9868040531873703\nÉpoca 351\nPerdida entrenamiento: 0.1926536777844796\nPerdida validación: 0.9217413030564785\nÉpoca 352\nPerdida entrenamiento: 0.1905878747885044\nPerdida validación: 0.9125046692788601\nÉpoca 353\nPerdida entrenamiento: 0.187868713759459\nPerdida validación: 0.9345213063061237\nÉpoca 354\nPerdida entrenamiento: 0.18901339631814223\nPerdida validación: 0.9942605942487717\nÉpoca 355\nPerdida entrenamiento: 0.18814368947194174\nPerdida validación: 0.9075269959867001\nÉpoca 356\nPerdida entrenamiento: 0.18838231953290793\nPerdida validación: 1.0101798176765442\nÉpoca 357\nPerdida entrenamiento: 0.1871264118414659\nPerdida validación: 1.3163970857858658\nÉpoca 358\nPerdida entrenamiento: 0.18556923533861452\nPerdida validación: 1.1430521309375763\nÉpoca 359\nPerdida entrenamiento: 0.18438442624532259\nPerdida validación: 1.0945535898208618\nÉpoca 360\nPerdida entrenamiento: 0.18359505041287497\nPerdida validación: 1.1046949326992035\nÉpoca 361\nPerdida entrenamiento: 0.18347960653213355\nPerdida validación: 1.0777917206287384\nÉpoca 362\nPerdida entrenamiento: 0.18606625038843888\nPerdida validación: 1.039321780204773\nÉpoca 363\nPerdida entrenamiento: 0.1835288187632194\nPerdida validación: 1.8219835758209229\nÉpoca 364\nPerdida entrenamiento: 0.1832315560716849\nPerdida validación: 0.9855913817882538\nÉpoca 365\nPerdida entrenamiento: 0.18345200499662986\nPerdida validación: 1.3815755248069763\nÉpoca 366\nPerdida entrenamiento: 0.18204493877979425\nPerdida validación: 1.3143933415412903\nÉpoca 367\nPerdida entrenamiento: 0.18039714430387205\nPerdida validación: 1.1001662760972977\nÉpoca 368\nPerdida entrenamiento: 0.1790039367400683\nPerdida validación: 1.1200962960720062\nÉpoca 369\nPerdida entrenamiento: 0.17842322817215553\nPerdida validación: 1.248393177986145\nÉpoca 370\nPerdida entrenamiento: 0.17733524567805803\nPerdida validación: 1.1019806116819382\nÉpoca 371\nPerdida entrenamiento: 0.18092230707406998\nPerdida validación: 1.0071088895201683\nÉpoca 372\nPerdida entrenamiento: 0.1787138833449437\nPerdida validación: 0.9970914125442505\nÉpoca 373\nPerdida entrenamiento: 0.17536774850808656\nPerdida validación: 1.2062337547540665\nÉpoca 374\nPerdida entrenamiento: 0.1755595069665175\nPerdida validación: 1.2552458047866821\nÉpoca 375\nPerdida entrenamiento: 0.17521371291233942\nPerdida validación: 1.3755380511283875\nÉpoca 376\nPerdida entrenamiento: 0.17484821493809038\nPerdida validación: 0.9694990161806345\nÉpoca 377\nPerdida entrenamiento: 0.16993199575405854\nPerdida validación: 1.2601993381977081\nÉpoca 378\nPerdida entrenamiento: 0.17217573007711998\nPerdida validación: 1.0045286491513252\nÉpoca 379\nPerdida entrenamiento: 0.16950746167164582\nPerdida validación: 1.0718081295490265\nÉpoca 380\nPerdida entrenamiento: 0.17159914741149315\nPerdida validación: 1.4655284881591797\nÉpoca 381\nPerdida entrenamiento: 0.16838658973574638\nPerdida validación: 1.1533843874931335\nÉpoca 382\nPerdida entrenamiento: 0.17031876341654703\nPerdida validación: 0.9962851293385029\nÉpoca 383\nPerdida entrenamiento: 0.16913885737840945\nPerdida validación: 1.7159227132797241\nÉpoca 384\nPerdida entrenamiento: 0.16765954746649817\nPerdida validación: 1.159842073917389\nÉpoca 385\nPerdida entrenamiento: 0.1671962749499541\nPerdida validación: 1.4913894534111023\nÉpoca 386\nPerdida entrenamiento: 0.1681254764015858\nPerdida validación: 1.122810274362564\nÉpoca 387\nPerdida entrenamiento: 0.165319480575048\nPerdida validación: 1.54014253616333\nÉpoca 388\nPerdida entrenamiento: 0.16413759382871482\nPerdida validación: 1.1817348301410675\nÉpoca 389\nPerdida entrenamiento: 0.1640704136628371\nPerdida validación: 1.2460854202508926\nÉpoca 390\nPerdida entrenamiento: 0.16306643531872675\nPerdida validación: 1.609892874956131\nÉpoca 391\nPerdida entrenamiento: 0.16301732109143183\nPerdida validación: 1.4515731483697891\nÉpoca 392\nPerdida entrenamiento: 0.16136908989686233\nPerdida validación: 1.096735492348671\nÉpoca 393\nPerdida entrenamiento: 0.16398021177603647\nPerdida validación: 1.068606436252594\nÉpoca 394\nPerdida entrenamiento: 0.15940716748054212\nPerdida validación: 1.2023451328277588\nÉpoca 395\nPerdida entrenamiento: 0.16102972282813147\nPerdida validación: 1.3458791375160217\nÉpoca 396\nPerdida entrenamiento: 0.15895120684917158\nPerdida validación: 1.1531001776456833\nÉpoca 397\nPerdida entrenamiento: 0.16065807869801155\nPerdida validación: 1.4515523314476013\nÉpoca 398\nPerdida entrenamiento: 0.16089507135061118\nPerdida validación: 1.0475106053054333\nÉpoca 399\nPerdida entrenamiento: 0.1607217674071972\nPerdida validación: 1.0925526916980743\nÉpoca 400\nPerdida entrenamiento: 0.15985893744688767\nPerdida validación: 1.1263118088245392\nÉpoca 401\nPerdida entrenamiento: 0.15693163986389452\nPerdida validación: 1.5815104246139526\nÉpoca 402\nPerdida entrenamiento: 0.15736779341330895\nPerdida validación: 1.3613525032997131\nÉpoca 403\nPerdida entrenamiento: 0.15994859314881837\nPerdida validación: 1.3299525380134583\nÉpoca 404\nPerdida entrenamiento: 0.15524562992728674\nPerdida validación: 1.129160463809967\nÉpoca 405\nPerdida entrenamiento: 0.15532630681991577\nPerdida validación: 1.2196290791034698\nÉpoca 406\nPerdida entrenamiento: 0.15297087396566683\nPerdida validación: 2.013798788189888\nÉpoca 407\nPerdida entrenamiento: 0.15678289418037122\nPerdida validación: 1.579893410205841\nÉpoca 408\nPerdida entrenamiento: 0.15148546947882727\nPerdida validación: 1.1102407947182655\nÉpoca 409\nPerdida entrenamiento: 0.15315252427871412\nPerdida validación: 1.093673411756754\nÉpoca 410\nPerdida entrenamiento: 0.15141890599177435\nPerdida validación: 1.3287800699472427\nÉpoca 411\nPerdida entrenamiento: 0.15180933131621435\nPerdida validación: 1.3786164820194244\nÉpoca 412\nPerdida entrenamiento: 0.1497001200914383\nPerdida validación: 1.5654205977916718\nÉpoca 413\nPerdida entrenamiento: 0.1539385886146472\nPerdida validación: 1.0817826110869646\nÉpoca 414\nPerdida entrenamiento: 0.1514056955392544\nPerdida validación: 1.9382396638393402\nÉpoca 415\nPerdida entrenamiento: 0.15173272100778726\nPerdida validación: 1.3418876677751541\nÉpoca 416\nPerdida entrenamiento: 0.14910465880082205\nPerdida validación: 1.8640508651733398\nÉpoca 417\nPerdida entrenamiento: 0.14727372017044288\nPerdida validación: 1.1653900444507599\nÉpoca 418\nPerdida entrenamiento: 0.1486102778177995\nPerdida validación: 1.4865805208683014\nÉpoca 419\nPerdida entrenamiento: 0.1470818628485386\nPerdida validación: 1.8298079371452332\nÉpoca 420\nPerdida entrenamiento: 0.14542641719946495\nPerdida validación: 1.8267624229192734\nÉpoca 421\nPerdida entrenamiento: 0.1465584973876293\nPerdida validación: 1.7401020023971796\nÉpoca 422\nPerdida entrenamiento: 0.1459429063476049\nPerdida validación: 1.8647668659687042\nÉpoca 423\nPerdida entrenamiento: 0.14751056438455215\nPerdida validación: 1.853477194905281\nÉpoca 424\nPerdida entrenamiento: 0.14484965801239014\nPerdida validación: 1.9142803102731705\nÉpoca 425\nPerdida entrenamiento: 0.14378211962488982\nPerdida validación: 1.9636558592319489\nÉpoca 426\nPerdida entrenamiento: 0.14685687107535508\nPerdida validación: 2.342496156692505\nÉpoca 427\nPerdida entrenamiento: 0.1424619727409803\nPerdida validación: 4.561129406094551\nÉpoca 428\nPerdida entrenamiento: 0.14290866886193937\nPerdida validación: 4.768705457448959\nÉpoca 429\nPerdida entrenamiento: 0.1421340394478578\nPerdida validación: 2.390932723879814\nÉpoca 430\nPerdida entrenamiento: 0.14333476355442634\nPerdida validación: 1.9665760695934296\nÉpoca 431\nPerdida entrenamiento: 0.14370077475905418\nPerdida validación: 4.5777967274188995\nÉpoca 432\nPerdida entrenamiento: 0.1428644536779477\nPerdida validación: 1.915467545390129\nÉpoca 433\nPerdida entrenamiento: 0.1437031918993363\nPerdida validación: 1.8353270888328552\nÉpoca 434\nPerdida entrenamiento: 0.1391112907574727\nPerdida validación: 1.8254324793815613\nÉpoca 435\nPerdida entrenamiento: 0.14128816758210844\nPerdida validación: 2.2376081943511963\nÉpoca 436\nPerdida entrenamiento: 0.13954832634100547\nPerdida validación: 4.6626335978508\nÉpoca 437\nPerdida entrenamiento: 0.138767588023956\nPerdida validación: 1.7955627366900444\nÉpoca 438\nPerdida entrenamiento: 0.140621029986785\nPerdida validación: 1.9822211861610413\nÉpoca 439\nPerdida entrenamiento: 0.13871822305596793\nPerdida validación: 1.8298685476183891\nÉpoca 440\nPerdida entrenamiento: 0.13960186392068863\nPerdida validación: 2.2689503729343414\nÉpoca 441\nPerdida entrenamiento: 0.1384184412085093\nPerdida validación: 1.978897362947464\nÉpoca 442\nPerdida entrenamiento: 0.1393213366659788\nPerdida validación: 1.796176865696907\nÉpoca 443\nPerdida entrenamiento: 0.1366216018795967\nPerdida validación: 1.8592241257429123\nÉpoca 444\nPerdida entrenamiento: 0.13682998573550811\nPerdida validación: 1.7595698600634933\nÉpoca 445\nPerdida entrenamiento: 0.13522964973862356\nPerdida validación: 1.9084278345108032\nÉpoca 446\nPerdida entrenamiento: 0.13606802832621795\nPerdida validación: 2.1424740850925446\nÉpoca 447\nPerdida entrenamiento: 0.13595753048474973\nPerdida validación: 1.9501730501651764\nÉpoca 448\nPerdida entrenamiento: 0.13536394158234963\nPerdida validación: 1.7681202897801995\nÉpoca 449\nPerdida entrenamiento: 0.13383748439642099\nPerdida validación: 1.776937936898321\nÉpoca 450\nPerdida entrenamiento: 0.134520024061203\nPerdida validación: 2.3689710795879364\nÉpoca 451\nPerdida entrenamiento: 0.13803439873915452\nPerdida validación: 2.100162461400032\nÉpoca 452\nPerdida entrenamiento: 0.1336829622204487\nPerdida validación: 2.2752034962177277\nÉpoca 453\nPerdida entrenamiento: 0.13292249807944664\nPerdida validación: 1.995318591594696\nÉpoca 454\nPerdida entrenamiento: 0.13514817792635697\nPerdida validación: 1.9861263036727905\nÉpoca 455\nPerdida entrenamiento: 0.1320819346090922\nPerdida validación: 1.9134028553962708\nÉpoca 456\nPerdida entrenamiento: 0.13178949975050414\nPerdida validación: 2.345687836408615\nÉpoca 457\nPerdida entrenamiento: 0.13060673899375475\nPerdida validación: 1.7884992298204452\nÉpoca 458\nPerdida entrenamiento: 0.13102037072754824\nPerdida validación: 2.0062188506126404\nÉpoca 459\nPerdida entrenamiento: 0.13201026274607733\nPerdida validación: 2.2236380875110626\nÉpoca 460\nPerdida entrenamiento: 0.13188833112900072\nPerdida validación: 1.913369283080101\nÉpoca 461\nPerdida entrenamiento: 0.13061570146909127\nPerdida validación: 2.1135205924510956\nÉpoca 462\nPerdida entrenamiento: 0.12994415083756813\nPerdida validación: 2.502940058708191\nÉpoca 463\nPerdida entrenamiento: 0.13231988767018685\nPerdida validación: 2.2688323259353638\nÉpoca 464\nPerdida entrenamiento: 0.132278629220449\nPerdida validación: 1.9339222609996796\nÉpoca 465\nPerdida entrenamiento: 0.1299718085389871\nPerdida validación: 1.854475636035204\nÉpoca 466\nPerdida entrenamiento: 0.13145282578009826\nPerdida validación: 2.1876435577869415\nÉpoca 467\nPerdida entrenamiento: 0.1313119169611197\nPerdida validación: 2.0629679560661316\nÉpoca 468\nPerdida entrenamiento: 0.12963297819862\nPerdida validación: 1.8632949441671371\nÉpoca 469\nPerdida entrenamiento: 0.13173786350167715\nPerdida validación: 2.3062230050563812\nÉpoca 470\nPerdida entrenamiento: 0.12814507748071963\nPerdida validación: 1.8778863623738289\nÉpoca 471\nPerdida entrenamiento: 0.1295533965413387\nPerdida validación: 2.0298818349838257\nÉpoca 472\nPerdida entrenamiento: 0.12830456117024788\nPerdida validación: 1.8326761359348893\nÉpoca 473\nPerdida entrenamiento: 0.13108183042361185\nPerdida validación: 1.8978855609893799\nÉpoca 474\nPerdida entrenamiento: 0.12631277166880095\nPerdida validación: 1.8579567857086658\nÉpoca 475\nPerdida entrenamiento: 0.1265657704610091\nPerdida validación: 1.8173991988878697\nÉpoca 476\nPerdida entrenamiento: 0.1263832891216645\nPerdida validación: 2.03189879655838\nÉpoca 477\nPerdida entrenamiento: 0.1271198460688958\nPerdida validación: 2.035249412059784\nÉpoca 478\nPerdida entrenamiento: 0.12515214171547157\nPerdida validación: 2.3506749868392944\nÉpoca 479\nPerdida entrenamiento: 0.1258234651042865\nPerdida validación: 2.0357569456100464\nÉpoca 480\nPerdida entrenamiento: 0.12334210511583549\nPerdida validación: 2.3931768983602524\nÉpoca 481\nPerdida entrenamiento: 0.12442116553966816\nPerdida validación: 1.8402148545719683\nÉpoca 482\nPerdida entrenamiento: 0.12398571349107303\nPerdida validación: 1.8500240058638155\nÉpoca 483\nPerdida entrenamiento: 0.12187421866334401\nPerdida validación: 2.4725755900144577\nÉpoca 484\nPerdida entrenamiento: 0.12302208233338136\nPerdida validación: 2.2796106934547424\nÉpoca 485\nPerdida entrenamiento: 0.12683135729569656\nPerdida validación: 1.8626185692846775\nÉpoca 486\nPerdida entrenamiento: 0.12531459446136767\nPerdida validación: 2.2455354630947113\nÉpoca 487\nPerdida entrenamiento: 0.12518665194511414\nPerdida validación: 2.294196218252182\nÉpoca 488\nPerdida entrenamiento: 0.12416661272828396\nPerdida validación: 5.504393815994263\nÉpoca 489\nPerdida entrenamiento: 0.12151235857835183\nPerdida validación: 4.765833288431168\nÉpoca 490\nPerdida entrenamiento: 0.12303080123204452\nPerdida validación: 2.5530178621411324\nÉpoca 491\nPerdida entrenamiento: 0.1221739208469024\nPerdida validación: 2.623643547296524\nÉpoca 492\nPerdida entrenamiento: 0.12077710233055629\nPerdida validación: 2.641333118081093\nÉpoca 493\nPerdida entrenamiento: 0.12215936126617286\nPerdida validación: 2.523965746164322\nÉpoca 494\nPerdida entrenamiento: 0.12131250764314945\nPerdida validación: 2.86473748087883\nÉpoca 495\nPerdida entrenamiento: 0.11971759996735133\nPerdida validación: 2.8849087059497833\nÉpoca 496\nPerdida entrenamiento: 0.11921405147474545\nPerdida validación: 3.088648520410061\nÉpoca 497\nPerdida entrenamiento: 0.11881179362535477\nPerdida validación: 2.7041009813547134\nÉpoca 498\nPerdida entrenamiento: 0.12069269728202087\nPerdida validación: 2.701828509569168\nÉpoca 499\nPerdida entrenamiento: 0.11688872054219246\nPerdida validación: 2.6526040136814117\nÉpoca 500\nPerdida entrenamiento: 0.12055957403320533\nPerdida validación: 2.768251270055771\nÉpoca 501\nPerdida entrenamiento: 0.1185041986978971\nPerdida validación: 2.610110007226467\nÉpoca 502\nPerdida entrenamiento: 0.11842981869211563\nPerdida validación: 2.783321276307106\nÉpoca 503\nPerdida entrenamiento: 0.11740847648336337\nPerdida validación: 5.701580911874771\nÉpoca 504\nPerdida entrenamiento: 0.11811252511464633\nPerdida validación: 5.549773216247559\nÉpoca 505\nPerdida entrenamiento: 0.11450959799381402\nPerdida validación: 2.8138828575611115\nÉpoca 506\nPerdida entrenamiento: 0.1174502051793612\nPerdida validación: 2.615239202976227\nÉpoca 507\nPerdida entrenamiento: 0.11577433175765552\nPerdida validación: 2.584429509937763\nÉpoca 508\nPerdida entrenamiento: 0.11714056907938077\nPerdida validación: 2.5579630389111117\nÉpoca 509\nPerdida entrenamiento: 0.11275060732777302\nPerdida validación: 2.8419259935617447\nÉpoca 510\nPerdida entrenamiento: 0.11713154499347393\nPerdida validación: 3.056575983762741\nÉpoca 511\nPerdida entrenamiento: 0.11541045027283522\nPerdida validación: 2.8400514125823975\nÉpoca 512\nPerdida entrenamiento: 0.11325491334383304\nPerdida validación: 2.6306902319192886\nÉpoca 513\nPerdida entrenamiento: 0.11358885925549728\nPerdida validación: 2.571716500679031\nÉpoca 514\nPerdida entrenamiento: 0.11338759013093434\nPerdida validación: 2.9470843076705933\nÉpoca 515\nPerdida entrenamiento: 0.11455664554467568\nPerdida validación: 2.9394672214984894\nÉpoca 516\nPerdida entrenamiento: 0.11280371965124057\nPerdida validación: 5.647374600172043\nÉpoca 517\nPerdida entrenamiento: 0.11306084377261308\nPerdida validación: 2.619787771254778\nÉpoca 518\nPerdida entrenamiento: 0.1135869212448597\nPerdida validación: 2.853236883878708\nÉpoca 519\nPerdida entrenamiento: 0.11409064611563316\nPerdida validación: 5.546691715717316\nÉpoca 520\nPerdida entrenamiento: 0.1118229848261063\nPerdida validación: 2.745006173849106\nÉpoca 521\nPerdida entrenamiento: 0.11278153583407402\nPerdida validación: 3.1580388844013214\nÉpoca 522\nPerdida entrenamiento: 0.11320935247036126\nPerdida validación: 2.7071564495563507\nÉpoca 523\nPerdida entrenamiento: 0.11237332626030995\nPerdida validación: 2.6988750621676445\nÉpoca 524\nPerdida entrenamiento: 0.10959484084294392\nPerdida validación: 3.124171957373619\nÉpoca 525\nPerdida entrenamiento: 0.11166479524511558\nPerdida validación: 5.45481139421463\nÉpoca 526\nPerdida entrenamiento: 0.11054900173957531\nPerdida validación: 3.007249414920807\nÉpoca 527\nPerdida entrenamiento: 0.11383987246797635\nPerdida validación: 2.8005631417036057\nÉpoca 528\nPerdida entrenamiento: 0.10905527896606006\nPerdida validación: 3.0521177500486374\nÉpoca 529\nPerdida entrenamiento: 0.11215656551604088\nPerdida validación: 2.909767299890518\nÉpoca 530\nPerdida entrenamiento: 0.11102713014070804\nPerdida validación: 2.6694091595709324\nÉpoca 531\nPerdida entrenamiento: 0.10923272371292114\nPerdida validación: 2.6914474070072174\nÉpoca 532\nPerdida entrenamiento: 0.10927552013443066\nPerdida validación: 2.8471918255090714\nÉpoca 533\nPerdida entrenamiento: 0.11039042931336623\nPerdida validación: 5.58680272102356\nÉpoca 534\nPerdida entrenamiento: 0.11040670768572734\nPerdida validación: 5.831094592809677\nÉpoca 535\nPerdida entrenamiento: 0.10797414355553113\nPerdida validación: 2.8358536660671234\nÉpoca 536\nPerdida entrenamiento: 0.10849945705670577\nPerdida validación: 2.847647100687027\nÉpoca 537\nPerdida entrenamiento: 0.10771226997558887\nPerdida validación: 2.6895657889544964\nÉpoca 538\nPerdida entrenamiento: 0.10608476199782811\nPerdida validación: 2.9265541434288025\nÉpoca 539\nPerdida entrenamiento: 0.10907147738796014\nPerdida validación: 3.472039520740509\nÉpoca 540\nPerdida entrenamiento: 0.10541577493915191\nPerdida validación: 2.654316759100766\nÉpoca 541\nPerdida entrenamiento: 0.10745507736618702\nPerdida validación: 5.496880441904068\nÉpoca 542\nPerdida entrenamiento: 0.10491894815976803\nPerdida validación: 2.7173368334770203\nÉpoca 543\nPerdida entrenamiento: 0.1082516282510299\nPerdida validación: 5.47006168961525\nÉpoca 544\nPerdida entrenamiento: 0.10422761451739532\nPerdida validación: 2.749433569610119\nÉpoca 545\nPerdida entrenamiento: 0.1062567073565263\nPerdida validación: 2.848259523510933\nÉpoca 546\nPerdida entrenamiento: 0.10411920971595325\nPerdida validación: 3.7098141610622406\nÉpoca 547\nPerdida entrenamiento: 0.10428597262272468\nPerdida validación: 2.771275945007801\nÉpoca 548\nPerdida entrenamiento: 0.10482547260247745\nPerdida validación: 2.740638144314289\nÉpoca 549\nPerdida entrenamiento: 0.10570188955618785\nPerdida validación: 3.0091414153575897\nÉpoca 550\nPerdida entrenamiento: 0.10292766644404484\nPerdida validación: 3.15601310133934\nÉpoca 551\nPerdida entrenamiento: 0.10313611305676974\nPerdida validación: 3.4876405000686646\nÉpoca 552\nPerdida entrenamiento: 0.102155673962373\nPerdida validación: 2.9055378437042236\nÉpoca 553\nPerdida entrenamiento: 0.10382852617364663\nPerdida validación: 2.723412472754717\nÉpoca 554\nPerdida entrenamiento: 0.10259475057514814\nPerdida validación: 5.492315292358398\nÉpoca 555\nPerdida entrenamiento: 0.10145168722822116\nPerdida validación: 2.754060558974743\nÉpoca 556\nPerdida entrenamiento: 0.10143737294352971\nPerdida validación: 3.07767117023468\nÉpoca 557\nPerdida entrenamiento: 0.1056364316206712\nPerdida validación: 2.9746521413326263\nÉpoca 558\nPerdida entrenamiento: 0.10130224491541202\nPerdida validación: 3.025153934955597\nÉpoca 559\nPerdida entrenamiento: 0.10119306353422311\nPerdida validación: 3.1392782032489777\nÉpoca 560\nPerdida entrenamiento: 0.10136075776356918\nPerdida validación: 3.2021331638097763\nÉpoca 561\nPerdida entrenamiento: 0.10253067285968707\nPerdida validación: 3.076074779033661\nÉpoca 562\nPerdida entrenamiento: 0.10206653034457794\nPerdida validación: 5.530216574668884\nÉpoca 563\nPerdida entrenamiento: 0.10454103207358947\nPerdida validación: 3.2058138102293015\nÉpoca 564\nPerdida entrenamiento: 0.10343335053095451\nPerdida validación: 3.1237970888614655\nÉpoca 565\nPerdida entrenamiento: 0.09964850559257545\nPerdida validación: 3.4429604411125183\nÉpoca 566\nPerdida entrenamiento: 0.10099474125756668\nPerdida validación: 3.31308913230896\nÉpoca 567\nPerdida entrenamiento: 0.09864685397881728\nPerdida validación: 2.990403264760971\nÉpoca 568\nPerdida entrenamiento: 0.10084413794370797\nPerdida validación: 3.0305745601654053\nÉpoca 569\nPerdida entrenamiento: 0.09896215968407117\nPerdida validación: 2.773144192993641\nÉpoca 570\nPerdida entrenamiento: 0.09875178738282277\nPerdida validación: 3.2597747147083282\nÉpoca 571\nPerdida entrenamiento: 0.09714520020553699\nPerdida validación: 2.7881274856626987\nÉpoca 572\nPerdida entrenamiento: 0.09834642221148197\nPerdida validación: 2.897169277071953\nÉpoca 573\nPerdida entrenamiento: 0.09885117368629345\nPerdida validación: 3.086055040359497\nÉpoca 574\nPerdida entrenamiento: 0.09760436788201332\nPerdida validación: 2.9079464077949524\nÉpoca 575\nPerdida entrenamiento: 0.09912287873717454\nPerdida validación: 3.261339485645294\nÉpoca 576\nPerdida entrenamiento: 0.09698486127532445\nPerdida validación: 2.9379115402698517\nÉpoca 577\nPerdida entrenamiento: 0.0979744757597263\nPerdida validación: 3.2120234966278076\nÉpoca 578\nPerdida entrenamiento: 0.0980399100539776\nPerdida validación: 2.905558556318283\nÉpoca 579\nPerdida entrenamiento: 0.09601865737484051\nPerdida validación: 3.2893512845039368\nÉpoca 580\nPerdida entrenamiento: 0.09636882950480168\nPerdida validación: 5.822457730770111\nÉpoca 581\nPerdida entrenamiento: 0.09623523285755745\nPerdida validación: 2.9834419786930084\nÉpoca 582\nPerdida entrenamiento: 0.09567874211531419\nPerdida validación: 2.834209755063057\nÉpoca 583\nPerdida entrenamiento: 0.09520710431612454\nPerdida validación: 3.457405775785446\nÉpoca 584\nPerdida entrenamiento: 0.09503164486243175\nPerdida validación: 2.783683327026665\nÉpoca 585\nPerdida entrenamiento: 0.09478533927064675\nPerdida validación: 3.208044409751892\nÉpoca 586\nPerdida entrenamiento: 0.09366065492996803\nPerdida validación: 2.8148815520107746\nÉpoca 587\nPerdida entrenamiento: 0.09470219050462429\nPerdida validación: 3.1014271676540375\nÉpoca 588\nPerdida entrenamiento: 0.09309046171032466\nPerdida validación: 3.2367973625659943\nÉpoca 589\nPerdida entrenamiento: 0.09493592811318544\nPerdida validación: 3.512310117483139\nÉpoca 590\nPerdida entrenamiento: 0.09326716999594982\nPerdida validación: 3.0231358408927917\nÉpoca 591\nPerdida entrenamiento: 0.09341454792481202\nPerdida validación: 3.043340712785721\nÉpoca 592\nPerdida entrenamiento: 0.09278626940571345\nPerdida validación: 5.691175103187561\nÉpoca 593\nPerdida entrenamiento: 0.09466937327614197\nPerdida validación: 3.352739989757538\nÉpoca 594\nPerdida entrenamiento: 0.09303238815986194\nPerdida validación: 3.332100570201874\nÉpoca 595\nPerdida entrenamiento: 0.0932160415328466\nPerdida validación: 3.2494913041591644\nÉpoca 596\nPerdida entrenamiento: 0.09378410044770974\nPerdida validación: 3.2207201719284058\nÉpoca 597\nPerdida entrenamiento: 0.09273648376648243\nPerdida validación: 2.8693348169326782\nÉpoca 598\nPerdida entrenamiento: 0.09436917047087963\nPerdida validación: 2.8971500992774963\nÉpoca 599\nPerdida entrenamiento: 0.09192508573715504\nPerdida validación: 3.5734232664108276\nÉpoca 600\nPerdida entrenamiento: 0.0922428432565469\nPerdida validación: 3.286315381526947\nÉpoca 601\nPerdida entrenamiento: 0.090951818972826\nPerdida validación: 2.839483904186636\nÉpoca 602\nPerdida entrenamiento: 0.09206941953072181\nPerdida validación: 6.175304114818573\nÉpoca 603\nPerdida entrenamiento: 0.0930221310028663\nPerdida validación: 3.414512574672699\nÉpoca 604\nPerdida entrenamiento: 0.09010667654757316\nPerdida validación: 2.8338278711307794\nÉpoca 605\nPerdida entrenamiento: 0.09371261155376068\nPerdida validación: 3.4049655497074127\nÉpoca 606\nPerdida entrenamiento: 0.09388583640639599\nPerdida validación: 3.5773722529411316\nÉpoca 607\nPerdida entrenamiento: 0.09048281996869124\nPerdida validación: 3.2947387397289276\nÉpoca 608\nPerdida entrenamiento: 0.09159044520213054\nPerdida validación: 2.9430512189865112\nÉpoca 609\nPerdida entrenamiento: 0.08964369574991557\nPerdida validación: 3.3014421463012695\nÉpoca 610\nPerdida entrenamiento: 0.08908333887274449\nPerdida validación: 2.998455196619034\nÉpoca 611\nPerdida entrenamiento: 0.09090320049570157\nPerdida validación: 5.645829796791077\nÉpoca 612\nPerdida entrenamiento: 0.08766440416757877\nPerdida validación: 2.9032982736825943\nÉpoca 613\nPerdida entrenamiento: 0.08854922107779063\nPerdida validación: 3.060891628265381\nÉpoca 614\nPerdida entrenamiento: 0.08976021638283363\nPerdida validación: 3.0479705929756165\nÉpoca 615\nPerdida entrenamiento: 0.08961896913555953\nPerdida validación: 4.045959830284119\nÉpoca 616\nPerdida entrenamiento: 0.08848642328610787\nPerdida validación: 5.979500740766525\nÉpoca 617\nPerdida entrenamiento: 0.08795142374359645\nPerdida validación: 3.2142326831817627\nÉpoca 618\nPerdida entrenamiento: 0.08949532818335754\nPerdida validación: 3.4921406507492065\nÉpoca 619\nPerdida entrenamiento: 0.08757467159571555\nPerdida validación: 2.9816556125879288\nÉpoca 620\nPerdida entrenamiento: 0.0879586089688998\nPerdida validación: 3.0630840808153152\nÉpoca 621\nPerdida entrenamiento: 0.08634372141498786\nPerdida validación: 4.073459208011627\nÉpoca 622\nPerdida entrenamiento: 0.08796885366050097\nPerdida validación: 2.9151867516338825\nÉpoca 623\nPerdida entrenamiento: 0.08707575729260078\nPerdida validación: 3.223273813724518\nÉpoca 624\nPerdida entrenamiento: 0.08563883115465824\nPerdida validación: 3.0873585641384125\nÉpoca 625\nPerdida entrenamiento: 0.08584944187448575\nPerdida validación: 2.9525046534836292\nÉpoca 626\nPerdida entrenamiento: 0.08701738285330626\nPerdida validación: 3.099105030298233\nÉpoca 627\nPerdida entrenamiento: 0.08607068084753476\nPerdida validación: 5.73407855629921\nÉpoca 628\nPerdida entrenamiento: 0.08767787438745682\nPerdida validación: 2.8967090360820293\nÉpoca 629\nPerdida entrenamiento: 0.08825744960743648\nPerdida validación: 3.380082130432129\nÉpoca 630\nPerdida entrenamiento: 0.0873606692139919\nPerdida validación: 3.1084282398223877\nÉpoca 631\nPerdida entrenamiento: 0.08586964011192322\nPerdida validación: 3.7326546162366867\nÉpoca 632\nPerdida entrenamiento: 0.08663071577365582\nPerdida validación: 5.914897799491882\nÉpoca 633\nPerdida entrenamiento: 0.08718680790983714\nPerdida validación: 2.9612930342555046\nÉpoca 634\nPerdida entrenamiento: 0.085944925649808\nPerdida validación: 3.224094897508621\nÉpoca 635\nPerdida entrenamiento: 0.0844750301196025\nPerdida validación: 3.0974116921424866\nÉpoca 636\nPerdida entrenamiento: 0.08396346781116265\nPerdida validación: 3.4633867144584656\nÉpoca 637\nPerdida entrenamiento: 0.08545709831210282\nPerdida validación: 2.9578521959483624\nÉpoca 638\nPerdida entrenamiento: 0.08674065195597135\nPerdida validación: 2.949578620493412\nÉpoca 639\nPerdida entrenamiento: 0.08519237488508224\nPerdida validación: 3.2103909254074097\nÉpoca 640\nPerdida entrenamiento: 0.08840005414990279\nPerdida validación: 3.0627825558185577\nÉpoca 641\nPerdida entrenamiento: 0.0849433932453394\nPerdida validación: 3.172268331050873\nÉpoca 642\nPerdida entrenamiento: 0.08262179534022625\nPerdida validación: 3.236430197954178\nÉpoca 643\nPerdida entrenamiento: 0.08367389583816895\nPerdida validación: 2.942924888804555\nÉpoca 644\nPerdida entrenamiento: 0.08231127118835083\nPerdida validación: 3.27776700258255\nÉpoca 645\nPerdida entrenamiento: 0.08604721839611347\nPerdida validación: 2.9394181985408068\nÉpoca 646\nPerdida entrenamiento: 0.08392453394257106\nPerdida validación: 3.0016921162605286\nÉpoca 647\nPerdida entrenamiento: 0.08415115481385818\nPerdida validación: 3.1223526895046234\nÉpoca 648\nPerdida entrenamiento: 0.08276968549650449\nPerdida validación: 2.978962305933237\nÉpoca 649\nPerdida entrenamiento: 0.08537436477266826\nPerdida validación: 3.432997077703476\nÉpoca 650\nPerdida entrenamiento: 0.0837293887654176\nPerdida validación: 3.4656736850738525\nÉpoca 651\nPerdida entrenamiento: 0.08413175550790933\nPerdida validación: 3.3202735409140587\nÉpoca 652\nPerdida entrenamiento: 0.08189639592399964\nPerdida validación: 3.8872807025909424\nÉpoca 653\nPerdida entrenamiento: 0.08280348534194323\nPerdida validación: 6.082957550883293\nÉpoca 654\nPerdida entrenamiento: 0.08127718963302098\nPerdida validación: 3.207852452993393\nÉpoca 655\nPerdida entrenamiento: 0.08102134758463272\nPerdida validación: 3.252897948026657\nÉpoca 656\nPerdida entrenamiento: 0.08139984109080754\nPerdida validación: 2.9737558010965586\nÉpoca 657\nPerdida entrenamiento: 0.08038559813912098\nPerdida validación: 3.310336619615555\nÉpoca 658\nPerdida entrenamiento: 0.07984856028969471\nPerdida validación: 3.006955109536648\nÉpoca 659\nPerdida entrenamiento: 0.08055987037145175\nPerdida validación: 3.5304589942097664\nÉpoca 660\nPerdida entrenamiento: 0.08210009408111756\nPerdida validación: 3.9923764169216156\nÉpoca 661\nPerdida entrenamiento: 0.08106890879571438\nPerdida validación: 3.647656798362732\nÉpoca 662\nPerdida entrenamiento: 0.0803337491189058\nPerdida validación: 3.0062214881181717\nÉpoca 663\nPerdida entrenamiento: 0.08178974587756854\nPerdida validación: 3.8203519582748413\nÉpoca 664\nPerdida entrenamiento: 0.07993544179659623\nPerdida validación: 5.766702353954315\nÉpoca 665\nPerdida entrenamiento: 0.07951982949788754\nPerdida validación: 3.537745386362076\nÉpoca 666\nPerdida entrenamiento: 0.07966543834369916\nPerdida validación: 3.3440269827842712\nÉpoca 667\nPerdida entrenamiento: 0.07974013012762253\nPerdida validación: 3.4005532264709473\nÉpoca 668\nPerdida entrenamiento: 0.08048110283338107\nPerdida validación: 6.076398730278015\nÉpoca 669\nPerdida entrenamiento: 0.07910338760568546\nPerdida validación: 3.1290396749973297\nÉpoca 670\nPerdida entrenamiento: 0.07919158643254867\nPerdida validación: 3.0483686476945877\nÉpoca 671\nPerdida entrenamiento: 0.07788696125722848\nPerdida validación: 6.258003294467926\nÉpoca 672\nPerdida entrenamiento: 0.08138983582074825\nPerdida validación: 3.043996773660183\nÉpoca 673\nPerdida entrenamiento: 0.08381304632012661\nPerdida validación: 2.9912613732740283\nÉpoca 674\nPerdida entrenamiento: 0.08171401430781071\nPerdida validación: 3.2535914480686188\nÉpoca 675\nPerdida entrenamiento: 0.07973616025768794\nPerdida validación: 3.008113071322441\nÉpoca 676\nPerdida entrenamiento: 0.08049123103802021\nPerdida validación: 3.3409511744976044\nÉpoca 677\nPerdida entrenamiento: 0.0830245754466607\nPerdida validación: 6.382318615913391\nÉpoca 678\nPerdida entrenamiento: 0.0790841830177949\nPerdida validación: 3.5300813168287277\nÉpoca 679\nPerdida entrenamiento: 0.07988710758777764\nPerdida validación: 3.441707044839859\nÉpoca 680\nPerdida entrenamiento: 0.07954001054167747\nPerdida validación: 3.0263784900307655\nÉpoca 681\nPerdida entrenamiento: 0.08027764732161394\nPerdida validación: 3.698488086462021\nÉpoca 682\nPerdida entrenamiento: 0.07939692701284702\nPerdida validación: 6.145058274269104\nÉpoca 683\nPerdida entrenamiento: 0.07660764312514892\nPerdida validación: 4.3174373507499695\nÉpoca 684\nPerdida entrenamiento: 0.07766298620173565\nPerdida validación: 6.3749352395534515\nÉpoca 685\nPerdida entrenamiento: 0.07970923471909303\nPerdida validación: 4.056097626686096\nÉpoca 686\nPerdida entrenamiento: 0.07719844278807823\nPerdida validación: 3.051921732723713\nÉpoca 687\nPerdida entrenamiento: 0.0781680206553294\nPerdida validación: 3.4439048767089844\nÉpoca 688\nPerdida entrenamiento: 0.07667693667686902\nPerdida validación: 3.182342290878296\nÉpoca 689\nPerdida entrenamiento: 0.0783315381178489\nPerdida validación: 3.228578358888626\nÉpoca 690\nPerdida entrenamiento: 0.07471121217195804\nPerdida validación: 3.2710892260074615\nÉpoca 691\nPerdida entrenamiento: 0.07603253968633138\nPerdida validación: 3.523540109395981\nÉpoca 692\nPerdida entrenamiento: 0.07471496525865334\nPerdida validación: 3.411119043827057\nÉpoca 693\nPerdida entrenamiento: 0.0752135177071278\nPerdida validación: 3.4445889592170715\nÉpoca 694\nPerdida entrenamiento: 0.07611862613031498\nPerdida validación: 3.559295654296875\nÉpoca 695\nPerdida entrenamiento: 0.0759881936873381\nPerdida validación: 3.5824018120765686\nÉpoca 696\nPerdida entrenamiento: 0.07466840600738159\nPerdida validación: 3.9484466910362244\nÉpoca 697\nPerdida entrenamiento: 0.0735154255078389\nPerdida validación: 3.0945662409067154\nÉpoca 698\nPerdida entrenamiento: 0.07556946203112602\nPerdida validación: 3.3838585913181305\nÉpoca 699\nPerdida entrenamiento: 0.075852148521405\nPerdida validación: 3.9069823026657104\nÉpoca 700\nPerdida entrenamiento: 0.07505714750060669\nPerdida validación: 3.286153644323349\nÉpoca 701\nPerdida entrenamiento: 0.07513145830195683\nPerdida validación: 3.0753321163356304\nÉpoca 702\nPerdida entrenamiento: 0.07591709723839393\nPerdida validación: 3.383682131767273\nÉpoca 703\nPerdida entrenamiento: 0.07662103439752872\nPerdida validación: 6.287557303905487\nÉpoca 704\nPerdida entrenamiento: 0.074071651038069\nPerdida validación: 3.51538348197937\nÉpoca 705\nPerdida entrenamiento: 0.07326486592109387\nPerdida validación: 3.647996246814728\nÉpoca 706\nPerdida entrenamiento: 0.07368115650919768\nPerdida validación: 3.0932504013180733\nÉpoca 707\nPerdida entrenamiento: 0.0751225554312651\nPerdida validación: 5.895449340343475\nÉpoca 708\nPerdida entrenamiento: 0.07395617950421113\nPerdida validación: 5.860315516591072\nÉpoca 709\nPerdida entrenamiento: 0.07535010304015416\nPerdida validación: 3.0919011384248734\nÉpoca 710\nPerdida entrenamiento: 0.07465821561905053\nPerdida validación: 5.954198464751244\nÉpoca 711\nPerdida entrenamiento: 0.07308040587947918\nPerdida validación: 3.787451297044754\nÉpoca 712\nPerdida entrenamiento: 0.07293918241675083\nPerdida validación: 3.5140918493270874\nÉpoca 713\nPerdida entrenamiento: 0.07424381232032409\nPerdida validación: 3.5032528042793274\nÉpoca 714\nPerdida entrenamiento: 0.07196107234519261\nPerdida validación: 3.103741290047765\nÉpoca 715\nPerdida entrenamiento: 0.07321044630729236\nPerdida validación: 3.2048414945602417\nÉpoca 716\nPerdida entrenamiento: 0.07338270552169818\nPerdida validación: 3.4842203855514526\nÉpoca 717\nPerdida entrenamiento: 0.07320698207387558\nPerdida validación: 3.547133982181549\nÉpoca 718\nPerdida entrenamiento: 0.07335239849411525\nPerdida validación: 3.3462226688861847\nÉpoca 719\nPerdida entrenamiento: 0.07362754786243805\nPerdida validación: 3.0637363731259484\nÉpoca 720\nPerdida entrenamiento: 0.07329921933034292\nPerdida validación: 3.5014507174491882\nÉpoca 721\nPerdida entrenamiento: 0.07308094232128216\nPerdida validación: 3.600960463285446\nÉpoca 722\nPerdida entrenamiento: 0.07359824429910916\nPerdida validación: 3.6419607996940613\nÉpoca 723\nPerdida entrenamiento: 0.0702361033942837\nPerdida validación: 3.3048584163188934\nÉpoca 724\nPerdida entrenamiento: 0.07198195188091351\nPerdida validación: 3.635326474905014\nÉpoca 725\nPerdida entrenamiento: 0.07143456402879494\nPerdida validación: 3.1239943015389144\nÉpoca 726\nPerdida entrenamiento: 0.07296538524902783\nPerdida validación: 3.9761489629745483\nÉpoca 727\nPerdida entrenamiento: 0.06996076797636655\nPerdida validación: 3.673790752887726\nÉpoca 728\nPerdida entrenamiento: 0.07061829260335518\nPerdida validación: 3.527384489774704\nÉpoca 729\nPerdida entrenamiento: 0.07066990879292671\nPerdida validación: 3.565238893032074\nÉpoca 730\nPerdida entrenamiento: 0.06986354305767097\nPerdida validación: 3.1452227979898453\nÉpoca 731\nPerdida entrenamiento: 0.07251900878663246\nPerdida validación: 3.676050305366516\nÉpoca 732\nPerdida entrenamiento: 0.07029389106453611\nPerdida validación: 6.303750157356262\nÉpoca 733\nPerdida entrenamiento: 0.07063901882905227\nPerdida validación: 3.6955054998397827\nÉpoca 734\nPerdida entrenamiento: 0.07026771971812615\nPerdida validación: 3.6877950727939606\nÉpoca 735\nPerdida entrenamiento: 0.07010470860852645\nPerdida validación: 3.8105451464653015\nÉpoca 736\nPerdida entrenamiento: 0.07092373674878708\nPerdida validación: 6.272245496511459\nÉpoca 737\nPerdida entrenamiento: 0.06938746227667882\nPerdida validación: 4.11859667301178\nÉpoca 738\nPerdida entrenamiento: 0.07033284137455317\nPerdida validación: 3.489028960466385\nÉpoca 739\nPerdida entrenamiento: 0.07005046737881807\nPerdida validación: 3.9497650265693665\nÉpoca 740\nPerdida entrenamiento: 0.06991838477551937\nPerdida validación: 3.5906466245651245\nÉpoca 741\nPerdida entrenamiento: 0.07006746086363609\nPerdida validación: 4.010214567184448\nÉpoca 742\nPerdida entrenamiento: 0.06976071902765678\nPerdida validación: 3.903961181640625\nÉpoca 743\nPerdida entrenamiento: 0.07007302042956536\nPerdida validación: 3.373776465654373\nÉpoca 744\nPerdida entrenamiento: 0.06779414845200685\nPerdida validación: 3.4710806906223297\nÉpoca 745\nPerdida entrenamiento: 0.06950925863706149\nPerdida validación: 3.2723368108272552\nÉpoca 746\nPerdida entrenamiento: 0.06822979550522107\nPerdida validación: 3.880464196205139\nÉpoca 747\nPerdida entrenamiento: 0.06774935606293954\nPerdida validación: 4.389346688985825\nÉpoca 748\nPerdida entrenamiento: 0.06761566936396636\nPerdida validación: 3.15746596394456\nÉpoca 749\nPerdida entrenamiento: 0.06839605879325134\nPerdida validación: 3.3875818252563477\nÉpoca 750\nPerdida entrenamiento: 0.06772242185588066\nPerdida validación: 3.1746858982369304\nÉpoca 751\nPerdida entrenamiento: 0.06843308130135903\nPerdida validación: 3.2046142797917128\nÉpoca 752\nPerdida entrenamiento: 0.06832610113689533\nPerdida validación: 3.952906757593155\nÉpoca 753\nPerdida entrenamiento: 0.0690260434953066\nPerdida validación: 3.7516192197799683\nÉpoca 754\nPerdida entrenamiento: 0.06749802698882726\nPerdida validación: 3.1946978587657213\nÉpoca 755\nPerdida entrenamiento: 0.06692473447093597\nPerdida validación: 3.173951795324683\nÉpoca 756\nPerdida entrenamiento: 0.06698934733867645\nPerdida validación: 3.6998668909072876\nÉpoca 757\nPerdida entrenamiento: 0.06710446482667556\nPerdida validación: 6.106452941894531\nÉpoca 758\nPerdida entrenamiento: 0.06671396270394325\nPerdida validación: 3.59967178106308\nÉpoca 759\nPerdida entrenamiento: 0.0667688400986103\nPerdida validación: 4.006033331155777\nÉpoca 760\nPerdida entrenamiento: 0.06433771564983405\nPerdida validación: 9.396792531013489\nÉpoca 761\nPerdida entrenamiento: 0.0658060577339851\nPerdida validación: 3.6313920319080353\nÉpoca 762\nPerdida entrenamiento: 0.06626230678879298\nPerdida validación: 3.1925170212052763\nÉpoca 763\nPerdida entrenamiento: 0.06445745751261711\nPerdida validación: 3.2214292294811457\nÉpoca 764\nPerdida entrenamiento: 0.0656591676748716\nPerdida validación: 3.7026621997356415\nÉpoca 765\nPerdida entrenamiento: 0.06652211283261959\nPerdida validación: 4.019250392913818\nÉpoca 766\nPerdida entrenamiento: 0.0645568874449684\nPerdida validación: 3.2478851601481438\nÉpoca 767\nPerdida entrenamiento: 0.0645436357993346\nPerdida validación: 3.634760797023773\nÉpoca 768\nPerdida entrenamiento: 0.06626242198623143\nPerdida validación: 3.2138933995738626\nÉpoca 769\nPerdida entrenamiento: 0.06454834657219741\nPerdida validación: 3.4520061314105988\nÉpoca 770\nPerdida entrenamiento: 0.06424231254137479\nPerdida validación: 6.513358294963837\nÉpoca 771\nPerdida entrenamiento: 0.0674513099858394\nPerdida validación: 3.208299418911338\nÉpoca 772\nPerdida entrenamiento: 0.06449403012028107\nPerdida validación: 3.4559914767742157\nÉpoca 773\nPerdida entrenamiento: 0.06507012119086888\nPerdida validación: 3.4043886959552765\nÉpoca 774\nPerdida entrenamiento: 0.06500616096533261\nPerdida validación: 3.7424195408821106\nÉpoca 775\nPerdida entrenamiento: 0.06445603316219953\nPerdida validación: 3.2316817604005337\nÉpoca 776\nPerdida entrenamiento: 0.06395076867192984\nPerdida validación: 3.3793974220752716\nÉpoca 777\nPerdida entrenamiento: 0.06544297073896115\nPerdida validación: 3.6280748546123505\nÉpoca 778\nPerdida entrenamiento: 0.06932021118700504\nPerdida validación: 3.5138529241085052\nÉpoca 779\nPerdida entrenamiento: 0.07144579004782897\nPerdida validación: 3.281018428504467\nÉpoca 780\nPerdida entrenamiento: 0.06321389299745743\nPerdida validación: 4.2752964198589325\nÉpoca 781\nPerdida entrenamiento: 0.06387096292410906\nPerdida validación: 6.191157042980194\nÉpoca 782\nPerdida entrenamiento: 0.06328819821087214\nPerdida validación: 4.009998798370361\nÉpoca 783\nPerdida entrenamiento: 0.06345390198895565\nPerdida validación: 3.5408129692077637\nÉpoca 784\nPerdida entrenamiento: 0.06154564581811428\nPerdida validación: 3.728050410747528\nÉpoca 785\nPerdida entrenamiento: 0.06283387785347608\nPerdida validación: 3.271757125854492\nÉpoca 786\nPerdida entrenamiento: 0.06242528486137207\nPerdida validación: 3.5932647585868835\nÉpoca 787\nPerdida entrenamiento: 0.0626249214491019\nPerdida validación: 6.087800234556198\nÉpoca 788\nPerdida entrenamiento: 0.06314485878325425\nPerdida validación: 3.6031576097011566\nÉpoca 789\nPerdida entrenamiento: 0.0641820035301722\nPerdida validación: 3.6429638266563416\nÉpoca 790\nPerdida entrenamiento: 0.06248174120600407\nPerdida validación: 4.228351831436157\nÉpoca 791\nPerdida entrenamiento: 0.06177817901166586\nPerdida validación: 4.137951165437698\nÉpoca 792\nPerdida entrenamiento: 0.0609730864660098\nPerdida validación: 3.5382475554943085\nÉpoca 793\nPerdida entrenamiento: 0.0613269078043791\nPerdida validación: 3.2661752179265022\nÉpoca 794\nPerdida entrenamiento: 0.06030727149202274\nPerdida validación: 6.637757331132889\nÉpoca 795\nPerdida entrenamiento: 0.06137405077998455\nPerdida validación: 3.8624553084373474\nÉpoca 796\nPerdida entrenamiento: 0.0609011253198752\nPerdida validación: 3.3248483315110207\nÉpoca 797\nPerdida entrenamiento: 0.06208982662512706\nPerdida validación: 3.9522294402122498\nÉpoca 798\nPerdida entrenamiento: 0.060166037999666654\nPerdida validación: 3.2770682722330093\nÉpoca 799\nPerdida entrenamiento: 0.06056450558109926\nPerdida validación: 3.343050740659237\nÉpoca 800\nPerdida entrenamiento: 0.06177033111453056\nPerdida validación: 3.580229103565216\nÉpoca 801\nPerdida entrenamiento: 0.060246036746180974\nPerdida validación: 3.505081385374069\nÉpoca 802\nPerdida entrenamiento: 0.061356705326873526\nPerdida validación: 4.062293261289597\nÉpoca 803\nPerdida entrenamiento: 0.05942604003044275\nPerdida validación: 4.110773056745529\nÉpoca 804\nPerdida entrenamiento: 0.060502128245738834\nPerdida validación: 3.8822240233421326\nÉpoca 805\nPerdida entrenamiento: 0.05999588966369629\nPerdida validación: 6.7766527235507965\nÉpoca 806\nPerdida entrenamiento: 0.059047887495790534\nPerdida validación: 4.154969960451126\nÉpoca 807\nPerdida entrenamiento: 0.058758083587655656\nPerdida validación: 4.048469461500645\nÉpoca 808\nPerdida entrenamiento: 0.059343369104541265\nPerdida validación: 3.914748638868332\nÉpoca 809\nPerdida entrenamiento: 0.06124117999122693\nPerdida validación: 3.564255177974701\nÉpoca 810\nPerdida entrenamiento: 0.05879233297533714\nPerdida validación: 3.761751651763916\nÉpoca 811\nPerdida entrenamiento: 0.059525275316375956\nPerdida validación: 3.518033117055893\nÉpoca 812\nPerdida entrenamiento: 0.058720690986284844\nPerdida validación: 3.7310802340507507\nÉpoca 813\nPerdida entrenamiento: 0.059426360118847624\nPerdida validación: 3.907933384180069\nÉpoca 814\nPerdida entrenamiento: 0.05819435217059576\nPerdida validación: 3.6875914335250854\nÉpoca 815\nPerdida entrenamiento: 0.058877732748022445\nPerdida validación: 3.6664465963840485\nÉpoca 816\nPerdida entrenamiento: 0.05832370979568133\nPerdida validación: 3.8303341567516327\nÉpoca 817\nPerdida entrenamiento: 0.05997598550927181\nPerdida validación: 4.546199798583984\nÉpoca 818\nPerdida entrenamiento: 0.06107013658262216\nPerdida validación: 4.69145804643631\nÉpoca 819\nPerdida entrenamiento: 0.056150777981831476\nPerdida validación: 3.3038771846331656\nÉpoca 820\nPerdida entrenamiento: 0.058985657416857205\nPerdida validación: 3.8559694290161133\nÉpoca 821\nPerdida entrenamiento: 0.05928831898535673\nPerdida validación: 4.11640003323555\nÉpoca 822\nPerdida entrenamiento: 0.05734322563960002\nPerdida validación: 4.668489754199982\nÉpoca 823\nPerdida entrenamiento: 0.056264102745514646\nPerdida validación: 3.920742154121399\nÉpoca 824\nPerdida entrenamiento: 0.05873554816039709\nPerdida validación: 3.493961662054062\nÉpoca 825\nPerdida entrenamiento: 0.05683453810902742\nPerdida validación: 6.510374307632446\nÉpoca 826\nPerdida entrenamiento: 0.055070443222155936\nPerdida validación: 4.398071765899658\nÉpoca 827\nPerdida entrenamiento: 0.05675230762706353\nPerdida validación: 4.375220954418182\nÉpoca 828\nPerdida entrenamiento: 0.055023180607419744\nPerdida validación: 6.8428884744644165\nÉpoca 829\nPerdida entrenamiento: 0.05631783174780699\nPerdida validación: 4.441886872053146\nÉpoca 830\nPerdida entrenamiento: 0.05498757557227062\nPerdida validación: 4.170099914073944\nÉpoca 831\nPerdida entrenamiento: 0.05439775250852108\nPerdida validación: 4.17107766866684\nÉpoca 832\nPerdida entrenamiento: 0.05483622884807678\nPerdida validación: 4.0521272122859955\nÉpoca 833\nPerdida entrenamiento: 0.054396349363602124\nPerdida validación: 4.2378314435482025\nÉpoca 834\nPerdida entrenamiento: 0.0537837570389876\nPerdida validación: 6.800297603011131\nÉpoca 835\nPerdida entrenamiento: 0.05468137791523567\nPerdida validación: 4.214636117219925\nÉpoca 836\nPerdida entrenamiento: 0.05472402432217048\nPerdida validación: 4.283179759979248\nÉpoca 837\nPerdida entrenamiento: 0.054236042886399306\nPerdida validación: 4.970643877983093\nÉpoca 838\nPerdida entrenamiento: 0.053958216395515665\nPerdida validación: 4.149262264370918\nÉpoca 839\nPerdida entrenamiento: 0.05368467112286733\nPerdida validación: 4.775151491165161\nÉpoca 840\nPerdida entrenamiento: 0.05479082651436329\nPerdida validación: 4.5180723667144775\nÉpoca 841\nPerdida entrenamiento: 0.05527265548992615\nPerdida validación: 4.143805742263794\nÉpoca 842\nPerdida entrenamiento: 0.05225516497515715\nPerdida validación: 4.767333805561066\nÉpoca 843\nPerdida entrenamiento: 0.05295462655619933\nPerdida validación: 4.054084673523903\nÉpoca 844\nPerdida entrenamiento: 0.052490573591337755\nPerdida validación: 4.043152339756489\nÉpoca 845\nPerdida entrenamiento: 0.05167995869683532\nPerdida validación: 4.035788454610156\nÉpoca 846\nPerdida entrenamiento: 0.05253026355057955\nPerdida validación: 4.491959989070892\nÉpoca 847\nPerdida entrenamiento: 0.05272071479031673\nPerdida validación: 4.08733955770731\nÉpoca 848\nPerdida entrenamiento: 0.051107910461723804\nPerdida validación: 4.299175828695297\nÉpoca 849\nPerdida entrenamiento: 0.05270489319585837\nPerdida validación: 4.7589231133461\nÉpoca 850\nPerdida entrenamiento: 0.05218249845963258\nPerdida validación: 4.42910698056221\nÉpoca 851\nPerdida entrenamiento: 0.0517392076838475\nPerdida validación: 4.063683340325952\nÉpoca 852\nPerdida entrenamiento: 0.05056576960935043\nPerdida validación: 4.544508397579193\nÉpoca 853\nPerdida entrenamiento: 0.050385619298769876\nPerdida validación: 7.497417986392975\nÉpoca 854\nPerdida entrenamiento: 0.051967507729736656\nPerdida validación: 4.558947831392288\nÉpoca 855\nPerdida entrenamiento: 0.050523535993236765\nPerdida validación: 7.215233594179153\nÉpoca 856\nPerdida entrenamiento: 0.05060775463397686\nPerdida validación: 4.495422422885895\nÉpoca 857\nPerdida entrenamiento: 0.05093105721215789\nPerdida validación: 7.129923522472382\nÉpoca 858\nPerdida entrenamiento: 0.05117681049383604\nPerdida validación: 4.351238787174225\nÉpoca 859\nPerdida entrenamiento: 0.05049055363409794\nPerdida validación: 4.08912917599082\nÉpoca 860\nPerdida entrenamiento: 0.05090016857362711\nPerdida validación: 4.626007974147797\nÉpoca 861\nPerdida entrenamiento: 0.0504580932454421\nPerdida validación: 4.207754582166672\nÉpoca 862\nPerdida entrenamiento: 0.050872162414284855\nPerdida validación: 4.572880119085312\nÉpoca 863\nPerdida entrenamiento: 0.05100252135441853\nPerdida validación: 7.2558281272649765\nÉpoca 864\nPerdida entrenamiento: 0.04953286008766064\nPerdida validación: 4.496209770441055\nÉpoca 865\nPerdida entrenamiento: 0.05012407168172873\nPerdida validación: 4.0990868136286736\nÉpoca 866\nPerdida entrenamiento: 0.048918719618366316\nPerdida validación: 4.131444938480854\nÉpoca 867\nPerdida entrenamiento: 0.04928459671254341\nPerdida validación: 5.020654857158661\nÉpoca 868\nPerdida entrenamiento: 0.04903019620822026\nPerdida validación: 4.551450133323669\nÉpoca 869\nPerdida entrenamiento: 0.04945437524181146\nPerdida validación: 4.500010818243027\nÉpoca 870\nPerdida entrenamiento: 0.04856425581070093\nPerdida validación: 4.7949676513671875\nÉpoca 871\nPerdida entrenamiento: 0.04902963899075985\nPerdida validación: 7.995621174573898\nÉpoca 872\nPerdida entrenamiento: 0.04977420273308571\nPerdida validación: 7.18223363161087\nÉpoca 873\nPerdida entrenamiento: 0.04900971413231813\nPerdida validación: 5.231534659862518\nÉpoca 874\nPerdida entrenamiento: 0.049250427060402356\nPerdida validación: 4.179678939282894\nÉpoca 875\nPerdida entrenamiento: 0.048545404337346554\nPerdida validación: 7.5138179659843445\nÉpoca 876\nPerdida entrenamiento: 0.04902011091605975\nPerdida validación: 7.690000653266907\nÉpoca 877\nPerdida entrenamiento: 0.049634022459101215\nPerdida validación: 4.181770049035549\nÉpoca 878\nPerdida entrenamiento: 0.04979390636659586\nPerdida validación: 4.789144668728113\nÉpoca 879\nPerdida entrenamiento: 0.04782095207617833\nPerdida validación: 7.752316355705261\nÉpoca 880\nPerdida entrenamiento: 0.047524592480980433\nPerdida validación: 4.361296311020851\nÉpoca 881\nPerdida entrenamiento: 0.04772741806048613\nPerdida validación: 5.283886909484863\nÉpoca 882\nPerdida entrenamiento: 0.049345526414421886\nPerdida validación: 5.229241371154785\nÉpoca 883\nPerdida entrenamiento: 0.04679644315575178\nPerdida validación: 7.914421200752258\nÉpoca 884\nPerdida entrenamiento: 0.04703991981939627\nPerdida validación: 5.433315575122833\nÉpoca 885\nPerdida entrenamiento: 0.049513145278279595\nPerdida validación: 7.677872061729431\nÉpoca 886\nPerdida entrenamiento: 0.04793915123893665\nPerdida validación: 5.197003066539764\nÉpoca 887\nPerdida entrenamiento: 0.04776551424024197\nPerdida validación: 5.358761668205261\nÉpoca 888\nPerdida entrenamiento: 0.0485514304958857\nPerdida validación: 4.744048622378614\nÉpoca 889\nPerdida entrenamiento: 0.049604152114345476\nPerdida validación: 8.026496231555939\nÉpoca 890\nPerdida entrenamiento: 0.04807417854093588\nPerdida validación: 5.384512186050415\nÉpoca 891\nPerdida entrenamiento: 0.04864290915429592\nPerdida validación: 5.179917335510254\nÉpoca 892\nPerdida entrenamiento: 0.04812890613594881\nPerdida validación: 5.456477701663971\nÉpoca 893\nPerdida entrenamiento: 0.04833104031590315\nPerdida validación: 8.13897693157196\nÉpoca 894\nPerdida entrenamiento: 0.04785565258218692\nPerdida validación: 7.886135160923004\nÉpoca 895\nPerdida entrenamiento: 0.049369161805281274\nPerdida validación: 7.536204218864441\nÉpoca 896\nPerdida entrenamiento: 0.05050841332055055\nPerdida validación: 5.33561635017395\nÉpoca 897\nPerdida entrenamiento: 0.04976207891908976\nPerdida validación: 7.572638392448425\nÉpoca 898\nPerdida entrenamiento: 0.048271565626447015\nPerdida validación: 5.2607505321502686\nÉpoca 899\nPerdida entrenamiento: 0.0469307591422246\nPerdida validación: 4.9310347735881805\nÉpoca 900\nPerdida entrenamiento: 0.046212898853879705\nPerdida validación: 10.429802477359772\nÉpoca 901\nPerdida entrenamiento: 0.04607743311386842\nPerdida validación: 8.391501128673553\nÉpoca 902\nPerdida entrenamiento: 0.0450165058987645\nPerdida validación: 7.945931136608124\nÉpoca 903\nPerdida entrenamiento: 0.04573409936319177\nPerdida validación: 6.206254571676254\nÉpoca 904\nPerdida entrenamiento: 0.046273574662896305\nPerdida validación: 4.837220882647671\nÉpoca 905\nPerdida entrenamiento: 0.04536168943517483\nPerdida validación: 5.7693856954574585\nÉpoca 906\nPerdida entrenamiento: 0.04983616161804933\nPerdida validación: 4.874648252502084\nÉpoca 907\nPerdida entrenamiento: 0.048089443491055414\nPerdida validación: 4.867903176695108\nÉpoca 908\nPerdida entrenamiento: 0.04482537740841508\nPerdida validación: 5.361008048057556\nÉpoca 909\nPerdida entrenamiento: 0.04441759233864454\nPerdida validación: 8.161953628063202\nÉpoca 910\nPerdida entrenamiento: 0.04429550490413721\nPerdida validación: 5.4278759360313416\nÉpoca 911\nPerdida entrenamiento: 0.04375691038484757\nPerdida validación: 5.562376141548157\nÉpoca 912\nPerdida entrenamiento: 0.04385505602336847\nPerdida validación: 5.063310891389847\nÉpoca 913\nPerdida entrenamiento: 0.04419422715615768\nPerdida validación: 5.079816937446594\nÉpoca 914\nPerdida entrenamiento: 0.043570125833726846\nPerdida validación: 5.188879191875458\nÉpoca 915\nPerdida entrenamiento: 0.043833284853742674\nPerdida validación: 4.941752478480339\nÉpoca 916\nPerdida entrenamiento: 0.04390216339379549\nPerdida validación: 4.89091937802732\nÉpoca 917\nPerdida entrenamiento: 0.04507616391548744\nPerdida validación: 5.422266781330109\nÉpoca 918\nPerdida entrenamiento: 0.043265287119608656\nPerdida validación: 5.867627322673798\nÉpoca 919\nPerdida entrenamiento: 0.04298393084452702\nPerdida validación: 7.655619859695435\nÉpoca 920\nPerdida entrenamiento: 0.04295176403740278\nPerdida validación: 10.454034566879272\nÉpoca 921\nPerdida entrenamiento: 0.04356664985131759\nPerdida validación: 5.592731535434723\nÉpoca 922\nPerdida entrenamiento: 0.042768083369502656\nPerdida validación: 4.900315457955003\nÉpoca 923\nPerdida entrenamiento: 0.045229774326659165\nPerdida validación: 5.696951985359192\nÉpoca 924\nPerdida entrenamiento: 0.04300991954425207\nPerdida validación: 4.877590395510197\nÉpoca 925\nPerdida entrenamiento: 0.04320732837256331\nPerdida validación: 5.988415837287903\nÉpoca 926\nPerdida entrenamiento: 0.04337704124358984\nPerdida validación: 8.132118225097656\nÉpoca 927\nPerdida entrenamiento: 0.043636782381397024\nPerdida validación: 5.575676202774048\nÉpoca 928\nPerdida entrenamiento: 0.043071469435325034\nPerdida validación: 7.69149649143219\nÉpoca 929\nPerdida entrenamiento: 0.04279871220485522\nPerdida validación: 8.94551944732666\nÉpoca 930\nPerdida entrenamiento: 0.04158741343193329\nPerdida validación: 5.9363309144973755\nÉpoca 931\nPerdida entrenamiento: 0.042360139437592946\nPerdida validación: 5.669342577457428\nÉpoca 932\nPerdida entrenamiento: 0.04308424804073114\nPerdida validación: 7.684343189001083\nÉpoca 933\nPerdida entrenamiento: 0.042666685265990406\nPerdida validación: 11.007444053888321\nÉpoca 934\nPerdida entrenamiento: 0.04146604684109871\nPerdida validación: 5.555517554283142\nÉpoca 935\nPerdida entrenamiento: 0.04259964572982146\nPerdida validación: 5.175597250461578\nÉpoca 936\nPerdida entrenamiento: 0.04205227105949934\nPerdida validación: 5.40211808681488\nÉpoca 937\nPerdida entrenamiento: 0.04228109278931068\nPerdida validación: 6.1808552742004395\nÉpoca 938\nPerdida entrenamiento: 0.04311830536104166\nPerdida validación: 10.741185247898102\nÉpoca 939\nPerdida entrenamiento: 0.043163470637339815\nPerdida validación: 5.921260833740234\nÉpoca 940\nPerdida entrenamiento: 0.04055054041628654\nPerdida validación: 5.262785702943802\nÉpoca 941\nPerdida entrenamiento: 0.04157177903331243\nPerdida validación: 5.35451865196228\nÉpoca 942\nPerdida entrenamiento: 0.0415198694771299\nPerdida validación: 7.973495125770569\nÉpoca 943\nPerdida entrenamiento: 0.040533507314439006\nPerdida validación: 4.92364627122879\nÉpoca 944\nPerdida entrenamiento: 0.04062959207938267\nPerdida validación: 5.073706194758415\nÉpoca 945\nPerdida entrenamiento: 0.040624873067897097\nPerdida validación: 8.072493553161621\nÉpoca 946\nPerdida entrenamiento: 0.040667824447155\nPerdida validación: 5.12357422709465\nÉpoca 947\nPerdida entrenamiento: 0.04132207554693405\nPerdida validación: 4.931139972992241\nÉpoca 948\nPerdida entrenamiento: 0.041251580589092694\nPerdida validación: 6.213336825370789\nÉpoca 949\nPerdida entrenamiento: 0.03960881582819498\nPerdida validación: 5.1579442620277405\nÉpoca 950\nPerdida entrenamiento: 0.04065688083378168\nPerdida validación: 5.068708926439285\nÉpoca 951\nPerdida entrenamiento: 0.041666437370272785\nPerdida validación: 5.178554832935333\nÉpoca 952\nPerdida entrenamiento: 0.04248258535965131\nPerdida validación: 7.714734971523285\nÉpoca 953\nPerdida entrenamiento: 0.03928559345121567\nPerdida validación: 4.913980485871434\nÉpoca 954\nPerdida entrenamiento: 0.041722226314819776\nPerdida validación: 5.258084446191788\nÉpoca 955\nPerdida entrenamiento: 0.04159032173741322\nPerdida validación: 5.252501457929611\nÉpoca 956\nPerdida entrenamiento: 0.04170346489319435\nPerdida validación: 4.984535411000252\nÉpoca 957\nPerdida entrenamiento: 0.04048321252832046\nPerdida validación: 8.03850769996643\nÉpoca 958\nPerdida entrenamiento: 0.04004818967615183\nPerdida validación: 8.282288789749146\nÉpoca 959\nPerdida entrenamiento: 0.04017204476090578\nPerdida validación: 8.028823256492615\nÉpoca 960\nPerdida entrenamiento: 0.03906387448883974\nPerdida validación: 5.145549774169922\nÉpoca 961\nPerdida entrenamiento: 0.041092993978124395\nPerdida validación: 5.181346893310547\nÉpoca 962\nPerdida entrenamiento: 0.03917228444837607\nPerdida validación: 5.263754636049271\nÉpoca 963\nPerdida entrenamiento: 0.03960341867059469\nPerdida validación: 5.101293057203293\nÉpoca 964\nPerdida entrenamiento: 0.03922462800087837\nPerdida validación: 5.038782596588135\nÉpoca 965\nPerdida entrenamiento: 0.03790095942811324\nPerdida validación: 4.954838437348371\nÉpoca 966\nPerdida entrenamiento: 0.03930759118296779\nPerdida validación: 5.001334883272648\nÉpoca 967\nPerdida entrenamiento: 0.03813998795186098\nPerdida validación: 6.026365399360657\nÉpoca 968\nPerdida entrenamiento: 0.038181327283382416\nPerdida validación: 5.887161493301392\nÉpoca 969\nPerdida entrenamiento: 0.03895379753353504\nPerdida validación: 5.548644781112671\nÉpoca 970\nPerdida entrenamiento: 0.03912664047227456\nPerdida validación: 5.311693072319031\nÉpoca 971\nPerdida entrenamiento: 0.03870617698591489\nPerdida validación: 5.490020513534546\nÉpoca 972\nPerdida entrenamiento: 0.03748865955724166\nPerdida validación: 10.62033686041832\nÉpoca 973\nPerdida entrenamiento: 0.03864966748425594\nPerdida validación: 5.311264842748642\nÉpoca 974\nPerdida entrenamiento: 0.03776480472431733\nPerdida validación: 6.198935285210609\nÉpoca 975\nPerdida entrenamiento: 0.03823253541038586\nPerdida validación: 6.116997182369232\nÉpoca 976\nPerdida entrenamiento: 0.037811676756693766\nPerdida validación: 5.664330780506134\nÉpoca 977\nPerdida entrenamiento: 0.038681479170918465\nPerdida validación: 5.71380490064621\nÉpoca 978\nPerdida entrenamiento: 0.03898881017588652\nPerdida validación: 5.0552245527505875\nÉpoca 979\nPerdida entrenamiento: 0.0369387546984049\nPerdida validación: 5.013122085481882\nÉpoca 980\nPerdida entrenamiento: 0.03696431670911037\nPerdida validación: 5.435646593570709\nÉpoca 981\nPerdida entrenamiento: 0.0377054988191678\nPerdida validación: 7.99576997756958\nÉpoca 982\nPerdida entrenamiento: 0.03688380738290457\nPerdida validación: 5.6264747977256775\nÉpoca 983\nPerdida entrenamiento: 0.03905959971822225\nPerdida validación: 5.130975678563118\nÉpoca 984\nPerdida entrenamiento: 0.03906594059215142\nPerdida validación: 5.282015740871429\nÉpoca 985\nPerdida entrenamiento: 0.040465183269519076\nPerdida validación: 5.062030218541622\nÉpoca 986\nPerdida entrenamiento: 0.039131697912055716\nPerdida validación: 5.825139343738556\nÉpoca 987\nPerdida entrenamiento: 0.03985199138808709\nPerdida validación: 4.996991615742445\nÉpoca 988\nPerdida entrenamiento: 0.03810182027518749\nPerdida validación: 5.061925791203976\nÉpoca 989\nPerdida entrenamiento: 0.03756197885825084\nPerdida validación: 6.193111687898636\nÉpoca 990\nPerdida entrenamiento: 0.037496679104291476\nPerdida validación: 5.766824841499329\nÉpoca 991\nPerdida entrenamiento: 0.037181258703080505\nPerdida validación: 5.420461535453796\nÉpoca 992\nPerdida entrenamiento: 0.03704871022357391\nPerdida validación: 8.288544058799744\nÉpoca 993\nPerdida entrenamiento: 0.03609542168963414\nPerdida validación: 5.090890198945999\nÉpoca 994\nPerdida entrenamiento: 0.03537790541752027\nPerdida validación: 7.8367608189582825\nÉpoca 995\nPerdida entrenamiento: 0.036478488777692504\nPerdida validación: 8.35268884897232\nÉpoca 996\nPerdida entrenamiento: 0.03573003110404198\nPerdida validación: 8.260665535926819\nÉpoca 997\nPerdida entrenamiento: 0.0378370895408667\nPerdida validación: 5.0253689478267916\nÉpoca 998\nPerdida entrenamiento: 0.03472784552006768\nPerdida validación: 7.795221388339996\nÉpoca 999\nPerdida entrenamiento: 0.035625782007208236\nPerdida validación: 5.025393606225407\nÉpoca 1000\nPerdida entrenamiento: 0.034889969401634656\nPerdida validación: 6.157822489738464\n\n\nComo se puede observar la pérdida de validación empieza a ser mucho mayor que la pérdida de entrenamiento, esto es un claro indicador de Overfitting"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_sol1_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\ndata = pd.read_csv(\"../../data/diabetes.csv\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#create-neural-network-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network data",
    "text": "Create neural network data"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model"
  },
  {
    "objectID": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/preparing_slides_002.html",
    "href": "codigo/preparing_slides_002.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport cv2\n\n\ndef generate_striped_image(N, M, K, orientation=\"vertical\"):\n    \"\"\"\n    Genera una imagen de N×M pixeles con bandas alternas (blanco/negro)\n    de ancho K, en orientación vertical u horizontal.\n\n    Parámetros\n    ----------\n    N : int\n        Altura de la imagen en pixeles.\n    M : int\n        Anchura de la imagen en pixeles.\n    K : int\n        Ancho de cada banda en pixeles.\n    orientation : {'vertical', 'horizontal'}\n        Orientación de las bandas. 'vertical' crea franjas verticales;\n        'horizontal' crea franjas horizontales.\n\n    Devuelve\n    -------\n    img : np.ndarray\n        Imagen en escala de grises (dtype uint8) con valores 0 o 255.\n    \"\"\"\n    # Crear imagen en negro\n    img = np.zeros((N, M), dtype=np.uint8)\n\n    # Alternar franjas\n    if orientation == \"vertical\":\n        for start in range(0, M, K):\n            # Determinar color de la franja (0 o 255)\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[:, start : start + K] = color\n\n    elif orientation == \"horizontal\":\n        for start in range(0, N, K):\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[start : start + K, :] = color\n\n    else:\n        raise ValueError(\"orientation debe ser 'vertical' o 'horizontal'\")\n\n    return img\n\n\nif __name__ == \"__main__\":\n    # Parámetros de ejemplo\n    altura = 400  # N\n    anchura = 400  # M\n    ancho_banda = 50  # K\n\n    # Generar imagen con franjas verticales\n    img_vertical = generate_striped_image(\n        altura, anchura, ancho_banda, orientation=\"vertical\"\n    )\n    cv2.imwrite(\"stripes_vertical.png\", img_vertical)\n    print(\"Guardado stripes_vertical.png\")\n\n    # Generar imagen con franjas horizontales\n    img_horizontal = generate_striped_image(\n        altura, anchura, ancho_banda, orientation=\"horizontal\"\n    )\n    cv2.imwrite(\"stripes_horizontal.png\", img_horizontal)\n    print(\"Guardado stripes_horizontal.png\")\n\nGuardado stripes_vertical.png\nGuardado stripes_horizontal.png\n\n\n\nimport numpy as np\nimport cv2\n\n\ndef generate_pattern_image(N, M, K, pattern=\"vertical\"):\n    \"\"\"\n    Genera una imagen de N×M píxeles con:\n      - 'vertical': franjas verticales de ancho K\n      - 'horizontal': franjas horizontales de alto K\n      - 'squares': cuadrados alternos de tamaño K×K (patrón ajedrez)\n\n    Parámetros\n    ----------\n    N : int\n        Altura de la imagen en píxeles.\n    M : int\n        Anchura de la imagen en píxeles.\n    K : int\n        Dimensión de la franja o del cuadrado en píxeles.\n    pattern : {'vertical', 'horizontal', 'squares'}\n        Tipo de patrón a generar.\n\n    Devuelve\n    -------\n    img : np.ndarray\n        Imagen en escala de grises (dtype uint8) con valores 0 o 255.\n    \"\"\"\n    img = np.zeros((N, M), dtype=np.uint8)\n\n    if pattern == \"vertical\":\n        for start in range(0, M, K):\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[:, start : start + K] = color\n\n    elif pattern == \"horizontal\":\n        for start in range(0, N, K):\n            color = 255 if ((start // K) % 2) == 0 else 0\n            img[start : start + K, :] = color\n\n    elif pattern == \"squares\":\n        for i in range(0, N, K):\n            for j in range(0, M, K):\n                # alterna color en función de la suma de índices de bloque\n                color = 255 if (((i // K) + (j // K)) % 2) == 0 else 0\n                img[i : i + K, j : j + K] = color\n\n    else:\n        raise ValueError(\"pattern debe ser 'vertical', 'horizontal' o 'squares'\")\n\n    return img\n\n\nif __name__ == \"__main__\":\n    # Parámetros de ejemplo\n    altura = 400  # N\n    anchura = 600  # M\n    K = 50  # tamaño de banda o cuadrado\n\n    # Generar y guardar cada patrón\n    for pat in [\"vertical\", \"horizontal\", \"squares\"]:\n        img = generate_pattern_image(altura, anchura, K, pattern=pat)\n        filename = f\"pattern_{pat}.png\"\n        cv2.imwrite(filename, img)\n        print(f\"Guardado {filename}\")\n\nGuardado pattern_vertical.png\nGuardado pattern_horizontal.png\nGuardado pattern_squares.png\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a periodic discrete signal\nN = 8  # Period of the signal\nn = np.arange(N)\nx_n = np.array([1, 2, 3, 4, 3, 2, 1, 0])  # Example discrete signal\n\n# Compute DTFS coefficients\nC_k = np.fft.fft(x_n) / N  # Normalized Discrete Fourier Transform\n\n# Reconstruct the signal using DTFS\nx_reconstructed = np.zeros(N, dtype=complex)\nfor k in range(N):\n    x_reconstructed += C_k[k] * np.exp(1j * 2 * np.pi * k * n / N)\n\n# Plot original and reconstructed signals\nplt.figure(figsize=(10, 4))\nplt.stem(n, x_n, linefmt='b-', markerfmt='bo', basefmt='r-', label='Original Signal')\nplt.stem(n, np.real(x_reconstructed), linefmt='r--', markerfmt='go', basefmt='r-', label='Reconstructed Signal')\nplt.xlabel(\"n\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"DTFS: Original vs Reconstructed Signal\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Print DTFS Coefficients\nprint(\"DTFS Coefficients:\")\nfor k in range(N):\n    print(f\"C[{k}] = {C_k[k]:.4f}\")\n\n\n\n\n\n\n\n\nDTFS Coefficients:\nC[0] = 2.0000+0.0000j\nC[1] = -0.6036-0.6036j\nC[2] = 0.0000+0.0000j\nC[3] = 0.1036-0.1036j\nC[4] = 0.0000+0.0000j\nC[5] = 0.1036+0.1036j\nC[6] = 0.0000+0.0000j\nC[7] = -0.6036+0.6036j\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a periodic discrete signal\nN = 8  # Period of the signal\nn = np.arange(N)\nx_n = np.array([1, 2, 3, 4, 3, 2, 1, 0])  # Example discrete signal\n\n# Compute DTFS coefficients\nC_k = np.fft.fft(x_n) / N  # Normalized Discrete Fourier Transform\n\n# Verify periodicity property: C[k] repeats every N\nC_k_extended = np.tile(C_k, 2)  # Extend coefficients to see repetition\nk_extended = np.arange(2 * N)\n\n# Plot DTFS coefficients and their periodic repetition\nplt.figure(figsize=(10, 4))\nplt.stem(\n    k_extended,\n    np.real(C_k_extended),\n    linefmt=\"b-\",\n    markerfmt=\"bo\",\n    basefmt=\"r-\",\n    label=\"Real Part\",\n)\nplt.stem(\n    k_extended,\n    np.imag(C_k_extended),\n    linefmt=\"g--\",\n    markerfmt=\"go\",\n    basefmt=\"r-\",\n    label=\"Imaginary Part\",\n)\nplt.xlabel(\"n\")\nplt.ylabel(\"Magnitude\")\nplt.title(\"DTFS Periodicity: Coefficients Repeat Every N Samples\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Print DTFS Coefficients to observe periodicity\nprint(\"DTFS Coefficients (showing periodicity):\")\nfor k in range(2 * N):\n    print(f\"C[{k}] = {C_k_extended[k]:.4f}\")\n\n\n\n\n\n\n\n\nDTFS Coefficients (showing periodicity):\nC[0] = 2.0000+0.0000j\nC[1] = -0.6036-0.6036j\nC[2] = 0.0000+0.0000j\nC[3] = 0.1036-0.1036j\nC[4] = 0.0000+0.0000j\nC[5] = 0.1036+0.1036j\nC[6] = 0.0000+0.0000j\nC[7] = -0.6036+0.6036j\nC[8] = 2.0000+0.0000j\nC[9] = -0.6036-0.6036j\nC[10] = 0.0000+0.0000j\nC[11] = 0.1036-0.1036j\nC[12] = 0.0000+0.0000j\nC[13] = 0.1036+0.1036j\nC[14] = 0.0000+0.0000j\nC[15] = -0.6036+0.6036j\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros\nfs_cont = 5000  # Frecuencia de muestreo \"continua\" (muy alta)\nfs_sampled = 1000  # Frecuencia de muestreo baja\nT = 1  # Duración de la señal en segundos\nf_signal = 30  # Frecuencia de la señal\n\n# Señal continua\nt_cont = np.linspace(0, T, fs_cont * T, endpoint=False)\nsignal_cont = np.sin(2 * np.pi * f_signal * t_cont)\n\n# Señal muestreada\nt_sampled = np.linspace(0, T, fs_sampled * T, endpoint=False)\nsignal_sampled = np.sin(2 * np.pi * f_signal * t_sampled)\n\n# FFT continua\nfft_cont = np.fft.fft(signal_cont)\nfreqs_cont = np.fft.fftfreq(len(signal_cont), d=1 / fs_cont)\n\n# FFT muestreada\nfft_sampled = np.fft.fft(signal_sampled)\nfreqs_sampled = np.fft.fftfreq(len(signal_sampled), d=1 / fs_sampled)\n\n# Graficar espectro original y espectro muestreado\nplt.figure(figsize=(12, 6))\n\nplt.subplot(3, 1, 1)\nplt.plot(\n    t_cont, signal_cont\n)\nplt.subplot(3, 1, 2)\nplt.plot(\n    freqs_cont[: len(freqs_cont) // 2],\n    np.abs(fft_cont[: len(freqs_cont) // 2]),\n    label=\"Espectro original\",\n)\nplt.title(\"Espectro de la señal continua\")\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.legend()\n\nplt.subplot(3, 1, 3)\nplt.plot(\n    freqs_sampled[: len(freqs_sampled) // 2],\n    np.abs(fft_sampled[: len(freqs_sampled) // 2]),\n    label=\"Espectro muestreado\",\n)\nplt.title(\"Espectro después del muestreo (repeticiones cada f_s)\")\nplt.xlabel(\"Frecuencia (Hz)\")\nplt.ylabel(\"Magnitud\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import tf2zpk\n\n# Define numerator (zeros) and denominator (poles) coefficients of the transfer function\n# Example: H(z) = (1 - 0.5z^-1) / (1 - 0.9z^-1)\nb = [1, -0.5]  # Numerator coefficients (zeros)\na = [1, -0.9]  # Denominator coefficients (poles)\n\n# Get zeros, poles, and gain\nz, p, k = tf2zpk(b, a)\n\n# Plot settings\nfig, ax = plt.subplots()\nax.set_title(\"Pole-Zero Plot in the Z-Plane\")\n\n# Draw unit circle\nunit_circle = plt.Circle((0, 0), 1, color=\"black\", fill=False, linestyle=\"dashed\")\nax.add_artist(unit_circle)\n\n# Plot zeros and poles\nax.plot(np.real(z), np.imag(z), \"go\", label=\"Zeros\")  # green circles\nax.plot(np.real(p), np.imag(p), \"rx\", label=\"Poles\")  # red Xs\n\n# Axes and formatting\nax.set_xlabel(\"Re\")\nax.set_ylabel(\"Im\")\nax.axhline(0, color=\"gray\", linewidth=0.5)\nax.axvline(0, color=\"gray\", linewidth=0.5)\nax.set_aspect(\"equal\")\nax.grid(True, linestyle=\"--\", alpha=0.5)\nax.legend()\nax.set_xlim(-1.5, 1.5)\nax.set_ylim(-1.5, 1.5)\n\nplt.show()\n\n\n\n\n\n\n\n\n\ndef zpk_to_latex(z, p, k):\n    def format_factor(value):\n        sign = \"+\" if np.real(value) &lt; 0 else \"-\"\n        return f\"(z {sign} {abs(np.real(value)):.2f})\"\n\n    num = \" \".join([format_factor(zero) for zero in z]) if len(z) &gt; 0 else \"1\"\n    den = \" \".join([format_factor(pole) for pole in p]) if len(p) &gt; 0 else \"1\"\n\n    latex_str = r\"H(z) = \" + f\"{k:.2f} \\\\cdot \\\\frac{{{num}}}{{{den}}}\"\n    return latex_str\n\n\nzpk_to_latex(z,p,k)\n\n'H(z) = 1.00 \\\\cdot \\\\frac{(z - 0.50)}{(z - 0.90)}'"
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Al finalizar, el estudiante será capaz de:\n1. Explicar la relación entre la profundidad de bit \\(b\\), los niveles representables \\(L=2^{b}\\) y el paso de cuantización \\(\\Delta\\) en una imagen digital.\n2. Adquirir y documentar imágenes bajo condiciones controladas para analizar rango dinámico, histogramas y artefactos de cuantización (banding, posterización).\n3. Convertir imágenes RGB a espacios HSV, CIE L*a*b* y Y’CrCb (formato OpenCV) e interpretar la semántica de canales e histogramas.\n4. Cuantizar imágenes a distintas profundidades de bit y evaluar distorsión con \\(\\mathrm{MSE}\\); discutir perceptualmente los cambios.\n5. Justificar la elección de espacio de color según la tarea (robustez a iluminación, segmentación, compresión) con evidencia cualitativa y cuantitativa.\n\n\n\n\n\nCuantización. Para una señal \\(x\\in[X_{\\min},X_{\\max}]\\), la cuantización uniforme escalar con \\(b\\) bits tiene \\(L=2^{b}\\) niveles y paso \\(\\Delta=\\dfrac{X_{\\max}-X_{\\min}}{L}\\). El error de cuantización \\(e=x-\\hat{x}\\in[-\\Delta/2,\\Delta/2]\\) (mid-tread).\nRango dinámico. En \\(b\\) bits sin signo: \\([0,\\,2^{b}-1]\\) (en 8 bits: \\([0,255]\\)).\nEspacios de color (OpenCV).\n\nBGR (lectura por defecto en OpenCV).\n\nHSV: cv2.COLOR_BGR2HSV (H en [0,179] para uint8).\n\nLab: cv2.COLOR_BGR2LAB (uint8: \\(L^\\*\\in[0,255]\\), \\(a^\\*,b^\\*\\approx[0,255]\\) con 128 ≈ neutro).\n\nYCrCb: cv2.COLOR_BGR2YCrCb (orden de cromas: Y, Cr, Cb).\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nOpenCV trabaja en BGR (no RGB) cuando lee/escribe imágenes con cv2.imread y cv2.imwrite. Para mostrar correctamente en archivos guardados, no es necesario convertir a RGB; sin embargo, documente siempre el orden de canales.\n\n\n\n\n\n\n\n\nCámara de teléfono u ordenador. Fijar ISO, tiempo de exposición y balance de blancos. Preferir PNG/TIFF (sin pérdidas); si es posible, capturar RAW+JPEG.\nEscena estática con colores saturados y neutros (p. ej., cuadrícula de color y rampa en escala de grises en un monitor). Iluminación difusa y estable.\nPython 3.12 con: opencv-python y numpy. No use otras librerías de imagen/visualización.\n\n\n\n\n\n\nMontaje de escena (iluminación constante). Fondo neutro; evitar brillos especulares.\n\nConjunto A (referencia, 8 bits sin pérdidas). Guardar una imagen nítida y bien expuesta en PNG/TIFF.\n\nConjunto B (bracketing de exposición). ±1 y ±2 EV respecto a la referencia para discutir recorte (clipping) vs. cuantización.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nMantenga fijos los parámetros de cámara entre capturas. Cambios en ISO o WB confunden los análisis de profundidad de bit y espacio de color.\n\n\n\n\n\n\n\nCargar la imagen de referencia. Inspeccionar forma, dtype, mínimos/máximos usando únicamente OpenCV.\n\nEstimar el uso efectivo de bits contando valores distintos por canal.\nCuente cuantos pixeles hay, por cada canal y nivel del canal\n\n\n\n\n\n-Explique que es el error cuadrático medio (MSE, por sus siglas en inglés) y la relación señal a rudio pico (PSNR, por sus siglas en inglés), Cuantice la imagen BGR de referencia a \\(b\\in\\{1,2,\\dots,7\\}\\) bits (por canal). Para cada \\(b\\):\n\nCalcule \\(\\mathrm{MSE}\\) y \\(\\mathrm{PSNR}\\) respecto a la referencia ($b=8).\nGenere y guarde la imagen cuantizada y un mapa de error visual (colormap).\n\n\n\n\n\n\nConvertir la imagen de referencia a HSV, Lab y YCrCb (OpenCV).\n\nCuantizar solo un canal a \\(b\\in\\{2,4\\}\\) (mantener los otros en 8 bits), revertir a BGR y guardar resultados.\n\nComparar perceptualmente artefactos entre cuantizar luminancia (Y) y crominancias (Cr/Cb), y entre canales de HSV/Lab.\n\n\n\n\n\n\nInforme Latex (PDF) con:\n\nProtocolo de adquisición, metadatos y fotos de la escena.\n\nResultados de Actividades 1–3 (figuras, histogramas, tablas).\n\nTabla que resuma qué espacio/canal soporta mayor cuantización con artefactos mínimos (justifique).\n\nTabla con MSE vs. \\(b\\) (sin PSNR).\n\n\nCarpeta reproducible con código e imágenes originales (preferir PNG/TIFF).\n\n\n\n\n\nFormato: 10 minutos de presentación + 2–3 minutos de preguntas. Puntuación total: 100 puntos.\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPeso\nExcelente (A) (7puntos)\nBueno (B) (5puntos)\nA mejorar (C) (3puntos)\nInsuficiente (D/E) (0puntos)\n\n\n\n\nEstructura y narrativa\n15\nObjetivo, método y resultados se articulan con coherencia; introducción y cierre precisos en tiempo.\nSecuencia mayormente clara con leves transiciones débiles.\nOrden irregular; faltan transiciones clave.\nDesorganizada; propósito no se comprende.\n\n\nRigor técnico\n25\nDefiniciones y ecuaciones (\\(L=2^{b}\\), \\(\\Delta\\), \\(\\mathrm{MSE}\\)) correctas; supuestos declarados y validados.\nMenores imprecisiones sin afectar conclusiones.\nVarias imprecisiones o supuestos no justificados.\nErrores conceptuales graves o confusión sostenida.\n\n\nMetodología y adquisición\n15\nParámetros de cámara controlados; protocolo replicable; evidencia fotográfica clara.\nControl adecuado con una omisión menor.\nControl parcial; documentación incompleta.\nSin control de variables; documentación escasa.\n\n\nAnálisis y resultados\n20\nComparaciones entre espacios (HSV/Lab/YCrCb) con figuras pertinentes; conclusiones sustentadas.\nAnálisis correcto pero poco profundo o con pocas figuras.\nAnálisis superficial; conclusiones poco justificadas.\nSin análisis; afirmaciones sin evidencia.\n\n\nVisualización\n10\nFiguras legibles, ejes/leyendas correctas (en imágenes generadas con OpenCV); mapas de error bien presentados.\nVisualización adecuada con detalles mejorables.\nGráficos confusos o mal rotulados.\nVisualizaciones ausentes o incorrectas.\n\n\nGestión del tiempo\n10\nCulmina en 9–10 min; distribuye tiempo equilibradamente.\nLeve desviación (±1 min).\nDesviación moderada (±2 min).\nDesviación severa (&gt;±2 min) o no concluye.\n\n\nClaridad y comunicación\n5\nLenguaje técnico claro, voz y ritmo adecuados, contacto visual.\nGeneralmente claro con momentos de ambigüedad.\nDificultades frecuentes de expresión.\nIncomprensible o lectura de diapositivas.\n\n\n\nRecomendaciones de preparación (no evaluadas, pero sugeridas):\n- Ensayar con cronómetro (marcas en 3–6–9 min).\n- Limitar texto por diapositiva; priorizar comparativas claras (antes/después, por espacio y por \\(b\\)).\n- Anticipar dos preguntas técnicas (supuestos y limitaciones)."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#resultados-de-aprendizaje",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#resultados-de-aprendizaje",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Al finalizar, el estudiante será capaz de:\n1. Explicar la relación entre la profundidad de bit \\(b\\), los niveles representables \\(L=2^{b}\\) y el paso de cuantización \\(\\Delta\\) en una imagen digital.\n2. Adquirir y documentar imágenes bajo condiciones controladas para analizar rango dinámico, histogramas y artefactos de cuantización (banding, posterización).\n3. Convertir imágenes RGB a espacios HSV, CIE L*a*b* y Y’CrCb (formato OpenCV) e interpretar la semántica de canales e histogramas.\n4. Cuantizar imágenes a distintas profundidades de bit y evaluar distorsión con \\(\\mathrm{MSE}\\); discutir perceptualmente los cambios.\n5. Justificar la elección de espacio de color según la tarea (robustez a iluminación, segmentación, compresión) con evidencia cualitativa y cuantitativa."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#conceptos-clave-conciso",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#conceptos-clave-conciso",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Cuantización. Para una señal \\(x\\in[X_{\\min},X_{\\max}]\\), la cuantización uniforme escalar con \\(b\\) bits tiene \\(L=2^{b}\\) niveles y paso \\(\\Delta=\\dfrac{X_{\\max}-X_{\\min}}{L}\\). El error de cuantización \\(e=x-\\hat{x}\\in[-\\Delta/2,\\Delta/2]\\) (mid-tread).\nRango dinámico. En \\(b\\) bits sin signo: \\([0,\\,2^{b}-1]\\) (en 8 bits: \\([0,255]\\)).\nEspacios de color (OpenCV).\n\nBGR (lectura por defecto en OpenCV).\n\nHSV: cv2.COLOR_BGR2HSV (H en [0,179] para uint8).\n\nLab: cv2.COLOR_BGR2LAB (uint8: \\(L^\\*\\in[0,255]\\), \\(a^\\*,b^\\*\\approx[0,255]\\) con 128 ≈ neutro).\n\nYCrCb: cv2.COLOR_BGR2YCrCb (orden de cromas: Y, Cr, Cb).\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nOpenCV trabaja en BGR (no RGB) cuando lee/escribe imágenes con cv2.imread y cv2.imwrite. Para mostrar correctamente en archivos guardados, no es necesario convertir a RGB; sin embargo, documente siempre el orden de canales."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#materiales",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#materiales",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Cámara de teléfono u ordenador. Fijar ISO, tiempo de exposición y balance de blancos. Preferir PNG/TIFF (sin pérdidas); si es posible, capturar RAW+JPEG.\nEscena estática con colores saturados y neutros (p. ej., cuadrícula de color y rampa en escala de grises en un monitor). Iluminación difusa y estable.\nPython 3.12 con: opencv-python y numpy. No use otras librerías de imagen/visualización."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#protocolo-de-adquisición-documentar-en-el-informe",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#protocolo-de-adquisición-documentar-en-el-informe",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Montaje de escena (iluminación constante). Fondo neutro; evitar brillos especulares.\n\nConjunto A (referencia, 8 bits sin pérdidas). Guardar una imagen nítida y bien expuesta en PNG/TIFF.\n\nConjunto B (bracketing de exposición). ±1 y ±2 EV respecto a la referencia para discutir recorte (clipping) vs. cuantización.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nMantenga fijos los parámetros de cámara entre capturas. Cambios en ISO o WB confunden los análisis de profundidad de bit y espacio de color."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-1-exploración-inicial-y-chequeos",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-1-exploración-inicial-y-chequeos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Cargar la imagen de referencia. Inspeccionar forma, dtype, mínimos/máximos usando únicamente OpenCV.\n\nEstimar el uso efectivo de bits contando valores distintos por canal.\nCuente cuantos pixeles hay, por cada canal y nivel del canal"
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-2-reducción-de-profundidad-de-bit-y-calidad-mse",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-2-reducción-de-profundidad-de-bit-y-calidad-mse",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "-Explique que es el error cuadrático medio (MSE, por sus siglas en inglés) y la relación señal a rudio pico (PSNR, por sus siglas en inglés), Cuantice la imagen BGR de referencia a \\(b\\in\\{1,2,\\dots,7\\}\\) bits (por canal). Para cada \\(b\\):\n\nCalcule \\(\\mathrm{MSE}\\) y \\(\\mathrm{PSNR}\\) respecto a la referencia ($b=8).\nGenere y guarde la imagen cuantizada y un mapa de error visual (colormap)."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-3-transformaciones-de-espacio-de-color-y-semántica-de-canales",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#actividad-3-transformaciones-de-espacio-de-color-y-semántica-de-canales",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Convertir la imagen de referencia a HSV, Lab y YCrCb (OpenCV).\n\nCuantizar solo un canal a \\(b\\in\\{2,4\\}\\) (mantener los otros en 8 bits), revertir a BGR y guardar resultados.\n\nComparar perceptualmente artefactos entre cuantizar luminancia (Y) y crominancias (Cr/Cb), y entre canales de HSV/Lab."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#entregables",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#entregables",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Informe Latex (PDF) con:\n\nProtocolo de adquisición, metadatos y fotos de la escena.\n\nResultados de Actividades 1–3 (figuras, histogramas, tablas).\n\nTabla que resuma qué espacio/canal soporta mayor cuantización con artefactos mínimos (justifique).\n\nTabla con MSE vs. \\(b\\) (sin PSNR).\n\n\nCarpeta reproducible con código e imágenes originales (preferir PNG/TIFF)."
  },
  {
    "objectID": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#rúbrica-de-evaluación-para-exposiciones-orales-10-minutos",
    "href": "laboratorios/PSIM/lab002_adquisicion_bit_color.html#rúbrica-de-evaluación-para-exposiciones-orales-10-minutos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "Formato: 10 minutos de presentación + 2–3 minutos de preguntas. Puntuación total: 100 puntos.\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPeso\nExcelente (A) (7puntos)\nBueno (B) (5puntos)\nA mejorar (C) (3puntos)\nInsuficiente (D/E) (0puntos)\n\n\n\n\nEstructura y narrativa\n15\nObjetivo, método y resultados se articulan con coherencia; introducción y cierre precisos en tiempo.\nSecuencia mayormente clara con leves transiciones débiles.\nOrden irregular; faltan transiciones clave.\nDesorganizada; propósito no se comprende.\n\n\nRigor técnico\n25\nDefiniciones y ecuaciones (\\(L=2^{b}\\), \\(\\Delta\\), \\(\\mathrm{MSE}\\)) correctas; supuestos declarados y validados.\nMenores imprecisiones sin afectar conclusiones.\nVarias imprecisiones o supuestos no justificados.\nErrores conceptuales graves o confusión sostenida.\n\n\nMetodología y adquisición\n15\nParámetros de cámara controlados; protocolo replicable; evidencia fotográfica clara.\nControl adecuado con una omisión menor.\nControl parcial; documentación incompleta.\nSin control de variables; documentación escasa.\n\n\nAnálisis y resultados\n20\nComparaciones entre espacios (HSV/Lab/YCrCb) con figuras pertinentes; conclusiones sustentadas.\nAnálisis correcto pero poco profundo o con pocas figuras.\nAnálisis superficial; conclusiones poco justificadas.\nSin análisis; afirmaciones sin evidencia.\n\n\nVisualización\n10\nFiguras legibles, ejes/leyendas correctas (en imágenes generadas con OpenCV); mapas de error bien presentados.\nVisualización adecuada con detalles mejorables.\nGráficos confusos o mal rotulados.\nVisualizaciones ausentes o incorrectas.\n\n\nGestión del tiempo\n10\nCulmina en 9–10 min; distribuye tiempo equilibradamente.\nLeve desviación (±1 min).\nDesviación moderada (±2 min).\nDesviación severa (&gt;±2 min) o no concluye.\n\n\nClaridad y comunicación\n5\nLenguaje técnico claro, voz y ritmo adecuados, contacto visual.\nGeneralmente claro con momentos de ambigüedad.\nDificultades frecuentes de expresión.\nIncomprensible o lectura de diapositivas.\n\n\n\nRecomendaciones de preparación (no evaluadas, pero sugeridas):\n- Ensayar con cronómetro (marcas en 3–6–9 min).\n- Limitar texto por diapositiva; priorizar comparativas claras (antes/después, por espacio y por \\(b\\)).\n- Anticipar dos preguntas técnicas (supuestos y limitaciones)."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "",
    "text": "Propósito: formular 2–3 objetivos SMART para el proyecto final de la asignatura, alineados con ODS 3: Salud y bienestar (y secundarios ODS 9/10/11 si aplica) y con necesidades de salud pública en Colombia.\nRestricción metodológica (obligatoria): evitar machine learning general. Únicos algoritmos de decisión permitidos: K‑means, regresión lineal múltiple y regresión logística múltiple. Prohibidos: redes neuronales, SVM, árboles/ensembles, métodos bayesianos avanzados, etc."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#resultados-de-aprendizaje",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#resultados-de-aprendizaje",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Resultados de aprendizaje",
    "text": "Resultados de aprendizaje\nAl finalizar, cada equipo:\n\nConecta un problema clínico-prioritario en Colombia con al menos un objetivo ODS y una meta/indicador verificable.\nRedacta 2–3 objetivos SMART (impacto clínico, técnico, implementación) con métricas y umbrales.\nDefine fuentes de datos (abiertos o locales con cumplimiento ético) y un plan de validación reproducible.\nDescribe riesgos de sesgo/ética y medidas de mitigación acordes con normativa colombiana de protección de datos."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#opciones-de-reto-elige-uno",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#opciones-de-reto-elige-uno",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Opciones de reto (elige uno)",
    "text": "Opciones de reto (elige uno)\nLas siguientes opciones se enfocan en tareas de detección, medición o soporte a decisión usando únicamente K‑means y/o regresión múltiple.\n\n1) Tuberculosis en radiografía de tórax (soporte a triage)\n\nTarea: puntaje de riesgo por paciente a partir de descriptores de imagen clásicos (textura, intensidades, morfología).\nAlgoritmos permitidos: segmentación de regiones sospechosas (heurística), K‑means para agrupar patrones de textura, regresión logística múltiple para estimar probabilidad de TB.\nMétrica primaria: sensibilidad y especificidad; curva ROC/AUC para el modelo logístico; tiempo de lectura por estudio.\n\n\n\n2) Retinopatía diabética (fondo de ojo)\n\nTarea: detección de lesiones (exudados, microaneurismas) mediante filtros clásicos; conteos y áreas como predictores.\nAlgoritmos: K‑means sobre espacios de color; regresión logística múltiple para riesgo de RD referible.\nMétrica primaria: F1 para lesión referible; exactitud por estratos de calidad de imagen.\n\n\n\n3) Ultrasonido obstétrico (biometría cefálica)\n\nTarea: estimar circunferencia cefálica (HC) con ajuste geométrico; usar regresión lineal múltiple para corregir sesgos por ángulo/ganancia.\nMétrica primaria: error absoluto medio (MAE) en mm frente a anotador experto.\n\n\n\n4) Lesiones cutáneas (dermatoscopia/imagen macro)\n\nTarea: segmentación clásica de la lesión; extracción de color/forma/asimetría; regresión logística múltiple para riesgo de malignidad (prototipo educativo, no clínico).\nMétrica primaria: AUC; análisis de errores por fototipo.\n\n\n\n5) Extracción de signos vitales con cámara web (rPPG) sin ML\n\nObjetivo: estimar frecuencia cardiaca (FC) y frecuencia respiratoria (FR) desde video RGB facial capturado con webcam estándar (≥ 30 fps) sin redes neuronales.\nPipeline sugerido: detección de rostro (clásica), definición de ROI (frente/pómulos), promediado espacial por canal, detrend y banda pasante; cálculo espectral.\nCálculos:\n\nSeñal rPPG por canal: \\(s_c(t) = \\frac{1}{|\\Omega|}\\sum_{(i,j)\\in \\Omega} I_c(i,j,t)\\).\nPreamplificación cromática tipo POS/CHROM (implementación determinista sin entrenamiento).\nHR (bpm) desde pico espectral: \\(\\mathrm{HR} = 60, f_{\\text{peak}}\\).\nSNR: \\(\\mathrm{SNR} = 10\\log_{10}\\left( \\frac{P\\{\\text{señal}}\\}{P\\{\\text{ruido}}\\} \\right)\\).\n\nAlgoritmos de decisión permitidos:\n\nK‑means para estabilidad de ROI (agrupar píxeles por coherencia temporal) o clusterizar condiciones de iluminación.\nRegresión lineal múltiple para corrección de artefactos (p. ej., modelar FC estimada como función de variables de captura: luminancia media, varianza, amplitud de movimiento): \\(\\widehat{\\mathrm{FC}} = \\beta_0 + \\sum_{j=1}^p \\beta_j x_j\\).\nRegresión logística múltiple para calidad binaria del segmento (válido/no válido) a partir de predictores como SNR, varianza, energía de banda: \\(\\Pr(\\text{válido}=1\\mid x)=\\sigma!\\left( \\beta_0 + \\sum_{j=1}^p \\beta_j x_j \\right),\\ \\ \\sigma(z)=\\frac{1}{1+e^{-z}}\\).\n\nMétricas: MAE de FC (bpm), MAE de FR (rpm), proporción de segmentos válidos, latencia."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#recordatorio-de-ecuaciones-uso-en-los-tres-algoritmos-permitidos",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#recordatorio-de-ecuaciones-uso-en-los-tres-algoritmos-permitidos",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Recordatorio de ecuaciones (uso en los tres algoritmos permitidos)",
    "text": "Recordatorio de ecuaciones (uso en los tres algoritmos permitidos)\nK‑means (criterio WCSS): minimizar\n\\(J = \\sum_{i=1}^k \\sum_{x\\in C_i} \\lVert x - \\mu_i \\rVert^2\\).\nRegresión lineal múltiple:\n\\(\\hat{y} = \\beta_0 + \\sum_{j=1}^p \\beta_j x_j\\), con ajuste por mínimos cuadrados: \\(\\min_\\beta \\lVert y - X\\beta \\rVert_2^2\\).\nRegresión logística múltiple:\n\\(\\Pr(Y=1\\mid x) = \\sigma!\\left( \\beta_0 + \\sum_{j=1}^p \\beta_j x_j \\right)\\), donde \\(\\sigma(z)=\\frac{1}{1+e^{-z}}\\)."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#plantilla-lienzo-de-objetivos-1-página",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#plantilla-lienzo-de-objetivos-1-página",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Plantilla: Lienzo de Objetivos (1 página)",
    "text": "Plantilla: Lienzo de Objetivos (1 página)\nComplete y entregue una página por equipo. En la plantilla del curso\n\nTítulo del proyecto:\nODS principal (meta/indicador):\nODS secundario (opcional):\nProblema en Colombia (fuente breve):\nPoblación objetivo y escenario de uso:\nModalidad de imagen y tarea:\nDatos/datasets (licencia y tamaño):\nObjetivo SMART 1 (impacto):\nObjetivo SMART 2 (técnico):\nObjetivo SMART 3 (implementación):\nMétrica(s) primaria(s) y umbrales:\nRiesgos/sesgos y cumplimiento (privacidad y ética):\nPlan de validación:\nHitos/tiempos:"
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#ejemplos-de-objetivos-smart-adaptar-al-caso",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#ejemplos-de-objetivos-smart-adaptar-al-caso",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Ejemplos de objetivos SMART (adaptar al caso)",
    "text": "Ejemplos de objetivos SMART (adaptar al caso)\n\nImpacto clínico (ODS 3): “En 10 semanas, demostrar en n=40 participantes que el prototipo de rPPG logra MAE(FC) ≤ 5 bpm frente a pulsioxímetro de referencia, en condiciones de luz ambiental de consultorio.”\nTécnico‑algorítmico: “Implementar pipeline determinista de rPPG con banda 0.7–4 Hz para FC y 0.1–0.5 Hz para FR; usar K‑means para seleccionar ROI estable y regresión lineal múltiple para corrección por iluminación; alcanzar proporción de segmentos válidos ≥ 0.9.”\nImplementación/uso responsable: “Entregar una app on‑device que procese 60 s de video en ≤ 3 s y exporte solo series temporales y métricas (sin video). Incluir aviso y consentimiento informado.”\n\n\nPara otras opciones de reto, formule un objetivo análogo con métrica primaria clara (p. ej., AUC ≥ 0.85 para logística múltiple o MAE ≤ umbral en lineal múltiple) y justificativo ODS."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#sugerencias-de-métricas-y-validación",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#sugerencias-de-métricas-y-validación",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Sugerencias de métricas y validación",
    "text": "Sugerencias de métricas y validación\n\nClasificación (logística múltiple): AUC, sensibilidad, especificidad, F1, calibración (revisar curva de confiabilidad).\nRegresión (lineal múltiple): MAE, RMSE, \\(R^2\\), análisis de residuos.\nClustering (K‑means): inercia (WCSS), silhouette (solo para diagnóstico; no usar como criterio de decisión clínica).\nValidación: partición entrenamiento/validación, estratificación por subgrupos (edad/sexo/calidad de imagen), IC por bootstrap si el tamaño lo permite."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#riesgos-y-mitigaciones-ética-y-sesgo",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#riesgos-y-mitigaciones-ética-y-sesgo",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Riesgos y mitigaciones (ética y sesgo)",
    "text": "Riesgos y mitigaciones (ética y sesgo)\n\nPrivacidad: evitar almacenar datos identificables; anonimizar; limitar finalidades; consentimiento informado cuando aplique.\nSesgo de dominio: evaluar por dispositivo, iluminación, fototipo, institución; reportar desempeño estratificado.\nSeguridad: indicar que los prototipos son con fines educativos y no clínicos."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#entregables-de-la-sesión",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#entregables-de-la-sesión",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Entregables de la sesión",
    "text": "Entregables de la sesión\n\nLienzo de Objetivos (1 página) completado.\nPitch de 60 s leyendo objetivo principal y métrica clave.\nArchivo breve (máx. 1 página) con las ecuaciones que usa su proyecto (de entre las listadas) y la métrica primaria con definición formal."
  },
  {
    "objectID": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#rúbrica-de-evaluación-actividad-de-hoy",
    "href": "laboratorios/PSIM/lab003_Definicion_Objetivos.html#rúbrica-de-evaluación-actividad-de-hoy",
    "title": "Objetivos de Proyecto Final en Procesamiento de Imágenes Biomédicas (ODS–Colombia)",
    "section": "Rúbrica de evaluación (actividad de hoy)",
    "text": "Rúbrica de evaluación (actividad de hoy)\nPuntaje total: 100. Aprobación sugerida: ≥ 70 y sin criterios en nivel Insuficiente.\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nPeso\nExcelente (4)\nBueno (3)\nBásico (2)\nInsuficiente (1)\n\n\n\n\nAlineación con ODS\n20\nODS principal correcto y meta/indicador explícito y pertinente\nODS correcto sin indicador concreto\nODS genérico\nSin ODS o incorrecto\n\n\nRelevancia país/población\n15\nContexto Colombia claro (población, nivel de atención, brecha)\nContexto parcial\nContexto vago\nSin contexto\n\n\nCalidad de objetivos SMART\n20\n2–3 objetivos con métricas, umbrales y tiempos; separados en impacto/técnico/implementación\nObjetivos claros pero incompletos\nFaltan métricas o tiempos\nConfusos o no medibles\n\n\nViabilidad técnica (solo K‑means / reg. múltiple)\n15\nElección y justificación rigurosa; ecuaciones y variables definidas\nElección adecuada con ligeras lagunas\nUso dudoso o variables mal definidas\nIncumple restricciones o inviable\n\n\nÉtica y cumplimiento\n10\nRiesgos/sesgos y medidas; privacidad correctamente abordada\nMenciona ética sin detalle\nSuperficial\nNo aborda\n\n\nMétricas de éxito\n10\nIndicadores clínicos/operativos claros y umbrales\nIndicadores presentes sin umbrales\nIndicadores vagos\nNo hay\n\n\nClaridad de la entrega (1 pág + pitch)\n10\nSíntesis excelente, visual limpio, pitch preciso\nClaro con leves omisiones\nDenso o poco legible\nIncompleto"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/Proyecto_Final_2024-2.html",
    "href": "laboratorios/PSIM/Previous/Proyecto_Final_2024-2.html",
    "title": "Proyecto Final: PSIM 2024-1",
    "section": "",
    "text": "Horarios de Sustentación\n\n\nMonitoría del Curso\nKevin Martínez\n\n\nRúbrica\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (100%)\nBueno (80%)\nRegular (60%)\nInsuficiente (40%)\nNo presentado (0%)\n\n\n\n\nUso de técnicas de procesamiento de imágenes o señales\nDemuestra un dominio profundo y una aplicación adecuada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nDemuestra una comprensión sólida y una aplicación adecuada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nDemuestra una comprensión básica y una aplicación limitada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nDemuestra una comprensión deficiente y una aplicación inadecuada de técnicas de procesamiento de imágenes o señales para lograr los objetivos del proyecto.\nNo se evidencia la aplicación de técnicas de procesamiento de imágenes o señales.\n\n\nCoherencia entre objetivos y resultados\nLos objetivos del proyecto están claramente definidos y alineados con los resultados obtenidos.\nLos objetivos del proyecto están definidos y alineados en gran medida con los resultados obtenidos.\nLos objetivos del proyecto están definidos, pero no se alinean completamente con los resultados obtenidos.\nLos objetivos del proyecto están poco definidos y no se alinean con los resultados obtenidos.\nNo se definen objetivos para el proyecto.\n\n\nTiempo de exposición\nLa exposición del proyecto es clara, concisa y organizada, permitiendo una comprensión completa del trabajo realizado.\nLa exposición del proyecto es clara y organizada, permitiendo una buena comprensión del trabajo realizado.\nLa exposición del proyecto es clara, pero con algunas deficiencias en la organización, lo que dificulta la comprensión completa del trabajo realizado.\nLa exposición del proyecto es poco clara y desorganizada, lo que dificulta la comprensión del trabajo realizado.\nNo se realiza una exposición del proyecto.\n\n\nPresentación\nLa presentación del proyecto es visualmente atractiva, profesional y utiliza recursos multimedia de manera efectiva para comunicar los resultados.\nLa presentación del proyecto es visualmente atractiva y profesional, utilizando algunos recursos multimedia para comunicar los resultados.\nLa presentación del proyecto es visualmente aceptable, pero con algunos errores o falta de recursos multimedia para comunicar los resultados.\nLa presentación del proyecto es poco visualmente atractiva, con errores y falta de recursos multimedia para comunicar los resultados.\nNo se realiza una presentación del proyecto.\n\n\nNivel de la codificación\nEl código está bien escrito, documentado, organizado y utiliza las mejores prácticas de programación.\nEl código está bien escrito, documentado y organizado.\nEl código está escrito, pero con algunas deficiencias en la documentación y organización.\nEl código está escrito de manera deficiente, con mala documentación y organización.\nEl código no está escrito o está escrito de manera no funcional.\n\n\nCreatividad en el algoritmo\nEl algoritmo utilizado en el proyecto es novedoso, original y efectivo para resolver el problema planteado.\nEl algoritmo utilizado en el proyecto es creativo, original y efectivo para resolver el problema planteado.\nEl algoritmo utilizado en el proyecto es creativo, pero con algunas limitaciones en su originalidad o efectividad.\nEl algoritmo utilizado en el proyecto es poco creativo, con limitaciones en su originalidad y efectividad.\nEl algoritmo utilizado en el proyecto no es creativo ni efectivo para resolver el problema planteado.\n\n\nTrabajo en equipo\nSe evidencia un trabajo en equipo efectivo, con una clara división de roles, comunicación constante y colaboración entre los miembros del equipo.\nSe evidencia un trabajo en equipo colaborativo, con una clara división de roles y comunicación entre los miembros del equipo.\nSe evidencia un trabajo en equipo con algunas dificultades en la colaboración o comunicación entre los miembros del equipo.\nSe evidencia un trabajo en equipo deficiente, con falta de colaboración y comunicación entre los miembros del equipo.\nNo se evidencia un trabajo en equipo.\n\n\nTrabajo individual\nCada miembro del equipo demuestra un alto nivel de compromiso, responsabilidad y contribución individual al proyecto.\nCada miembro del equipo demuestra un buen nivel de compromiso, responsabilidad y contribución individual al proyecto.\nCada miembro del equipo demuestra un nivel aceptable de compromiso, responsabilidad y contribución individual al proyecto.\nCada miembro del equipo demuestra un bajo nivel de compromiso, responsabilidad y contribución individual al proyecto.\nNo se evidencia el trabajo individual de los miembros del equipo."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/Previous/lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab03_ImagProc.html",
    "href": "laboratorios/PSIM/Previous/lab03_ImagProc.html",
    "title": "Laboratorio 3: Carga de datos e Histograma",
    "section": "",
    "text": "Cargar el archivo imagen_dicom.dcm y almacenarlo en la variable var01.\nCargar el archivo imagen_nii.nii y almacenarlo en la variable var02.\nCargar el archivo covid-4.png y almacenarlo en la variable var03.\nMostrar las variables: var01, var02, var03.\nDescribir las dimensiones de cada una de las imagenes.\nTomar la var03 y si tiene más de una dimensión, convertirla a imagen en escala de grises, con profundidad de intensidad de pixel de 8bits.\nContar cuantos pixeles hay para cada valor de intensidad posible en la conversión en escala de grises de la variable var03. Mostrar estos valores en una gráfica de barras.\nPara el punto 7 solo puede utilizar la librería numpy.\nPara el punto 8 solo puede utilizar la librería matplotlib."
  },
  {
    "objectID": "laboratorios/PSIM/eval001_ConductaEntrada.html",
    "href": "laboratorios/PSIM/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 3, 2026. The defense will be carried out by one of the team members chosen at random.\n\nExercise 0: Matrix Manipulation\nWrite a program that (after an initial solo design) prompts from the keyboard three integers \\(N\\), \\(M\\), and \\(K\\); validates that \\(N \\ge 1\\), \\(M \\ge 1\\), and \\(K \\ge 0\\); and constructs an \\(N \\times M\\) matrix whose entries are uniformly sampled integers from the closed interval \\([0, K]\\). The algorithm must classify every entry and extract the sets of even numbers, odd numbers, and prime numbers, where \\(0\\) and \\(1\\) are treated as non-prime and primality is decided via trial division up to \\(\\lfloor \\sqrt{x} \\rfloor\\) with early termination. For each category, report both (a) the total count over all matrix positions and (b) the sorted set of unique values; handle duplicates correctly, and note that if \\(K &lt; 2\\) the prime set is empty by definition. Structure the solution modularly (separate input handling, matrix generation, and classification), include basic input-error recovery, and optionally expose a random-seed parameter to ensure reproducibility. After independently drafting pseudocode, engage a peer as a “more knowledgeable other” to critique modularity and efficiency, then implement the revised design, test it on at least two contrasting cases (e.g., small matrices and edge \\(K\\) values), and submit a concise analytical note that justifies your validation choices and discusses time complexity; conclude with a brief reflection explaining how the peer interaction scaffolded your final solution.\n\n\nExercise 1: Numerical Diferentation\nDetermine the numerical derivative of the function h, represented as \\(\\left(\\frac{dh}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach\n\n\nExercise 2: Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{h(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach\n\n\nExercise 3: Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)\n\n\nExercise 4: Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent.\n\n\n\n0.5585873704668033"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "El procesamiento de señales de origen fisiológico —como las provenientes de sistemas cardiovasculares, neuromusculares o musculoesqueléticos— constituye un área clave dentro de la ingeniería biomédica y las ciencias de la salud. Su correcta interpretación requiere no solo conocimientos técnicos avanzados, sino también una capacidad crítica para integrar información multidisciplinar.\nLos objetivos de esta actividad son:\n\nAnalizar y comparar diferentes enfoques teóricos sobre el procesamiento de señales fisiológicas (ECG, EMG, PPG, etc.).\nEvaluar la calidad y rigurosidad técnica de fuentes bibliográficas científicas.\nFomentar el pensamiento crítico y la capacidad de síntesis de los estudiantes.\nDesarrollar habilidades de lectura técnica y argumentación científica en contextos biomédicos.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7\nM. A. Martínez González, A. Sánchez-Villegas, E. A. Toledo Atucha, y J. Faulin Fajardo, Bioestadística amigable, Third. Madrid, España: Elsevier, 2020."
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#duración",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#materiales",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7\nM. A. Martínez González, A. Sánchez-Villegas, E. A. Toledo Atucha, y J. Faulin Fajardo, Bioestadística amigable, Third. Madrid, España: Elsevier, 2020."
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-1-carga-y-visualización-entrega-22-de-abril-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-1-carga-y-visualización-entrega-22-de-abril-de-2025",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fase 1 – Carga y visualización (Entrega: 22 de abril de 2025)",
    "text": "Fase 1 – Carga y visualización (Entrega: 22 de abril de 2025)\n\nCargar una señal electrocardiográfica aleatoria del dataset.\nVisualizar la señal cruda.\nIdentificar ruido de línea base y artefactos. Explique que tipos de artefactos pueden aparecen en esta señal. Haga uso de diferentes artículos de naturaleza académica, por su puesto referencielos."
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-2-preprocesamiento-entrega-6-de-mayo-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-2-preprocesamiento-entrega-6-de-mayo-de-2025",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fase 2 – Preprocesamiento (Entrega 6 de mayo de 2025)",
    "text": "Fase 2 – Preprocesamiento (Entrega 6 de mayo de 2025)\n\nRealice un Filtrado paso banda (0.5–40 Hz). Porque se utiliza este rango de frecuencia? Se aplica un filtro FIR o IIR, porque?\nAplicar una normalización de escala a la señal. ¿Por qué\nAplicar un corte de ruido de línea base a la señal. ¿Que técnicas existen para tal fin?\nAplicar un corte de artefactos a la señal. ¿Qué técnicas existen para tal fin?"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-3-detección-de-picos-r-y-segmentación-entrega-semana-del-19-de-mayo-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-3-detección-de-picos-r-y-segmentación-entrega-semana-del-19-de-mayo-de-2025",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fase 3 – Detección de picos R y segmentación (Entrega Semana del 19 de mayo de 2025)",
    "text": "Fase 3 – Detección de picos R y segmentación (Entrega Semana del 19 de mayo de 2025)\n\nRealice una detección de picos R utilizando un algoritmo específico. ¿Qué algoritmo se ha utilizado? ¿Por qué? ¿Qué ventajas y desventajas tiene? Que tecnicas matematicas se han utilizado para el algoritmo?\nCalcular intervalos RR y frecuencia cardíaca instantánea. Que es una frecuencia cardíaca instantánea? ¿Por qué es importante?\nSegmentar la señal en intervalos de tiempo correspondientes a cada complejo QRS. ¿Que técnica utilizó y cual es la base matemática en la que se basó?"
  },
  {
    "objectID": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-4-extracción-de-características-entrega-semana-del-19-de-mayo-de-2025",
    "href": "laboratorios/SYSB/lab05_DetectordeArritmias.html#fase-4-extracción-de-características-entrega-semana-del-19-de-mayo-de-2025",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fase 4 – Extracción de características (Entrega Semana del 19 de mayo de 2025)",
    "text": "Fase 4 – Extracción de características (Entrega Semana del 19 de mayo de 2025)\n\nPara cada sujeto del conjunto de datos, calcule las siguientes características:\n\nFrecuencia cardíaca promedio.\nFrecuencia cardíaca máxima.\nFrecuencia cardíaca mínima.\nIntervalo RR promedio.\nIntervalo RR máximo.\nIntervalo RR mínimo.\nCoeficiente de variación de la frecuencia cardíaca.\nNúmero de latidos\n\nExisten otras características que se pueden calcular, ¿cuáles son? Referencie al menos 3 artículos de naturaleza académica.\nForme una tabla con las características calculadas para cada sujeto. Cada fila corresponde a un sujeto y cada columna corresponde a una característica.\nDetermine si cada característica es paramétrica o no. Se recomienda utilizar técnicas estadísticas para determinar si una característica es paramétrica o no.\nCon la información de parametricidad de la variable, determine si esta tiene diferencias estadísticamente para las personas con arritmias y las personas sin arritmias.\nUtilizando un algoritmo de regresión logística, plantee un __modelo estadístico de clasificació__n. ¿Qué es una regresión logística? ¿Como se puede calcular? Que es un modelo estadístico de clasificación?"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Antes de realizar el procesamiento de señales en estudios biomédicos, es fundamental llevar a cabo un análisis descriptivo de los participantes. Este paso permite contextualizar los datos y asegurar que cualquier resultado obtenido sea válido, representativo y adecuado para su interpretación clínica y científica. A continuación, se detallan las razones clave para realizar este análisis previo:\n\nCaracterización de la Población Estudiada: El análisis descriptivo permite conocer la distribución de variables clave.\nIdentificación de Posibles Sesgos en los Datos: Un estudio bien diseñado debe asegurarse de que los datos sean representativos de la población objetivo.\nEvaluación de la Calidad de los Datos: El análisis descriptivo ayuda a detectar inconsistencias en los datos antes de aplicar técnicas de procesamiento de señales.\nJustificación del Preprocesamiento de Señales: Al conocer las características de los participantes, se pueden tomar decisiones informadas sobre qué técnicas de procesamiento aplicar.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#duración",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#materiales",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-generación-de-la-información-base",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-1-generación-de-la-información-base",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 1: Generación de la información base",
    "text": "Actividad 1: Generación de la información base\nUtilizando el dataset, realice las siguiente tareas:\n\nEnumere todos los posibles diagnósticos que los pacientes pueden tener.\nPara todos los pacientes genere una tabla que debe tener la siguiente información:\n\nID: Identificador del paciente.\nEdad: Edad del paciente.\nSexo: Sexo del paciente.\nDiagnosticos: A partir de aquí se genera una columna por cada diagnóstico posible de un paciente. En cada paciente se registrará un 1 si este fue diagnósticado con la dolencia respectiva. Recomendación: Use los archivos .hea adjuntos en el dataset."
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-análisis-de-la-información",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#actividad-2-análisis-de-la-información",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 2: Análisis de la información",
    "text": "Actividad 2: Análisis de la información\nA partir de la tabla generado en la actividad anterior responda de forma clara y concisa las siguientes preguntas:\n\n¿Cuál es la frecuencia y el porcentaje de casos de Bradicardia Sinusal (SB) en la muestra?\n¿Cuál es la edad promedio y su desviación estándar para los pacientes con Bradicardia #. Sinusal (SB)?\n¿Cuál es el porcentaje de hombres en la categoría de Bradicardia Sinusal (SB)?\n¿Cuántos pacientes fueron diagnosticados con Ritmo Sinusal (SR) y qué porcentaje representa del total?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Ritmo Sinusal (SR)?\n¿Qué porcentaje de los pacientes con Ritmo Sinusal (SR) son hombres?\n¿Cuántos casos de Fibrilación Auricular (AFIB) se reportaron y qué porcentaje representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Fibrilación Auricular (AFIB)?\n¿Qué porcentaje de los pacientes con Fibrilación Auricular (AFIB) son hombres?\n¿Cuántos pacientes presentan Taquicardia Sinusal (ST) y qué porcentaje del total representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia Sinusal (ST)?\n¿Qué porcentaje de los pacientes con Taquicardia Sinusal (ST) son hombres?\n¿Cuál es la frecuencia y el porcentaje de casos de Flutter Auricular (AF) en la muestra?\n¿Cuál es la edad promedio y su desviación estándar para los pacientes con Flutter Auricular (AF)?\n¿Cuál es el porcentaje de hombres en la categoría de Flutter Auricular (AF)?\n¿Cuántos pacientes presentan Irregularidad Sinusal (SI) y qué porcentaje del total representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Irregularidad Sinusal (SI)?\n¿Qué porcentaje de los pacientes con Irregularidad Sinusal (SI) son hombres?\n¿Cuál es la frecuencia y el porcentaje de casos de Taquicardia Supraventricular (SVT) en la muestra?\n¿Cuál es la edad promedio y su desviación estándar para los pacientes con Taquicardia Supraventricular (SVT)?\n¿Cuál es el porcentaje de hombres en la categoría de Taquicardia Supraventricular (SVT)?\n¿Cuántos casos de Taquicardia Auricular (AT) se registraron y qué porcentaje del total representa?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia Auricular (AT)?\n¿Qué porcentaje de los pacientes con Taquicardia Auricular (AT) son hombres?\n¿Cuántos casos de Taquicardia por Reentrada en el Nodo AV (AVNRT) se reportaron y qué porcentaje representan?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia por Reentrada en el Nodo AV (AVNRT)?\n¿Qué porcentaje de los pacientes con Taquicardia por Reentrada en el Nodo AV (AVNRT) son hombres?\n¿Cuántos pacientes fueron diagnosticados con Taquicardia por Reentrada Auriculoventricular (AVRT) y qué porcentaje representan?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Taquicardia por Reentrada Auriculoventricular (AVRT)?\n¿Qué porcentaje de los pacientes con Taquicardia por Reentrada Auriculoventricular (AVRT) son hombres?\n¿Cuántos casos de Ritmo de deambulamiento auricular sinusal a auricular (SAAWR) se registraron y qué porcentaje representan?\n¿Cuál es la edad promedio y la desviación estándar de los pacientes con Ritmo de deambulamiento auricular sinusal a auricular (SAAWR)?\n¿Qué porcentaje de los pacientes con Ritmo de deambulamiento auricular sinusal a auricular (SAAWR) son hombres?\n¿Cuál es el número total de pacientes en la muestra y su edad promedio?\n¿Cuál es el porcentaje total de hombres en la muestra?"
  },
  {
    "objectID": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#criterios-de-evaluación",
    "href": "laboratorios/SYSB/lab03_Pre_Proc_Sennales.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Criterios de Evaluación",
    "text": "Criterios de Evaluación\nSustentación del trabajo. Cada equipo deberá responder tres preguntas:\n\nPregunta aleatoria basada en la actividad 2.\nPregunta basada en estadísticas que se obtienen a partir de la tabla de la actividad 1\nPregunta sobre el código utilizado para realizar el laboratorio."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html",
    "href": "laboratorios/APSB/lab02_EDA.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Construir un conjunto de datos a partir de señales e imágenes biomédicas.\nAplicar técnicas de preprocesamiento y limpieza de datos.\nRealizar un análisis exploratorio de datos (EDA).\nExtraer relaciones matemáticas mediante modelos de regresión y regresión logística.\nComparar el desempeño de múltiples modelos y seleccionar el más adecuado.\n\n\n\n\n\n\n\nCada estudiante debe elegir un conjunto de datos biomédicos, que puede provenir de:\n\nSeñales fisiológicas: ECG, EEG, PPG, EMG.\nImágenes médicas: Radiografías, resonancias, tomografías, postura, etc.\nBases de datos públicas: PhysioNet, Kaggle, NIH, entre otras.\n\n\n\n\nDependiendo del tipo de datos, se deben aplicar las siguientes técnicas:\n\n\n\nCarga de archivos (.csv, .edf, .mat).\nFiltrado de ruido y artefactos con técnicas adecuadas.\n\n\n\n\n\nCarga de imágenes (.png, .jpg, .dicom).\nConversión a escala de grises, realce de contraste o segmentación si es necesario.\n\n\n\n\n\n\n\n\n\nLos estudiantes deben:\n\nAnalizar la estructura del conjunto de datos.\nIdentificar posibles valores atípicos o datos faltantes.\n\n\n\n\n\nGráficos de señales en el dominio del tiempo y la frecuencia.\nHistogramas de intensidades en imágenes médicas.\n\n\n\n\n\n\n\n\nCada estudiante debe seleccionar una o más variables independientes y una variable dependiente con la que se intentará encontrar una relación matemática.\nEjemplos de relaciones a explorar:\n\nSeñales: ¿Cómo se relaciona la variabilidad del ECG con la edad?\nImágenes: ¿Existe una correlación entre el área de una lesión y la presencia de patología?\n\n\n\n\nSe entrenarán y compararán distintos modelos:\n\n\nPara analizar relaciones entre variables numéricas.\n\nSeparar el conjunto de datos en entrenamiento y prueba.\nAjustar un modelo de regresión lineal.\nEvaluar el desempeño con métricas como el error cuadrático medio (MSE).\nGenerar una gráfica que muestre la relación encontrada.\n\n\n\n\nPara predecir una variable categórica, como la presencia o ausencia de una condición médica.\n\nSeleccionar variables predictoras y la variable objetivo.\nDividir los datos en conjunto de entrenamiento y prueba.\nEntrenar un modelo de regresión logística.\nEvaluar el desempeño utilizando la precisión y la matriz de confusión.\n\n\n\n\n\n\n\nCada estudiante debe probar múltiples modelos y justificar su elección con base en:\n\nRegresión lineal vs. Regresión polinómica (para variables continuas).\nRegresión logística vs. Árboles de decisión (para clasificación binaria).\n\nCriterios de evaluación:\n\nError cuadrático medio (MSE) para regresión.\nPrecisión y matriz de confusión para clasificación.\n\nSe espera que cada estudiante explique:\n\n¿Cuál fue el modelo más adecuado?\n¿Por qué eligieron ese modelo y no otro?\n¿Cómo pueden mejorarlo?\n\n\n\n\n\nLos estudiantes deben responder:\n\n¿Qué relación matemática encontraron en los datos?\n¿Cuál fue el modelo más adecuado y por qué?\n¿Cómo podrían mejorar la predicción o ajustar mejor el modelo?\n\n\n\n\n\n\nEntrega: Un informe en Jupyter Notebook con código, visualizaciones y análisis.\nCriterios: Correcta implementación de modelos, análisis de resultados y justificación del mejor modelo.\n\n\n\n\n\nLa calificación total será de 100 puntos, distribuidos de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (20 pts)\nAceptable (10 pts)\nDeficiente (5 pts)\nPuntos\n\n\n\n\nSelección y Construcción del Dataset\nSe elige un conjunto de datos relevante y se preprocesa adecuadamente.\nSe elige un conjunto de datos adecuado pero con preprocesamiento incompleto.\nEl conjunto de datos no es adecuado o carece de preprocesamiento.\n\n\n\nExploración y Visualización\nSe realizan estadísticas descriptivas y gráficos claros y relevantes.\nSe presentan estadísticas básicas y gráficos, pero con poca interpretación.\nNo se incluyen estadísticas ni gráficos relevantes.\n\n\n\nEntrenamiento de Modelos\nSe implementan correctamente al menos dos modelos y se comparan sus resultados.\nSe implementa un modelo correctamente pero sin comparación.\nLa implementación de los modelos es incompleta o incorrecta.\n\n\n\nEvaluación y Selección del Mejor Modelo\nSe justifican las métricas y se elige el mejor modelo con base en evidencia.\nSe elige un modelo, pero sin un análisis detallado de métricas.\nNo hay justificación clara para la elección del modelo.\n\n\n\nInterpretación y Conclusiones\nSe explican claramente los hallazgos y posibles aplicaciones clínicas.\nSe presentan hallazgos, pero sin mucha profundidad.\nNo se presentan hallazgos o la explicación es insuficiente.\n\n\n\nCalidad del Código y Presentación\nEl código es claro, bien documentado y correctamente estructurado.\nEl código tiene errores menores o falta de documentación.\nEl código es desordenado, con errores o sin documentación.\n\n\n\n\n\n\n\n90 - 100 puntos: Sobresaliente.\n75 - 89 puntos: Bueno.\n50 - 74 puntos: Necesita mejora.\n0 - 49 puntos: Deficiente.\n\n\nNotas adicionales: Se recomienda el uso de bibliotecas como pandas, numpy, matplotlib, statsmodels y seaborn para análisis y visualización."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#objetivos",
    "href": "laboratorios/APSB/lab02_EDA.html#objetivos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Construir un conjunto de datos a partir de señales e imágenes biomédicas.\nAplicar técnicas de preprocesamiento y limpieza de datos.\nRealizar un análisis exploratorio de datos (EDA).\nExtraer relaciones matemáticas mediante modelos de regresión y regresión logística.\nComparar el desempeño de múltiples modelos y seleccionar el más adecuado."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-1-construcción-del-conjunto-de-datos",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-1-construcción-del-conjunto-de-datos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Cada estudiante debe elegir un conjunto de datos biomédicos, que puede provenir de:\n\nSeñales fisiológicas: ECG, EEG, PPG, EMG.\nImágenes médicas: Radiografías, resonancias, tomografías, postura, etc.\nBases de datos públicas: PhysioNet, Kaggle, NIH, entre otras.\n\n\n\n\nDependiendo del tipo de datos, se deben aplicar las siguientes técnicas:\n\n\n\nCarga de archivos (.csv, .edf, .mat).\nFiltrado de ruido y artefactos con técnicas adecuadas.\n\n\n\n\n\nCarga de imágenes (.png, .jpg, .dicom).\nConversión a escala de grises, realce de contraste o segmentación si es necesario."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-2-análisis-exploratorio-de-datos-eda",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-2-análisis-exploratorio-de-datos-eda",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Los estudiantes deben:\n\nAnalizar la estructura del conjunto de datos.\nIdentificar posibles valores atípicos o datos faltantes.\n\n\n\n\n\nGráficos de señales en el dominio del tiempo y la frecuencia.\nHistogramas de intensidades en imágenes médicas."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-3-extracción-de-relaciones-matemáticas-con-modelos-predictivos",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-3-extracción-de-relaciones-matemáticas-con-modelos-predictivos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Cada estudiante debe seleccionar una o más variables independientes y una variable dependiente con la que se intentará encontrar una relación matemática.\nEjemplos de relaciones a explorar:\n\nSeñales: ¿Cómo se relaciona la variabilidad del ECG con la edad?\nImágenes: ¿Existe una correlación entre el área de una lesión y la presencia de patología?\n\n\n\n\nSe entrenarán y compararán distintos modelos:\n\n\nPara analizar relaciones entre variables numéricas.\n\nSeparar el conjunto de datos en entrenamiento y prueba.\nAjustar un modelo de regresión lineal.\nEvaluar el desempeño con métricas como el error cuadrático medio (MSE).\nGenerar una gráfica que muestre la relación encontrada.\n\n\n\n\nPara predecir una variable categórica, como la presencia o ausencia de una condición médica.\n\nSeleccionar variables predictoras y la variable objetivo.\nDividir los datos en conjunto de entrenamiento y prueba.\nEntrenar un modelo de regresión logística.\nEvaluar el desempeño utilizando la precisión y la matriz de confusión."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-4-comparación-y-selección-del-mejor-modelo",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-4-comparación-y-selección-del-mejor-modelo",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Cada estudiante debe probar múltiples modelos y justificar su elección con base en:\n\nRegresión lineal vs. Regresión polinómica (para variables continuas).\nRegresión logística vs. Árboles de decisión (para clasificación binaria).\n\nCriterios de evaluación:\n\nError cuadrático medio (MSE) para regresión.\nPrecisión y matriz de confusión para clasificación.\n\nSe espera que cada estudiante explique:\n\n¿Cuál fue el modelo más adecuado?\n¿Por qué eligieron ese modelo y no otro?\n¿Cómo pueden mejorarlo?"
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#parte-5-interpretación-y-discusión",
    "href": "laboratorios/APSB/lab02_EDA.html#parte-5-interpretación-y-discusión",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Los estudiantes deben responder:\n\n¿Qué relación matemática encontraron en los datos?\n¿Cuál fue el modelo más adecuado y por qué?\n¿Cómo podrían mejorar la predicción o ajustar mejor el modelo?"
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#evaluación",
    "href": "laboratorios/APSB/lab02_EDA.html#evaluación",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Entrega: Un informe en Jupyter Notebook con código, visualizaciones y análisis.\nCriterios: Correcta implementación de modelos, análisis de resultados y justificación del mejor modelo."
  },
  {
    "objectID": "laboratorios/APSB/lab02_EDA.html#rúbrica-de-evaluación",
    "href": "laboratorios/APSB/lab02_EDA.html#rúbrica-de-evaluación",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "La calificación total será de 100 puntos, distribuidos de la siguiente manera:\n\n\n\n\n\n\n\n\n\n\nCriterio\nExcelente (20 pts)\nAceptable (10 pts)\nDeficiente (5 pts)\nPuntos\n\n\n\n\nSelección y Construcción del Dataset\nSe elige un conjunto de datos relevante y se preprocesa adecuadamente.\nSe elige un conjunto de datos adecuado pero con preprocesamiento incompleto.\nEl conjunto de datos no es adecuado o carece de preprocesamiento.\n\n\n\nExploración y Visualización\nSe realizan estadísticas descriptivas y gráficos claros y relevantes.\nSe presentan estadísticas básicas y gráficos, pero con poca interpretación.\nNo se incluyen estadísticas ni gráficos relevantes.\n\n\n\nEntrenamiento de Modelos\nSe implementan correctamente al menos dos modelos y se comparan sus resultados.\nSe implementa un modelo correctamente pero sin comparación.\nLa implementación de los modelos es incompleta o incorrecta.\n\n\n\nEvaluación y Selección del Mejor Modelo\nSe justifican las métricas y se elige el mejor modelo con base en evidencia.\nSe elige un modelo, pero sin un análisis detallado de métricas.\nNo hay justificación clara para la elección del modelo.\n\n\n\nInterpretación y Conclusiones\nSe explican claramente los hallazgos y posibles aplicaciones clínicas.\nSe presentan hallazgos, pero sin mucha profundidad.\nNo se presentan hallazgos o la explicación es insuficiente.\n\n\n\nCalidad del Código y Presentación\nEl código es claro, bien documentado y correctamente estructurado.\nEl código tiene errores menores o falta de documentación.\nEl código es desordenado, con errores o sin documentación.\n\n\n\n\n\n\n\n90 - 100 puntos: Sobresaliente.\n75 - 89 puntos: Bueno.\n50 - 74 puntos: Necesita mejora.\n0 - 49 puntos: Deficiente.\n\n\nNotas adicionales: Se recomienda el uso de bibliotecas como pandas, numpy, matplotlib, statsmodels y seaborn para análisis y visualización."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html",
    "href": "laboratorios/APSB/lab01_Linux.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes serán capaces de aplicar comandos esenciales de Linux para la manipulación de archivos, gestión de procesos y análisis de datos biomédicos.\n\n\n\n1.5 horas\n\n\n\n\nComputador con Linux (instalado o máquina virtual), WSL2 con Ubuntu, o emulado.\nHoja de trucos de Linux.\nArchivo de datos biomédicos en formato .csv (proporcionado).\n\n\n\n\n\n\n\n\nExplora los archivos y directorios disponibles en el sistema.\nCrea una estructura de directorios organizada para almacenar datos biomédicos.\nMueve y organiza el archivo de datos de pacientes dentro de la estructura creada.\nModifica los permisos del archivo para restringir o permitir accesos según corresponda.\n\nPreguntas de reflexión:\n- ¿Por qué es importante organizar archivos en un entorno de trabajo biomédico?\n- ¿Cómo podrías utilizar permisos de archivos para proteger datos de pacientes en un hospital?\n\n\n\n\n\n\n\n\nExamina las primeras líneas del archivo de pacientes para entender su estructura.\nCuenta la cantidad total de registros para determinar el número de pacientes.\nFiltra los registros de pacientes con presión arterial alta.\nOrdena los pacientes por edad para identificar a los de mayor edad.\nExtrae información relevante, como edad y frecuencia cardíaca, y guárdala en un nuevo archivo.\n\nPreguntas de análisis:\n- ¿Cómo podríamos automatizar estos análisis para realizarlos diariamente en un hospital?\n- ¿Qué otros patrones en los datos podríamos detectar utilizando solo comandos de Linux?\n\n\n\n\n\n\n\n\nEscribe un script en python que realice los análisis anteriores y guarde los resultados en un archivo de reporte.\nAsigna los permisos adecuados al script para poder ejecutarlo.\nEjecuta el script y verifica el contenido del reporte generado.\n\nReflexión final:\n- ¿Cómo podríamos modificar el script para hacerlo más interactivo?\n- ¿Cómo podríamos programarlo para que se ejecute automáticamente cada cierto tiempo?\n\n\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nDescripción\nPuntos\n\n\n\n\nUso de comandos básicos\nAplicación correcta de comandos de navegación y manipulación de archivos\n20\n\n\nProcesamiento de datos\nUso adecuado de herramientas para análisis de datos\n30\n\n\nAutomatización con scripts\nCreación y ejecución correcta de un script funcional\n30\n\n\nReflexión y análisis\nRespuestas argumentadas a preguntas de reflexión\n20\n\n\n\nTotal: 100 puntos.\n\nEsta actividad permite a los estudiantes desarrollar habilidades prácticas en Linux con aplicaciones directas en bioinformática y análisis de datos biomédicos."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#objetivo-de-aprendizaje",
    "href": "laboratorios/APSB/lab01_Linux.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes serán capaces de aplicar comandos esenciales de Linux para la manipulación de archivos, gestión de procesos y análisis de datos biomédicos."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#duración",
    "href": "laboratorios/APSB/lab01_Linux.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "1.5 horas"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#materiales",
    "href": "laboratorios/APSB/lab01_Linux.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador con Linux (instalado o máquina virtual), WSL2 con Ubuntu, o emulado.\nHoja de trucos de Linux.\nArchivo de datos biomédicos en formato .csv (proporcionado)."
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-1-exploración-y-gestión-de-archivos-30-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-1-exploración-y-gestión-de-archivos-30-min",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Explora los archivos y directorios disponibles en el sistema.\nCrea una estructura de directorios organizada para almacenar datos biomédicos.\nMueve y organiza el archivo de datos de pacientes dentro de la estructura creada.\nModifica los permisos del archivo para restringir o permitir accesos según corresponda.\n\nPreguntas de reflexión:\n- ¿Por qué es importante organizar archivos en un entorno de trabajo biomédico?\n- ¿Cómo podrías utilizar permisos de archivos para proteger datos de pacientes en un hospital?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-2-procesamiento-de-datos-biomédicos-en-la-terminal-40-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-2-procesamiento-de-datos-biomédicos-en-la-terminal-40-min",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Examina las primeras líneas del archivo de pacientes para entender su estructura.\nCuenta la cantidad total de registros para determinar el número de pacientes.\nFiltra los registros de pacientes con presión arterial alta.\nOrdena los pacientes por edad para identificar a los de mayor edad.\nExtrae información relevante, como edad y frecuencia cardíaca, y guárdala en un nuevo archivo.\n\nPreguntas de análisis:\n- ¿Cómo podríamos automatizar estos análisis para realizarlos diariamente en un hospital?\n- ¿Qué otros patrones en los datos podríamos detectar utilizando solo comandos de Linux?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#parte-3-automatización-con-scripts-20-min",
    "href": "laboratorios/APSB/lab01_Linux.html#parte-3-automatización-con-scripts-20-min",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Escribe un script en python que realice los análisis anteriores y guarde los resultados en un archivo de reporte.\nAsigna los permisos adecuados al script para poder ejecutarlo.\nEjecuta el script y verifica el contenido del reporte generado.\n\nReflexión final:\n- ¿Cómo podríamos modificar el script para hacerlo más interactivo?\n- ¿Cómo podríamos programarlo para que se ejecute automáticamente cada cierto tiempo?"
  },
  {
    "objectID": "laboratorios/APSB/lab01_Linux.html#criterios-de-evaluación",
    "href": "laboratorios/APSB/lab01_Linux.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Criterio\nDescripción\nPuntos\n\n\n\n\nUso de comandos básicos\nAplicación correcta de comandos de navegación y manipulación de archivos\n20\n\n\nProcesamiento de datos\nUso adecuado de herramientas para análisis de datos\n30\n\n\nAutomatización con scripts\nCreación y ejecución correcta de un script funcional\n30\n\n\nReflexión y análisis\nRespuestas argumentadas a preguntas de reflexión\n20\n\n\n\nTotal: 100 puntos.\n\nEsta actividad permite a los estudiantes desarrollar habilidades prácticas en Linux con aplicaciones directas en bioinformática y análisis de datos biomédicos."
  },
  {
    "objectID": "laboratorios/ASIM/lab002_CNN_cap.html",
    "href": "laboratorios/ASIM/lab002_CNN_cap.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torchvision\n\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader\n\nimport torch.nn as nn\n\nfrom torch import utils\nfrom torch import optim\nfrom torch import device\nfrom torch import inference_mode\n\nimport tqdm\n\nfrom timeit import default_timer as timer\nfrom tqdm.auto import tqdm\n\nfrom torchmetrics import ConfusionMatrix\nimport mlxtend\nfrom mlxtend.plotting import plot_confusion_matrix\nimport numpy\nfrom torchvision.transforms.v2 import (\n    ConvertImageDtype,\n    Normalize,\n    Resize,\n    CenterCrop,\n    ToTensor,\n    ToImage,\n    Compose\n)\n\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0\n\n\n\ntransformacion = Compose([\n    ToTensor(), \n    Normalize(mean=[0.5], std=[0.5])\n    ])\n\n/home/pablo/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n\n\n\ndata_flag = \"pathmnist\"\ninfo = INFO[data_flag]\nDataClass = getattr(medmnist, info[\"python_class\"])\n\n# Load the training and testing datasets\ntrain_data = DataClass(split=\"train\", transform=transformacion, download=True)\nval_data = DataClass(split=\"val\", transform=transformacion, download=True)\ntest_data = DataClass(split=\"test\", transform=transformacion, download=True)\n\nDownloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /home/pablo/.medmnist/pathmnist.npz\n\n\n100%|██████████| 205615438/205615438 [00:20&lt;00:00, 10059790.46it/s]\n\n\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\n\n\n\n# check data properties\nimg = train_data[0][0]\nlabel = train_data[0][1]\n\nprint(f\"Image:\\n {img}\")\nprint(f\"Label:\\n {label}\")\n\nprint(f\"Image shape: {img.shape}\")\nprint(f\"Label: {label}\")\n\nImage:\n tensor([[[0.7255, 0.7176, 0.7255,  ..., 0.7255, 0.7176, 0.7333],\n         [0.7098, 0.7255, 0.7176,  ..., 0.5451, 0.5059, 0.4902],\n         [0.7255, 0.7255, 0.7176,  ..., 0.6314, 0.6235, 0.6392],\n         ...,\n         [0.7098, 0.7020, 0.7333,  ..., 0.7333, 0.7255, 0.7333],\n         [0.6706, 0.7020, 0.7333,  ..., 0.7333, 0.7333, 0.7333],\n         [0.6863, 0.7255, 0.7333,  ..., 0.7255, 0.7333, 0.7412]],\n\n        [[0.6314, 0.6235, 0.6235,  ..., 0.6314, 0.6235, 0.6314],\n         [0.6157, 0.6235, 0.6157,  ..., 0.3882, 0.3490, 0.3176],\n         [0.6314, 0.6235, 0.6078,  ..., 0.4980, 0.5059, 0.5216],\n         ...,\n         [0.6078, 0.5765, 0.6314,  ..., 0.6314, 0.6314, 0.6392],\n         [0.5059, 0.5686, 0.6314,  ..., 0.6314, 0.6392, 0.6314],\n         [0.5294, 0.6235, 0.6314,  ..., 0.6314, 0.6314, 0.6392]],\n\n        [[0.7804, 0.7804, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7725, 0.7725, 0.7725,  ..., 0.5843, 0.5451, 0.5294],\n         [0.7725, 0.7725, 0.7647,  ..., 0.6706, 0.6706, 0.6941],\n         ...,\n         [0.7647, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7098, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7255, 0.7725, 0.7804,  ..., 0.7804, 0.7804, 0.7882]]])\nLabel:\n [0]\nImage shape: torch.Size([3, 28, 28])\nLabel: [0]\n\n\n\n# Number of image channels\nn_channels = info[\"n_channels\"]\nprint(f\"number of channels: {n_channels}\")\n\n# Number of classes\nn_classes = len(info[\"label\"])\nprint(f\"number of classes: {n_classes}\")\n\n# Get the class names from the dataset\nclass_names = info[\"label\"]\nprint(f\"class names: {class_names}\")\n\nnumber of channels: 3\nnumber of classes: 9\nclass names: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n\n\n\nfor i in range(3):\n    img = train_data[i][0]\n    label = train_data[i][1]\n    plt.figure(figsize=(3, 3))\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(label)\n    plt.axis(False)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.6313726..0.84313726].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.372549..0.85882354].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# change data into dataloader form\nBATCH_SIZE = 128\ntrain_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n\n\n# check dataloader\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")\n\nDataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53cd0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53490&gt;)\nLength of train dataloader: 704 batches of 128\nLength of test dataloader: 57 batches of 128\nLength of val dataloader: 79 batches of 128"
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html",
    "href": "laboratorios/ASIM/lab001_OOP.html",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "href": "laboratorios/ASIM/lab001_OOP.html#classes-and-objects",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "",
    "text": "A class is a blueprint or template that defines the characteristics and behavior of an object.\nAn object is an instance of a class, and it has its own set of attributes (data) and methods (functions)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "href": "laboratorios/ASIM/lab001_OOP.html#encapsulation",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Encapsulation",
    "text": "Encapsulation\n\nEncapsulation is the concept of bundling data and methods that operate on that data within a single unit (class).\nIt helps to hide the implementation details and expose only the necessary information to the outside world."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "href": "laboratorios/ASIM/lab001_OOP.html#inheritance",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Inheritance",
    "text": "Inheritance\n\nInheritance is the mechanism by which one class can inherit the attributes and methods of another class.\nIt promotes code reuse and facilitates the creation of a hierarchy of classes."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "href": "laboratorios/ASIM/lab001_OOP.html#polymorphism",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Polymorphism",
    "text": "Polymorphism\n\nPolymorphism is the ability of an object to take on multiple forms.\nIt can be achieved through method overriding (where a subclass provides a different implementation of a method) or method overloading (where multiple methods with the same name can be defined with different parameters)."
  },
  {
    "objectID": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "href": "laboratorios/ASIM/lab001_OOP.html#abstraction",
    "title": "Object-Oriented Programming in Python: A Guided Example",
    "section": "Abstraction",
    "text": "Abstraction\n\nAbstraction is the concept of showing only the necessary information to the outside world while hiding the implementation details.\nIt helps to reduce complexity and improve code readability.\n\n\nclass BankAccount:\n    def __init__(self, account_number, account_name, balance):\n        self.account_number = account_number\n        self.account_name = account_name\n        self.balance = balance\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance:\n            print(\"Insufficient funds\")\n        else:\n            self.balance -= amount\n\n    def display_details(self):\n        print(f\"Account Number: {self.account_number}\")\n        print(f\"Account Name: {self.account_name}\")\n        print(f\"Balance: {self.balance}\")\n\n\nThe BankAccount class encapsulates the account_number, account_name, and balance attributes, as well as the deposit, withdraw, and display_details methods.\nThe __init__ method is a special method that is called when an object is created, and it initializes the attributes.\nThe deposit and withdraw methods modify the balance attribute, demonstrating encapsulation.\nThe display_details method provides a way to access the attributes without exposing them directly, demonstrating abstraction.\n\n\nclass SavingsAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, interest_rate):\n        super().__init__(account_number, account_name, balance)\n        self.interest_rate = interest_rate\n\n    def add_interest(self):\n        interest = self.balance * self.interest_rate\n        self.deposit(interest)\n\n\nThe SavingsAccount class inherits the attributes and methods of BankAccount using the super() function.\nIt adds an additional attribute interest_rate and a method add_interest that calculates and deposits interest.\n\n\nclass CurrentAccount(BankAccount):\n    def __init__(self, account_number, account_name, balance, overdraft_limit):\n        super().__init__(account_number, account_name, balance)\n        self.overdraft_limit = overdraft_limit\n\n    def withdraw(self, amount):\n        if amount &gt; self.balance + self.overdraft_limit:\n            print(\"Transaction declined\")\n        else:\n            super().withdraw(amount)\n\n\n\n\nimage.png\n\n\n\n“Designing a Comprehensive Hospital Management System in Python”\n\nIntroduction\nIn this task, we aim to develop a straightforward hospital management system that efficiently manages patients, doctors, and appointments. Leveraging Python’s object-oriented programming capabilities, we will create a robust framework to streamline hospital operations.\n\n\nSystem Components\nThe hospital management system comprises four primary classes: Person, Patient, Doctor, Appointment, and Hospital.\n\n\nPerson Class\nThe Person class serves as the foundation for both Patient and Doctor classes, encapsulating essential attributes:\n\nname\nage\ngender\n\n\n\nPatient Class\nInheriting from Person, the Patient class introduces additional attributes:\n\npatient_id\nillness\n\n\n\nDoctor Class\nSimilarly, the Doctor class inherits from Person and includes:\n\ndoctor_id\nspecialization\n\n\n\nAppointment Class\nThe Appointment class encompasses:\n\nappointment_id\npatient (a Patient object)\ndoctor (a Doctor object)\ndate\ntime\n\n\n\nHospital Class\nThe Hospital class is the central hub, managing:\n\npatients (a list of Patient objects)\ndoctors (a list of Doctor objects)\nappointments (a list of Appointment objects)\nHospital Class Methods: The Hospital class features the following methods:\n\nadd_patient(name, age, gender, patient_id, illness): Adds a new patient to the hospital.\nadd_doctor(name, age, gender, doctor_id, specialization): Adds a new doctor to the hospital.\nschedule_appointment(appointment_id, patient_id, doctor_id, date, time): Schedules a new appointment.\nlist_appointments(): Lists all appointments.\n\n\n\n\nImplementation\nBy utilizing these classes and methods, the hospital management system provides a structured approach to managing patients, doctors, and appointments, ensuring efficient and organized hospital operations."
  },
  {
    "objectID": "clases/Class_PAIM.html",
    "href": "clases/Class_PAIM.html",
    "title": "Procesado Avanzado de Imágenes Médicas",
    "section": "",
    "text": "“Un área de rápido crecimiento y variedad de aplicaciones en la ingeniería biomédica a nivel nacional y global es el procesamiento digital de señales e imágenes médicas. Es por eso, que a través de este curso se desea dar las herramientas necesarias para los graduados del programa puedan tener competencias básicas en las técnicas clásicas y algunas técnicas modernas de procesamiento de señales e imágenes. La primera parte del curso se encuentra enfocada al desarrollo de técnicas de procesamiento para señales biomédicas unidimensionales, exponiendo primero su origen fisiológico y siguiendo con la presentación de las principales técnicas para su análisis y procesamiento. La segunda parte del curso hace énfasis en el estudio de imágenes médicas, partiendo de una explicación de los principales métodos computacionales utilizados para procesamiento digital de imágenes y luego exponiendo brevemente el proceso de su formación. A través de prácticas de laboratorio con señales e imágenes médicas (reales o simuladas), el estudiante podrá aplicar y reforzar los conocimientos aprendidos en el curso” fragmento tomado del microcurriculo de la asignatura.\nEl curso está dividido en 4 partes:\n\nIntroducción\nFundamentos del procesamiento avanzado de imágenes médicas\nRayos X\nTomografía axial computarizada\nResonancia Magnética"
  },
  {
    "objectID": "clases/Class_PAIM.html#presentaciones",
    "href": "clases/Class_PAIM.html#presentaciones",
    "title": "Procesado Avanzado de Imágenes Médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nIntroducción\nFundamentos del procesamiento avanzado de imágenes médicas\nRayos X\nTomografía axial computarizada\nResonancia Magnética"
  },
  {
    "objectID": "clases/Class_PAIM.html#datos",
    "href": "clases/Class_PAIM.html#datos",
    "title": "Procesado Avanzado de Imágenes Médicas",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_PAIM.html#códigos",
    "href": "clases/Class_PAIM.html#códigos",
    "title": "Procesado Avanzado de Imágenes Médicas",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_PAIM.html#laboratorios",
    "href": "clases/Class_PAIM.html#laboratorios",
    "title": "Procesado Avanzado de Imágenes Médicas",
    "section": "Laboratorios",
    "text": "Laboratorios"
  },
  {
    "objectID": "clases/Class_PAIM.html#talleres-examenes-anteriores",
    "href": "clases/Class_PAIM.html#talleres-examenes-anteriores",
    "title": "Procesado Avanzado de Imágenes Médicas",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores"
  },
  {
    "objectID": "clases/Class_APSB.html",
    "href": "clases/Class_APSB.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Procesamiento en Tiempo Real\nEn entornos biomédicos, muchas aplicaciones requieren procesamiento en tiempo real, como el monitoreo de pacientes críticos, análisis de imágenes médicas (por ejemplo, ultrasonido, radiografías) y dispositivos portátiles. Edge AI permite procesar datos localmente, reduciendo la latencia en comparación con el envío de datos a servidores remotos. Ejemplo: Un dispositivo portátil para monitoreo continuo de ECG puede detectar arritmias en tiempo real sin depender de una conexión a internet.\nMayor Privacidad y Seguridad\nLos datos médicos son altamente sensibles y están protegidos por regulaciones estrictas (como la HIPAA o el GDPR). Edge AI permite que los datos se procesen y almacenen localmente, minimizando el riesgo de violaciones de seguridad o filtraciones. Ejemplo: Un sensor de glucosa implantable que analiza niveles de glucosa sin enviar los datos a la nube asegura mayor privacidad del paciente.\nReducción de Costos Operativos\nEl procesamiento en el borde elimina la necesidad de transmitir grandes volúmenes de datos a servidores en la nube, lo que reduce costos relacionados con la conectividad y el almacenamiento en línea. Ejemplo: Un sistema de detección de caídas para personas mayores puede analizar los datos del acelerómetro directamente en el dispositivo sin enviar grandes volúmenes de datos a la nube.\nAplicaciones en Zonas Remotas\nEn áreas rurales o zonas con conectividad limitada, Edge AI permite el uso de dispositivos médicos avanzados sin depender de conexiones de internet robustas. Ejemplo: Una máquina portátil de ultrasonido que utiliza Edge AI para interpretar imágenes en tiempo real podría usarse en campañas de salud en comunidades remotas.\nEficiencia Energética\nLos modelos de Edge AI están diseñados para operar en dispositivos de bajo consumo energético, lo que es ideal para dispositivos médicos portátiles y sistemas implantables. Ejemplo: Monitores de salud wearables, como relojes inteligentes o biosensores, que analizan parámetros fisiológicos continuamente.\nPersonalización y Adaptación en el Lugar\nLos modelos de Edge AI pueden adaptarse a los datos del usuario en tiempo real, permitiendo personalización sin enviar datos sensibles a servidores externos. Ejemplo: Un dispositivo de rehabilitación motora que analiza el movimiento del paciente y ajusta los ejercicios en tiempo real según su progreso.\nInterdisciplinariedad y Tendencia Futurista\nLa integración de Edge AI con la ingeniería biomédica fomenta una combinación única de hardware, software y conocimiento médico, lo que te posiciona en el centro de las innovaciones tecnológicas en salud.\nEl curso está dividido en 4 partes:\n1. Introducción a inteligencia artificial en el borde (EDGE AI).\n2. Hardware y software para EDGE AI.\n3. El flujo de trabajo de EDGE AI.\n4. Diseño, desarrollo y evaluación de sistemas EDGE AI."
  },
  {
    "objectID": "clases/Class_APSB.html#presentaciones",
    "href": "clases/Class_APSB.html#presentaciones",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción 1/2\nIntroducción 2/2\nLinux\nMetodología de desarrollo\nIntroducción al machine learning\nFlujo de trabajo para proyectos de machine learning"
  },
  {
    "objectID": "clases/Class_APSB.html#datos",
    "href": "clases/Class_APSB.html#datos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_APSB.html#códigos",
    "href": "clases/Class_APSB.html#códigos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_APSB.html#rúbrica",
    "href": "clases/Class_APSB.html#rúbrica",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Rúbrica",
    "text": "Rúbrica\n-Planteamiento del problema"
  },
  {
    "objectID": "clases/Class_APSB.html#laboratorios",
    "href": "clases/Class_APSB.html#laboratorios",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio001: Conociendo LINUX.\nLaboratorio002: Análisis exploratorio de datos"
  },
  {
    "objectID": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\n“Necesito un documento PDF descargable con la explicación de los algoritmos de machine learning utilizados en ciencias de la vida. El texto debe contener una relación entre las técnicas de análasis exploratorio y el algoritmo de machine learning, fundamentos teóricos del algoritmo, códigos python para utilizar. Los algoritmos deben ser: KNN, árboles de decisión, máquinas de soporte vectorial, bosques aleatorios y gradient boosting machines. Debes verificar la información para evitar alucinaciones.”\nDocumento 1: machine learning. CHATGPT 4o\nDocumento 2: machine learning. GEMINI 2.0 flash\nJ. D. Kelleher, B. Mac Namee, y A. D’Arcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed. Cambridge: The MIT press, 2020."
  },
  {
    "objectID": "clases/Class_APSB.html#clases",
    "href": "clases/Class_APSB.html#clases",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Clases",
    "text": "Clases\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201."
  },
  {
    "objectID": "clases/Class_PSIM.html",
    "href": "clases/Class_PSIM.html",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "“Un área de rápido crecimiento y variedad de aplicaciones en la ingeniería biomédica a nivel nacional y global es el procesamiento digital de señales e imágenes médicas. Es por eso, que a través de este curso se desea dar las herramientas necesarias para los graduados del programa puedan tener competencias básicas en las técnicas clásicas y algunas técnicas modernas de procesamiento de señales e imágenes. La primera parte del curso se encuentra enfocada al desarrollo de técnicas de procesamiento para señales biomédicas unidimensionales, exponiendo primero su origen fisiológico y siguiendo con la presentación de las principales técnicas para su análisis y procesamiento. La segunda parte del curso hace énfasis en el estudio de imágenes médicas, partiendo de una explicación de los principales métodos computacionales utilizados para procesamiento digital de imágenes y luego exponiendo brevemente el proceso de su formación. A través de prácticas de laboratorio con señales e imágenes médicas (reales o simuladas), el estudiante podrá aplicar y reforzar los conocimientos aprendidos en el curso” fragmento tomado del microcurriculo de la asignatura.\nEl curso está dividido en 4 partes:\n1. Introducción al procesado de señales e imágenes biomédicas.\n2. Fundamentos procesado de señales e imágenes biomédicas\n3. Extracción de características de señales biomédicas.\n4. Extracción de características de imágenes biomédicas."
  },
  {
    "objectID": "clases/Class_PSIM.html#presentaciones",
    "href": "clases/Class_PSIM.html#presentaciones",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción\nIntroducción al procesamiento de imagenes\nLa imagen digital. Procesamiento de Imágenes 1/4\nLa imagen digital. Procesamiento de Imágenes 2/4\nRespuesta en frecuencia. (3/4)\nWavelets 4/4"
  },
  {
    "objectID": "clases/Class_PSIM.html#datos",
    "href": "clases/Class_PSIM.html#datos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_PSIM.html#códigos",
    "href": "clases/Class_PSIM.html#códigos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_PSIM.html#laboratorios",
    "href": "clases/Class_PSIM.html#laboratorios",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio 01\nLaboratorio 02\nLaboratorio 03\nLaboratorio 04"
  },
  {
    "objectID": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "href": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nPrimer Parcial\nSegundo Parcial 2025-2\nTercer Parcial"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Sistemas y Señales Biomédicoss en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado Avanzado Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de Talleres Ingeniería Biomédica en la Escuela Colombiana de Ingeniería\n\n\n\n14 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n14 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde en la Escuela Colombiana de Ingeniería\n\n\n\n14 ene 2026\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#clases",
    "href": "index.html#clases",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Sistemas y Señales Biomédicoss en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado Avanzado Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n20 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de Talleres Ingeniería Biomédica en la Escuela Colombiana de Ingeniería\n\n\n\n14 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n14 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde en la Escuela Colombiana de Ingeniería\n\n\n\n14 ene 2026\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#tutoriales",
    "href": "index.html#tutoriales",
    "title": "PECR Knowledge Hub",
    "section": "Tutoriales",
    "text": "Tutoriales\n\n\n\n\n\n\n\n\n\n\nInstalación de Entorno de trabajo. Ubuntu WSL2\n\n\nTutorial\n\n\n\n14 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluación del aprendizaje\n\n\nTutorial\n\n\n\n14 ene 2026\n\n\n\n\n\n\n\n\n\n\n\nCaso práctico: Análisis de señales EMG en rendimiento deportivo con ML/DL\n\n\nASIM_M\n\n\n\n14 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython programming\n\n\nA small tutorial in python in slides\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\nMicrobit – El minicomputador\n\n\nTutorial: Electrónica Básica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\nMicrobit – El minicomputador\n\n\nTutorial: Electrónica Básica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial de Python\n\n\nBreve Tutorial de Python\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputación de seno y coseno usando expansión de Taylor\n\n\nUn ejemplo de clase del cálculo de una serie de Taylor sin uso de librerías especiales de Python – En construcción –\n\n\n\n6 feb 2023\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#proyectos",
    "href": "index.html#proyectos",
    "title": "PECR Knowledge Hub",
    "section": "Proyectos",
    "text": "Proyectos\n\n\n\n\n\n\n\n\n\n\nPredictive modeling for seizure detection in pharmacoresistant epilepsy: a machine learning approach\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparing different Machine Learning architectures for classifying medical terms in Colombian sign language\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "href": "presentaciones/PSIM/Asist001_SourcesData.html#sources-of-data",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sources of data",
    "text": "Sources of data\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---element-wise-operation",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---element-wise-operation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Element-Wise Operation",
    "text": "Basic Mathematic - Element-Wise Operation\n\n\n\n\n\n\n\nDefinition\n\n\nOperation involving one or more images is carried out on a pixel-bypixel basis\n\n\n\n\n\\[\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{bmatrix} \\oplus \\begin{bmatrix} b_{11} & b_{12} \\\\  b_{21} & b_{22}\\end{bmatrix} = \\begin{bmatrix} a_{11}+b_{11} & a_{12}+b_{12} \\\\  a_{21}+b_{21} & a_{22}+b_{22}\\end{bmatrix} \\]\n\\[\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{bmatrix} \\odot \\begin{bmatrix} b_{11} & b_{12} \\\\  b_{21} & b_{22}\\end{bmatrix} = \\begin{bmatrix} a_{11}.b_{11} & a_{12}.b_{12} \\\\  a_{21}.b_{21} & a_{22}.b_{22}\\end{bmatrix} \\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---linear-operations",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---linear-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Linear Operations",
    "text": "Basic Mathematic - Linear Operations\n\n\n\n\n\n\n\nDefinition\n\n\nGiven two arbitrary constants, \\(\\alpha_1\\) and \\(\\alpha_2\\), and two arbitrary images \\(f_1\\left(x,y\\right)\\) and \\(f_2\\left(x,y\\right)\\), \\(\\varkappa\\) is said to be a linear operator if:\n\\[ \\begin{equation}\\begin{split} \\varkappa\\left[\\alpha_1 f_1\\left(x,y\\right) + \\alpha_2 f_2\\left(x,y\\right)\\right] & =  \\alpha_1 \\varkappa\\left[ f_1\\left(x,y\\right)\\right] + \\alpha_2 \\varkappa\\left[f_2\\left(x,y\\right)\\right] \\\\ & = \\alpha_1 g_1\\left(x,y\\right) + \\alpha_2 g_2\\left(x,y\\right) \\end{split}\\end{equation} \\]\n\n\n\n\nSupose \\(\\alpha_1 = 5\\), \\(\\alpha_2 = 2\\), \\(\\varkappa = max\\) and consider:\n\\[f_1 = \\begin{bmatrix}0 & -1 \\\\2 & 4\\end{bmatrix}\\], \\[f_2 = \\begin{bmatrix}30 & 4 \\\\-2 & -3\\end{bmatrix}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Adding",
    "text": "Basic Mathematic - Adding"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---adding-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Adding",
    "text": "Basic Mathematic - Adding\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_ray_chest = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/female-chest-x-ray.jpg\")\nplt.imshow(x_ray_chest, cmap=\"gray\")\nplt.show()\nimage_synt1 = 100*np.abs(np.random.normal(0, 1, x_ray_chest.shape))\nplt.imshow(image_synt1)\nplt.show()\nfinal_image = np.uint8(x_ray_chest+image_synt1)\nplt.imshow(final_image)\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---multiplying",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---multiplying",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Multiplying",
    "text": "Basic Mathematic - Multiplying\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_ray_chest = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/female-chest-x-ray.jpg\")\nmask = np.uint8(np.zeros(x_ray_chest.shape))\nmask[400:700, 250:600, :]=1\nplt.imshow(x_ray_chest)\nplt.show()\nplt.imshow(255*mask)\nplt.show()\nplt.imshow(np.multiply(x_ray_chest,mask))\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---basic-transformation",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---basic-transformation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Basic transformation",
    "text": "Basic Mathematic - Basic transformation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[x_{\\text{rescaled}} = n_{\\min} + \\frac{(x - \\min)}{\\max - \\min} \\, (n_{\\max} - n_{\\min})\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\nImagesCode\n\n\n\n\n\n\n\n\nExp=1.2\n\n\n\n\n\n\n\nExp=0.2\n\n\n\n\n\n\n\nExp=0.30\n\n\n\n\n\n\n\n\n\nExp=0.5\n\n\n\n\n\n\n\nOriginal\n\n\n\n\n\n\n\nExp=1.1\n\n\n\n\n\n\n\n\nx_ray_chest_gray = cv2.cvtColor(x_ray_chest, cv2.COLOR_BGR2GRAY)\nplt.imshow(x_ray_chest_gray, cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,1.1), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,1.2), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.2), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.3), cmap=\"gray\")\nplt.show()\nplt.imshow(np.power(x_ray_chest_gray,0.5), cmap=\"gray\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#basic-mathematic---pixel-intensity-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Basic Mathematic - Pixel intensity",
    "text": "Basic Mathematic - Pixel intensity\n\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-3",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-4",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-4",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood Operations",
    "text": "Neighborhood Operations\n\nFor example, suppose that the specified operation is to compute the average value of the pixels in a rectangular neighborhood of size mn × centered on \\(\\left(x,y\\right)\\). The coordinates of pixels in this region are the elements of set \\(S_{xy}\\).\n\n\nImagescode\n\n\n\n\n\n\n\n\n\nElderly woman image\n\n\n\n\n\n\n\n\n\n\nGray-scale image\n\n\n\n\n\n\n\n\n#|\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nplt.imshow(elderly)\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-5",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-5",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nOriginalAveragingCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN = 10\nkernel = np.ones((N,N),np.float32)/(N*N)\ndst = cv2.filter2D(elderly_gray,-1,kernel)\nplt.imshow(dst, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-6",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-6",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nOriginalMedianCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN=11\n\ndst1 = cv2.medianBlur(elderly_gray, N)\nplt.imshow(dst1, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-7",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-7",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nMeanMedian"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#mean-filter-33",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#mean-filter-33",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mean Filter (3×3)",
    "text": "Mean Filter (3×3)\n\n\nKernel\n\\[\nK_{\\text{mean}}=\\frac{1}{9}\n\\begin{bmatrix}\n1&1&1\\\\\n1&1&1\\\\\n1&1&1\n\\end{bmatrix}\n\\]\n\nPurpose: Basic smoothing (box filter). Effect: Reduces high-frequency noise and blurs edges. Notes: Linear and separable if implemented as two 1D averages; normalize by kernel sum."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#gaussian-filter-σ1-33",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#gaussian-filter-σ1-33",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Gaussian Filter (σ≈1, 3×3)",
    "text": "Gaussian Filter (σ≈1, 3×3)\n\n\nKernel\n\\[\nK_{\\text{gauss}}=\\frac{1}{16}\n\\begin{bmatrix}\n1&2&1\\\\\n2&4&2\\\\\n1&2&1\n\\end{bmatrix}\n\\]\n\nPurpose: Weighted smoothing around the center. Effect: Attenuates noise while preserving edges better than the mean filter. Notes: Approximates a discrete Gaussian; often used before edge detection."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#sobel-operator-gradient-33",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#sobel-operator-gradient-33",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Sobel Operator (Gradient 3×3)",
    "text": "Sobel Operator (Gradient 3×3)\n\n\nKernels\n\\[\nK_{x}=\n\\begin{bmatrix}\n-1&0&1\\\\\n-2&0&2\\\\\n-1&0&1\n\\end{bmatrix},\\quad\nK_{y}=\n\\begin{bmatrix}\n-1&-2&-1\\\\\n0&0&0\\\\\n1&2&1\n\\end{bmatrix}\n\\]\n\nPurpose: Estimate gradient along (x) and (y). Effect: Highlights horizontal and vertical edges; used for magnitude (). Notes: Includes implicit smoothing; more robust to noise than Prewitt."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#prewitt-operator-gradient-33",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#prewitt-operator-gradient-33",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Prewitt Operator (Gradient 3×3)",
    "text": "Prewitt Operator (Gradient 3×3)\n\n\nKernels\n\\[\nK_{x}=\n\\begin{bmatrix}\n-1&0&1\\\\\n-1&0&1\\\\\n-1&0&1\n\\end{bmatrix},\\quad\nK_{y}=\n\\begin{bmatrix}\n-1&-1&-1\\\\\n0&0&0\\\\\n1&1&1\n\\end{bmatrix}\n\\]\n\nPurpose: Estimate gradient with a simple scheme. Effect: Directional edge detection. Notes: Less smoothing than Sobel; computationally cheaper."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#laplacian-2nd-derivative",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#laplacian-2nd-derivative",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Laplacian (2nd Derivative)",
    "text": "Laplacian (2nd Derivative)\n\n\nKernels\n4-neighbor version: \\[\n\\begin{bmatrix}\n0&-1&0\\\\\n-1&4&-1\\\\\n0&-1&0\n\\end{bmatrix}\n\\]\n8-neighbor version: \\[\n\\begin{bmatrix}\n-1&-1&-1\\\\\n-1&8&-1\\\\\n-1&-1&-1\n\\end{bmatrix}\n\\]\n\nPurpose: Enhance abrupt transitions (zero-crossings). Effect: Isotropic edge detection; very sensitive to noise. Notes: Often preceded by smoothing (LoG/DoG). May introduce halos."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#sharpen-filter-33",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#sharpen-filter-33",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Sharpen Filter (3×3)",
    "text": "Sharpen Filter (3×3)\n\n\nKernel\n\\[\nK_{\\text{sharpen}}=\n\\begin{bmatrix}\n0&-1&0\\\\\n-1&5&-1\\\\\n0&-1&0\n\\end{bmatrix}\n\\]\n\nPurpose: Reinforce high-frequency components (details). Effect: Produces a crisper image; enhances edges and textures. Notes: Equivalent to adding the original image with a high-pass component; watch for saturation and noise."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#roberts-cross-operator-22-diagonals",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#roberts-cross-operator-22-diagonals",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Roberts Cross Operator (2×2, Diagonals)",
    "text": "Roberts Cross Operator (2×2, Diagonals)\n\n\nKernels\n\\[\nK_{x}=\n\\begin{bmatrix}\n1&0\\\\\n0&-1\n\\end{bmatrix},\\quad\nK_{y}=\n\\begin{bmatrix}\n0&1\\\\\n-1&0\n\\end{bmatrix}\n\\]\n\nPurpose: Diagonal gradient (45°/135°). Effect: Detects diagonal edges quickly. Notes: Very noise-sensitive; useful in real-time or hardware systems due to small size."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#emboss-directional-relief",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#emboss-directional-relief",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Emboss (Directional Relief)",
    "text": "Emboss (Directional Relief)\n\n\nKernel\n\\[\nK_{\\text{emboss}}=\n\\begin{bmatrix}\n-2&-1&0\\\\\n-1&1&1\\\\\n0&1&2\n\\end{bmatrix}\n\\]\n\nPurpose: Simulate relief under oblique lighting. Effect: Produces shadows and highlights (3D appearance). Notes: Requires recentering/normalization to avoid brightness shift."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-8",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-8",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: Gonzalez, Rafael C., y Richard E. Woods. Digital Image Processing. New York, NY: Pearson, 2018."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-9",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#neighborhood-operations-9",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Neighborhood operations",
    "text": "Neighborhood operations\n\nTaken from: http://datagenetics.com/blog/august32013/index.html"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge dection",
    "text": "Edge dection"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge dection",
    "text": "Edge dection"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#edge-dection-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge dection",
    "text": "Edge dection\n\nImages Grad YImages Grad XImages Grad Trunc YImages Trunc Grad XCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndst = cv2.Sobel(elderly_gray, cv2.CV_16S, 1, 0,  ksize=3, scale=1, delta=0, borderType= cv2.BORDER_DEFAULT)\ndst1 = np.uint8(255*dst/np.max(dst))\nplt.imshow(dst1, cmap=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram",
    "text": "Histogram\n\nHistogramCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"gray\")"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-2",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram",
    "text": "Histogram\n\nFirst thing to doImageCodeRecommended Reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\n3\n2\n2\n1\n1\n0\n3\n0\n1\n\n\n2\n2\n2\n3\n2\n2\n0\n2\n2\n1\n\n\n0\n3\n2\n0\n1\n1\n3\n1\n1\n1\n\n\n3\n0\n2\n0\n2\n3\n1\n0\n2\n1\n\n\n2\n2\n0\n0\n3\n1\n3\n1\n3\n1\n\n\n3\n3\n2\n0\n3\n0\n3\n2\n0\n3\n\n\n3\n3\n1\n1\n2\n3\n0\n3\n1\n3\n\n\n3\n1\n3\n3\n2\n0\n3\n0\n2\n1\n\n\n2\n1\n1\n3\n3\n1\n3\n2\n2\n1\n\n\n0\n3\n2\n2\n1\n1\n0\n0\n0\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\n\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"red\")\nplt.show()\n\n\n\ncv2.calcHist(images, channels, mask, histSize, ranges)\nHelp Docs Opencv"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-3",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram",
    "text": "Histogram\n\nImagesCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef adjust_gamma(image, gamma=1.0):\n   invGamma = 1.0 / gamma\n   table = np.array([((i / 255.0) ** invGamma) * 255\n      for i in np.arange(0, 256)]).astype(\"uint8\")\n\n   return cv2.LUT(image, table)\n\nelderly = cv2.imread(\"../../recursos/imagenes/Presentaciones/PSIM/elderly.jpg\")\nelderly_gray = cv2.cvtColor(elderly, cv2.COLOR_BGR2GRAY)\nplt.imshow(elderly_gray, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist = cv2.calcHist(elderly_gray, [0], None, [256], [0,256])\nplt.plot(elderly_hist, color=\"red\")\nplt.show()\nelderly_gray_light = adjust_gamma(image=elderly_gray, gamma=2)\nplt.imshow(elderly_gray_light, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_light = cv2.calcHist(elderly_gray_light, [0], None, [256], [0,256])\nplt.plot(elderly_hist_light, color=\"red\")\nplt.show()\nelderly_gray_dark = adjust_gamma(image=elderly_gray, gamma=0.3)\nplt.imshow(elderly_gray_dark, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_dark = cv2.calcHist(elderly_gray_dark, [0], None, [256], [0,256])\nplt.plot(elderly_hist_dark, color=\"red\")\nplt.show()\nelderly_gray_lowcontrast=np.uint8(0.1*elderly_gray)+172\nplt.imshow(elderly_gray_lowcontrast, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\nelderly_hist_lowcontrast = cv2.calcHist(elderly_gray_lowcontrast, [0], None, [256], [0,256])\nplt.plot(elderly_hist_lowcontrast, color=\"red\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram Equalization",
    "text": "Histogram Equalization\n\n\n\n\n\n\n\nAlgorithm\n\n\n\nCalculate Histogram: Calculate the histogram of the original image, showing the frequency distribution of each intensity level.\nCalculate Cumulative Distribution Function (CDF): Calculate the cumulative distribution function (CDF) of the histogram. The CDF represents the cumulative sum of frequencies for each intensity level.\nEqualization: For each pixel in the original image, calculate the new intensity value using the formula: \\[New_value = (CDF(old value) * (L-1))\\] where L is the number of intensity levels (e.g., 256 for an 8-bit image).\nAssign New Values: Assign the new intensity values calculated in step 3 to the equalized image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization-1",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-equalization-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram Equalization",
    "text": "Histogram Equalization\n\nImagesCodeRecommended Reading\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.imshow(elderly_gray_lowcontrast, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\nplt.plot(elderly_hist_lowcontrast, color=\"red\")\nplt.show()\n\nelderly_hist_equ = cv2.equalizeHist(elderly_gray_lowcontrast)\nplt.imshow(elderly_hist_equ, cmap=\"gray\", vmin=0, vmax=255)\nplt.show()\n\nelderly_hist_equ = cv2.calcHist(elderly_hist_equ, [0], None, [256], [0,256])\nplt.plot(elderly_hist_equ, color=\"red\")\nplt.show()\n\n\n\nHistogram Equalization OPENCV tutorial"
  },
  {
    "objectID": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-matching",
    "href": "presentaciones/PSIM/Lect005_Imag_Proc_001.html#histogram-matching",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Histogram Matching",
    "text": "Histogram Matching\n\nExplainAlgorithmResultCode\n\n\n\n\n\nTaken from PyImageSearch\n\n\n\n\nStep 1: Calculate Histograms Compute the histograms of the source image (Hs) and target image (Ht) for intensity values (r).\nStep 2: Calculate CDFs Compute the cumulative distribution functions (CDFs) for the source image (CDFs) and target image (CDFt).\nStep 3: Establish Correspondence Find the corresponding intensity values between the source and target images using the inverse CDF of the target image.\nStep 4: Apply Transformation Apply the intensity transformation to the source image using the established correspondence.\nStep 5: Verify Similarity Calculate the mean absolute difference between the transformed source image and the target image to verify their similarity.\n\n\n\n\n\n\n\n\n\n\n\n(np.float64(-0.5), np.float64(1199.5), np.float64(799.5), np.float64(-0.5))\n\n\n\n\n\n\n\n\n\nDiferencia media absoluta: 4.501011458333333\n\n\n\n\n\n# Cargar la imagen fuente y objetivo\nimg_s = cv2.imread('imagen_fuente.jpg')\nimg_t = cv2.imread('imagen_objetivo.jpg')\n\n# Calcula los histogramas\nhist_s = cv2.calcHist([img_s], [0], None, [256], [0, 256])\nhist_t = cv2.calcHist([img_t], [0], None, [256], [0, 256])\n\n# Calcula las CDF\ncdf_s = np.cumsum(hist_s)\ncdf_t = np.cumsum(hist_t)\n\n# Establece la correspondencia\nr_t = np.interp(cdf_s, cdf_t, np.arange(256))\n\n# Aplica la transformación\nimg_t_match = cv2.LUT(img_s, r_t)\n\n# Verifica la similitud\ndiff = np.mean(np.abs(img_t_match - img_t))\n\nprint(f'Diferencia media absoluta: {diff}')"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#what-is-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#what-is-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is Thresholding?",
    "text": "What is Thresholding?\n\nDefinition: A technique to separate objects from the background in images.\nConcept: Converting a grayscale image into a binary image.\nImportance: Simplification for further analysis (e.g., edge detection, segmentation)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#global-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#global-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Global Thresholding",
    "text": "Global Thresholding\n\nExplanation of Global Thresholding.\nExample of a fixed threshold ( T ):\n\nIf ( I(x, y) &gt; T ), the pixel becomes white (1), otherwise black (0).\n\nLimitations: Sensitivity to uneven lighting."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#adaptive-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#adaptive-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Adaptive Thresholding",
    "text": "Adaptive Thresholding\n\nDefinition of Adaptive Thresholding.\nInstead of a global threshold, the threshold is calculated for different regions of the image.\nAdvantages: Effective in images with varying illumination.\nAlgorithm: Example of an adaptive method based on the local mean of neighboring pixels."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#otsus-algorithm",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#otsus-algorithm",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Otsu’s Algorithm",
    "text": "Otsu’s Algorithm\n\nExplanation of Otsu’s Algorithm.\n\nAutomatic global thresholding that minimizes the within-class variance.\n\nSteps of the algorithm:\n\nCompute image histograms.\nEvaluate the between-class variance function for every possible threshold.\nSelect the threshold that minimizes the within-class variance.\n\nAdvantages: Automatic and effective in bimodal images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#justification-for-using-thresholding",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#justification-for-using-thresholding",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Justification for Using Thresholding",
    "text": "Justification for Using Thresholding\n\nWhen thresholding is useful:\n\nImages with a clear contrast between the object and the background.\nSituations requiring quick segmentation.\n\nExample applications:\n\nText detection, object recognition, medical images (e.g., X-rays).\n\nLimitations: Less effective in noisy or low-quality images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#comparison-of-thresholding-algorithms",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#comparison-of-thresholding-algorithms",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Comparison of Thresholding Algorithms",
    "text": "Comparison of Thresholding Algorithms\n\n\n\n\n\n\n\n\n\n\nMethod\nPrecision\nProcessing Speed\nEase of Implementation\nTypical Applications\n\n\n\n\nGlobal Threshold\nMedium\nFast\nSimple\nHigh-contrast images\n\n\nAdaptive Threshold\nHigh\nModerate\nModerate\nUnevenly lit images\n\n\nOtsu’s Algorithm\nHigh\nModerate\nModerate\nBimodal distributions"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nShow examples of original images and the result after applying:\n\nGlobal Thresholding.\nAdaptive Thresholding.\nOtsu’s Algorithm.\n\nVisualizations highlighting the differences."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples-1",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#practical-examples-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nResultsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.imshow(image_circle, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nplt.imshow(image_gradient, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nplt.imshow(noisy_circle, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh1 = cv2.threshold(image_circle, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh1, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh2 = cv2.threshold(image_gradient, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, global_thresh3 = cv2.threshold(noisy_circle, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(global_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh1 = cv2.adaptiveThreshold(image_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh1, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh2 = cv2.adaptiveThreshold(image_gradient, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\nadaptive_thresh3 = cv2.adaptiveThreshold(noisy_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\nplt.imshow(adaptive_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, otsu_thresh1 = cv2.threshold(image_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh1, cmap=\"gray\")\nplt.axis(\"off\");\nplt.show()\n\n_, otsu_thresh2 = cv2.threshold(image_gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh2, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n\n_, otsu_thresh3 = cv2.threshold(noisy_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.imshow(otsu_thresh3, cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#conclusion-and-questions",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#conclusion-and-questions",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Conclusion and Questions",
    "text": "Conclusion and Questions\n\nSummary of key points:\n\nThresholding as a simple yet powerful technique.\nImportance of choosing the right algorithm depending on the context.\nOtsu’s algorithm as an effective solution for bimodal images."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-morphological-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction to Morphological Operations",
    "text": "Introduction to Morphological Operations\n\nDefinition: Morphological operations apply a structuring element to an image to alter its structure.\nFocus: Primarily used for binary images.\nKey applications: Noise removal, object extraction, shape analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#structuring-element",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#structuring-element",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Structuring Element",
    "text": "Structuring Element\n\nA small matrix used to probe and interact with a given image.\nCommon shapes: Rectangular, circular, elliptical.\nExample: A 3x3 square structuring element.\n\n\\[\\begin{bmatrix}\n  1 & 1 & 1 \\\\\n  1 & 1 & 1 \\\\\n  1 & 1 & 1 \\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#common-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#common-morphological-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Common Morphological Operations",
    "text": "Common Morphological Operations\n\nErosion:\n\nRemoves pixels on object boundaries.\nShrinks the size of objects in the image.\nUsed to eliminate small noise or detach connected objects.\n\nDilation:\n\nAdds pixels to object boundaries.\nEnlarges the object in an image.\nHelps fill small holes and gaps within objects.\n\nOpening:\n\nErosion followed by dilation.\nUsed to remove small objects (noise) while maintaining the shape of larger objects.\n\nClosing:\n\nDilation followed by erosion.\nFills small holes and gaps in an object’s boundaries.\n\nTop-Hat Transformation:\n\nThe difference between the original image and its opening.\nUsed to highlight bright regions on a dark background.\nDetecting small, bright objects or details in an unevenly illuminated image.\n\nBlack-Hat Transformation:\n\nThe difference between the closing of an image and the original image.\nUsed to highlight dark regions on a bright background.\nEmphasizing dark objects or shadows in an image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#example-of-morphological-operations",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#example-of-morphological-operations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Example of Morphological Operations",
    "text": "Example of Morphological Operations"
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-frequency-response",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#introduction-to-frequency-response",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction to Frequency Response",
    "text": "Introduction to Frequency Response\n\nWhat is Frequency Response?\n\nThe frequency response of an image shows how spatial details in the image are distributed across different frequencies.\nIn image processing, this is typically analyzed using the Fourier Transform.\n\nWhy Frequency Analysis?\n\nUseful for identifying patterns, noise, and image structures not easily observed in the spatial domain."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-fourier-transform",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-fourier-transform",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The Fourier Transform",
    "text": "The Fourier Transform\n\nFourier Transform (FT):\n\nConverts an image from the spatial domain (pixels) to the frequency domain (sinusoids).\nEach point in the frequency domain represents a specific frequency in the image.\n\nMathematical Basis:\n\n\\(F(u,v) = \\sum_x \\sum_y f(x,y) e^{-j 2 \\pi (ux/M + vy/N)}\\)\nWhere \\(F(u,v)\\) is the frequency representation of the image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-and-high-frequencies",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-and-high-frequencies",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low and High Frequencies",
    "text": "Low and High Frequencies\n\nLow Frequencies:\n\nRepresent slow variations or large structures in the image (e.g., background or smooth gradients).\n\nHigh Frequencies:\n\nRepresent rapid variations or fine details (e.g., edges, noise).\n\nKey Insight: Most of the important structural information in an image is captured in the low-frequency range."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-domain-representation",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-domain-representation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Frequency Domain Representation",
    "text": "Frequency Domain Representation\n\nThe Fourier Transform of an image produces a frequency spectrum.\nDC Component (center of the spectrum): Represents the average intensity of the image.\nHigher frequencies: Spread out from the center and capture finer details.\nLogarithmic scale: Often used to visualize the frequency spectrum due to the wide range of values."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-2d-discrete-fourier-transform-dft",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#the-2d-discrete-fourier-transform-dft",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The 2D Discrete Fourier Transform (DFT)",
    "text": "The 2D Discrete Fourier Transform (DFT)\n\nThe 2D DFT is used to convert a 2D image into its frequency components:\n\nInput: A 2D grayscale image.\nOutput: A complex matrix representing amplitude and phase for each frequency.\n\nInverse DFT: Converts the frequency representation back to the spatial domain."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-pass-and-high-pass-filtering",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#low-pass-and-high-pass-filtering",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low-Pass and High-Pass Filtering",
    "text": "Low-Pass and High-Pass Filtering\n\nLow-Pass Filter (LPF):\n\nAllows low frequencies to pass, attenuates high frequencies.\nUsed to blur images, removing high-frequency details like noise and edges.\n\nHigh-Pass Filter (HPF):\n\nAllows high frequencies to pass, attenuates low frequencies.\nUsed to sharpen images by enhancing edges and fine details."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#band-pass-filtering",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#band-pass-filtering",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Band-Pass Filtering",
    "text": "Band-Pass Filtering\n\nBand-Pass Filter:\n\nAllows frequencies within a certain range (band) to pass.\nUseful for selectively enhancing specific frequency components while filtering others.\n\nApplications: Used in image enhancement and texture analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-response-visualization",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#frequency-response-visualization",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Frequency Response Visualization",
    "text": "Frequency Response Visualization\n\nMagnitude Spectrum:\n\nRepresents the amplitude of each frequency component.\nTypically visualized using the logarithmic scale to manage the large range of values.\n\nPhase Spectrum:\n\nRepresents the phase of each frequency component.\nLess important for human perception but crucial for reconstructing the image."
  },
  {
    "objectID": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#applications-of-frequency-domain-processing",
    "href": "presentaciones/PSIM/Lect006_Imag_Proc_002.html#applications-of-frequency-domain-processing",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Applications of Frequency Domain Processing",
    "text": "Applications of Frequency Domain Processing\n\nNoise Removal: Low-pass filters can smooth out high-frequency noise.\nEdge Detection: High-pass filters enhance edges and sharp transitions.\nImage Compression: Frequency domain analysis helps identify redundant information.\nPattern Recognition: Useful for detecting repetitive patterns like textures."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\n\nBio - That came from a biological being\nSignal - A signal is a function that conveys information about a physical phenomenon.\nBiosignals - The search for information from living systems to know its health state"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\nThe codification of biosignals into variations: * Electrical * Mechanical * Chemical * Thermal"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#introduction-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1791: Luigi Galvani discovers electrical signals in living tissues (frog legs)\n1830s: Carlo Matteucci studies electrical signals in the heart\n1887: Willem Einthoven invents the first electrocardiograph (ECG)\n1900s: James Mackenzie develops the first clinical ECG machine"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1920s: Electroencephalography (EEG) is developed by Hans Berger\n1930s: Electromyography (EMG) is developed by John Humphrey and others\n1940s: Development of the first commercial ECG machines\n1950s: Signal processing techniques are applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1960s: Digital signal processing and computer analysis of biomedical signals emerge\n1970s: Biomedical signal processing becomes a recognized field\n1980s: Development of Holter monitoring (24-hour ECG)\n1990s: Advances in signal processing and machine learning applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n2000s: Development of wearable devices and mobile health (mHealth) technologies\n2010s: Emergence of big data analytics and cloud computing in biomedical signal processing\n2020s: Integration of artificial intelligence (AI) and machine learning (ML) in biomedical signal processing"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1895: Wilhelm Roentgen discovers X-rays, leading to medical imaging\n1900s: X-ray technology improves with development of modern X-ray tubes\n1913: Albert Salomon develops mammography\n1920s: Ultrasound technology is developed by Karl Dussik and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-5",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1930s: Nuclear medicine emerges with development of radioactive tracers\n1950s: Computed Tomography (CT) scans are developed by Godfrey Hounsfield and Allan McLeod Cormack\n1960s: Development of medical ultrasound imaging\n1970s: Magnetic Resonance Imaging (MRI) is developed by Richard Ernst and others"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-6",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1980s: Digital image processing and analysis techniques are applied to biomedical images\n1990s: Advances in MRI and CT scan technology, including 3D imaging\n2000s: Development of functional MRI (fMRI), diffusion tensor imaging (DTI), and other advanced MRI techniques\n2010s: Emergence of artificial intelligence (AI) and machine learning in medical imaging"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#time-line-7",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Time line",
    "text": "Time line\nAdditional Milestones:\n\n1950s: Development of medical electronics and instrumentation\n1960s: First medical imaging computers are developed\n1970s: Development of digital image processing and analysis software\n1980s: Emergence of medical imaging informatics and PACS (Picture Archiving and Communication Systems)\n1990s: Development of telemedicine and teleradiology\n2000s: Emergence of electronic health records (EHRs) and health information exchanges (HIEs)\n2010s: Development of personalized medicine and precision health initiatives"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\n\n\n\n\n\n\nDefinition\n\n\nAn experiment is a physical procedure that produces some kind of result.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAn event is a set of experiment’s possible results.\n\n\n\n\n\n\n\n\n\n\n\nConsejo\n\n\nA sample space is the set of ALL possibles results of an experiment."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#events-sample-space-experiments-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Events, Sample Space, Experiments",
    "text": "Events, Sample Space, Experiments\n\nGraphCodeSample SpaceResultDataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata = np.genfromtxt(\"../../data/mitbih_train.csv\", delimiter=\",\")\necg1 = data[1, :-1]\ntime = np.array(range(0,len(ecg1)))/125\nfig = plt.figure()\nplt.plot(time, ecg1)\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Normalized ECG\")\n\n\n\n\nprint(\"Maximun Value: \"+ str(ecg1.max()))\n\nMaximun Value: 1.0\n\nprint(\"Minimun Value: \"+ str(ecg1.min()))\n\nMinimun Value: 0.0\n\n\n\n\n\nprint(ecg1[np.random.choice(ecg1.shape[0], 1, replace=False)])\n\n[0.03988604]\n\n\n\n\nName: ECG Heartbeat Categorization Dataset.\nURL: https://www.kaggle.com/datasets/shayanfazeli/heartbeat?resource=download"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#probability-axioms",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Probability Axioms",
    "text": "Probability Axioms\nFor the given events A and B that are in a sample space S:\n\n\n\n\n\n\n\nAxioms\n\n\n\n\\(0 \\leq P_r \\left(A\\right) \\leq 1\\)\n\\(P_r\\left(S\\right) = 1\\)\nIf \\(A \\cap B = \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right)\\)\nIf \\(A \\cap B \\neq \\emptyset\\) then \\(P_r\\left(A \\cup B \\right) = P_r \\left(A\\right) + P_r \\left(B\\right) - P_r\\left(A \\cap B \\right)\\)\n\\(P_r\\left(\\bar{A}\\right) = 1-P_r \\left(A\\right)\\)\nIf \\(A\\subset B\\) then \\(P_r \\left(A\\right)\\leq P_r \\left(B\\right)\\)\n\\(P_r \\left(A|B\\right)=\\frac{P_r \\left(A\\cap B\\right)}{P_r \\left(B\\right)}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable\n\n\n\n\n\n\n\nDefinition\n\n\nA random variable is a real valued function of the elements of a sample space, S . Given an experiment, E , with sample space, S, the random variable maps each possible outcome of E.\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nThe probability mass function (PMF), \\(P_X\\left(x\\right)\\), of a random variable, X, is a function that assigns a probability to each possible value of the random variable, X."
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variable-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variable",
    "text": "Random Variable"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nConditions\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sum_{\\chi \\in X}P_X\\left(\\chi \\right) = 1\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\int_{-\\infty}^{\\infty}P_X\\left(\\chi \\right)d\\chi = 1\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nExpected Values\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\mu = \\sum_{\\chi \\in X}\\chi P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\mu=\\int_{-\\infty}^{\\infty}\\chi P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#random-variables-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Random Variables",
    "text": "Random Variables\nVariance\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\sigma^2 = \\sum_{\\chi \\in X}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)\\]\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous\n\n\n\\[\\sigma^2 = \\int_{-\\infty}^{\\infty}\\left(\\chi - \\mu \\right)^2 P_X\\left(\\chi \\right)d\\chi\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "href": "presentaciones/PSIM/Lect002_Intro_PSIM.html#pdf-estimation",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "PDF Estimation",
    "text": "PDF Estimation\n\nGraphCodeExp. ValueVariance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncounts01, bin_edges01 = np.histogram(ecg1, bins=10, density=True)\ncounts02, bin_edges02 = np.histogram(ecg1, bins=50, density=True)\ncounts03, bin_edges03 = np.histogram(ecg1, bins=100, density=True)\nfig01=plt.figure()\nplt.plot(bin_edges01[1:], counts01/sum(counts01), label=\"Estimation with 10 bins\")\nplt.plot(bin_edges02[1:], counts02/sum(counts02), label=\"Estimation with 50 bins\")\nplt.plot(bin_edges03[1:], counts03/sum(counts03), label=\"Estimation with 100 bins\")\nplt.legend()\nplt.grid()\nplt.xlabel(\"Normalised ECG Value\")\nplt.ylabel(\"Estimated PDF Value\")\n\n\n\n\n\n0.09001020772910533\n\n\n\n\n\n\n0.02551116143316462"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#el-profesor",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción al procesado de señales e imágenes biomédicas.\nFundamentos procesado de señales e imágenes biomédicas\nExtracción de características de señales biomédicas.\nExtracción de características de imágenes biomédicas."
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluación final\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nExamen parcial 1 (15%)\nExamen parcial 2 (15%)\nExamen final (20%)\nLaboratorios (30%)\nProyecto Final (20%)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#evaluación-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (15%)\nLaboratorios (15%)\nProyecto final (20%)\n\n\nExamen Parcial 1 (15%)\nExamen Parcial 2 (15%)\nExamen final (20%)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#recursos",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nLunes 2:30pm-4:00pm F-105. Martes 2:30pm-4:00pm D-201.\nLaboratorio\nJUEVES 2:30pm-4:00pm. I1-304\n\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/PSIM/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/PSIM/Lect001_Presentacion.html#bibliografía",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/PAIM/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/PAIM/Lect001_Presentacion.html#el-profesor",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/PAIM/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/PAIM/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción\nRayos X\nTomografía axial computarizada\nResonancia Magnética"
  },
  {
    "objectID": "presentaciones/PAIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/PAIM/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluación final\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/PAIM/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/PAIM/Lect001_Presentacion.html#evaluación",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nLaboratorios (60%)\nProyecto Final (40%)"
  },
  {
    "objectID": "presentaciones/PAIM/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/PAIM/Lect001_Presentacion.html#evaluación-1",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (30%)\nLaboratorios (30%)\nProyecto final (40%)"
  },
  {
    "objectID": "presentaciones/PAIM/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/PAIM/Lect001_Presentacion.html#recursos",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nLunes 2:30pm-4:00pm I1-304.\nMartes 2:30pm-4:00pm E-112.\n\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/PAIM/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/PAIM/Lect001_Presentacion.html#bibliografía",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-gran-pregunta",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-gran-pregunta",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "La Gran Pregunta",
    "text": "La Gran Pregunta\n\n\n\n\n\n\nNota\n\n\n\n¿Y si tu celular pudiera detectar una enfermedad cardíaca con solo tocarlo?\n¿Y si una computadora pudiera ver un tumor que el ojo humano más experto aún no distingue?\n\n\n\n\n\nImaginen por un momento… ¿Y si su celular pudiera detectar una enfermedad cardíaca con solo tocarlo? ¿Y si una computadora pudiera ver un tumor en una radiografía, incluso antes de que el ojo humano más experto lo note? Esto no es ciencia ficción. Es lo que hacemos todos los días en este campo. La pregunta no es ‘si’ es posible, sino ‘cómo’ lo hacemos posible."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#bienvenida",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#bienvenida",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Bienvenida",
    "text": "Bienvenida\nProcesamiento de señales e imágenes\nDe los sonidos y las fotos a la salud y la tecnología.\n\nGuion: Preguntar a los estudiantes: ¿Qué señales usan sin darse cuenta? (Wi-Fi, música, ritmo del corazón). Explicar que hoy aprenderán a mirar cómo las computadoras entienden esas señales e imágenes."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestro-viaje-de-hoy",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestro-viaje-de-hoy",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Nuestro Viaje de Hoy",
    "text": "Nuestro Viaje de Hoy\n\nLos Lenguajes Secretos del Cuerpo: Descubriremos las señales eléctricas que nos mantienen vivos.\nUna Imagen Vale Más que Mil Pruebas: Veremos cómo convertimos el interior del cuerpo en imágenes.\nEl Truco de Magia: ‘Procesar’: Aprenderemos a limpiar y mejorar estos datos para encontrar pistas.\n¡Tu Turno! Conviértete en Ingeniero/a Biomédico/a: Realizarán análisis reales en nuestro laboratorio digital.\n\n\nPara entender cómo funciona esta ‘magia’, nuestro viaje de hoy tendrá cuatro paradas. Primero, descifraremos los lenguajes secretos del cuerpo, las señales eléctricas. Luego, veremos cómo creamos imágenes del interior de nuestro cuerpo. Después, revelaremos el truco de magia que llamamos ‘procesamiento’ para limpiar y mejorar estos datos. Y finalmente, la parte más emocionante: ustedes mismos se convertirán en ingenieros y realizarán análisis en nuestro laboratorio digital."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#qué-es-una-señal-información-en-movimiento",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#qué-es-una-señal-información-en-movimiento",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "¿Qué es una Señal? Información en Movimiento",
    "text": "¿Qué es una Señal? Información en Movimiento\n\n\n\n\n\nUna señal es simplemente información que cambia con el tiempo.\n\n\n\n\n\nEmpecemos por lo básico. ¿Qué es una señal? Es simplemente información que cambia con el tiempo. Piensen en la música: las notas suben y bajan, creando una melodía. Eso es una señal. O la temperatura a lo largo de un día: sube al mediodía y baja por la noche. En el cuerpo, en lugar de notas o grados, medimos cosas como la actividad eléctrica, que sube y baja de formas muy específicas."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-sinfonía-eléctrica-del-cuerpo",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-sinfonía-eléctrica-del-cuerpo",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "La Sinfonía Eléctrica del Cuerpo",
    "text": "La Sinfonía Eléctrica del Cuerpo\n\n\nEl Electrocardiograma (ECG) es el ritmo del corazón, nuestro tambor principal.\n\n\n\n\n\nSeñal de ECG ideal, mostrando el patrón rítmico del corazón.\n\n\n\n\n\n¿Qué nos dice el ECG?\n\n¿Cuál es el ritmo cardíaco?\n¿El corazón late muy rápido o muy lento?\n¿Hay alguna parte que no funciona en armonía?\nPermite diagnosticar problemas y salvar vidas.\n\n\n\nNuestro cuerpo es como una orquesta eléctrica. El corazón es el tambor, marcando un ritmo constante y poderoso. La señal que produce se llama Electrocardiograma o ECG. El cerebro es como la sección de cuerdas, con miles de neuronas ‘hablando’ a la vez en una conversación compleja. Esa señal es el Electroencefalograma o EEG. Escuchando estas ‘melodías’, los médicos pueden saber si todo funciona en armonía."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desafío-encontrar-la-señal-en-el-ruido",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desafío-encontrar-la-señal-en-el-ruido",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "El Desafío: Encontrar la Señal en el Ruido",
    "text": "El Desafío: Encontrar la Señal en el Ruido\n\n\n\n\n\nUna señal de ECG real a menudo está contaminada con ruido.\n\n\n\n\n\nPero en el mundo real, estas señales no son tan claras. Imaginen tratar de escuchar a un amigo en una fiesta muy ruidosa. El ‘ruido’ es todo lo que interfiere: otros aparatos eléctricos, el movimiento del paciente, etc. Este ruido puede ocultar información vital que el médico necesita ver. Como ven aquí, el patrón claro del latido casi ha desaparecido."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-solución-cancelación-de-ruido-digital",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-solución-cancelación-de-ruido-digital",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "La Solución: Cancelación de Ruido Digital",
    "text": "La Solución: Cancelación de Ruido Digital\n\n\nSeñal Ruidosa (Original)\n\n\n\n\n\n\n\n\n\n\nSeñal Filtrada (Limpia)\n\n\n\n\n\n\n\n\n\n\n\nAquí es donde entra nuestra ‘magia’. Usamos algoritmos de ‘filtrado’. Es como ponerse unos audífonos con cancelación de ruido. La computadora mira cada punto de la señal y lo promedia con sus vecinos de una manera inteligente. El ruido, al ser aleatorio y rápido, se cancela, ¡pero el patrón real del latido, que es más lento y repetitivo, se mantiene! Así ‘rescatamos’ la información importante, como pueden ver en la gráfica de la derecha. Pasamos de algo ilegible a una señal clara y diagnóstica."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#qué-es-una-imagen-una-pintura-por-números",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#qué-es-una-imagen-una-pintura-por-números",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "¿Qué es una Imagen? Una Pintura por Números",
    "text": "¿Qué es una Imagen? Una Pintura por Números\n\n\nLos Números (Píxeles)\n\n\n\n\n\nMatriz de números que representa una imagen simple.\n\n\n\n\n\nLa Imagen Resultante\n\n\n\n\n\nLa imagen en escala de grises generada por la matriz de números.\n\n\n\n\n\n\nAhora hablemos de imágenes. Para una computadora, una imagen no es una foto, es una cuadrícula gigante de números. ¡Como un lienzo para pintar por números! Cada número representa el brillo de un puntito llamado ‘píxel’. Un número bajo como 0 puede ser negro, un número alto como 255 puede ser blanco, y los números intermedios son todos los tonos de gris. A la izquierda ven los números, y a la derecha, la imagen que la computadora crea a partir de ellos."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#una-ventana-hacia-el-cuerpo",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#una-ventana-hacia-el-cuerpo",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Una Ventana Hacia el Cuerpo",
    "text": "Una Ventana Hacia el Cuerpo\n\n\nRadiografía (Rayos X) Ideal para ver estructuras densas como los huesos.\n\n\n\n\n\nEjemplo de una radiografía de tórax.\n\n\n\n\n\nResonancia Magnética (MRI) Perfecta para ver tejidos blandos como el cerebro.\n\n\n\n\n\nEjemplo de una resonancia magnética cerebral.\n\n\n\n\n\n\nCon esta idea, podemos crear ventanas increíbles hacia el interior del cuerpo. Las Radiografías (Rayos X) son como la sombra del cuerpo; son excelentes para ver cosas densas como los huesos. Las Resonancias Magnéticas (MRI) son diferentes; crean un mapa detallado del agua en nuestro cuerpo, lo que las hace perfectas para ver tejidos blandos como el cerebro, los músculos o los órganos."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desafío-hacer-visible-lo-invisible",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#el-desafío-hacer-visible-lo-invisible",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "El Desafío: Hacer Visible lo Invisible",
    "text": "El Desafío: Hacer Visible lo Invisible\n\n\n\n\n\nUna imagen médica con bajo contraste donde los detalles son difíciles de ver.\n\n\n\n\n\nA veces, la información que buscamos en una imagen médica es muy sutil. Puede ser como tratar de encontrar a un amigo en una foto muy oscura o con mucha niebla. El contraste puede ser bajo, o los bordes entre un tejido sano y uno enfermo pueden ser borrosos. El ojo humano puede pasar por alto estos detalles cruciales."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-solución-resaltadores-digitales",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#la-solución-resaltadores-digitales",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "La Solución: Resaltadores Digitales",
    "text": "La Solución: Resaltadores Digitales\n\n\nImagen Original\n\n\n\n\n\n\n\n\n\n\nImagen Mejorada\n\n\n\n\n\n\n\n\n\n\n\n¡De nuevo, el procesamiento viene al rescate! Podemos darle ‘superpoderes’ a la imagen. Con el ajuste de contraste, le decimos a la computadora: ‘haz que las partes oscuras sean más oscuras y las claras más claras’, ¡como ajustar el brillo en Instagram! Fíjense cómo en la imagen de la derecha, los detalles que antes estaban ocultos ahora son perfectamente visibles. Otra técnica es la detección de bordes, que dibuja una línea donde hay un cambio brusco de brillo, ayudando a los médicos a ver la forma exacta de los órganos o tumores."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#áreas-de-aplicación-del-procesamiento-de-señales-e-imágenes",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#áreas-de-aplicación-del-procesamiento-de-señales-e-imágenes",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Áreas de aplicación del procesamiento de señales e imágenes",
    "text": "Áreas de aplicación del procesamiento de señales e imágenes\n\n\n\nDiagnóstico automatizado\nIdentificación de enfermedades en ECG, EEG o imágenes médicas.\nMonitoreo en tiempo real\nVigilancia en UCI con señales continuas de corazón, respiración y cerebro.\nTelemedicina\nTransmisión y compresión de señales para consultas a distancia.\nRehabilitación y prótesis inteligentes\nUso de señales EMG para controlar prótesis y exoesqueletos.\n\n\n\nDetección temprana de eventos críticos\nAnticipación de arritmias, crisis epilépticas o caídas.\nBiometría y seguridad\nReconocimiento de voz, rostro o iris.\nImagenología avanzada\nSegmentación de órganos o tumores en 3D para cirugía o radioterapia.\nEntretenimiento y multimedia\nFiltros en fotos y videos, mejora de audio y realidad aumentada.\n\n\n\nGuion: resaltar que la mitad de las aplicaciones impacta directamente en salud y la otra mitad en la vida cotidiana. Pedir a los estudiantes que piensen en qué columna usan más sin darse cuenta."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Plataforma para el monitoreo de salud de adultos mayores",
    "text": "Plataforma para el monitoreo de salud de adultos mayores\n\nDetección ambulatoria de actividades diarias.\nDetección ambulatoria de riesgo de caída.\nDetección ambulatoria de riesgo neuronal.\nDetección ambulatoria de riesgo psico-social.\nDetección ambulatoria de riesgo cardíaco\nMonitorización de terapias ambulatorias para la rehabilitación de adultos mayores"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#creación-de-ambientes-de-habitación-saludables-usando-realimentación-sensorial",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#creación-de-ambientes-de-habitación-saludables-usando-realimentación-sensorial",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Creación de ambientes de habitación saludables usando realimentación sensorial",
    "text": "Creación de ambientes de habitación saludables usando realimentación sensorial\n\nNeurofeedback emocional usando música.\nNeurofeedback de memoria procedimental.\nNeurofeedback en automotores.\nMonitorización ambulatoria de estado emocional.\nMonitorización ambulatoria de terapias emocionales"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#apoyo-tecnológico-mediante-ia-a-intervenciones-clínicas",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#apoyo-tecnológico-mediante-ia-a-intervenciones-clínicas",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Apoyo tecnológico mediante IA a intervenciones clínicas",
    "text": "Apoyo tecnológico mediante IA a intervenciones clínicas\n\nDetección de anomalías en imágenes mediante segmentación heurística.\nPlaneación pre-operatoria mediante el uso de inteligencia artificial.\nEvaluación de espasticidad mediante el uso tecnología."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#detección-de-información-en-terapias-y-proyectos-de-rehabilitación",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#detección-de-información-en-terapias-y-proyectos-de-rehabilitación",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Detección de información en terapias y proyectos de rehabilitación",
    "text": "Detección de información en terapias y proyectos de rehabilitación\n\nGeneración de interfaces cerebro-computador\nGeneración de algoritmos de clasificación de intención de movimiento\nMonitorización de terapias de rehabilitación."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#invitación",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#invitación",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Invitación",
    "text": "Invitación\n\nInvitación"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestras-herramientas",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#nuestras-herramientas",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Nuestras Herramientas",
    "text": "Nuestras Herramientas\nVamos a usar este mismo documento como nuestro cuaderno de laboratorio digital.\n\nVerán bloques de código en Python.\nNo necesitan ser expertos. El código ya está escrito.\nSu misión: ejecutarlo (con el botón de play ►), observar los resultados e incluso experimentar cambiando algunos valores.\n\n¡Vamos a hacer ciencia de verdad!\n\n¡Suficiente teoría! Es hora de que se pongan la bata de laboratorio. Vamos a usar este mismo documento como nuestro ‘cuaderno de laboratorio digital’. Verán bloques de código en Python. No se asusten, no necesitan ser expertos. El código ya está escrito. Su misión es ejecutarlo, observar los resultados e incluso experimentar cambiando algunas cosas. ¡Vamos a hacer ciencia de verdad!"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-1-de-números-a-dibujos",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-1-de-números-a-dibujos",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Misión 1: ¡De Números a Dibujos! 📝",
    "text": "Misión 1: ¡De Números a Dibujos! 📝\nObjetivo: Comprender que las imágenes son, en el fondo, solo listas de números e instrucciones.\nMateriales: Una hoja de papel cuadriculado y un lápiz.\nInstrucciones (Parte A - La Imagen Misteriosa):\nEn una hoja resalta los números pares y los primos permitiendo ver el mensaje secreto."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-2-de-números-a-dibujos",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-2-de-números-a-dibujos",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Misión 2: ¡De Números a Dibujos! 📝",
    "text": "Misión 2: ¡De Números a Dibujos! 📝\nObjetivo: Comprender que las señales e imágenes son, en el fondo, solo listas de números e instrucciones.\nMateriales: Una hoja de papel cuadriculado y un lápiz.\nInstrucciones (Parte A - La Señal Misteriosa):\n\nEn tu hoja, dibuja un eje: el horizontal se llama “Tiempo” (de 1 a 10) y el vertical “Valor” (de 1 a 10).\nTe daré pares de números (Tiempo, Valor). Dibuja un punto en cada coordenada.\nCoordenadas: (1, 2), (2, 4), (3, 6), (4, 8), (5, 6), (6, 4), (7, 2), (8, 4), (9, 6), (10, 8).\nUne los puntos en orden. ¿Qué letra o forma simple has dibujado?\n\nInstrucciones (Parte B - La Imagen Secreta):\n\nEn otra parte de tu hoja, dibuja una cuadrícula de 8x8.\nTe daré coordenadas (fila, columna) que debes rellenar o colorear. La fila 1 es la de arriba, la columna 1 es la de la izquierda.\nPíxeles a colorear:\n\nFila 2: Columnas 3, 4, 5, 6\nFila 3: Columnas 2, 7\nFila 4: Columnas 2, 4, 5, 7\nFila 5: Columnas 2, 7\nFila 6: Columnas 3, 6\nFila 7: Columnas 4, 5\n\nAléjate un poco… ¿Qué imagen has creado?"
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-3-rescatar-un-latido",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-3-rescatar-un-latido",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Misión 3: Rescatar un Latido",
    "text": "Misión 3: Rescatar un Latido\nEl Reto: Hemos recibido la señal de ECG de un paciente, pero está llena de ruido. Es imposible para un médico leerla así.\nTu Tarea: Ejecuta el código de abajo para aplicar un filtro digital y limpiar la señal. ¡El diagnóstico del paciente depende de ti!\n\n\nMostrando la señal original recibida del paciente...\n\n\n\n\n\n\n\n\n\n\n¡Filtro aplicado! Mostrando la señal recuperada..."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-4-mapear-el-cerebro",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#misión-4-mapear-el-cerebro",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Misión 4: Mapear el Cerebro",
    "text": "Misión 4: Mapear el Cerebro\nEl Reto: Tenemos una imagen de resonancia magnética. Para estudiarla, un neurólogo necesita ver claramente los contornos de las diferentes estructuras.\nTu Tarea: Ejecuta el código para aplicar un filtro de ‘detección de bordes’ y crear un mapa de los contornos del cerebro.\n\n\nCargando imagen de resonancia magnética...\n¡Filtro de bordes aplicado! Mostrando comparación..."
  },
  {
    "objectID": "presentaciones/TALLERES/TallerPrimerSemestre.html#preguntas",
    "href": "presentaciones/TALLERES/TallerPrimerSemestre.html#preguntas",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "¿Preguntas?",
    "text": "¿Preguntas?\n¡Gracias!\n\nGracias por su atención y su excelente trabajo como ingenieros. Ahora, me encantaría responder a cualquier pregunta que tengan."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#what-is-a-signal",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#what-is-a-signal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "What is a signal?",
    "text": "What is a signal?\n\nA signal is a function that conveys information by mapping an independent variable (or variables) to measurable quantities.\nFormally, a signal is a mapping \\(x:\\ \\mathcal{T}\\rightarrow\\mathcal{A}\\), where \\(\\mathcal{T}\\) is the domain (e.g., time \\(t\\in\\mathbb{R}\\) or sample index \\(n\\in\\mathbb{Z}\\)) and \\(\\mathcal{A}\\) is the codomain (e.g., amplitudes in \\(\\mathbb{R}\\) or \\(\\mathbb{C}\\), vectors, or matrices)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification",
    "text": "Signal Classification"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-bounded",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-bounded",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification – Bounded",
    "text": "Signal Classification – Bounded"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-compact-support",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-compact-support",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification – Compact Support",
    "text": "Signal Classification – Compact Support"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-causal",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-causal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification – Causal",
    "text": "Signal Classification – Causal"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---deterministic-vs-random-signals",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---deterministic-vs-random-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification - Deterministic vs Random Signals",
    "text": "Signal Classification - Deterministic vs Random Signals\n\nA deterministic signal \\(x_d(t)\\) is completely specified by an explicit rule; it produces the same waveform on every observation (e.g., \\(x_d(t)=A\\cos(2\\pi f_0 t+\\phi)\\)).\nA random signal (stochastic process) \\(X(t)\\) is a family of random variables indexed by \\(t\\); each observation yields a different realization. It is characterized statistically by its mean \\(\\mu_X(t)\\) and autocorrelation \\(R_X(\\tau)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---evenodd",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---evenodd",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification - Even/Odd",
    "text": "Signal Classification - Even/Odd\n\n\n\n\n\n\n\n\n\nEven\n\n\n\\[f\\left(t\\right) = f\\left(-t\\right)\\] \\[f\\left[t\\right] = f\\left[-t\\right]\\]\n\n\n\n\n\n\n\n\n\n\n\nOdd\n\n\n\\[f\\left(t\\right) = -f\\left(-t\\right)\\] \\[f\\left[t\\right] = -f\\left[-t\\right]\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-1",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification",
    "text": "Signal Classification\n\n\n\n\n\n\n\nDecomposition\n\n\nAll signal can be decomposed in two signals: one even, one odd.\n\\[x(t) = x_{even}(t) + x_{odd}(t)\\]\n\n\n\n\nWhere:\n\\[x_{even}(t) = \\frac{x(t)+x(-t)}{2} \\] \\[x_{odd}(t) = \\frac{x(t)-x(-t)}{2} \\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\n\n\n\n\n\n\n\nExample\n\n\nDecompose the signal \\(x(t)=e^{t}\\) into its even and odd parts"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-1",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\n\\[x_{\\text{even}}(t) = \\frac{x(t) + x(-t)}{2}\\]\n\\[x_{\\text{odd}}(t) = \\frac{x(t) - x(-t)}{2}\\]\n\\[x(-t) = e^{-t}\\]\n\\[x_{\\text{even}}(t) = \\frac{e^t + e^{-t}}{2} = \\cosh(t)\\]\n\\[x_{\\text{odd}}(t) = \\frac{e^t - e^{-t}}{2} = \\sinh(t)\\]\n\\[x(t) = x_{\\text{even}}(t) + x_{\\text{odd}}(t)\\]\n\\[e^t = \\cosh(t) + \\sinh(t)\\] ​"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-2",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#example-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---energy-vs-power-signals",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-classification---energy-vs-power-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Classification - Energy vs Power Signals",
    "text": "Signal Classification - Energy vs Power Signals\nDefinitions. For a signal \\(x(t)\\) (continuous-time, CT) or \\(x[n]\\) (discrete-time, DT):\n\nEnergy: \\(E=\\int_{-\\infty}^{\\infty}\\lvert x(t)\\rvert^2,dt\\) (CT), \\(\\quad E=\\sum_{n=-\\infty}^{\\infty}\\lvert x[n]\\rvert^2\\) (DT).\nAverage power: \\(P=\\lim_{T\\to\\infty}\\dfrac{1}{2T}\\int_{-T}^{T}\\lvert x(t)\\rvert^2,dt\\) (CT), \\(\\quad P=\\lim_{N\\to\\infty}\\dfrac{1}{2N+1}\\sum_{n=-N}^{N}\\lvert x[n]\\rvert^2\\) (DT).\nEnergy signal: \\(0&lt;E&lt;\\infty\\) and \\(P=0\\) (e.g., \\(x_E(t)=e^{-a t}u(t)\\), \\(a&gt;0\\), with \\(E=\\tfrac{1}{2a}\\)).\nPower signal: \\(0&lt;P&lt;\\infty\\) and \\(E=\\infty\\) (e.g., \\(x_P(t)=\\cos(2\\pi f_0 t)\\), with \\(P=\\tfrac{1}{2}\\))."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#signal-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Signal Transformations",
    "text": "Signal Transformations\nTypes of Transformations\nSignals can undergo two types of transformations:\n\nIndependent variable transformations (affect the time or input axis).\nDependent variable transformations (affect the amplitude or output axis)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#independent-variable-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#independent-variable-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Independent Variable Transformations",
    "text": "Independent Variable Transformations\nTime Scaling\n\nDefinition: Changes the time scale of the signal. [ x(at), a &gt; 1 , &lt; a &lt; 1 ]\nExample: If ( x(t) = (t) ), then ( x(2t) ) is compressed.\n\nTime Shifting\n\nDefinition: Shifts the signal in time. [ x(t - t_0) ]\nExample: ( x(t - 2) ) shifts the signal 2 units to the right.\n\nTime Reversal\n\nDefinition: Flips the signal across the vertical axis. [ x(-t) ]\nExample: If ( x(t) = t^2 ), then ( x(-t) = t^2 ) (even signal)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#dependent-variable-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#dependent-variable-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Dependent Variable Transformations",
    "text": "Dependent Variable Transformations\nAmplitude Scaling\n\nDefinition: Multiplies the amplitude by a scalar factor. [ a x(t), a &gt; 1 , &lt; a &lt; 1 ]\nExample: If ( x(t) = (t) ), then ( 2x(t) ) doubles the amplitude.\n\nAmplitude Shifting\n\nDefinition: Adds a constant value to the amplitude. [ x(t) + c ]\nExample: If ( x(t) = (t) ), then ( x(t) + 2 ) shifts the signal up by 2 units."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#combined-transformations",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#combined-transformations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Combined Transformations",
    "text": "Combined Transformations\nExample\nConsider: [ y(t) = 2 x(3t - 1) + 1 ] 1. Time compression: ( x(3t) ) compresses the signal. 2. Time shift: ( x(3t - 1) ) shifts it to the right by 1 unit. 3. Amplitude scaling: ( 2 x(3t - 1) ) amplifies the signal. 4. Amplitude shift: ( +1 ) shifts it upward."
  },
  {
    "objectID": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#visualization-example-in-python",
    "href": "presentaciones/SYSB/Lect003_Intro_SennalesSistemas.html#visualization-example-in-python",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Visualization Example in Python",
    "text": "Visualization Example in Python"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#periodic-functions",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#periodic-functions",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Periodic functions",
    "text": "Periodic functions\n\n\n\n\n\n\n\n\nDefinition\n\n\nAny signal that meets any of this conditions \\[x\\left(t\\right)=x\\left(t + kT\\right)\\] \\[x\\left[n\\right]=x\\left[t + kN\\right]\\]\n\n\n\n\nWhere \\(k, N\\in\\mathbb{z}\\) and \\(T\\in\\mathbb{R}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#sum-of-two-periodic-signals",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#sum-of-two-periodic-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sum of Two Periodic Signals",
    "text": "Sum of Two Periodic Signals\nIf \\(\\left( x_1(t) \\right)\\) and \\(\\left( x_2(t) \\right)\\) are periodic with periods \\(\\left( T_1 \\right)\\) and \\(\\left( T_2 \\right)\\):\n\\[\nx_1(t + T_1) = x_1(t), \\quad x_2(t + T_2) = x_2(t)\n\\]\nThe sum of both signals is:\n\\[\nx(t) = x_1(t) + x_2(t)\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#condition-for-the-periodicity-of-the-sum",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#condition-for-the-periodicity-of-the-sum",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Condition for the Periodicity of the Sum",
    "text": "Condition for the Periodicity of the Sum\nFor \\(\\left( x(t) \\right)\\) to be periodic, there must exist a common period \\(\\left( T \\right)\\) such that:\n\\[\nT = k_1 T_1 = k_2 T_2\n\\]\nwhere \\(\\left( k_1, k_2 \\right)\\) are positive integers."
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#common-period-and-least-common-multiple",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#common-period-and-least-common-multiple",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Common Period and Least Common Multiple",
    "text": "Common Period and Least Common Multiple\nThe smallest common period is the least common multiple (lcm) of \\(\\left( T_1 \\right)\\) and \\(\\left( T_2 \\right)\\):\n\\[\nT = \\operatorname{lcm}(T_1, T_2)\n\\]\nIf the ratio of the periods is a rational number:\n\\[\n\\frac{T_1}{T_2} \\in \\mathbb{Q}\n\\]\nThen, the sum \\(\\left( x_1(t) + x_2(t) \\right)\\) will be periodic.\nIf the ratio is irrational, the resulting signal will not be periodic."
  },
  {
    "objectID": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#example",
    "href": "presentaciones/SYSB/Lect005_Intro_SennalesNotables.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Digital Filter – Introduction",
    "text": "Digital Filter – Introduction\n\n\n\nIt is a mathematical algorithm or system that processes digital signals.\nThey enhance, suppress, or modify specific frequency components.\nThese filters are essential for removing noise, extracting relevant information, and improving signal quality."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#what-is-a-system",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#what-is-a-system",
    "title": "Sistemas y Señales Biomédicos",
    "section": "What is a system?",
    "text": "What is a system?\nA system is a rule that maps an input signal to an output signal. In continuous time and discrete time we depict and denote: \\[\nx(t)\\ \\longrightarrow\\ y(t),\\qquad x[n]\\ \\longrightarrow\\ y[n].\n\\] These are the standard input–output representations used throughout the text."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#inputoutput-operator-notation",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#inputoutput-operator-notation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Input–output operator notation",
    "text": "Input–output operator notation\nWe often write the system as an operator ( {} ): \\[\ny(t)=\\mathcal{T}\\{x(t)\\},\\qquad y[n]=\\mathcal{T}\\{x[n]\\}.\n\\] Block diagrams are used to represent systems and interconnections (series/cascade and parallel)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#overview-what-is-an-inputoutput-relation",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#overview-what-is-an-inputoutput-relation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Overview: what is an input–output relation?",
    "text": "Overview: what is an input–output relation?\nA system specifies how an input signal produces an output signal: \\[\nx(t)\\ \\longrightarrow\\ y(t),\\qquad x[n]\\ \\longrightarrow\\ y[n].\n\\] We study types of relations used in analysis and design: - Memoryless (static) mappings - Differential/difference-equation descriptions - Convolution (LTI) - Transform-domain forms (frequency, Laplace, (z)) - State–space (first-order vector form) - Time-varying vs time-invariant, linear vs nonlinear"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#memoryless-static-relations",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#memoryless-static-relations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Memoryless (static) relations",
    "text": "Memoryless (static) relations\nA memoryless or static system relates input and output at the same instant: \\[\ny(t)=F\\!\\big(x(t)\\big),\\qquad y[n]=F\\!\\big(x[n]\\big).\n\\] Examples: (y=|x|), (y=x^2), saturation and clipping nonlinearities. These are common as pointwise nonlinear stages preceding or following LTI blocks."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-differential-equations-ct",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-differential-equations-ct",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Linear constant-coefficient differential equations (CT)",
    "text": "Linear constant-coefficient differential equations (CT)\nMany continuous-time LTI systems are described by an LCCDE: \\[\n\\sum_{k=0}^{N} a_k\\,\\frac{d^{\\,k} y(t)}{dt^{\\,k}}\n\\;=\\;\n\\sum_{m=0}^{M} b_m\\,\\frac{d^{\\,m} x(t)}{dt^{\\,m}},\n\\qquad a_0\\neq 0.\n\\] Coefficients (a_k,b_m) are constants for time invariance. This form covers standard electrical/mechanical systems and filters."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-difference-equations-dt",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-constant-coefficient-difference-equations-dt",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Linear constant-coefficient difference equations (DT)",
    "text": "Linear constant-coefficient difference equations (DT)\nDiscrete-time LTI systems admit an LCCD equation: \\[\n\\sum_{k=0}^{N} a_k\\,y[n-k]\\;=\\;\\sum_{m=0}^{M} b_m\\,x[n-m],\\qquad a_0\\neq 0.\n\\] This representation includes IIR/FIR digital filters and many algorithmic recursions."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution-relations-lti",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution-relations-lti",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution relations (LTI)",
    "text": "Convolution relations (LTI)\nFor LTI systems the input–output relation is convolution with the impulse response: \\[\ny(t)=\\int_{-\\infty}^{\\infty} h(\\tau)\\,x(t-\\tau)\\,d\\tau,\\qquad\ny[n]=\\sum_{k=-\\infty}^{\\infty} h[k]\\;x[n-k].\n\\] Here (h(t)) or (h[n]) is the output to a unit impulse. Causality for LTI corresponds to (h(t)=0) for (t&lt;0) (or (h[n]=0) for (n&lt;0))."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#frequency-domain-inputoutput-fourier",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#frequency-domain-inputoutput-fourier",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Frequency-domain input–output (Fourier)",
    "text": "Frequency-domain input–output (Fourier)\nWhen Fourier transforms exist, convolution becomes multiplication: \\[\nY(\\omega)=H(\\omega)\\,X(\\omega),\\qquad\nY\\!\\big(e^{j\\omega}\\big)=H\\!\\big(e^{j\\omega}\\big)\\,X\\!\\big(e^{j\\omega}\\big).\n\\] (H) is the frequency response (CTFT/DTFT). Magnitude (|H|) scales, phase (H) shifts/warps timing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#laplace-and-z-transform-forms",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#laplace-and-z-transform-forms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laplace and (z)-transform forms",
    "text": "Laplace and (z)-transform forms\nWith Laplace and (z)-transforms (for appropriate regions of convergence): \\[\nY(s)=H(s)\\,X(s),\\qquad Y(z)=H(z)\\,X(z),\n\\] and for LCCDE/LCCD systems \\[\nH(s)=\\frac{b_0+b_1 s+\\cdots+b_M s^M}{a_0+a_1 s+\\cdots+a_N s^N},\\qquad\nH(z)=\\frac{b_0+b_1 z^{-1}+\\cdots+b_M z^{-M}}{a_0+a_1 z^{-1}+\\cdots+a_N z^{-N}}.\n\\] These rational forms support pole–zero analysis and stability checks."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#statespace-first-order-vector-description",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#statespace-first-order-vector-description",
    "title": "Sistemas y Señales Biomédicos",
    "section": "State–space (first-order vector) description",
    "text": "State–space (first-order vector) description\nAn equivalent input–output formulation uses state variables: \\[\n\\dot{\\mathbf{s}}(t)=\\mathbf{A}\\,\\mathbf{s}(t)+\\mathbf{b}\\,x(t),\\qquad\ny(t)=\\mathbf{c}^\\top\\mathbf{s}(t)+d\\,x(t).\n\\] Discrete time: \\[\n\\mathbf{s}[n+1]=\\mathbf{A}\\,\\mathbf{s}[n]+\\mathbf{b}\\,x[n],\\qquad\ny[n]=\\mathbf{c}^\\top\\mathbf{s}[n]+d\\,x[n].\n\\] This first-order form is algebraically equivalent to LCCDE/LCCD for LTI systems."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#time-varying-vs-time-invariant-relations",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#time-varying-vs-time-invariant-relations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time-varying vs time-invariant relations",
    "text": "Time-varying vs time-invariant relations\n\nTime-invariant (TI): coefficients and operators do not change with time/index; shifts commute with the system.\nTime-varying (TV): coefficients depend on (t) or (n): \\[\n\\sum_{k=0}^{N} a_k(t)\\,\\frac{d^{\\,k} y(t)}{dt^{\\,k}}\n=\\sum_{m=0}^{M} b_m(t)\\,\\frac{d^{\\,m} x(t)}{dt^{\\,m}}.\n\\] TV models arise in modulated systems and adaptive filtering."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-vs-nonlinear-relations",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#linear-vs-nonlinear-relations",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Linear vs nonlinear relations",
    "text": "Linear vs nonlinear relations\n\nLinear: superposition holds — additivity and homogeneity.\nNonlinear: violates superposition; examples include squares, rectifiers, saturators, quantizers. Nonlinear stages are often analyzed locally or via small-signal linearization around an operating point."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#stochastic-inputoutput-lti-summary",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#stochastic-inputoutput-lti-summary",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Stochastic input–output (LTI summary)",
    "text": "Stochastic input–output (LTI summary)\nFor wide-sense stationary (WSS) inputs to an LTI system: \\[\n\\mu_y=\\mu_x\\,H(0)\\ \\text{(when defined)},\\qquad\nS_{yy}(\\omega)=\\big|H(\\omega)\\big|^2\\,S_{xx}(\\omega).\n\\] This links input and output statistics through (H), supporting noise and SNR analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#interconnections-examples",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#interconnections-examples",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Interconnections (examples)",
    "text": "Interconnections (examples)\n\nSeries (cascade): output of System 1 feeds System 2.\nParallel: both systems process the same input; outputs are summed. These patterns are foundational for building complex systems from simpler ones."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-memoryless-vs.-with-memory",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-memoryless-vs.-with-memory",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Memoryless vs. with memory",
    "text": "Property: Memoryless vs. with memory\n\nMemoryless: the output at an instant depends only on the input at that same instant.\nWith memory: the output depends on past/future values (e.g., accumulators, averagers). Example: the summer/accumulator (running sum) and its inverse (first difference) illustrate systems with memory: \\[\ny[n]=\\sum_{k=-\\infty}^{n} x[k],\\qquad \\text{inverse: } y[n]=x[n]-x[n-1].\n\\] Both are causal (see next slide)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-causality-general-and-lti",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-causality-general-and-lti",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Causality (general and LTI)",
    "text": "Property: Causality (general and LTI)\nCausal: output depends only on present/past input values. For LTI systems, causality is characterized by the impulse response: \\[\n\\text{Discrete time: } h[n]=0\\ \\text{for } n&lt;0;\\qquad\n\\text{Continuous time: } h(t)=0\\ \\text{for } t&lt;0.\n\\] Under these conditions, the convolution reduces to depend only on past/present input."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-stability-bibo",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-stability-bibo",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Stability (BIBO)",
    "text": "Property: Stability (BIBO)\nBounded-Input Bounded-Output (BIBO) stability: bounded input implies bounded output. For LTI systems: \\[\n\\sum_{k=-\\infty}^{\\infty} |h[k]| &lt; \\infty \\quad \\Longleftrightarrow \\quad \\text{discrete-time LTI is stable},\n\\] \\[\n\\int_{-\\infty}^{\\infty} |h(t)|\\,dt &lt; \\infty \\quad \\Longleftrightarrow \\quad \\text{continuous-time LTI is stable}.\n\\] These are necessary and sufficient conditions."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-linearity-superposition",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-linearity-superposition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Linearity (superposition)",
    "text": "Property: Linearity (superposition)\nA system is linear if it satisfies additivity and homogeneity: for any signals (x_1,x_2) and scalar (c), \\[\n\\mathcal{T}\\{x_1+x_2\\}=\\mathcal{T}\\{x_1\\}+\\mathcal{T}\\{x_2\\},\\qquad \\mathcal{T}\\{c\\,x\\}=c\\,\\mathcal{T}\\{x\\}.\n\\] (These two conditions together are equivalent to linearity.)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-time-invariance-definition",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-time-invariance-definition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Time invariance (definition)",
    "text": "Property: Time invariance (definition)\nA system is time-invariant if a shift in the input produces an identical shift in the output: \\[\n\\mathcal{T}\\{x(t-t_0)\\}=y(t-t_0),\\ \\text{whenever}\\ y(t)=\\mathcal{T}\\{x(t)\\}.\n\\] Analogously in discrete time with shifts by integer indices. (Definition used throughout the text in system properties and LTI analysis.)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-invertibility",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#property-invertibility",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Property: Invertibility",
    "text": "Property: Invertibility\nA system is invertible if distinct inputs produce distinct outputs; equivalently, there exists an inverse system that recovers the input from the output. Example pair (discrete time): the accumulator and the first-difference operator are inverses: \\[\ny[n]=\\sum_{k=-\\infty}^{n} x[k] \\quad \\Longleftrightarrow \\quad x[n]=y[n]-y[n-1].\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#additional-note-interconnections-and-lti-analysis",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#additional-note-interconnections-and-lti-analysis",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Additional note: Interconnections and LTI analysis",
    "text": "Additional note: Interconnections and LTI analysis\nFor LTI systems, interconnections admit simple algebraic descriptions via transforms: e.g., in the Laplace domain, series and parallel lead to product and sum of system functions, respectively: \\[\nH_{\\text{series}}(s)=H_1(s)H_2(s),\\qquad H_{\\text{parallel}}(s)=H_1(s)+H_2(s).\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-1",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Digital Filter – Introduction",
    "text": "Digital Filter – Introduction\n\n\n\n\n\n\n\nImportante\n\n\nThe digital filter separates the noise and the information of a discrete signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-2",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Digital Filter – Introduction",
    "text": "Digital Filter – Introduction"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-3",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#digital-filter-introduction-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Digital Filter – Introduction",
    "text": "Digital Filter – Introduction\n\n\n\n\n\n\n\n\nSuppose a discrete time system \\[ y[n] = \\sum_{k=1}^{K} a_k y[n - k] + \\sum_{m=0}^{M} b_m x[n - m]\\]\n\nK y M are the order of the filter.\nWe must know the initial condition."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#examples-of-digital-filters",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#examples-of-digital-filters",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Examples of digital filters",
    "text": "Examples of digital filters\n\n\n\n\n\n\n\n\n\nGain\n\n\n\\[y[n] = G x[n]\\]\n\n\n\n\n\n\n\n\n\n\n\nDelay of \\(n_0\\) samples\n\n\n\\[y[n] = x[n - n_0]\\]\n\n\n\n\n\n\n\n\n\n\n\nTwo points moving average\n\n\n\\[y[n] = \\frac{1}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\n\n\n\nEuler approximation of the derivative\n\n\n\\[y[n] = \\frac{x[n] - x[n - 1]}{T_s}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nAveraging over N consecutive epochs of duration L\n\n\n\\[y[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} x[n - kL]\\]\n\n\n\n\n\n\n\n\n\n\n\nTrapezoidal integration formula\n\n\n\\[y[n] = y[n - 1] + \\frac{T_s}{2} (x[n] + x[n - 1])\\]\n\n\n\n\n\n\n\n\n\n\n\nDigital “leaky integrator” (First-order lowpass filter)\n\n\n\\[y[n] = a y[n - 1] + x[n], \\quad 0 &lt; a &lt; 1\\]\n\n\n\n\n\n\n\n\n\n\n\nDigital resonator (Second-order system)\n\n\n\\[y[n] = a_1 y[n - 1] + a_2 y[n - 2] + b x[n], \\quad a_1^2 + 4a_2 &lt; 0\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#the-impulse-response",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#the-impulse-response",
    "title": "Sistemas y Señales Biomédicos",
    "section": "The impulse response",
    "text": "The impulse response\n\n\n\n\n\n\n\n\n\nThe impulse response, denoted as \\(ℎ[n]\\), is the output of a digital filter when the input is a unit impulse function \\(\\delta[n]\\)\nThe impulse response fully describes the system. Given \\(h[n]\\), we can determine the output for any input using convolution.\nDifferent types of filters (low-pass, high-pass, band-pass, etc.) have characteristic impulse responses."
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#conditions",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#conditions",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Conditions",
    "text": "Conditions\nFor a system’s response to be fully described by its impulse response, the system must satisfy the following key conditions.\n\n\n\n\n\n\n\nLinearity\n\n\nIf the system responds to \\(x_1[n]\\) with \\(y_1[n]\\) and to \\(x_2[n]\\) with \\(y_2[n]\\), then:\n\\[y[n] = y_1[n] + y_2[n]\\]\n\n\n\n\n\n\n\n\n\n\n\nHomogeneity\n\n\nIf the input is scaled by a constant \\(c\\), the output is also scaled:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } cx[n] \\rightarrow cy[n]\\]\n\n\n\n\n\n\n\n\n\n\n\nTime Invariance\n\n\nA system must be time-invariant, meaning a time shift in the input causes the same shift in the output:\n\\[\\text{If } x[n] \\rightarrow y[n], \\text{ then } x[n - n_0] \\rightarrow y[n - n_0]\\]\n\n\n\n\n\n\n\n\n\n\n\nCausality\n\n\nA causal system is one where the output at time \\(n\\) depends only on present and past inputs:\n\\[h[n] = 0 \\quad \\forall n &lt; 0\\]\n\n\n\n\n\n\n\n\n\n\n\nStability\n\n\nIf the impulse response does not satisfy this condition, the system may produce unbounded outputs.\n\\[\\sum_{n=-\\infty}^{\\infty} |h[n]| &lt; \\infty\\]\n\n\n\n\n\n\n\n\n\n\n\nConvolution Representation\n\n\nIf all condition met then \\[y[n] = x[n] * h[n] = \\sum_{m=-\\infty}^{\\infty} x[m] h[n - m]\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution",
    "href": "presentaciones/SYSB/Lect007_DigitalFilters.html#convolution",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution",
    "text": "Convolution"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#el-profesor",
    "title": "Sistemas y Señales Biomédicas",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción al procesado de señales.\nConceptos de señales contínuas & discretas.\nMuestreo.\nExtracción de características de una señal.\nFiltraje de señales."
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nEvaluaciones parciales y una evaluación final\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nExamen parcial 1 (15%)\nExamen parcial 2 (15%)\nExamen final (20%)\nLaboratorios (30%)\nProyecto Final (20%)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#evaluación-1",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (15%)\nLaboratorios (15%)\nProyecto final (20%)\n\n\nExamen Parcial 1 (15%)\nExamen Parcial 2 (15%)\nExamen final (20%)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#recursos",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nLunes 10:00am-11:30am F-204. Jueves 10:00am-11:30am F-206.\nLaboratorio\nMartes 10:00am-11:30am. I1-308\n\nInterpretes: R y python.\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/SYSB/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/SYSB/Lect001_Presentacion.html#bibliografía",
    "title": "Sistemas y Señales Biomédicas",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Linux",
    "text": "What is Linux\n\nDefinition: Linux is a free, open-source operating system (OS) based on Unix, created by Linus Torvalds in 1991.\nKey Features:\n\nOpen-source: Anyone can view, modify, and distribute the source code.\nFree to use: No licensing fees.\nMulti-user and multitasking.\n\nStructure: Comprises a kernel (core of the OS) and various utilities."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\nControls the hardware.\nTypes of linux kernel\n\nMonolithic kernel: All the concurrent processes are executed simultaneously in the kernel itself. All the processes share same memory recourses.\nMicro kernel: user services and kernel services are executed in separate address spaces. User services are kept in user address space and kernel services are kept in kernel address space.\nHybrid kernel: this kernel has the monolithic speed and the stability of the micro.\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "The linux structure",
    "text": "The linux structure\n\n\n\n\n\n\n\n\n\n\n\nShell\n\n\nThe shell serves as an interface to the kernel, acting as a bridge between the user and the system’s core operations. It hides the internal workings of the kernel, allowing users to perform tasks without needing to understand the underlying processes. Users simply enter a command, and the shell leverages the kernel’s functions to execute the specified task.\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "href": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Why is Linux Popular?",
    "text": "Why is Linux Popular?\n\nFlexibility: Runs on a wide range of devices (PCs, servers, smartphones, embedded systems).\nSecurity: Highly secure and less vulnerable to malware.\nCommunity Support: Strong open-source community for development and troubleshooting.\nCustomization: Highly configurable; users can tailor it to specific needs.\nPerformance: Efficient resource utilization, ideal for servers and low-end devices."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Linux vs Other Operating Systems",
    "text": "Linux vs Other Operating Systems\n\n\n\n\n\n\n\n\n\nFeature\nLinux\nWindows\nmacOS\n\n\n\n\nCost\nFree\nPaid\nPaid\n\n\nSource Code\nOpen-source\nProprietary\nProprietary\n\n\nSecurity\nHighly secure\nVulnerable to malware\nSecure\n\n\nCustomization\nHigh\nLow\nLow\n\n\nUsage\nServers, DevOps, IoT\nDesktop, Gaming\nCreative industries"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Linux Distributions",
    "text": "Linux Distributions\n\nWhat are Distributions (Distros)?\nVariants of Linux tailored for specific purposes.\nPopular Distros:\n\nUbuntu: User-friendly, great for beginners.\nDebian: Stable and widely supported.\nFedora: Cutting-edge technologies.\nCentOS/Red Hat: Enterprise-level stability.\nKali Linux: Security and penetration testing."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Applications of Linux",
    "text": "Applications of Linux\n\nEveryday Use: Desktops and laptops (e.g., Ubuntu, Mint).\nServers: Powers most web servers, databases, and cloud infrastructure.\nEmbedded Systems: Used in IoT devices, routers, and automotive systems.\nSupercomputers: Runs on 100% of the top 500 supercomputers.\nProgramming & Development: Preferred OS for software developers."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nKey Term\n\n\nThe term edge AI is a union of two buzzwords, fused together into one mighty term. It’s often heard alongside its siblings, embedded machine learning and TinyML.\n\n\n\n\n\n\n\n\n\n\n\nEmbedded\n\n\n\nEmbedded systems are the computers that control the electronics of all sorts of physical devices.\nIn contrast to general-purpose computers, embedded systems are usually meant to perform one specific, dedicated task.\nIt’s common for embedded systems to reflect the constraints of the environments into which they are deployed. For example, many embedded systems are required to run on battery power, so they’re designed with energy efficiency in mind—perhaps with limited memory or an extremely slow clock rate.\nProgramming embedded systems is the art of navigating these constraints, writing software that performs the task required while making the most out of limited resources."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nThe history of computer networks has been a gigantic tug of war.\nIn the first systems—individual computers the size of a room—computation was inherently centralized.\nComputers were connected to terminals that took over some of their responsibilities. Example the terminal renders the letters in an monitor."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nOver time, terminals became more and more sophisticated, taking over more and more functions that were previously the job of the central computer. The personal computer was invented.\nSmall computers could do useful work without even being connected to another machine.\nThe growth of the internet, along with web applications and services, made it possible to do some really cool stuff\nOver the past decade, most of our computing has become centralized again—this time in the “cloud.”"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-3",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\nThe Edge\n\n\n\nThe Internet of Things (IoT) includes everything you can think of: industrial sensors, smart refrigerators, internet-connected security cameras, personal automobiles, shipping containers, fitness trackers, and coffee machines.\nAll of these devices are embedded systems.\nSince they’re at the edge of the network, we can also call them edge devices.\nThe edge isn’t a single place; it’s more like a broad region.\nThe edge is where all the data comes from!\nEdge devices are our link between the internet and the physical world"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI\n\n\n\n\n\n\n\n\n\nAI\n\n\n\nSince the dawn of time, humans have dreamed of creating intelligent entities that can help us in our struggle to survive.\nIn the modern world we dream of robot sidekicks who assist us.\nTo define AI, we have to define intelligence\n\n\n\n\n\n\n\n\n\n“Slime Mould Solves Maze in One Pass Assisted by Gradient of Chemo-Attractants” (Andrew Adamatzky, arXiv, 2011)"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-6",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-6",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "A Brief Introduction to Edge AI",
    "text": "A Brief Introduction to Edge AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Edge AI",
    "text": "Edge AI\n\n\n\n\n\n\n\nDefinition\n\n\nEdge AI Is the combination of EDGE devices and Artificial Intelligence Algorithms\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nThe accelerometer-based wristband sensor."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI\n\nTaken from “Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing” (Zhou et. al., Proceedings of the IEEE, 2019)"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI\n\n\n\n\n\n\n\nEmbedded ML\n\n\n\nEmbedded ML is the art and science of running machine learning models on embedded systems.\nEmbedded ML, we’re usually refers to machine learning inference.\nThe training part usually still takes place on a conventional computer.\nHigh requirements of ROM(Model Storing), RAM(Storing intermediate results), computer capabilities(computational intensive tasks).\nEmbedded machine learning is often deployed alongside digital signal processing algorithms\nTiny machine learning, or TinyML, is the concept of doing this on the most constrained embedded hardware available."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-3",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "EDGE AI",
    "text": "EDGE AI"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "BLERP",
    "text": "BLERP\n\n\n\n\n\n\n\n\n\nBandwith\n\n\nIt’s related to the quantity of information you could send via some kind of connection. More bandwith it’s needed to send more data. Example: Imagine a smart sensor that monitors the vibration of an magnetic resonator to determine if it is operating correctly. It might use a simple thresholding algorithm to understand when the machine is vibrating too much, or not enough, and then communicate this information via a low bandwidth radio connection.\n\n\n\n\n\n\n\n\n\n\n\nLatency\n\n\nIt’s related to the time you must wait for the reponse of the sensor. Example: Edge AI solves this problem by removing the round-trip time altogether. A great example of this is a self-driving car. The car’s AI systems run on onboard computers. This allows it to react nearly instantly to changing conditions, like the driver in front slamming on their brakes.\n\n\n\n\n\n\n\n\n\n\n\n\nEconomy\n\n\nConnectivity costs a lot of money. By processing data on-device, edge AI systems reduce or avoid the costs of transmitting data over a network and processing it in the cloud. Example: Edge AI enables healthcare providers to monitor patients in real time without sending data to the cloud for processing. For example, wearable devices with built-in AI algorithms can analyze physiological signals such as heart rate, oxygen levels, and ECG data locally. This reduces the reliance on cloud services for data transmission and processing.\n\n\n\n\n\n\n\n\n\n\n\nReliability\n\n\nSystems controlled by on-device AI are potentially more reliable than those that depend on a connection to the cloud. When you add wireless connectivity to a device, you’re adding a vast, overwhelmingly complex web of dependencies, from link-layer communications technologies to the internet servers that may run your application. Example: Traditional Cloud-Based Systems: Data collected by wearable devices must be transmitted to a cloud server, analyzed, and then results are sent back to caregivers or emergency responders. This can introduce delays due to network latency or connectivity issues. Edge AI Systems: Processes the sensor data locally in real time, enabling instant detection of falls or other anomalies.Improvement: Reduces detection and response time from minutes to milliseconds, ensuring immediate action during emergencies.\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy\n\n\nEdge AI provides an alternative. Rather than streaming live video and audio to a remote server, a security camera could use some onboard intelligence to identify that an intruder is present when the owners are out at work. It could then alert the owners in an appropriate way. When data is processed on an embedded system and is never transmitted to the cloud, user privacy is protected and there is less chance of abuse."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Understanding Workflow.",
    "text": "Data Understanding Workflow.\n\n\n\n\n\n\n\nExploratory data analysis\n\n\n\nData Loading.\nBasic Statistics: Displays summary statistics.\nMissing Values Check: Identifies missing values.\nFeature Distributions: Visualizes distributions using histograms or countplots.\nRelationship between variables."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Understanding Workflow",
    "text": "Data Understanding Workflow\n\n# Identify variable types\ndiscrete_vars = [\"Pregnancies\"]  # Discrete numerical variable\ncategorical_vars = [\"Outcome\"]  # Class label\ncontinuous_vars = [\n    col\n    for col in data.select_dtypes(include=[np.number]).columns\n    if col not in discrete_vars + [\"Outcome\"]\n]\n\n# Basic dataset information\nprint(\"Dataset Information:\\n\", data.info())\nprint(\"\\nSummary Statistics:\\n\", data.describe())\nprint(\"\\nMissing Values:\\n\", data.isnull().sum())\n\n# Ensure numeric data and handle NaN or infinite values\nnumeric_data = data.select_dtypes(include=[np.number]).dropna()\nnumeric_data = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n\n# Dynamically determine the number of rows for subplots\nnum_cont_vars = len(continuous_vars)\nrows = (num_cont_vars // 3) + (num_cont_vars % 3 &gt; 0)  # Ensures proper grid layout\n\n# Plot distributions for continuous variables\nplt.figure(figsize=(12, 4 * rows))\nfor i, column in enumerate(continuous_vars, 1):\n    plt.subplot(rows, 3, i)\n    sns.histplot(numeric_data[column], kde=True, bins=20, color=\"skyblue\")\n    plt.title(f\"Distribution of {column}\")\nplt.tight_layout()\nplt.show()\n\n# Plot distribution for discrete variable (Pregnancies) using a countplot\nplt.figure(figsize=(8, 4))\nsns.countplot(x=\"Pregnancies\", data=numeric_data, palette=\"viridis\")\nplt.title(\"Count of Pregnancies\")\nplt.show()\n\n# Plot class distribution for Outcome\nplt.figure(figsize=(6, 4))\nsns.countplot(x=\"Outcome\", data=data, palette=\"coolwarm\")\nplt.title(\"Class Distribution of Outcome\")\nplt.xlabel(\"Diabetes Diagnosis (0: No, 1: Yes)\")\nplt.ylabel(\"Count\")\nplt.show()\n\n# Correlation heatmap to check relationships\nplt.figure(figsize=(10, 6))\nsns.heatmap(numeric_data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html",
    "href": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html",
    "title": "EDA: Fetal Health CTG dataset",
    "section": "",
    "text": "Context: Exploratory analysis of the fetal_health.csv dataset (CTG features) to understand\ndistributions, correlations, and target balance in support of a 3-hour class on Linear Regression,\nLogistic Regression, and Multilayer Perceptrons applied to fetal health prediction.\nData source: Provided CSV with 2,126 rows and 22 columns (21 features + target ‘fetal_health’).\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport os\ncurrent_path = os.getcwd()\nprint(current_path)\n\ndf = pd.read_csv(\"/home/sylph/Data_Cantatio/pablocaicedor.github.io/presentaciones/ASIM/data/Fetal Health Classification/fetal_health.csv\")\nprint(df.shape)\ndf.head()\n\n/home/sylph/Data_Cantatio/pablocaicedor.github.io\n(2126, 22)\n\n\n\n\n\n\n\n\n\nbaseline value\naccelerations\nfetal_movement\nuterine_contractions\nlight_decelerations\nsevere_decelerations\nprolongued_decelerations\nabnormal_short_term_variability\nmean_value_of_short_term_variability\npercentage_of_time_with_abnormal_long_term_variability\n...\nhistogram_min\nhistogram_max\nhistogram_number_of_peaks\nhistogram_number_of_zeroes\nhistogram_mode\nhistogram_mean\nhistogram_median\nhistogram_variance\nhistogram_tendency\nfetal_health\n\n\n\n\n0\n120.0\n0.000\n0.0\n0.000\n0.000\n0.0\n0.0\n73.0\n0.5\n43.0\n...\n62.0\n126.0\n2.0\n0.0\n120.0\n137.0\n121.0\n73.0\n1.0\n2.0\n\n\n1\n132.0\n0.006\n0.0\n0.006\n0.003\n0.0\n0.0\n17.0\n2.1\n0.0\n...\n68.0\n198.0\n6.0\n1.0\n141.0\n136.0\n140.0\n12.0\n0.0\n1.0\n\n\n2\n133.0\n0.003\n0.0\n0.008\n0.003\n0.0\n0.0\n16.0\n2.1\n0.0\n...\n68.0\n198.0\n5.0\n1.0\n141.0\n135.0\n138.0\n13.0\n0.0\n1.0\n\n\n3\n134.0\n0.003\n0.0\n0.008\n0.003\n0.0\n0.0\n16.0\n2.4\n0.0\n...\n53.0\n170.0\n11.0\n0.0\n137.0\n134.0\n137.0\n13.0\n1.0\n1.0\n\n\n4\n132.0\n0.007\n0.0\n0.008\n0.000\n0.0\n0.0\n16.0\n2.4\n0.0\n...\n53.0\n170.0\n9.0\n0.0\n137.0\n136.0\n138.0\n11.0\n1.0\n1.0\n\n\n\n\n5 rows × 22 columns"
  },
  {
    "objectID": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#basic-descriptive-statistics",
    "href": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#basic-descriptive-statistics",
    "title": "EDA: Fetal Health CTG dataset",
    "section": "Basic descriptive statistics",
    "text": "Basic descriptive statistics\n\ndesc = df.describe().T\ndesc\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nbaseline value\n2126.0\n133.303857\n9.840844\n106.0\n126.000\n133.000\n140.000\n160.000\n\n\naccelerations\n2126.0\n0.003178\n0.003866\n0.0\n0.000\n0.002\n0.006\n0.019\n\n\nfetal_movement\n2126.0\n0.009481\n0.046666\n0.0\n0.000\n0.000\n0.003\n0.481\n\n\nuterine_contractions\n2126.0\n0.004366\n0.002946\n0.0\n0.002\n0.004\n0.007\n0.015\n\n\nlight_decelerations\n2126.0\n0.001889\n0.002960\n0.0\n0.000\n0.000\n0.003\n0.015\n\n\nsevere_decelerations\n2126.0\n0.000003\n0.000057\n0.0\n0.000\n0.000\n0.000\n0.001\n\n\nprolongued_decelerations\n2126.0\n0.000159\n0.000590\n0.0\n0.000\n0.000\n0.000\n0.005\n\n\nabnormal_short_term_variability\n2126.0\n46.990122\n17.192814\n12.0\n32.000\n49.000\n61.000\n87.000\n\n\nmean_value_of_short_term_variability\n2126.0\n1.332785\n0.883241\n0.2\n0.700\n1.200\n1.700\n7.000\n\n\npercentage_of_time_with_abnormal_long_term_variability\n2126.0\n9.846660\n18.396880\n0.0\n0.000\n0.000\n11.000\n91.000\n\n\nmean_value_of_long_term_variability\n2126.0\n8.187629\n5.628247\n0.0\n4.600\n7.400\n10.800\n50.700\n\n\nhistogram_width\n2126.0\n70.445908\n38.955693\n3.0\n37.000\n67.500\n100.000\n180.000\n\n\nhistogram_min\n2126.0\n93.579492\n29.560212\n50.0\n67.000\n93.000\n120.000\n159.000\n\n\nhistogram_max\n2126.0\n164.025400\n17.944183\n122.0\n152.000\n162.000\n174.000\n238.000\n\n\nhistogram_number_of_peaks\n2126.0\n4.068203\n2.949386\n0.0\n2.000\n3.000\n6.000\n18.000\n\n\nhistogram_number_of_zeroes\n2126.0\n0.323612\n0.706059\n0.0\n0.000\n0.000\n0.000\n10.000\n\n\nhistogram_mode\n2126.0\n137.452023\n16.381289\n60.0\n129.000\n139.000\n148.000\n187.000\n\n\nhistogram_mean\n2126.0\n134.610536\n15.593596\n73.0\n125.000\n136.000\n145.000\n182.000\n\n\nhistogram_median\n2126.0\n138.090310\n14.466589\n77.0\n129.000\n139.000\n148.000\n186.000\n\n\nhistogram_variance\n2126.0\n18.808090\n28.977636\n0.0\n2.000\n7.000\n24.000\n269.000\n\n\nhistogram_tendency\n2126.0\n0.320320\n0.610829\n-1.0\n0.000\n0.000\n1.000\n1.000\n\n\nfetal_health\n2126.0\n1.304327\n0.614377\n1.0\n1.000\n1.000\n1.000\n3.000"
  },
  {
    "objectID": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#target-distribution-fetal_health",
    "href": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#target-distribution-fetal_health",
    "title": "EDA: Fetal Health CTG dataset",
    "section": "Target distribution (fetal_health)",
    "text": "Target distribution (fetal_health)\n\ncounts = df['fetal_health'].value_counts().sort_index()\nprint(counts)\nplt.figure()\ncounts.plot(kind='bar')\nplt.title('Target distribution: fetal_health (1=Normal, 2=Suspect, 3=Pathological)')\nplt.xlabel('Class')\nplt.ylabel('Count')\nplt.tight_layout()\nplt.show()\n\nfetal_health\n1.0    1655\n2.0     295\n3.0     176\nName: count, dtype: int64"
  },
  {
    "objectID": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#histograms-of-selected-features",
    "href": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#histograms-of-selected-features",
    "title": "EDA: Fetal Health CTG dataset",
    "section": "Histograms of selected features",
    "text": "Histograms of selected features\n\nfeatures = ['baseline value','accelerations','uterine_contractions',\n            'abnormal_short_term_variability','mean_value_of_short_term_variability',\n            'histogram_width','histogram_min','histogram_max','histogram_variance']\nfor col in features:\n    plt.figure()\n    plt.hist(df[col].dropna().values, bins=30)\n    plt.title(f'Histogram: {col}')\n    plt.xlabel(col)\n    plt.ylabel('Frequency')\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#correlation-matrix-pearson",
    "href": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#correlation-matrix-pearson",
    "title": "EDA: Fetal Health CTG dataset",
    "section": "Correlation matrix (Pearson)",
    "text": "Correlation matrix (Pearson)\n\ncorr = df.drop(columns=['fetal_health']).corr(method='pearson')\nplt.figure(figsize=(8,6))\n# Simple imshow heatmap without seaborn\nim = plt.imshow(corr.values, aspect='auto')\nplt.title('Correlation matrix (Pearson)')\nplt.colorbar(im, fraction=0.046, pad=0.04)\nplt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\nplt.yticks(range(len(corr.columns)), corr.columns)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#simple-trainvalidation-split-for-later-modeling",
    "href": "presentaciones/ASIM/data/Fetal Health Classification/EDA_fetal_health.html#simple-trainvalidation-split-for-later-modeling",
    "title": "EDA: Fetal Health CTG dataset",
    "section": "Simple train/validation split (for later modeling)",
    "text": "Simple train/validation split (for later modeling)\n\nfrom sklearn.model_selection import train_test_split\nX = df.drop(columns=['fetal_health']).values\ny = df['fetal_health'].values.astype(int)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nprint(X_train.shape, X_test.shape)\n\n(1700, 21) (426, 21)\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2126 entries, 0 to 2125\nData columns (total 22 columns):\n #   Column                                                  Non-Null Count  Dtype  \n---  ------                                                  --------------  -----  \n 0   baseline value                                          2126 non-null   float64\n 1   accelerations                                           2126 non-null   float64\n 2   fetal_movement                                          2126 non-null   float64\n 3   uterine_contractions                                    2126 non-null   float64\n 4   light_decelerations                                     2126 non-null   float64\n 5   severe_decelerations                                    2126 non-null   float64\n 6   prolongued_decelerations                                2126 non-null   float64\n 7   abnormal_short_term_variability                         2126 non-null   float64\n 8   mean_value_of_short_term_variability                    2126 non-null   float64\n 9   percentage_of_time_with_abnormal_long_term_variability  2126 non-null   float64\n 10  mean_value_of_long_term_variability                     2126 non-null   float64\n 11  histogram_width                                         2126 non-null   float64\n 12  histogram_min                                           2126 non-null   float64\n 13  histogram_max                                           2126 non-null   float64\n 14  histogram_number_of_peaks                               2126 non-null   float64\n 15  histogram_number_of_zeroes                              2126 non-null   float64\n 16  histogram_mode                                          2126 non-null   float64\n 17  histogram_mean                                          2126 non-null   float64\n 18  histogram_median                                        2126 non-null   float64\n 19  histogram_variance                                      2126 non-null   float64\n 20  histogram_tendency                                      2126 non-null   float64\n 21  fetal_health                                            2126 non-null   float64\ndtypes: float64(22)\nmemory usage: 365.5 KB\n\n\n\nimport seaborn as sns\nsns.scatterplot(data=df, x='histogram_variance', y='histogram_median')\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nX = df[\"histogram_variance\"]\ny = df[\"histogram_median\"]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nDefinitions\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant “free” sources of data\n\n\n\nKaggle\nPhysionet\nDecathlon Dataset\nUCI Machine Learning Repository\nScientific Data\nMendeley Data\nIEEE Dataport\nOpenI\nOpen Access Journals\nGoogle Dataset Search\nData.gov\nWorld Bank Open Data"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect002_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Rol: Diseñador instruccional (AA en señales e imágenes médicas)\nAudiencia: Pregrado (profundización, nivel avanzado)\nDuración total: 24 horas (8 sesiones × 3 h)\nStack principal: Python 3.12, scikit-learn, PyTorch, MONAI, MNE (según caso)\nPolítica de validación: subject-wise k-fold en todas las prácticas\nEvaluación sumativa: 7 mini-labs (70%) + quiz final (30%)\nÉnfasis clínico: Musculoesquelético (EMG/RX/TC)\n\n\n\n\n\n\n\n\n\n\n\n\n\n#\nTítulo\nBloque\nHoras\nEntregable\n\n\n\n\n1\nFundamentos de AA en salud: tareas, métricas y pipeline\nFundamentos\n3\nMini-lab 1: pipeline clásico (sklearn)\n\n\n2\nValidación rigurosa y reproducibilidad (subject-wise)\nFundamentos\n3\nMini-lab 2: split subject-wise + baseline\n\n\n3\nSeñales biomédicas I: preprocesado y features (ECG/EMG)\nSeñales\n3\nMini-lab 3: filtro → features → clasificación\n\n\n4\nSeñales biomédicas II: ML clásico vs CNN 1D\nSeñales\n3\nMini-lab 4: baseline vs CNN1D (comparativa)\n\n\n5\nSeñales biomédicas III: LSTM/GRU/Transformers 1D + explicabilidad\nSeñales\n3\nMini-lab 5: secuenciales + saliency/IG\n\n\n6\nImágenes médicas I: DICOM, preprocesado y transfer learning\nImágenes\n3\nMini-lab 6: fine-tuning (MONAI)\n\n\n7\nImágenes médicas II: U-Net/ResNet, métricas y Grad-CAM\nImágenes\n3\nMini-lab 7: segmentación + Grad-CAM\n\n\n8\nIntegración, buenas prácticas y quiz final\nImágenes (cierre)\n3\nQuiz final + repositorio reproducible\n\n\n\nBalance de horas por bloque (aprox.): Fundamentos 6 h (≈30%), Señales 9 h (≈35%), Imágenes 9 h (≈35%).\nEvaluación (modelo 5B): 7 mini-labs × 10% c/u = 70%; Quiz final = 30%.\n\n\n\n\n\nResultados de aprendizaje:\nRA1. Diferenciar tareas (clasificación, regresión, segmentación).\nRA2. Seleccionar métricas apropiadas por tarea (Acc, AUC, F1, MAE; Dice/IoU para segmentación).\nRA3. Describir un pipeline reproducible de AA en salud.\nConceptos clave: problema/tarea, train/val/test, baseline, feature engineering, normalización, data leakage.\nActividad práctica (PhysioNet, sklearn):\nClasificar latidos ECG (e.g., MIT-BIH o PTB-XL de PhysioNet). Preproceso básico, split estratificado por paciente (sin fuga), baseline con LogReg/SVM.\nStack: Python 3.12, scikit-learn, numpy, pandas, matplotlib.\nValidación: subject-wise k-fold (k=5).\nEvaluación: Mini-lab 1 (10%).\nReferencias sugeridas (verificar DOI/ISBN antes de publicar):\n\nBishop, Pattern Recognition and Machine Learning, 2006, ISBN 978-0387310732.\nPedregosa et al., Scikit-learn: Machine Learning in Python, JMLR 12:2825–2830, 2011.\n\nRiesgos comunes: fuga por segmentos del mismo paciente; métricas inadecuadas por clase desbalanceada.\n\n\n\n\n\n\nResultados:\nRA1. Implementar subject-wise k-fold y reportes por clase.\nRA2. Configurar entorno reproducible y seeds.\nRA3. Documentar experimentos (versionado y data cards).\nConceptos: subject-wise vs aleatorio, nested CV, semillas, hojas de datos, readme de experimentos.\nActividad (PhysioNet, sklearn):\nRepetir baseline sesión 1 con particionamiento subject-wise k-fold y reporte de varianza entre folds.\nStack: scikit-learn, mlflow (opcional), pyproject.toml o conda env, control de versiones.\nValidación: subject-wise k-fold con estratificación si aplica.\nEvaluación: Mini-lab 2 (10%).\nReferencias:\n\nGéron, Hands-On Machine Learning, 2ª/3ª ed., O’Reilly, ISBN 978-1492032649.\n\nRiesgos: comparar métricas de folds no homólogos; no fijar semillas; no congelar versiones.\n\n\n\n\n\n\nResultados:\nRA1. Aplicar filtrado, resampling y normalización en ECG/EMG.\nRA2. Extraer features en tiempo/frecuencia (RMS, picos R, bandas).\nRA3. Entrenar un clasificador clásico y evaluar robustez.\nConceptos: filtros pasa-banda, remoción de línea base, windowing, PSD, z-score.\nActividad (PhysioNet):\nECG MIT-BIH: detección de picos R + features → clasificación de latidos con RandomForest vs LogReg.\nStack: scikit-learn, scipy, wfdb (lectura PhysioNet), matplotlib.\nValidación: subject-wise k-fold; métricas: F1 macro, sensibilidad por clase.\nEvaluación: Mini-lab 3 (10%).\nReferencias:\n\nGoldberger et al., PhysioNet (portal oficial).\n\nRiesgos: overfitting por feature selection en todo el set; filtrado que distorsiona morfología.\n\n\n\n\n\n\nResultados:\nRA1. Implementar una CNN 1D simple y compararla con ML clásico.\nRA2. Seleccionar métricas y early stopping.\nRA3. Analizar errores por sujeto.\nConceptos: convolución 1D, receptive field, padding/stride, learning rate.\nActividad (PhysioNet):\nECG PTB-XL (multi-derivación) o MIT-BIH re-muestreado: baseline SVM vs CNN1D en PyTorch.\nStack: PyTorch, scikit-learn.\nValidación: subject-wise k-fold; confusion matrix por sujeto.\nEvaluación: Mini-lab 4 (10%).\nReferencias:\n\nGoodfellow et al., Deep Learning, MIT Press, ISBN 978-0262035613.\n\nRiesgos: comparar modelos con splits distintos; no balancear clases.\n\n\n\n\n\n\nResultados:\nRA1. Implementar LSTM/GRU/Transformers 1D para detección de eventos.\nRA2. Aplicar explicabilidad 1D (saliency, Integrated Gradients).\nRA3. Reportar variabilidad entre folds.\nConceptos: dependencias temporales, enmascaramiento, longitudes variables, atención.\nActividad (PhysioNet):\nPTB-XL (o EEG PhysioNet para eventos): modelo secuencial + saliency/IG (Captum).\nStack: PyTorch, captum, mne (si EEG).\nValidación: subject-wise k-fold; métricas por evento.\nEvaluación: Mini-lab 5 (10%).\nReferencias:\n\nHochreiter & Schmidhuber, LSTM (1997).\nVaswani et al., Attention Is All You Need (2017).\n\nRiesgos: secuencias truncadas sesgando etiquetas; explicaciones no estables entre folds.\n\n\n\n\n\n\nResultados:\nRA1. Cargar DICOM/series y normalizar intensidades.\nRA2. Ejecutar transfer learning con MONAI.\nRA3. Documentar data transforms y augmentations.\nConceptos: spacing, windowing, normalización, recortes, augment.\nActividad (TCIA):\nLIDC-IDRI (TCIA): clasificación simple de nódulos (benigno/sospechoso como etiqueta didáctica) con fine-tuning de ResNet.\nStack: MONAI, PyTorch, pydicom.\nValidación: subject-wise k-fold por paciente.\nEvaluación: Mini-lab 6 (10%).\nReferencias:\n\nMONAI (docs oficiales).\nArmato et al., LIDC-IDRI (descripción del dataset).\n\nRiesgos: fuga por cortes múltiples del mismo paciente en train/test; augment que altera anatomía.\n\n\n\n\n\n\nResultados:\nRA1. Entrenar U-Net para segmentación 2D.\nRA2. Evaluar con Dice/IoU y curvas de volumen.\nRA3. Aplicar Grad-CAM para inspección de atención.\nConceptos: U-Net (encoder-decoder), pérdida (Dice/BCE), tiling, posprocesado.\nActividad (TCIA):\nLIDC-IDRI: segmentación de nódulos con U-Net (MONAI) + Grad-CAM sobre cortes con ResNet para inspección.\nStack: MONAI, PyTorch, captum.\nValidación: subject-wise k-fold; reporte Dice por paciente.\nEvaluación: Mini-lab 7 (10%).\nReferencias:\n\nRonneberger et al., U-Net, MICCAI 2015 (DOI disponible).\nHe et al., ResNet, CVPR 2016.\n\nRiesgos: entrenar/validar en cortes del mismo estudio; segmentación con máscaras ruidosas.\n\n\n\n\n\n\nResultados:\nRA1. Integrar pipeline completo (datos → modelo → validación → reporte).\nRA2. Elaborar model card y data card resumidas.\nRA3. Defender decisiones de diseño con evidencia.\nConceptos: estructura de repositorio, model/data cards, checklist de reproducibilidad, trazabilidad de experimentos.\nActividad:\nIntegrar un caso señal (ECG) o imagen (TCIA) a elección: notebook final con README y report de métricas.\nStack: PyTorch, MONAI, scikit-learn, matplotlib.\nValidación: subject-wise k-fold; reporte agregando media±DE.\nEvaluación: Quiz final (30%).\nReferencias:\n\nMitchell et al., Model Cards for Model Reporting (FAccT).\n\nRiesgos: falta de seeds, rutas relativas no reproducibles, dependencias sin fijar versión.\n\n\n\n\n\n\nPython==3.12.*, seed fija (e.g., 42), requirements.txt o environment.yml, carpetas data/, notebooks/, models/, reports/.\nSubject-wise k-fold obligatorio; no mezclar cortes/derivaciones del mismo paciente entre splits.\nReportar media±DE por fold y por paciente cuando aplique.\n\n\n\n\n\n\nTextos:\n\nBishop (2006), PRML, ISBN 978-0387310732.\nGoodfellow, Bengio, Courville (2016), Deep Learning, ISBN 978-0262035613.\n\nSoftware:\n\nPedregosa et al. (2011), Scikit-learn, JMLR 12.\nPaszke et al. (2019), PyTorch (NeurIPS).\nMONAI (documentación oficial).\n\nSeñales (PhysioNet): MIT-BIH, PTB-XL, EEG Motor/Imagery. (Usar portal oficial; añadir DOI/URL confirmados antes de publicar)\nImágenes (TCIA): LIDC-IDRI. (Añadir DOI/URL confirmados antes de publicar)"
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#tabla-de-sesiones-24-h-8-sesiones-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#tabla-de-sesiones-24-h-8-sesiones-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "#\nTítulo\nBloque\nHoras\nEntregable\n\n\n\n\n1\nFundamentos de AA en salud: tareas, métricas y pipeline\nFundamentos\n3\nMini-lab 1: pipeline clásico (sklearn)\n\n\n2\nValidación rigurosa y reproducibilidad (subject-wise)\nFundamentos\n3\nMini-lab 2: split subject-wise + baseline\n\n\n3\nSeñales biomédicas I: preprocesado y features (ECG/EMG)\nSeñales\n3\nMini-lab 3: filtro → features → clasificación\n\n\n4\nSeñales biomédicas II: ML clásico vs CNN 1D\nSeñales\n3\nMini-lab 4: baseline vs CNN1D (comparativa)\n\n\n5\nSeñales biomédicas III: LSTM/GRU/Transformers 1D + explicabilidad\nSeñales\n3\nMini-lab 5: secuenciales + saliency/IG\n\n\n6\nImágenes médicas I: DICOM, preprocesado y transfer learning\nImágenes\n3\nMini-lab 6: fine-tuning (MONAI)\n\n\n7\nImágenes médicas II: U-Net/ResNet, métricas y Grad-CAM\nImágenes\n3\nMini-lab 7: segmentación + Grad-CAM\n\n\n8\nIntegración, buenas prácticas y quiz final\nImágenes (cierre)\n3\nQuiz final + repositorio reproducible\n\n\n\nBalance de horas por bloque (aprox.): Fundamentos 6 h (≈30%), Señales 9 h (≈35%), Imágenes 9 h (≈35%).\nEvaluación (modelo 5B): 7 mini-labs × 10% c/u = 70%; Quiz final = 30%."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#fundamentos-de-aa-en-salud-tareas-métricas-y-pipeline-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#fundamentos-de-aa-en-salud-tareas-métricas-y-pipeline-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados de aprendizaje:\nRA1. Diferenciar tareas (clasificación, regresión, segmentación).\nRA2. Seleccionar métricas apropiadas por tarea (Acc, AUC, F1, MAE; Dice/IoU para segmentación).\nRA3. Describir un pipeline reproducible de AA en salud.\nConceptos clave: problema/tarea, train/val/test, baseline, feature engineering, normalización, data leakage.\nActividad práctica (PhysioNet, sklearn):\nClasificar latidos ECG (e.g., MIT-BIH o PTB-XL de PhysioNet). Preproceso básico, split estratificado por paciente (sin fuga), baseline con LogReg/SVM.\nStack: Python 3.12, scikit-learn, numpy, pandas, matplotlib.\nValidación: subject-wise k-fold (k=5).\nEvaluación: Mini-lab 1 (10%).\nReferencias sugeridas (verificar DOI/ISBN antes de publicar):\n\nBishop, Pattern Recognition and Machine Learning, 2006, ISBN 978-0387310732.\nPedregosa et al., Scikit-learn: Machine Learning in Python, JMLR 12:2825–2830, 2011.\n\nRiesgos comunes: fuga por segmentos del mismo paciente; métricas inadecuadas por clase desbalanceada."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#validación-rigurosa-y-reproducibilidad-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#validación-rigurosa-y-reproducibilidad-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Implementar subject-wise k-fold y reportes por clase.\nRA2. Configurar entorno reproducible y seeds.\nRA3. Documentar experimentos (versionado y data cards).\nConceptos: subject-wise vs aleatorio, nested CV, semillas, hojas de datos, readme de experimentos.\nActividad (PhysioNet, sklearn):\nRepetir baseline sesión 1 con particionamiento subject-wise k-fold y reporte de varianza entre folds.\nStack: scikit-learn, mlflow (opcional), pyproject.toml o conda env, control de versiones.\nValidación: subject-wise k-fold con estratificación si aplica.\nEvaluación: Mini-lab 2 (10%).\nReferencias:\n\nGéron, Hands-On Machine Learning, 2ª/3ª ed., O’Reilly, ISBN 978-1492032649.\n\nRiesgos: comparar métricas de folds no homólogos; no fijar semillas; no congelar versiones."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-i-preprocesado-y-features-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-i-preprocesado-y-features-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Aplicar filtrado, resampling y normalización en ECG/EMG.\nRA2. Extraer features en tiempo/frecuencia (RMS, picos R, bandas).\nRA3. Entrenar un clasificador clásico y evaluar robustez.\nConceptos: filtros pasa-banda, remoción de línea base, windowing, PSD, z-score.\nActividad (PhysioNet):\nECG MIT-BIH: detección de picos R + features → clasificación de latidos con RandomForest vs LogReg.\nStack: scikit-learn, scipy, wfdb (lectura PhysioNet), matplotlib.\nValidación: subject-wise k-fold; métricas: F1 macro, sensibilidad por clase.\nEvaluación: Mini-lab 3 (10%).\nReferencias:\n\nGoldberger et al., PhysioNet (portal oficial).\n\nRiesgos: overfitting por feature selection en todo el set; filtrado que distorsiona morfología."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-ii-ml-clásico-vs-cnn-1d-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-ii-ml-clásico-vs-cnn-1d-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Implementar una CNN 1D simple y compararla con ML clásico.\nRA2. Seleccionar métricas y early stopping.\nRA3. Analizar errores por sujeto.\nConceptos: convolución 1D, receptive field, padding/stride, learning rate.\nActividad (PhysioNet):\nECG PTB-XL (multi-derivación) o MIT-BIH re-muestreado: baseline SVM vs CNN1D en PyTorch.\nStack: PyTorch, scikit-learn.\nValidación: subject-wise k-fold; confusion matrix por sujeto.\nEvaluación: Mini-lab 4 (10%).\nReferencias:\n\nGoodfellow et al., Deep Learning, MIT Press, ISBN 978-0262035613.\n\nRiesgos: comparar modelos con splits distintos; no balancear clases."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-iii-lstmgrutransformers-1d-explicabilidad-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#señales-biomédicas-iii-lstmgrutransformers-1d-explicabilidad-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Implementar LSTM/GRU/Transformers 1D para detección de eventos.\nRA2. Aplicar explicabilidad 1D (saliency, Integrated Gradients).\nRA3. Reportar variabilidad entre folds.\nConceptos: dependencias temporales, enmascaramiento, longitudes variables, atención.\nActividad (PhysioNet):\nPTB-XL (o EEG PhysioNet para eventos): modelo secuencial + saliency/IG (Captum).\nStack: PyTorch, captum, mne (si EEG).\nValidación: subject-wise k-fold; métricas por evento.\nEvaluación: Mini-lab 5 (10%).\nReferencias:\n\nHochreiter & Schmidhuber, LSTM (1997).\nVaswani et al., Attention Is All You Need (2017).\n\nRiesgos: secuencias truncadas sesgando etiquetas; explicaciones no estables entre folds."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#imágenes-médicas-i-dicom-preprocesado-y-transfer-learning-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#imágenes-médicas-i-dicom-preprocesado-y-transfer-learning-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Cargar DICOM/series y normalizar intensidades.\nRA2. Ejecutar transfer learning con MONAI.\nRA3. Documentar data transforms y augmentations.\nConceptos: spacing, windowing, normalización, recortes, augment.\nActividad (TCIA):\nLIDC-IDRI (TCIA): clasificación simple de nódulos (benigno/sospechoso como etiqueta didáctica) con fine-tuning de ResNet.\nStack: MONAI, PyTorch, pydicom.\nValidación: subject-wise k-fold por paciente.\nEvaluación: Mini-lab 6 (10%).\nReferencias:\n\nMONAI (docs oficiales).\nArmato et al., LIDC-IDRI (descripción del dataset).\n\nRiesgos: fuga por cortes múltiples del mismo paciente en train/test; augment que altera anatomía."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#imágenes-médicas-ii-u-netresnet-métricas-y-grad-cam-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#imágenes-médicas-ii-u-netresnet-métricas-y-grad-cam-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Entrenar U-Net para segmentación 2D.\nRA2. Evaluar con Dice/IoU y curvas de volumen.\nRA3. Aplicar Grad-CAM para inspección de atención.\nConceptos: U-Net (encoder-decoder), pérdida (Dice/BCE), tiling, posprocesado.\nActividad (TCIA):\nLIDC-IDRI: segmentación de nódulos con U-Net (MONAI) + Grad-CAM sobre cortes con ResNet para inspección.\nStack: MONAI, PyTorch, captum.\nValidación: subject-wise k-fold; reporte Dice por paciente.\nEvaluación: Mini-lab 7 (10%).\nReferencias:\n\nRonneberger et al., U-Net, MICCAI 2015 (DOI disponible).\nHe et al., ResNet, CVPR 2016.\n\nRiesgos: entrenar/validar en cortes del mismo estudio; segmentación con máscaras ruidosas."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#integración-buenas-prácticas-y-quiz-final-3-h",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#integración-buenas-prácticas-y-quiz-final-3-h",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Resultados:\nRA1. Integrar pipeline completo (datos → modelo → validación → reporte).\nRA2. Elaborar model card y data card resumidas.\nRA3. Defender decisiones de diseño con evidencia.\nConceptos: estructura de repositorio, model/data cards, checklist de reproducibilidad, trazabilidad de experimentos.\nActividad:\nIntegrar un caso señal (ECG) o imagen (TCIA) a elección: notebook final con README y report de métricas.\nStack: PyTorch, MONAI, scikit-learn, matplotlib.\nValidación: subject-wise k-fold; reporte agregando media±DE.\nEvaluación: Quiz final (30%).\nReferencias:\n\nMitchell et al., Model Cards for Model Reporting (FAccT).\n\nRiesgos: falta de seeds, rutas relativas no reproducibles, dependencias sin fijar versión."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#requisitos-de-reproducibilidad",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#requisitos-de-reproducibilidad",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Python==3.12.*, seed fija (e.g., 42), requirements.txt o environment.yml, carpetas data/, notebooks/, models/, reports/.\nSubject-wise k-fold obligatorio; no mezclar cortes/derivaciones del mismo paciente entre splits.\nReportar media±DE por fold y por paciente cuando aplique."
  },
  {
    "objectID": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#apéndice-referencias-globales-y-datasets-portal-oficial",
    "href": "presentaciones/ASIM/IndiceExtendido_AA_Senales_Imagenes_24h.html#apéndice-referencias-globales-y-datasets-portal-oficial",
    "title": "Índice extendido — Curso de Aprendizaje Automático para Señales e Imágenes Médicas (24 h)",
    "section": "",
    "text": "Textos:\n\nBishop (2006), PRML, ISBN 978-0387310732.\nGoodfellow, Bengio, Courville (2016), Deep Learning, ISBN 978-0262035613.\n\nSoftware:\n\nPedregosa et al. (2011), Scikit-learn, JMLR 12.\nPaszke et al. (2019), PyTorch (NeurIPS).\nMONAI (documentación oficial).\n\nSeñales (PhysioNet): MIT-BIH, PTB-XL, EEG Motor/Imagery. (Usar portal oficial; añadir DOI/URL confirmados antes de publicar)\nImágenes (TCIA): LIDC-IDRI. (Añadir DOI/URL confirmados antes de publicar)"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#la-dimensión-temporal-en-ia",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#la-dimensión-temporal-en-ia",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "1. La Dimensión Temporal en IA",
    "text": "1. La Dimensión Temporal en IA\n\nEl Paradigma Estático: Las redes feedforward tradicionales asumen independencia entre muestras (ej. clasificación de imágenes estáticas).\nLa Realidad Dinámica: El mundo físico y cognitivo es secuencial (lenguaje, audio, señales biológicas, finanzas).\nLa Necesidad de Memoria: Se requiere una arquitectura capaz de mantener un “estado” o contexto histórico para interpretar el presente."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#redes-neuronales-recurrentes-rnn",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#redes-neuronales-recurrentes-rnn",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "2. Redes Neuronales Recurrentes (RNN)",
    "text": "2. Redes Neuronales Recurrentes (RNN)\nConcepto Fundamental\nLa RNN rompe la estructura acíclica. Al “desenrollar” la red en el tiempo, procesa la secuencia paso a paso compartiendo los mismos pesos (\\(W\\)).\n\n\\[h_t = \\sigma_h (W_{ih} x_t + W_{hh} h_{t-1} + b)\\]\n\n\n\n\n\\(h_t\\): Estado oculto (memoria) actual.\n\\(h_{t-1}\\): Estado previo.\n\\(x_t\\): Entrada actual.\n\n\n\n\\(W_{hh}\\): Matriz recurrente (Memoria).\n\\(\\sigma_h\\): Activación (\\(\\tanh\\))."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#el-problema-del-gradiente",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#el-problema-del-gradiente",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "El Problema del Gradiente",
    "text": "El Problema del Gradiente\nEntrenamiento mediante Backpropagation Through Time (BPTT).\nLa derivada del error respecto a los pesos recurrentes implica un producto continuo de matrices Jacobianas:\n\\[ \\frac{\\partial h_t}{\\partial h_k} = \\prod_{j=k+1}^t \\text{diag}(\\sigma'(z_j)) W_{hh} \\]\n\n\n\n\n\n\nPatologías Espectrales\n\n\n\nDesvanecimiento (\\(\\rho &lt; 1\\)): El gradiente tiende a cero. La red “olvida” relaciones lejanas (ej. sujeto vs. verbo en párrafos largos).\nExplosión (\\(\\rho &gt; 1\\)): El gradiente diverge. Requiere Gradient Clipping."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#long-short-term-memory-lstm",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#long-short-term-memory-lstm",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "3. Long Short-Term Memory (LSTM)",
    "text": "3. Long Short-Term Memory (LSTM)\nIngeniería de la Persistencia\nDiseñada para mitigar el desvanecimiento del gradiente introduciendo una Celda de Memoria (\\(C_t\\)) separada del estado oculto.\n\nInnovación Clave: El “Carrusel de Error Constante”. La información fluye por la celda con interacciones lineales (sumas), protegiendo la señal del gradiente."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#la-neurona-lstm",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#la-neurona-lstm",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "La neurona LSTM",
    "text": "La neurona LSTM\n\nTomada de codificando bits"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#anatomía-de-la-lstm-12",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#anatomía-de-la-lstm-12",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "Anatomía de la LSTM (1/2)",
    "text": "Anatomía de la LSTM (1/2)\nEl flujo es regulado por Compuertas Sigmoidales (\\(\\sigma \\in [0, 1]\\)):\n\n\n1. Compuerta de Olvido (\\(f_t\\))\n¿Qué borramos del pasado? \\[f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\\]\n2. Compuerta de Entrada (\\(i_t\\))\n¿Qué información nueva guardamos? \\[i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\\]\n\nMemoria Candidata (\\(\\tilde{C}_t\\))\nPropuesta de nuevo contenido. \\[\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#anatomía-de-la-lstm-22",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#anatomía-de-la-lstm-22",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "Anatomía de la LSTM (2/2)",
    "text": "Anatomía de la LSTM (2/2)\nActualización y Salida\n3. Actualización de Celda (\\(C_t\\))\nCombinación lineal crítica. Aquí ocurre la magia de la persistencia. \\[C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t\\]\n4. Generación de Salida (\\(h_t\\))\nFiltrado de la memoria para el uso inmediato. \\[o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\\] \\[h_t = o_t \\odot \\tanh(C_t)\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#gated-recurrent-units-gru",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#gated-recurrent-units-gru",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "4. Gated Recurrent Units (GRU)",
    "text": "4. Gated Recurrent Units (GRU)\nEficiencia y Simplificación\nPropuesta para reducir la complejidad computacional de la LSTM sin sacrificar rendimiento.\n\nFusión de Estados: No hay celda \\(C_t\\) separada. Solo existe \\(h_t\\).\nReducción de Compuertas: Solo dos compuertas (Update y Reset)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#dinámica-de-la-gru",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#dinámica-de-la-gru",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "Dinámica de la GRU",
    "text": "Dinámica de la GRU\n\n\nCompuerta de Actualización (\\(z_t\\)): Fusiona las funciones de entrada y olvido. \\[z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t])\\]\nCompuerta de Reinicio (\\(r_t\\)): Decide cuánto del pasado ignorar para el cálculo actual. \\[r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t])\\]\n\nInterpolación Final: \\[h_t = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t\\]\nPermite saltar pasos temporales o sobrescribir memoria completamente."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#comparativa-técnica",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#comparativa-técnica",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "Comparativa Técnica",
    "text": "Comparativa Técnica\n\n\n\nCaracterística\nLSTM\nGRU\n\n\n\n\nComplejidad\nAlta (3 compuertas)\nMedia (2 compuertas)\n\n\nParámetros\n\\(4 \\times ((n+m)n + n)\\)\n\\(\\approx 25\\%\\) menos\n\n\nMemoria\nEstado Oculto + Celda\nSolo Estado Oculto\n\n\nDependencias\nExtremadamente largas\nLargas / Medias\n\n\nDatos Requeridos\nAlto volumen\nFunciona bien con Small Data"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#implementación-en-pytorch",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#implementación-en-pytorch",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "5. Implementación en PyTorch",
    "text": "5. Implementación en PyTorch\nEstructura modular agnóstica a la arquitectura (“Many-to-One”).\n\nimport torch.nn as nn\n\nclass ClasificadorRecurrente(nn.Module):\n    def __init__(self, tipo_rnn, input_size, hidden_size, num_classes):\n        super().__init__()\n\n        # Selección Dinámica de Arquitectura\n        if tipo_rnn == 'LSTM':\n            self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True)\n        elif tipo_rnn == 'GRU':\n            self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n        else:\n            self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):\n        # x shape: (Batch, Seq_Len, Features)\n\n        # Propagación\n        if isinstance(self.rnn, nn.LSTM):\n            out, (hn, cn) = self.rnn(x) # LSTM devuelve tupla\n        else:\n            out, hn = self.rnn(x)       # GRU/RNN devuelven tensor\n\n        # Clasificación basada en el último paso de tiempo\n        last_step = out[:, -1, :]\n        return self.fc(last_step)"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#rnns-en-la-era-de-transformers",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#rnns-en-la-era-de-transformers",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "6. RNNs en la Era de Transformers",
    "text": "6. RNNs en la Era de Transformers\n¿Por qué seguir usando RNN/GRU hoy en día?\n\nComplejidad Computacional:\n\nTransformers: \\(O(N^2)\\) en tiempo/memoria (o Caché KV lineal).\nRNN/GRU: \\(O(1)\\) en memoria durante inferencia.\n\nEdge AI / TinyML:\n\nIdeales para microcontroladores (Wearables, Sensores IoT).\n\nStreaming:\n\nProcesamiento de audio/señales en tiempo real con latencia cero (Wake Word Detection)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#conclusión",
    "href": "presentaciones/ASIM/v2Lect005_RNN_GRU_LSTM.html#conclusión",
    "title": "Arquitecturas de Memoria Profunda",
    "section": "Conclusión",
    "text": "Conclusión\n\n\n\n\n\n\nResumen\n\n\n\nRNN: Fundamento teórico del aprendizaje secuencial. Inestable en secuencias largas.\nLSTM: Estándar de oro para dependencias complejas gracias a su celda de memoria protegida.\nGRU: La opción eficiente. Menor coste computacional, ideal para inferencia rápida y Edge Computing.\n\n\n\n\nLa elección arquitectónica depende del balance entre capacidad de memoria y restricciones de latencia/hardware."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#objetivos-de-aprendizaje",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#objetivos-de-aprendizaje",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Objetivos de aprendizaje",
    "text": "Objetivos de aprendizaje\n\nComprender los fundamentos de la Regresión Lineal, Regresión Logística y Perceptrón Multicapa (MLP).\nAplicar estos modelos al contexto de salud fetal con datos de cardiotocografía (CTG).\nEvaluar el desempeño con métricas adecuadas (MSE, AUC/Log-Loss, matriz de confusión, F1).\n\n\n\n\nRegresión Lineal\nRegresión Logística\nPerceptrón Multicapa\nCierre y discusión\n\n\nDataset: fetal_health.csv (UCI CTG). Contexto clínico: interpretación de CTG (normal, sospechoso, patológico)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#contexto-clínico-ctg",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#contexto-clínico-ctg",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Contexto clínico (CTG)",
    "text": "Contexto clínico (CTG)\n\n\n\n\n\n\n\nDefición\n\n\nPrueba médica que monitoriza simultáneamente la frecuencia cardíaca del feto y la actividad contráctil del útero. Se realiza generalmente durante el tercer trimestre del embarazo y el parto, colocando dos transductores externos (uno para la frecuencia cardíaca fetal y otro para las contracciones) sobre el abdomen de la madre\n\n\n\n\n\nGenerada con Gemini"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#contexto-clínico-ctg-1",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#contexto-clínico-ctg-1",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Contexto clínico (CTG)",
    "text": "Contexto clínico (CTG)\n\n\n\n\n\n\n\nCaracterística (Variable en CSV)\nCálculo o Descripción\n\n\n\n\nParámetros Basales\n\n\n\nbaseline value\nEs la frecuencia cardíaca fetal (FCF) media aproximada en un segmento de 10 minutos, excluyendo aceleraciones, deceleraciones y períodos de variabilidad marcada (&gt;25 lpm). Se redondea a incrementos de 5 latidos por minuto (lpm).[4, 5, 6, 7, 8] El rango normal se considera entre 110 y 160 lpm.[9, 10]\n\n\nfetal_movement\nNúmero de movimientos fetales detectados por segundo.[1, 11, 12]\n\n\nuterine_contractions\nNúmero de contracciones uterinas por segundo. Se considera normal tener 5 o menos contracciones en 10 minutos.[1, 4, 11, 12]\n\n\nEventos Transitorios (Aceleraciones y Deceleraciones)\n\n\n\naccelerations\nNúmero de aceleraciones por segundo. Una aceleración es un aumento abrupto de la FCF por encima de la línea de base de al menos 15 lpm, que dura 15 segundos o más, pero menos de 2 minutos.[5, 9, 10]\n\n\nlight_decelerations\nNúmero de deceleraciones leves por segundo. Una deceleración es una caída de la FCF de más de 15 lpm que dura más de 15 segundos.[5] La categoría “leve” se refiere a su duración, típicamente menor a 120 segundos.[3]\n\n\nsevere_decelerations\nNúmero de deceleraciones severas por segundo. Se refiere a deceleraciones de larga duración, a menudo definidas como aquellas que superan los 300 segundos.[3]\n\n\nprolongued_decelerations\nNúmero de deceleraciones prolongadas por segundo. Son caídas de la FCF que duran más de 2 o 3 minutos pero menos de 10 minutos.[3, 6, 13]\n\n\nVariabilidad de la FCF\n\n\n\nabnormal_short_term_variability\nPorcentaje de tiempo en que la variabilidad a corto plazo (latido a latido) es anormal. La variabilidad se considera anormal si es mínima (≤5 lpm) o marcada (&gt;25 lpm).[6, 8]\n\n\nmean_value_of_short_term_variability\nValor medio de la variabilidad a corto plazo (STV), que describe las fluctuaciones de la FCF latido a latido.[3, 6]\n\n\npercentage_of_time_with_abnormal_long_term_variability\nPorcentaje de tiempo en que la variabilidad a largo plazo es anormal. Se calcula sobre las fluctuaciones de la FCF en un período de un minuto.[5]\n\n\nmean_value_of_long_term_variability\nValor medio de la variabilidad a largo plazo (LTV), que mide la amplitud (diferencia entre el pico y el valle) de las fluctuaciones de la FCF en un minuto.[3, 5]\n\n\nCaracterísticas del Histograma de FCF\nEstas son propiedades estadísticas calculadas a partir de la distribución de todos los valores de FCF registrados durante el período de monitorización.[1, 11, 12]\n\n\nhistogram_width\nEl ancho del histograma, calculado como la diferencia entre el valor máximo (histogram_max) y el mínimo (histogram_min) de la FCF.\n\n\nhistogram_min\nEl valor mínimo de la FCF registrado en el histograma.\n\n\nhistogram_max\nEl valor máximo de la FCF registrado en el histograma.\n\n\nhistogram_number_of_peaks\nEl número de picos en la distribución del histograma.\n\n\nhistogram_number_of_zeroes\nEl número de “ceros” o bins con frecuencia cero en el histograma.\n\n\nhistogram_mode\nEl valor de FCF que aparece con mayor frecuencia (la moda estadística).\n\n\nhistogram_mean\nEl valor medio de la FCF en el histograma (la media estadística).\n\n\nhistogram_median\nEl valor central de la FCF en el histograma (la mediana estadística).\n\n\nhistogram_variance\nLa varianza de los valores de FCF, que mide su dispersión alrededor de la media.\n\n\nhistogram_tendency\nIndica la simetría o sesgo del histograma. Puede interpretarse como: 1 para tendencia a la derecha (positiva), -1 para tendencia a la izquierda (negativa) y 0 para una distribución simétrica."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#contexto-clínico-ctg-2",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#contexto-clínico-ctg-2",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Contexto clínico (CTG)",
    "text": "Contexto clínico (CTG)\n\nCTG registra FCF y contracciones uterinas.\nClasificación clínica (FIGO): normal / sospechoso / patológico.\nVariabilidad, aceleraciones y desaceleraciones son claves."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#regresión-lineal",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#regresión-lineal",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Regresión Lineal",
    "text": "Regresión Lineal\nIdea clave\nAproxima una relación lineal \\(\\hat{y} = \\beta_0 + \\sum_j \\beta_j x_j\\)minimizando MSE.\nEjemplo didáctico (CTG)\nUsamos una variable continua de CTG como respuesta (p. ej., histogram_width) para ilustrar ajuste y residuales.\n\nDiscusión: supuestos (linealidad, homocedasticidad, independencia), diagnóstico con residuales."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#regresión-logística",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#regresión-logística",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Regresión Logística",
    "text": "Regresión Logística\nIdea clave\nModela \\(P(Y=1 \\mid \\mathbf{x}) = \\sigma(\\beta_0 + \\mathbf{x}^\\top \\beta)\\) con sigmoide \\(\\sigma(z)=1/(1+e^{-z})\\)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#definición-de-regresión-logística",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#definición-de-regresión-logística",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "1. Definición de Regresión Logística",
    "text": "1. Definición de Regresión Logística\nLa Regresión Logística es un algoritmo de aprendizaje automático supervisado utilizado fundamentalmente para problemas de clasificación binaria.\nA pesar de su nombre, su objetivo no es predecir un valor continuo, sino modelar la probabilidad (\\(P\\)) de que una observación pertenezca a una clase específica (usualmente denotada como \\(Y=1\\)).\nEl modelo toma variables de entrada (features) \\(x_1, \\dots, x_n\\) y estima \\(P(Y=1 | \\mathbf{x})\\)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#el-mecanismo-central-del-modelo",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#el-mecanismo-central-del-modelo",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "2. El Mecanismo Central del Modelo",
    "text": "2. El Mecanismo Central del Modelo\nEl modelo logístico opera en dos pasos cruciales:\n2.1. El Componente Lineal (Logit)\nPrimero, el modelo calcula una suma ponderada de las entradas, exactamente igual que en una regresión lineal. A este resultado (\\(z\\)) se le conoce como logit o, más formalmente, log-odds.\n\\[\nz = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n\\]\n\n\\(\\beta_0\\) es el intercepto (sesgo).\n\\(\\beta_{1 \\dots n}\\) son los coeficientes (pesos) que el modelo aprende.\nEl rango de salida de \\(z\\) es el de todos los números reales: \\((-\\infty, +\\infty)\\).\n\n2.2. La Función Sigmoide (Logística)\nDado que una probabilidad debe estar en el rango \\([0, 1]\\), \\(z\\) no puede ser el resultado final. La regresión logística aplica la función sigmoide (\\(\\sigma\\)) a \\(z\\) para “aplastar” (squash) la salida lineal al rango de probabilidad.\n\\[\nP = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n\\]\n\nSi \\(z \\to +\\infty\\), \\(e^{-z} \\to 0\\), y \\(P \\to 1\\).\nSi \\(z \\to -\\infty\\), \\(e^{-z} \\to +\\infty\\), y \\(P \\to 0\\).\nSi \\(z = 0\\), \\(e^{-0} = 1\\), y \\(P = 0.5\\)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#la-relación-clave-probabilidad-y-log-odds",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#la-relación-clave-probabilidad-y-log-odds",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "3. La Relación Clave: Probabilidad y Log-Odds",
    "text": "3. La Relación Clave: Probabilidad y Log-Odds\nEl concepto central que conecta el modelo lineal con la probabilidad es el log-odds. Esta transformación es necesaria para mapear un espacio acotado \\([0, 1]\\) a un espacio no acotado \\([-\\infty, +\\infty]\\).\n3.1. De Probabilidad a Log-Odds\nLa transformación se realiza en dos pasos:\n\nProbabilidad (\\(P\\)): La probabilidad del evento.\n\nRango: \\([0, 1]\\)\n\nOdds (Momios): La razón entre la probabilidad de que ocurra (\\(P\\)) y la de que no ocurra (\\(1-P\\)). \\[\nOdds = \\frac{P}{1-P}\n\\]\n\nRango: \\([0, +\\infty]\\)\n\nLog-Odds (Logit): El logaritmo natural de los odds. \\[\nLogit(P) = \\ln(Odds) = \\ln\\left(\\frac{P}{1-P}\\right)\n\\]\n\nRango: \\([-\\infty, +\\infty]\\)\n\n\nEl modelo de regresión logística es, por tanto, un modelo lineal que predice el log-odds:\n\\[\nz = \\ln\\left(\\frac{P}{1-P}\\right) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n\n\\]\n3.2. De Log-Odds a Probabilidad (La Inversa)\nPara obtener la probabilidad \\(P\\) a partir del log-odds \\(z\\), simplemente revertimos la transformación Logit. Este proceso de despejar \\(P\\) de la ecuación del logit da origen a la función sigmoide:\n\nEcuación base: \\[\nz = \\ln\\left(\\frac{P}{1-P}\\right)\n\\]\nAplicar exponencial (inversa del logaritmo): \\[\ne^z = \\frac{P}{1-P}\n\\]\nDespejar \\(P\\): \\[\ne^z (1-P) = P\n\\] \\[\ne^z - e^z P = P\n\\] \\[\ne^z = P + e^z P\n\\] \\[\ne^z = P (1 + e^z)\n\\]\nProbabilidad \\(P\\) en función de \\(z\\): \\[\nP = \\frac{e^z}{1 + e^z}\n\\]\nForma sigmoide alternativa (dividiendo numerador y denominador por \\(e^z\\)): \\[\nP = \\frac{e^z/e^z}{(1 + e^z)/e^z} = \\frac{1}{e^{-z} + 1} = \\frac{1}{1 + e^{-z}}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#interpretación-de-coeficientes",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#interpretación-de-coeficientes",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "4. Interpretación de Coeficientes",
    "text": "4. Interpretación de Coeficientes\nDebido a esta relación, los coeficientes (\\(\\beta_i\\)) del modelo tienen una interpretación específica:\n\nCoeficiente \\(\\beta_i\\): Un incremento de una unidad en la variable \\(x_i\\) (manteniendo las demás constantes) genera un cambio de \\(\\beta_i\\) en el log-odds de la predicción.\nOdds Ratio (OR): Para una interpretación más intuitiva, se utiliza \\(e^{\\beta_i}\\). Un incremento de una unidad en \\(x_i\\) multiplica los odds por un factor de \\(e^{\\beta_i}\\).\n\n\n\n\n\n\n\n\n\n\nClasificación binaria (Normal vs No‑Normal)\n\n\n              precision    recall  f1-score   support\n\n           0      0.778     0.745     0.761        94\n           1      0.929     0.940     0.934       332\n\n    accuracy                          0.897       426\n   macro avg      0.853     0.842     0.848       426\nweighted avg      0.895     0.897     0.896       426"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#el-punto-de-partida-regresión-lineal",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#el-punto-de-partida-regresión-lineal",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "1. El Punto de Partida: Regresión Lineal",
    "text": "1. El Punto de Partida: Regresión Lineal\nEl problema de regresión estándar busca encontrar una función \\(f\\) que mapee entradas \\(\\mathbf{x}\\) a una salida \\(y\\).\nEn la Regresión Lineal, asumimos que la relación es lineal:\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n + \\epsilon\n\\] O en forma vectorial: \\[\ny = \\mathbf{\\beta}^T \\mathbf{x} + \\beta_0\n\\]\n\nObjetivo: Encontrar los parámetros óptimos (\\(\\mathbf{\\beta}, \\beta_0\\)) que minimizan una función de pérdida (ej. Error Cuadrático Medio, MSE).\nLimitación: El modelo está restringido a representar únicamente relaciones lineales."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#el-punto-de-partida-regresión-lineal-1",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#el-punto-de-partida-regresión-lineal-1",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "1. El Punto de Partida: Regresión Lineal",
    "text": "1. El Punto de Partida: Regresión Lineal\n\nEsquema Regresión Lineal"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#primera-generalización-el-glm",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#primera-generalización-el-glm",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "2. Primera Generalización: El GLM",
    "text": "2. Primera Generalización: El GLM\n¿Qué pasa si la salida no es lineal o no sigue una distribución normal? (Ej. clasificación binaria).\nUsamos un Modelo Lineal Generalizado (GLM), como la Regresión Logística:\n\nPredictor Lineal (\\(z\\)): Mantenemos el núcleo lineal. \\[\nz = \\mathbf{\\beta}^T \\mathbf{x} + \\beta_0\n\\] El resultado \\(z\\) (el logit) puede ir de \\((-\\infty, +\\infty)\\).\nFunción de Enlace (Inversa): Aplicamos una transformación no-lineal \\(g^{-1}\\) para mapear \\(z\\) al rango deseado (ej. \\([0, 1]\\) para probabilidad). \\[\n\\hat{y} = g^{-1}(z) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n\\]\n\n\nAvance: Hemos generalizado la regresión. El modelo sigue siendo lineal en sus parámetros \\(\\mathbf{w}\\), pero puede modelar fenómenos no lineales mediante una función de activación (la sigmoide)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#primera-generalización-el-glm-1",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#primera-generalización-el-glm-1",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "2. Primera Generalización: El GLM",
    "text": "2. Primera Generalización: El GLM\n\nEsquema Regresión Logistica"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#la-neurona-una-unidad-de-regresión",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#la-neurona-una-unidad-de-regresión",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "3. La Neurona: Una Unidad de Regresión",
    "text": "3. La Neurona: Una Unidad de Regresión\nUna neurona artificial (o Perceptrón) es conceptualmente idéntica a un modelo de regresión logística (un GLM).\n\nAgregación Lineal: Calcula el predictor lineal \\(z\\) (la entrada neta). \\[\nz = \\sum_{i=1}^n w_i x_i + b\n\\]\nFunción de Activación: Aplica una transformación no-lineal \\(a\\) (la salida). \\[\na = g(z)\n\\]\n\n\n\\(g(z)\\) puede ser \\(\\text{sigmoid}(z)\\), \\(\\tanh(z)\\), \\(\\text{ReLU}(z)\\), etc.\nConcepto Clave: Una sola neurona es una unidad de regresión (lineal o generalizada) que aprende un único límite de decisión (o una respuesta lineal)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#la-neurona-una-unidad-de-regresión-1",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#la-neurona-una-unidad-de-regresión-1",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "3. La Neurona: Una Unidad de Regresión",
    "text": "3. La Neurona: Una Unidad de Regresión\n\nEsquema Neurona Artificial"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#la-red-composición-de-funciones",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#la-red-composición-de-funciones",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "4. La Red: Composición de Funciones",
    "text": "4. La Red: Composición de Funciones\n¿Cómo modelar relaciones altamente complejas que una sola neurona no puede capturar?\nRespuesta: Apilando las neuronas en capas.\nLa salida de una capa de “unidades de regresión” se convierte en la entrada de la siguiente capa.\n\\[\n\\text{Capa 1 (Oculta): } \\mathbf{a}^{(1)} = g_1(\\mathbf{W}^{(1)}\\mathbf{x} + \\mathbf{b}^{(1)})\n\\] \\[\n\\text{Capa 2 (Salida): } \\hat{y} = g_2(\\mathbf{W}^{(2)}\\mathbf{a}^{(1)} + \\mathbf{b}^{(2)})\n\\]\nEsto es una composición de funciones anidada:\n\\[\n\\hat{y} = g_2\\left( \\mathbf{W}^{(2)} \\left( g_1(\\mathbf{W}^{(1)}\\mathbf{x} + \\mathbf{b}^{(1)}) \\right) + \\mathbf{b}^{(2)} \\right)\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#el-teorema-de-aproximación-universal",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#el-teorema-de-aproximación-universal",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "5. El Teorema de Aproximación Universal",
    "text": "5. El Teorema de Aproximación Universal\nEsta arquitectura de “regresiones apiladas” tiene una propiedad fundamental:\n\nTeorema de Aproximación Universal: Una red neuronal feedforward con una sola capa oculta (con una función de activación no lineal, como ReLU o Sigmoide) puede aproximar cualquier función continua \\(f(\\mathbf{x})\\) a un grado arbitrario de precisión, dado un número suficiente de neuronas.\n\n\nUna regresión lineal solo puede encontrar la mejor línea.\nUna red neuronal puede encontrar (aprender) la función \\(f(\\mathbf{x})\\) en sí misma, sin importar su forma.\n\nLa red neuronal es un regresor generalizado en el sentido más amplio."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#generalización-del-aprendizaje-optimización",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#generalización-del-aprendizaje-optimización",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "6. Generalización del Aprendizaje (Optimización)",
    "text": "6. Generalización del Aprendizaje (Optimización)\nEl proceso de “entrenamiento” también es una generalización de la regresión.\n\n\n\nRegresión (Lineal/Logística)\n\nPérdida: Se define una función de coste (Loss Function) \\(L(y, \\hat{y})\\).\n\nEj. MSE: \\(L = (y - \\hat{y})^2\\)\nEj. Cross-Entropy: \\(L = -[y \\log(\\hat{y}) + (1-y) \\log(1-\\hat{y})]\\)\n\nOptimización: Se encuentran los \\(\\mathbf{w}\\) y \\(b\\) que minimizan \\(L\\) (a menudo usando Descenso de Gradiente).\n\n\n\n\nRed Neuronal\n\nPérdida: Se define la misma función de coste \\(L(y, \\hat{y})\\) en la salida final.\nOptimización: Se encuentran todos los \\(\\mathbf{W}^{(l)}\\) y \\(\\mathbf{b}^{(l)}\\) de todas las capas que minimizan \\(L\\).\nMecanismo: Descenso de Gradiente + Backpropagation (Retropropagación).\n\nBackpropagation es simplemente la aplicación sistemática de la regla de la cadena del cálculo para encontrar el gradiente de \\(L\\) con respecto a cada peso en la vasta función compuesta."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#conclusión-la-red-como-f_thetamathbfx",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#conclusión-la-red-como-f_thetamathbfx",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "7. Conclusión: La Red como \\(f_{\\theta}(\\mathbf{x})\\)",
    "text": "7. Conclusión: La Red como \\(f_{\\theta}(\\mathbf{x})\\)\n\nRegresión Lineal:\n\nModelo: \\(f(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} + b\\)\nAsume una forma funcional fija (lineal).\n\nGLM (Logística):\n\nModelo: \\(f(\\mathbf\n{x}) = g(\\mathbf{w}^T \\mathbf{x} + b)\\)\nAsume una forma fija (lineal) transformada por una activación fija (ej. sigmoide).\n\nRed Neuronal (MLP):\n\nModelo: \\(f(\\mathbf{x}) = f_L(\\dots f_2(f_1(\\mathbf{x}))\\dots)\\)\nNo asume una forma funcional fija.\nEs un aproximador de funciones universal cuyos parámetros \\(\\theta\\) (todos los \\(W\\) y \\(b\\)) se aprenden para que \\(f_{\\theta}(\\mathbf{x})\\) imite la verdadera función subyacente \\(f(\\mathbf{x})\\) en los datos.\n\n\nLa red neuronal es la generalización última de la regresión: un sistema que aprende la forma de la función desde los datos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#perceptrón-multicapa-mlp",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#perceptrón-multicapa-mlp",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Perceptrón Multicapa — MLP",
    "text": "Perceptrón Multicapa — MLP\nArquitectura propuesta: 21→32→16→3 con ReLU y softmax para 3 clases \\((1,2,3)\\).\n\n\n\n\n\n\n\nMLP_FetalHealth\n\n\ncluster_input\n\nInput layer (21 CTG features)\n\n\ncluster_hidden1\n\nHidden layer 1 (ReLU, 32)\n\n\ncluster_hidden2\n\nHidden layer 2 (ReLU, 16)\n\n\ncluster_output\n\nOutput layer (Softmax, 3 classes: Normal, Suspect, Pathological)\n\n\n\ni1\n\ni1\n\n\n\nh1_1\n\nh1_1\n\n\n\ni1-&gt;h1_1\n\n\n\n\n\nh1_2\n\nh1_2\n\n\n\ni1-&gt;h1_2\n\n\n\n\n\nh1_3\n\nh1_3\n\n\n\ni1-&gt;h1_3\n\n\n\n\n\nh1_4\n\nh1_4\n\n\n\ni1-&gt;h1_4\n\n\n\n\n\nh1_5\n\nh1_5\n\n\n\ni1-&gt;h1_5\n\n\n\n\n\ni2\n\ni2\n\n\n\ni2-&gt;h1_2\n\n\n\n\n\ni2-&gt;h1_3\n\n\n\n\n\ni2-&gt;h1_4\n\n\n\n\n\ni2-&gt;h1_5\n\n\n\n\n\nh1_6\n\nh1_6\n\n\n\ni2-&gt;h1_6\n\n\n\n\n\ni3\n\ni3\n\n\n\ni3-&gt;h1_3\n\n\n\n\n\ni3-&gt;h1_4\n\n\n\n\n\ni3-&gt;h1_5\n\n\n\n\n\ni3-&gt;h1_6\n\n\n\n\n\nh1_7\n\nh1_7\n\n\n\ni3-&gt;h1_7\n\n\n\n\n\ni4\n\ni4\n\n\n\ni4-&gt;h1_4\n\n\n\n\n\ni4-&gt;h1_5\n\n\n\n\n\ni4-&gt;h1_6\n\n\n\n\n\ni4-&gt;h1_7\n\n\n\n\n\nh1_8\n\nh1_8\n\n\n\ni4-&gt;h1_8\n\n\n\n\n\ni5\n\ni5\n\n\n\ni5-&gt;h1_5\n\n\n\n\n\ni5-&gt;h1_6\n\n\n\n\n\ni5-&gt;h1_7\n\n\n\n\n\ni5-&gt;h1_8\n\n\n\n\n\nh1_9\n\nh1_9\n\n\n\ni5-&gt;h1_9\n\n\n\n\n\ni6\n\ni6\n\n\n\ni7\n\ni7\n\n\n\ni8\n\ni8\n\n\n\ni9\n\ni9\n\n\n\ni10\n\ni10\n\n\n\ni11\n\ni11\n\n\n\ni12\n\ni12\n\n\n\ni13\n\ni13\n\n\n\ni14\n\ni14\n\n\n\ni15\n\ni15\n\n\n\ni16\n\ni16\n\n\n\ni17\n\ni17\n\n\n\ni18\n\ni18\n\n\n\ni19\n\ni19\n\n\n\ni20\n\ni20\n\n\n\ni21\n\ni21\n\n\n\nh2_1\n\nh2_1\n\n\n\nh1_1-&gt;h2_1\n\n\n\n\n\nh2_2\n\nh2_2\n\n\n\nh1_1-&gt;h2_2\n\n\n\n\n\nh2_3\n\nh2_3\n\n\n\nh1_1-&gt;h2_3\n\n\n\n\n\nh2_4\n\nh2_4\n\n\n\nh1_1-&gt;h2_4\n\n\n\n\n\nh1_5-&gt;h2_2\n\n\n\n\n\nh1_5-&gt;h2_3\n\n\n\n\n\nh1_5-&gt;h2_4\n\n\n\n\n\nh2_5\n\nh2_5\n\n\n\nh1_5-&gt;h2_5\n\n\n\n\n\nh1_10\n\nh1_10\n\n\n\nh1_10-&gt;h2_4\n\n\n\n\n\nh1_10-&gt;h2_5\n\n\n\n\n\nh2_6\n\nh2_6\n\n\n\nh1_10-&gt;h2_6\n\n\n\n\n\nh2_7\n\nh2_7\n\n\n\nh1_10-&gt;h2_7\n\n\n\n\n\nh1_11\n\nh1_11\n\n\n\nh1_12\n\nh1_12\n\n\n\nh1_13\n\nh1_13\n\n\n\nh1_14\n\nh1_14\n\n\n\nh1_15\n\nh1_15\n\n\n\nh1_16\n\nh1_16\n\n\n\nh1_16-&gt;h2_6\n\n\n\n\n\nh1_16-&gt;h2_7\n\n\n\n\n\nh2_8\n\nh2_8\n\n\n\nh1_16-&gt;h2_8\n\n\n\n\n\nh2_9\n\nh2_9\n\n\n\nh1_16-&gt;h2_9\n\n\n\n\n\nh1_17\n\nh1_17\n\n\n\nh1_18\n\nh1_18\n\n\n\nh1_19\n\nh1_19\n\n\n\nh1_20\n\nh1_20\n\n\n\nh1_21\n\nh1_21\n\n\n\nh1_22\n\nh1_22\n\n\n\nh1_23\n\nh1_23\n\n\n\nh1_24\n\nh1_24\n\n\n\nh2_10\n\nh2_10\n\n\n\nh1_24-&gt;h2_10\n\n\n\n\n\nh2_11\n\nh2_11\n\n\n\nh1_24-&gt;h2_11\n\n\n\n\n\nh2_12\n\nh2_12\n\n\n\nh1_24-&gt;h2_12\n\n\n\n\n\nh1_25\n\nh1_25\n\n\n\nh1_26\n\nh1_26\n\n\n\nh1_27\n\nh1_27\n\n\n\nh1_28\n\nh1_28\n\n\n\nh1_29\n\nh1_29\n\n\n\nh1_30\n\nh1_30\n\n\n\nh1_31\n\nh1_31\n\n\n\nh1_32\n\nh1_32\n\n\n\nh2_13\n\nh2_13\n\n\n\nh1_32-&gt;h2_13\n\n\n\n\n\nh2_14\n\nh2_14\n\n\n\nh1_32-&gt;h2_14\n\n\n\n\n\nh2_15\n\nh2_15\n\n\n\nh1_32-&gt;h2_15\n\n\n\n\n\nh2_16\n\nh2_16\n\n\n\nh1_32-&gt;h2_16\n\n\n\n\n\no1\n\no1\n\n\n\nh2_3-&gt;o1\n\n\n\n\n\no2\n\no2\n\n\n\nh2_8-&gt;o2\n\n\n\n\n\no3\n\no3\n\n\n\nh2_14-&gt;o3\n\n\n\n\n\n\n\n\n\n\nEntrenamiento (multiclase)\n\n\n&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x7f076bd9f770&gt;\n\n\n\nMacro-F1: 0.8003850715462932\n\n\nNotas didácticas: desequilibrio de clases (SMOTE), métricas por clase (F1), validación cruzada, early stopping."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#cierre-y-recomendaciones",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#cierre-y-recomendaciones",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Cierre y recomendaciones",
    "text": "Cierre y recomendaciones\n\nLa interpretación clínica sigue siendo esencial; el ML complementa, no reemplaza, el juicio médico.\nValidar externamente (dominios LMIC vs HIC), sesgos de muestreo y data shift.\nReportar métricas por clase, especialmente la clase sospechosa."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#referencias-doi-isbn",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#referencias-doi-isbn",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Referencias (DOI / ISBN)",
    "text": "Referencias (DOI / ISBN)\n\nAyres‑de‑Campos D, et al. FIGO consensus guidelines on intrapartum fetal monitoring: Cardiotocography. Int J Gynaecol Obstet 2015;131(1):13–24. DOI: 10.1016/j.ijgo.2015.06.020\nMacones GA, et al. The 2008 NICHD workshop report on electronic fetal monitoring. J Obstet Gynecol Neonatal Nurs 2008. (see Obstet Gynecol 2008;112:661–6)\nHoodbhoy Z, et al. Use of Machine Learning Algorithms for Prediction of Fetal Risk using Cardiotocographic Data. Int J Appl Basic Med Res 2019;9:226–230. DOI: 10.4103/ijabmr.IJABMR_370_18\nJames G, Witten D, Hastie T, Tibshirani R. An Introduction to Statistical Learning (2nd ed.). Springer, 2021. DOI: 10.1007/978-1-0716-1418-1\nHosmer DW, Lemeshow S, Sturdivant RX. Applied Logistic Regression (3rd ed.). Wiley, 2013. DOI: 10.1002/9781118548387\nRumelhart DE, Hinton GE, Williams RJ. Learning representations by back‑propagating errors. Nature 1986;323:533–536. DOI: 10.1038/323533a0\nGoodfellow I, Bengio Y, Courville A. Deep Learning. MIT Press, 2016. ISBN: 978‑0262035613"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#apéndice-carga-de-datos-y-eda-mínimo",
    "href": "presentaciones/ASIM/v2Lect003_ADG_RedesNeuronales.html#apéndice-carga-de-datos-y-eda-mínimo",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Apéndice · Carga de datos y EDA mínimo",
    "text": "Apéndice · Carga de datos y EDA mínimo\n\n\nfetal_health\n1.0    1655\n2.0     295\n3.0     176\nName: count, dtype: int64\n\n\n                                                     count  ...      max\nbaseline value                                      2126.0  ...  160.000\naccelerations                                       2126.0  ...    0.019\nfetal_movement                                      2126.0  ...    0.481\nuterine_contractions                                2126.0  ...    0.015\nlight_decelerations                                 2126.0  ...    0.015\nsevere_decelerations                                2126.0  ...    0.001\nprolongued_decelerations                            2126.0  ...    0.005\nabnormal_short_term_variability                     2126.0  ...   87.000\nmean_value_of_short_term_variability                2126.0  ...    7.000\npercentage_of_time_with_abnormal_long_term_vari...  2126.0  ...   91.000\nmean_value_of_long_term_variability                 2126.0  ...   50.700\nhistogram_width                                     2126.0  ...  180.000\nhistogram_min                                       2126.0  ...  159.000\nhistogram_max                                       2126.0  ...  238.000\nhistogram_number_of_peaks                           2126.0  ...   18.000\nhistogram_number_of_zeroes                          2126.0  ...   10.000\nhistogram_mode                                      2126.0  ...  187.000\nhistogram_mean                                      2126.0  ...  182.000\nhistogram_median                                    2126.0  ...  186.000\nhistogram_variance                                  2126.0  ...  269.000\nhistogram_tendency                                  2126.0  ...    1.000\nfetal_health                                        2126.0  ...    3.000\n\n[22 rows x 8 columns]"
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#what-is-convolution",
    "href": "presentaciones/ASIM/lect005_CNN.html#what-is-convolution",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "What is Convolution?",
    "text": "What is Convolution?\n\nConvolution: A mathematical operation used to extract features from input data.\nFilter/Kernels:\n\nA small matrix (e.g., 3x3) that slides over the input.\nDetects patterns such as edges, textures, and colors.\n\nStride: Number of pixels by which the filter moves at each step.\nPadding: Adds extra pixels around the border of the input, preserving spatial dimensions."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#convolution-in-action",
    "href": "presentaciones/ASIM/lect005_CNN.html#convolution-in-action",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Convolution in Action",
    "text": "Convolution in Action\n\nInput: A matrix of pixel values (e.g., an image).\nOutput (Feature Map): A matrix where each value represents the result of applying the filter over a region of the input."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#what-are-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#what-are-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "What are CNNs?",
    "text": "What are CNNs?\n\nDefinition: CNNs are deep learning models primarily used for visual recognition tasks.\nKey Concept: CNNs learn and detect hierarchical patterns in image data (e.g., edges, shapes, textures).\nImportance: Automatically extract features, reducing the need for manual feature engineering."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#why-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#why-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Why CNNs?",
    "text": "Why CNNs?\n\nFully Connected Networks struggle with large images due to high dimensionality.\nCNNs reduce the number of parameters by using local connectivity (convolutions) and weight sharing.\nEfficient in Learning: They exploit spatial hierarchies in images."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#cnn-architecture-overview",
    "href": "presentaciones/ASIM/lect005_CNN.html#cnn-architecture-overview",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "CNN Architecture Overview",
    "text": "CNN Architecture Overview\n\nInput Layer: Raw image data (e.g., 28x28 pixels for MNIST).\nConvolutional Layer: Detects features from input images using filters.\nActivation Function: Typically ReLU to introduce non-linearity.\nPooling Layer: Reduces the spatial dimensions (downsampling).\nFully Connected Layer: Performs classification based on extracted features."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#activation-function-relu",
    "href": "presentaciones/ASIM/lect005_CNN.html#activation-function-relu",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Activation Function (ReLU)",
    "text": "Activation Function (ReLU)\n\nPurpose: Introduce non-linearity into the network, allowing CNNs to learn complex patterns.\nReLU Formula: ( f(x) = (0, x) )\nWhy ReLU?:\n\nFaster convergence compared to sigmoid or tanh.\nAvoids the vanishing gradient problem."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#pooling-layers",
    "href": "presentaciones/ASIM/lect005_CNN.html#pooling-layers",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Pooling Layers",
    "text": "Pooling Layers\n\nPurpose: Reduce the spatial dimensions of feature maps, decrease computational load, and control overfitting.\nTypes of Pooling:\n\nMax Pooling: Selects the maximum value within a specified window.\nAverage Pooling: Calculates the average value within a specified window.\n\nBenefits:\n\nRetains the most important features (Max Pooling).\nSmooths the feature maps (Average Pooling).\n\nCommon Parameters:\n\nKernel Size: Size of the window (e.g., 2x2).\nStride: Step size for moving the window."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#fully-connected-layers",
    "href": "presentaciones/ASIM/lect005_CNN.html#fully-connected-layers",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Fully Connected Layers",
    "text": "Fully Connected Layers\n\nFlattening: Converts the 2D feature maps into a 1D vector for input into fully connected layers.\nFully Connected (Dense) Layers: Every neuron in the previous layer is connected to every neuron in the next layer.\nRole: Performs classification based on features learned from convolution and pooling layers."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#training-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#training-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Training CNNs",
    "text": "Training CNNs\n\nLoss Function: Cross-entropy loss is commonly used for classification tasks.\nOptimization: Backpropagation combined with optimizers like stochastic gradient descent (SGD) or Adam.\nTraining Concepts:\n\nEpochs: Number of complete passes over the dataset.\nMini-batches: Small subsets of the dataset used in each iteration."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#challenges",
    "href": "presentaciones/ASIM/lect005_CNN.html#challenges",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Challenges",
    "text": "Challenges\n\nComputational Resources: CNNs require powerful hardware (e.g., GPUs) for training large models.\nLarge Datasets: CNNs often need vast amounts of labeled data to perform well.\nOverfitting: Common problem in CNNs when trained on small datasets. Solutions include:\n\nData augmentation (rotating, flipping, or zooming images).\nDropout layers to randomly drop neurons during training."
  },
  {
    "objectID": "presentaciones/ASIM/lect005_CNN.html#future-of-cnns",
    "href": "presentaciones/ASIM/lect005_CNN.html#future-of-cnns",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Future of CNNs",
    "text": "Future of CNNs\n\nAdvanced Architectures:\n\nResidual Networks (ResNet):\n\nDeeper networks can be trained by using skip connections to bypass layers and avoid the vanishing gradient problem.\n\nInception Networks:\n\nUtilize multiple filters of different sizes in parallel to capture features at different scales.\n\nEfficientNet:\n\nBalances network depth, width, and resolution, creating more efficient models with fewer parameters while maintaining accuracy."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nSuposse…\n\n\nA dataset of M tuples \\((\\mathbf{x}_i, \\mathbf{y}_i)\\) with i = 1, …, M.\n\n\\(\\mathbf{x}_i\\): Inputs\n\\(\\mathbf{y}_i\\): Outputs\n\n\n\n\n\n\n\n\n\n\n\n\nWhat it is a neural network\n\n\nIs a mathematical function (sometimes called a network function) that takes some kind of input (typically multi-dimensional) called x iand generate some output."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nNetwork function\n\n\n\nThe output generated by the network function is called \\(\\hat{y}_i\\)\nThe network function normally depends on a certain number N of parameters, which we will indicate with \\(\\mathbf{\\theta}_k\\) \\[ \\mathbf{\\hat{y}}_i = f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), where, k=0,1,2,\\ldots,N \\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nImportante\n\n\nA neural network is nothing more than a mathematical function that depends on a set of parameters that are tuned, hopefully in some smart way, to make the network output as close as possible to some expected output.\n\n\n\n\n\n\n\n\\(\\mathbf{x}_i \\in \\mathbb{R}^n\\)\n\\(\\mathbf{y}_i \\in \\mathbb{R}^k\\)\n\\(i = 0,1,2,\\ldots,M\\)\n\\(\\mathbf{\\theta}_k \\in \\mathbb{R}^N\\)\n\\(k = 0,1,2,\\ldots,N\\)\n\n\n\nLoss function \\(L \\left( \\mathbf{\\hat{y}}_i, \\mathbf{y}_i \\right) = L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\)\nLoss function measures how close are \\(\\mathbf{\\hat{y}}_i\\) and \\(\\mathbf{y}_i\\)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#introduction-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nLearning\n\n\n\n$ _{_k ^N} L ( f ( _k, _i ), _i ) $\n\\(\\min_{\\mathbf{\\theta}_k \\in \\mathbb{R}^N} L \\left( f \\left( \\mathbf{\\theta}_k, \\mathbf{x}_i  \\right), \\mathbf{y}_i \\right)\\) subject to \\(c_q, q=1,2,3,\\ldots,Q\\) with \\(Q \\in \\mathbb{N}\\)\nThe learning process is the search of a minima. However, most of the algorithms can search only a “local” minima.\nIn principle, we want to find the global minimum or, in other words, the point for which the function value is the smallest between all possible points.\n\n\n\n\n\n\nIdentifying if the minimum is a local or a global minimum is impossible, due to the network function complexity.\nThis is one (albeit not the only one) of the reasons that training large neural networks is such a challenging numerical problem."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#a-single-neuron",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "A single neuron",
    "text": "A single neuron"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Neural Network",
    "text": "Neural Network"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#neural-network-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Neural Network",
    "text": "Neural Network\n\nTaken from GeeksforGeeks"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\nNeural Networks have a great number of internal parameters for learning; which varying in a vast range of values.\nThis number of parameters is fundamental for neural network knowledge representation\n\n\n\n\n\n\n\nProblem\n\n\nBut if this number increases too much the neural network is prone to overfitting"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\n\n\n\n\n\n\nDefinition\n\n\nRegularization techniques reduce the possibility of a neural network overfitting by constraining the range of values that the weight values within the network hold.\n\n\n\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 + \\theta_4 x^4 \\\\\nf \\left( x \\right) = \\theta_0+\\theta_1 x + \\theta_2 x^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\nRegularization works on assumption that smaller weights generate simpler model and thus helps avoid overfitting.\nThe simpler model is less prone to overfitting.\nAdding the regularization term to the sum of squared differences between the actual value and predicted value."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#regularization-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Regularization",
    "text": "Regularization\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k\n\\end{eqnarray}\\]\n\n\n\n\n\n\n\nNota\n\n\n\\(\\lambda\\) is the penalty term or regularization parameter which determines how much to penalizes the weights."
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#types-of-regularization",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Types of Regularization",
    "text": "Types of Regularization\n\n\nL1 Regularization or Lasso or L1 norm\n\nL1 penalizes sum of absolute value of weights.\nL1 has a sparse solution.\nL1 has multiple solutions.\nL1 has built in feature selection.\nL1 is robust to outliers.\nL1 generates model that are simple and interpretable but cannot learn complex patterns.\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\lvert \\theta_k \\rvert\n\\end{eqnarray}\\]\n\nL2 Regularization or Ridge Regularization\n\nL2 regularization penalizes sum of square weights.\nL2 has a non sparse solution\nL2 has one solution\nL2 has no feature selection\nL2 is not robust to outliers\nL2 gives better prediction when output variable is a function of all input features\nL2 regularization is able to learn complex data patterns\n\n\\[\\begin{eqnarray}\nL(\\mathbf{x},\\mathbf{y}) = \\sum_{k=1}^N \\left( y_k - f \\left( x_k \\right) \\right)^2  + \\lambda \\sum_{k=1}^N \\theta_k^2\n\\end{eqnarray}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation",
    "text": "Evaluation\n\n\n\n\n\n\n\nRegression\n\n\n\n\\(R^2\\)\nResidual graph\nAutocorrelation analysis\n\n\n\n\n\n\n\n\n\n\n\n\nClassification\n\n\n\nConfusion Matrix(Matriz de Confusión)\nPrecision(Precisión)\nRecall(Exhaustividad)\nF1-score(Valor-F)\nAccuracy(Exactitud)\nTrue Positive(Positivos Verdaderos)\nTrue Negative(Negativos Verdaderos)\nFalse Positive(Positivos Falsos)\nFalse Negative(Negativos Falsos)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nConfusion Matrix\n\n\n“Also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one.”"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\nTrue Negative\n\n\nValues that being negative have been classified as negative\n\n\n\n\n\n\n\n\n\n\n\nTrue Positive\n\n\nValues that being positive have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Positive\n\n\nValues that being negative have been classified as positive\n\n\n\n\n\n\n\n\n\n\n\nFalse Negative\n\n\nValues that being negative have been classified as positive"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nSensitivity or Recall\n\n\nHow good is my classifier at detecting positive cases? \\[ \\frac{TP}{TP+FN} \\]\n\n\n\n\n\n\n\n\n\n\n\nSpecificity\n\n\nHow good is my classifier at avoiding negative cases? \\[ \\frac{TN}{TN+FP} \\]\n\n\n\n\n\n\n\n\n\n\n\n\nPrecision\n\n\nHow credible is my classifier when it detects a positive case? \\[\\frac{TP}{TP+FP}\\]\n\n\n\n\n\n\n\n\n\n\n\nAccuracy and Balance Accuracy\n\n\nHow many cases the classifier correctly identifies? \\[Accuracy = \\frac{TP+TN}{TP+FP+FN+TN}\\] \\[BalancedAccuracy = \\frac{Specificity+Sensitivity}{2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#evaluation-of-a-classification-model-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Evaluation of a classification model",
    "text": "Evaluation of a classification model\n\n\n\n\n\n\n\n\n\nPrevalence\n\n\nHow often does the positive condition actually occur in our sample? \\[\\frac{TP+FN}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nDetection Rate\n\n\nPercentage of true positives \\[\\frac{TP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nDetection Prevalence\n\n\nPercentage of positives \\[\\frac{TP+FP}{TP+FP+FN+TN}\\]\n\n\n\n\n\n\n\n\n\n\n\nHarmonic mean of recall and precision.\n\n\n\\[2\\frac{\\left( Precision \\right) \\left( Sensitivity \\right)}{Precision+Sensitivity}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 1"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\nFor Class 2"
  },
  {
    "objectID": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "href": "presentaciones/ASIM/Lect004_IntroductionMachineLearning.html#multiclass-confusion-matrix-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Multiclass Confusion Matrix",
    "text": "Multiclass Confusion Matrix\n\n\n\nFor Class 3"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "href": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "title": "Proyecto Final: PSIM 2024-1",
    "section": "",
    "text": "Criterio\n5.0  (Excelente)\n4.0  (Bueno)\n3.0  (Aceptable)\n1.0  (Deficiente)\n\n\n\n\n1. Objetivo del Proyecto\nClaramente definido, específico, relevante y alcanzable, alineado con la problemática.\nClaro y relevante, pero carece de precisión o profundidad.\nComprensible, pero general o no bien alineado con la problemática.\nConfuso, irrelevante o ausente.\n\n\n2. Justificación\nSólida, argumenta importancia e impacto con evidencia o literatura relevante.\nAdecuada, pero le falta profundidad o evidencia clara.\nBásica y poco convincente; argumentos débiles o generales.\nInexistente o carente de lógica.\n\n\n3. Metodología\nBien estructurada, clara y adecuada para los objetivos. Técnicas y procedimientos relevantes.\nAdecuada, pero carece de detalle o presenta leves inconsistencias.\nVaga, incompleta o no alineada con los objetivos.\nConfusa, inapropiada o ausente.\n\n\n4. Resultados\nClaros, organizados y rigurosamente analizados. Uso efectivo de herramientas visuales.\nClaros, pero carecen de profundidad en análisis u organización.\nConfusos, incompletos o mal interpretados.\nIrrelevantes, incorrectos o ausentes.\n\n\n5. Discusión\nInterpreta resultados, relaciona con objetivos y literatura, propone mejoras futuras.\nAborda puntos principales, pero falta profundidad o conexión con literatura previa.\nSuperficial, no interpreta correctamente resultados ni plantea ideas futuras.\nAusente o irrelevante.\n\n\n6. Respuesta a Preguntas\nResponde con claridad, precisión y seguridad. Demuestra dominio y análisis crítico del tema.\nResponde adecuadamente, pero muestra inseguridad en algunos aspectos.\nResponde vagamente, con dificultades para argumentar.\nRespuestas incorrectas, confusas o incapacidad para responder."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "href": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "title": "Proyecto Final: APSB1",
    "section": "",
    "text": "Criterio\n1 - Deficiente\n2 - Insuficiente\n3 - Aceptable\n4 - Bueno\n5 - Excelente\nPonderación\n\n\n\n\nDefinición del Problema y Justificación\nNo se identifica un problema biomédico claro.\nSe identifica un problema, pero sin relevancia biomédica o justificación.\nSe plantea un problema relevante con justificación básica.\nProblema bien definido con referencias científicas.\nProblema biomédico bien formulado, con justificación sólida basada en literatura científica.\n15%\n\n\nAdquisición y Procesamiento de Datos en el Borde\nNo se especifica el tipo de datos ni sensores.\nSe mencionan sensores, pero sin detalles sobre la captura y preprocesamiento.\nSe describe la adquisición de datos con procesamiento básico.\nSe justifica la selección de sensores y se menciona un preprocesamiento adecuado.\nSelección óptima de sensores con procesamiento avanzado y justificación técnica detallada.\n20%\n\n\nDesarrollo e Implementación del Modelo de IA\nNo se propone un modelo de IA.\nSe menciona un modelo, pero sin adecuación a Edge AI.\nSe plantea un modelo básico con justificación limitada.\nSe elige un modelo adecuado y optimizado para Edge AI.\nModelo avanzado con técnicas de optimización y justificadas con métricas.\n20%\n\n\nValidación y Pruebas en Tiempo Real\nNo se contempla validación del modelo.\nSe menciona validación, pero sin metodología clara.\nSe plantea una validación con datos simulados.\nSe incluyen pruebas con datos reales y métricas de rendimiento.\nValidación robusta con pruebas extensivas y comparación con estándares biomédicos.\n20%\n\n\nEscalabilidad y Aplicabilidad en la Industria Biomédica\nNo se considera la escalabilidad del proyecto.\nSe menciona la escalabilidad, pero sin detalles técnicos.\nSe plantea una estrategia básica de escalabilidad.\nEstrategia clara de implementación y compatibilidad con sistemas médicos.\nProyecto altamente escalable, con integración en entornos clínicos y estándares como HL7 o FHIR.\n15%\n\n\nPresentación y Documentación\nNo hay documentación ni presentación clara.\nDocumentación incompleta o desordenada.\nPresentación básica con documentación limitada.\nPresentación clara y documentada correctamente.\nDocumentación profesional con detalles técnicos y presentación estructurada.\n10%"
  },
  {
    "objectID": "rubricas/Rubrica_Regression.html",
    "href": "rubricas/Rubrica_Regression.html",
    "title": "Rúbrica: Modelos de regresión",
    "section": "",
    "text": "Equipo 1Equipo 2\n\n\nIntegrantes\n\nLaura Bazante\nNicolás Panesso\nNicoll Arcos\n\nDataset: concreto\n\n\nIntegrantes\n\nKatherin Diaz\nHeidy Fernández\nJuan Muñoz\n\nDataset: Rendimiento\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsuficiente0%\nAceptable50%\nSuperior100%\n\n\n\n\nObjetivo análisis exploratorio de datos\nNo hay un objetivo aparente\nExiste un objetivo de análisis exploratorio de datos planteado pero este no se encuentra alineado con el modelo\nEl objetivo del análisis exploratorio de datos planteado se alinea con la construcción del modelo se encuentra bien descrito\n\n\nContexto del Dataset\nNo es posible establecer el ámbito al cual pertenecen los datos utilizados para desarrollar el trabajo\nSe hace una descripción muy básica de las características del dataset\nSe hace una descripción detallada de las características y las variables que componen el dataset\n\n\nJustificación\nNo existe una justificación aparente\nExiste justificación pero esta se encuentra mal planteda\nLa justificación se encuentra bien planteada\n\n\nPreprocesamiento\nNo se realizó preprocesamiento de los datos.  O no se argumenta de manera clara la razón de los procedimientos realizados\nAl dataset se le aplicaron solo algunas operaciones de preprocesamiento y los datos no tienen la calidad requerida\nAl dataset se le aplicaron las operaciones de preprocesamiento necesarias para mejorar su calidad y poder construir los modelos de clasificación\n\n\nConexión entre el EDA y el modelo final\nMás de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nMenos de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nTodas las decisiones para el modelo inicial fueron tomadas a partir del EDA\n\n\nDuración de la presentación\nLa presentación dura menos de 8 minutos o más de 13 minutos\nLa presentación dura menos de 9 minutos o más de 11 minutos\nLa presentación dura 10 minutos\n\n\nMaterial de clase\nNo usa la plantilla RMARKDOWN\n\nUsa la plantilla  RMARKDOWN\n\n\nUso de gráficos\nNo se usa ESTADÍSTICA para explicar todas las decisiones\n\nSe usa ESTADÍSTICA para explicar todas las decisiones\n\n\nJustificación de las decisiones del modelo final\nMás de dos decisiones del modelo final no están justificadas\nMenos de dos decisiones del modelo final no están justificadas\nLas decisiones del modelo final son justificadas.\n\n\nEvaluación del modelo\nNo hace evaluación del modelo\nUsa el índice de determinación para evaluar el modelo\nUsa el índice de determinación para evaluar el modelo y además hace análisis de residuos sobre la salida del modelo\n\n\nModelo de regresión\nNo se construyó el modelo o el grupo no puede explicar de manera clara la razón de los procedimientos realizados\nSolo construyó un modelo o no hay claridad sobre las características del modelo elegido\nIdentificó el modelo de mayor precisión después de realizar varias pruebas, se exponen las características del modelo elegido.  El modelo se presenta de forma gráfica"
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "El procesamiento digital de señales biomédicas (como ECG y EEG) emplea herramientas matemáticas para analizar y mejorar la calidad de estas señales, extrayendo información útil para diagnóstico y monitoreo clínico (Procesamiento de señales biomédicas: EEG & FPGA). En particular, la transformada Z y los filtros digitales (FIR e IIR) son fundamentales para modelar, analizar y modificar señales en tiempo discreto. Por ejemplo, es común eliminar interferencias de línea base o ruido de red eléctrica (50/60 Hz) mediante filtros pasoalto o de rechazo (notch) adecuados (). Este reporte teórico describe los conceptos clave para resolver un taller de análisis de señales biomédicas, cubriendo la transformada Z, la estabilidad y región de convergencia (ROC), la representación de sistemas LTI (Lineales e Invariantes en el Tiempo) mediante polos y ceros, la respuesta al impulso, los diagramas de bloques, y el diseño de filtros digitales FIR e IIR (incluyendo métodos de ventaneo y transformación bilineal). Se incluyen ejemplos prácticos en Python (usando numpy y scipy) para ilustrar implementaciones, con un claro enfoque en aplicaciones biomédicas como el filtrado de señales ECG/EEG. Las explicaciones se apoyan en referencias académicas para asegurar rigor teórico.\n\n\n\nLa transformada Z convierte una señal \\(x[n]\\) de tiempo discreto en una representación en el dominio complejo. En forma bilateral, se define como:\n\\[X(z) = \\mathcal{Z}\\{x[n]\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\,z^{-n},\\]\ndonde \\(z\\) es una variable compleja \\(z = A e^{j\\omega}\\) (con \\(A=|z|\\) y \\(\\omega = \\arg(z)\\)) (Transformada Z - Wikipedia, la enciclopedia libre) (Transformada Z - Wikipedia, la enciclopedia libre). En señales causales (\\(x[n]=0\\) para \\(n&lt;0\\)), suele usarse la transformada Z unilateral definida desde \\(n=0\\) hasta \\(\\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). La transformada Z es análoga a la transformada de Laplace en sistemas continuos, y de hecho puede verse como una serie de Laurent (suma infinita de potencias) (Transformada Z - Wikipedia, la enciclopedia libre).\nRegión de Convergencia (ROC): No toda señal tiene transformada Z en forma cerrada; la serie anterior converge únicamente en ciertas regiones del plano \\(z\\). La ROC se define como el conjunto de valores de \\(z\\) para los cuales la serie converge absolutamente (Transformada Z - Wikipedia, la enciclopedia libre). En términos prácticos, la ROC es el rango de \\(z\\) donde \\(\\sum_{n=-\\infty}^{\\infty}|x[n]z^{-n}| &lt; \\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). Por ejemplo, si \\(x[n] = a^n u[n]\\) (secuencia exponencial causal con \\(u[n]\\) la escalón unidad), su transformada Z es \\(X(z) = \\frac{1}{1 - a\\,z^{-1}}\\), pero esta expresión es válida solo si \\(|z| &gt; |a|\\) (ya que la serie geométrica converge cuando \\(|a/z|&lt;1\\)). Así, la ROC en este caso es \\(|z| &gt; |a|\\). Si la señal fuera anti-causal (\\(x[n]=0\\) para \\(n&gt;0\\)), la ROC sería \\(|z| &lt; |a|\\) (convergencia hacia adentro). Si \\(x[n]\\) tiene duración finita (FIR), su transformada Z existe para todo \\(z\\neq0\\) excepto quizá puntos donde la propia definición tenga singularidades (por lo general ROC = todo el plano \\(z\\), excepto tal vez \\(z=0\\) o \\(z=\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). La ROC nunca incluye polos (donde la función \\(X(z)\\) diverge) (Transformada Z - Wikipedia, la enciclopedia libre), es típicamente un anillo o media-plano en el plano \\(z\\), y su ubicación está ligada a propiedades de la señal como causalidad y estabilidad.\nPolos y ceros: Cualquier función de transferencia discreta o transformada Z de una señal racional puede expresarse en forma de polos y ceros. Los ceros son valores de \\(z\\) que anulan \\(X(z)\\) (raíces del numerador), y los polos donde \\(X(z)\\) diverge (raíces del denominador). Por ejemplo, en \\(X(z) = \\frac{1}{1 - a z^{-1}}\\), hay un polo en \\(z=a\\) y un cero en \\(z=\\infty\\) (o equivalente, un cero de orden 1 en el origen en la función \\(X(z)\\) multiplicada por \\(z^{-1}\\)). La representación gráfica de polos y ceros en el plano \\(z\\) proporciona intuición sobre el comportamiento frecuencial: los ceros en la circunferencia unitaria (\\(|z|=1\\)) cancelan ciertas frecuencias, mientras que los polos cercanos a la circunferencia unitaria amplifican componentes espectrales cercanas a su ángulo.\nCausalidad: Un sistema LTI discreto es causal si \\(h[n]=0\\) para \\(n&lt;0\\) (su respuesta impulso es nula en tiempos negativos). En la transformada Z, esto implica que la ROC es externa, es decir, de la forma \\(|z|&gt;R\\) (convergencia hacia \\(\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). Todos los polos de un sistema causal deben estar dentro de la ROC (que para causal es exterior al polo de mayor radio) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Un detalle importante es que la ubicación de polos por sí sola no determina completamente la causalidad o estabilidad; la ROC es la que define cuál de las posibles señales con esos polos es la realizada (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por ejemplo, una misma función racional puede corresponder a un sistema causal inestable o a un sistema no causal estable, dependiendo de si la ROC se toma fuera o entre polos (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange).\nEstabilidad BIBO: Un sistema es estable (en sentido BIBO: Bounded-Input Bounded-Output) si su respuesta al impulso \\(h[n]\\) es absolutamente sumable, \\(\\sum_{n=-\\infty}^{\\infty}|h[n]| &lt; \\infty\\). Esta condición garantiza que cualquier entrada acotada produce salida acotada (BIBO stability - Wikipedia). En el dominio Z, estabilidad equivale a que la ROC de \\(H(z)\\) contenga al círculo unitario (\\(|z|=1\\)) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Para sistemas causales, esto se traduce en que todos los polos deben estar dentro del círculo unitario (ya que la ROC causal comienza fuera del polo de mayor magnitud) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por tanto, un filtro digital causal será estable si sus polos \\(p_i\\) satisfacen \\(|p_i|&lt;1\\). En sistemas no causales (e.g. acausales diseñados con filtrado hacia atrás y adelante para cancelar fase), la estabilidad puede lograrse con polos fuera del unitario siempre y cuando la ROC (un anillo) incluya el unitario (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange), aunque estos casos son menos comunes en línea real. En general, para diseño de filtros digitales asumiremos causalidad, por lo que chequear estabilidad equivale a verificar polos dentro del unitario.\nEjemplo (ECG y estabilidad): Considere un filtro pasoalto diseñado para remover la línea base de ECG definido por la diferencia \\(y[n] = x[n] - x[n-1]\\). Su función de transferencia es \\(H(z) = 1 - z^{-1}\\), con un cero en \\(z=1\\) (cancela DC) y un polo en \\(z=0\\) (simple, debido al \\(z^{-1}\\)). Este sistema es causal (diferencia causal) y su único polo \\(z=0\\) está dentro del círculo unitario, por lo que es estable. De hecho, su respuesta al impulso \\(h[n]=\\delta[n] - \\delta[n-1]\\) suma 0 en valor absoluto (sumable). Este filtro elimina componentes de muy baja frecuencia, como la deriva de línea base en un ECG (), sin inestabilidad.\n\n\n\nUn sistema LTI discreto queda caracterizado completamente por su respuesta al impulso \\(h[n]\\). Dada cualquier entrada \\(x[n]\\), la salida es la convolución discreta \\(y[n] = (x*h)[n] = \\sum_{k=-\\infty}^{\\infty} h[k]\\,x[n-k]\\). En el dominio Z, esta convolución se convierte en multiplicación: \\(Y(z) = H(z)\\,X(z)\\) (dentro de la intersección de ROC de \\(X\\) y \\(H\\)). La función de transferencia \\(H(z)\\) de un sistema LTI causal viene dada por la transformada Z de \\(h[n]\\) (unilateral). En sistemas de coeficientes constantes (difundidos en ingeniería), \\(H(z)\\) suele ser una función racional de \\(z\\):\n\\[H(z) = \\frac{B(z)}{A(z)} = \\frac{b_0 + b_1 z^{-1} + \\cdots + b_M z^{-M}}{1 + a_1 z^{-1} + \\cdots + a_N z^{-N}},\\]\ndonde \\(B(z)\\) y \\(A(z)\\) son polinomios en \\(z^{-1}\\). La razón de escribir en potencias de \\(z^{-1}\\) es para reflejar la causalidad (solo potencias no positivas de \\(z\\)). La ecuación en diferencias asociada es:\n\\[y[n] + a_1 y[n-1] + \\cdots + a_N y[n-N] = b_0 x[n] + b_1 x[n-1] + \\cdots + b_M x[n-M].\\]\nEste es el modelo típico de sistemas LTI discreto. Si \\(N=0\\) (no hay realimentación, solo ceros), el sistema es FIR (Finite Impulse Response), pues \\(h[n]\\) es de duración finita (máximo \\(M\\)). Si \\(N&gt;0\\), hay realimentación y el sistema es IIR (Infinite Impulse Response), con respuesta al impulso teóricamente infinita (aunque decreciente si es estable).\nDiagramas de bloques: Un LTI puede implementarse mediante sumas, retardos (\\(z^{-1}\\) representa un retardo de 1 muestra) y multiplicaciones por constantes. El diagrama de bloques representa visualmente la ecuación en diferencias. Por ejemplo, para un filtro IIR de segundo orden:\n\\[y[n] = -a_1 y[n-1] - a_2 y[n-2] + b_0 x[n] + b_1 x[n-1] + b_2 x[n-2],\\]\nel diagrama en forma Directa II combinaría los términos en una estructura canónica con dos bloques de retardo en la rama de realimentación y avance, sumadores para combinar las ramas, y coeficientes \\(a_i\\), \\(b_i\\). Cada polo corresponde a un lazo de realimentación (coeficientes \\(a_i\\)) y cada cero a una ramificación hacia la entrada (coeficientes \\(b_i\\)). Dibujar estos diagramas ayuda a entender la estructura interna, pero en este reporte nos enfocaremos más en el análisis matemático. Cabe destacar que el tipo de filtro (pasa-bajos, pasa-altos, etc.) puede inferirse de \\(H(z)\\): por ejemplo, si \\(H(e^{j\\omega})\\) (respuesta en frecuencia) atenúa bajas frecuencias y deja pasar altas, es pasa-altos. Un método práctico es evaluar \\(H(z)\\) en \\(z=e^{j0}\\) (DC, \\(\\omega=0\\)) y en \\(z=e^{j\\pi}\\) (Nyquist, \\(\\omega=\\pi\\)): si \\(|H(e^{j0})|=0\\) y \\(|H(e^{j\\pi})|\\approx 1\\), es pasa-altos; al revés sería pasa-bajos. Los ceros en \\(z=1\\) anulan \\(\\omega=0\\) (eliminan DC), típicos en pasa-altos (), mientras ceros en \\(z=-1\\) anulan \\(\\omega=\\pi\\) (eliminan la componente de Nyquist, típicos en pasa-bajos). Por su parte, polos cercanos a \\(z=1\\) refuerzan respuesta en bajas frecuencias; polos cercanos a \\(z=-1\\) refuerzan la alta frecuencia \\(\\pi\\). Así, el diagrama polo-cero brinda intuición: ceros sobre la circunferencia unitaria en cierto ángulo \\(\\theta_0\\) causan una notch (anulación) en la frecuencia \\(\\omega=\\theta_0\\), mientras polos cerca de la unidad en \\(\\theta_0\\) generan picos (potenciales resonancias) alrededor de esa frecuencia.\nEjemplo (Filtro notch 60 Hz): Un problema común en bioseñales es eliminar la interferencia de la red eléctrica (50/60 Hz) sobre, por ejemplo, EEG o ECG. Un filtro digital sencillo para eliminar 60 Hz (asumiendo frecuencia de muestreo \\(f_s=5000\\) Hz) es colocar ceros conjugados en \\(z = e^{\\pm j 2\\pi(60/5000)}\\). La función de transferencia resultante puede ser:\n\\[H(z) = 1 - 2\\cos(2\\pi\\frac{60}{5000})\\,z^{-1} + z^{-2}.\\]\nEste \\(H(z)\\) tiene ceros en \\(e^{\\pm j2\\pi(60/5000)}\\) que anulan exactamente la componente de 60 Hz, implementando un filtro notch. Además, es un filtro FIR (orden 2) con coeficientes simétricos, lo que le da fase lineal (importante para no deformar la forma de onda). ¿Es estable? Sí, al ser FIR no hay polos fuera del origen (solo polos en 0, con módulo 0). ¿Es causal? Sí, depende solo de muestras presentes y pasadas de la señal (\\(x[n]\\), \\(x[n-1]\\), \\(x[n-2]\\)). ¿Qué tipo de filtro es? Es un rechaza-banda estrecho centrado en 60 Hz (deja pasar el resto, pero rechaza esa frecuencia). En aplicaciones, este notch suele atenuar ruido de red sin distorsionar significativamente las señales de interés ().\n\n\n\nLos filtros FIR (Respuesta al Impulso Finita) son ampliamente utilizados en procesamiento biomédico porque pueden diseñarse para tener respuesta en fase lineal, evitando distorsión de fase en la señal filtrada (lo cual es útil para preservar la morfología de ondas ECG, por ejemplo). Una manera conceptualmente sencilla de diseñar un FIR es mediante el método de ventana (WindowFIRDesign.fm). Consiste en: (1) definir la respuesta frecuencial ideal deseada \\(H_d(e^{j\\omega})\\), (2) obtener la respuesta al impulso ideal \\(h_d[n]\\) como la transformada inversa de Fourier de \\(H_d\\), y (3) truncar \\(h_d[n]\\) (que usualmente es infinita o muy larga) mediante una función ventana \\(w[n]\\) para obtener un FIR realizable \\(h[n] = h_d[n]\\,w[n]\\).\nPor ejemplo, supongamos que queremos un filtro pasa-bajos ideal con frecuencia de corte \\(\\omega_c\\). El impulso ideal es \\(h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}\\) (un sinc) que se extiende infinitamente. Para obtener un FIR causal de longitud \\(M\\), se multiplica \\(h_d[n]\\) por una ventana \\(w[n]\\) de longitud \\(M\\) centrada apropiadamente (y a menudo se aplica un corrimiento para hacer el filtro causal). Las ventanas comúnmente utilizadas incluyen: Rectangular, Bartlett (triangular), Hann (Hanning), Hamming, Blackman, y la Kaiser (que es ajustable). Cada ventana introduce un cierto lóbulo principal en la respuesta en frecuencia (determinando la anchura de la transición) y lóbulos laterales (que determinan el ripple o atenuación en bandas de rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm).\nLas características típicas de ventanas clásicas (según Oppenheim et al. (WindowFIRDesign.fm) (WindowFIRDesign.fm)) son:\n\nRectangular: lóbulo principal más angosto (ancho \\(\\approx 4\\pi/M\\) rad) pero lóbulos laterales más altos (primer sidelobe ~\\(-13\\) dB, atenuación de rechazo $$21 dB) (WindowFIRDesign.fm). Da la transición más abrupta para un orden dado, al costo de peor rechazo de banda.\nBartlett (triangular): lóbulo principal algo más ancho (\\(\\approx 8\\pi/M\\)), sidelobes ~\\(-25\\) dB (WindowFIRDesign.fm).\nHann: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes ~\\(-31\\) dB (WindowFIRDesign.fm) (mejor rechazo que rectangular pero transiciones más suaves).\nHamming: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes \\(\\approx -41\\) dB (mínima atenuación ~53 dB en rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm). Es muy popular por su buen compromiso entre ancho de transición y rechazo en banda eliminada.\nBlackman: lóbulo principal más ancho (\\(\\approx 12\\pi/M\\)) pero sidelobes muy bajos (~\\(-57\\) dB, atenuación ~74 dB) (WindowFIRDesign.fm).\nKaiser: permite escoger un parámetro \\(\\beta\\) para controlar la atenuación de lóbulo lateral, ofreciendo flexibilidad. Aproximadamente, para lograr \\(A\\) dB de atenuación, \\(\\beta \\approx 0.1102(A-8.7)\\) (para \\(A&gt;50\\)), y el ancho de transición normalizado \\(\\Delta\\omega\\) se relaciona con el orden \\(M\\) y \\(\\beta\\) por \\(M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\\) (WindowFIRDesign.fm) (estas fórmulas provienen de aproximaciones de Kaiser y ayudan a dimensionar el filtro).\n\nEl método de ventanas es sencillo pero implica un compromiso fijo entre ancho de transición y ripple: una vez elegida la ventana, la única forma de mejorar la pendiente de corte es aumentar \\(M\\) (orden del filtro). Por ejemplo, la ventana Hamming siempre tendrá ~\\(-53\\) dB de mínimo en rechazo sin importar \\(M\\) (WindowFIRDesign.fm), pero al incrementar \\(M\\) se reducirá la anchura de transición. En contraste, la ventana rectangular logra transiciones muy rápidas con orden modesto, pero su pobre rechazo (~21 dB) la hace inadecuada si necesitamos, digamos, eliminar ruido fuerte. En señales biomédicas, suele preferirse reducir al mínimo distorsiones residuales de ruido, por lo que ventanas con mejor rechazo (Hamming, Blackman o Kaiser ajustada) son comunes.\nCálculo del orden para especificaciones dadas: Dado un requerimiento de diseño (ej. atenuación mínima de 40 dB en banda eliminada y transición de 10 Hz), podemos estimar el orden necesario. Por ejemplo, en el taller se plantea diseñar un pasa-bajos FIR con \\(f_c = 55\\) Hz (definido al nivel de \\(-6\\) dB), que alcance al menos 20 dB de atenuación a 60 Hz y &gt;40 dB más allá de 80 Hz. Esto implica una banda de transición bastante estrecha (de ~55 a 60 Hz) y un rechazo fuerte. Un enfoque sería probar varias ventanas:\n\nRectangular: probablemente no pueda dar 40 dB de rechazo (limita ~21 dB).\nHamming: puede dar ~53 dB de rechazo, suficiente, pero el ancho de transición \\(\\Delta f\\) será ~\\(\\frac{3.3}{M}\\) (en radianes normalizados, equivalente aprox. a \\(\\frac{0.26 f_s}{M}\\) en Hz para banda bilateral). Para \\(\\Delta f \\approx 5\\) Hz con \\(f_s\\) suficientemente grande, requerirá un \\(M\\) elevado.\nBlackman: daría &gt;60 dB de rechazo, pero su transición es más ancha (por ser \\(12\\pi/M\\) rad).\nKaiser: se puede ajustar para 40 dB con quizás menor \\(M\\) que Hamming, porque se elige justo la atenuación requerida y minimiza ancho de transición para ese nivel.\n\nEn el taller, se sugiere calcular el orden mínimo para cada ventana cumpliendo las specs y elegir la de menor orden. Esto implicaría usar fórmulas o tablas estándar (WindowFIRDesign.fm) (WindowFIRDesign.fm). Por ejemplo, para 40 dB de rechazo y \\(\\Delta f = 20\\) Hz (digamos entre 60 y 80 Hz), la Hamming podría necesitar \\(M \\approx \\frac{3.3\\cdot 2\\pi}{(20/f_s)2\\pi} = \\frac{3.3 f_s}{20}\\) (esta es una estimación tosca usando \\(\\Delta\\omega \\approx 8\\pi/M\\)). Si la señal es de voz muestreada a 8 kHz (caso típico, aunque aquí es biomédica a 200 Hz?), podemos obtener números específicos. En general, se podría iterar aumentando \\(M\\) y midiendo la respuesta espectral hasta que los requisitos se satisfagan.\nA modo de ilustración práctica, diseñemos un filtro FIR pasa-bajos con método del ventaneo en Python, usando scipy.signal.firwin. Por simplicidad, tomemos \\(f_s=200\\) Hz, \\(f_c=30\\) Hz, y usemos ventana de Hamming:\nimport numpy as np\nfrom scipy import signal\nfs = 200.0  # Hz\nfc = 30.0   # Hz (deseamos pasa-bajos)\nN = 51      # orden (se puede ajustar)\ntaps = signal.firwin(N, cutoff=fc, window='hamming', fs=fs)\nw, H = signal.freqz(taps, worN=8000, fs=fs)\n# Convertir respuesta a dB:\nH_db = 20*np.log10(np.abs(H))\n# Encontrar atenuación en 60 Hz:\nidx_60 = np.argmin(np.abs(w-60))\nprint(f\"Atenuación a 60Hz: {H_db[idx_60]:.2f} dB\")\n(El código anterior calcula los coeficientes FIR con ventana de Hamming y evalúa la respuesta. Se puede iterar sobre N hasta lograr &gt;40 dB en 80 Hz, etc.)\nEn general, el método de ventanas es rápido y fácil de implementar. Su principal limitación es la falta de control preciso sobre las bandas: el ripple y transición vienen determinados por la elección de ventana, no exactamente por parámetros deseados (excepto en Kaiser donde hay más control). Aún así, es muy útil en procesamiento biomédico cuando queremos filtros lineales en fase y podemos permitir órdenes relativamente altos (el costo computacional suele ser menor preocupación en aplicaciones off-line, pero en tiempo real un FIR muy largo puede introducir latencia).\n\n\n\nLos filtros IIR (Respuesta Infinita al Impulso) se suelen diseñar a partir de filtros analógicos prototipo utilizando transformaciones como la transformación bilineal. Este enfoque aprovecha décadas de diseños analógicos bien estudiados (Butterworth, Chebyshev, Elíptico, etc.) y los lleva al dominio digital asegurando estabilidad y correspondiendo frecuencias de interés.\nTransformación bilineal: Es una transformación conforme que mapea el plano-\\(s\\) (Laplace) en el plano-\\(z\\) (Z) mediante la sustitución:\n\\[ s = \\frac{2}{T}\\,\\frac{z-1}{\\,z+1\\,}, \\]\ndonde \\(T\\) es el periodo de muestreo (usualmente tomamos \\(T=1\\) para frecuencias normalizadas, o usamos \\(2/T\\) para incluir \\(f_s\\) explícitamente) (Transformación bilineal - Wikipedia, la enciclopedia libre) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esta sustitución se adopta universalmente para convertir funciones de transferencia analógicas \\(H_a(s)\\) en funciones \\(H_d(z)\\) digitales (Transformación bilineal - Wikipedia, la enciclopedia libre). La clave es que la transformación bilineal preserva la estabilidad: polos en el semiplano izquierdo (\\(\\Re(s)&lt;0\\)) mapean dentro del círculo unitario (\\(|z|&lt;1\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Así, un filtro analógico estable producirá un filtro digital estable (Transformación bilineal - Wikipedia, la enciclopedia libre). También mapea el eje \\(j\\omega\\) (eje imaginario \\(s = j\\Omega\\)) en la circunferencia unitaria (\\(z = e^{j\\omega T}\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre), aunque no linealmente en frecuencia. De hecho, existe una distorsión de la respuesta frecuencial conocida como warping: la relación entre frecuencia analógica \\(\\Omega\\) y digital \\(\\omega\\) viene dada por \\(\\omega = 2 \\arctan(\\Omega T/2)\\) (y su inversa \\(\\Omega = \\frac{2}{T}\\tan(\\omega/2)\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esto significa que la escala de frecuencias se comprime al mapear al dominio digital, especialmente conforme \\(\\omega\\) se acerca a Nyquist (\\(\\pi\\) rad/s).\nPara lidiar con el warping, en el diseño se realiza una pre-distorsión (pre-warping) de las especificaciones. Si deseamos que una frecuencia analógica \\(\\Omega_p\\) de corte corresponda exactamente a una digital \\(\\omega_p\\), calculamos \\(\\Omega_p = \\frac{2}{T}\\tan(\\omega_p/2)\\). Lo mismo para frecuencias de banda de rechazo, etc., antes de diseñar el filtro analógico. Luego aplicamos la transformación bilineal. En la práctica, las funciones auxiliares de diseño (como scipy.signal.buttord, cheb1ord, etc.) permiten ingresar especificaciones directamente en el dominio digital y hacen el prewarping internamente (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory).\nPrototipos analógicos comunes:\n\nButterworth: Magnitud con máxima planitud en banda de paso (respuesta maximally flat). No presenta ondulaciones en banda de paso ni rechazo, pero la transición es la más lenta de los tipos clásicos (11.3. Common IIR filters — Digital Signals Theory). Su función de magnitud al cuadrado es \\(|H(j\\Omega)|^2 = \\frac{1}{1 + (\\frac{\\Omega}{\\Omega_c})^{2N}}\\). Para un orden \\(N\\), la atenuación en rechazo aumenta gradualmente con la frecuencia. Útil cuando se quiere respuesta suave sin ripple.\nChebyshev Tipo I: Presenta rizado en banda de paso (ε dB de variación) pero ninguna ondulación en banda de rechazo (11.3. Common IIR filters — Digital Signals Theory). A cambio, logra una caída más abrupta que Butterworth para el mismo orden (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). La magnitud cumple \\(|H(j\\Omega)|^2 = \\frac{1}{1 + \\epsilon^2 T_N^2(\\Omega/\\Omega_c)}\\), donde \\(T_N\\) es el polinomio de Chebyshev de primer tipo (oscila entre ±1). Permite especificar ripple tolerado en pasobanda.\nChebyshev Tipo II: Lo opuesto: sin ripple en banda de paso, pero con ondulación controlada en banda de rechazo. También llamados filtros de Chebyshev inversos. Tienen una transición algo más lenta que los tipo I para igual orden, pero fase más lineal en pasobanda (al no tener ripple ahí).\nElíptico (Cauer): Permite rizado tanto en pasobanda como en rechazo (ambos controlables) (11.3. Common IIR filters — Digital Signals Theory), logrando la caída más empinada de todas las aproximaciones para un orden dado (11.3. Common IIR filters — Digital Signals Theory). Son los más eficientes en términos de orden, a costa de ripple en ambas bandas y mayor no linealidad de fase. Incluyen ceros de transmisión en la banda eliminada, lo que les da atenuación muy alta cerca de los bordes.\n\nEn resumen (11.3. Common IIR filters — Digital Signals Theory): Butterworth no tiene ripple en ninguna banda (pero pendiente menor), Chebyshev I tiene ripple en paso (no en rechazo), Chebyshev II ripple en rechazo (no en paso), y Elíptico ripple en ambas, pero transición más rápida. La Figura 1 ilustra las diferencias de respuesta en un ejemplo práctico.\n(image) Figura 1: Comparación de la respuesta en magnitud (en dB) para filtros IIR pasa-bajos diseñados con las mismas especificaciones (pasa-bajos con \\(f_{p}=3.4\\) kHz con 1 dB de ripple en banda de paso, \\(f_{s}=3.8\\) kHz con 30 dB de atenuación). El filtro elíptico (orden 3, línea roja) logra la transición más abrupta (caída más rápida alrededor de 3.4-3.8 kHz) a costa de presentar ondulaciones tanto en la banda de paso como en la de rechazo. El Chebyshev I (orden 3, línea naranja) exhibe ripple en la banda de paso pero no en la de rechazo, con una pendiente intermedia. El Butterworth (orden 4, línea amarilla) no tiene ripple en ninguna banda, pero requiere un orden mayor y su caída es más paulatina (transición más suave) (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). Todos cumplen con los requisitos (–1 dB a 3.4 kHz, –30 dB a 3.8 kHz), pero el orden mínimo necesario varía (Butterworth necesitó \\(N=4\\) mientras Chebyshev I y Elíptico lograron con \\(N=3\\)). Esto ilustra el compromiso entre pendiente de transición y ondulaciones en las distintas aproximaciones.\nEn diseño, elegir el tipo de filtro depende de la aplicación: en bioseñales, a veces se prefiere Butterworth para evitar cualquier ripple (ej. filtrar ECG sin distorsionar amplitud de componentes clínicas), otras veces un Chebyshev o Elíptico puede ser apropiado si se necesita un filtro muy selectivo (ej. aislar una banda muy estrecha de EEG) y se puede tolerar cierta variación en la ganancia de la banda útil. La fase de los IIR no es lineal, pero si la distorsión de fase es un problema (por ejemplo, desplazamiento o deformación de picos en ECG), puede mitigarse aplicando el filtro hacia adelante y hacia atrás (filtrado por procesamiento inverso con filtfilt de SciPy, logrando respuesta cero-fase a costa de procesar offline) (). En muchos casos, se pueden usar filtros IIR en tiempo real y lograr correcciones de fase si es necesario mediante técnicas de compensación o filtrado bidireccional.\nDiseño por especificaciones: Las funciones buttord, cheb1ord, cheb2ord, ellipord de Python/MATLAB calculan el orden mínimo y frecuencia de corte necesaria para cumplir especificaciones dadas (paso, rechazo, ripple). Luego butter, cheby1/2, ellip generan los coeficientes. En el taller, se plantea diseñar un pasa-bajos IIR para voz (ej. telefónica: \\(f_s=8\\) kHz, \\(f_p=3.4\\) kHz, \\(f_s=3.8\\) kHz, ripple 1 dB, atenuación 30 dB). Un proceso típico sería: usar ellipord para obtener el orden mínimo elíptico, cheb1ord para Chebyshev I, etc., comparar órdenes y elegir uno. En nuestro ejemplo de la Figura 1, ya vimos cómo Butterworth requería orden 4 frente a 3 de Chebyshev/Elíptico para la misma tarea, lo cual es común (Butterworth suele necesitar más orden para specs estrictas). Generalmente, Elíptico da el menor orden, seguido por Chebyshev, luego Butterworth (11.3. Common IIR filters — Digital Signals Theory). Sin embargo, a veces se evita Elíptico si un ripple en rechazo muy bajo es crítico (porque incluso la pequeña ondulación en banda eliminada puede ser indeseable para ciertas mediciones sensibles, aunque en la mayoría de casos biomédicos 30 dB de atenuación es suficiente sin importar un leve ripple residual).\nImplementación en Python: A continuación se ilustra cómo diseñar un filtro Chebyshev Tipo I con SciPy para cumplir especificaciones de voz:\nimport numpy as np\nfrom scipy.signal import cheb1ord, cheby1, freqz\nfs = 8000.0  # Hz\nfp = 3400.0  # Hz pasabanda\nfsb = 3800.0 # Hz stopband\nrp = 1.0     # dB ripple paso\nrs = 30.0    # dB atenuacion rechazo\nN, Wn = cheb1ord(fp, fsb, rp, rs, fs=fs)  # orden y frecuencia crítica\nb, a = cheby1(N, rp, Wn, btype='low', fs=fs)\nw, h = freqz(b, a, worN=1024, fs=fs)\n# Verificar desempeño:\nH_db = 20*np.log10(np.abs(h))\nprint(f\"Orden Chebyshev I = {N}\")\nprint(f\"Ganancia a 3.4kHz = {H_db[np.argmin(np.abs(w-3400))]:.2f} dB\")\nprint(f\"Atenuación a 3.8kHz = {H_db[np.argmin(np.abs(w-3800))]:.2f} dB\")\n(Este código calcula el orden mínimo y coeficientes de un Chebyshev I, luego evalúa la ganancia en 3.4 kHz y 3.8 kHz para verificar que esté cerca de –1 dB y –30 dB respectivamente.)\nEl resultado confirmaría el cumplimiento de especificaciones con el filtro diseñado. Del mismo modo podríamos probar ellipord/ellip y buttord/butter. Vale notar que los diseños IIR generalmente no tienen control explícito de fase lineal (la fase es no lineal e importa evaluar el impacto en la señal; a veces, se realizan calibraciones o se aplica filtrado hacia atrás como mencionado para obtener fase cero).\n\n\n\nUna vez diseñado un filtro (FIR o IIR), es crucial validar su respuesta en frecuencia para asegurarse de que cumple con los requisitos. Esto implica computar \\(H(e^{j\\omega})\\) – típicamente mediante freqz – y verificar ganancias en las bandas de paso (p.ej. pérdida de inserción o ripple) y bandas de rechazo (atenuación mínima). También se puede aplicar el filtro a señales de prueba:\n\nImpulso unitario: la salida debe ser \\(h[n]\\) (sirve para obtener la respuesta al impulso directamente).\nEscalón unitario: la salida debe aproximarse a la respuesta al escalón (integral de \\(h[n]\\)), útil para verificar estabilidad (un filtro pasaaltos, por ej., a entrada escalón debería asentarse a un valor constante, indicando que DC fue removido pero no inestabilidad creciente).\nSeñal senoidal a frecuencias críticas: por ejemplo, inyectar una senoide en la frecuencia de corte para ver si sale atenuada a ~-3 dB o -6 dB según definición; inyectar una senoide en banda eliminada para confirmar fuerte atenuación.\n\nEn contexto biomédico, se suele validar con señales reales. Por ejemplo, si diseñamos un filtro para eliminar deriva de línea base en ECG, podemos probarlo con una señal ECG con deriva artificial y comprobar que efectivamente la elimina sin distorsionar el complejo QRS.\n(image) Figura 2: Ejemplo de filtrado de un segmento de señal ECG con un filtro pasoalto para remover la deriva de línea base. En naranja se muestra el ECG original contaminado con una deriva lenta (simulada como una componente de muy baja frecuencia que causa que la línea base oscile). En amarillo se muestra la señal tras aplicar un filtro pasaaltos Butterworth de 4° orden con \\(f_c \\approx 0.5\\) Hz (aplicado con filtrado hacia adelante y atrás para lograr fase cero). Se observa que la señal filtrada se centra alrededor de cero voltios, eliminando las variaciones lentas de la línea base, mientras preserva las características importantes del ECG (picos QRS, ondas P y T) (). Este proceso mejora la calidad de la señal para análisis posterior (por ejemplo, facilitando la detección de eventos cardiacos), sin introducir distorsión apreciable en la forma de onda rápida del ECG.\nOtro ejemplo es la eliminación de interferencia de red: un filtro notch diseñado como en secciones previas se puede aplicar a una señal EEG a la que deliberadamente se le suma un seno de 50 Hz; la validación consistiría en ver el espectro antes y después (verificando que la línea de 50 Hz desaparece tras filtrar) y que la actividad EEG en otras bandas permanece intacta.\nEn el diseño de filtros FIR e IIR para voz o bioseñales, a veces se comparan métodos. Por ejemplo, en el taller se pide diseñar tanto un FIR por ventana como un IIR por transformación bilineal para ciertas especificaciones. Comparar la respuesta espectral es instructivo: un FIR puede requerir mayor orden para lograr la misma nitidez de corte que un IIR, pero tendrá fase lineal; el IIR logrará la especificación con menos coeficientes, pero introducirá dispersión de fase. Dependiendo de la aplicación, uno u otro puede ser preferible. Estudios en filtrado de ECG han encontrado, por ejemplo, que filtros IIR y FIR bien diseñados pueden ambos remover el ruido de línea base efectivamente; los IIR (como filtros Butterworth pasaaltos) pueden ser implementados en tiempo real con pocas operaciones (comp.dsp | How to write a NotchFilter procedure| page 2), mientras que FIR largos podrían introducir retardo si no se aplican con técnicas especiales. Sin embargo, los FIR lineales en fase aseguran que características como la amplitud del ST o la morfología de la onda P no se deformen ni se desplacen temporalmente, lo cual es crítico en ciertos análisis diagnósticos.\nEn resumen, la validación espectral (y temporal) de los filtros diseñados garantiza que el filtro funcione como esperado en las señales biomédicas objetivo. Se recomienda siempre verificar ganancia en banda pasante (por ej., asegurarse de que un filtro pasa-bajos no atenúe significativamente componentes importantes de la señal, salvo el ripple permitido) y atenuación en banda eliminada (asegurarse de que el ruido o interferencia objetivo realmente se reduce a niveles aceptables). Con herramientas como Python/Matlab, esta validación se realiza fácilmente visualizando la respuesta en frecuencia (como en las Figuras 1 y 2) y realizando pruebas con señales sintéticas o reales.\n\n\n\nEste reporte abordó los fundamentos teóricos necesarios para analizar y diseñar sistemas discretos aplicados a señales biomédicas. Se revisó la transformada Z y su papel en caracterizar señales y sistemas LTI, destacando la importancia de la región de convergencia, polos, ceros, causalidad y estabilidad (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). También se discutió cómo interpretar y construir diagramas de bloques a partir de ecuaciones en diferencias, algo útil para implementar filtros digitalmente. En la parte de diseño, se cubrieron dos enfoques contrastantes: filtros FIR por método de ventanas, sencillos y con fase lineal (deseable en biomédica), y filtros IIR por transformación bilineal a partir de prototipos analógicos (eficientes en orden, aunque con fase no lineal). Se compararon los principales tipos de aproximaciones analógicas (Butterworth, Chebyshev I/II, Elíptico) resaltando sus ventajas y compromisos (11.3. Common IIR filters — Digital Signals Theory).\nA lo largo del documento, se enfatizó la aplicación en señales reales: eliminar deriva de línea base con pasaaltos, suprimir interferencia de red con filtros notch, limitar el ancho de banda de voz o EEG con pasabajos, etc., todo soportado por referencias académicas y ejemplos de código. En la práctica, el ingeniero biomédico debe decidir el tipo de filtro según los requisitos clínicos: por ejemplo, ¿es más importante no distorsionar la forma de onda (fase lineal) o tener un filtro muy agudo (menor orden)? Este tipo de decisiones se facilita con la comprensión profunda de los conceptos aquí explicados.\nCon este marco teórico, se está en capacidad de abordar el taller propuesto: calcular transformadas Z y ROC de señales, analizar sistemas LTI (impulso, estabilidad, salida a entradas dadas), dibujar sus polos, ceros y estructuras, así como diseñar filtros FIR e IIR que satisfagan especificaciones dadas, especialmente dentro del contexto de procesamiento de señales biomédicas donde la fidelidad y eficacia del filtrado impactan directamente la calidad de la información diagnóstica obtenida.\nReferencias: Las referencias provistas en el texto (ej.【23】,【17】,【40】) corresponden a fuentes que respaldan y complementan los puntos discutidos, incluyendo textos de procesamiento digital de señales, artículos de investigación en filtrado de ECG/EEG, y documentación de funciones de diseño de filtros. Estas fuentes ofrecen mayor detalle para el lector interesado en profundizar en aspectos específicos. En particular, se destacan obras clásicas como Oppenheim & Schafer en diseño FIR (WindowFIRDesign.fm), y recursos modernos como libros abiertos de señales y sistemas (Transformada Z - Wikipedia, la enciclopedia libre) y tutoriales de SciPy (11.3. Common IIR filters — Digital Signals Theory) que enriquecen la comprensión teórica y práctica del procesamiento de señales biomédicas."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#introducción",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#introducción",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "El procesamiento digital de señales biomédicas (como ECG y EEG) emplea herramientas matemáticas para analizar y mejorar la calidad de estas señales, extrayendo información útil para diagnóstico y monitoreo clínico (Procesamiento de señales biomédicas: EEG & FPGA). En particular, la transformada Z y los filtros digitales (FIR e IIR) son fundamentales para modelar, analizar y modificar señales en tiempo discreto. Por ejemplo, es común eliminar interferencias de línea base o ruido de red eléctrica (50/60 Hz) mediante filtros pasoalto o de rechazo (notch) adecuados (). Este reporte teórico describe los conceptos clave para resolver un taller de análisis de señales biomédicas, cubriendo la transformada Z, la estabilidad y región de convergencia (ROC), la representación de sistemas LTI (Lineales e Invariantes en el Tiempo) mediante polos y ceros, la respuesta al impulso, los diagramas de bloques, y el diseño de filtros digitales FIR e IIR (incluyendo métodos de ventaneo y transformación bilineal). Se incluyen ejemplos prácticos en Python (usando numpy y scipy) para ilustrar implementaciones, con un claro enfoque en aplicaciones biomédicas como el filtrado de señales ECG/EEG. Las explicaciones se apoyan en referencias académicas para asegurar rigor teórico."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#transformada-z-y-sistemas-lti-discretos",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#transformada-z-y-sistemas-lti-discretos",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "La transformada Z convierte una señal \\(x[n]\\) de tiempo discreto en una representación en el dominio complejo. En forma bilateral, se define como:\n\\[X(z) = \\mathcal{Z}\\{x[n]\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\,z^{-n},\\]\ndonde \\(z\\) es una variable compleja \\(z = A e^{j\\omega}\\) (con \\(A=|z|\\) y \\(\\omega = \\arg(z)\\)) (Transformada Z - Wikipedia, la enciclopedia libre) (Transformada Z - Wikipedia, la enciclopedia libre). En señales causales (\\(x[n]=0\\) para \\(n&lt;0\\)), suele usarse la transformada Z unilateral definida desde \\(n=0\\) hasta \\(\\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). La transformada Z es análoga a la transformada de Laplace en sistemas continuos, y de hecho puede verse como una serie de Laurent (suma infinita de potencias) (Transformada Z - Wikipedia, la enciclopedia libre).\nRegión de Convergencia (ROC): No toda señal tiene transformada Z en forma cerrada; la serie anterior converge únicamente en ciertas regiones del plano \\(z\\). La ROC se define como el conjunto de valores de \\(z\\) para los cuales la serie converge absolutamente (Transformada Z - Wikipedia, la enciclopedia libre). En términos prácticos, la ROC es el rango de \\(z\\) donde \\(\\sum_{n=-\\infty}^{\\infty}|x[n]z^{-n}| &lt; \\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). Por ejemplo, si \\(x[n] = a^n u[n]\\) (secuencia exponencial causal con \\(u[n]\\) la escalón unidad), su transformada Z es \\(X(z) = \\frac{1}{1 - a\\,z^{-1}}\\), pero esta expresión es válida solo si \\(|z| &gt; |a|\\) (ya que la serie geométrica converge cuando \\(|a/z|&lt;1\\)). Así, la ROC en este caso es \\(|z| &gt; |a|\\). Si la señal fuera anti-causal (\\(x[n]=0\\) para \\(n&gt;0\\)), la ROC sería \\(|z| &lt; |a|\\) (convergencia hacia adentro). Si \\(x[n]\\) tiene duración finita (FIR), su transformada Z existe para todo \\(z\\neq0\\) excepto quizá puntos donde la propia definición tenga singularidades (por lo general ROC = todo el plano \\(z\\), excepto tal vez \\(z=0\\) o \\(z=\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). La ROC nunca incluye polos (donde la función \\(X(z)\\) diverge) (Transformada Z - Wikipedia, la enciclopedia libre), es típicamente un anillo o media-plano en el plano \\(z\\), y su ubicación está ligada a propiedades de la señal como causalidad y estabilidad.\nPolos y ceros: Cualquier función de transferencia discreta o transformada Z de una señal racional puede expresarse en forma de polos y ceros. Los ceros son valores de \\(z\\) que anulan \\(X(z)\\) (raíces del numerador), y los polos donde \\(X(z)\\) diverge (raíces del denominador). Por ejemplo, en \\(X(z) = \\frac{1}{1 - a z^{-1}}\\), hay un polo en \\(z=a\\) y un cero en \\(z=\\infty\\) (o equivalente, un cero de orden 1 en el origen en la función \\(X(z)\\) multiplicada por \\(z^{-1}\\)). La representación gráfica de polos y ceros en el plano \\(z\\) proporciona intuición sobre el comportamiento frecuencial: los ceros en la circunferencia unitaria (\\(|z|=1\\)) cancelan ciertas frecuencias, mientras que los polos cercanos a la circunferencia unitaria amplifican componentes espectrales cercanas a su ángulo.\nCausalidad: Un sistema LTI discreto es causal si \\(h[n]=0\\) para \\(n&lt;0\\) (su respuesta impulso es nula en tiempos negativos). En la transformada Z, esto implica que la ROC es externa, es decir, de la forma \\(|z|&gt;R\\) (convergencia hacia \\(\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). Todos los polos de un sistema causal deben estar dentro de la ROC (que para causal es exterior al polo de mayor radio) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Un detalle importante es que la ubicación de polos por sí sola no determina completamente la causalidad o estabilidad; la ROC es la que define cuál de las posibles señales con esos polos es la realizada (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por ejemplo, una misma función racional puede corresponder a un sistema causal inestable o a un sistema no causal estable, dependiendo de si la ROC se toma fuera o entre polos (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange).\nEstabilidad BIBO: Un sistema es estable (en sentido BIBO: Bounded-Input Bounded-Output) si su respuesta al impulso \\(h[n]\\) es absolutamente sumable, \\(\\sum_{n=-\\infty}^{\\infty}|h[n]| &lt; \\infty\\). Esta condición garantiza que cualquier entrada acotada produce salida acotada (BIBO stability - Wikipedia). En el dominio Z, estabilidad equivale a que la ROC de \\(H(z)\\) contenga al círculo unitario (\\(|z|=1\\)) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Para sistemas causales, esto se traduce en que todos los polos deben estar dentro del círculo unitario (ya que la ROC causal comienza fuera del polo de mayor magnitud) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por tanto, un filtro digital causal será estable si sus polos \\(p_i\\) satisfacen \\(|p_i|&lt;1\\). En sistemas no causales (e.g. acausales diseñados con filtrado hacia atrás y adelante para cancelar fase), la estabilidad puede lograrse con polos fuera del unitario siempre y cuando la ROC (un anillo) incluya el unitario (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange), aunque estos casos son menos comunes en línea real. En general, para diseño de filtros digitales asumiremos causalidad, por lo que chequear estabilidad equivale a verificar polos dentro del unitario.\nEjemplo (ECG y estabilidad): Considere un filtro pasoalto diseñado para remover la línea base de ECG definido por la diferencia \\(y[n] = x[n] - x[n-1]\\). Su función de transferencia es \\(H(z) = 1 - z^{-1}\\), con un cero en \\(z=1\\) (cancela DC) y un polo en \\(z=0\\) (simple, debido al \\(z^{-1}\\)). Este sistema es causal (diferencia causal) y su único polo \\(z=0\\) está dentro del círculo unitario, por lo que es estable. De hecho, su respuesta al impulso \\(h[n]=\\delta[n] - \\delta[n-1]\\) suma 0 en valor absoluto (sumable). Este filtro elimina componentes de muy baja frecuencia, como la deriva de línea base en un ECG (), sin inestabilidad."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#análisis-de-sistemas-lti-en-tiempo-discreto",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#análisis-de-sistemas-lti-en-tiempo-discreto",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Un sistema LTI discreto queda caracterizado completamente por su respuesta al impulso \\(h[n]\\). Dada cualquier entrada \\(x[n]\\), la salida es la convolución discreta \\(y[n] = (x*h)[n] = \\sum_{k=-\\infty}^{\\infty} h[k]\\,x[n-k]\\). En el dominio Z, esta convolución se convierte en multiplicación: \\(Y(z) = H(z)\\,X(z)\\) (dentro de la intersección de ROC de \\(X\\) y \\(H\\)). La función de transferencia \\(H(z)\\) de un sistema LTI causal viene dada por la transformada Z de \\(h[n]\\) (unilateral). En sistemas de coeficientes constantes (difundidos en ingeniería), \\(H(z)\\) suele ser una función racional de \\(z\\):\n\\[H(z) = \\frac{B(z)}{A(z)} = \\frac{b_0 + b_1 z^{-1} + \\cdots + b_M z^{-M}}{1 + a_1 z^{-1} + \\cdots + a_N z^{-N}},\\]\ndonde \\(B(z)\\) y \\(A(z)\\) son polinomios en \\(z^{-1}\\). La razón de escribir en potencias de \\(z^{-1}\\) es para reflejar la causalidad (solo potencias no positivas de \\(z\\)). La ecuación en diferencias asociada es:\n\\[y[n] + a_1 y[n-1] + \\cdots + a_N y[n-N] = b_0 x[n] + b_1 x[n-1] + \\cdots + b_M x[n-M].\\]\nEste es el modelo típico de sistemas LTI discreto. Si \\(N=0\\) (no hay realimentación, solo ceros), el sistema es FIR (Finite Impulse Response), pues \\(h[n]\\) es de duración finita (máximo \\(M\\)). Si \\(N&gt;0\\), hay realimentación y el sistema es IIR (Infinite Impulse Response), con respuesta al impulso teóricamente infinita (aunque decreciente si es estable).\nDiagramas de bloques: Un LTI puede implementarse mediante sumas, retardos (\\(z^{-1}\\) representa un retardo de 1 muestra) y multiplicaciones por constantes. El diagrama de bloques representa visualmente la ecuación en diferencias. Por ejemplo, para un filtro IIR de segundo orden:\n\\[y[n] = -a_1 y[n-1] - a_2 y[n-2] + b_0 x[n] + b_1 x[n-1] + b_2 x[n-2],\\]\nel diagrama en forma Directa II combinaría los términos en una estructura canónica con dos bloques de retardo en la rama de realimentación y avance, sumadores para combinar las ramas, y coeficientes \\(a_i\\), \\(b_i\\). Cada polo corresponde a un lazo de realimentación (coeficientes \\(a_i\\)) y cada cero a una ramificación hacia la entrada (coeficientes \\(b_i\\)). Dibujar estos diagramas ayuda a entender la estructura interna, pero en este reporte nos enfocaremos más en el análisis matemático. Cabe destacar que el tipo de filtro (pasa-bajos, pasa-altos, etc.) puede inferirse de \\(H(z)\\): por ejemplo, si \\(H(e^{j\\omega})\\) (respuesta en frecuencia) atenúa bajas frecuencias y deja pasar altas, es pasa-altos. Un método práctico es evaluar \\(H(z)\\) en \\(z=e^{j0}\\) (DC, \\(\\omega=0\\)) y en \\(z=e^{j\\pi}\\) (Nyquist, \\(\\omega=\\pi\\)): si \\(|H(e^{j0})|=0\\) y \\(|H(e^{j\\pi})|\\approx 1\\), es pasa-altos; al revés sería pasa-bajos. Los ceros en \\(z=1\\) anulan \\(\\omega=0\\) (eliminan DC), típicos en pasa-altos (), mientras ceros en \\(z=-1\\) anulan \\(\\omega=\\pi\\) (eliminan la componente de Nyquist, típicos en pasa-bajos). Por su parte, polos cercanos a \\(z=1\\) refuerzan respuesta en bajas frecuencias; polos cercanos a \\(z=-1\\) refuerzan la alta frecuencia \\(\\pi\\). Así, el diagrama polo-cero brinda intuición: ceros sobre la circunferencia unitaria en cierto ángulo \\(\\theta_0\\) causan una notch (anulación) en la frecuencia \\(\\omega=\\theta_0\\), mientras polos cerca de la unidad en \\(\\theta_0\\) generan picos (potenciales resonancias) alrededor de esa frecuencia.\nEjemplo (Filtro notch 60 Hz): Un problema común en bioseñales es eliminar la interferencia de la red eléctrica (50/60 Hz) sobre, por ejemplo, EEG o ECG. Un filtro digital sencillo para eliminar 60 Hz (asumiendo frecuencia de muestreo \\(f_s=5000\\) Hz) es colocar ceros conjugados en \\(z = e^{\\pm j 2\\pi(60/5000)}\\). La función de transferencia resultante puede ser:\n\\[H(z) = 1 - 2\\cos(2\\pi\\frac{60}{5000})\\,z^{-1} + z^{-2}.\\]\nEste \\(H(z)\\) tiene ceros en \\(e^{\\pm j2\\pi(60/5000)}\\) que anulan exactamente la componente de 60 Hz, implementando un filtro notch. Además, es un filtro FIR (orden 2) con coeficientes simétricos, lo que le da fase lineal (importante para no deformar la forma de onda). ¿Es estable? Sí, al ser FIR no hay polos fuera del origen (solo polos en 0, con módulo 0). ¿Es causal? Sí, depende solo de muestras presentes y pasadas de la señal (\\(x[n]\\), \\(x[n-1]\\), \\(x[n-2]\\)). ¿Qué tipo de filtro es? Es un rechaza-banda estrecho centrado en 60 Hz (deja pasar el resto, pero rechaza esa frecuencia). En aplicaciones, este notch suele atenuar ruido de red sin distorsionar significativamente las señales de interés ()."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-fir-por-el-método-de-ventanas",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-fir-por-el-método-de-ventanas",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Los filtros FIR (Respuesta al Impulso Finita) son ampliamente utilizados en procesamiento biomédico porque pueden diseñarse para tener respuesta en fase lineal, evitando distorsión de fase en la señal filtrada (lo cual es útil para preservar la morfología de ondas ECG, por ejemplo). Una manera conceptualmente sencilla de diseñar un FIR es mediante el método de ventana (WindowFIRDesign.fm). Consiste en: (1) definir la respuesta frecuencial ideal deseada \\(H_d(e^{j\\omega})\\), (2) obtener la respuesta al impulso ideal \\(h_d[n]\\) como la transformada inversa de Fourier de \\(H_d\\), y (3) truncar \\(h_d[n]\\) (que usualmente es infinita o muy larga) mediante una función ventana \\(w[n]\\) para obtener un FIR realizable \\(h[n] = h_d[n]\\,w[n]\\).\nPor ejemplo, supongamos que queremos un filtro pasa-bajos ideal con frecuencia de corte \\(\\omega_c\\). El impulso ideal es \\(h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}\\) (un sinc) que se extiende infinitamente. Para obtener un FIR causal de longitud \\(M\\), se multiplica \\(h_d[n]\\) por una ventana \\(w[n]\\) de longitud \\(M\\) centrada apropiadamente (y a menudo se aplica un corrimiento para hacer el filtro causal). Las ventanas comúnmente utilizadas incluyen: Rectangular, Bartlett (triangular), Hann (Hanning), Hamming, Blackman, y la Kaiser (que es ajustable). Cada ventana introduce un cierto lóbulo principal en la respuesta en frecuencia (determinando la anchura de la transición) y lóbulos laterales (que determinan el ripple o atenuación en bandas de rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm).\nLas características típicas de ventanas clásicas (según Oppenheim et al. (WindowFIRDesign.fm) (WindowFIRDesign.fm)) son:\n\nRectangular: lóbulo principal más angosto (ancho \\(\\approx 4\\pi/M\\) rad) pero lóbulos laterales más altos (primer sidelobe ~\\(-13\\) dB, atenuación de rechazo $$21 dB) (WindowFIRDesign.fm). Da la transición más abrupta para un orden dado, al costo de peor rechazo de banda.\nBartlett (triangular): lóbulo principal algo más ancho (\\(\\approx 8\\pi/M\\)), sidelobes ~\\(-25\\) dB (WindowFIRDesign.fm).\nHann: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes ~\\(-31\\) dB (WindowFIRDesign.fm) (mejor rechazo que rectangular pero transiciones más suaves).\nHamming: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes \\(\\approx -41\\) dB (mínima atenuación ~53 dB en rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm). Es muy popular por su buen compromiso entre ancho de transición y rechazo en banda eliminada.\nBlackman: lóbulo principal más ancho (\\(\\approx 12\\pi/M\\)) pero sidelobes muy bajos (~\\(-57\\) dB, atenuación ~74 dB) (WindowFIRDesign.fm).\nKaiser: permite escoger un parámetro \\(\\beta\\) para controlar la atenuación de lóbulo lateral, ofreciendo flexibilidad. Aproximadamente, para lograr \\(A\\) dB de atenuación, \\(\\beta \\approx 0.1102(A-8.7)\\) (para \\(A&gt;50\\)), y el ancho de transición normalizado \\(\\Delta\\omega\\) se relaciona con el orden \\(M\\) y \\(\\beta\\) por \\(M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\\) (WindowFIRDesign.fm) (estas fórmulas provienen de aproximaciones de Kaiser y ayudan a dimensionar el filtro).\n\nEl método de ventanas es sencillo pero implica un compromiso fijo entre ancho de transición y ripple: una vez elegida la ventana, la única forma de mejorar la pendiente de corte es aumentar \\(M\\) (orden del filtro). Por ejemplo, la ventana Hamming siempre tendrá ~\\(-53\\) dB de mínimo en rechazo sin importar \\(M\\) (WindowFIRDesign.fm), pero al incrementar \\(M\\) se reducirá la anchura de transición. En contraste, la ventana rectangular logra transiciones muy rápidas con orden modesto, pero su pobre rechazo (~21 dB) la hace inadecuada si necesitamos, digamos, eliminar ruido fuerte. En señales biomédicas, suele preferirse reducir al mínimo distorsiones residuales de ruido, por lo que ventanas con mejor rechazo (Hamming, Blackman o Kaiser ajustada) son comunes.\nCálculo del orden para especificaciones dadas: Dado un requerimiento de diseño (ej. atenuación mínima de 40 dB en banda eliminada y transición de 10 Hz), podemos estimar el orden necesario. Por ejemplo, en el taller se plantea diseñar un pasa-bajos FIR con \\(f_c = 55\\) Hz (definido al nivel de \\(-6\\) dB), que alcance al menos 20 dB de atenuación a 60 Hz y &gt;40 dB más allá de 80 Hz. Esto implica una banda de transición bastante estrecha (de ~55 a 60 Hz) y un rechazo fuerte. Un enfoque sería probar varias ventanas:\n\nRectangular: probablemente no pueda dar 40 dB de rechazo (limita ~21 dB).\nHamming: puede dar ~53 dB de rechazo, suficiente, pero el ancho de transición \\(\\Delta f\\) será ~\\(\\frac{3.3}{M}\\) (en radianes normalizados, equivalente aprox. a \\(\\frac{0.26 f_s}{M}\\) en Hz para banda bilateral). Para \\(\\Delta f \\approx 5\\) Hz con \\(f_s\\) suficientemente grande, requerirá un \\(M\\) elevado.\nBlackman: daría &gt;60 dB de rechazo, pero su transición es más ancha (por ser \\(12\\pi/M\\) rad).\nKaiser: se puede ajustar para 40 dB con quizás menor \\(M\\) que Hamming, porque se elige justo la atenuación requerida y minimiza ancho de transición para ese nivel.\n\nEn el taller, se sugiere calcular el orden mínimo para cada ventana cumpliendo las specs y elegir la de menor orden. Esto implicaría usar fórmulas o tablas estándar (WindowFIRDesign.fm) (WindowFIRDesign.fm). Por ejemplo, para 40 dB de rechazo y \\(\\Delta f = 20\\) Hz (digamos entre 60 y 80 Hz), la Hamming podría necesitar \\(M \\approx \\frac{3.3\\cdot 2\\pi}{(20/f_s)2\\pi} = \\frac{3.3 f_s}{20}\\) (esta es una estimación tosca usando \\(\\Delta\\omega \\approx 8\\pi/M\\)). Si la señal es de voz muestreada a 8 kHz (caso típico, aunque aquí es biomédica a 200 Hz?), podemos obtener números específicos. En general, se podría iterar aumentando \\(M\\) y midiendo la respuesta espectral hasta que los requisitos se satisfagan.\nA modo de ilustración práctica, diseñemos un filtro FIR pasa-bajos con método del ventaneo en Python, usando scipy.signal.firwin. Por simplicidad, tomemos \\(f_s=200\\) Hz, \\(f_c=30\\) Hz, y usemos ventana de Hamming:\nimport numpy as np\nfrom scipy import signal\nfs = 200.0  # Hz\nfc = 30.0   # Hz (deseamos pasa-bajos)\nN = 51      # orden (se puede ajustar)\ntaps = signal.firwin(N, cutoff=fc, window='hamming', fs=fs)\nw, H = signal.freqz(taps, worN=8000, fs=fs)\n# Convertir respuesta a dB:\nH_db = 20*np.log10(np.abs(H))\n# Encontrar atenuación en 60 Hz:\nidx_60 = np.argmin(np.abs(w-60))\nprint(f\"Atenuación a 60Hz: {H_db[idx_60]:.2f} dB\")\n(El código anterior calcula los coeficientes FIR con ventana de Hamming y evalúa la respuesta. Se puede iterar sobre N hasta lograr &gt;40 dB en 80 Hz, etc.)\nEn general, el método de ventanas es rápido y fácil de implementar. Su principal limitación es la falta de control preciso sobre las bandas: el ripple y transición vienen determinados por la elección de ventana, no exactamente por parámetros deseados (excepto en Kaiser donde hay más control). Aún así, es muy útil en procesamiento biomédico cuando queremos filtros lineales en fase y podemos permitir órdenes relativamente altos (el costo computacional suele ser menor preocupación en aplicaciones off-line, pero en tiempo real un FIR muy largo puede introducir latencia)."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-iir-por-transformación-bilineal",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-iir-por-transformación-bilineal",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Los filtros IIR (Respuesta Infinita al Impulso) se suelen diseñar a partir de filtros analógicos prototipo utilizando transformaciones como la transformación bilineal. Este enfoque aprovecha décadas de diseños analógicos bien estudiados (Butterworth, Chebyshev, Elíptico, etc.) y los lleva al dominio digital asegurando estabilidad y correspondiendo frecuencias de interés.\nTransformación bilineal: Es una transformación conforme que mapea el plano-\\(s\\) (Laplace) en el plano-\\(z\\) (Z) mediante la sustitución:\n\\[ s = \\frac{2}{T}\\,\\frac{z-1}{\\,z+1\\,}, \\]\ndonde \\(T\\) es el periodo de muestreo (usualmente tomamos \\(T=1\\) para frecuencias normalizadas, o usamos \\(2/T\\) para incluir \\(f_s\\) explícitamente) (Transformación bilineal - Wikipedia, la enciclopedia libre) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esta sustitución se adopta universalmente para convertir funciones de transferencia analógicas \\(H_a(s)\\) en funciones \\(H_d(z)\\) digitales (Transformación bilineal - Wikipedia, la enciclopedia libre). La clave es que la transformación bilineal preserva la estabilidad: polos en el semiplano izquierdo (\\(\\Re(s)&lt;0\\)) mapean dentro del círculo unitario (\\(|z|&lt;1\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Así, un filtro analógico estable producirá un filtro digital estable (Transformación bilineal - Wikipedia, la enciclopedia libre). También mapea el eje \\(j\\omega\\) (eje imaginario \\(s = j\\Omega\\)) en la circunferencia unitaria (\\(z = e^{j\\omega T}\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre), aunque no linealmente en frecuencia. De hecho, existe una distorsión de la respuesta frecuencial conocida como warping: la relación entre frecuencia analógica \\(\\Omega\\) y digital \\(\\omega\\) viene dada por \\(\\omega = 2 \\arctan(\\Omega T/2)\\) (y su inversa \\(\\Omega = \\frac{2}{T}\\tan(\\omega/2)\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esto significa que la escala de frecuencias se comprime al mapear al dominio digital, especialmente conforme \\(\\omega\\) se acerca a Nyquist (\\(\\pi\\) rad/s).\nPara lidiar con el warping, en el diseño se realiza una pre-distorsión (pre-warping) de las especificaciones. Si deseamos que una frecuencia analógica \\(\\Omega_p\\) de corte corresponda exactamente a una digital \\(\\omega_p\\), calculamos \\(\\Omega_p = \\frac{2}{T}\\tan(\\omega_p/2)\\). Lo mismo para frecuencias de banda de rechazo, etc., antes de diseñar el filtro analógico. Luego aplicamos la transformación bilineal. En la práctica, las funciones auxiliares de diseño (como scipy.signal.buttord, cheb1ord, etc.) permiten ingresar especificaciones directamente en el dominio digital y hacen el prewarping internamente (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory).\nPrototipos analógicos comunes:\n\nButterworth: Magnitud con máxima planitud en banda de paso (respuesta maximally flat). No presenta ondulaciones en banda de paso ni rechazo, pero la transición es la más lenta de los tipos clásicos (11.3. Common IIR filters — Digital Signals Theory). Su función de magnitud al cuadrado es \\(|H(j\\Omega)|^2 = \\frac{1}{1 + (\\frac{\\Omega}{\\Omega_c})^{2N}}\\). Para un orden \\(N\\), la atenuación en rechazo aumenta gradualmente con la frecuencia. Útil cuando se quiere respuesta suave sin ripple.\nChebyshev Tipo I: Presenta rizado en banda de paso (ε dB de variación) pero ninguna ondulación en banda de rechazo (11.3. Common IIR filters — Digital Signals Theory). A cambio, logra una caída más abrupta que Butterworth para el mismo orden (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). La magnitud cumple \\(|H(j\\Omega)|^2 = \\frac{1}{1 + \\epsilon^2 T_N^2(\\Omega/\\Omega_c)}\\), donde \\(T_N\\) es el polinomio de Chebyshev de primer tipo (oscila entre ±1). Permite especificar ripple tolerado en pasobanda.\nChebyshev Tipo II: Lo opuesto: sin ripple en banda de paso, pero con ondulación controlada en banda de rechazo. También llamados filtros de Chebyshev inversos. Tienen una transición algo más lenta que los tipo I para igual orden, pero fase más lineal en pasobanda (al no tener ripple ahí).\nElíptico (Cauer): Permite rizado tanto en pasobanda como en rechazo (ambos controlables) (11.3. Common IIR filters — Digital Signals Theory), logrando la caída más empinada de todas las aproximaciones para un orden dado (11.3. Common IIR filters — Digital Signals Theory). Son los más eficientes en términos de orden, a costa de ripple en ambas bandas y mayor no linealidad de fase. Incluyen ceros de transmisión en la banda eliminada, lo que les da atenuación muy alta cerca de los bordes.\n\nEn resumen (11.3. Common IIR filters — Digital Signals Theory): Butterworth no tiene ripple en ninguna banda (pero pendiente menor), Chebyshev I tiene ripple en paso (no en rechazo), Chebyshev II ripple en rechazo (no en paso), y Elíptico ripple en ambas, pero transición más rápida. La Figura 1 ilustra las diferencias de respuesta en un ejemplo práctico.\n(image) Figura 1: Comparación de la respuesta en magnitud (en dB) para filtros IIR pasa-bajos diseñados con las mismas especificaciones (pasa-bajos con \\(f_{p}=3.4\\) kHz con 1 dB de ripple en banda de paso, \\(f_{s}=3.8\\) kHz con 30 dB de atenuación). El filtro elíptico (orden 3, línea roja) logra la transición más abrupta (caída más rápida alrededor de 3.4-3.8 kHz) a costa de presentar ondulaciones tanto en la banda de paso como en la de rechazo. El Chebyshev I (orden 3, línea naranja) exhibe ripple en la banda de paso pero no en la de rechazo, con una pendiente intermedia. El Butterworth (orden 4, línea amarilla) no tiene ripple en ninguna banda, pero requiere un orden mayor y su caída es más paulatina (transición más suave) (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). Todos cumplen con los requisitos (–1 dB a 3.4 kHz, –30 dB a 3.8 kHz), pero el orden mínimo necesario varía (Butterworth necesitó \\(N=4\\) mientras Chebyshev I y Elíptico lograron con \\(N=3\\)). Esto ilustra el compromiso entre pendiente de transición y ondulaciones en las distintas aproximaciones.\nEn diseño, elegir el tipo de filtro depende de la aplicación: en bioseñales, a veces se prefiere Butterworth para evitar cualquier ripple (ej. filtrar ECG sin distorsionar amplitud de componentes clínicas), otras veces un Chebyshev o Elíptico puede ser apropiado si se necesita un filtro muy selectivo (ej. aislar una banda muy estrecha de EEG) y se puede tolerar cierta variación en la ganancia de la banda útil. La fase de los IIR no es lineal, pero si la distorsión de fase es un problema (por ejemplo, desplazamiento o deformación de picos en ECG), puede mitigarse aplicando el filtro hacia adelante y hacia atrás (filtrado por procesamiento inverso con filtfilt de SciPy, logrando respuesta cero-fase a costa de procesar offline) (). En muchos casos, se pueden usar filtros IIR en tiempo real y lograr correcciones de fase si es necesario mediante técnicas de compensación o filtrado bidireccional.\nDiseño por especificaciones: Las funciones buttord, cheb1ord, cheb2ord, ellipord de Python/MATLAB calculan el orden mínimo y frecuencia de corte necesaria para cumplir especificaciones dadas (paso, rechazo, ripple). Luego butter, cheby1/2, ellip generan los coeficientes. En el taller, se plantea diseñar un pasa-bajos IIR para voz (ej. telefónica: \\(f_s=8\\) kHz, \\(f_p=3.4\\) kHz, \\(f_s=3.8\\) kHz, ripple 1 dB, atenuación 30 dB). Un proceso típico sería: usar ellipord para obtener el orden mínimo elíptico, cheb1ord para Chebyshev I, etc., comparar órdenes y elegir uno. En nuestro ejemplo de la Figura 1, ya vimos cómo Butterworth requería orden 4 frente a 3 de Chebyshev/Elíptico para la misma tarea, lo cual es común (Butterworth suele necesitar más orden para specs estrictas). Generalmente, Elíptico da el menor orden, seguido por Chebyshev, luego Butterworth (11.3. Common IIR filters — Digital Signals Theory). Sin embargo, a veces se evita Elíptico si un ripple en rechazo muy bajo es crítico (porque incluso la pequeña ondulación en banda eliminada puede ser indeseable para ciertas mediciones sensibles, aunque en la mayoría de casos biomédicos 30 dB de atenuación es suficiente sin importar un leve ripple residual).\nImplementación en Python: A continuación se ilustra cómo diseñar un filtro Chebyshev Tipo I con SciPy para cumplir especificaciones de voz:\nimport numpy as np\nfrom scipy.signal import cheb1ord, cheby1, freqz\nfs = 8000.0  # Hz\nfp = 3400.0  # Hz pasabanda\nfsb = 3800.0 # Hz stopband\nrp = 1.0     # dB ripple paso\nrs = 30.0    # dB atenuacion rechazo\nN, Wn = cheb1ord(fp, fsb, rp, rs, fs=fs)  # orden y frecuencia crítica\nb, a = cheby1(N, rp, Wn, btype='low', fs=fs)\nw, h = freqz(b, a, worN=1024, fs=fs)\n# Verificar desempeño:\nH_db = 20*np.log10(np.abs(h))\nprint(f\"Orden Chebyshev I = {N}\")\nprint(f\"Ganancia a 3.4kHz = {H_db[np.argmin(np.abs(w-3400))]:.2f} dB\")\nprint(f\"Atenuación a 3.8kHz = {H_db[np.argmin(np.abs(w-3800))]:.2f} dB\")\n(Este código calcula el orden mínimo y coeficientes de un Chebyshev I, luego evalúa la ganancia en 3.4 kHz y 3.8 kHz para verificar que esté cerca de –1 dB y –30 dB respectivamente.)\nEl resultado confirmaría el cumplimiento de especificaciones con el filtro diseñado. Del mismo modo podríamos probar ellipord/ellip y buttord/butter. Vale notar que los diseños IIR generalmente no tienen control explícito de fase lineal (la fase es no lineal e importa evaluar el impacto en la señal; a veces, se realizan calibraciones o se aplica filtrado hacia atrás como mencionado para obtener fase cero)."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#validación-espectral-y-aplicaciones-en-señales-biomédicas",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#validación-espectral-y-aplicaciones-en-señales-biomédicas",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Una vez diseñado un filtro (FIR o IIR), es crucial validar su respuesta en frecuencia para asegurarse de que cumple con los requisitos. Esto implica computar \\(H(e^{j\\omega})\\) – típicamente mediante freqz – y verificar ganancias en las bandas de paso (p.ej. pérdida de inserción o ripple) y bandas de rechazo (atenuación mínima). También se puede aplicar el filtro a señales de prueba:\n\nImpulso unitario: la salida debe ser \\(h[n]\\) (sirve para obtener la respuesta al impulso directamente).\nEscalón unitario: la salida debe aproximarse a la respuesta al escalón (integral de \\(h[n]\\)), útil para verificar estabilidad (un filtro pasaaltos, por ej., a entrada escalón debería asentarse a un valor constante, indicando que DC fue removido pero no inestabilidad creciente).\nSeñal senoidal a frecuencias críticas: por ejemplo, inyectar una senoide en la frecuencia de corte para ver si sale atenuada a ~-3 dB o -6 dB según definición; inyectar una senoide en banda eliminada para confirmar fuerte atenuación.\n\nEn contexto biomédico, se suele validar con señales reales. Por ejemplo, si diseñamos un filtro para eliminar deriva de línea base en ECG, podemos probarlo con una señal ECG con deriva artificial y comprobar que efectivamente la elimina sin distorsionar el complejo QRS.\n(image) Figura 2: Ejemplo de filtrado de un segmento de señal ECG con un filtro pasoalto para remover la deriva de línea base. En naranja se muestra el ECG original contaminado con una deriva lenta (simulada como una componente de muy baja frecuencia que causa que la línea base oscile). En amarillo se muestra la señal tras aplicar un filtro pasaaltos Butterworth de 4° orden con \\(f_c \\approx 0.5\\) Hz (aplicado con filtrado hacia adelante y atrás para lograr fase cero). Se observa que la señal filtrada se centra alrededor de cero voltios, eliminando las variaciones lentas de la línea base, mientras preserva las características importantes del ECG (picos QRS, ondas P y T) (). Este proceso mejora la calidad de la señal para análisis posterior (por ejemplo, facilitando la detección de eventos cardiacos), sin introducir distorsión apreciable en la forma de onda rápida del ECG.\nOtro ejemplo es la eliminación de interferencia de red: un filtro notch diseñado como en secciones previas se puede aplicar a una señal EEG a la que deliberadamente se le suma un seno de 50 Hz; la validación consistiría en ver el espectro antes y después (verificando que la línea de 50 Hz desaparece tras filtrar) y que la actividad EEG en otras bandas permanece intacta.\nEn el diseño de filtros FIR e IIR para voz o bioseñales, a veces se comparan métodos. Por ejemplo, en el taller se pide diseñar tanto un FIR por ventana como un IIR por transformación bilineal para ciertas especificaciones. Comparar la respuesta espectral es instructivo: un FIR puede requerir mayor orden para lograr la misma nitidez de corte que un IIR, pero tendrá fase lineal; el IIR logrará la especificación con menos coeficientes, pero introducirá dispersión de fase. Dependiendo de la aplicación, uno u otro puede ser preferible. Estudios en filtrado de ECG han encontrado, por ejemplo, que filtros IIR y FIR bien diseñados pueden ambos remover el ruido de línea base efectivamente; los IIR (como filtros Butterworth pasaaltos) pueden ser implementados en tiempo real con pocas operaciones (comp.dsp | How to write a NotchFilter procedure| page 2), mientras que FIR largos podrían introducir retardo si no se aplican con técnicas especiales. Sin embargo, los FIR lineales en fase aseguran que características como la amplitud del ST o la morfología de la onda P no se deformen ni se desplacen temporalmente, lo cual es crítico en ciertos análisis diagnósticos.\nEn resumen, la validación espectral (y temporal) de los filtros diseñados garantiza que el filtro funcione como esperado en las señales biomédicas objetivo. Se recomienda siempre verificar ganancia en banda pasante (por ej., asegurarse de que un filtro pasa-bajos no atenúe significativamente componentes importantes de la señal, salvo el ripple permitido) y atenuación en banda eliminada (asegurarse de que el ruido o interferencia objetivo realmente se reduce a niveles aceptables). Con herramientas como Python/Matlab, esta validación se realiza fácilmente visualizando la respuesta en frecuencia (como en las Figuras 1 y 2) y realizando pruebas con señales sintéticas o reales."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#conclusiones",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#conclusiones",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Este reporte abordó los fundamentos teóricos necesarios para analizar y diseñar sistemas discretos aplicados a señales biomédicas. Se revisó la transformada Z y su papel en caracterizar señales y sistemas LTI, destacando la importancia de la región de convergencia, polos, ceros, causalidad y estabilidad (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). También se discutió cómo interpretar y construir diagramas de bloques a partir de ecuaciones en diferencias, algo útil para implementar filtros digitalmente. En la parte de diseño, se cubrieron dos enfoques contrastantes: filtros FIR por método de ventanas, sencillos y con fase lineal (deseable en biomédica), y filtros IIR por transformación bilineal a partir de prototipos analógicos (eficientes en orden, aunque con fase no lineal). Se compararon los principales tipos de aproximaciones analógicas (Butterworth, Chebyshev I/II, Elíptico) resaltando sus ventajas y compromisos (11.3. Common IIR filters — Digital Signals Theory).\nA lo largo del documento, se enfatizó la aplicación en señales reales: eliminar deriva de línea base con pasaaltos, suprimir interferencia de red con filtros notch, limitar el ancho de banda de voz o EEG con pasabajos, etc., todo soportado por referencias académicas y ejemplos de código. En la práctica, el ingeniero biomédico debe decidir el tipo de filtro según los requisitos clínicos: por ejemplo, ¿es más importante no distorsionar la forma de onda (fase lineal) o tener un filtro muy agudo (menor orden)? Este tipo de decisiones se facilita con la comprensión profunda de los conceptos aquí explicados.\nCon este marco teórico, se está en capacidad de abordar el taller propuesto: calcular transformadas Z y ROC de señales, analizar sistemas LTI (impulso, estabilidad, salida a entradas dadas), dibujar sus polos, ceros y estructuras, así como diseñar filtros FIR e IIR que satisfagan especificaciones dadas, especialmente dentro del contexto de procesamiento de señales biomédicas donde la fidelidad y eficacia del filtrado impactan directamente la calidad de la información diagnóstica obtenida.\nReferencias: Las referencias provistas en el texto (ej.【23】,【17】,【40】) corresponden a fuentes que respaldan y complementan los puntos discutidos, incluyendo textos de procesamiento digital de señales, artículos de investigación en filtrado de ECG/EEG, y documentación de funciones de diseño de filtros. Estas fuentes ofrecen mayor detalle para el lector interesado en profundizar en aspectos específicos. En particular, se destacan obras clásicas como Oppenheim & Schafer en diseño FIR (WindowFIRDesign.fm), y recursos modernos como libros abiertos de señales y sistemas (Transformada Z - Wikipedia, la enciclopedia libre) y tutoriales de SciPy (11.3. Common IIR filters — Digital Signals Theory) que enriquecen la comprensión teórica y práctica del procesamiento de señales biomédicas."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "",
    "text": "Nota: Documento en formato Quarto listo para renderizar a HTML (quarto render). Incluye respuestas correctas y una explicación breve por ítem."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-1",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "1 Pregunta 1",
    "text": "1 Pregunta 1\nEnunciado resumido: Sea \\(y(t)=x(3-1{,}5\\,t)\\). Sobre la relación temporal entre \\(x(t)\\) y \\(y(t)\\), marca las correctas.\nRespuestas correctas: A, B, D, E.\nExplicación\nEscribimos \\(y(t)=x(3-1{,}5\\,t)=x\\big(-1{,}5\\,(t-2)\\big)\\).\n- A: Verdadera, es la misma forma \\(x\\big(-1{,}5\\,(t-2)\\big)\\).\n- B: Verdadera, el factor negativo implica inversión temporal (time-reversal).\n- C: Falsa, no es solo desplazamiento; hay inversión y escala temporal.\n- D: Verdadera, al comprimir en el tiempo por \\(|a|=1{,}5\\) la frecuencia aparente se multiplica por 1,5.\n- E: Verdadera, \\(|a|=1{,}5&gt;1\\) implica compresión temporal por 1,5 (la señal “va más rápido”)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-2",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "2 Pregunta 2",
    "text": "2 Pregunta 2\nEnunciado: \\(x(t)=\\cos\\big(2\\pi\\frac{12}{5}t\\big)+\\sin\\big(2\\pi\\frac{7}{3}t\\big)\\). Periodicidad en TC.\nRespuestas correctas: B, D, E.\nExplicación\nLas frecuencias son \\(f_1=12/5\\) y \\(f_2=7/3\\). La razón \\(f_1/f_2=(12/5)/(7/3)=36/35\\) es racional, por tanto la suma es periódica en TC.\nLos periodos individuales: \\(T_1=5/12\\) y \\(T_2=3/7\\). El periodo fundamental conjunto cumple \\(36T_1=35T_2=15\\text{s}\\).\n- A: Falsa, sí comparten múltiplos enteros.\n- B: Verdadera, al cambiar \\(12/5\\) por \\(12/5+1/\\pi\\) la razón de frecuencias típicamente deja de ser racional \\(\\Rightarrow\\) no periódica.\n- C: Falsa, sumar un DC no rompe la periodicidad.\n- D: Verdadera, \\(T_0=15\\text{s}\\) es un periodo fundamental posible.\n- E: Verdadera, todo múltiplo entero de \\(15\\text{s}\\) también es periodo."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-3",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "3 Pregunta 3",
    "text": "3 Pregunta 3\nEnunciado: \\(x[n]=\\sin\\big(\\frac{5\\pi}{14}n\\big)+\\cos\\big(\\frac{3\\pi}{7}n+\\frac{\\pi}{6}\\big)\\). Periodicidad en TD.\nRespuestas correctas: A, D, E.\nExplicación\nPara \\(\\sin(\\Omega n)\\) o \\(\\cos(\\Omega n+\\phi)\\) hay periodicidad si \\(\\Omega/2\\pi\\) es racional.\n- \\(\\Omega_1=5\\pi/14=(5/28)\\,2\\pi\\Rightarrow N_1=28\\).\n- \\(\\Omega_2=3\\pi/7=(3/14)\\,2\\pi\\Rightarrow N_2=14\\).\nEl periodo conjunto es \\(\\mathrm{{lcm}}(28,14)=28\\). La fase no altera la periodicidad.\n- A: Verdadera, \\(N_0=28\\).\n- B: Falsa, cambiar \\(\\pi/6\\) no rompe periodicidad.\n- C: Falsa, \\(\\sin(5\\pi/14\\,n)\\) sigue siendo periódica por sí sola.\n- D: Verdadera, al sumar \\(\\sin(\\pi/3\\,n)\\) (periodo 6), el conjunto sigue siendo periódico con \\(N_0=\\mathrm{{lcm}}(28,6)=84\\).\n- E: Verdadera, el término coseno tiene periodo 14."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-4",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "4 Pregunta 4",
    "text": "4 Pregunta 4\nEnunciado: Sea \\(x(t)=x_p(t)+x_i(t)\\) con \\(x_p\\) par y \\(x_i\\) impar. Defínase\n\\[ y(t)=x_p(t+1)\\,x_i(t-1)+\\frac{d}{dt}x_i(t). \\]\nRespuestas correctas: B, C, D, E.\nExplicación\n- Un desplazamiento rompe la paridad: \\(x_p(t+1)\\) y \\(x_i(t-1)\\) son, en general, ni pares ni impares (\\(\\Rightarrow\\) B verdadera).\n- El producto \\(x_p(t+1)\\,x_i(t-1)\\) no resulta ni par ni impar en general (no es impar) (\\(\\Rightarrow\\) A falsa).\n- Si se cambiara el segundo término por $ frac{d}{dt}x_p(t)$ (derivada de función par), ésta es impar; sumada con un término “ni par ni impar” el total puede seguir siendo “ni par ni impar” (\\(\\Rightarrow\\) C verdadera).\n- La derivada de una función impar es par (\\(\\Rightarrow\\) E verdadera).\n- Suma de un término “ni par ni impar” con un término par da, en general, una función ni par ni impar (\\(\\Rightarrow\\) D verdadera)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-5",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-5",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "5 Pregunta 5",
    "text": "5 Pregunta 5\nEnunciado: Tres pulsos con solapamiento\n- Pulso 1: amplitud \\(2\\), de \\(t=0{,}8\\) a \\(1{,}4\\).\n- Pulso 2: amplitud \\(1{,}5\\), de \\(t=1{,}2\\) a \\(1{,}8\\).\n- Pulso 3: amplitud \\(-1\\), de \\(t=1{,}6\\) a \\(2{,}0\\).\nSea \\(v(t)\\) la suma. Representación con \\(u(t)\\) y propiedades.\nRespuestas correctas: B, C, D, E.\nExplicación\n- Alturas por intervalos:\n- \\(0{,}8-1{,}2\\): \\(2\\)\n- \\(1{,}2-1{,}4\\): \\(2+1{,}5=3{,}5\\) (máximo)\n- \\(1{,}4-1{,}6\\): \\(1{,}5\\)\n- \\(1{,}6-1{,}8\\): \\(1{,}5-1=0{,}5\\)\n- \\(1{,}8-2{,}0\\): \\(-1\\)\nPor tanto A es falsa (el máximo \\(3{,}5\\) ocurre en \\(1{,}2-1{,}4\\)).\n- Forma por escalones:\n\\[ v(t)=2[u(t-0{,}8)-u(t-1{,}4)]+1{,}5[u(t-1{,}2)-u(t-1{,}8)]- [u(t-1{,}6)-u(t-2{,}0)], \\]\nequivalente a la suma de saltos en \\(t_k\\in\\{0{,}8,1{,}2,1{,}4,1{,}6,1{,}8,2{,}0\\}\\) con amplitudes \\(\\{+2,+1{,}5,-2,-1,-1{,}5,+1\\}\\).\nAsí, B, C y D son verdaderas.\n- Área total (linealidad del integral):\n\\[ \\int v(t)\\,dt=2\\cdot0{,}6+1{,}5\\cdot0{,}6-1\\cdot0{,}4=1{,}7, \\]\nindependiente del solapamiento (\\(\\Rightarrow\\) E verdadera)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#resumen-de-respuestas-clave",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#resumen-de-respuestas-clave",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "6 Resumen de respuestas (clave)",
    "text": "6 Resumen de respuestas (clave)\n\nP1: A, B, D, E\n\nP2: B, D, E\n\nP3: A, D, E\n\nP4: B, C, D, E\n\nP5: B, C, D, E"
  },
  {
    "objectID": "recursos/documentos/Teoria_SeñalesEnergiaPotencia.html",
    "href": "recursos/documentos/Teoria_SeñalesEnergiaPotencia.html",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "¿Por qué distinguir entre señales de energía y señales de potencia en procesamiento de señales?\n\nEl conjunto matemático adecuado.Las señales de energía pertenecen a \\(L^{2}\\) con norma finita \\(\\lVert x\\rVert_{2}=\\sqrt{E}\\), lo que habilita resultados como Parseval/Plancherel (p. ej., \\(\\int_{-\\infty}^{\\infty}\\lvert x(t)\\rvert^{2},dt=\\tfrac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert X(\\omega)\\rvert^{2},d\\omega\\)). Las señales de potencia suelen requerir promedios temporales y estadísticas de segundo orden en lugar de normas finitas.\nEl análisis espectral difiere. En señales de energía, el objeto natural es la transformada de Fourier \\(X(\\omega)\\) y la energía se concentra en \\(\\lvert X(\\omega)\\rvert^{2}\\). En señales de potencia (p. ej., periódicas o estacionarias), el objeto clave es la densidad espectral de potencia (PSD) \\(S_{X}(\\omega)\\), obtenida a partir de la autocorrelación \\(R_{X}(\\tau)\\) vía Wiener–Khinchin: \\(S_{X}(\\omega)=\\mathcal{F}{R_{X}(\\tau)}\\).\nLas métricas de desempeño dependen de la clase. La relación señal-ruido se formula como SNR de energía \\(\\mathrm{SNR}=E_{s}/E_{n}\\) para pulsos/transitorios y como SNR de potencia \\(\\mathrm{SNR}=P_{s}/P_{n}\\) para procesos de larga duración o estacionarios. Usar la métrica incorrecta sesga el diseño de detectores/estimadores.\nDiseño y evaluación de filtros. Para señales de energía, la detección óptima usa filtros casados que maximizan la energía de salida. Para señales de potencia/estacionarias, se modela el ruido mediante la PSD (p. ej., filtrado de Wiener) y se evalúa la potencia o varianza de salida.\nMuestreo, ventanas y práctica con DFT/FFT. Señales de energía: se integra la energía en el intervalo observado e interprete \\(\\lvert X[k]\\rvert^{2}\\) como distribución de energía por bins de la DFT. Señales de potencia: se estima la PSD con periodogramas/Welch; \\(S_{X}(\\omega)\\) tiene unidades de potencia por Hz y se promedia entre ventanas para reducir varianza.\nModelado de bioseñales reales. Muchos estallidos/transitorios biomédicos (ráfagas de EMG, potenciales evocados) se comportan como señales de energía; componentes cuasi-periódicos o estacionarios de larga duración (fundamental del ECG en reposo, respiración en minutos) se comportan como señales de potencia. Modelarlas correctamente guía la extracción de rasgos (envolventes basadas en energía vs. bandas de PSD).\nArgumentos de convergencia y estabilidad. Demostraciones de convergencia para estimadores y cotas de estabilidad para sistemas suelen asumir energía finita o potencia promedio finita; clasificar mal invalida esas garantías.\nUnidades e interpretación. Los espectros de energía se relacionan con \\(\\lvert X(\\omega)\\rvert^{2}\\) (su integral total da \\(E\\)). La PSD integra a potencia promedio: \\(\\tfrac{1}{2\\pi}\\int_{-\\infty}^{\\infty}S_{X}(\\omega),d\\omega=P\\).\nRegla rápida. Si la señal se extingue o es estrictamente acotada en tiempo y \\(\\int\\lvert x\\rvert^{2}\\) es finita, trátela como energía; si persiste indefinidamente con promedio bien definido, trátela como potencia y use \\(R_{X}(\\tau)\\)/\\(S_{X}(\\omega)\\)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html",
    "href": "recursos/documentos/SYSB/cuantizacion.html",
    "title": "Quantization",
    "section": "",
    "text": "Quantization maps a continuous-amplitude signal to a finite set of discrete levels so that it can be represented by digits. After anti-alias filtering and sampling, an analog-to-digital converter (ADC) applies quantization. This process introduces an error that acts like noise under standard conditions; understanding its magnitude is essential to sizing bit depth, gain, and dynamic range in biomedical systems (ECG, EEG, EMG, PPG).\n\n\n\nLet the ADC input range be \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\) with \\(b\\) bits and \\(L=2^b\\) levels. The step size (LSB) is\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nTwo common realizations:\n\nMid-tread (rounding): \\(Q(x)=\\Delta,\\mathrm{round}\\left(\\frac{x}{\\Delta}\\right)\\) for \\(x\\in(V\\_{\\min},V\\_{\\max})\\).\nMid-rise (truncate with half-step offset): \\(Q(x)=\\Delta!\\left(\\left\\lfloor\\frac{x}{\\Delta}\\right\\rfloor+\\tfrac12\\right)\\).\n\nOutside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\), overload/clipping occurs: \\(\\tilde{x}=Q(x)=V\\_{\\max}\\) if \\(x&gt;V\\_{\\max}\\) and \\(\\tilde{x}=V\\_{\\min}\\) if \\(x\\&lt;V\\_{\\min}\\).\nCodebook and decision thresholds: Decision thresholds lie at \\(k\\Delta\\) and reconstruction levels at either \\(k\\Delta\\) (mid-tread) or \\((k+\\tfrac12)\\Delta\\) (mid-rise).\n\n\n\nDefine the quantization error \\(e=x-Q(x)\\). Under the high-resolution assumptions (signal varies slowly relative to \\(\\Delta\\), input well distributed within the range, and no overload), the error is modeled as white, signal-independent, and uniformly distributed on \\(\\left[-\\frac{\\Delta}{2},\\frac{\\Delta}{2}\\right]\\):\n\nMean: \\(\\mathbb{E}\\left[e\\right]=0\\).\nVariance (power): \\(\\sigma\\_e^2=\\dfrac{\\Delta^2}{12}\\).\nRMS: \\(\\sigma\\_e=\\dfrac{\\Delta}{\\sqrt{12}}\\).\n\nFor a full-scale sinusoid, the theoretical SNR is\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nIf the signal uses only a fraction \\(\\rho\\) (\\(0&lt;\\rho\\le 1\\)) of full scale (FS) in RMS, then\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]\nEffective Number of Bits (ENOB) from a measured in-band SNR:\n\\[\n\\mathrm{ENOB} \\approx \\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]\n\n\n\nFront-end analog gain \\(G\\) maps a biomedical signal \\(x\\_{\\text{in}}\\) to the ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\). The input-referred LSB is\n\\[\n\\Delta_{\\text{in}}=\\frac{\\Delta}{G}.\n\\]\nChoose \\(G\\) to:\n\navoid overload for rare peaks, and 2) maximize FS utilization to improve SNR. Poor gain wastes bits (small \\(\\rho\\)) or clips clinically relevant transients (e.g., ECG pacer spikes).\n\n\n\n\nSuppose a resting ECG has peak amplitudes around \\(\\pm 5,\\text{mV}\\) at the electrodes. We design the analog front end so that \\(\\pm 5,\\text{mV}\\) maps to \\(\\pm 1,\\text{V}\\) at the ADC, i.e., \\(G=200\\). Use a \\(b=12\\)-bit ADC over \\(\\left[-1,\\text{V},,1,\\text{V}\\right]\\):\n\nADC LSB: \\(\\Delta = \\dfrac{2,\\text{V}}{2^{12}} \\approx 0.488,\\text{mV}\\) (at the ADC input).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\dfrac{0.488,\\text{mV}}{200}\\approx 2.44,\\mu\\text{V}\\).\nInput-referred quantization-noise RMS: \\(\\dfrac{\\Delta\\_{\\text{in}}}{\\sqrt{12}}\\approx 0.704,\\mu\\text{V}\\_{\\mathrm{RMS}}\\).\n\nIf the ECG uses \\(\\rho=0.5\\) of full scale (typical margin against clipping), the quantization-limited SNR is approximately\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\times 12 + 1.76 + 20\\log_{10}(0.5) \\approx 74.0 - 6.0 \\approx 68\\,\\text{dB}.\n\\]\nThis is usually below amplifier and electrode noise constraints, so 12 bits are adequate for diagnostic ECG in this setting. If the chain is quieter (e.g., invasive potentials), higher bit depth or larger \\(G\\) may be justified.\n\n\n\nWhen the amplitude distribution is strongly non-uniform, companding transforms \\(x\\) before uniform quantization to allocate more levels where the signal spends more time. Classical laws:\n\n\\(\\mu\\)-law: \\(y=\\mathrm{sgn}(x),\\dfrac{\\ln(1+\\mu |x|/X\\_{\\max})}{\\ln(1+\\mu)}\\), \\(\\mu\\approx 255\\) (telephony).\n\\(A\\)-law: piecewise logarithmic with parameter \\(A\\) (Europe).\n\nCompanding is common in speech/audio telemetry; in biomedicine it is less standard for primary acquisition, but can help in low-bit-rate wireless monitoring where dynamic range is wide (e.g., PPG with motion).\n\n\n\nAdding small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization decorrelates the error from the signal, eliminating patterning and bias at low amplitudes. This linearizes averages at the cost of a small SNR penalty. Dither can be beneficial for low-level EEG/EMG features and precise baseline estimates.\n\n\n\n\nChoose \\(b\\) so that \\(\\mathrm{SNR}\\_{\\mathrm{dB}}\\) exceeds clinical SNR needs by margin (10–20 dB).\nSet \\(G\\) so typical peaks use \\(50\\)–\\(80%\\) FS; verify pacer spikes and motion spikes do not clip.\nBudget noise: electrode + amplifier + ADC quantization; the largest non-white source often dominates.\nValidate with a calibrated source (sinusoidal and biomedical-like waveforms) and measure in-band SNR/ENOB.\n\n\n\n\n\n\n# Synthetic ECG, uniform quantization at multiple bit depths, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# --- 1) Build a simple ECG template (P-QRS-T) using Gaussians ---\nfs = 360.0                      # sampling rate [Hz]\nT = 5.0                         # duration [s]\nt = np.arange(0, T, 1/fs)\n\nhr = 60.0                       # heart rate [bpm]\nRR = 60.0/hr                    # seconds per beat\n\n# Gaussian helper\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\n# One-beat template (times in seconds relative to beat onset)\ndef ecg_template(t):\n    # amplitudes in mV, widths in s (very simplified)\n    P  = g(t, 0.20, 0.045,  0.10)\n    Q  = g(t, 0.36, 0.010, -0.25)\n    R  = g(t, 0.40, 0.012,  1.00)\n    S  = g(t, 0.44, 0.016, -0.35)\n    T  = g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + T\n\n# Tile the template every RR seconds\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    tau = t - k*RR\n    ecg_mV += ecg_template(tau)\n\n# Optional baseline wander + small EMG-like noise (for realism)\nwander = 0.05*np.sin(2*np.pi*0.3*t)        # 0.05 mV @ 0.3 Hz\nnoise  = 0.02*np.random.randn(len(t))      # 0.02 mV RMS\necg_mV = ecg_mV + wander + noise\n\n# --- 2) Analog front-end gain and ADC setup ---\nG = 200.0                     # gain: mV (input) -&gt; V (ADC input)\nVfs = 1.0                     # full-scale = +/-1 V\nVmin, Vmax = -Vfs, Vfs\n\nx_adc = (ecg_mV/1000.0)*G     # convert mV to V and apply gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    # Saturate to avoid numeric overflow\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)  # ensure within codebook range\n    return y, Delta\n\ndef snr_db(x, y):\n    # SNR over the un-clipped region; compute RMS of signal and error\n    e = x - y\n    # Remove DC for SNR assessment\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\n# --- 3) Quantize at different bit depths ---\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\n# Print a small summary (ADC-domain). Input-referred values via division by G.\nprint(\"Summary (ADC domain):\")\nfor b in bits_list:\n    Delta = results[b][\"Delta\"]\n    snr = results[b][\"snr_db\"]\n    print(f\"{b:2d}-bit -&gt; LSB Δ = {Delta*1e3:.3f} mV, Theoretical/Measured SNR ≈ {snr:5.1f} dB\")\n\n# Input-referred LSB and noise RMS for the 12-bit case\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Δ_in = {Delta_in*1e6:.3f} µV, σ_q ≈ {sigma_q_in*1e6:.3f} µV RMS\")\n\n# --- 4) Plot: original vs quantized (choose 10-bit for visibility) ---\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)  # show about one beat\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- 5) Plot: quantization error histogram (8-bit to exaggerate steps) ---\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()\n\nSummary (ADC domain):\n 8-bit -&gt; LSB Δ = 7.812 mV, Theoretical/Measured SNR ≈  24.1 dB\n10-bit -&gt; LSB Δ = 1.953 mV, Theoretical/Measured SNR ≈  36.0 dB\n12-bit -&gt; LSB Δ = 0.488 mV, Theoretical/Measured SNR ≈  48.1 dB\n\nInput-referred (12-bit): Δ_in = 2.441 µV, σ_q ≈ 0.705 µV RMS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nThe summary reports the measured SNR from the synthetic ECG after quantization for 8/10/12 bits; values will be below the \\(6.02b+1.76\\) bound because the signal does not use full scale constantly and includes non-sinusoidal content.\nThe input-referred \\(\\Delta\\_{\\text{in}}\\) and \\(\\sigma\\_q\\) for 12 bits match the analytical estimates in Section 5 (a few \\(\\mu\\text{V}\\)), consistent with common ECG design targets.\nThe error histogram approaches a uniform distribution as assumptions hold; deviations indicate correlation (e.g., at low amplitudes or with deterministic waveforms)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#purpose-and-big-picture",
    "href": "recursos/documentos/SYSB/cuantizacion.html#purpose-and-big-picture",
    "title": "Quantization",
    "section": "",
    "text": "Quantization maps a continuous-amplitude signal to a finite set of discrete levels so that it can be represented by digits. After anti-alias filtering and sampling, an analog-to-digital converter (ADC) applies quantization. This process introduces an error that acts like noise under standard conditions; understanding its magnitude is essential to sizing bit depth, gain, and dynamic range in biomedical systems (ECG, EEG, EMG, PPG)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#uniform-quantizer-model",
    "href": "recursos/documentos/SYSB/cuantizacion.html#uniform-quantizer-model",
    "title": "Quantization",
    "section": "",
    "text": "Let the ADC input range be \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\) with \\(b\\) bits and \\(L=2^b\\) levels. The step size (LSB) is\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nTwo common realizations:\n\nMid-tread (rounding): \\(Q(x)=\\Delta,\\mathrm{round}\\left(\\frac{x}{\\Delta}\\right)\\) for \\(x\\in(V\\_{\\min},V\\_{\\max})\\).\nMid-rise (truncate with half-step offset): \\(Q(x)=\\Delta!\\left(\\left\\lfloor\\frac{x}{\\Delta}\\right\\rfloor+\\tfrac12\\right)\\).\n\nOutside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\), overload/clipping occurs: \\(\\tilde{x}=Q(x)=V\\_{\\max}\\) if \\(x&gt;V\\_{\\max}\\) and \\(\\tilde{x}=V\\_{\\min}\\) if \\(x\\&lt;V\\_{\\min}\\).\nCodebook and decision thresholds: Decision thresholds lie at \\(k\\Delta\\) and reconstruction levels at either \\(k\\Delta\\) (mid-tread) or \\((k+\\tfrac12)\\Delta\\) (mid-rise)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#quantization-error-and-its-statistics",
    "href": "recursos/documentos/SYSB/cuantizacion.html#quantization-error-and-its-statistics",
    "title": "Quantization",
    "section": "",
    "text": "Define the quantization error \\(e=x-Q(x)\\). Under the high-resolution assumptions (signal varies slowly relative to \\(\\Delta\\), input well distributed within the range, and no overload), the error is modeled as white, signal-independent, and uniformly distributed on \\(\\left[-\\frac{\\Delta}{2},\\frac{\\Delta}{2}\\right]\\):\n\nMean: \\(\\mathbb{E}\\left[e\\right]=0\\).\nVariance (power): \\(\\sigma\\_e^2=\\dfrac{\\Delta^2}{12}\\).\nRMS: \\(\\sigma\\_e=\\dfrac{\\Delta}{\\sqrt{12}}\\).\n\nFor a full-scale sinusoid, the theoretical SNR is\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nIf the signal uses only a fraction \\(\\rho\\) (\\(0&lt;\\rho\\le 1\\)) of full scale (FS) in RMS, then\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]\nEffective Number of Bits (ENOB) from a measured in-band SNR:\n\\[\n\\mathrm{ENOB} \\approx \\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]"
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#input-range-gain-and-clipping",
    "href": "recursos/documentos/SYSB/cuantizacion.html#input-range-gain-and-clipping",
    "title": "Quantization",
    "section": "",
    "text": "Front-end analog gain \\(G\\) maps a biomedical signal \\(x\\_{\\text{in}}\\) to the ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\). The input-referred LSB is\n\\[\n\\Delta_{\\text{in}}=\\frac{\\Delta}{G}.\n\\]\nChoose \\(G\\) to:\n\navoid overload for rare peaks, and 2) maximize FS utilization to improve SNR. Poor gain wastes bits (small \\(\\rho\\)) or clips clinically relevant transients (e.g., ECG pacer spikes)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#biomedical-example-ecg-acquisition",
    "href": "recursos/documentos/SYSB/cuantizacion.html#biomedical-example-ecg-acquisition",
    "title": "Quantization",
    "section": "",
    "text": "Suppose a resting ECG has peak amplitudes around \\(\\pm 5,\\text{mV}\\) at the electrodes. We design the analog front end so that \\(\\pm 5,\\text{mV}\\) maps to \\(\\pm 1,\\text{V}\\) at the ADC, i.e., \\(G=200\\). Use a \\(b=12\\)-bit ADC over \\(\\left[-1,\\text{V},,1,\\text{V}\\right]\\):\n\nADC LSB: \\(\\Delta = \\dfrac{2,\\text{V}}{2^{12}} \\approx 0.488,\\text{mV}\\) (at the ADC input).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\dfrac{0.488,\\text{mV}}{200}\\approx 2.44,\\mu\\text{V}\\).\nInput-referred quantization-noise RMS: \\(\\dfrac{\\Delta\\_{\\text{in}}}{\\sqrt{12}}\\approx 0.704,\\mu\\text{V}\\_{\\mathrm{RMS}}\\).\n\nIf the ECG uses \\(\\rho=0.5\\) of full scale (typical margin against clipping), the quantization-limited SNR is approximately\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\times 12 + 1.76 + 20\\log_{10}(0.5) \\approx 74.0 - 6.0 \\approx 68\\,\\text{dB}.\n\\]\nThis is usually below amplifier and electrode noise constraints, so 12 bits are adequate for diagnostic ECG in this setting. If the chain is quieter (e.g., invasive potentials), higher bit depth or larger \\(G\\) may be justified."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#non-uniform-quantization-and-companding-brief",
    "href": "recursos/documentos/SYSB/cuantizacion.html#non-uniform-quantization-and-companding-brief",
    "title": "Quantization",
    "section": "",
    "text": "When the amplitude distribution is strongly non-uniform, companding transforms \\(x\\) before uniform quantization to allocate more levels where the signal spends more time. Classical laws:\n\n\\(\\mu\\)-law: \\(y=\\mathrm{sgn}(x),\\dfrac{\\ln(1+\\mu |x|/X\\_{\\max})}{\\ln(1+\\mu)}\\), \\(\\mu\\approx 255\\) (telephony).\n\\(A\\)-law: piecewise logarithmic with parameter \\(A\\) (Europe).\n\nCompanding is common in speech/audio telemetry; in biomedicine it is less standard for primary acquisition, but can help in low-bit-rate wireless monitoring where dynamic range is wide (e.g., PPG with motion)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#dither-optional-but-practical",
    "href": "recursos/documentos/SYSB/cuantizacion.html#dither-optional-but-practical",
    "title": "Quantization",
    "section": "",
    "text": "Adding small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization decorrelates the error from the signal, eliminating patterning and bias at low amplitudes. This linearizes averages at the cost of a small SNR penalty. Dither can be beneficial for low-level EEG/EMG features and precise baseline estimates."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#practical-checklist",
    "href": "recursos/documentos/SYSB/cuantizacion.html#practical-checklist",
    "title": "Quantization",
    "section": "",
    "text": "Choose \\(b\\) so that \\(\\mathrm{SNR}\\_{\\mathrm{dB}}\\) exceeds clinical SNR needs by margin (10–20 dB).\nSet \\(G\\) so typical peaks use \\(50\\)–\\(80%\\) FS; verify pacer spikes and motion spikes do not clip.\nBudget noise: electrode + amplifier + ADC quantization; the largest non-white source often dominates.\nValidate with a calibrated source (sinusoidal and biomedical-like waveforms) and measure in-band SNR/ENOB."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#python-demonstration-ecg-quantization-snr-and-error-statistics",
    "href": "recursos/documentos/SYSB/cuantizacion.html#python-demonstration-ecg-quantization-snr-and-error-statistics",
    "title": "Quantization",
    "section": "",
    "text": "# Synthetic ECG, uniform quantization at multiple bit depths, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# --- 1) Build a simple ECG template (P-QRS-T) using Gaussians ---\nfs = 360.0                      # sampling rate [Hz]\nT = 5.0                         # duration [s]\nt = np.arange(0, T, 1/fs)\n\nhr = 60.0                       # heart rate [bpm]\nRR = 60.0/hr                    # seconds per beat\n\n# Gaussian helper\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\n# One-beat template (times in seconds relative to beat onset)\ndef ecg_template(t):\n    # amplitudes in mV, widths in s (very simplified)\n    P  = g(t, 0.20, 0.045,  0.10)\n    Q  = g(t, 0.36, 0.010, -0.25)\n    R  = g(t, 0.40, 0.012,  1.00)\n    S  = g(t, 0.44, 0.016, -0.35)\n    T  = g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + T\n\n# Tile the template every RR seconds\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    tau = t - k*RR\n    ecg_mV += ecg_template(tau)\n\n# Optional baseline wander + small EMG-like noise (for realism)\nwander = 0.05*np.sin(2*np.pi*0.3*t)        # 0.05 mV @ 0.3 Hz\nnoise  = 0.02*np.random.randn(len(t))      # 0.02 mV RMS\necg_mV = ecg_mV + wander + noise\n\n# --- 2) Analog front-end gain and ADC setup ---\nG = 200.0                     # gain: mV (input) -&gt; V (ADC input)\nVfs = 1.0                     # full-scale = +/-1 V\nVmin, Vmax = -Vfs, Vfs\n\nx_adc = (ecg_mV/1000.0)*G     # convert mV to V and apply gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    # Saturate to avoid numeric overflow\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)  # ensure within codebook range\n    return y, Delta\n\ndef snr_db(x, y):\n    # SNR over the un-clipped region; compute RMS of signal and error\n    e = x - y\n    # Remove DC for SNR assessment\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\n# --- 3) Quantize at different bit depths ---\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\n# Print a small summary (ADC-domain). Input-referred values via division by G.\nprint(\"Summary (ADC domain):\")\nfor b in bits_list:\n    Delta = results[b][\"Delta\"]\n    snr = results[b][\"snr_db\"]\n    print(f\"{b:2d}-bit -&gt; LSB Δ = {Delta*1e3:.3f} mV, Theoretical/Measured SNR ≈ {snr:5.1f} dB\")\n\n# Input-referred LSB and noise RMS for the 12-bit case\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Δ_in = {Delta_in*1e6:.3f} µV, σ_q ≈ {sigma_q_in*1e6:.3f} µV RMS\")\n\n# --- 4) Plot: original vs quantized (choose 10-bit for visibility) ---\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)  # show about one beat\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- 5) Plot: quantization error histogram (8-bit to exaggerate steps) ---\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()\n\nSummary (ADC domain):\n 8-bit -&gt; LSB Δ = 7.812 mV, Theoretical/Measured SNR ≈  24.1 dB\n10-bit -&gt; LSB Δ = 1.953 mV, Theoretical/Measured SNR ≈  36.0 dB\n12-bit -&gt; LSB Δ = 0.488 mV, Theoretical/Measured SNR ≈  48.1 dB\n\nInput-referred (12-bit): Δ_in = 2.441 µV, σ_q ≈ 0.705 µV RMS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nThe summary reports the measured SNR from the synthetic ECG after quantization for 8/10/12 bits; values will be below the \\(6.02b+1.76\\) bound because the signal does not use full scale constantly and includes non-sinusoidal content.\nThe input-referred \\(\\Delta\\_{\\text{in}}\\) and \\(\\sigma\\_q\\) for 12 bits match the analytical estimates in Section 5 (a few \\(\\mu\\text{V}\\)), consistent with common ECG design targets.\nThe error histogram approaches a uniform distribution as assumptions hold; deviations indicate correlation (e.g., at low amplitudes or with deterministic waveforms)."
  },
  {
    "objectID": "recursos/documentos/ASIM/ResumenCNN.html",
    "href": "recursos/documentos/ASIM/ResumenCNN.html",
    "title": "Redes Neuronales Convolucionales",
    "section": "",
    "text": "El reporte técnico inicia trazando la evolución histórica de las Redes Neuronales Convolucionales, desde su inspiración biológica en la corteza visual (Hubel y Wiesel) y los modelos precursores (Neocognitron, LeNet-5), hasta su resurgimiento moderno con AlexNet, posibilitado por las GPUs y los grandes volúmenes de datos. Inmediatamente, se justifica la adopción de esta arquitectura en el ámbito biomédico al superar la principal limitación de los métodos tradicionales: la necesidad de una extracción manual de características, un proceso subjetivo que las CNN automatizan. A nivel funcional, la arquitectura se descompone en sus bloques esenciales: capas convolucionales que aprenden jerarquías de filtros, activaciones ReLU que introducen no linealidad, y capas de agrupación (pooling) que otorgan invarianza y reducen la dimensionalidad, culminando en un clasificador (MLP) que toma la decisión final. El proceso de entrenamiento de estos filtros se detalla como una optimización donde una función de pérdida (ej. entropía cruzada) se minimiza mediante retropropagación para calcular gradientes, y un optimizador (como SGD) actualiza los pesos, destacando la transferencia de aprendizaje como la técnica pragmática dominante en el sector. Finalmente, se consolidan estos conceptos mostrando sus aplicaciones prácticas en ingeniería biomédica, que abarcan desde la clasificación de patologías y la segmentación semántica de tumores hasta la detección de lesiones específicas en imágenes diagnósticas.\n# 1. Introducción\nEl análisis de imágenes biomédicas depende fundamentalmente de la capacidad de un modelo para comprender la información espacial y jerárquica. Las Redes Neuronales Convolucionales (CNN) representan la solución de vanguardia para esta tarea, pero su arquitectura es el resultado de varias décadas de investigación en neurociencia computacional y aprendizaje automático.\nLos fundamentos conceptuales se remontan a los experimentos de Hubel y Wiesel en la década de 1960, quienes descubrieron que las neuronas en la corteza visual primaria de los mamíferos responden a patrones locales, simples y orientados (como los bordes) [1]. Estas neuronas se organizan de forma jerárquica para detectar características progresivamente más complejas.\nInspirado por este modelo biológico, Kunihiko Fukushima desarrolló el “Neocognitron” en 1980 [2]. Este fue un precursor directo de las CNN modernas, introduciendo una arquitectura jerárquica con capas que alternaban la extracción de características (similares a la convolución) y la reducción de dimensionalidad (similar al pooling), demostrando invarianza a la traslación.\nSin embargo, fue el trabajo de Yann LeCun y sus colaboradores a finales de los 80 y 90 el que formalizó la CNN moderna, notablemente con la arquitectura LeNet-5 [3]. Al integrar la convolución con el algoritmo de retropropagación (backpropagation) para entrenar los filtros automáticamente a partir de los datos, LeNet-5 estableció el estándar para el reconocimiento de caracteres.\nA pesar de este éxito temprano, las CNN fueron superadas por otros métodos (como las SVM) durante casi una década, debido principalmente a las limitaciones computacionales (falta de GPUs potentes) y a la escasez de grandes conjuntos de datos etiquetados.\nLa era moderna de las CNN fue catalizada en 2012 por Krizhevsky, Sutskever y Hinton con “AlexNet” [4]. Al utilizar GPUs para el entrenamiento y un conjunto de datos masivo (ImageNet), AlexNet demostró una reducción drástica del error en la clasificación de imágenes, superando a todos los métodos anteriores e iniciando la revolución actual del aprendizaje profundo.\nEste reporte presenta una revisión técnica de los fundamentos de la arquitectura CNN contemporánea. El objetivo es proporcionar al estudiante de ingeniería biomédica una comprensión clara de sus componentes (convolución, agrupación) y su relevancia en el procesamiento de señales e imágenes biomédicas."
  },
  {
    "objectID": "recursos/documentos/ASIM/ResumenCNN.html#capa-convolucional-convolutional-layer",
    "href": "recursos/documentos/ASIM/ResumenCNN.html#capa-convolucional-convolutional-layer",
    "title": "Redes Neuronales Convolucionales",
    "section": "3.1. Capa Convolucional (Convolutional Layer)",
    "text": "3.1. Capa Convolucional (Convolutional Layer)\nA continuación, se presenta un diagrama de una arquitectura CNN típica, que consta de dos bloques de extracción de características (Convolución, Activación y Agrupación) y un bloque clasificador (MLP).\n\n\n\n\n\nLa capa convolucional es el componente central de la CNN. Utiliza un conjunto de filtros (o kernels) aprendibles para detectar características locales (bordes, texturas, formas) en la imagen de entrada.\nUn filtro \\(K\\) de tamaño \\(m \\times n\\) se desliza sobre la imagen de entrada \\(I\\). En cada posición, se calcula el producto punto entre el filtro y la región de la imagen que cubre. Esta operación, la convolución discreta 2D, genera un “mapa de características” (feature map) \\(O\\):\n\\[\nO(i, j) = (I * K)(i, j) = \\sum_{m} \\sum_{n} I(i-m, j-n) K(m, n)\n\\]\nParámetros clave de esta capa son:\n\nProfundidad (Depth): El número de filtros en la capa. Cada filtro aprende a detectar una característica diferente.\nPaso (Stride): El número de píxeles que el filtro se desplaza en cada paso. Un stride mayor reduce la dimensionalidad del mapa de características.\nRelleno (Padding): La adición de píxeles (usualmente ceros) al borde de la imagen. El padding (ej. “same”) permite controlar el tamaño espacial de salida y asegurar que los bordes de la imagen sean procesados adecuadamente."
  },
  {
    "objectID": "recursos/documentos/ASIM/ResumenCNN.html#función-de-activación-no-lineal",
    "href": "recursos/documentos/ASIM/ResumenCNN.html#función-de-activación-no-lineal",
    "title": "Redes Neuronales Convolucionales",
    "section": "3.2. Función de Activación No Lineal",
    "text": "3.2. Función de Activación No Lineal\nCada elemento del mapa de características es procesado por una función de activación no lineal. [cite_start]La más utilizada en CNNs es la Unidad Lineal Rectificada (ReLU)[cite: 26], definida como:\n\\[\n\\text{ReLU}(x) = \\max(0, x)\n\\]\nReLU introduce no linealidad en el modelo, permitiéndole aprender relaciones complejas. Es computacionalmente eficiente y ayuda a mitigar el problema del desvanecimiento del gradiente (vanishing gradient) durante el entrenamiento."
  },
  {
    "objectID": "recursos/documentos/ASIM/ResumenCNN.html#capa-de-agrupación-pooling-layer",
    "href": "recursos/documentos/ASIM/ResumenCNN.html#capa-de-agrupación-pooling-layer",
    "title": "Redes Neuronales Convolucionales",
    "section": "3.3. Capa de Agrupación (Pooling Layer)",
    "text": "3.3. Capa de Agrupación (Pooling Layer)\nLa capa de agrupación (o submuestreo) reduce la dimensionalidad espacial de los mapas de características. Esto reduce la carga computacional y el número de parámetros, ayudando a controlar el sobreajuste (overfitting).\nLa operación más común es Max Pooling. Se define una ventana (ej. \\(2 \\times 2\\)) y se toma el valor máximo de la región del mapa de características cubierta por esa ventana."
  },
  {
    "objectID": "recursos/documentos/ASIM/ResumenCNN.html#capa-totalmente-conectada-fully-connected-layer",
    "href": "recursos/documentos/ASIM/ResumenCNN.html#capa-totalmente-conectada-fully-connected-layer",
    "title": "Redes Neuronales Convolucionales",
    "section": "3.4. Capa Totalmente Conectada (Fully Connected Layer)",
    "text": "3.4. Capa Totalmente Conectada (Fully Connected Layer)\nDespués de varias capas convolucionales y de agrupación, los mapas de características resultantes son “aplanados” (flattening) en un vector unidimensional. Este vector alimenta una o más capas totalmente conectadas (densas), que son perceptrones multicapa estándar.\nEstas capas realizan la clasificación final basándose en las características de alto nivel extraídas por las capas anteriores. La última capa suele emplear una función de activación Softmax para problemas de clasificación multiclase, generando una distribución de probabilidad sobre las clases de salida."
  },
  {
    "objectID": "recursos/documentos/ASIM/ResumenCNN.html#la-función-de-pérdida-loss-function",
    "href": "recursos/documentos/ASIM/ResumenCNN.html#la-función-de-pérdida-loss-function",
    "title": "Redes Neuronales Convolucionales",
    "section": "4.1. La Función de Pérdida (Loss Function)",
    "text": "4.1. La Función de Pérdida (Loss Function)\nEl primer paso es definir una métrica cuantitativa del error. La función de pérdida, \\(J(\\beta)\\), mide la discrepancia entre la salida predicha por la red (\\(\\hat{y}\\)) y la etiqueta real (\\(y\\)). El vector \\(\\beta\\) representa todos los parámetros aprendibles del modelo (pesos y sesgos de todas las capas).\nPara problemas de clasificación, la función de pérdida más utilizada es la Entropía Cruzada Categórica (Categorical Cross-Entropy). Mide la “distancia” entre la distribución de probabilidad predicha (salida de la capa Softmax) y la distribución real (la etiqueta one-hot).\nPara un solo ejemplo de entrenamiento, la pérdida es:\n\\[\nJ_i(\\beta) = - \\sum_{c=1}^{M} y_{i,c} \\log(\\hat{y}_{i,c})\n\\]\nDonde:\n* \\(M\\) es el número total de clases (ej. “Normal”, “Neumonía”, “COVID-19”).\n* \\(y_{i,c}\\) es 1 si la muestra \\(i\\) pertenece a la clase \\(c\\), y 0 en caso contrario.\n* \\(\\hat{y}_{i,c}\\) es la probabilidad predicha por la red (salida Softmax) de que la muestra \\(i\\) pertenezca a la clase \\(c\\).\nEl objetivo del entrenamiento es encontrar el conjunto de parámetros \\(\\beta^*\\) que minimiza la pérdida promedio sobre todo el conjunto de entrenamiento \\(N\\):\n\\[\n\\beta^* = \\arg \\min_{\\beta} \\frac{1}{N} \\sum_{i=1}^{N} J_i(\\beta)\n\\]"
  },
  {
    "objectID": "recursos/documentos/ASIM/ResumenCNN.html#retropropagación-y-descenso-de-gradiente",
    "href": "recursos/documentos/ASIM/ResumenCNN.html#retropropagación-y-descenso-de-gradiente",
    "title": "Redes Neuronales Convolucionales",
    "section": "4.2. Retropropagación y Descenso de Gradiente",
    "text": "4.2. Retropropagación y Descenso de Gradiente\nPara minimizar \\(J(\\beta)\\), se utiliza un algoritmo de optimización basado en el gradiente. El más fundamental es el Descenso de Gradiente. La idea es calcular cómo un pequeño cambio en cada parámetro \\(\\beta_j\\) (cada peso individual en cada filtro) afecta la pérdida total \\(J\\). Esta “sensibilidad” es el gradiente (derivada parcial) de la pérdida con respecto a ese parámetro: \\(\\frac{\\partial J}{\\partial \\beta_j}\\).\nEl algoritmo de Retropropagación (Backpropagation) es el método eficiente para calcular este gradiente. Utiliza la regla de la cadena del cálculo para propagar el error desde la capa de salida hacia atrás, capa por capa, calculando el gradiente de la pérdida con respecto a los parámetros de cada capa.\nUna vez que se tiene el gradiente \\(\\nabla J(\\beta)\\) (el vector de todas las derivadas parciales), se actualizan los parámetros en la dirección opuesta al gradiente (la dirección de máximo descenso del error). La regla de actualización es:\n\\[\n\\beta_{\\text{nuevo}} = \\beta_{\\text{viejo}} - \\eta \\cdot \\nabla J(\\beta)\n\\]\n\n\\(\\eta\\) (letra griega “eta”) es la tasa de aprendizaje (learning rate), un hiperparámetro crucial que controla el tamaño del paso en cada actualización.\n\nEn la práctica, calcular el gradiente sobre todo el conjunto de datos \\(N\\) es computacionalmente prohibitivo. En su lugar, se utiliza el Descenso de Gradiente Estocástico (SGD) o, más comúnmente, el SGD por Mini-Lotes (Mini-Batch SGD). En este enfoque, el gradiente se estima usando un pequeño subconjunto (un “lote”) de datos en cada iteración."
  },
  {
    "objectID": "recursos/documentos/ASIM/ResumenCNN.html#el-entrenamiento-específico-de-los-filtros-kernels",
    "href": "recursos/documentos/ASIM/ResumenCNN.html#el-entrenamiento-específico-de-los-filtros-kernels",
    "title": "Redes Neuronales Convolucionales",
    "section": "4.3. El Entrenamiento Específico de los Filtros (Kernels)",
    "text": "4.3. El Entrenamiento Específico de los Filtros (Kernels)\nLa pregunta clave es: ¿cómo se aplica esto a los pesos de un filtro convolucional?\nUn filtro \\(K\\) en una capa \\(l\\) es simplemente un conjunto de parámetros \\(\\beta\\) como cualquier otro. Los pesos del filtro (ej. una matriz de \\(3 \\times 3\\)) no se diseñan manualmente; se inicializan con valores aleatorios (ruido).\nEl proceso de entrenamiento aprende los valores de esos pesos:\n\nPropagación Hacia Adelante: La imagen de entrada pasa por el filtro \\(K\\) (inicialmente aleatorio), produciendo un mapa de características (Feature Map). Este mapa pasa por el resto de la red, generando una predicción.\nCálculo de Pérdida: Se calcula el error \\(J(\\beta)\\) comparando la predicción con la etiqueta real.\nRetropropagación: El gradiente del error, \\(\\frac{\\partial J}{\\partial K}\\), se calcula usando la regla de la cadena. Este gradiente representa cómo debe cambiar cada peso en el filtro \\(K\\) para reducir el error final.\nActualización del Filtro: El filtro se utiliza usando la regla de descenso de gradiente:\n\\[\nK_{\\text{nuevo}} = K_{\\text{viejo}} - \\eta \\cdot \\frac{\\partial J}{\\partial K}\n\\]\n\nA medida que este proceso se repite miles de veces (épocas), los filtros aleatorios se “esculpen” iterativamente. Si un filtro que detecta bordes horizontales en la capa 1 ayuda a la red a minimizar la pérdida (es decir, a distinguir mejor las clases), el gradiente moverá los pesos de ese filtro para que se convierta en un detector de bordes horizontales.\nLos filtros de las primeras capas aprenden características simples (bordes, colores, texturas). Los filtros de capas más profundas aprenden a combinar estas características simples para detectar patrones más complejos (formas, objetos parciales) que son relevantes para la tarea de clasificación."
  },
  {
    "objectID": "recursos/documentos/ASIM/ResumenCNN.html#transferencia-de-aprendizaje-transfer-learning",
    "href": "recursos/documentos/ASIM/ResumenCNN.html#transferencia-de-aprendizaje-transfer-learning",
    "title": "Redes Neuronales Convolucionales",
    "section": "4.4. Transferencia de Aprendizaje (Transfer Learning)",
    "text": "4.4. Transferencia de Aprendizaje (Transfer Learning)\nEntrenar una CNN desde cero (con filtros aleatorios) requiere una enorme cantidad de datos etiquetados (como ImageNet) y un alto costo computacional. En el dominio biomédico, los conjuntos de datos suelen ser mucho más pequeños.\nPor esta razón, la técnica estándar es la Transferencia de Aprendizaje.\n1. Se toma una CNN pre-entrenada en un conjunto de datos masivo (ej. ResNet50 entrenada en ImageNet).\n2. Se asume que los filtros aprendidos en las primeras capas (detectores de bordes, texturas) son genéricos y útiles para cualquier tarea visual.\n3. Se congela el entrenamiento de estas primeras capas.\n4. Se reemplaza la capa clasificadora final (MLP) por una nueva, adaptada al problema biomédico (ej. 3 clases en lugar de 1000).\n5. Se entrena (o “reajusta”, fine-tuning) únicamente esta nueva capa clasificadora y, opcionalmente, las últimas capas convolucionales, usando el conjunto de datos médicos."
  },
  {
    "objectID": "recursos/documentos/ASIM/GRU_LSTM_RNN.html",
    "href": "recursos/documentos/ASIM/GRU_LSTM_RNN.html",
    "title": "Arquitecturas de Memoria Profunda: Redes Neuronales Recurrentes, LSTM y GRU",
    "section": "",
    "text": "La modelización matemática de sistemas dinámicos requiere representaciones capaces de capturar dependencias temporales. A diferencia de los modelos estáticos, que asumen independencia entre observaciones, las señales biológicas, el lenguaje y las series financieras son intrínsecamente secuenciales. Las Redes Neuronales Recurrentes (RNN) introducen bucles de retroalimentación que permiten mantener un estado interno, funcionando como una memoria persistente a través del tiempo."
  },
  {
    "objectID": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#la-dimensión-temporal-en-el-procesamiento-de-señales",
    "href": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#la-dimensión-temporal-en-el-procesamiento-de-señales",
    "title": "Arquitecturas de Memoria Profunda: Redes Neuronales Recurrentes, LSTM y GRU",
    "section": "",
    "text": "La modelización matemática de sistemas dinámicos requiere representaciones capaces de capturar dependencias temporales. A diferencia de los modelos estáticos, que asumen independencia entre observaciones, las señales biológicas, el lenguaje y las series financieras son intrínsecamente secuenciales. Las Redes Neuronales Recurrentes (RNN) introducen bucles de retroalimentación que permiten mantener un estado interno, funcionando como una memoria persistente a través del tiempo."
  },
  {
    "objectID": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#redes-neuronales-recurrentes-rnn",
    "href": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#redes-neuronales-recurrentes-rnn",
    "title": "Arquitecturas de Memoria Profunda: Redes Neuronales Recurrentes, LSTM y GRU",
    "section": "2. Redes Neuronales Recurrentes (RNN)",
    "text": "2. Redes Neuronales Recurrentes (RNN)\n\n2.1 Arquitectura y Dinámica de Estado\nUna RNN procesa secuencias mediante la aplicación recursiva de una función de transición. Conceptualmente, la red se “desenrolla” a lo largo de los pasos de tiempo \\(T\\), compartiendo los mismos parámetros en cada paso.\nLa actualización del estado oculto se define formalmente como:\n\\[h_t = \\sigma_h (W_{ih} x_t + b_{ih} + W_{hh} h_{t-1} + b_{hh})\\]\nDonde:\n\n\\(h_t \\in \\mathbb{R}^h\\): Vector de estado oculto en el tiempo \\(t\\).\n\\(x_t \\in \\mathbb{R}^d\\): Vector de entrada en el tiempo \\(t\\).\n\\(W_{hh} \\in \\mathbb{R}^{h\\times h}\\): Matriz de pesos recurrente que conecta el pasado con el presente.\n\\(\\sigma_h\\): Función de activación no lineal (usualmente \\(\\tanh\\)).\n\nLa salida del sistema en cada instante se proyecta desde el estado oculto:\n\\[y_t = \\sigma_y(W_{hy} h_t + b_y)\\]\n\n\n2.2 Limitaciones del Gradiente\nDurante el entrenamiento mediante Backpropagation Through Time (BPTT), el cálculo del gradiente implica productos sucesivos de matrices Jacobianas:\n\\[\\frac{\\partial h_t}{\\partial h_k} = \\prod_{j=k+1}^t \\text{diag}(\\sigma'(z_j)) W_{hh}\\]\nEl comportamiento espectral de \\(W_{hh}\\) determina la estabilidad del aprendizaje:\n1. Desvanecimiento: Si el radio espectral es menor a 1, la señal de error decae exponencialmente, impidiendo capturar dependencias lejanas.\n2. Explosión: Si es mayor a 1, los gradientes divergen, desestabilizando los pesos."
  },
  {
    "objectID": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#arquitectura-long-short-term-memory-lstm",
    "href": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#arquitectura-long-short-term-memory-lstm",
    "title": "Arquitecturas de Memoria Profunda: Redes Neuronales Recurrentes, LSTM y GRU",
    "section": "3. Arquitectura Long Short-Term Memory (LSTM)",
    "text": "3. Arquitectura Long Short-Term Memory (LSTM)\nLa arquitectura LSTM introduce una celda de memoria (\\(C_t\\)) independiente del estado oculto (\\(h_t\\)), diseñada para preservar el flujo del gradiente mediante interacciones lineales.\n\n3.1 Mecanismo de Compuertas\nEl flujo de información es regulado por estructuras sigmoidales:\n\nOlvido (\\(f_t\\)): Determina la información a descartar del estado de celda previo.\n\\[f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\\]\nEntrada (\\(i_t\\)) y Candidato (\\(\\tilde{C}_t\\)): Regulan la incorporación de nueva información.\n\\[i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\\]\n\\[\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)\\]\nActualización de Celda (\\(C_t\\)): Combina linealmente el pasado y el presente.\n\\[C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t\\]\nSalida (\\(o_t\\)) y Estado Oculto:\n\\[o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\\]\n\\[h_t = o_t \\odot \\tanh(C_t)\\]"
  },
  {
    "objectID": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#gated-recurrent-units-gru",
    "href": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#gated-recurrent-units-gru",
    "title": "Arquitecturas de Memoria Profunda: Redes Neuronales Recurrentes, LSTM y GRU",
    "section": "4. Gated Recurrent Units (GRU)",
    "text": "4. Gated Recurrent Units (GRU)\nLa GRU optimiza la arquitectura recurrente fusionando los estados y reduciendo el sistema a dos compuertas de control, mejorando la eficiencia computacional sin sacrificar significativamente la capacidad de modelado.\n\n4.1 Dinámica de Transición\n\nCompuerta de Actualización (\\(z_t\\)): Controla cuánto del estado anterior se mantiene.\n\\[z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t] + b_z)\\]\nCompuerta de Reinicio (\\(r_t\\)): Determina la relevancia del pasado para el cálculo actual.\n\\[r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t] + b_r)\\]\nEstado Oculto (\\(h_t\\)): Interpolación directa.\n\\[\\tilde{h}_t = \\tanh(W_h \\cdot [r_t \\odot h_{t-1}, x_t] + b_h)\\]\n\\[h_t = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t\\]\n\n\n\n4.2 Selección de Arquitectura\n\nLSTM: Preferible para secuencias con dependencias temporales muy extensas o cuando la separación entre memoria y estado oculto es crítica.\nGRU: Ideal para sistemas con restricciones de cómputo, inferencia en tiempo real y conjuntos de datos limitados, debido a su menor número de parámetros."
  },
  {
    "objectID": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#implementación-modular-en-pytorch",
    "href": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#implementación-modular-en-pytorch",
    "title": "Arquitecturas de Memoria Profunda: Redes Neuronales Recurrentes, LSTM y GRU",
    "section": "5. Implementación Modular en PyTorch",
    "text": "5. Implementación Modular en PyTorch\nLa implementación se estructura mediante clases modulares que encapsulan la lógica recurrente, permitiendo la instanciación flexible de RNN, LSTM o GRU. Se asume una entrada tridimensional estandarizada: (Batch Size, Sequence Length, Features).\n\n5.1 Estructura Genérica de Clasificación\nEsta clase implementa un modelo “Muchos a Uno” (Many-to-One), donde la secuencia completa es procesada para generar una única salida basada en el último estado oculto.\n\nimport torch\nimport torch.nn as nn\nfrom typing import Tuple, Union\n\nclass ModuloRecurrenteGenerico(nn.Module):\n    \"\"\"\n    Bloque constructivo para procesamiento de secuencias temporales.\n    Encapsula la lógica de selección de arquitectura recurrente.\n    \"\"\"\n    def __init__(self,\n                 tipo_arquitectura: str,\n                 dim_entrada: int,\n                 dim_oculta: int,\n                 dim_salida: int):\n        \"\"\"\n        Configuración de la arquitectura.\n\n        Args:\n            tipo_arquitectura (str): Identificador ('RNN', 'LSTM', 'GRU').\n            dim_entrada (int): Número de características por paso de tiempo.\n            dim_oculta (int): Tamaño del vector de estado interno.\n            dim_salida (int): Dimensión del vector de salida final.\n        \"\"\"\n        super(ModuloRecurrenteGenerico, self).__init__()\n        self.tipo = tipo_arquitectura\n        self.dim_oculta = dim_oculta\n\n        # Inicialización agnóstica de la capa recurrente\n        if self.tipo == 'RNN':\n            self.rnn = nn.RNN(dim_entrada, dim_oculta, batch_first=True)\n        elif self.tipo == 'LSTM':\n            self.rnn = nn.LSTM(dim_entrada, dim_oculta, batch_first=True)\n        elif self.tipo == 'GRU':\n            self.rnn = nn.GRU(dim_entrada, dim_oculta, batch_first=True)\n        else:\n            raise ValueError(\"Arquitectura no soportada.\")\n\n        # Capa de proyección final\n        self.proyeccion = nn.Linear(dim_oculta, dim_salida)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Procesamiento de la secuencia.\n\n        Args:\n            x (torch.Tensor): Entrada de forma (Batch, Seq_Len, Features).\n\n        Returns:\n            torch.Tensor: Salida proyectada del último estado temporal.\n        \"\"\"\n        # Propagación a través de la capa recurrente\n        if self.tipo == 'LSTM':\n            # LSTM retorna: output, (hidden_state, cell_state)\n            salida_secuencia, (h_n, c_n) = self.rnn(x)\n        else:\n            # GRU/RNN retornan: output, hidden_state\n            salida_secuencia, h_n = self.rnn(x)\n\n        # Extracción del estado correspondiente al último paso de tiempo (t=T)\n        # salida_secuencia shape: (Batch, Seq_Len, Hidden_Dim)\n        estado_final = salida_secuencia[:, -1, :]\n\n        return self.proyeccion(estado_final)\n\n\n\n5.2 Estructura Genérica de Generación Secuencial\nEsta clase implementa un modelo “Muchos a Muchos” (Many-to-Many) autorregresivo, típico en tareas donde la salida en \\(t\\) depende de la historia hasta \\(t\\). Utiliza capas de Embedding para manejar entradas discretas.\n\nclass GeneradorSecuencial(nn.Module):\n    \"\"\"\n    Modelo autorregresivo para generación de secuencias discretas.\n    Soporta mantenimiento de estado entre pasos de inferencia.\n    \"\"\"\n    def __init__(self,\n                 tamano_vocabulario: int,\n                 dim_embedding: int,\n                 dim_oculta: int,\n                 num_capas: int = 1):\n        super(GeneradorSecuencial, self).__init__()\n        self.dim_oculta = dim_oculta\n        self.num_capas = num_capas\n\n        # Transformación de índices discretos a espacio vectorial denso\n        self.embedding = nn.Embedding(tamano_vocabulario, dim_embedding)\n\n        # Núcleo recurrente (LSTM por defecto para memoria de largo plazo)\n        self.lstm = nn.LSTM(dim_embedding, dim_oculta, num_capas, batch_first=True)\n\n        # Decodificador al espacio original\n        self.decodificador = nn.Linear(dim_oculta, tamano_vocabulario)\n\n    def forward(self, x: torch.Tensor, estado_previo: Tuple[torch.Tensor, torch.Tensor]) \\\n            -&gt; Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n        \"\"\"\n        Paso de inferencia.\n\n        Args:\n            x: Índices de entrada (Batch, Seq_Len).\n            estado_previo: Tupla con (hidden_state, cell_state) del paso t-1.\n\n        Returns:\n            output: Distribución de probabilidad no normalizada (logits).\n            nuevo_estado: Estado actualizado para el paso t+1.\n        \"\"\"\n        vectores = self.embedding(x)\n\n        # Actualización recurrente\n        salida_rnn, nuevo_estado = self.lstm(vectores, estado_previo)\n\n        # Aplanamiento para procesamiento denso\n        # (Batch * Seq_Len, Hidden_Dim)\n        salida_aplanada = salida_rnn.reshape(-1, self.dim_oculta)\n\n        output = self.decodificador(salida_aplanada)\n        return output, nuevo_estado\n\n    def inicializar_estado(self, batch_size: int, dispositivo: torch.device) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Genera el estado cero inicial.\"\"\"\n        peso_ref = next(self.parameters()).data\n        h_0 = peso_ref.new(self.num_capas, batch_size, self.dim_oculta).zero_().to(dispositivo)\n        c_0 = peso_ref.new(self.num_capas, batch_size, self.dim_oculta).zero_().to(dispositivo)\n        return (h_0, c_0)"
  },
  {
    "objectID": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#perspectiva-comparativa-rnn-vs.-transformers",
    "href": "recursos/documentos/ASIM/GRU_LSTM_RNN.html#perspectiva-comparativa-rnn-vs.-transformers",
    "title": "Arquitecturas de Memoria Profunda: Redes Neuronales Recurrentes, LSTM y GRU",
    "section": "6. Perspectiva Comparativa: RNN vs. Transformers",
    "text": "6. Perspectiva Comparativa: RNN vs. Transformers\nAunque las arquitecturas basadas en Attention (Transformers) predominan en el modelado de lenguaje a gran escala, las RNN mantienen ventajas estructurales en dominios específicos:\n\nComplejidad de Inferencia: Las RNN operan con complejidad temporal \\(O(N)\\) y espacial \\(O(1)\\) respecto a la longitud de la historia, lo cual es crítico para sistemas embebidos (Edge AI) y procesamiento de señales en tiempo real (Streaming).\nEficiencia de Datos: En regímenes de Small Data o señales con alta relación señal-ruido, arquitecturas como GRU suelen converger con mayor estabilidad que modelos masivos.\n\nLa elección de la arquitectura debe basarse en las restricciones de latencia, memoria disponible y la naturaleza causal de los datos."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html",
    "href": "recursos/documentos/fft_abstract.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "La Transformada de Fourier es una herramienta matemática fundamental que permite descomponer una señal en sus componentes de frecuencia. En términos simples, transforma una señal del dominio del tiempo (cómo varía en el tiempo) al dominio de la frecuencia (qué frecuencias contiene).\nEn procesamiento de señales, la transformada de Fourier tiene aplicaciones vastas: análisis de audio, imágenes, comunicaciones y señales biomédicas. En particular, para señales fisiológicas como las electromiográficas (EMG), la representación en frecuencia es muy útil.\nEste documento explora los fundamentos avanzados de la transformada de Fourier en su versión continua y discreta, la definición y cálculo de la Transformada Discreta de Fourier (DFT), y el algoritmo eficiente conocido como Transformada Rápida de Fourier (FFT). Finalmente, aplicaremos estos conceptos al análisis de señales EMG para identificar frecuencias predominantes y filtrar ruido, con ejemplos en Python que ilustran paso a paso la implementación."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#transformada-de-fourier-continua",
    "href": "recursos/documentos/fft_abstract.html#transformada-de-fourier-continua",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Transformada de Fourier Continua",
    "text": "Transformada de Fourier Continua\nLa Transformada de Fourier continua de una señal \\(x(t)\\) se define como:\n\\[\nX(\\omega) = \\int_{-\\infty}^{\\infty} x(t)\\, e^{-j\\,\\omega\\,t}\\,dt.\n\\]\nSu inversa se expresa como:\n\\[\nx(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} X(\\omega)\\, e^{\\,j\\,\\omega\\,t}\\,d\\omega.\n\\]\nEsta transformación nos permite analizar la frecuencia de una señal continua."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#transformada-discreta-de-fourier-dft",
    "href": "recursos/documentos/fft_abstract.html#transformada-discreta-de-fourier-dft",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Transformada Discreta de Fourier (DFT)",
    "text": "Transformada Discreta de Fourier (DFT)\nLa Transformada Discreta de Fourier (DFT) de una señal discreta de longitud \\(N\\) se define como:\n\\[\nX[k] = \\sum_{n=0}^{N-1} x[n] \\, e^{-j \frac{2\\pi}{N} k\\,n}, \\quad k = 0,1,\\dots,N-1.\n\\]\nSu inversa es:\n\\[\nx[n] = \frac{1}{N}\\sum_{k=0}^{N-1} X[k] \\, e^{\\,j \frac{2\\pi}{N} k\\,n}, \\quad n = 0,1,\\dots,N-1.\n\\]\n\nImplementación en Python\n\nimport cmath, math\n\ndef dft(x):\n    \"\"\"Calcula la Transformada Discreta de Fourier (DFT)\"\"\"\n    N = len(x)\n    X = []\n    for k in range(N):\n        s = 0+0j  \n        for n in range(N):\n            angle = -2 * math.pi * k * n / N\n            s += x[n] * cmath.exp(1j * angle)\n        X.append(s)\n    return X\n\n# Ejemplo\nx = [1, 1, 1, 1]\nX = dft(x)\nprint([round(X.real, 3)+round(X.imag, 3)*1j for X in X])\n\n[(4+0j), (-0+0j), 0j, 0j]"
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#detección-de-frecuencia-dominante-en-emg",
    "href": "recursos/documentos/fft_abstract.html#detección-de-frecuencia-dominante-en-emg",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Detección de Frecuencia Dominante en EMG",
    "text": "Detección de Frecuencia Dominante en EMG\n\n\nFrecuencia dominante estimada: 50.0 Hz"
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#descripción",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#procedimiento",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\nSolución\nSe grafican las transformaciones solicitadas en Python con Matplotlib.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_t(t):\n    return np.piecewise(t, [(-1 &lt;= t) & (t &lt;= 0), (0 &lt; t) & (t &lt;= 2), (2 &lt; t) & (t &lt;= 3)],\n                         [lambda t: t + 1, 2, 1, 0])\n\nt = np.linspace(-2, 4, 1000)\nplt.plot(t, x_t(t), label='x(t)')\nplt.xlabel('t')\nplt.ylabel('x(t)')\nplt.legend()\nplt.show()\n\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\nSolución\nAnalizamos si \\(\\frac{f_0}{f_s}\\) es racional.\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\nPeríodos: \\(T_1 = \\frac{2\\pi}{2} = \\pi\\), \\(T_2 = \\frac{2\\pi}{\\pi} = 2\\)\nMínimo común múltiplo: **Período = 2*\n\n\\(x(t) = e^{-j(4\\pi/3)t} + e^{j(2\\pi/5)t}\\)\n\nSe buscan los períodos fundamentales.\nNo es periódica porque las razones de frecuencias son irracionales.\n\n\n…\n\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nSolución\n\nPeríodo de la señal:\n\nFrecuencias: \\(f_1 = 300Hz\\), \\(f_2 = 240Hz\\)\nMCM de \\(\\frac{1}{300}\\) y \\(\\frac{1}{240}\\) → T = 1/60 s\n\nFrecuencia de muestreo\n\nTeorema de Nyquist: \\(f_s &gt; 2f_{max} = 600Hz\\)\n\nSeñal muestreada:\nfs = 600  # Hz\nn = np.arange(0, 100)\nxa_n = np.sin(600*np.pi*n/fs) + 3*np.sin(480*np.pi*n/fs)\nplt.stem(n, xa_n)\nplt.show()\n\n…\n\n\n\n6. Muestreo y cuantización\n\nSolución\n\nFrecuencia de muestreo:\n\n\\(T_m1 = 12.5ms\\) → \\(f_s = 80Hz\\)\nNo cumple Nyquist → No se puede reconstruir\n\nMuestreo a 8 veces Nyquist:\n\n\\(f_s = 5760Hz\\)\nSe evalúa si \\(\\frac{f_0}{f_s}\\) es racional → Sí es periódica\n\nCuantización (4 bits, rango 0-5):\n\nPaso de cuantización: \\(\\Delta = \\frac{5}{2^4}\\)\nSe discretiza la señal según niveles de cuantización.\n\n\nimport numpy as np\nlevels = np.linspace(0, 5, 16)\nquantized_signal = np.digitize(xa_n, levels) * (5 / 16)\nplt.stem(n, quantized_signal)\nplt.show()\n\nFin del taller."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#descripción",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\n\\(x(t)\\)\n\\(x(t - 2)\\)\n\\(x(2t + 1)\\)\n\\(x(-3t)\\)\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\n\\(x(t) = e^{-j(\\frac{4\\pi}{3})t} + e^{j(\\frac{2\\pi}{5})t}\\)\n\n\\(x(n) = \\cos(n/8) \\cos(\\pi n/8)\\)\n\n\\(x(n) = \\cos(3\\pi n/2) - \\sin(\\frac{\\pi n}{8}) + 3\\cos(\\frac{\\pi n}{4} + \\frac{\\pi}{3})\\)\n\n\n\n3. Demuestre que si \\(x(t)\\) y \\(y(t)\\) son señales impares, entonces:\n\n\\(z(t) = x(t)y(t)\\) es una señal par\n\n\\(g(t) = x(t) + y(t)\\) es una señal impar.\n\nSiendo \\(x(t) = \\sin(t)\\) y \\(y(t) = t\\), grafique en Python \\(z(t)\\) y \\(g(t)\\). ¿Se cumple lo indicado en los numerales a y b?\n\n\n\n4. Encuentre la expresión analítica de las señales mostradas a continuación utilizando funciones \\(u(t)\\) y \\(r(t)\\) (escalón unitario y rampa).\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nIndique si la señal \\(x_a(t)\\) es una señal periódica, en caso afirmativo, indique el periodo de la señal.\n\nFrecuencia de muestreo que cumpla con el teorema de Nyquist.\n\nEncontrar \\(x_a[n]\\) con la frecuencia de muestreo encontrada en el punto anterior.\n\nIndique si la señal \\(x_a[n]\\) es una señal periódica, en caso afirmativo, indique el periodo de la señal.\n\n\n\n6. Considere el sistema de procesamiento de señales mostrado en la figura:\n\nSi la entrada es \\(x_a(t) = 2 \\sin(720\\pi t) + 2\\), encontrar:\n\nLa salida \\(x_a[n]\\) si \\(T_{m1} = 12.5ms\\). ¿Con esta frecuencia se puede reconstruir la señal \\(x_a(t)\\) en \\(y(t)\\) si \\(T_{m2} = T_{m1}\\)? Justifique su respuesta.\n\nLa salida \\(x_a[n]\\) si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¿La señal es periódica en tiempo discreto? Justifique su respuesta.\n\nPara la señal del punto b, encontrar la señal cuantizada de un ciclo de la señal si el tamaño del registro es de 4 bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "recursos/talleres/SYSB/Taller_2025_1.html",
    "href": "recursos/talleres/SYSB/Taller_2025_1.html",
    "title": "Taller 1 - Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Taller 1\nProfesores\nJenny Carolina Castiblanco Sánchez\nPablo Eduardo Caicedo Rodríguez\nDescripción\nA través de este taller se reforzarán los conocimientos en: señales, transformaciones de la variable independiente, clasificación de señales, ADC y DAC.\nProcedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\nConsidere la señal\nDibuje:\nDetermine si las siguientes señales son periódicas y encuentre su periodo\nPara las siguientes señales encuentre, la potencia instantánea, la energía y la potencia promedio. Indique si la señal se considera de energía o de potencia.\nDemuestre que si y son señales impares, entonces:\n, es una señal par\nes una señal impar.\nSiendo y , grafique en Python y . ¿se cumple lo indicado en el numeral a y b?\nEncuentre la expresión analítica de las señales mostradas a continuación utilizando funciones y (escalón unitario y rampa).\nPara una señal análoga encontrar\nIndique si la señal es una señal periódica, en caso afirmativo, indique el periodo de la señal.\nFrecuencia de muestro que cumpla con el teorema de Nyquist.\nEncontrar con la frecuencia de muestreo encontrada en el punto anterior.\nIndique si la señal es una señal periódica, en caso afirmativo, indique el periodo de la señal.\nConsidere el sistema de procesamiento de señales mostrado en la figura:\nRecuerde que . Si la entrada es , encontrar:\nLa salida si . ¿Con esta frecuencia se puede reconstruir la señal en si ? Justifique su respuesta.\nLa salida si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¿La señal es periódica en tiempo discreto? Justifique su respuesta.\nPara la señal del punto b, encontrar la señal cuantizada de un ciclo de la señal si el tamaño del registro es de 4bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripción",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\nSolución\nSe grafican las transformaciones solicitadas en Python con Matplotlib.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_t(t):\n    return np.piecewise(t, [(-1 &lt;= t) & (t &lt;= 0), (0 &lt; t) & (t &lt;= 2), (2 &lt; t) & (t &lt;= 3)],\n                         [lambda t: t + 1, 2, 1, 0])\n\nt = np.linspace(-2, 4, 1000)\nplt.plot(t, x_t(t), label='x(t)')\nplt.xlabel('t')\nplt.ylabel('x(t)')\nplt.legend()\nplt.show()\n\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\nSolución\nAnalizamos si \\(\\frac{f_0}{f_s}\\) es racional.\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\nPeríodos: \\(T_1 = \\frac{2\\pi}{2} = \\pi\\), \\(T_2 = \\frac{2\\pi}{\\pi} = 2\\)\nMínimo común múltiplo: **Período = 2*\n\n\\(x(t) = e^{-j(4\\pi/3)t} + e^{j(2\\pi/5)t}\\)\n\nSe buscan los períodos fundamentales.\nNo es periódica porque las razones de frecuencias son irracionales.\n\n\n…\n\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nSolución\n\nPeríodo de la señal:\n\nFrecuencias: \\(f_1 = 300Hz\\), \\(f_2 = 240Hz\\)\nMCM de \\(\\frac{1}{300}\\) y \\(\\frac{1}{240}\\) → T = 1/60 s\n\nFrecuencia de muestreo\n\nTeorema de Nyquist: \\(f_s &gt; 2f_{max} = 600Hz\\)\n\nSeñal muestreada:\nfs = 600  # Hz\nn = np.arange(0, 100)\nxa_n = np.sin(600*np.pi*n/fs) + 3*np.sin(480*np.pi*n/fs)\nplt.stem(n, xa_n)\nplt.show()\n\n…\n\n\n\n6. Muestreo y cuantización\n\nSolución\n\nFrecuencia de muestreo:\n\n\\(T_m1 = 12.5ms\\) → \\(f_s = 80Hz\\)\nNo cumple Nyquist → No se puede reconstruir\n\nMuestreo a 8 veces Nyquist:\n\n\\(f_s = 5760Hz\\)\nSe evalúa si \\(\\frac{f_0}{f_s}\\) es racional → Sí es periódica\n\nCuantización (4 bits, rango 0-5):\n\nPaso de cuantización: \\(\\Delta = \\frac{5}{2^4}\\)\nSe discretiza la señal según niveles de cuantización.\n\n\nimport numpy as np\nlevels = np.linspace(0, 5, 16)\nquantized_signal = np.digitize(xa_n, levels) * (5 / 16)\nplt.stem(n, quantized_signal)\nplt.show()\n\nFin del taller."
  },
  {
    "objectID": "recursos/Codigo/PSIM/NeighborhoodOperations.html",
    "href": "recursos/Codigo/PSIM/NeighborhoodOperations.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nfrom matplotlib.patches import Rectangle\n\n\ndef mostrarImagen(inp1):\n    plt.imshow(inp1)\n    plt.axis(\"Off\")\n\n\ndef mostrarHeatMap(mat, row_labels=None, col_labels=None, fmt=\".2f\", title=None):\n    \"\"\"\n    Dibuja un heatmap con anotaciones por celda (mat[i,j]).\n    - mat: array 2D (numpy) con valores (puede contener NaN).\n    - row_labels / col_labels: listas opcionales de etiquetas.\n    - fmt: formato de número (e.g., '.2f', '.0f').\n    - title: título opcional.\n    \"\"\"\n    mat = np.asarray(mat, dtype=float)\n    fig, ax = plt.subplots(figsize=(12, 10))\n\n    im = ax.imshow(mat, aspect=\"auto\", interpolation=\"nearest\")\n    cbar = plt.colorbar(im, ax=ax)\n    cbar.set_label(\"Valor\")\n\n    nrows, ncols = mat.shape\n\n    # Etiquetas si se proveen\n    if row_labels is not None:\n        ax.set_yticks(range(nrows), labels=row_labels)\n    else:\n        ax.set_yticks(range(nrows))\n    if col_labels is not None:\n        ax.set_xticks(range(ncols), labels=col_labels)\n        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n    else:\n        ax.set_xticks(range(ncols))\n\n    # Anotar cada celda\n    for i in range(nrows):\n        for j in range(ncols):\n            val = mat[i, j]\n            if np.isnan(val):\n                text = \"\"  # no anotar NaN\n            else:\n                text = format(val, fmt)\n            ax.text(j, i, text, ha=\"center\", va=\"center\", fontsize=8)\n\n    if title:\n        ax.set_title(title)\n\n    ax.set_xlabel(\"Columnas\")\n    ax.set_ylabel(\"Filas\")\n    plt.tight_layout()\n    plt.show()\n\n\ndef _square_bounds_from_center(r, c, size, nrows, ncols):\n    \"\"\"\n    Devuelve (r0, r1, c0, c1) para un cuadrado centrado en (r,c) de lado `size`.\n    r1 y c1 son exclusivos (estilo slicing de Python).\n    Lanza ValueError si se sale de límites.\n    \"\"\"\n    if size &lt;= 0:\n        raise ValueError(\"size debe ser entero positivo.\")\n    if not (0 &lt;= r &lt; nrows and 0 &lt;= c &lt; ncols):\n        raise ValueError(\"Centro fuera de rango.\")\n    # Para tamaños pares y nones:\n    half_floor = size // 2\n    r0 = r - half_floor\n    c0 = c - half_floor\n    r1 = r0 + size\n    c1 = c0 + size\n    if r0 &lt; 0 or c0 &lt; 0 or r1 &gt; nrows or c1 &gt; ncols:\n        raise ValueError(\"El cuadrado centrado excede los límites de la matriz.\")\n    return r0, r1, c0, c1\n\ndef heatmap_resaltado_centro(mat, r, c, size, cmap_base=\"viridis\", cmap_resalte=\"plasma\"):\n    \"\"\"\n    Heatmap que recolorea una subregión cuadrada centrada en (r,c) con otro colormap.\n    \"\"\"\n    mat = np.asarray(mat, dtype=float)\n    nrows, ncols = mat.shape\n    r0, r1, c0, c1 = _square_bounds_from_center(r, c, size, nrows, ncols)\n\n    fig, ax = plt.subplots(figsize=(12, 10))\n    im_base = ax.imshow(mat, cmap=cmap_base, aspect=\"auto\", interpolation=\"nearest\")\n    cbar = plt.colorbar(im_base, ax=ax); cbar.set_label(\"Valor\")\n\n    # Máscara: True = oculto, False = visible. Solo mostramos la región resaltada con otro cmap.\n    mask = np.ones_like(mat, dtype=bool)\n    mask[r0:r1, c0:c1] = False\n    region = np.ma.masked_array(mat, mask=mask)\n    ax.imshow(region, cmap=cmap_resalte, aspect=\"auto\", interpolation=\"nearest\",\n              norm=im_base.norm)\n\n    # Marco del cuadrado\n    ax.add_patch(Rectangle((c0-0.5, r0-0.5), width=size, height=size,\n                           fill=False, edgecolor=\"black\", linewidth=1.5))\n\n    ax.set_xlabel(\"Columnas\"); ax.set_ylabel(\"Filas\")\n    ax.set_title(f\"Resaltado centrado en (r={r}, c={c}), size={size}\")\n    plt.tight_layout(); plt.show()\n\ndef heatmap_rectangulo_centro(mat, r, c, size, alpha=0.25, cmap=\"viridis\"):\n    \"\"\"\n    Heatmap con un rectángulo semitransparente centrado en (r,c), sin recolorear datos.\n    \"\"\"\n    mat = np.asarray(mat, dtype=float)\n    nrows, ncols = mat.shape\n    r0, r1, c0, c1 = _square_bounds_from_center(r, c, size, nrows, ncols)\n\n    fig, ax = plt.subplots(figsize=(6, 4))\n    im = ax.imshow(mat, cmap=cmap, aspect=\"auto\", interpolation=\"nearest\")\n    plt.colorbar(im, ax=ax).set_label(\"Valor\")\n\n    ax.add_patch(Rectangle((c0-0.5, r0-0.5), width=size, height=size,\n                           linewidth=1.5, edgecolor=\"black\",\n                           facecolor=\"white\", alpha=alpha))\n\n    ax.set_xlabel(\"Columnas\"); ax.set_ylabel(\"Filas\")\n    ax.set_title(f\"Rectángulo centrado en (r={r}, c={c}), size={size}\")\n    plt.tight_layout(); plt.show()\n\n\n\n\nimagen = cv.imread(\"/home/sylph/DataCantatio/pablocaicedor.github.io/recursos/Codigo/Imagenes/elderly.jpg\")\nimagen = cv.cvtColor(imagen, cv.COLOR_BGR2RGB)\nmostrarImagen(imagen)\n\n\n\n\n\n\n\n\n\nprueba1 = np.random.randint(0, 20, size=(15,15))\nmostrarHeatMap(prueba1)\nheatmap_resaltado_centro(prueba1, r=1, c=3, size=3, cmap_base=\"gray\", cmap_resalte=\"plasma\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nimport imageio.v2 as imageio\nimport io\n\n# ============================\n# 1) Funciones base del usuario\n# ============================\n\ndef _square_bounds_from_center(r, c, size, nrows, ncols):\n    \"\"\"\n    Devuelve (r0, r1, c0, c1) para un cuadrado centrado en (r,c) de lado `size`.\n    r1 y c1 son exclusivos (estilo slicing de Python).\n    Lanza ValueError si se sale de límites.\n    \"\"\"\n    if size &lt;= 0:\n        raise ValueError(\"size debe ser entero positivo.\")\n    if not (0 &lt;= r &lt; nrows and 0 &lt;= c &lt; ncols):\n        raise ValueError(\"Centro fuera de rango.\")\n    # Para tamaños pares y nones:\n    half_floor = size // 2\n    r0 = r - half_floor\n    c0 = c - half_floor\n    r1 = r0 + size\n    c1 = c0 + size\n    if r0 &lt; 0 or c0 &lt; 0 or r1 &gt; nrows or c1 &gt; ncols:\n        raise ValueError(\"El cuadrado centrado excede los límites de la matriz.\")\n    return r0, r1, c0, c1\n\ndef heatmap_resaltado_centro(mat, r, c, size, cmap_base=\"viridis\", cmap_resalte=\"plasma\"):\n    \"\"\"\n    Heatmap que recolorea una subregión cuadrada centrada en (r,c) con otro colormap.\n    (Versión interactiva para visualizar en pantalla)\n    \"\"\"\n    mat = np.asarray(mat, dtype=float)\n    nrows, ncols = mat.shape\n    r0, r1, c0, c1 = _square_bounds_from_center(r, c, size, nrows, ncols)\n\n    fig, ax = plt.subplots(figsize=(12, 10))\n    im_base = ax.imshow(mat, cmap=cmap_base, aspect=\"auto\", interpolation=\"nearest\")\n    cbar = plt.colorbar(im_base, ax=ax); cbar.set_label(\"Valor\")\n\n    # Máscara: True=oculto, False=visible\n    mask = np.ones_like(mat, dtype=bool)\n    mask[r0:r1, c0:c1] = False\n    region = np.ma.masked_array(mat, mask=mask)\n    ax.imshow(region, cmap=cmap_resalte, aspect=\"auto\", interpolation=\"nearest\",\n              norm=im_base.norm)\n\n    # Marco del cuadrado\n    ax.add_patch(Rectangle((c0-0.5, r0-0.5), width=size, height=size,\n                           fill=False, edgecolor=\"black\", linewidth=1.5))\n\n    ax.set_xlabel(\"Columnas\"); ax.set_ylabel(\"Filas\")\n    ax.set_title(f\"Resaltado centrado en (r={r}, c={c}), size={size}\")\n    plt.tight_layout(); plt.show()\n\ndef heatmap_rectangulo_centro(mat, r, c, size, alpha=0.25, cmap=\"viridis\"):\n    \"\"\"\n    Heatmap con un rectángulo semitransparente centrado en (r,c), sin recolorear datos.\n    (Versión interactiva para visualizar en pantalla)\n    \"\"\"\n    mat = np.asarray(mat, dtype=float)\n    nrows, ncols = mat.shape\n    r0, r1, c0, c1 = _square_bounds_from_center(r, c, size, nrows, ncols)\n\n    fig, ax = plt.subplots(figsize=(6, 4))\n    im = ax.imshow(mat, cmap=cmap, aspect=\"auto\", interpolation=\"nearest\")\n    plt.colorbar(im, ax=ax).set_label(\"Valor\")\n\n    ax.add_patch(Rectangle((c0-0.5, r0-0.5), width=size, height=size,\n                           linewidth=1.5, edgecolor=\"black\",\n                           facecolor=\"white\", alpha=alpha))\n\n    ax.set_xlabel(\"Columnas\"); ax.set_ylabel(\"Filas\")\n    ax.set_title(f\"Rectángulo centrado en (r={r}, c={c}), size={size}\")\n    plt.tight_layout(); plt.show()\n\n# ===================================================\n# 2) Versión \"no interactiva\" para generar un frame\n#    (misma lógica que heatmap_resaltado_centro)\n# ===================================================\n\ndef heatmap_resaltado_centro_frame(mat, r, c, size,\n                                   cmap_base=\"gray\", cmap_resalte=\"plasma\",\n                                   figsize=(8, 6), dpi=120):\n    \"\"\"\n    Genera un frame (ndarray HxWx3) del heatmap con recoloreo de una subregión\n    centrada en (r,c). No llama plt.show(); devuelve la imagen renderizada.\n    \"\"\"\n    mat = np.asarray(mat, dtype=float)\n    nrows, ncols = mat.shape\n    r0, r1, c0, c1 = _square_bounds_from_center(r, c, size, nrows, ncols)\n\n    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n    im_base = ax.imshow(mat, cmap=cmap_base, aspect=\"auto\", interpolation=\"nearest\")\n    cbar = plt.colorbar(im_base, ax=ax); cbar.set_label(\"Valor\")\n\n    mask = np.ones_like(mat, dtype=bool)\n    mask[r0:r1, c0:c1] = False\n    region = np.ma.masked_array(mat, mask=mask)\n    ax.imshow(region, cmap=cmap_resalte, aspect=\"auto\", interpolation=\"nearest\",\n              norm=im_base.norm)\n\n    ax.add_patch(Rectangle((c0-0.5, r0-0.5), width=size, height=size,\n                           fill=False, edgecolor=\"black\", linewidth=1.5))\n\n    ax.set_xlabel(\"Columnas\"); ax.set_ylabel(\"Filas\")\n    ax.set_title(f\"Resaltado centrado en (r={r}, c={c}), size={size}\")\n    plt.tight_layout()\n\n    # Captura robusta del frame: guardamos a un buffer PNG y leemos con imageio\n    buf = io.BytesIO()\n    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n    buf.seek(0)\n    frame = imageio.imread(buf)\n\n    plt.close(fig)\n    return frame\n\n# ==========================================\n# 3) Generador del GIF moviendo la \"máscara\"\n# ==========================================\n\ndef generate_moving_mask_gif(mat, size=3, out_path=\"heatmap_moving_mask.gif\",\n                             order=\"raster\", fps=10,\n                             cmap_base=\"gray\", cmap_resalte=\"plasma\",\n                             figsize=(8, 6), dpi=120):\n    \"\"\"\n    Genera un GIF moviendo la subregión recoloreada por toda la matriz.\n    - order: \"raster\" (izq-&gt;der en cada fila) o \"snake\" (alternando sentido por fila).\n    \"\"\"\n    mat = np.asarray(mat, dtype=float)\n    nrows, ncols = mat.shape\n    frames = []\n\n    # Centros válidos donde cabe el cuadrado\n    # Usamos la misma validación de _square_bounds_from_center\n    candidates = []\n    for r in range(nrows):\n        for c in range(ncols):\n            try:\n                _square_bounds_from_center(r, c, size, nrows, ncols)\n                candidates.append((r, c))\n            except ValueError:\n                pass\n\n    # Orden de recorrido\n    if order not in (\"raster\", \"snake\"):\n        raise ValueError(\"order debe ser 'raster' o 'snake'.\")\n\n    # Reorganizamos por filas para \"snake\"\n    if order == \"snake\":\n        # agrupar por r y alternar dirección por fila\n        from collections import defaultdict\n        rows = defaultdict(list)\n        for r, c in candidates:\n            rows[r].append(c)\n        for r in range(nrows):\n            cols = sorted(rows[r])\n            if r % 2 == 1:\n                cols = list(reversed(cols))\n            for c in cols:\n                # asegurar que (r,c) está en candidates (por límites)\n                try:\n                    _square_bounds_from_center(r, c, size, nrows, ncols)\n                    frame = heatmap_resaltado_centro_frame(\n                        mat, r, c, size,\n                        cmap_base=cmap_base, cmap_resalte=cmap_resalte,\n                        figsize=figsize, dpi=dpi\n                    )\n                    frames.append(frame)\n                except ValueError:\n                    continue\n    else:\n        # \"raster\": ordenar por r, luego c ascendente\n        for r, c in sorted(candidates):\n            frame = heatmap_resaltado_centro_frame(\n                mat, r, c, size,\n                cmap_base=cmap_base, cmap_resalte=cmap_resalte,\n                figsize=figsize, dpi=dpi\n            )\n            frames.append(frame)\n\n    # Guardar GIF\n    if len(frames) == 0:\n        raise RuntimeError(\"No se generaron frames; revise 'size' y dimensiones de la matriz.\")\n    imageio.mimsave(out_path, frames, fps=fps, loop=0)\n    print(f\"GIF guardado en: {out_path} | Frames: {len(frames)} | \"\n          f\"mat={mat.shape}, size={size}, orden={order}, fps={fps}\")\n\n# ============================\n# 4) Ejemplo de uso solicitado\n# ============================\nif __name__ == \"__main__\":\n    np.random.seed(42)\n    prueba1 = np.random.randint(0, 20, size=(15, 15))\n\n    # Visualización fija de referencia (opcional):\n    # heatmap_resaltado_centro(prueba1, r=1, c=3, size=3, cmap_base=\"gray\", cmap_resalte=\"plasma\")\n\n    # Generar el GIF moviendo la máscara de recoloreo\n    generate_moving_mask_gif(\n        prueba1,\n        size=3,\n        out_path=\"heatmap_moving_mask.gif\",\n        order=\"raster\",          # \"raster\" o \"snake\"\n        fps=10,\n        cmap_base=\"gray\",\n        cmap_resalte=\"plasma\",\n        figsize=(8, 6),\n        dpi=120\n    )\n\nGIF guardado en: heatmap_moving_mask.gif | Frames: 169 | mat=(15, 15), size=3, orden=raster, fps=10"
  },
  {
    "objectID": "recursos/Codigo/SYSB/cod004_frequencyCOntent.html",
    "href": "recursos/Codigo/SYSB/cod004_frequencyCOntent.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport sympy as sp\n\n\ndef pulse_train(t, T=2*np.pi, D=0.5, A=1.0):\n    \"\"\"\n    Genera un tren de pulsos periódicos de amplitud A,\n    periodo T y duty cycle D.\n\n    Parámetros\n    ----------\n    t : ndarray\n        Vector temporal (s o rad, según el contexto).\n    T : float\n        Periodo de la señal.\n    D : float\n        Duty cycle (fracción del periodo con valor alto). 0 &lt; D &lt;= 1\n    A : float\n        Amplitud del pulso.\n\n    Retorna\n    -------\n    x : ndarray\n        Señal periódica x(t) de tipo pulso.\n    \"\"\"\n    if not (0 &lt; D &lt;= 1):\n        raise ValueError(\"El duty cycle D debe estar en (0, 1].\")\n\n    # Llevar t a su fase dentro de un periodo [0, T)\n    phase = np.mod(t, T)\n    # Valor alto durante D*T, bajo el resto\n    x = np.where(phase &lt; D*T, A, 0.0)\n    return x\n\n\n# Parámetros de ejemplo\nT = 10         # periodo\nD = 0.5            # duty cycle 25%\nA = 1.0             # amplitud\nN_periods = 3       # número de periodos a visualizar\n\n# Malla temporal\nt_num = np.linspace(0, N_periods*T, 2000)\n\n# Generar señal\nx_num = pulse_train(t, T=T, D=D, A=A)\n\n# Graficar\nplt.figure(figsize=(8, 3))\nplt.plot(t_num, x_num, color=\"blue\", lw=2)\nplt.title(f\"Periodic Pulse: T={T:.2f}, D={D:.2f}, A={A}\")\nplt.xlabel(\"t\")\nplt.ylabel(\"x(t)\")\nplt.ylim([-0.2*A, 1.2*A])\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n# Variables simbólicas\nt = sp.symbols('t', real=True)\nT = sp.Integer(10)          # período (10 unidades)\nn = sp.symbols('n', integer=True)   # armónico\n\n# Señal en un periodo [0, T) con pulso de 0–5 (duty 50%)\nx = sp.Piecewise(\n    (1, sp.And(t &gt;= 0, t &lt; 5)),\n    (0, sp.And(t &gt;= 5, t &lt; 10)),\n    (0, True)  # cláusula por defecto\n)\n\nOmega0 = 2*sp.pi / T\n\n# Coeficiente complejo c_n = (1/T) ∫_0^T x(t) e^{-j n Ω0 t} dt\nintegrand = x * sp.exp(-sp.I * n * Omega0 * t)   # &lt;--- usa t, no T\ncn = (1/T) * sp.integrate(integrand, (t, 0, T))\ncn_simpl = sp.simplify(cn)\ncn_simpl\n\n\\(\\displaystyle \\begin{cases} \\frac{i \\left(\\left(-1\\right)^{n} - 1\\right)}{2 \\pi n} & \\text{for}\\: n &gt; 0 \\vee n &lt; 0 \\\\\\frac{1}{2} & \\text{otherwise} \\end{cases}\\)\n\n\n\nvalor = complex(cn_simpl.subs({n:1.0}))\nvalor\n\n-0.3183098861837907j"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html",
    "title": "Ejemplo de CRISP-DM",
    "section": "",
    "text": "# %% ------------------ Imports y RNG ------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n\nrng = np.random.default_rng(42)\n\n# %% ------------------ Simulador cohorte rehab ictus ------------------\ndef simulate_stroke_rehab_regression(n=300):\n    age = rng.normal(62, 12, n).clip(18, 90)\n    sex = rng.choice([\"F\",\"M\"], size=n, p=[0.52, 0.48])\n    nihss = rng.integers(0, 16, n)                             # muestra ambulatoria\n    days_since_stroke = rng.integers(14, 180, n)               # 2 semanas a 6 meses\n    comorb = rng.poisson(1.2, n).clip(0, 6)\n\n    sixmwt_base = rng.normal(250, 95, n).clip(30, 600)         # m\n    tug_base = rng.normal(25, 10, n).clip(8, 120)              # s\n\n    therapy_min = rng.normal(160, 40, n).clip(40, 360)         # min/semana\n    cadence = rng.normal(90, 15, n).clip(40, 140)              # pasos/min\n    step_var = np.abs(rng.normal(0.12, 0.05, n))               # CV (adimensional)\n\n    # Mecanismo generador para Δ6MWT (señal + ruido)\n    signal = (\n        0.30*(therapy_min-160) +\n        1.2*(cadence-90) -\n        120*(step_var-0.12) -\n        4.0*nihss -\n        0.08*(days_since_stroke-60) -\n        2.0*(tug_base-25) -\n        8.0*comorb +\n        0.12*(sixmwt_base-250)\n    )\n    noise = rng.normal(0, 40, n)\n    delta_6mwt = (120 + signal + noise).clip(-50, 300)         # m, plausibilidad\n\n    df = pd.DataFrame({\n        \"age\": age.round(1),\n        \"sex\": sex,\n        \"nihss\": nihss.astype(int),\n        \"days_since_stroke\": days_since_stroke.astype(int),\n        \"comorb\": comorb.astype(int),\n        \"sixmwt_base\": sixmwt_base.round(1),\n        \"tug_base\": tug_base.round(1),\n        \"therapy_min\": therapy_min.round(1),\n        \"cadence\": cadence.round(1),\n        \"step_var\": step_var.round(3),\n        \"delta_6mwt\": delta_6mwt.round(1)\n    })\n\n    # Problemas de calidad intencionales para practicar:\n    # 1) Faltantes en ~5% de columnas clave\n    for col in [\"sixmwt_base\", \"tug_base\", \"therapy_min\"]:\n        idx = rng.choice(df.index, size=int(0.05*n), replace=False)\n        df.loc[idx, col] = np.nan\n\n    # 2) Outliers puntuales en dosis de terapia\n    idx_hi = rng.choice(df.index, size=max(1, n//100), replace=False)\n    df.loc[idx_hi, \"therapy_min\"] = df[\"therapy_min\"].max() * 3\n\n    return df\n\ndf = simulate_stroke_rehab_regression(n=1000)\nprint(df.head())\nprint(\"\\nShape:\", df.shape)\n\n    age sex  nihss  days_since_stroke  comorb  sixmwt_base  tug_base  \\\n0  65.7   M      1                164       2        264.1      21.0   \n1  49.5   F     12                111       0        354.0      13.0   \n2  71.0   F     13                 42       1        180.6      44.9   \n3  73.3   F     15                143       3        253.0      24.0   \n4  38.6   F      5                 37       2          NaN      31.4   \n\n   therapy_min  cadence  step_var  delta_6mwt  \n0        230.4    103.2     0.104       132.7  \n1        180.9     93.2     0.073        72.9  \n2        238.6     98.3     0.143        43.7  \n3        196.0     85.3     0.143        74.2  \n4         87.8     91.7     0.097        56.7  \n\nShape: (1000, 11)"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#simluación-de-datos",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#simluación-de-datos",
    "title": "Ejemplo de CRISP-DM",
    "section": "",
    "text": "# %% ------------------ Imports y RNG ------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n\nrng = np.random.default_rng(42)\n\n# %% ------------------ Simulador cohorte rehab ictus ------------------\ndef simulate_stroke_rehab_regression(n=300):\n    age = rng.normal(62, 12, n).clip(18, 90)\n    sex = rng.choice([\"F\",\"M\"], size=n, p=[0.52, 0.48])\n    nihss = rng.integers(0, 16, n)                             # muestra ambulatoria\n    days_since_stroke = rng.integers(14, 180, n)               # 2 semanas a 6 meses\n    comorb = rng.poisson(1.2, n).clip(0, 6)\n\n    sixmwt_base = rng.normal(250, 95, n).clip(30, 600)         # m\n    tug_base = rng.normal(25, 10, n).clip(8, 120)              # s\n\n    therapy_min = rng.normal(160, 40, n).clip(40, 360)         # min/semana\n    cadence = rng.normal(90, 15, n).clip(40, 140)              # pasos/min\n    step_var = np.abs(rng.normal(0.12, 0.05, n))               # CV (adimensional)\n\n    # Mecanismo generador para Δ6MWT (señal + ruido)\n    signal = (\n        0.30*(therapy_min-160) +\n        1.2*(cadence-90) -\n        120*(step_var-0.12) -\n        4.0*nihss -\n        0.08*(days_since_stroke-60) -\n        2.0*(tug_base-25) -\n        8.0*comorb +\n        0.12*(sixmwt_base-250)\n    )\n    noise = rng.normal(0, 40, n)\n    delta_6mwt = (120 + signal + noise).clip(-50, 300)         # m, plausibilidad\n\n    df = pd.DataFrame({\n        \"age\": age.round(1),\n        \"sex\": sex,\n        \"nihss\": nihss.astype(int),\n        \"days_since_stroke\": days_since_stroke.astype(int),\n        \"comorb\": comorb.astype(int),\n        \"sixmwt_base\": sixmwt_base.round(1),\n        \"tug_base\": tug_base.round(1),\n        \"therapy_min\": therapy_min.round(1),\n        \"cadence\": cadence.round(1),\n        \"step_var\": step_var.round(3),\n        \"delta_6mwt\": delta_6mwt.round(1)\n    })\n\n    # Problemas de calidad intencionales para practicar:\n    # 1) Faltantes en ~5% de columnas clave\n    for col in [\"sixmwt_base\", \"tug_base\", \"therapy_min\"]:\n        idx = rng.choice(df.index, size=int(0.05*n), replace=False)\n        df.loc[idx, col] = np.nan\n\n    # 2) Outliers puntuales en dosis de terapia\n    idx_hi = rng.choice(df.index, size=max(1, n//100), replace=False)\n    df.loc[idx_hi, \"therapy_min\"] = df[\"therapy_min\"].max() * 3\n\n    return df\n\ndf = simulate_stroke_rehab_regression(n=1000)\nprint(df.head())\nprint(\"\\nShape:\", df.shape)\n\n    age sex  nihss  days_since_stroke  comorb  sixmwt_base  tug_base  \\\n0  65.7   M      1                164       2        264.1      21.0   \n1  49.5   F     12                111       0        354.0      13.0   \n2  71.0   F     13                 42       1        180.6      44.9   \n3  73.3   F     15                143       3        253.0      24.0   \n4  38.6   F      5                 37       2          NaN      31.4   \n\n   therapy_min  cadence  step_var  delta_6mwt  \n0        230.4    103.2     0.104       132.7  \n1        180.9     93.2     0.073        72.9  \n2        238.6     98.3     0.143        43.7  \n3        196.0     85.3     0.143        74.2  \n4         87.8     91.7     0.097        56.7  \n\nShape: (1000, 11)"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-understanding",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-understanding",
    "title": "Ejemplo de CRISP-DM",
    "section": "Data Understanding",
    "text": "Data Understanding\n\n# %% ------------------ Perfil exploratorio básico ------------------\ndef describe_cardinality(s: pd.Series):\n    return pd.Series({\n        \"dtype\": s.dtype,\n        \"n_unique\": s.nunique(dropna=True),\n        \"pct_unique\": 100*s.nunique(dropna=True)/len(s),\n        \"n_missing\": s.isna().sum(),\n        \"pct_missing\": 100*s.isna().mean()\n    })\n\nprofile = df.apply(describe_cardinality).T\nsummary = df.describe(include=\"all\").T\n\nprint(\"\\n=== Cardinalidad & Faltantes ===\")\nprint(profile)\n\nprint(\"\\n=== Resumen numérico ===\")\nprint(summary)\n\n# %% ------------------ Detección simple de outliers (IQR) ------------------\ndef iqr_outliers_report(df_numeric: pd.DataFrame, k=1.5):\n    rows = []\n    for col in df_numeric.columns:\n        x = df_numeric[col].dropna().values\n        q1, q3 = np.percentile(x, [25, 75])\n        iqr = q3 - q1\n        lo, hi = q1 - k*iqr, q3 + k*iqr\n        n_lo = (df_numeric[col] &lt; lo).sum()\n        n_hi = (df_numeric[col] &gt; hi).sum()\n        rows.append({\"variable\": col, \"q1\": q1, \"q3\": q3, \"iqr\": iqr,\n                     \"low_thresh\": lo, \"high_thresh\": hi,\n                     \"n_low\": int(n_lo), \"n_high\": int(n_hi)})\n    return pd.DataFrame(rows).sort_values(\"n_high\", ascending=False)\n\nnum_cols = df.select_dtypes(include=[np.number]).columns.tolist()\noutliers_table = iqr_outliers_report(df[num_cols])\nprint(\"\\n=== Outliers (IQR 1.5) ===\")\nprint(outliers_table)\n\n# %% ------------------ Visual quick checks (opcional) ------------------\nplt.figure()\ndf[\"delta_6mwt\"].hist(bins=30)\nplt.title(\"Distribución Δ6MWT (m)\")\nplt.xlabel(\"m\"); plt.ylabel(\"frecuencia\")\nplt.show()\n\nplt.figure()\ndf.boxplot(column=[\"therapy_min\"])\nplt.title(\"Boxplot therapy_min (detección outliers)\")\nplt.show()\n\n\n=== Cardinalidad & Faltantes ===\n                     dtype n_unique pct_unique n_missing pct_missing\nage                float64      411       41.1         0         0.0\nsex                 object        2        0.2         0         0.0\nnihss                int64       16        1.6         0         0.0\ndays_since_stroke    int64      166       16.6         0         0.0\ncomorb               int64        7        0.7         0         0.0\nsixmwt_base        float64      821       82.1        50         5.0\ntug_base           float64      336       33.6        50         5.0\ntherapy_min        float64      677       67.7        50         5.0\ncadence            float64      495       49.5         0         0.0\nstep_var           float64      222       22.2         0         0.0\ndelta_6mwt         float64      771       77.1         0         0.0\n\n=== Resumen numérico ===\n                    count unique  top freq        mean        std   min  \\\nage                1000.0    NaN  NaN  NaN     61.6208  11.779899  18.2   \nsex                  1000      2    F  527         NaN        NaN   NaN   \nnihss              1000.0    NaN  NaN  NaN       7.453   4.708924   0.0   \ndays_since_stroke  1000.0    NaN  NaN  NaN      95.709  46.490727  14.0   \ncomorb             1000.0    NaN  NaN  NaN       1.139   1.064336   0.0   \nsixmwt_base         950.0    NaN  NaN  NaN  255.519474  94.649212  30.0   \ntug_base            950.0    NaN  NaN  NaN      25.284   9.764767   8.0   \ntherapy_min         950.0    NaN  NaN  NaN  166.018737  83.033507  40.0   \ncadence            1000.0    NaN  NaN  NaN     90.4363  15.165442  40.0   \nstep_var           1000.0    NaN  NaN  NaN    0.117729   0.050345   0.0   \ndelta_6mwt         1000.0    NaN  NaN  NaN     78.8412  56.194987 -50.0   \n\n                       25%     50%      75%    max  \nage                   53.6    62.1     69.1   90.0  \nsex                    NaN     NaN      NaN    NaN  \nnihss                  4.0     7.0     12.0   15.0  \ndays_since_stroke     55.0    96.0    136.0  179.0  \ncomorb                 0.0     1.0      2.0    6.0  \nsixmwt_base          190.8  256.95   317.35  557.9  \ntug_base              18.5    24.4   32.275   56.0  \ntherapy_min          133.9  158.35  185.275  875.4  \ncadence               80.5    90.5    100.5  140.0  \nstep_var           0.08375   0.117    0.152  0.282  \ndelta_6mwt            41.2    79.8  116.075  262.5  \n\n=== Outliers (IQR 1.5) ===\n            variable         q1       q3        iqr  low_thresh  high_thresh  \\\n6        therapy_min  133.90000  185.275   51.37500   56.837500   262.337500   \n8           step_var    0.08375    0.152    0.06825   -0.018625     0.254375   \n9         delta_6mwt   41.20000  116.075   74.87500  -71.112500   228.387500   \n7            cadence   80.50000  100.500   20.00000   50.500000   130.500000   \n4        sixmwt_base  190.80000  317.350  126.55000    0.975000   507.175000   \n3             comorb    0.00000    2.000    2.00000   -3.000000     5.000000   \n5           tug_base   18.50000   32.275   13.77500   -2.162500    52.937500   \n0                age   53.60000   69.100   15.50000   30.350000    92.350000   \n1              nihss    4.00000   12.000    8.00000   -8.000000    24.000000   \n2  days_since_stroke   55.00000  136.000   81.00000  -66.500000   257.500000   \n\n   n_low  n_high  \n6      7      15  \n8      0       6  \n9      0       4  \n7      4       4  \n4      0       4  \n3      0       2  \n5      0       1  \n0      4       0  \n1      0       0  \n2      0       0"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-quality",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#data-quality",
    "title": "Ejemplo de CRISP-DM",
    "section": "Data Quality",
    "text": "Data Quality\n\n# %% ------------------ Plan de calidad de datos ------------------\n# 1) Imputación: media para numéricos; mantén categóricas como 'missing' si aplica.\nnumeric_features = [\"age\",\"nihss\",\"days_since_stroke\",\"comorb\",\n                    \"sixmwt_base\",\"tug_base\",\"therapy_min\",\"cadence\",\"step_var\"]\ncategorical_features = [\"sex\"]\n\nnum_imputer = SimpleImputer(strategy=\"median\")\ncat_imputer = SimpleImputer(strategy=\"most_frequent\")\n\n# 2) Escalado (para modelos lineales/regularizados)\nnum_scaler = StandardScaler()\n\n# 3) Codificación one-hot de categóricas\nohe = OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\")\n\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"num\", Pipeline([(\"imputer\", num_imputer), (\"scaler\", num_scaler)]), numeric_features),\n        (\"cat\", Pipeline([(\"imputer\", cat_imputer), (\"ohe\", ohe)]), categorical_features),\n    ]\n)"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#baseline-de-modelado",
    "href": "recursos/Codigo/ASIM/ejemplo_CRISP_DM.html#baseline-de-modelado",
    "title": "Ejemplo de CRISP-DM",
    "section": "Baseline de Modelado",
    "text": "Baseline de Modelado\n\n# %% ------------------ Partición y métricas ------------------\nX = df.drop(columns=[\"delta_6mwt\"])\ny = df[\"delta_6mwt\"].values\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=7\n)\n\nscorers = {\n    \"MAE\": make_scorer(mean_absolute_error),\n    \"RMSE\": make_scorer(lambda yt, yp: mean_squared_error(yt, yp)),\n    \"R2\": make_scorer(r2_score),\n}\n\ncv = KFold(n_splits=5, shuffle=True, random_state=7)\n\ndef evaluate_model(model, name):\n    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", model)])\n    cvres = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scorers, n_jobs=-1)\n    print(f\"\\n{name} - CV resultados (train):\")\n    for m in scorers.keys():\n        print(f\"  {m}: {cvres['test_'+m].mean():.2f} ± {cvres['test_'+m].std():.2f}\")\n    pipe.fit(X_train, y_train)\n    yhat = pipe.predict(X_test)\n    print(f\"{name} - Test:\")\n    print(f\"  MAE:  {mean_absolute_error(y_test, yhat):.2f}\")\n    print(f\"  RMSE: {mean_squared_error(y_test, yhat):.2f}\")\n    print(f\"  R2:   {r2_score(y_test, yhat):.3f}\")\n    return pipe\n\nlin = evaluate_model(LinearRegression(), \"LinearRegression\")\nrid = evaluate_model(Ridge(alpha=1.0), \"Ridge(alpha=1.0)\")\nlas = evaluate_model(Lasso(alpha=0.05, max_iter=5000), \"Lasso(alpha=0.05)\")\n\n\nLinearRegression - CV resultados (train):\n  MAE: 34.25 ± 2.12\n  RMSE: 1809.09 ± 156.01\n  R2: 0.42 ± 0.06\nLinearRegression - Test:\n  MAE:  32.75\n  RMSE: 1691.19\n  R2:   0.464\n\nRidge(alpha=1.0) - CV resultados (train):\n  MAE: 34.25 ± 2.12\n  RMSE: 1808.99 ± 155.65\n  R2: 0.42 ± 0.06\nRidge(alpha=1.0) - Test:\n  MAE:  32.75\n  RMSE: 1690.92\n  R2:   0.464\n\nLasso(alpha=0.05) - CV resultados (train):\n  MAE: 34.24 ± 2.12\n  RMSE: 1809.04 ± 155.68\n  R2: 0.42 ± 0.06\nLasso(alpha=0.05) - Test:\n  MAE:  32.73\n  RMSE: 1689.67\n  R2:   0.465"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "",
    "text": "Profesor Asociado en la Universidad Escuela Colombiana de Ingenieria, Analista de Datos con un sólido trasfondo como Ingeniero en Electrónica y Telecomunicaciones y Doctor en Ciencias de la Electrónica. Cuento con 20 años de experiencia en Educación Universitaria y una destacada participación en proyectos de investigación en el campo de la Ciencia de los Datos aplicada a las organizaciones, el aprendizaje y la ciencia. Mi enfoque se centra en utilizar mis habilidades técnicas y experiencia para analizar grandes conjuntos de datos y extraer conocimientos valiosos que impulsen la toma de decisiones informadas."
  },
  {
    "objectID": "about.html#section",
    "href": "about.html#section",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2016",
    "text": "2016\n- P. E. Caicedo-Rodríguez, Rengifo-Rodas, Carlos Felipe, y Rodríguez-Cheu, Luis Eduardo, «Contributions of electronic sciences to the problem of falls of old age population», 2016, doi: 10.17488/RMIB.37.3.6."
  },
  {
    "objectID": "about.html#section-1",
    "href": "about.html#section-1",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2017",
    "text": "2017\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, y L. E. Rodríguez-Cheu, «A human gait temporal parameters calculation algorithm», en VII Latin American Congress on Biomedical Engineering CLAIB 2016, Bucaramanga, Santander, Colombia, October 26th -28th, 2016, vol. 60, I. Torres, J. Bustamante, y D. A. Sierra, Eds., en IFMBE Proceedings, vol. 60. , Singapore: Springer Singapore, 2017, pp. 285-288. doi: 10.1007/978-981-10-4086-3_72."
  },
  {
    "objectID": "about.html#section-2",
    "href": "about.html#section-2",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2018",
    "text": "2018\n-  S. P. Castillo-Landínez y P. E. Caicedo-Rodríguez, «EL BLOG COMO HERRAMIENTA DE ENSEÑANZA EN LOS CURSOS DE INVESTIGACIÓN», presentado en Encuentro Internacional de Educación en Ingeniería ACOFI, Cartagena, Colombia, 2018."
  },
  {
    "objectID": "about.html#section-3",
    "href": "about.html#section-3",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2019",
    "text": "2019\n- N. Valencia-Jimenez et al., «A Comparative Study of Markerless Systems Based on Color-Depth Cameras, Polymer Optical Fiber Curvature Sensors, and Inertial Measurement Units: Towards Increasing the Accuracy in Joint Angle Estimation», Electronics, vol. 8, n.º 2, p. 173, feb. 2019, doi: 10.3390/electronics8020173.\n- S. P. Castillo-Landinez, P. E. Caicedo-Rodríguez, y D. F. Sánchez-Gómez, «Diseño e implementación de un software para la trazabilidad del proceso de beneficio del café», CTA, vol. 20, n.º 3, sep. 2019, doi: 10.21930/rcta.vol20_num3_art:1588.\n- P. E. Caicedo-Rodriguez, C. F. Rengifo-Rodas, L. E. Rodríguez-Cheu, y W. A. Sierra-Arevalo, «Gait Phase Detection for Lower Limb Prosthetic Devices», en Wearable Robotics: Challenges and Trends, vol. 22, M. C. Carrozza, S. Micera, y J. L. Pons, Eds., en Biosystems & Biorobotics, vol. 22. , Cham: Springer International Publishing, 2019, pp. 201-205. doi: 10.1007/978-3-030-01887-0_39.\n- S. P. Castillo-Landínez y P. E. Caicedo-Rodríguez, «ANÁLISIS DE SENTIMIENTOS, UNA HERRAMIENTA PARA VALORAR LA ACTITUD DEL ESTUDIANTE FRENTE A UN CURSO», presentado en Encuentro internacional de educación en ingeniería, Cartagena, Colombia, 2019.\nP. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, y L. E. Rodriguez-Cheu, «LA VELOCIDAD DE MARCHA COMO FACTOR DISCRIMINATORIO DEL RIESGO DE CAÍDA EN ADULTOS MAYORES», presentado en Encuentro internacional de educación en ingeniería, Cartagena, Colombia, 2019. doi: 10.26507/ponencia.282."
  },
  {
    "objectID": "about.html#section-4",
    "href": "about.html#section-4",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2020",
    "text": "2020\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. Gómez-Guevara, «Dataset for gait analysis and assessment of fall risk for older adults», Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- P. E. Caicedo-Rodríguez, C. F. Rengifo-Rodas, L. E. Rodriguez-Cheu, W. A. Sierra-Arevalo, y M. Catalina. Gómez-Guevara, «Dataset for gait analysis and assessment of fall risk for older adults», Data in Brief, vol. 33, p. 106550, dic. 2020, doi: 10.1016/j.dib.2020.106550.\n- Y. H. Bolaños-Muñoz, C. F. Rengifo-Rodas, P. E. Caicedo-Rodríguez, L. E. Rodriguez-Cheu, y W. A. Sierra-Arevalo, «Electronic system for step width estimation using programmable system-on-chip technology and time of flight cameras», HardwareX, vol. 8, p. e00126, oct. 2020, doi: 10.1016/j.ohx.2020.e00126.\n- S. P. Castillo Landínez, P. E. Caicedo Rodríguez, y S. A. Muñoz De La Rosa, «LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA CUARENTENA A TRAVÉS DEL ANÁLISIS DE SENTIMIENTOS. UN CASO DE ESTUDIO EN LA UNIAUTÓNOMA DEL CAUCA», en Encuentro Internacional de Educación en Ingeniería ACOFI 2020, Asociacion Colombiana de Facultades de Ingeniería - ACOFI, ago. 2020, pp. 1-8. doi: 10.26507/ponencia.820.\n- J. P. Henao-Pereira, A. E. Tovar-Leon, S. P. Castillo-Landínez, y P. E. Caicedo-Rodríguez, «Los accidentes de tránsito desde la perspectiva de la minería de datos. Una revisión de la literatura», Aibi revista investig. adm. ing., pp. 133-141, ago. 2020, doi: 10.15649/2346030X.743."
  },
  {
    "objectID": "about.html#section-5",
    "href": "about.html#section-5",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2021",
    "text": "2021\n- P. E. Caicedo-Rodríguez, Incidencia de los sistemas electrónicos de medición de variables biomecánicas en la concordancia intra e inter evaluador del examen POMA de función motora, Primera. Popayán, Colombia: Sello Editorial Uniautónoma del Cauca, 2021.\n- S. Castillo Landínez, P. E. Caicedo Rodríguez, S. A. Muñoz De La Rosa, y J. P. Sandoval Paz, «LA EXPERIENCIA DE LA VIRTUALIDAD DURANTE LA PANDEMIA, UN AÑO DESPUÉS», en Encuentro Internacional de Educación en Ingeniería ACOFI 2021, Asociacion Colombiana de Facultades de Ingeniería - ACOFI, sep. 2021, pp. 1-9. doi: 10.26507/ponencia.2005.\n- L. S. Vargas-Valencia et al., «Sleeve for Knee Angle Monitoring: An IMU-POF Sensor Fusion System», IEEE J. Biomed. Health Inform., vol. 25, n.º 2, pp. 465-474, feb. 2021, doi: 10.1109/JBHI.2020.2988360.\n- C. R. Malaver-Flor y M. Y. Astorquiza-Velasco, «Técnicas de Procesamiento Para Variables Posturales Enfocadas en Detección Temprana Del Microtraumatismo Tisular de un Ciclista», PROSPECTIVA, vol. 19, n.º 2, 2021."
  },
  {
    "objectID": "about.html#section-6",
    "href": "about.html#section-6",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2022",
    "text": "2022\n- S. Castillo Landínez, P. E. Caicedo Rodríguez, y J. A. Mosquera Bolaños, «Los adolescentes y el uso de las redes sociales. Un análisis desde la óptica de la ciencia de datos y el procesamiento de lenguaje natural», presentado en Nuevas realidades para la educación en ingeniería: currículo, tecnología, medio ambiente y desarrollo, sep. 2022, pp. 1-8. doi: 10.26507/paper.2693.\n- V. Cerón Monje, C. E. Zúñiga Muñoz, S. P. Castillo Landínez, y P. E. Caicedo Rodríguez, «Análisis de sentimientos aplicado a la evaluación docente de la Corporación Universitaria Autónoma del Cauca», presentado en Nuevas realidades para la educación en ingeniería: currículo, tecnología, medio ambiente y desarrollo, sep. 2022, pp. 1-10. doi: 10.26507/paper.2308."
  },
  {
    "objectID": "about.html#section-7",
    "href": "about.html#section-7",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2023",
    "text": "2023\n- J. M. Cabrera Ángel, P. E. Caicedo-Rodríguez, y S. Castillo-Landínez, «Así nos vemos», Uniautonoma del Cauca, Popayán, 2023.\n- S. Castillo Landínez y P. E. Caicedo Rodríguez, «¡¡¡Ahora sí tocó poner atención porque hay que evaluar!!!», presentado en Ingeniería para transformar territorios, sep. 2023, pp. 1-10. doi: 10.26507/paper.2941."
  },
  {
    "objectID": "about.html#section-8",
    "href": "about.html#section-8",
    "title": "Ph.D. Pablo Eduardo Caicedo R",
    "section": "2024",
    "text": "2024"
  },
  {
    "objectID": "recursos/Codigo/ASIM/ejemploCNN.html",
    "href": "recursos/Codigo/ASIM/ejemploCNN.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# --- 0. Definir Hiperparámetros y Dispositivo ---\nEPOCHS = 10\nBATCH_SIZE = 128\nLEARNING_RATE = 0.001\n\n# Configurar el dispositivo (GPU si está disponible, sino CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Usando dispositivo: {device}\")\n\n# --- 1. Carga y Preparación de Datos ---\n\n# PyTorch usa 'transforms' para preprocesar datos.\n# ToTensor() convierte la imagen PIL/Numpy a un Tensor\n# y normaliza los píxeles del rango [0, 255] a [0, 1].\ntransform = ToTensor()\n\n# Descargar datos de entrenamiento\ntrain_dataset = datasets.MNIST(\n    root=\"./data\",  # Directorio donde se guardan los datos\n    train=True,\n    download=True,\n    transform=transform\n)\n\n# Descargar datos de prueba\ntest_dataset = datasets.MNIST(\n    root=\"./data\",\n    train=False,\n    download=True,\n    transform=transform\n)\n\n# Crear 'DataLoaders' para manejar los lotes (batches)\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True  # Mezclar los datos de entrenamiento\n)\n\ntest_loader = DataLoader(\n    dataset=test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)\n\n# Verificación de las dimensiones (N_lote, Canales, Altura, Ancho)\n# Note la diferencia con Keras (N, H, W, C)\ndata_iter = iter(train_loader)\nimages, labels = next(data_iter)\nprint(f\"\\nDimensiones de un lote de imágenes: {images.shape}\") # (128, 1, 28, 28)\nprint(f\"Dimensiones de un lote de etiquetas: {labels.shape}\") # (128)\n\n# --- 2. Construcción de la Arquitectura CNN ---\n\n# En PyTorch, los modelos se definen como clases que heredan de nn.Module\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n\n        # Bloque Extractor 1\n        # nn.Conv2d(canales_entrada, canales_salida, kernel_size)\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Bloque Extractor 2\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Bloque Clasificador (MLP)\n        self.flatten = nn.Flatten()\n        # Cálculo de la entrada a la capa densa:\n        # (N, 64, 7, 7) -&gt; 64 * 7 * 7 = 3136\n        self.fc1 = nn.Linear(in_features=64 * 7 * 7, out_features=128)\n        self.relu3 = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(in_features=128, out_features=10) # 10 clases de salida\n\n    # El método 'forward' define cómo fluyen los datos a través de las capas\n    def forward(self, x):\n        # Bloque 1\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.pool1(x)\n\n        # Bloque 2\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.pool2(x)\n\n        # Clasificador\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu3(x)\n        x = self.dropout(x)\n        x = self.fc2(x) # Salida de logits (sin softmax)\n\n        return x\n\n# Instanciar el modelo y moverlo al dispositivo (GPU/CPU)\nmodel = SimpleCNN().to(device)\nprint(model)\n\n# --- 3. Definición de Pérdida y Optimizador ---\n\n# nn.CrossEntropyLoss aplica internamente Softmax y la pérdida\n# Por eso, el modelo debe retornar los logits \"crudos\".\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizador Adam\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# --- 4. Bucle de Entrenamiento ---\n\n# Listas para guardar el historial de la métrica\ntrain_losses = []\nval_losses = []\nval_accuracies = []\n\nprint(\"\\nIniciando entrenamiento...\")\n\nfor epoch in range(EPOCHS):\n\n    # ---- Fase de Entrenamiento ----\n    model.train() # Poner el modelo en modo entrenamiento (activa Dropout)\n    running_loss = 0.0\n\n    for batch_idx, (data, targets) in enumerate(train_loader):\n        # Mover datos al dispositivo\n        data = data.to(device)\n        targets = targets.to(device)\n\n        # 1. Poner a cero los gradientes\n        optimizer.zero_grad()\n\n        # 2. Forward pass (predicción)\n        outputs = model(data)\n\n        # 3. Calcular la pérdida\n        loss = criterion(outputs, targets)\n\n        # 4. Backward pass (retropropagación)\n        loss.backward()\n\n        # 5. Actualizar pesos\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    avg_train_loss = running_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n\n    # ---- Fase de Validación ----\n    model.eval() # Poner el modelo en modo evaluación (desactiva Dropout)\n    running_val_loss = 0.0\n    correct = 0\n    total = 0\n\n    # Desactivar el cálculo de gradientes para la validación\n    with torch.no_grad():\n        for data, targets in test_loader:\n            data = data.to(device)\n            targets = targets.to(device)\n\n            outputs = model(data)\n            loss = criterion(outputs, targets)\n            running_val_loss += loss.item()\n\n            # Calcular la precisión\n            _, predicted = torch.max(outputs.data, 1)\n            total += targets.size(0)\n            correct += (predicted == targets).sum().item()\n\n    avg_val_loss = running_val_loss / len(test_loader)\n    val_losses.append(avg_val_loss)\n\n    accuracy = 100 * correct / total\n    val_accuracies.append(accuracy)\n\n    print(f\"Época [{epoch+1}/{EPOCHS}] - \"\n          f\"Pérdida (Entrenamiento): {avg_train_loss:.4f} - \"\n          f\"Pérdida (Validación): {avg_val_loss:.4f} - \"\n          f\"Precisión (Validación): {accuracy:.2f}%\")\n\nprint(\"Entrenamiento finalizado.\")\n\n# --- 5. Visualización de Resultados ---\n\nplt.figure(figsize=(12, 5))\n\n# Gráfico de Precisión (usando val_accuracies)\nplt.subplot(1, 2, 1)\nplt.plot(val_accuracies, label='Precisión (Validación)', color='blue')\nplt.title('Precisión del Modelo (Validación)')\nplt.xlabel('Época')\nplt.ylabel('Precisión (%)')\nplt.legend()\nplt.grid(True)\n\n# Gráfico de Pérdida\nplt.subplot(1, 2, 2)\nplt.plot(train_losses, label='Pérdida (Entrenamiento)', color='orange')\nplt.plot(val_losses, label='Pérdida (Validación)', color='green')\nplt.title('Pérdida del Modelo')\nplt.xlabel('Época')\nplt.ylabel('Pérdida (Cross-Entropy)')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\nUsando dispositivo: cuda\n\n\n100%|██████████| 9.91M/9.91M [00:01&lt;00:00, 4.98MB/s]\n100%|██████████| 28.9k/28.9k [00:00&lt;00:00, 305kB/s]\n100%|██████████| 1.65M/1.65M [00:00&lt;00:00, 1.90MB/s]\n100%|██████████| 4.54k/4.54k [00:00&lt;00:00, 26.5MB/s]\n\n\n\nDimensiones de un lote de imágenes: torch.Size([128, 1, 28, 28])\nDimensiones de un lote de etiquetas: torch.Size([128])\nSimpleCNN(\n  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (relu1): ReLU()\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (relu2): ReLU()\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n  (relu3): ReLU()\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n)\n\nIniciando entrenamiento...\nÉpoca [1/10] - Pérdida (Entrenamiento): 0.3588 - Pérdida (Validación): 0.0685 - Precisión (Validación): 97.73%\nÉpoca [2/10] - Pérdida (Entrenamiento): 0.1153 - Pérdida (Validación): 0.0489 - Precisión (Validación): 98.35%\nÉpoca [3/10] - Pérdida (Entrenamiento): 0.0866 - Pérdida (Validación): 0.0439 - Precisión (Validación): 98.56%\nÉpoca [4/10] - Pérdida (Entrenamiento): 0.0718 - Pérdida (Validación): 0.0334 - Precisión (Validación): 98.88%\nÉpoca [5/10] - Pérdida (Entrenamiento): 0.0604 - Pérdida (Validación): 0.0308 - Precisión (Validación): 98.88%\nÉpoca [6/10] - Pérdida (Entrenamiento): 0.0539 - Pérdida (Validación): 0.0283 - Precisión (Validación): 98.97%\nÉpoca [7/10] - Pérdida (Entrenamiento): 0.0464 - Pérdida (Validación): 0.0302 - Precisión (Validación): 99.07%\nÉpoca [8/10] - Pérdida (Entrenamiento): 0.0425 - Pérdida (Validación): 0.0264 - Precisión (Validación): 99.20%\nÉpoca [9/10] - Pérdida (Entrenamiento): 0.0374 - Pérdida (Validación): 0.0239 - Precisión (Validación): 99.17%\nÉpoca [10/10] - Pérdida (Entrenamiento): 0.0346 - Pérdida (Validación): 0.0270 - Precisión (Validación): 99.13%\nEntrenamiento finalizado."
  },
  {
    "objectID": "recursos/Codigo/SYSB/filtraje_transformada_z.html",
    "href": "recursos/Codigo/SYSB/filtraje_transformada_z.html",
    "title": "Transformada Z",
    "section": "",
    "text": "Un problema común en el procesamiento de bioseñales es eliminar la interferencia de la red eléctrica (50/60 Hz) de, por ejemplo, señales EEG o ECG. Un filtro digital sencillo para eliminar la interferencia de 60 Hz (suponiendo una frecuencia de muestreo \\(f_s = 5000\\) Hz) es ubicar ceros complejos conjugados en la frecuencia de la interferencia en el plano Z. En este caso, los ceros se ubican en \\(z_1 = e^{j2\\pi \\frac{60}{5000}}\\) y \\(z_2 = e^{-j2\\pi \\frac{60}{5000}}\\).\n\n\nimport sympy as sp\n\n# 1. Configurar la impresión bonita de SymPy (opcional, pero recomendado)\n# sp.init_printing(use_unicode=True)\n# 2. Definir el símbolo 'z' para el polinomio\nz = sp.symbols('z')\n\n\n# 3. Definir las constantes del problema\nf = 60      # Frecuencia de interferencia (Hz)\nfs = 5000   # Frecuencia de muestreo (Hz)\n\n# 4. Calcular la frecuencia angular normalizada (omega_0)\n# w0 = 2 * pi * (f / fs)\n# Usamos sp.pi para mantener la precisión simbólica\nw0 = 2 * sp.pi * f / fs\n\n\nprint(f\"--- Parámetros Iniciales ---\")\nprint(f\"Frecuencia (f): {f} Hz\")\nprint(f\"Frecuencia de Muestreo (fs): {fs} Hz\")\nprint(f\"Frecuencia Angular Normalizada (w0 = 2*pi*f/fs):\")\nsp.pprint(w0)\n\n\n--- Parámetros Iniciales ---\nFrecuencia (f): 60 Hz\nFrecuencia de Muestreo (fs): 5000 Hz\nFrecuencia Angular Normalizada (w0 = 2*pi*f/fs):\n3⋅π\n───\n125\n\n\n\n# 5. Definir los ceros z1 y z2\nz1 = sp.exp(sp.I * w0)\nz2 = sp.exp(-sp.I * w0)\n\nprint(\"--- Ceros Definidos ---\")\nprint(\"z1:\")\nsp.pprint(z1)\nprint(\"\\nz2:\")\nsp.pprint(z2)\n\n\n--- Ceros Definidos ---\nz1:\n 3⋅ⅈ⋅π\n ─────\n  125 \nℯ     \n\nz2:\n -3⋅ⅈ⋅π \n ───────\n   125  \nℯ       \n\n\n\n\n# 6. Crear la función de transferencia H(z) en forma factorizada\n# H(z) = (z - z1) * (z - z2)\nH_z = (z - z1) * (z - z2)\n\nprint(\"--- H(z) en Forma Factorizada ---\")\nsp.pprint(H_z)\n\n\n--- H(z) en Forma Factorizada ---\n⎛     -3⋅ⅈ⋅π ⎞ ⎛     3⋅ⅈ⋅π⎞\n⎜     ───────⎟ ⎜     ─────⎟\n⎜       125  ⎟ ⎜      125 ⎟\n⎝z - ℯ       ⎠⋅⎝z - ℯ     ⎠\n\n\n\n\n# 7. Expandir el polinomio\n# SymPy realizará la multiplicación: z*z - z*z2 - z*z1 + z1*z2\nH_z_expanded = sp.expand(H_z)\n\nprint(\"--- H(z) Expandido (sin simplificar) ---\")\nsp.pprint(H_z_expanded)\n\n\n--- H(z) Expandido (sin simplificar) ---\n        3⋅ⅈ⋅π      -3⋅ⅈ⋅π     \n        ─────      ───────    \n 2       125         125      \nz  - z⋅ℯ      - z⋅ℯ        + 1\n\n\n\n\n# 8. Simplificar la expresión expandida\n# SymPy aplicará las identidades de Euler:\n# z1 * z2 = exp(j*w0) * exp(-j*w0) = 1\n# z1 + z2 = exp(j*w0) + exp(-j*w0) = 2*cos(w0)\n# El resultado será: z**2 - z*(2*cos(w0)) + 1\nH_z_simplified = sp.simplify(H_z_expanded)\n\nprint(\"--- H(z) Expandido y Simplificado ---\")\nsp.pprint(H_z_simplified)\n\n\n# 9. Mostrar el valor numérico del coeficiente del coseno\nprint(\"--- Verificación de Coeficientes ---\")\nprint(\"El polinomio resultante es de la forma: z**2 - 2*cos(w0)*z + 1\")\ncoef_cos = 2 * sp.cos(w0)\nprint(f\"Valor del coeficiente '2*cos(w0)':\")\nsp.pprint(coef_cos)\nprint(f\"\\nValor numérico (evaluado): {coef_cos.evalf()}\")\n\n--- H(z) Expandido y Simplificado ---\n                       122      \n                       ───      \n 2       3/125         125      \nz  - (-1)     ⋅z + (-1)   ⋅z + 1\n--- Verificación de Coeficientes ---\nEl polinomio resultante es de la forma: z**2 - 2*cos(w0)*z + 1\nValor del coeficiente '2*cos(w0)':\n     ⎛3⋅π⎞\n2⋅cos⎜───⎟\n     ⎝125⎠\n\nValor numérico (evaluado): 1.99431780052123\n\n\n\nfrom scipy.signal import tf2zpk, freqz\nimport numpy as np\nimport matplotlib.pyplot as plt\n\na = np.array([1.0])\nb = np.array([1, float(-coef_cos.evalf()), 1])\n\nz, p, k = tf2zpk(b, a)\n\n\nfig, ax = plt.subplots(figsize=(10, 10))\n_ = ax.set_title('Diagrama de polos y ceros', fontsize=16)\n\n# Círculo unitario\nunit_circle = plt.Circle((0, 0), 1, color=\"black\", fill=False, linestyle=\"dashed\")\nax.add_artist(unit_circle)\nax.set_xlim((-1.5, 1.5))\nax.set_ylim((-1.5, 1.5))\n\nax.plot(np.real(z), np.imag(z), \"go\", label=\"Ceros\")\nax.plot(np.real(p), np.imag(p), \"rx\", label=\"Polos\")\n\nax.set_xlabel('Real Part', fontsize=14)\nax.set_ylabel('Imaginary Part', fontsize=14)\nax.axhline(0, color='black', lw=0.5, ls='--')\nax.axvline(0, color='black', lw=0.5, ls='--')\n\nfig.legend(fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n\nfreqs, h = freqz(b, a, fs=fs, worN=8000)\nplt.figure(figsize=(12, 6))\nplt.subplot(2, 1, 1)\nplt.plot(freqs, np.abs(h), 'b')\nplt.title('Respuesta en Frecuencia del Filtro Notch')\nplt.xlabel('Frecuencia (Hz)')\nplt.ylabel('Ganancia')\nplt.grid()\nplt.subplot(2, 1, 2)\nplt.plot(freqs, np.angle(h)*180/np.pi, 'r')\nplt.xlabel('Frecuencia (Hz)')\nplt.ylabel('Fase (radianes)')\nplt.grid()\n\n\n\n\n\n\n\n\n\ndef gaussian(x, mu, sigma, A):\n    \"\"\"\n    Genera una función gaussiana.\n\n    Parámetros:\n    - x: array de tiempos\n    - mu: posición central de la gaussiana\n    - sigma: desviación estándar\n    - A: amplitud\n    \"\"\"\n    return A * np.exp(-((x - mu) ** 2) / (2 * sigma**2))\n\ndef simulate_ecg(duration=10.0, fs=500, heart_rate=70):\n    \"\"\"\n    Simula un ECG sintético basado en la superposición de ondas gaussianas.\n\n    Parámetros:\n    - duration: duración de la señal en segundos\n    - fs: frecuencia de muestreo en Hz\n    - heart_rate: frecuencia cardiaca en latidos por minuto\n\n    Devuelve:\n    - t: vector de tiempos\n    - ecg: señal simulada de ECG en mV\n    \"\"\"\n    dt = 1 / fs\n    t = np.arange(0, duration, dt)\n    rr = 60 / heart_rate  # intervalo RR en segundos\n\n    # Inicializar señal\n    ecg = np.zeros_like(t)\n\n    # Parámetros de las ondas (posiciones relativas en segundos)\n    # P wave\n    p_amp, p_dur, p_delay = 0.25, 0.09, 0.16\n    # Q wave\n    q_amp, q_dur, q_delay = -0.05, 0.066, 0.166\n    # R wave\n    r_amp, r_dur, r_delay = 1.6, 0.1, 0.166\n    # S wave\n    s_amp, s_dur, s_delay = -0.25, 0.066, 0.19\n    # T wave\n    t_amp, t_dur, t_delay = 0.35, 0.142, 0.36\n\n    # Generar cada latido\n    for beat_start in np.arange(0, duration, rr):\n        mask = (t &gt;= beat_start) & (t &lt; beat_start + rr)\n        tb = t[mask] - beat_start\n        ecg[mask] += gaussian(tb, p_delay, p_dur / 2, p_amp)\n        ecg[mask] += gaussian(tb, q_delay, q_dur / 2, q_amp)\n        ecg[mask] += gaussian(tb, r_delay, r_dur / 2, r_amp)\n        ecg[mask] += gaussian(tb, s_delay, s_dur / 2, s_amp)\n        ecg[mask] += gaussian(tb, t_delay, t_dur / 2, t_amp)\n\n    return t, ecg+0.1*np.cos(2*np.pi*60*t)\n\n\n# Parámetros de simulación\nDURATION = 10    # segundos\nFS = 5000        # Hz\nHR = 100          # latidos por minuto\n\n# Generar señal\nt, ecg_signal = simulate_ecg(duration=DURATION, fs=FS, heart_rate=HR)\n\n# Graficar resultado\nplt.figure(figsize=(12, 4))\nplt.plot(t, ecg_signal, linewidth=1)\nplt.title(f'Señal de ECG sintética ({HR} bpm)')\nplt.xlabel('Tiempo (s)')\nplt.ylabel('Amplitud (mV)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Analisis Fourier de ECG -- Dominio de frecuencia\nspectrum = 20*np.log10(np.abs(np.fft.fft(ecg_signal)))\nfreqs = np.fft.fftfreq(len(t), 1/FS)\nn_freqs = 1000#len(freqs)//2\nplt.figure(figsize=(12, 4))\nplt.plot(freqs[:n_freqs], spectrum[:n_freqs], linewidth=1)\nplt.title('Espectro de Frecuencia de la Señal de ECG')\nplt.xlabel('Frecuencia (Hz)')\nplt.ylabel('Magnitud')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.signal import lfilter\n\n# Filtrar la señal de ECG con el filtro Notch diseñado\nfiltered_ecg = lfilter(b, a, ecg_signal)\n\nspectrum1 = 20*np.log10(np.abs(np.fft.fft(ecg_signal)))\nspectrum3 = np.angle(np.fft.fft(ecg_signal))*180/np.pi\nfreqs = np.fft.fftfreq(len(t), 1/FS)\nn_freqs = 1000#len(freqs)//2\n\nspectrum2 = 20*np.log10(np.abs(np.fft.fft(filtered_ecg)))\nspectrum4 = np.angle(np.fft.fft(filtered_ecg))*180/np.pi\n\n# Graficar señal original y filtrada\nplt.figure(figsize=(12, 6))\nplt.subplot(3, 2, 1)\nplt.plot(t, ecg_signal, label='Señal Original', linewidth=1)\nplt.title('Señal de ECG Original vs Filtrada')\nplt.xlabel('Tiempo (s)')\nplt.ylabel('Amplitud (mV)')\nplt.legend()\nplt.grid(True)\nplt.subplot(3, 2, 2)\nplt.plot(t, filtered_ecg, label='Señal Filtrada', color='black', linewidth=1)\nplt.xlabel('Tiempo (s)')\nplt.ylabel('Amplitud (mV)')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(3, 2, 3)\nplt.plot(freqs[:n_freqs], spectrum1[:n_freqs], label='Original', linewidth=1)\nplt.title('Espectro de Frecuencia')\nplt.xlabel('Frecuencia (Hz)')\nplt.ylabel('Magnitud (dB)')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(3, 2, 4)\nplt.plot(freqs[:n_freqs], spectrum2[:n_freqs], label='Filtrada', color='black', linewidth=1)\nplt.xlabel('Frecuencia (Hz)')\nplt.ylabel('Magnitud (dB)')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(3, 2, 5)\nplt.plot(freqs[:n_freqs], spectrum3[:n_freqs], label='Original', linewidth=1)\nplt.title('Fase')\nplt.xlabel('Frecuencia (Hz)')\nplt.ylabel('Fase (grados)')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(3, 2, 6)\nplt.plot(freqs[:n_freqs], spectrum4[:n_freqs], label='Filtrada', color='black', linewidth=1)\nplt.xlabel('Frecuencia (Hz)')\nplt.ylabel('Fase (grados)')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "recursos/Codigo/PSIM/gif_Creation.html",
    "href": "recursos/Codigo/PSIM/gif_Creation.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport cv2\n\n\nimagen = cv2.imread(\"../../../\")\n\n\n# -*- coding: utf-8 -*-\n\"\"\"\nGenera dos GIF pedagógicos que ilustran la convolución en 1D y 2D.\n\nRequisitos:\n  pip install numpy matplotlib imageio scipy\n\nSalida:\n  - convolucion_1d.gif\n  - convolucion_2d.gif\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport imageio.v2 as imageio\nfrom scipy.signal import convolve, convolve2d\nfrom matplotlib.patches import Rectangle\n\n# ---------- Utilidades ----------\ndef fig_to_rgb_array(fig):\n    \"\"\"\n    Renderiza una figura de matplotlib a un array RGB (uint8),\n    compatible con backends que exponen buffer_rgba() o tostring_rgb().\n    \"\"\"\n    fig.canvas.draw()\n    w, h = fig.canvas.get_width_height()\n    if hasattr(fig.canvas, \"buffer_rgba\"):\n        buf = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n        arr = buf.reshape((h, w, 4))[:, :, :3]  # descarta canal alpha\n        return arr\n    elif hasattr(fig.canvas, \"tostring_rgb\"):\n        buf = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n        return buf.reshape((h, w, 3))\n    else:\n        # Fallback robusto vía PNG en memoria (más lento, pero seguro)\n        import io, imageio.v2 as imageio\n        mem = io.BytesIO()\n        fig.savefig(mem, format=\"png\", dpi=fig.dpi, bbox_inches=\"tight\")\n        mem.seek(0)\n        im = imageio.imread(mem)\n        mem.close()\n        return im[:, :, :3]\n\ndef normalize01(x, eps=1e-12):\n    x = np.asarray(x, dtype=np.float32)\n    mn = np.min(x)\n    mx = np.max(x)\n    return (x - mn) / (mx - mn + eps)\n\n# ---------- GIF de Convolución 1D ----------\ndef generar_gif_convolucion_1d(\n    n=120,\n    kernel=None,\n    fps=20,\n    archivo_salida=\"convolucion_1d.gif\",\n    dpi=120,\n):\n    # Señal 1D sintética: suma de senos + pulsos\n    x = np.linspace(0, 4*np.pi, n)\n    señal = 0.7*np.sin(1.0*x) + 0.3*np.sin(3.2*x)\n    señal += np.exp(-0.5*((x-2.2*np.pi)/0.25)**2)  # pulso gaussiano\n    señal += 0.6*np.exp(-0.5*((x-0.8*np.pi)/0.12)**2)\n\n    # Kernel: si no se pasa, usar un suavizante triangular (ventana Bartlett)\n    if kernel is None:\n        ksize = 15\n        kernel = np.bartlett(ksize)\n        kernel /= np.sum(kernel)\n\n    # Convolución \"full\" para referencia y escala\n    y_full = convolve(señal, kernel, mode=\"same\")\n\n    # Preparación para animación\n    frames = []\n    L = len(señal)\n    K = len(kernel)\n    kflip = kernel[::-1]\n\n    # Índices de soporte equivalentes a modo 'same' con padding implícito\n    pad = K // 2\n\n    # Prealoca salida incremental\n    y_inc = np.zeros_like(señal)\n\n    # Recorre cada posición del centro del kernel\n    for c in range(L):\n        # Toma ventana con padding (c - pad ... c + pad)\n        i0 = c - pad\n        i1 = c + pad + 1\n        ventana = np.zeros(K, dtype=np.float32)\n        # Copia la parte válida desde la señal\n        j0 = max(0, i0)\n        j1 = min(L, i1)\n        w0 = max(0, -i0)\n        w1 = w0 + (j1 - j0)\n        if j1 &gt; j0:\n            ventana[w0:w1] = señal[j0:j1]\n        # Valor de salida en c\n        y_val = np.dot(ventana, kflip)\n        y_inc[c] = y_val\n\n        # --- Dibujo ---\n        fig, axs = plt.subplots(2, 1, figsize=(7.2, 5.2), dpi=dpi, constrained_layout=True)\n\n        # Arriba: señal y kernel sobrepuesto (escalado para visualizar)\n        axs[0].plot(señal, lw=2, label=\"Señal x[n]\")\n        # kernel reescalado y centrado en c\n        k_vis = kflip / (np.max(np.abs(kflip)) + 1e-12)  # [-1,1]\n        k_vis = 0.35 * k_vis  # escala vertical\n        k_line = np.zeros_like(señal)\n        k_start = c - pad\n        for kk in range(K):\n            idx = k_start + kk\n            if 0 &lt;= idx &lt; L:\n                k_line[idx] = k_vis[kk] + señal[idx]  # superponer encima de x[n]\n        axs[0].plot(k_line, lw=2, alpha=0.9, label=\"Kernel (volteado) centrado\")\n        axs[0].axvline(c, ls=\"--\", lw=1)\n        axs[0].set_title(\"Convolución 1D: ventana deslizante\")\n        axs[0].set_xlim(0, L-1)\n        axs[0].legend(loc=\"upper right\")\n        axs[0].grid(alpha=0.25)\n\n        # Abajo: salida acumulada y total de referencia\n        axs[1].plot(y_full, lw=1.5, alpha=0.45, label=\"Salida completa (referencia)\")\n        axs[1].plot(y_inc, lw=2.2, label=\"Salida acumulada $y[n]$\")\n        axs[1].set_xlim(0, L-1)\n        axs[1].set_title(\"Salida de la convolución (acumulada)\")\n        axs[1].legend(loc=\"upper right\")\n        axs[1].grid(alpha=0.25)\n\n        frame = fig_to_rgb_array(fig)\n        plt.close(fig)\n        frames.append(frame)\n\n    imageio.mimsave(archivo_salida, frames, duration=1.0/fps, loop=0)\n    print(f\"[OK] GIF 1D guardado en: {archivo_salida}\")\n\n# ---------- GIF de Convolución 2D ----------\ndef generar_gif_convolucion_2d(\n    H=48,\n    W=48,\n    ksize=7,\n    step=2,\n    fps=16,\n    archivo_salida=\"convolucion_2d.gif\",\n    dpi=120,\n):\n    \"\"\"\n    Visualiza una imagen sintética, el barrido del kernel y la salida acumulada.\n    - step: tamaño del paso del barrido para reducir número de frames.\n    \"\"\"\n    # Imagen 2D sintética: patrón tipo \"checkerboard\" + blobs\n    yy, xx = np.meshgrid(np.arange(H), np.arange(W), indexing=\"ij\")\n    tablero = (((xx // 6) % 2) ^ ((yy // 6) % 2)).astype(np.float32)\n    blob1 = np.exp(-((xx-14)**2 + (yy-18)**2)/(2*5.0**2))\n    blob2 = np.exp(-((xx-34)**2 + (yy-30)**2)/(2*7.0**2))\n    img = normalize01(0.6*tablero + 0.9*blob1 + 0.8*blob2)\n\n    # Kernel 2D: Gaussiano suave (simétrico y normalizado)\n    g1d = np.hanning(ksize)\n    g2d = np.outer(g1d, g1d)\n    kernel = g2d / (np.sum(g2d) + 1e-12)\n\n    # Convolución completa (para escala/guía)\n    y_full = convolve2d(img, kernel, mode=\"same\", boundary=\"fill\", fillvalue=0.0)\n    y_full_n = normalize01(y_full)\n\n    # Preparación para animación\n    frames = []\n    pad = ksize // 2\n    padded = np.pad(img, pad_width=pad, mode=\"constant\", constant_values=0.0)\n    out = np.zeros_like(img, dtype=np.float32)\n\n    # Barrido fila-columna con paso 'step'\n    H_range = range(0, H, step)\n    W_range = range(0, W, step)\n\n    for r in H_range:\n        for c in W_range:\n            # Ventana y valor de salida en (r,c)\n            ventana = padded[r:r+ksize, c:c+ksize]\n            val = np.sum(ventana * kernel[::-1, ::-1])  # conv: kernel volteado\n            out[r, c] = val\n\n            # Dibujo\n            fig, axs = plt.subplots(1, 2, figsize=(8.6, 4.6), dpi=dpi, constrained_layout=True)\n\n            # Izquierda: imagen con ventana actual\n            axs[0].imshow(img, vmin=0, vmax=1, interpolation=\"nearest\")\n            axs[0].set_title(\"Entrada: imagen 2D\\n(Ventana del kernel)\")\n            rect = Rectangle(\n                (max(c-pad, 0), max(r-pad, 0)),\n                width=min(ksize, W - max(c-pad, 0)),\n                height=min(ksize, H - max(r-pad, 0)),\n                fill=False, linewidth=2\n            )\n            axs[0].add_patch(rect)\n            axs[0].set_xticks([]); axs[0].set_yticks([])\n\n            # Derecha: salida acumulada con referencia semitransparente\n            out_n = normalize01(out)\n            axs[1].imshow(y_full_n, vmin=0, vmax=1, interpolation=\"nearest\", alpha=0.35)\n            im = axs[1].imshow(out_n, vmin=0, vmax=1, interpolation=\"nearest\")\n            axs[1].set_title(\"Salida de la convolución (acumulada)\")\n            axs[1].set_xticks([]); axs[1].set_yticks([])\n\n            # Barra de color pequeña\n            cbar = plt.colorbar(im, ax=axs[1], fraction=0.046, pad=0.04)\n            cbar.set_label(\"Intensidad (norm.)\", rotation=90)\n\n            frame = fig_to_rgb_array(fig)\n            plt.close(fig)\n            frames.append(frame)\n\n    imageio.mimsave(archivo_salida, frames, duration=1.0/fps, loop=0)\n    print(f\"[OK] GIF 2D guardado en: {archivo_salida}\")\n\n# ---------- Main ----------\nif __name__ == \"__main__\":\n    # Ajusta parámetros si deseas GIFs más/menos fluidos o ligeros\n    generar_gif_convolucion_1d(\n        n=140,\n        fps=20,\n        archivo_salida=\"convolucion_1d.gif\",\n        dpi=120\n    )\n\n    generar_gif_convolucion_2d(\n        H=48, W=48,\n        ksize=7,\n        step=2,          # aumenta para menos frames (p.ej., 3 o 4)\n        fps=16,\n        archivo_salida=\"convolucion_2d.gif\",\n        dpi=120\n    )\n\n[OK] GIF 1D guardado en: convolucion_1d.gif\n\n\n\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport numpy as np\nimport imageio.v2 as imageio\nimport matplotlib\nmatplotlib.use(\"Agg\")  # WSL/headless\nimport matplotlib.pyplot as plt\n\nIMG_SIZE = 28\nKERNEL_NAME = \"edge\"   # \"blur\" | \"sharpen\" | \"edge\" | \"gauss\"\nK = 5\nSTRIDE = 2\nFPS = 12\nOUT_GIF = \"convolution_demo.gif\"\nCMAP = \"gray\"\nFIG_DPI = 120\n\ndef make_test_image(n=IMG_SIZE, seed=42):\n    rng = np.random.default_rng(seed)\n    img = np.zeros((n, n), dtype=float)\n    y = np.linspace(0, 1, n).reshape(n, 1)\n    x = np.linspace(0, 1, n).reshape(1, n)\n    img += 0.25 * (x + y)\n    s = n // 3\n    img[n//4:n//4 + s, n//5:n//5 + s] += 0.6\n    for r in range(3, n, 6):\n        img[r:r+1, :] += 0.25\n    for c in range(5, n, 7):\n        img[:, c:c+1] += 0.25\n    img += 0.05 * rng.standard_normal((n, n))\n    return np.clip(img, 0, 1)\n\ndef make_kernel(name=\"edge\", k=5):\n    assert k % 2 == 1, \"El kernel debe ser impar.\"\n    if name == \"blur\":\n        ker = np.ones((k, k), dtype=float) / (k * k)\n    elif name == \"sharpen\":\n        ker = -np.ones((k, k), dtype=float); ker[k//2, k//2] = (k * k); ker /= (k * k)\n    elif name == \"edge\":\n        ker = -np.ones((k, k), dtype=float); ker[k//2, k//2] = (k * k - 1); ker /= (k * k)\n    elif name == \"gauss\":\n        sigma = k / 3.0\n        ax = np.arange(-(k//2), k//2 + 1)\n        xx, yy = np.meshgrid(ax, ax)\n        ker = np.exp(-(xx**2 + yy**2) / (2 * sigma**2)); ker /= ker.sum()\n    else:\n        raise ValueError(\"Kernel no reconocido.\")\n    return ker\n\ndef fig_to_rgb_array(fig):\n    # Compatibilidad Matplotlib &gt;= 3.9 (usa buffer_rgba)\n    fig.canvas.draw()\n    buf = np.asarray(fig.canvas.buffer_rgba())   # (H, W, 4) RGBA\n    return buf[..., :3].copy()                   # descartar alfa\n\ndef convolve_and_frames(img, ker, stride=1):\n    H, W = img.shape\n    kH, kW = ker.shape\n    outH = (H - kH) // stride + 1\n    outW = (W - kW) // stride + 1\n\n    out = np.zeros((outH, outW), dtype=float)\n    frames = []\n\n    fig = plt.figure(figsize=(8, 3), dpi=FIG_DPI)\n\n    for i_out, i in enumerate(range(0, H - kH + 1, stride)):\n        for j_out, j in enumerate(range(0, W - kW + 1, stride)):\n            patch = img[i:i + kH, j:j + kW]\n            val = float(np.sum(patch * ker))\n            out[i_out, j_out] = val\n\n            plt.clf()\n            ax1 = plt.subplot(1, 3, 1)\n            ax1.set_title(\"Entrada\")\n            ax1.imshow(img, cmap=CMAP, vmin=0, vmax=1)\n            rect = matplotlib.patches.Rectangle((j - 0.5, i - 0.5), kW, kH,\n                                                fill=False, linewidth=2, edgecolor=\"red\")\n            ax1.add_patch(rect); ax1.set_xticks([]); ax1.set_yticks([])\n\n            ax2 = plt.subplot(1, 3, 2)\n            ax2.set_title(\"Kernel\")\n            kmax = np.max(np.abs(ker))\n            ax2.imshow(ker, cmap=\"bwr\", vmin=-kmax, vmax=kmax)\n            for r in range(kH):\n                for c in range(kW):\n                    ax2.text(c, r, f\"{ker[r,c]:.2f}\", ha=\"center\", va=\"center\", fontsize=7)\n            ax2.set_xticks([]); ax2.set_yticks([])\n\n            ax3 = plt.subplot(1, 3, 3)\n            ax3.set_title(\"Salida (acumulada)\")\n            shown = out.copy()\n            lo, hi = np.percentile(shown, [5, 95])\n            if hi - lo &lt; 1e-6:\n                lo, hi = shown.min(), shown.max() + 1e-6\n            ax3.imshow(np.clip((shown - lo) / (hi - lo), 0, 1), cmap=CMAP, vmin=0, vmax=1)\n            ax3.set_xticks([]); ax3.set_yticks([])\n            ax3.text(0.02, 0.95, f\"pos=({i},{j}) → {val:.3f}\", transform=ax3.transAxes,\n                     fontsize=8, bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"none\"))\n\n            plt.tight_layout()\n            frames.append(fig_to_rgb_array(fig))\n\n    plt.close(fig)\n    return frames\n\ndef main():\n    img = make_test_image(IMG_SIZE)\n    ker = make_kernel(KERNEL_NAME, K)\n    frames = convolve_and_frames(img, ker, stride=STRIDE)\n    imageio.mimsave(OUT_GIF, frames, fps=FPS, loop=0)\n    print(f\"Listo. GIF guardado en: {OUT_GIF}\")\n    print(f\"Imagen: {IMG_SIZE}x{IMG_SIZE} | Kernel: {KERNEL_NAME} ({K}x{K}) | Stride: {STRIDE} | Frames: {len(frames)}\")\n\nif __name__ == \"__main__\":\n    main()\n\nListo. GIF guardado en: convolution_demo.gif\nImagen: 28x28 | Kernel: edge (5x5) | Stride: 2 | Frames: 144"
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Este documento presenta la resolución justificada de cada pregunta del cuestionario, sirviendo como una herramienta didáctica para reforzar los conceptos fundamentales del procesamiento de señales en el ámbito biomédico.\n\n\n\n\nEnunciado: En un laboratorio de neurofisiología, se registra la actividad eléctrica de una neurona individual mediante un microelectrodo. La señal registrada, \\(v(t)\\), corresponde a un potencial de acción, el cual es un pulso de voltaje que se puede modelar como una señal de energía finita y duración limitada. Desde la perspectiva de la teoría de señales, ¿cómo se clasificaría esta señal \\(v(t)\\)?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEl concepto clave aquí es la distinción entre señales de energía y señales de potencia.\n\nUna señal de energía \\(v(t)\\) es aquella cuya energía total \\(E\\) es finita (\\(0 &lt; E &lt; \\infty\\)). La energía se calcula como:\n\\[E = \\int_{-\\infty}^{\\infty} |v(t)|^2 dt\\]\nUna señal de potencia es aquella cuya energía total es infinita, pero su potencia promedio \\(P\\) es finita (\\(0 &lt; P &lt; \\infty\\)).\n\nJustificación Didáctica:\nDado que el potencial de acción es un pulso de voltaje con duración limitada (unos pocos milisegundos) y amplitud finita, el área bajo el cuadrado de su curva es necesariamente finita. Es decir, cumple la condición de energía finita. Aunque una neurona genere múltiples potenciales (lo que llevaría a una señal de potencia), el potencial de acción individual se modela como una señal de energía. Las opciones A, C y D son incorrectas porque:\n* A. Confunde el pulso individual con el proceso estocástico de trenes de potenciales.\n* C. La naturaleza determinística es independiente de la clasificación por energía/potencia.\n* D. Aunque el momento de ocurrencia puede ser aleatorio, la forma del pulso en sí es la que se clasifica.\n\n\n\n\n\n\nEnunciado: Durante el análisis de una señal de electromiografía (EMG) para evaluar la fatiga muscular, un ingeniero aplica una transformación para invertir el registro en el tiempo y analizar la simetría de la activación muscular. Si la señal original es \\(s(t)\\), ¿cuál de las siguientes operaciones representa correctamente la inversión temporal de la señal?\n\n\nRespuesta Correcta: D\n\n\nAnálisis Conceptual:\nLa inversión temporal o “plegado” de una señal \\(s(t)\\) se realiza sustituyendo la variable independiente \\(t\\) por \\(-t\\). Esto significa que el valor de la señal en el tiempo \\(-t\\) en la señal transformada es igual al valor de la señal en el tiempo \\(t\\) en la señal original.\nJustificación Didáctica:\nLa operación \\(s(-t)\\) refleja la señal \\(s(t)\\) respecto al eje vertical (\\(t=0\\)).\n* A. \\(s(t-t_{0})\\) representa un desplazamiento temporal (retraso si \\(t_{0}&gt;0\\)).\n* B. \\(s(at)\\) con \\(a&gt;1\\) representa una compresión temporal (escalamiento en el tiempo).\n* C. \\(as(t)\\) representa un escalamiento en amplitud.\nLa única que invierte el eje temporal es \\(s(-t)\\). Este concepto es fundamental para la definición de simetría (par/impar) en señales.\n\n\n\n\n\n\nEnunciado: Un sistema de monitoreo de electrocardiografía (ECG) está diseñado para detectar arritmias. El sistema se considera causal porque la detección de una arritmia en un instante \\(t_{o}\\) solo puede depender de los valores del ECG \\(x(t)\\) para \\(t\\le t_{0}\\). Si la entrada al sistema es la señal de ECG \\(x(t)\\) y la salida es una señal de alerta \\(y(t)\\) ¿cuál de las siguientes ecuaciones de entrada-salida describe un sistema que NO es causal?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nUn sistema es causal si su salida en cualquier instante \\(t\\) depende únicamente de los valores de la entrada en el instante actual (\\(t\\)) y en instantes pasados (\\(t&lt;t\\)). Si la salida depende de valores futuros (\\(t'&gt;t\\)) de la entrada, el sistema es no causal (o anticipatorio). Los sistemas físicos en tiempo real deben ser causales.\nJustificación Didáctica:\n* A. \\(y(t)=x(t)+x(t-1)\\): Depende del valor actual (\\(t\\)) y de un valor pasado (\\(t-1\\)). Causal.\n* B. \\(y(t)=\\int_{-\\infty}^{t}x(\\tau)d\\tau\\): La integral solo usa valores de la entrada \\(x(\\tau)\\) desde \\(-\\infty\\) hasta el tiempo actual \\(t\\). Causal.\n* C. \\(y(t)=x(t+1)\\): La salida en el tiempo \\(t\\) depende del valor de la entrada en el tiempo futuro \\(t+1\\). No Causal.\n* D. \\(y(t)=x^{2}(t)\\): Depende solo del valor actual \\(x(t)\\). Causal.\n\n\n\n\n\n\nEnunciado: Para calibrar un equipo de imagen por resonancia magnética (IRM), se utiliza una señal de prueba que representa un pulso de radiofrecuencia idealmente instantáneo y de área unitaria en \\(t=0\\). Este tipo de señal es fundamental para caracterizar la respuesta al impulso del sistema de adquisición. ¿Qué función matemática modela mejor esta señal de prueba ideal?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nLa función Delta de Dirac \\(\\delta(t)\\) es la representación matemática de un impulso unitario ideal. Se define por dos propiedades fundamentales:\n1. Es cero en todo punto excepto en el origen: \\(\\delta(t)=0\\) para \\(t \\neq 0\\).\n2. Tiene un área unitaria: \\(\\int_{-\\infty}^{\\infty} \\delta(t) dt = 1\\).\nJustificación Didáctica:\nLa descripción “pulso… idealmente instantáneo y de área unitaria” define precisamente al Delta de Dirac.\n* A. El escalón unitario, \\(u(t)\\), es 0 para \\(t&lt;0\\) y 1 para \\(t \\ge 0\\), no es un pulso.\n* B. La rampa unitaria, \\(r(t)\\), es 0 para \\(t&lt;0\\) y \\(t\\) para \\(t \\ge 0\\).\n* D. El pulso rectangular, \\(rect(t)\\), es un pulso de duración y amplitud finita.\nEl concepto de respuesta al impulso (\\(\\delta(t)\\)) es crucial, ya que si se conoce, se puede determinar la salida de cualquier sistema LTI mediante la convolución.\n\n\n\n\n\n\nEnunciado: En la monitorización fetal, la frecuencia cardíaca del feto se registra a lo largo del tiempo, generando una señal \\(f[n]\\). Para detectar una posible bradicardia, un algoritmo calcula el promedio de la frecuencia cardíaca en una ventana de N muestras. Este proceso se puede describir como un sistema que, para cada instante n, produce una salida \\(y[n]\\) promediando las N muestras anteriores, incluida la actual. ¿Cómo se clasifica este sistema de promediado?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nEl sistema de promediado de \\(N\\) muestras anteriores se modela como:\n\\[y[n] = \\frac{1}{N} \\sum_{k=n-N+1}^{n} x[k]\\]\nSe debe evaluar la Linealidad y la Invarianza en el Tiempo (Time-Invariance).\n\nLinealidad: Un sistema es lineal si cumple con la superposición (aditividad y homogeneidad). Dado que el operador de suma y el escalamiento por \\(\\frac{1}{N}\\) son operaciones lineales, el sistema es Lineal. Por ejemplo, si \\(x_3[n] = a x_1[n] + b x_2[n]\\), entonces \\(y_3[n] = a y_1[n] + b y_2[n]\\).\nInvarianza en el Tiempo: Un sistema es invariante en el tiempo si un retardo en la entrada (\\(x[n-n_0]\\)) causa un retardo idéntico en la salida (\\(y[n-n_0]\\)). Dado que los coeficientes de la suma (\\(\\frac{1}{N}\\)) son constantes y no dependen de \\(n\\), la relación entrada-salida no cambia con el tiempo. El sistema es Invariante en el Tiempo.\n\nJustificación Didáctica:\nEl filtro de promedio móvil es un ejemplo canónico de un sistema LTI (Lineal e Invariante en el Tiempo) en tiempo discreto.\n\n\n\n\n\n\nEnunciado: Un ingeniero está diseñando un marcapasos cuyo algoritmo de estimulación debe activarse si el ritmo cardíaco del paciente, \\(x(t)\\), cae por debajo de un umbral U y permanece así durante un tiempo \\(\\Delta T.\\) La salida del sistema, \\(y(t)\\), es 1 (activar estimulación) o 0 (no activar). Este sistema debe cumplir con la propiedad de memoria, ya que necesita “recordar” el comportamiento pasado de \\(x(t)\\) para tomar una decisión. ¿Cuál de las siguientes operaciones describe un sistema CON memoria?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nUn sistema tiene memoria si su salida en el instante \\(t\\) depende de valores de la entrada en instantes diferentes al instante \\(t\\). Si la salida en \\(t\\) depende solo del valor de la entrada en \\(t\\), el sistema es sin memoria (o instantáneo).\nJustificación Didáctica:\nEl requisito de “recordar” el pasado es la definición de un sistema con memoria.\n* A. \\(y(t)=5x(t)\\): Depende solo de \\(x(t)\\). Sin memoria.\n* B. \\(y(t)=x(t)^{2}-x(t)\\): Depende solo de \\(x(t)\\). Sin memoria (aunque es no lineal).\n* C. \\(y(t)=\\frac{1}{\\Delta T}\\int_{t-\\Delta T}^{t}x(\\tau)d\\tau\\): Esta es una integral de promedio móvil. La salida en \\(t\\) depende de los valores de la entrada \\(x(\\tau)\\) en el intervalo \\([t-\\Delta T, t]\\), es decir, de valores pasados. Con memoria.\n* D. \\(y(t)=\\begin{cases}1&si~x(t)&lt;U\\\\ 0&si~x(t)\\ge U\\end{cases}\\): Depende solo de \\(x(t)\\). Sin memoria (aunque es no lineal).\nLa operación en C requiere almacenar o integrar valores pasados, lo que didácticamente ejemplifica un sistema con memoria.\n\n\n\n\n\n\nEnunciado: Para digitalizar una señal de electroencefalografía (EEG) que contiene componentes de frecuencia relevantes hasta los \\(100\\) Hz, un investigador debe seleccionar una frecuencia de muestreo \\((f_{s})\\) adecuada para evitar el fenómeno de aliasing y garantizar una reconstrucción fiel de la señal. Según el teorema de Nyquist-Shannon, ¿cuál es la frecuencia de muestreo MÍNIMA que debería utilizar?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nEl Teorema de Muestreo de Nyquist-Shannon establece que para reconstruir de forma única y sin ambigüedades una señal de tiempo continuo que está limitada en banda a una frecuencia máxima \\(f_{max}\\), la frecuencia de muestreo \\(f_{s}\\) debe ser estrictamente mayor que el doble de esa frecuencia máxima:\n\\[f_{s} &gt; 2 f_{max}\\]\nEl valor \\(2 f_{max}\\) se conoce como la tasa de Nyquist.\nJustificación Didáctica:\nLa frecuencia máxima de interés es \\(f_{max} = 100 \\text{ Hz}\\).\nLa frecuencia de muestreo mínima requerida (tasa de Nyquist) es \\(f_{Nyquist} = 2 \\times 100 \\text{ Hz} = 200 \\text{ Hz}\\).\nPara evitar el aliasing, la frecuencia de muestreo debe ser \\(f_{s} &gt; 200 \\text{ Hz}\\). De las opciones proporcionadas, \\(200 \\text{ Hz}\\) es el límite inferior y, en el contexto de selección múltiple, es la respuesta que corresponde a la tasa mínima teórica. En la práctica se usa una frecuencia mayor (e.g., \\(2.2 f_{max}\\)).\n\n\n\n\n\n\nEnunciado: Un oxímetro de pulso mide la saturación de oxígeno en sangre \\((SpO_{2})\\) generando una señal pletismográfica. Esta señal analógica es muestreada por un conversor analógico-digital (ADC) de 12 bits. Suponiendo que el rango de voltaje de entrada del ADC es de 0 a 5 V, ¿cuál es la resolución de cuantificación del sistema, es decir, el cambio de voltaje más pequeño que puede detectar?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nLa resolución de cuantificación (\\(\\Delta V\\) o Step Size) es el cambio de voltaje más pequeño que el ADC puede distinguir. Se calcula como la división del rango de voltaje total (\\(V_{rango}\\)) entre el número de niveles de cuantificación (\\(L\\)).\n* El rango de voltaje es \\(V_{rango} = V_{max} - V_{min} = 5 \\text{ V} - 0 \\text{ V} = 5 \\text{ V}\\).\n* Para un ADC de \\(B\\) bits, el número de niveles distintos es \\(L = 2^B\\). Para 12 bits, \\(L = 2^{12} = 4096\\).\nFórmula de Resolución:\n\\[\\Delta V = \\frac{V_{rango}}{L-1} \\quad \\text{o} \\quad \\Delta V = \\frac{V_{rango}}{2^B-1}\\]\nJustificación Didáctica:\nLa justificación de usar \\(2^B-1\\) en lugar de \\(2^B\\) es que \\(2^B\\) es el número de niveles, pero el número de intervalos o pasos entre \\(V_{min}\\) y \\(V_{max}\\) es uno menos que el número de niveles, ya que se incluye el nivel de \\(0 \\text{ V}\\) y el nivel de \\(5 \\text{ V}\\). Es el cambio de voltaje entre el nivel más bajo y el más alto. Por lo tanto, \\(\\Delta V = \\frac{5 \\text{ V}}{2^{12}-1}\\). La opción B es común para aproximaciones didácticas, pero C es la formulación rigurosa para un rango de \\(V_{min}\\) a \\(V_{max}\\).\n\n\n\n\n\n\nEnunciado: Un investigador adquiere una señal de ECG a una frecuencia de muestreo \\(f_{s}=500\\) Hz. En el análisis espectral, observa un pico de alta amplitud a 60 Hz, correspondiente a la interferencia de la red eléctrica. Para eliminar esta interferencia, decide aplicar un filtro digital. Sin embargo, por un error en la configuración del muestreo, la señal de ECG original tenía un componente de \\(440\\) Hz que no fue pre-filtrado analógicamente. ¿A qué frecuencia aparecerá este componente de \\(440\\) Hz en la señal digitalizada debido al aliasing?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEl aliasing ocurre cuando una componente de frecuencia \\(f\\) en la señal analógica es mayor que la frecuencia de Nyquist (\\(f_{Nyquist} = f_{s}/2\\)). En el dominio discreto, esta frecuencia “se pliega” o “se refleja” en una frecuencia aparente \\(f_{alias}\\) en el rango \\([0, f_{s}/2]\\).\nLa frecuencia aliada se calcula encontrando el múltiplo de \\(f_{s}\\) más cercano a \\(f\\): \\(f_{s} \\cdot m\\).\nLa frecuencia aparente es:\n\\[f_{alias} = |f - m \\cdot f_{s}|\\]\ndonde \\(m\\) es el entero que minimiza \\(|f - m \\cdot f_{s}|\\).\nCálculo Didáctico:\n* Frecuencia de la señal no filtrada: \\(f = 440 \\text{ Hz}\\).\n* Frecuencia de muestreo: \\(f_{s} = 500 \\text{ Hz}\\).\n* La frecuencia de Nyquist es \\(f_{s}/2 = 250 \\text{ Hz}\\). Como \\(440 \\text{ Hz} &gt; 250 \\text{ Hz}\\), habrá aliasing.\nEl múltiplo de \\(f_{s}\\) más cercano a \\(440 \\text{ Hz}\\) es \\(m=1\\), donde \\(1 \\cdot f_{s} = 500 \\text{ Hz}\\).\n\\[f_{alias} = |440 \\text{ Hz} - 500 \\text{ Hz}| = |-60 \\text{ Hz}| = 60 \\text{ Hz}\\]\nJustificación Didáctica:\nEl componente de \\(440 \\text{ Hz}\\) se refleja en \\(60 \\text{ Hz}\\) en el espectro digital. Este resultado es didácticamente significativo, ya que muestra cómo una interferencia de alta frecuencia puede superponerse a frecuencias de interés o, en este caso, a otra interferencia conocida (la de \\(60 \\text{ Hz}\\) de la red eléctrica), complicando la interpretación y el filtrado posterior. Esto subraya la importancia de un filtro anti-aliasing analógico (paso bajo) antes de la conversión A/D.\n\n\n\n\n\n\nEnunciado: Para eliminar el ruido de alta frecuencia de una señal de electromiografía (EMG) digitalizada, se decide usar un filtro de respuesta finita al impulso (FIR). Una de las principales ventajas de los filtros FIR en aplicaciones biomédicas es que pueden ser diseñados para tener una fase perfectamente lineal. ¿Por qué esta característica es crucial para el análisis de señales biomédicas como el EMG o el ECG?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nLa fase lineal en un filtro digital implica que el retardo de grupo (Group Delay) es constante para todas las frecuencias. El retardo de grupo \\(\\tau_g(\\omega)\\) mide el retardo que experimenta la envolvente de las componentes de frecuencia, y se calcula como:\n\\[\\tau_g(\\omega) = - \\frac{d\\phi(\\omega)}{d\\omega}\\]\ndonde \\(\\phi(\\omega)\\) es la respuesta de fase. Si \\(\\phi(\\omega)\\) es lineal, su derivada es constante.\nJustificación Didáctica:\n* La distorsión de fase ocurre cuando diferentes componentes de frecuencia de una señal sufren diferentes retardos temporales al pasar por el filtro. Esto distorsiona la forma de onda original de la señal.\n* En señales biomédicas como el ECG o el potencial de acción (PA), la forma de la onda y la relación temporal entre picos (como el complejo QRS en el ECG) son cruciales para el diagnóstico.\n* Una fase lineal asegura que todas las componentes de frecuencia se retrasen por el mismo tiempo constante (retardo de grupo constante), lo que preserva la morfología temporal de la señal (no hay dispersión de las componentes) y evita la distorsión de fase.\nLas opciones A, C y D son incorrectas: A. Es una propiedad computacional, no de fidelidad de la señal. C. La fase lineal no tiene relación con el tipo de banda (paso-bajo/alto/banda-rechazo). D. Esta es una propiedad de la respuesta de magnitud, no de la fase."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-1-clasificación-de-señales-potencial-de-acción",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-1-clasificación-de-señales-potencial-de-acción",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: En un laboratorio de neurofisiología, se registra la actividad eléctrica de una neurona individual mediante un microelectrodo. La señal registrada, \\(v(t)\\), corresponde a un potencial de acción, el cual es un pulso de voltaje que se puede modelar como una señal de energía finita y duración limitada. Desde la perspectiva de la teoría de señales, ¿cómo se clasificaría esta señal \\(v(t)\\)?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEl concepto clave aquí es la distinción entre señales de energía y señales de potencia.\n\nUna señal de energía \\(v(t)\\) es aquella cuya energía total \\(E\\) es finita (\\(0 &lt; E &lt; \\infty\\)). La energía se calcula como:\n\\[E = \\int_{-\\infty}^{\\infty} |v(t)|^2 dt\\]\nUna señal de potencia es aquella cuya energía total es infinita, pero su potencia promedio \\(P\\) es finita (\\(0 &lt; P &lt; \\infty\\)).\n\nJustificación Didáctica:\nDado que el potencial de acción es un pulso de voltaje con duración limitada (unos pocos milisegundos) y amplitud finita, el área bajo el cuadrado de su curva es necesariamente finita. Es decir, cumple la condición de energía finita. Aunque una neurona genere múltiples potenciales (lo que llevaría a una señal de potencia), el potencial de acción individual se modela como una señal de energía. Las opciones A, C y D son incorrectas porque:\n* A. Confunde el pulso individual con el proceso estocástico de trenes de potenciales.\n* C. La naturaleza determinística es independiente de la clasificación por energía/potencia.\n* D. Aunque el momento de ocurrencia puede ser aleatorio, la forma del pulso en sí es la que se clasifica."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-2-operaciones-sobre-señales-inversión-temporal",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-2-operaciones-sobre-señales-inversión-temporal",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: Durante el análisis de una señal de electromiografía (EMG) para evaluar la fatiga muscular, un ingeniero aplica una transformación para invertir el registro en el tiempo y analizar la simetría de la activación muscular. Si la señal original es \\(s(t)\\), ¿cuál de las siguientes operaciones representa correctamente la inversión temporal de la señal?\n\n\nRespuesta Correcta: D\n\n\nAnálisis Conceptual:\nLa inversión temporal o “plegado” de una señal \\(s(t)\\) se realiza sustituyendo la variable independiente \\(t\\) por \\(-t\\). Esto significa que el valor de la señal en el tiempo \\(-t\\) en la señal transformada es igual al valor de la señal en el tiempo \\(t\\) en la señal original.\nJustificación Didáctica:\nLa operación \\(s(-t)\\) refleja la señal \\(s(t)\\) respecto al eje vertical (\\(t=0\\)).\n* A. \\(s(t-t_{0})\\) representa un desplazamiento temporal (retraso si \\(t_{0}&gt;0\\)).\n* B. \\(s(at)\\) con \\(a&gt;1\\) representa una compresión temporal (escalamiento en el tiempo).\n* C. \\(as(t)\\) representa un escalamiento en amplitud.\nLa única que invierte el eje temporal es \\(s(-t)\\). Este concepto es fundamental para la definición de simetría (par/impar) en señales."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-3-clasificación-de-sistemas-causalidad",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-3-clasificación-de-sistemas-causalidad",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: Un sistema de monitoreo de electrocardiografía (ECG) está diseñado para detectar arritmias. El sistema se considera causal porque la detección de una arritmia en un instante \\(t_{o}\\) solo puede depender de los valores del ECG \\(x(t)\\) para \\(t\\le t_{0}\\). Si la entrada al sistema es la señal de ECG \\(x(t)\\) y la salida es una señal de alerta \\(y(t)\\) ¿cuál de las siguientes ecuaciones de entrada-salida describe un sistema que NO es causal?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nUn sistema es causal si su salida en cualquier instante \\(t\\) depende únicamente de los valores de la entrada en el instante actual (\\(t\\)) y en instantes pasados (\\(t&lt;t\\)). Si la salida depende de valores futuros (\\(t'&gt;t\\)) de la entrada, el sistema es no causal (o anticipatorio). Los sistemas físicos en tiempo real deben ser causales.\nJustificación Didáctica:\n* A. \\(y(t)=x(t)+x(t-1)\\): Depende del valor actual (\\(t\\)) y de un valor pasado (\\(t-1\\)). Causal.\n* B. \\(y(t)=\\int_{-\\infty}^{t}x(\\tau)d\\tau\\): La integral solo usa valores de la entrada \\(x(\\tau)\\) desde \\(-\\infty\\) hasta el tiempo actual \\(t\\). Causal.\n* C. \\(y(t)=x(t+1)\\): La salida en el tiempo \\(t\\) depende del valor de la entrada en el tiempo futuro \\(t+1\\). No Causal.\n* D. \\(y(t)=x^{2}(t)\\): Depende solo del valor actual \\(x(t)\\). Causal."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-4-señales-fundamentales-pulso-ideal",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-4-señales-fundamentales-pulso-ideal",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: Para calibrar un equipo de imagen por resonancia magnética (IRM), se utiliza una señal de prueba que representa un pulso de radiofrecuencia idealmente instantáneo y de área unitaria en \\(t=0\\). Este tipo de señal es fundamental para caracterizar la respuesta al impulso del sistema de adquisición. ¿Qué función matemática modela mejor esta señal de prueba ideal?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nLa función Delta de Dirac \\(\\delta(t)\\) es la representación matemática de un impulso unitario ideal. Se define por dos propiedades fundamentales:\n1. Es cero en todo punto excepto en el origen: \\(\\delta(t)=0\\) para \\(t \\neq 0\\).\n2. Tiene un área unitaria: \\(\\int_{-\\infty}^{\\infty} \\delta(t) dt = 1\\).\nJustificación Didáctica:\nLa descripción “pulso… idealmente instantáneo y de área unitaria” define precisamente al Delta de Dirac.\n* A. El escalón unitario, \\(u(t)\\), es 0 para \\(t&lt;0\\) y 1 para \\(t \\ge 0\\), no es un pulso.\n* B. La rampa unitaria, \\(r(t)\\), es 0 para \\(t&lt;0\\) y \\(t\\) para \\(t \\ge 0\\).\n* D. El pulso rectangular, \\(rect(t)\\), es un pulso de duración y amplitud finita.\nEl concepto de respuesta al impulso (\\(\\delta(t)\\)) es crucial, ya que si se conoce, se puede determinar la salida de cualquier sistema LTI mediante la convolución."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-5-clasificación-de-sistemas-linealidad-e-invarianza-temporal",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-5-clasificación-de-sistemas-linealidad-e-invarianza-temporal",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: En la monitorización fetal, la frecuencia cardíaca del feto se registra a lo largo del tiempo, generando una señal \\(f[n]\\). Para detectar una posible bradicardia, un algoritmo calcula el promedio de la frecuencia cardíaca en una ventana de N muestras. Este proceso se puede describir como un sistema que, para cada instante n, produce una salida \\(y[n]\\) promediando las N muestras anteriores, incluida la actual. ¿Cómo se clasifica este sistema de promediado?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nEl sistema de promediado de \\(N\\) muestras anteriores se modela como:\n\\[y[n] = \\frac{1}{N} \\sum_{k=n-N+1}^{n} x[k]\\]\nSe debe evaluar la Linealidad y la Invarianza en el Tiempo (Time-Invariance).\n\nLinealidad: Un sistema es lineal si cumple con la superposición (aditividad y homogeneidad). Dado que el operador de suma y el escalamiento por \\(\\frac{1}{N}\\) son operaciones lineales, el sistema es Lineal. Por ejemplo, si \\(x_3[n] = a x_1[n] + b x_2[n]\\), entonces \\(y_3[n] = a y_1[n] + b y_2[n]\\).\nInvarianza en el Tiempo: Un sistema es invariante en el tiempo si un retardo en la entrada (\\(x[n-n_0]\\)) causa un retardo idéntico en la salida (\\(y[n-n_0]\\)). Dado que los coeficientes de la suma (\\(\\frac{1}{N}\\)) son constantes y no dependen de \\(n\\), la relación entrada-salida no cambia con el tiempo. El sistema es Invariante en el Tiempo.\n\nJustificación Didáctica:\nEl filtro de promedio móvil es un ejemplo canónico de un sistema LTI (Lineal e Invariante en el Tiempo) en tiempo discreto."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-6-clasificación-de-sistemas-memoria",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-6-clasificación-de-sistemas-memoria",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: Un ingeniero está diseñando un marcapasos cuyo algoritmo de estimulación debe activarse si el ritmo cardíaco del paciente, \\(x(t)\\), cae por debajo de un umbral U y permanece así durante un tiempo \\(\\Delta T.\\) La salida del sistema, \\(y(t)\\), es 1 (activar estimulación) o 0 (no activar). Este sistema debe cumplir con la propiedad de memoria, ya que necesita “recordar” el comportamiento pasado de \\(x(t)\\) para tomar una decisión. ¿Cuál de las siguientes operaciones describe un sistema CON memoria?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nUn sistema tiene memoria si su salida en el instante \\(t\\) depende de valores de la entrada en instantes diferentes al instante \\(t\\). Si la salida en \\(t\\) depende solo del valor de la entrada en \\(t\\), el sistema es sin memoria (o instantáneo).\nJustificación Didáctica:\nEl requisito de “recordar” el pasado es la definición de un sistema con memoria.\n* A. \\(y(t)=5x(t)\\): Depende solo de \\(x(t)\\). Sin memoria.\n* B. \\(y(t)=x(t)^{2}-x(t)\\): Depende solo de \\(x(t)\\). Sin memoria (aunque es no lineal).\n* C. \\(y(t)=\\frac{1}{\\Delta T}\\int_{t-\\Delta T}^{t}x(\\tau)d\\tau\\): Esta es una integral de promedio móvil. La salida en \\(t\\) depende de los valores de la entrada \\(x(\\tau)\\) en el intervalo \\([t-\\Delta T, t]\\), es decir, de valores pasados. Con memoria.\n* D. \\(y(t)=\\begin{cases}1&si~x(t)&lt;U\\\\ 0&si~x(t)\\ge U\\end{cases}\\): Depende solo de \\(x(t)\\). Sin memoria (aunque es no lineal).\nLa operación en C requiere almacenar o integrar valores pasados, lo que didácticamente ejemplifica un sistema con memoria."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-7-muestreo-teorema-de-nyquist-shannon",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-7-muestreo-teorema-de-nyquist-shannon",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: Para digitalizar una señal de electroencefalografía (EEG) que contiene componentes de frecuencia relevantes hasta los \\(100\\) Hz, un investigador debe seleccionar una frecuencia de muestreo \\((f_{s})\\) adecuada para evitar el fenómeno de aliasing y garantizar una reconstrucción fiel de la señal. Según el teorema de Nyquist-Shannon, ¿cuál es la frecuencia de muestreo MÍNIMA que debería utilizar?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nEl Teorema de Muestreo de Nyquist-Shannon establece que para reconstruir de forma única y sin ambigüedades una señal de tiempo continuo que está limitada en banda a una frecuencia máxima \\(f_{max}\\), la frecuencia de muestreo \\(f_{s}\\) debe ser estrictamente mayor que el doble de esa frecuencia máxima:\n\\[f_{s} &gt; 2 f_{max}\\]\nEl valor \\(2 f_{max}\\) se conoce como la tasa de Nyquist.\nJustificación Didáctica:\nLa frecuencia máxima de interés es \\(f_{max} = 100 \\text{ Hz}\\).\nLa frecuencia de muestreo mínima requerida (tasa de Nyquist) es \\(f_{Nyquist} = 2 \\times 100 \\text{ Hz} = 200 \\text{ Hz}\\).\nPara evitar el aliasing, la frecuencia de muestreo debe ser \\(f_{s} &gt; 200 \\text{ Hz}\\). De las opciones proporcionadas, \\(200 \\text{ Hz}\\) es el límite inferior y, en el contexto de selección múltiple, es la respuesta que corresponde a la tasa mínima teórica. En la práctica se usa una frecuencia mayor (e.g., \\(2.2 f_{max}\\))."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-8-cuantificación-resolución-del-adc",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-8-cuantificación-resolución-del-adc",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: Un oxímetro de pulso mide la saturación de oxígeno en sangre \\((SpO_{2})\\) generando una señal pletismográfica. Esta señal analógica es muestreada por un conversor analógico-digital (ADC) de 12 bits. Suponiendo que el rango de voltaje de entrada del ADC es de 0 a 5 V, ¿cuál es la resolución de cuantificación del sistema, es decir, el cambio de voltaje más pequeño que puede detectar?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nLa resolución de cuantificación (\\(\\Delta V\\) o Step Size) es el cambio de voltaje más pequeño que el ADC puede distinguir. Se calcula como la división del rango de voltaje total (\\(V_{rango}\\)) entre el número de niveles de cuantificación (\\(L\\)).\n* El rango de voltaje es \\(V_{rango} = V_{max} - V_{min} = 5 \\text{ V} - 0 \\text{ V} = 5 \\text{ V}\\).\n* Para un ADC de \\(B\\) bits, el número de niveles distintos es \\(L = 2^B\\). Para 12 bits, \\(L = 2^{12} = 4096\\).\nFórmula de Resolución:\n\\[\\Delta V = \\frac{V_{rango}}{L-1} \\quad \\text{o} \\quad \\Delta V = \\frac{V_{rango}}{2^B-1}\\]\nJustificación Didáctica:\nLa justificación de usar \\(2^B-1\\) en lugar de \\(2^B\\) es que \\(2^B\\) es el número de niveles, pero el número de intervalos o pasos entre \\(V_{min}\\) y \\(V_{max}\\) es uno menos que el número de niveles, ya que se incluye el nivel de \\(0 \\text{ V}\\) y el nivel de \\(5 \\text{ V}\\). Es el cambio de voltaje entre el nivel más bajo y el más alto. Por lo tanto, \\(\\Delta V = \\frac{5 \\text{ V}}{2^{12}-1}\\). La opción B es común para aproximaciones didácticas, pero C es la formulación rigurosa para un rango de \\(V_{min}\\) a \\(V_{max}\\)."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-9-muestreo-aliasing",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-9-muestreo-aliasing",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: Un investigador adquiere una señal de ECG a una frecuencia de muestreo \\(f_{s}=500\\) Hz. En el análisis espectral, observa un pico de alta amplitud a 60 Hz, correspondiente a la interferencia de la red eléctrica. Para eliminar esta interferencia, decide aplicar un filtro digital. Sin embargo, por un error en la configuración del muestreo, la señal de ECG original tenía un componente de \\(440\\) Hz que no fue pre-filtrado analógicamente. ¿A qué frecuencia aparecerá este componente de \\(440\\) Hz en la señal digitalizada debido al aliasing?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEl aliasing ocurre cuando una componente de frecuencia \\(f\\) en la señal analógica es mayor que la frecuencia de Nyquist (\\(f_{Nyquist} = f_{s}/2\\)). En el dominio discreto, esta frecuencia “se pliega” o “se refleja” en una frecuencia aparente \\(f_{alias}\\) en el rango \\([0, f_{s}/2]\\).\nLa frecuencia aliada se calcula encontrando el múltiplo de \\(f_{s}\\) más cercano a \\(f\\): \\(f_{s} \\cdot m\\).\nLa frecuencia aparente es:\n\\[f_{alias} = |f - m \\cdot f_{s}|\\]\ndonde \\(m\\) es el entero que minimiza \\(|f - m \\cdot f_{s}|\\).\nCálculo Didáctico:\n* Frecuencia de la señal no filtrada: \\(f = 440 \\text{ Hz}\\).\n* Frecuencia de muestreo: \\(f_{s} = 500 \\text{ Hz}\\).\n* La frecuencia de Nyquist es \\(f_{s}/2 = 250 \\text{ Hz}\\). Como \\(440 \\text{ Hz} &gt; 250 \\text{ Hz}\\), habrá aliasing.\nEl múltiplo de \\(f_{s}\\) más cercano a \\(440 \\text{ Hz}\\) es \\(m=1\\), donde \\(1 \\cdot f_{s} = 500 \\text{ Hz}\\).\n\\[f_{alias} = |440 \\text{ Hz} - 500 \\text{ Hz}| = |-60 \\text{ Hz}| = 60 \\text{ Hz}\\]\nJustificación Didáctica:\nEl componente de \\(440 \\text{ Hz}\\) se refleja en \\(60 \\text{ Hz}\\) en el espectro digital. Este resultado es didácticamente significativo, ya que muestra cómo una interferencia de alta frecuencia puede superponerse a frecuencias de interés o, en este caso, a otra interferencia conocida (la de \\(60 \\text{ Hz}\\) de la red eléctrica), complicando la interpretación y el filtrado posterior. Esto subraya la importancia de un filtro anti-aliasing analógico (paso bajo) antes de la conversión A/D."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-10-filtros-digitales-fase-lineal",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-10-filtros-digitales-fase-lineal",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "",
    "text": "Enunciado: Para eliminar el ruido de alta frecuencia de una señal de electromiografía (EMG) digitalizada, se decide usar un filtro de respuesta finita al impulso (FIR). Una de las principales ventajas de los filtros FIR en aplicaciones biomédicas es que pueden ser diseñados para tener una fase perfectamente lineal. ¿Por qué esta característica es crucial para el análisis de señales biomédicas como el EMG o el ECG?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nLa fase lineal en un filtro digital implica que el retardo de grupo (Group Delay) es constante para todas las frecuencias. El retardo de grupo \\(\\tau_g(\\omega)\\) mide el retardo que experimenta la envolvente de las componentes de frecuencia, y se calcula como:\n\\[\\tau_g(\\omega) = - \\frac{d\\phi(\\omega)}{d\\omega}\\]\ndonde \\(\\phi(\\omega)\\) es la respuesta de fase. Si \\(\\phi(\\omega)\\) es lineal, su derivada es constante.\nJustificación Didáctica:\n* La distorsión de fase ocurre cuando diferentes componentes de frecuencia de una señal sufren diferentes retardos temporales al pasar por el filtro. Esto distorsiona la forma de onda original de la señal.\n* En señales biomédicas como el ECG o el potencial de acción (PA), la forma de la onda y la relación temporal entre picos (como el complejo QRS en el ECG) son cruciales para el diagnóstico.\n* Una fase lineal asegura que todas las componentes de frecuencia se retrasen por el mismo tiempo constante (retardo de grupo constante), lo que preserva la morfología temporal de la señal (no hay dispersión de las componentes) y evita la distorsión de fase.\nLas opciones A, C y D son incorrectas: A. Es una propiedad computacional, no de fidelidad de la señal. C. La fase lineal no tiene relación con el tipo de banda (paso-bajo/alto/banda-rechazo). D. Esta es una propiedad de la respuesta de magnitud, no de la fase."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-1-descomposición-de-señales-par-e-impar",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-1-descomposición-de-señales-par-e-impar",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "Pregunta 1: Descomposición de Señales Par e Impar",
    "text": "Pregunta 1: Descomposición de Señales Par e Impar\n\nEnunciado: En una prueba de vasodilatación cutánea, se registra una señal PPG \\(x(t)\\) libre de artefactos. Se construye \\(x_{par}(t)=\\frac{x(t)+x(-t)}{2}\\) y \\(x_{impar}(t)=\\frac{x(t)-x(-t)}{2}\\). ¿Cuál afirmación es siempre correcta para cualquier \\(x(t)\\)?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nCualquier señal \\(x(t)\\) puede descomponerse de manera única en la suma de una componente par (\\(x_{par}(t)\\)) y una componente impar (\\(x_{impar}(t)\\)): \\(x(t) = x_{par}(t) + x_{impar}(t)\\).\nJustificación Didáctica:\nLa descomposición garantiza que:\n1. La suma de las dos componentes reconstruye la señal original:\n\\[x_{par}(t) + x_{impar}(t) = \\frac{x(t)+x(-t)}{2} + \\frac{x(t)-x(-t)}{2} = \\frac{2x(t)}{2} = x(t)\\]\n2. Las componentes par e impar son ortogonales entre sí, lo que significa que el producto interno (o la integral de su producto) es cero sobre un rango simétrico.\nLas demás opciones son incorrectas, ya que la causalidad (A), la acotación (C), o la identidad de las componentes (D) no son propiedades universales de esta descomposición."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-2-transformaciones-combinadas-de-señales",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-2-transformaciones-combinadas-de-señales",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "Pregunta 2: Transformaciones Combinadas de Señales",
    "text": "Pregunta 2: Transformaciones Combinadas de Señales\n\nEnunciado: En un sistema de monitoreo de EMG, se define \\(y(t)=2\\cdot x(3t-0.1)+0.5\\). ¿Cuál describe correctamente las transformaciones respecto a \\(x(t)\\)?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nLa transformación temporal \\(x(at-t_0)\\) requiere factorizar el término \\(a\\) para identificar correctamente el desplazamiento:\n\\[x(3t - 0.1) = x(3(t - \\frac{0.1}{3}))\\]\nEl término temporal es \\(x(a(t-t_{d}))\\), donde \\(a=3\\) (escala temporal) y \\(t_{d} = 0.1/3 \\approx 0.0333\\) (desplazamiento).\nJustificación Didáctica:\nSiguiendo la jerarquía de transformaciones:\n1. \\(x(3t)\\): Compresión temporal por un factor de 3 (la señal se hace 3 veces más rápida).\n2. \\(x(3(t-0.1/3))\\): Desplazamiento a la derecha (retraso) por \\(0.1/3\\) segundos. El enunciado aproxima este desplazamiento al valor no factorizado de \\(0.1\\) y asume que es la compresión por 3. Es un error común en la didáctica de señales, pero la opción A es la única que tiene la secuencia correcta (Compresión, Derecha, x2, +0.5).\n3. \\(2\\cdot x(\\dots)\\): Escalamiento de amplitud por 2.\n4. \\(\\dots + 0.5\\): Desplazamiento vertical (DC offset) por \\(+0.5\\).\nA pesar de la ambigüedad en la magnitud del desplazamiento en el enunciado (0.1s en lugar de 0.0333s), la Compresión temporal por 3 y el desplazamiento a la derecha son correctos en relación a la estructura de la función original \\(x(3t-0.1)\\), ya que \\(3t-0.1=0 \\implies t=0.1/3\\) (tiempo de inicio). La opción A es la única que describe correctamente la compresión (factor \\(\\alpha &gt; 1\\)) y el sentido de las transformaciones."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-3-artefactos-en-señales-biomédicas-ppg",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-3-artefactos-en-señales-biomédicas-ppg",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "Pregunta 3: Artefactos en Señales Biomédicas (PPG)",
    "text": "Pregunta 3: Artefactos en Señales Biomédicas (PPG)\n\nEnunciado: Durante una prueba de esfuerzo, el acelerómetro de muñeca introduce variaciones de baja frecuencia en la PPG. ¿Qué tipo de “ruido” predomina?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEl PPG (Fotopletismografía) se registra comúnmente en la muñeca o el dedo. Las pruebas de esfuerzo implican movimiento. El movimiento causa un cambio en la presión del sensor sobre la piel y/o cambios en el volumen de sangre no relacionados con el pulso cardíaco.\nJustificación Didáctica:\nEste efecto se clasifica como un Artefacto de Movimiento (Motion Artifact). Típicamente, este artefacto se presenta como una modulación de la amplitud de la señal PPG y se caracteriza por contener componentes de muy baja frecuencia (típicamente \\(&lt; 2 \\text{ Hz}\\)), a menudo superponiéndose a las frecuencias relevantes de la señal."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-4-muestreo-frecuencia-mínima-aceptable-nyquist",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-4-muestreo-frecuencia-mínima-aceptable-nyquist",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "Pregunta 4: Muestreo: Frecuencia Mínima Aceptable (Nyquist)",
    "text": "Pregunta 4: Muestreo: Frecuencia Mínima Aceptable (Nyquist)\n\nEnunciado: Se adquiere ECG diagnóstico (contenido relevante \\(\\sim 0.05-150 \\text{ Hz}\\)). Para evitar aliasing, elija la frecuencia de muestreo mínima aceptable:\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nEl Teorema de Muestreo de Nyquist-Shannon requiere que la frecuencia de muestreo (\\(f_{s}\\)) sea estrictamente mayor que el doble de la frecuencia máxima (\\(f_{max}\\)) de la señal.\n\\[f_{s} &gt; 2 f_{max}\\]\nJustificación Didáctica:\nDado que la frecuencia máxima relevante es \\(f_{max} = 150 \\text{ Hz}\\), la tasa de Nyquist es \\(2 \\cdot 150 \\text{ Hz} = 300 \\text{ Hz}\\). Para garantizar la ausencia de aliasing, la frecuencia de muestreo debe ser mayor, pero de las opciones dadas, la frecuencia mínima aceptable es la tasa de Nyquist, \\(300 \\text{ Hz}\\). En la práctica, se utiliza un margen de seguridad (\\(f_{s} &gt; 300 \\text{ Hz}\\)), pero \\(300 \\text{ Hz}\\) es la respuesta teórica."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-5-cuantificación-impacto-del-número-de-bits",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-5-cuantificación-impacto-del-número-de-bits",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "Pregunta 5: Cuantificación: Impacto del Número de Bits",
    "text": "Pregunta 5: Cuantificación: Impacto del Número de Bits\n\nEnunciado: En un sistema de adquisición para EEG, se aumenta la resolución del ADC de 12 a 16 bits manteniendo el rango de entrada. ¿Cuál enunciado es más preciso?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nEl ruido de cuantización es el error introducido al discretizar la amplitud de una señal. La Potencia del Ruido de Cuantización (\\(P_Q\\)) es inversamente proporcional a \\(2^{2B}\\).\nJustificación Didáctica:\nLa relación Señal-a-Ruido de Cuantización (\\(SQNR\\)) ideal en un ADC está dada por \\(SQNR \\approx 6.02 B + 1.76 \\text{ dB}\\), donde \\(B\\) es el número de bits.\n* Aumentar la resolución en \\(1 \\text{ bit}\\) equivale a duplicar el número de niveles (\\(2^B \\to 2^{B+1}\\)), lo que incrementa la \\(SQNR\\) en aproximadamente \\(6 \\text{ dB}\\).\n* Un aumento de \\(12\\) a \\(16 \\text{ bits}\\) (\\(4 \\text{ bits}\\) adicionales) mejora el \\(SQNR\\) en \\(\\approx 24 \\text{ dB}\\), lo que se traduce en una disminución del ruido de cuantización de aproximadamente \\(6 \\text{ dB}\\) por bit adicional."
  },
  {
    "objectID": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-6-sistemas-de-diferencia-detección-de-cambios",
    "href": "recursos/talleres/SYSB/sol_parc_sysb2025ii.html#pregunta-6-sistemas-de-diferencia-detección-de-cambios",
    "title": "Resolución Detallada: Examen de Señales y Sistemas Biomédicos",
    "section": "Pregunta 6: Sistemas de Diferencia: Detección de Cambios",
    "text": "Pregunta 6: Sistemas de Diferencia: Detección de Cambios\n\nEnunciado: Un sistema lineal y causal de adquisición aplica \\(y(t)=x(t)-x(t-5ms)\\) a una señal PPG. Seleccione la opción correcta:\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nLa operación \\(y(t)=x(t)-x(t-\\Delta t)\\) es una diferencia finita de primer orden. Esta operación es una aproximación a la primera derivada de la señal, especialmente cuando \\(\\Delta t\\) es pequeño.\nJustificación Didáctica:\n* La derivación es una operación de filtrado pasa-alto (filtro de altas frecuencias), ya que amplifica las variaciones rápidas (altas frecuencias) y suprime las variaciones lentas (bajas frecuencias).\n* Este sistema, al ser una diferencia entre el valor actual y un valor pasado, actúa como un diferenciador discreto aproximado. Su efecto es realzar los cambios rápidos de la señal (por ejemplo, el peak sistólico en el PPG), lo que equivale a realzar las altas frecuencias."
  },
  {
    "objectID": "recursos/talleres/SYSB/Taller3_2025_1.html",
    "href": "recursos/talleres/SYSB/Taller3_2025_1.html",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Profesores\nJenny Carolina Castiblanco Sánchez\nPablo Eduardo Caicedo Rodríguez\n\n\nDescripción\nA través de este taller se reforzarán los conocimientos en:\n\nTransformada Z\nDiseño, análisis e implementación de filtros digitales FIR e IIR\n\n\n\nProcedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\nTransformada Z y Región de Convergencia\nDetermine la transformada Z y dibuje la ROC de las siguientes señales:\n\n\\(x\\left[n\\right] = =\\begin{cases}\\displaystyle \\left(\\frac{1}{3}\\right)^{n}, & n \\ge 0,\\\\[6pt]\\displaystyle \\left(\\frac{1}{2}\\right)^{-n}, & n &lt; 0.\\end{cases}\\)\n\\(x\\left[n\\right]=\\begin{cases}\\displaystyle \\left(\\frac{1}{3}\\right)^{n}, & n \\ge 5,\\\\[6pt]0, & n &lt; 5.\\end{cases}\\)\n\nRespuesta del Sistema\nDetermine la respuesta del sistema\n\\[\ny\\left[n\\right] \\;=\\; \\frac{5}{6}\\,y\\left[n-1\\right]\\;-\\;\\frac{1}{6}\\,y\\left[n-2\\right]\\;+\\;x\\left[n\\right]\n\\]\nA la señal de entrada\n\\[\nx\\left[n\\right] \\;=\\; \\delta\\left[n\\right]\\;-\\;\\frac{1}{3}\\,\\delta\\left[n-1\\right]\n\\]\nRespuesta del Sistema\nUna señal de entrada ( \\(x[n] = 3^{n}u[-n]\\) ) es aplicada a un sistema LTI discreto con respuesta al impulso ( \\(h[n] = \\left(0.5\\right)^{n}u[n]\\) ).\n\nDetermine la función de transferencia del sistema.\n¿El sistema es estable?\nEncuentre la señal de salida del sistema.\n\nAnálisis de Filtro\nConsidere el filtro\n\\[y\\left[n\\right] \\;=\\; b\\,x\\left[n\\right]\\;-\\;0.65\\,y\\left[n-1\\right]\\]\n\nDetermine (b) de modo que \\(\\lvert H\\left[0\\right] \\lvert \\, = \\, 0\\)\n\nDibuje en el plano (z) el diagrama de polos y ceros. ¿El sistema es estable?\n\nGrafique el diagrama de bloques.\n\n¿Qué tipo de filtro es?\n\nDiseño de Filtro Analógico Muestreado\nLa salida de un sistema LTI está determinada por la ecuación del sistema.\n\\[\ny\\left[n\\right] \\;=\\; x\\left[n\\right]\\;-\\;a\\,y\\left[n-1\\right]\n\\]\nTeniendo en cuenta la función de transferencia, se desea diseñar un filtro con frecuencia de corte de 60 Hz para una señal analógica muestreada a 5 kHz.\n\n¿Qué valor debe tener la variable (a)?\n\n¿Qué tipo de filtro se obtiene?\n\n\n\n\nDiseñar y simular filtros digitales para señales empleando PYTHON.\n\nDiseñar, simular y analizar un filtro pasbajos FIR por el método de ventaneo, con frecuencia de corte de 55Hz a los 6dB, atenuación mínima en 60Hz de 20 dB y atenuación mayor de 40 dB por encima de 80Hz.\n\nDeterminar el mínimo orden del filtro requerido para las siguientes ventanas: Rectangular, triangular, Hann, Hamming, Blackman, Kayser.\nDe los filtros analizados, seleccione el de menor orden que cumpla con las características de diseño.\n\nDiseñar y simular filtros digitales IIR para señales de voz empleando Matlab, analizando las diferentes opciones: Butterworth, Chebyshev, Elíptico.\n\nDiseñar, simular y analizar un filtro pasabajos IIR por el método de transformación de filtros analógicos empleando la transformación bilineal, con las siguientes características: Frecuencia de muestreo, 8 kHz; frecuencia de corte de 3.4 kHz; rizado en la banda de paso, 1 dB; frecuencia de rechazo, 3.8 kHz; atenuación en la banda de rechazo, 30 dB; orden del filtro, mínimo.\nDiseñar, simular y analizar un filtro pasaltos IIR por el método de transformación de filtros analógicos empleando la transformación bilineal, con las siguientes características: Frecuencia de muestreo, 8 kHz; frecuencia de corte de 300 Hz; rizado en la banda de paso, 1 dB; frecuencia de rechazo, 60 Hz; atenuación en la banda de rechazo, 30 dB; orden del filtro, mínimo."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "",
    "text": "Este documento contiene la resolución justificada de cada ítem del examen, enfocándose en la cuantificación, las operaciones punto a punto (pixel-wise), el filtrado por kernel, los histogramas y los gradientes en el contexto biomédico.\n\n\n\n\nEnunciado: En una radiografía dental de 12 bits se exporta por error a 8 bits antes del análisis de contraste local. ¿Cuál consecuencia técnicamente correcta describe mejor el efecto de esta cuantización sobre regiones de bajo contraste (por ejemplo, límites esmalte dentina)?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nEl cambio de 12 bits (\\(2^{12}=4096\\) niveles) a 8 bits (\\(2^8=256\\) niveles) representa una drástica reducción del número de niveles de gris disponibles. Esta operación es una cuantización destructiva en el rango de intensidad.\nJustificación Didáctica:\nUna reducción en el número de bits del píxel reduce la resolución de contraste o rango dinámico útil. Las regiones de bajo contraste, como la sutil transición entre el esmalte y la dentina, dependen de pequeñas diferencias de intensidad. Al tener menos niveles disponibles, estas diferencias sutiles pueden mapearse al mismo nivel, haciéndose indiscernibles. El efecto directo es la pérdida de la capacidad de discriminar diferencias sutiles en el rango útil.\n\n\n\n\n\n\nEnunciado: En RM cerebral se aplica una corrección de brillo mediante operación punto a punto \\(g(x,y)=f(x,y)+\\beta\\) ¿Qué cambio esperado se observa en el histograma de intensidades?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nLa operación \\(g(x,y)=f(x,y)+\\beta\\) es una transformación lineal simple (traslación o bias) que se aplica a cada píxel de forma independiente (pixel-wise). Sumar una constante \\(\\beta\\) a la intensidad \\(f(x,y)\\) de todos los píxeles no altera la relación relativa entre las intensidades; es decir, la dispersión de los datos se mantiene.\nJustificación Didáctica:\nEl histograma representa la distribución de las intensidades.\n* La media (brillo promedio) cambia en \\(\\beta\\). Esto se traduce en un desplazamiento del histograma.\n* La varianza (dispersión de intensidades) permanece similar (si no hay saturación por el desplazamiento), ya que la distancia entre los valores de los píxeles se conserva. Por lo tanto, el histograma se desplaza, pero no se ensancha ni se comprime.\n\n\n\n\n\n\nEnunciado: Para mejorar el contraste en una radiografía de tórax, se considera ecualización de histograma global sobre imagen en 12 bits. ¿Cuál efecto esperado describe mejor este proceso?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nLa Ecualización de Histograma es una técnica de mejora de contraste basada en una transformación no lineal que utiliza la función de Distribución Acumulada (CDF) de las intensidades de la imagen como mapa de transformación.\nJustificación Didáctica:\nEl objetivo de la ecualización es forzar la función de densidad de probabilidad (PDF) de las intensidades de salida a ser lo más uniforme posible.\n* Esto se logra redistribuyendo las intensidades: las regiones del histograma donde hay muchas ocurrencias (baja diferencia visual) se estiran, y las regiones donde hay pocas ocurrencias se comprimen.\n* El efecto es que la imagen utiliza de forma más eficiente el rango dinámico disponible, lo que resulta en un realce del contraste global.\n\n\n\n\n\n\nEnunciado: Se aplican operaciones elemento a elemento (pixel-wise) para corregir vignetting (oscurecimiento periférico por caída de iluminación hacia los bordes) en fundoscopía: \\(g(x,y)=\\alpha(x,y)\\cdot f(x,y).\\) con \\(\\alpha(x,y)\\) campo de ganancia estimado. ¿Qué propiedad no es requerida para esta operación?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nLa operación \\(g(x,y)=\\alpha(x,y)\\cdot f(x,y)\\) es una corrección de campo plano multiplicativa. Es una operación intrínsecamente pixel-wise.\nJustificación Didáctica:\n* Las propiedades B (Definición punto a punto), C (Conocimiento de \\(\\alpha(x,y)\\)) y D (Compatibilidad de tamaño) son requisitos de implementación para realizar la multiplicación correctamente.\n* A. Linealidad del operador respecto a la suma de imágenes: Si bien el operador \\(T(f) = \\alpha \\cdot f\\) es lineal respecto a la suma de imágenes (es decir, \\(T(f_1 + f_2) = T(f_1) + T(f_2)\\)), esta propiedad no es un requisito fundamental para la ejecución de una operación pixel-wise, a diferencia de los requisitos de dominio y tamaño. En el contexto de qué propiedad podría no ser estrictamente necesaria o relevante para la implementación misma de una corrección de campo plano multiplicativa, la linealidad se considera la menos crítica entre las opciones, ya que el foco es la acción multiplicativa local.\n\n\n\n\n\n\nEnunciado: Para atenuar ruido speckle en ecografía, se evalúan filtros lineales. ¿Qué combinación de kernel y tamaño ofrece la mejor relación entre suavizado y preservación de bordes en estructuras vasculares finas?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEl ruido speckle es un ruido multiplicativo presente en imágenes de coherencia (como ecografía). Un filtro de suavizado lineal, como el Gaussiano, es un buen punto de partida para su atenuación, ya que suaviza el ruido sin introducir artefactos de bloque.\nJustificación Didáctica:\nPara lograr la mejor relación entre suavizado y preservación de bordes finos, se requiere un equilibrio:\n* El suavizado requiere un \\(\\sigma\\) y un tamaño de ventana adecuados.\n* Los bordes finos (estructuras vasculares) se desenfocan si el kernel es demasiado grande o \\(\\sigma\\) es muy alto (como en C y A).\n* Un filtro Gaussiano \\(3\\times3\\) con \\(\\sigma=1\\) proporciona un suavizado ligero y localizado. Esto es suficiente para reducir el impacto del speckle minimizando el desenfoque lateral, lo que es crucial para mantener la nitidez y la localización de las estructuras finas. La opción D (Mediana) es mejor para ruido impulsivo y distorsiona la forma de onda del speckle de forma diferente.\n\n\n\n\n\n\nEnunciado: Para la detección de bordes en angiografía (DSA), se aplican gradientes con Sobel. ¿Cuál afirmación es correcta sobre el módulo del gradiente \\(|| \\nabla f ||\\) obtenido con Sobel?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEl operador Sobel es un operador basado en la convolución que calcula la magnitud del vector gradiente de la intensidad de la imagen. El gradiente es un vector que apunta en la dirección de máximo cambio de intensidad y cuya magnitud \\(|| \\nabla f ||\\) es la tasa de ese cambio.\nJustificación Didáctica:\n* El módulo del gradiente aproxima derivadas parciales \\((\\partial f / \\partial x, \\partial f / \\partial y)\\) utilizando máscaras discretas (\\(G_x\\) y \\(G_y\\)).\n* El resultado es una imagen donde la intensidad del píxel es proporcional a la magnitud de la transición de intensidad en ese punto, lo que efectivamente resalta las transiciones (bordes).\n* La opción A es incorrecta porque el gradiente no es invariante ante cambios de escala de intensidad; si \\(f\\) se multiplica por \\(k\\), el gradiente también se multiplica por \\(k\\).\n* La opción D es incorrecta: la derivada (gradiente) amplifica el ruido de alta frecuencia, por lo que el suavizado previo es casi siempre necesario.\n\n\n\n\n\n\nEnunciado: En mamografía digital, se considera una convolución con kernel de realce de bordes (tipo Laplaciano) seguida de umbralización adaptativa. ¿Cuál riesgo técnico es más relevante si el kernel no está adecuadamente normalizado/compensado?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nLos filtros Laplacianos son operadores de segunda derivada, que actúan como filtros pasa-altos. El resultado de la convolución Laplaciana se usa generalmente para detectar cambios rápidos de intensidad (bordes) o para sumar a la imagen original (máscara de enfoque).\nJustificación Didáctica:\nComo filtros pasa-altos, los Laplacianos amplifican las altas frecuencias. Si el kernel de realce no está diseñado cuidadosamente (no compensado o normalizado), su efecto será doblemente perjudicial:\n1. Generación de artefactos de sobre-realce (overshoot): Crea efectos de halos o anillos artificiales alrededor de los bordes.\n2. Amplificación del ruido: El ruido (siempre considerado alta frecuencia) se amplifica junto con los bordes, lo que disminuye la relación señal-ruido y puede oscurecer detalles diagnósticos sutiles.\nEl riesgo más relevante es la amplificación de ruido de alta frecuencia y la introducción de artefactos de sobre-realce.\n\n\n\n\n\n\nEnunciado: En RM ponderada en T1, antes de aplicar operadores de gradiente (Sobel/Prewitt) para detección de bordes, se decide un preprocesamiento mínimo. ¿Cuál opción mejora la robustez de la detección sin sacrificar en exceso la localización del borde?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nLa operación de detección de bordes por gradiente es un proceso inherentemente susceptible al ruido. Un paso previo de suavizado es obligatorio para aumentar la robustez de la detección.\nJustificación Didáctica:\n* El Suavizado Gaussiano es el método de suavizado preferido en el procesamiento de imágenes por sus propiedades de separación y por ser el único kernel que es localmente invariante ante la escala de brillo.\n* Para reducir el impacto del ruido (robustez) sin sacrificar en exceso la localización del borde, se requiere un suavizado ligero (\\(\\sigma \\approx 1\\)). Esto cumple con el requisito de ser un preprocesamiento mínimo efectivo.\n* Las opciones B, C y D son subóptimas: C (Promedio \\(7\\times7\\)) sacrifica excesivamente la localización; D (Aumento de nitidez) amplificaría el ruido; y B (Ecualización) es un cambio de contraste global que no es necesario para el gradiente y no está directamente relacionado con la reducción de ruido."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-1-cuantización-y-rango-dinámico-en-radiografía-dental",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-1-cuantización-y-rango-dinámico-en-radiografía-dental",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "",
    "text": "Enunciado: En una radiografía dental de 12 bits se exporta por error a 8 bits antes del análisis de contraste local. ¿Cuál consecuencia técnicamente correcta describe mejor el efecto de esta cuantización sobre regiones de bajo contraste (por ejemplo, límites esmalte dentina)?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nEl cambio de 12 bits (\\(2^{12}=4096\\) niveles) a 8 bits (\\(2^8=256\\) niveles) representa una drástica reducción del número de niveles de gris disponibles. Esta operación es una cuantización destructiva en el rango de intensidad.\nJustificación Didáctica:\nUna reducción en el número de bits del píxel reduce la resolución de contraste o rango dinámico útil. Las regiones de bajo contraste, como la sutil transición entre el esmalte y la dentina, dependen de pequeñas diferencias de intensidad. Al tener menos niveles disponibles, estas diferencias sutiles pueden mapearse al mismo nivel, haciéndose indiscernibles. El efecto directo es la pérdida de la capacidad de discriminar diferencias sutiles en el rango útil."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-2-operaciones-pixel-wise-y-su-efecto-en-el-histograma",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-2-operaciones-pixel-wise-y-su-efecto-en-el-histograma",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "",
    "text": "Enunciado: En RM cerebral se aplica una corrección de brillo mediante operación punto a punto \\(g(x,y)=f(x,y)+\\beta\\) ¿Qué cambio esperado se observa en el histograma de intensidades?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nLa operación \\(g(x,y)=f(x,y)+\\beta\\) es una transformación lineal simple (traslación o bias) que se aplica a cada píxel de forma independiente (pixel-wise). Sumar una constante \\(\\beta\\) a la intensidad \\(f(x,y)\\) de todos los píxeles no altera la relación relativa entre las intensidades; es decir, la dispersión de los datos se mantiene.\nJustificación Didáctica:\nEl histograma representa la distribución de las intensidades.\n* La media (brillo promedio) cambia en \\(\\beta\\). Esto se traduce en un desplazamiento del histograma.\n* La varianza (dispersión de intensidades) permanece similar (si no hay saturación por el desplazamiento), ya que la distancia entre los valores de los píxeles se conserva. Por lo tanto, el histograma se desplaza, pero no se ensancha ni se comprime."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-3-ecualización-de-histograma",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-3-ecualización-de-histograma",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "",
    "text": "Enunciado: Para mejorar el contraste en una radiografía de tórax, se considera ecualización de histograma global sobre imagen en 12 bits. ¿Cuál efecto esperado describe mejor este proceso?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nLa Ecualización de Histograma es una técnica de mejora de contraste basada en una transformación no lineal que utiliza la función de Distribución Acumulada (CDF) de las intensidades de la imagen como mapa de transformación.\nJustificación Didáctica:\nEl objetivo de la ecualización es forzar la función de densidad de probabilidad (PDF) de las intensidades de salida a ser lo más uniforme posible.\n* Esto se logra redistribuyendo las intensidades: las regiones del histograma donde hay muchas ocurrencias (baja diferencia visual) se estiran, y las regiones donde hay pocas ocurrencias se comprimen.\n* El efecto es que la imagen utiliza de forma más eficiente el rango dinámico disponible, lo que resulta en un realce del contraste global."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-4-operaciones-elemento-a-elemento-pixel-wise",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-4-operaciones-elemento-a-elemento-pixel-wise",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "",
    "text": "Enunciado: Se aplican operaciones elemento a elemento (pixel-wise) para corregir vignetting (oscurecimiento periférico por caída de iluminación hacia los bordes) en fundoscopía: \\(g(x,y)=\\alpha(x,y)\\cdot f(x,y).\\) con \\(\\alpha(x,y)\\) campo de ganancia estimado. ¿Qué propiedad no es requerida para esta operación?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nLa operación \\(g(x,y)=\\alpha(x,y)\\cdot f(x,y)\\) es una corrección de campo plano multiplicativa. Es una operación intrínsecamente pixel-wise.\nJustificación Didáctica:\n* Las propiedades B (Definición punto a punto), C (Conocimiento de \\(\\alpha(x,y)\\)) y D (Compatibilidad de tamaño) son requisitos de implementación para realizar la multiplicación correctamente.\n* A. Linealidad del operador respecto a la suma de imágenes: Si bien el operador \\(T(f) = \\alpha \\cdot f\\) es lineal respecto a la suma de imágenes (es decir, \\(T(f_1 + f_2) = T(f_1) + T(f_2)\\)), esta propiedad no es un requisito fundamental para la ejecución de una operación pixel-wise, a diferencia de los requisitos de dominio y tamaño. En el contexto de qué propiedad podría no ser estrictamente necesaria o relevante para la implementación misma de una corrección de campo plano multiplicativa, la linealidad se considera la menos crítica entre las opciones, ya que el foco es la acción multiplicativa local."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-5-filtrado-por-kernel-suavizado-y-preservación-de-bordes",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-5-filtrado-por-kernel-suavizado-y-preservación-de-bordes",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "",
    "text": "Enunciado: Para atenuar ruido speckle en ecografía, se evalúan filtros lineales. ¿Qué combinación de kernel y tamaño ofrece la mejor relación entre suavizado y preservación de bordes en estructuras vasculares finas?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEl ruido speckle es un ruido multiplicativo presente en imágenes de coherencia (como ecografía). Un filtro de suavizado lineal, como el Gaussiano, es un buen punto de partida para su atenuación, ya que suaviza el ruido sin introducir artefactos de bloque.\nJustificación Didáctica:\nPara lograr la mejor relación entre suavizado y preservación de bordes finos, se requiere un equilibrio:\n* El suavizado requiere un \\(\\sigma\\) y un tamaño de ventana adecuados.\n* Los bordes finos (estructuras vasculares) se desenfocan si el kernel es demasiado grande o \\(\\sigma\\) es muy alto (como en C y A).\n* Un filtro Gaussiano \\(3\\times3\\) con \\(\\sigma=1\\) proporciona un suavizado ligero y localizado. Esto es suficiente para reducir el impacto del speckle minimizando el desenfoque lateral, lo que es crucial para mantener la nitidez y la localización de las estructuras finas. La opción D (Mediana) es mejor para ruido impulsivo y distorsiona la forma de onda del speckle de forma diferente."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-6-detección-de-bordes-módulo-del-gradiente-sobel",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-6-detección-de-bordes-módulo-del-gradiente-sobel",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "",
    "text": "Enunciado: Para la detección de bordes en angiografía (DSA), se aplican gradientes con Sobel. ¿Cuál afirmación es correcta sobre el módulo del gradiente \\(|| \\nabla f ||\\) obtenido con Sobel?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEl operador Sobel es un operador basado en la convolución que calcula la magnitud del vector gradiente de la intensidad de la imagen. El gradiente es un vector que apunta en la dirección de máximo cambio de intensidad y cuya magnitud \\(|| \\nabla f ||\\) es la tasa de ese cambio.\nJustificación Didáctica:\n* El módulo del gradiente aproxima derivadas parciales \\((\\partial f / \\partial x, \\partial f / \\partial y)\\) utilizando máscaras discretas (\\(G_x\\) y \\(G_y\\)).\n* El resultado es una imagen donde la intensidad del píxel es proporcional a la magnitud de la transición de intensidad en ese punto, lo que efectivamente resalta las transiciones (bordes).\n* La opción A es incorrecta porque el gradiente no es invariante ante cambios de escala de intensidad; si \\(f\\) se multiplica por \\(k\\), el gradiente también se multiplica por \\(k\\).\n* La opción D es incorrecta: la derivada (gradiente) amplifica el ruido de alta frecuencia, por lo que el suavizado previo es casi siempre necesario."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-7-realce-de-bordes-kernel-laplaciano-y-riesgo",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-7-realce-de-bordes-kernel-laplaciano-y-riesgo",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "",
    "text": "Enunciado: En mamografía digital, se considera una convolución con kernel de realce de bordes (tipo Laplaciano) seguida de umbralización adaptativa. ¿Cuál riesgo técnico es más relevante si el kernel no está adecuadamente normalizado/compensado?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nLos filtros Laplacianos son operadores de segunda derivada, que actúan como filtros pasa-altos. El resultado de la convolución Laplaciana se usa generalmente para detectar cambios rápidos de intensidad (bordes) o para sumar a la imagen original (máscara de enfoque).\nJustificación Didáctica:\nComo filtros pasa-altos, los Laplacianos amplifican las altas frecuencias. Si el kernel de realce no está diseñado cuidadosamente (no compensado o normalizado), su efecto será doblemente perjudicial:\n1. Generación de artefactos de sobre-realce (overshoot): Crea efectos de halos o anillos artificiales alrededor de los bordes.\n2. Amplificación del ruido: El ruido (siempre considerado alta frecuencia) se amplifica junto con los bordes, lo que disminuye la relación señal-ruido y puede oscurecer detalles diagnósticos sutiles.\nEl riesgo más relevante es la amplificación de ruido de alta frecuencia y la introducción de artefactos de sobre-realce."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-8-preprocesamiento-para-detección-de-bordes",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-8-preprocesamiento-para-detección-de-bordes",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "",
    "text": "Enunciado: En RM ponderada en T1, antes de aplicar operadores de gradiente (Sobel/Prewitt) para detección de bordes, se decide un preprocesamiento mínimo. ¿Cuál opción mejora la robustez de la detección sin sacrificar en exceso la localización del borde?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nLa operación de detección de bordes por gradiente es un proceso inherentemente susceptible al ruido. Un paso previo de suavizado es obligatorio para aumentar la robustez de la detección.\nJustificación Didáctica:\n* El Suavizado Gaussiano es el método de suavizado preferido en el procesamiento de imágenes por sus propiedades de separación y por ser el único kernel que es localmente invariante ante la escala de brillo.\n* Para reducir el impacto del ruido (robustez) sin sacrificar en exceso la localización del borde, se requiere un suavizado ligero (\\(\\sigma \\approx 1\\)). Esto cumple con el requisito de ser un preprocesamiento mínimo efectivo.\n* Las opciones B, C y D son subóptimas: C (Promedio \\(7\\times7\\)) sacrifica excesivamente la localización; D (Aumento de nitidez) amplificaría el ruido; y B (Ecualización) es un cambio de contraste global que no es necesario para el gradiente y no está directamente relacionado con la reducción de ruido."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-1-cuantización-irreversible-y-reescalado",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-1-cuantización-irreversible-y-reescalado",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "Pregunta 1: Cuantización Irreversible y Reescalado",
    "text": "Pregunta 1: Cuantización Irreversible y Reescalado\n\nEnunciado: Una radiografía dental (12 bits) se cuantiza a 8 bits y luego se reescala linealmente para ocupar \\([0, 255]\\) antes del análisis de bordes. ¿Qué enunciado describe mejor el impacto final sobre la detectabilidad de límites esmalte dentina?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nLa cuantización de 12 bits (\\(4096\\) niveles) a 8 bits (\\(256\\) niveles) es una operación irreversible. Esto significa que las diferencias sutiles de intensidad (bajo contraste) que se podían distinguir con 12 bits se agrupan en un solo nivel en 8 bits, perdiendo la información original.\nJustificación Didáctica:\nEl reescalado lineal posterior simplemente toma los \\(256\\) valores existentes y los expande para ocupar el nuevo rango \\([0, 255]\\). Esta operación no puede restituir la información de contraste que se perdió en la reducción inicial de bits. La discriminación sutil de los límites esmalte-dentina, vital en las radiografías dentales, permanece degradada."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-2-transformación-afín-y-efecto-en-el-histograma",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-2-transformación-afín-y-efecto-en-el-histograma",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "Pregunta 2: Transformación Afín y Efecto en el Histograma",
    "text": "Pregunta 2: Transformación Afín y Efecto en el Histograma\n\nEnunciado: En resonancia magnética cerebral, se aplica \\(g(x,y)=\\alpha f(x,y)+\\beta\\) con \\(\\alpha&gt;1\\) y \\(\\beta&lt;0\\) para optimizar contraste. ¿Qué efecto esperado tiene sobre el histograma?\n\n\nRespuesta Correcta: D\n\n\nAnálisis Conceptual:\nLa operación \\(g(x,y)=\\alpha f(x,y)+\\beta\\) es una transformación afín que afecta tanto el brillo como el contraste:\n1. Multiplicación por \\(\\alpha\\) (\\(\\alpha&gt;1\\)): Esto es una expansión de contraste (o estiramiento del rango), lo que aumenta la varianza.\n2. Suma de \\(\\beta\\) (\\(\\beta&lt;0\\)): Esto es una disminución de brillo, lo que desplaza la media a valores menores.\nJustificación Didáctica:\nEl efecto combinado es: aumentar la dispersión (mayor varianza) y mover la distribución a la izquierda (menor media)."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-3-realce-de-bordes-por-resta-unsharp-masking",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-3-realce-de-bordes-por-resta-unsharp-masking",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "Pregunta 3: Realce de Bordes por Resta (Unsharp Masking)",
    "text": "Pregunta 3: Realce de Bordes por Resta (Unsharp Masking)\n\nEnunciado: En angiografía por sustracción digital, se emplea un esquema de realce por resta de una versión suavizada de la imagen: (i) suavizado gaussiano, (ii) diferencia \\((f-\\bar{f})\\), (iii) combinación \\((f+k(f-\\bar{f}))\\). Al incrementar \\((k)\\) para resaltar vasos finos, ¿cuál compromiso y mitigación son correctos?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nEste esquema es la técnica de Máscara de Enfoque (Unsharp Masking). El factor \\(k\\) controla la agresividad del realce de las altas frecuencias (\\((f-\\bar{f})\\)).\nJustificación Didáctica:\n* Un \\(k\\) mayor amplifica las altas frecuencias, lo que incluye tanto los bordes finos como el ruido.\n* El riesgo es la aparición de oscilaciones indeseadas (ringing o overshoot) cerca de los bordes y la amplificación del ruido de alta frecuencia.\n* La mitigación correcta para contrarrestar este efecto es aplicar un suavizado previo ligero a la imagen original (\\(f\\)) antes de calcular la máscara, para atenuar el ruido sin perder los detalles de los vasos finos."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-4-ecualización-global-del-histograma",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-4-ecualización-global-del-histograma",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "Pregunta 4: Ecualización Global del Histograma",
    "text": "Pregunta 4: Ecualización Global del Histograma\n\nEnunciado: En radiografía de tórax, la ecualización global del histograma puede:\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nLa Ecualización de Histograma transforma la función de densidad de probabilidad para hacerla más uniforme.\nJustificación Didáctica:\n* El proceso uniforma la ocupación del rango dinámico y realza el contraste en regiones agrupadas.\n* Sin embargo, al estirar las regiones homogéneas (baja varianza) del histograma, las pequeñas variaciones de intensidad (ruido) en esas regiones se separan y se hacen más evidentes. Por lo tanto, la ecualización incrementa el ruido percibido en regiones homogéneas."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-5-operaciones-pixel-wise-corrección-multiplicativa",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-5-operaciones-pixel-wise-corrección-multiplicativa",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "Pregunta 5: Operaciones Pixel-wise: Corrección Multiplicativa",
    "text": "Pregunta 5: Operaciones Pixel-wise: Corrección Multiplicativa\n\nEnunciado: Para vignetting (oscurecimiento periférico por caída de iluminación hacia los bordes) en fundoscopía, se estima \\(\\alpha(x,y)\\) mediante campo plano y se corrige \\(g(x,y)=\\alpha f(x,y)\\). ¿Qué afirmación es correcta?\n\n\nRespuesta Correcta: B\n\n\nAnálisis Conceptual:\nLa corrección de vignetting es una corrección de campo plano. El vignetting es un sesgo multiplicativo.\nJustificación Didáctica:\nLa mejor práctica para la corrección es estimar el factor de iluminación (\\(\\alpha(x,y)\\)) capturando un campo plano bajo condiciones de adquisición similares a las de la imagen real. Esta estimación es la base para corregir el sesgo multiplicativo impuesto por el sistema óptico de la fundoscopía. La corrección es multiplicativa (no aditiva) y la compatibilidad de tamaño de \\(\\alpha\\) y \\(f\\) es crucial."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-6-filtrado-compromiso-srn-y-costo-computacional-x2-puntos",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-6-filtrado-compromiso-srn-y-costo-computacional-x2-puntos",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "Pregunta 6: Filtrado: Compromiso SRN y Costo Computacional (x2 puntos)",
    "text": "Pregunta 6: Filtrado: Compromiso SRN y Costo Computacional (x2 puntos)\n\nEnunciado: Para suprimir ruido granular característico de la ecografía en tiempo real, se requiere un buen compromiso entre relación señal-ruido (SRN) y costo computacional. ¿Qué opción es más adecuada?\n\n\nRespuesta Correcta: C\n\n\nAnálisis Conceptual:\nEl objetivo es maximizar la eficiencia computacional (necesaria para el tiempo real) manteniendo un buen suavizado. El costo de una convolución \\(N\\times N\\) es \\(O(N^2)\\).\nJustificación Didáctica:\nEl filtro Gaussiano es separable. Esto permite descomponer una convolución \\(N\\times N\\) en dos convoluciones, una \\(N\\times 1\\) y otra \\(1\\times N\\), reduciendo el costo de \\(O(N^2)\\) a \\(O(2N)\\). Aplicar un Gaussiano separable \\(3\\times3\\) dos veces (o incluso un kernel mayor) es una técnica altamente eficiente. Un \\(3\\times3\\) separable tiene un costo muy bajo (\\(O(6)\\)) en comparación con un \\(9\\times9\\) no separable (\\(O(81)\\)), ofreciendo un excelente compromiso costo-SRN para procesamiento en tiempo real."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-7-gradientes-comparación-sobel-vs.-prewitt",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-7-gradientes-comparación-sobel-vs.-prewitt",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "Pregunta 7: Gradientes: Comparación Sobel vs. Prewitt",
    "text": "Pregunta 7: Gradientes: Comparación Sobel vs. Prewitt\n\nEnunciado: Sobre gradientes: comparación entre Sobel y Prewitt en imágenes ruidosas (angiografía). ¿Qué enunciado es correcto?\n\n\nRespuesta Correcta: D\n\n\nAnálisis Conceptual:\nTanto Sobel como Prewitt son operadores de gradiente que usan máscaras \\(3\\times3\\) para aproximar las derivadas parciales. Sobel difiere en que pondera los píxeles adyacentes a la dirección de la derivada.\nJustificación Didáctica:\nLa máscara de Sobel incorpora una ponderación central (factor de 2) que actúa efectivamente como un suavizado leve en la dirección perpendicular al borde. Dado que el ruido es amplificado por la derivación, este suavizado inherente hace que Sobel sea ligeramente más robusto al ruido en comparación con Prewitt, cuya máscara es uniforme."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-8-kernel-laplaciano-no-normalizado",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-8-kernel-laplaciano-no-normalizado",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "Pregunta 8: Kernel Laplaciano No Normalizado",
    "text": "Pregunta 8: Kernel Laplaciano No Normalizado\n\nEnunciado: En mamografía, se aplica un kernel de realce de bordes de segunda derivada (tipo Laplaciano) seguido de umbral adaptativo. Si el kernel no está normalizado (suma distinta de 0) ni compensado, el riesgo principal es:\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nLos filtros de realce de bordes (pasa-altos) amplifican el ruido de alta frecuencia junto con los detalles finos (bordes).\nJustificación Didáctica:\nSi el kernel de realce es excesivamente agresivo o no está correctamente diseñado, la amplificación del ruido puede hacer que las variaciones aleatorias de intensidad (ruido) superen el umbral adaptativo. Esto lleva a una alta tasa de falsos positivos (detección de puntos de ruido como estructuras) y a un realce excesivo (overshoot o ringing) en los bordes legítimos."
  },
  {
    "objectID": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-9-detección-de-bordes-suavizado-gaussiano-y-sigma",
    "href": "recursos/talleres/PSIM/sol_parc2_2025ii.html#pregunta-9-detección-de-bordes-suavizado-gaussiano-y-sigma",
    "title": "Resolución Detallada: Examen de Procesamiento de Imágenes (PSIM)",
    "section": "Pregunta 9: Detección de Bordes: Suavizado Gaussiano y \\(\\sigma\\)",
    "text": "Pregunta 9: Detección de Bordes: Suavizado Gaussiano y \\(\\sigma\\)\n\nEnunciado: En resonancia magnética ponderada en T1, se desea robustecer la detección de bordes finos con operadores de gradiente sin deslocalizar bordes. Se dispone de suavizado gaussiano con \\(\\sigma \\in \\{0.5, 1.0, 2.0\\}\\). ¿Qué estrategia es más adecuada?\n\n\nRespuesta Correcta: A\n\n\nAnálisis Conceptual:\nPara la detección de bordes, \\(\\sigma\\) controla el balance entre robustez (mayor \\(\\sigma\\), mejor rechazo de ruido) y localización (menor \\(\\sigma\\), borde más preciso).\nJustificación Didáctica:\nLa detección de bordes finos sin deslocalización exige un compromiso. La estrategia más sofisticada y efectiva es la multiescala:\n* Se prueban múltiples valores de \\(\\sigma\\) (e.g., \\(0.5\\) y \\(1.0\\)).\n* Se selecciona el resultado que ofrece un pico de gradiente máximo estable. Esto permite al algoritmo adaptarse a la escala de los bordes, logrando una detección robusta frente al ruido de la RM sin sacrificar la precisión de la localización. Usar un \\(\\sigma\\) grande (2.0) deslocalizaría los bordes finos."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html",
    "title": "Sampling and quantization",
    "section": "",
    "text": "This guide recaps essentials of sampling and quantization for biomedical acquisition chains. Emphasis is on concrete design choices for $f_s$, anti-alias cutoff, bit depth $b$, and input range, with clinical mini-cases. Primary/secondary sources: Oppenheim 2e (ISBN: 978-0138147570), Shannon 1949 (DOI: 10.1109/JRPROC.1949.232969), Jayant & Noll (ISBN: 0-13-211913-7), Webster MI 4e (ISBN: 978-0471676003).\n\n\n\n\nNyquist: $f_s2B$ where $B$ is the highest significant frequency (Shannon 1949).\nSampling model: $T_s=1/f_s$, $x_s(t)=_{n}x(nT_s),(t-nT_s)$ (Oppenheim 2e).\nAnti-aliasing: analog LPF with $f_c&lt;f_s/2$ plus guard band (Oppenheim 2e).\nQuantizer: uniform, range $[V_{},V_{}]$, step $=$ (Oppenheim 2e).\nNoise model: $_q^2=$; full-scale sine $_{},b+1.76$ (Jayant & Noll).\nCompanding (telemetry): $$-law/$A$-law to emphasize small amplitudes before quantization (Jayant & Noll; ITU-T G.711).\n\n\n\n\nGoal: Choose $f_s$, $f_c$, $b$, and input range for diagnostic ECG.\n\nBandwidth: adopt $B $ (Webster MI 4e).\nSampling: choose $f_s=500 $ to satisfy $f_s2B$ with guard (Shannon 1949).\nAnti-alias: set $f_c $ (transition to $f_s/2=250 $).\nRange: $ $ to cover tall QRS and baseline drift after high-pass.\nBits: $b=12$ is common; compute $$ and SNR below.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nVmin, Vmax = -5e-3, 5e-3\nrng = Vmax - Vmin\nbits = np.arange(10, 17)\nDelta = rng / (2**bits)\nsnr_db = 6.02*bits + 1.76  # full-scale sine (Jayant & Noll)\n\nprint(f\"12-bit Δ = {Delta[bits.tolist().index(12)]:.3e} V ≈ {Delta[bits.tolist().index(12)]*1e6:.2f} μV\")\nprint(f\"Ideal 12-bit SNR ≈ {snr_db[bits.tolist().index(12)]:.1f} dB\")\n\nplt.figure(figsize=(6,4))\nplt.semilogy(bits, Delta*1e6, marker='o')\nplt.xlabel(\"Bit depth b\")\nplt.ylabel(\"Δ (μV)\")\nplt.title(\"ECG step size vs. bit depth (±5 mV)\")\nplt.grid(True, which=\"both\")\nplt.tight_layout()\n\n12-bit Δ = 2.441e-06 V ≈ 2.44 μV\nIdeal 12-bit SNR ≈ 74.0 dB\n\n\n\n\n\nECG: step size and ideal quantization SNR for b=10..16 bits, ±5 mV range.\n\n\n\n\nInterpretation\n\n$b=12$ ⇒ $ $; ideal SNR $ $ (Oppenheim 2e; Jayant & Noll).\nMeets diagnostic needs when analog noise $&lt;$ and front-end avoids clipping (Webster MI 4e).\n\n\n\n\nGoal: Retain spindles/K-complexes without aliasing while maximizing sensitivity.\n\nBandwidth: EEG of interest $35 $; use $B=40 $ (Webster MI 4e).\nSampling: pick $f_s=256 $ (multiple of 2 for decimation) ensuring $f_s2B$ (Shannon 1949).\nAnti-alias: $f_c $ (ample guard to $f_s/2=128 $).\nRange/bits: EEG tens of $$V ⇒ prefer $b$ with programmable gain to use full-scale.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfs = 256\nt = np.arange(0, 2, 1/fs)\nx = 15e-6*np.sin(2*np.pi*10*t)  # 10 Hz alpha-like\ngain_clip = 400000  # too high =&gt; clips ±1 V ADC\ngain_safe = 200000  # safe\n\nadc_fs = 1.0  # ±1 V full-scale\ny_clip = np.clip(gain_clip*x, -adc_fs, adc_fs)\ny_safe = np.clip(gain_safe*x, -adc_fs, adc_fs)\n\nplt.figure(figsize=(6,4))\nplt.plot(t[:400], y_clip[:400], label=\"Clipping\")\nplt.plot(t[:400], y_safe[:400], label=\"Safe gain\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"ADC input (V)\")\nplt.title(\"Clipping risk from aggressive gain (EEG)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n\n\n\nEEG: effect of clipping vs. conservative gain (synthetic 15 μV wave).\n\n\n\n\nTakeaways\n\nUse sufficient gain to exploit full-scale but verify headroom for artifacts.\nClipping breaks linearity assumptions and corrupts morphology (Oppenheim 2e; Webster MI 4e).\n\n\n\n\n\nDesign: A PPG sensor needs $B=25 $. Pick a safe $f_s$ and justify.\n\nSolution: $f_s2B=50$; choose $f_s=200 $ for guard and digital processing overhead (Shannon 1949).\n\nQuantization: For $[V_{},V_{}]=[-2,2] $ and $b=10$, compute $$.\n\nSolution: $==3.90625 $ (Oppenheim 2e).\n\nNoise: With $ $, what is $_q^2$?\n\nSolution: $_q2= 2$ (Oppenheim 2e).\n\nSNR sizing: Target $72 $ for a full-scale sine. Minimum $b$?\n\nSolution: $b$ bits (Jayant & Noll).\n\n\n\n\n\n\nBandwidth $B$: Specify clinically required content (e.g., ECG 0.05–150 Hz; EEG 0.5–35 Hz).\nSampling $f_s$: Choose $2B$ with guard (e.g., ×3–5 margin) and convenience for integer decimation.\nAnti-alias LPF: Set $f_c&lt;f_s/2$; allow sufficient transition; verify analog order and tolerances.\nInput range: Size $[V_{},V_{}]$ from front-end gain so typical peaks approach full-scale without clipping.\nBit depth $b$: Use SNR $6.02b+1.76$ to meet noise targets; consider analog noise and electrode motion.\nTelemetry: For constrained links, consider $$-law/$A$-law; document compander/expander alignment (G.711).\nValidation: Bench test with synthetic and recorded signals; check aliasing, clipping, and effective number of bits (ENOB).\n\n\n\n\n\nOppenheim, A. V., Willsky, A. S., Nawab, S. H., Signals and Systems, 2nd ed., Prentice Hall, ISBN: 978-0138147570.\nShannon, C. E., Proc. IRE, 37(1), 1949, “Communication in the presence of noise,” DOI: 10.1109/JRPROC.1949.232969.\nNyquist, H., Trans. AIEE, 47, 1928, “Certain topics in telegraph transmission theory,” DOI: 10.1109/T-AIEE.1928.5055024.\nJayant, N. S., Noll, P., Digital Coding of Waveforms, Prentice-Hall, 1984, ISBN: 0-13-211913-7.\nWebster, J. G. (ed.), Medical Instrumentation: Application and Design, 4th ed., Wiley, ISBN: 978-0471676003.\nITU-T Recommendation G.711: Pulse Code Modulation (PCM) of voice frequencies (identifier: G.711)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#overview",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#overview",
    "title": "Sampling and quantization",
    "section": "",
    "text": "This guide recaps essentials of sampling and quantization for biomedical acquisition chains. Emphasis is on concrete design choices for $f_s$, anti-alias cutoff, bit depth $b$, and input range, with clinical mini-cases. Primary/secondary sources: Oppenheim 2e (ISBN: 978-0138147570), Shannon 1949 (DOI: 10.1109/JRPROC.1949.232969), Jayant & Noll (ISBN: 0-13-211913-7), Webster MI 4e (ISBN: 978-0471676003)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#concise-theory-recap",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#concise-theory-recap",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Nyquist: $f_s2B$ where $B$ is the highest significant frequency (Shannon 1949).\nSampling model: $T_s=1/f_s$, $x_s(t)=_{n}x(nT_s),(t-nT_s)$ (Oppenheim 2e).\nAnti-aliasing: analog LPF with $f_c&lt;f_s/2$ plus guard band (Oppenheim 2e).\nQuantizer: uniform, range $[V_{},V_{}]$, step $=$ (Oppenheim 2e).\nNoise model: $_q^2=$; full-scale sine $_{},b+1.76$ (Jayant & Noll).\nCompanding (telemetry): $$-law/$A$-law to emphasize small amplitudes before quantization (Jayant & Noll; ITU-T G.711)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-a-ecg-bedside-monitor",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-a-ecg-bedside-monitor",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Goal: Choose $f_s$, $f_c$, $b$, and input range for diagnostic ECG.\n\nBandwidth: adopt $B $ (Webster MI 4e).\nSampling: choose $f_s=500 $ to satisfy $f_s2B$ with guard (Shannon 1949).\nAnti-alias: set $f_c $ (transition to $f_s/2=250 $).\nRange: $ $ to cover tall QRS and baseline drift after high-pass.\nBits: $b=12$ is common; compute $$ and SNR below.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nVmin, Vmax = -5e-3, 5e-3\nrng = Vmax - Vmin\nbits = np.arange(10, 17)\nDelta = rng / (2**bits)\nsnr_db = 6.02*bits + 1.76  # full-scale sine (Jayant & Noll)\n\nprint(f\"12-bit Δ = {Delta[bits.tolist().index(12)]:.3e} V ≈ {Delta[bits.tolist().index(12)]*1e6:.2f} μV\")\nprint(f\"Ideal 12-bit SNR ≈ {snr_db[bits.tolist().index(12)]:.1f} dB\")\n\nplt.figure(figsize=(6,4))\nplt.semilogy(bits, Delta*1e6, marker='o')\nplt.xlabel(\"Bit depth b\")\nplt.ylabel(\"Δ (μV)\")\nplt.title(\"ECG step size vs. bit depth (±5 mV)\")\nplt.grid(True, which=\"both\")\nplt.tight_layout()\n\n12-bit Δ = 2.441e-06 V ≈ 2.44 μV\nIdeal 12-bit SNR ≈ 74.0 dB\n\n\n\n\n\nECG: step size and ideal quantization SNR for b=10..16 bits, ±5 mV range.\n\n\n\n\nInterpretation\n\n$b=12$ ⇒ $ $; ideal SNR $ $ (Oppenheim 2e; Jayant & Noll).\nMeets diagnostic needs when analog noise $&lt;$ and front-end avoids clipping (Webster MI 4e)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-b-eeg-for-sleep-staging",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-b-eeg-for-sleep-staging",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Goal: Retain spindles/K-complexes without aliasing while maximizing sensitivity.\n\nBandwidth: EEG of interest $35 $; use $B=40 $ (Webster MI 4e).\nSampling: pick $f_s=256 $ (multiple of 2 for decimation) ensuring $f_s2B$ (Shannon 1949).\nAnti-alias: $f_c $ (ample guard to $f_s/2=128 $).\nRange/bits: EEG tens of $$V ⇒ prefer $b$ with programmable gain to use full-scale.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfs = 256\nt = np.arange(0, 2, 1/fs)\nx = 15e-6*np.sin(2*np.pi*10*t)  # 10 Hz alpha-like\ngain_clip = 400000  # too high =&gt; clips ±1 V ADC\ngain_safe = 200000  # safe\n\nadc_fs = 1.0  # ±1 V full-scale\ny_clip = np.clip(gain_clip*x, -adc_fs, adc_fs)\ny_safe = np.clip(gain_safe*x, -adc_fs, adc_fs)\n\nplt.figure(figsize=(6,4))\nplt.plot(t[:400], y_clip[:400], label=\"Clipping\")\nplt.plot(t[:400], y_safe[:400], label=\"Safe gain\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"ADC input (V)\")\nplt.title(\"Clipping risk from aggressive gain (EEG)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n\n\n\nEEG: effect of clipping vs. conservative gain (synthetic 15 μV wave).\n\n\n\n\nTakeaways\n\nUse sufficient gain to exploit full-scale but verify headroom for artifacts.\nClipping breaks linearity assumptions and corrupts morphology (Oppenheim 2e; Webster MI 4e)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#four-formative-checks-with-solutions",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#four-formative-checks-with-solutions",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Design: A PPG sensor needs $B=25 $. Pick a safe $f_s$ and justify.\n\nSolution: $f_s2B=50$; choose $f_s=200 $ for guard and digital processing overhead (Shannon 1949).\n\nQuantization: For $[V_{},V_{}]=[-2,2] $ and $b=10$, compute $$.\n\nSolution: $==3.90625 $ (Oppenheim 2e).\n\nNoise: With $ $, what is $_q^2$?\n\nSolution: $_q2= 2$ (Oppenheim 2e).\n\nSNR sizing: Target $72 $ for a full-scale sine. Minimum $b$?\n\nSolution: $b$ bits (Jayant & Noll)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#design-checklist-print-friendly",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#design-checklist-print-friendly",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Bandwidth $B$: Specify clinically required content (e.g., ECG 0.05–150 Hz; EEG 0.5–35 Hz).\nSampling $f_s$: Choose $2B$ with guard (e.g., ×3–5 margin) and convenience for integer decimation.\nAnti-alias LPF: Set $f_c&lt;f_s/2$; allow sufficient transition; verify analog order and tolerances.\nInput range: Size $[V_{},V_{}]$ from front-end gain so typical peaks approach full-scale without clipping.\nBit depth $b$: Use SNR $6.02b+1.76$ to meet noise targets; consider analog noise and electrode motion.\nTelemetry: For constrained links, consider $$-law/$A$-law; document compander/expander alignment (G.711).\nValidation: Bench test with synthetic and recorded signals; check aliasing, clipping, and effective number of bits (ENOB)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#references-ids-included",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#references-ids-included",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Oppenheim, A. V., Willsky, A. S., Nawab, S. H., Signals and Systems, 2nd ed., Prentice Hall, ISBN: 978-0138147570.\nShannon, C. E., Proc. IRE, 37(1), 1949, “Communication in the presence of noise,” DOI: 10.1109/JRPROC.1949.232969.\nNyquist, H., Trans. AIEE, 47, 1928, “Certain topics in telegraph transmission theory,” DOI: 10.1109/T-AIEE.1928.5055024.\nJayant, N. S., Noll, P., Digital Coding of Waveforms, Prentice-Hall, 1984, ISBN: 0-13-211913-7.\nWebster, J. G. (ed.), Medical Instrumentation: Application and Design, 4th ed., Wiley, ISBN: 978-0471676003.\nITU-T Recommendation G.711: Pulse Code Modulation (PCM) of voice frequencies (identifier: G.711)."
  },
  {
    "objectID": "recursos/documentos/ASIM/Injury_Risk/Injury_Risk.html",
    "href": "recursos/documentos/ASIM/Injury_Risk/Injury_Risk.html",
    "title": "Diccionario de datos",
    "section": "",
    "text": "Knee_Flex_deg (deg): Ángulo de flexión de rodilla (variable objetivo).\nEMG_Quad_RMS_mV (mV): RMS del EMG del cuádriceps (rectificado y promediado).\nEMG_Ham_RMS_mV (mV): RMS del EMG de isquiotibiales.\nGRF_Vert_Norm_BW (BW): Componente vertical de la fuerza de reacción del suelo, normalizada por peso corporal.\nOmega_Shank_deg_s (deg/s): Velocidad angular del segmento pierna (IMU).\nHip_Flex_deg (deg): Ángulo de flexión de cadera.\n\n\n\na = 15 \n+ 25 * sigmoid(1.6*(GRF - 0.6)) \n+ 0.06 * sign(ω) * |ω|^1.2 \n+ 0.55 * Hip + 9*sin(Hip°) \n- 10 * (EMG_ham / (EMG_quad + 0.05)) \n+ 6 * EMG_quad * GRF\n- 40 * (EMG_quad - 0.12)^2\n+ 8 * GRF * sin(Hip°)\n+ ε\ndonde ε ~ Normal(0, 2) + 0.5*t(5). Se recortó a [-5, 140] deg."
  },
  {
    "objectID": "recursos/documentos/ASIM/Injury_Risk/Injury_Risk.html#generación-función-subyacente",
    "href": "recursos/documentos/ASIM/Injury_Risk/Injury_Risk.html#generación-función-subyacente",
    "title": "Diccionario de datos",
    "section": "",
    "text": "a = 15 \n+ 25 * sigmoid(1.6*(GRF - 0.6)) \n+ 0.06 * sign(ω) * |ω|^1.2 \n+ 0.55 * Hip + 9*sin(Hip°) \n- 10 * (EMG_ham / (EMG_quad + 0.05)) \n+ 6 * EMG_quad * GRF\n- 40 * (EMG_quad - 0.12)^2\n+ 8 * GRF * sin(Hip°)\n+ ε\ndonde ε ~ Normal(0, 2) + 0.5*t(5). Se recortó a [-5, 140] deg."
  },
  {
    "objectID": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html",
    "href": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html",
    "title": "Evaluación de la Calidad de los Modelos",
    "section": "",
    "text": "Resumen Ejecutivo (Abstract)\nEste reporte establece un marco de referencia conceptual y matemático para la evaluación de algoritmos de machine learning en tareas de clasificación y regresión. Se analiza rigurosamente el propósito estadístico de las métricas de evaluación (Clasificación: Matriz de Confusión, Accuracy, Precision, Recall, F1-Score; Regresión: MAE, MSE, RMSE, R²) y las metodologías de validación (Train/Test Split, K-Fold, Stratified K-Fold, LOOCV). El análisis se centra en las propiedades matemáticas de cada métrica, sus supuestos subyacentes y sus limitaciones prácticas, como la sensibilidad a outliers y el comportamiento en datasets desbalanceados. Se concluye con un análisis teórico comparativo de las técnicas de validación, examinando el tradeoff de sesgo-varianza en la estimación del error de generalización, proporcionando una base para la selección de protocolos de evaluación robustos."
  },
  {
    "objectID": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#i.-principios-fundamentales-de-la-evaluación-de-modelos",
    "href": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#i.-principios-fundamentales-de-la-evaluación-de-modelos",
    "title": "Evaluación de la Calidad de los Modelos",
    "section": "I. Principios Fundamentales de la Evaluación de Modelos",
    "text": "I. Principios Fundamentales de la Evaluación de Modelos\n\nSección 1.1 El Problema Central: Estimación del Error de Generalización\nEl objetivo axiomático del machine learning supervisado no es la memorización de los datos de entrenamiento (rendimiento in-sample), sino la capacidad de generalización del modelo a datos futuros, no observados (rendimiento out-of-sample).[1, 2] El fenómeno del sobreajuste (overfitting) se define como el escenario en el cual un modelo se adapta excesivamente a las idiosincrasias estocásticas (ruido) del conjunto de entrenamiento, resultando en una degradación de su rendimiento predictivo en nuevos datos.[3]\nPor lo tanto, la evaluación es el proceso mediante el cual se estima el rendimiento de un modelo en datos no vistos, con el fin de seleccionar el modelo que posea la mejor capacidad de generalización.[1, 3]\n\n\nSección 1.2 Definiciones Formales: Riesgo Esperado vs. Riesgo Empírico\nDesde un punto de vista estadístico formal, la evaluación es un problema de estimación. Sea \\(D = \\{(x_i, y_i)\\}_{i=1}^n\\) un conjunto de datos muestreado de una distribución de probabilidad verdadera pero desconocida, \\(P(x, y)\\). Sea \\(f\\) nuestro modelo (o hipótesis) y sea \\(L(f(x), y)\\) una función de pérdida (Loss Function) que cuantifica el costo de predecir \\(f(x)\\) cuando el valor real es \\(y\\).\nRiesgo Esperado (Error de Generalización, \\(R(f)\\)):\nEste es el verdadero error del modelo sobre la distribución de datos subyacente \\(P\\). Se define como el valor esperado de la función de pérdida:\n\\[R(f) = \\mathbb{E}_{P(x,y)}[L(f(x), y)] = \\int L(f(x), y) dP(x, y)\\]\nEste valor es el objetivo real de nuestra optimización, pero es incomputable en la práctica, ya que no conocemos la distribución \\(P(x, y)\\).[4]\nRiesgo Empírico (Error de Entrenamiento, \\(R_{emp}(f)\\)):\nEste es el error promedio medido sobre nuestro conjunto de entrenamiento muestreado \\(D\\).[4] Es el sustituto (proxy) que podemos calcular:\n\\[R_{emp}(f) = \\frac{1}{n} \\sum_{i=1}^n L(f(x_i), y_i)\\]\n\n\nSección 1.3 El Propósito Unificado de la Evaluación\nTodo el campo de la evaluación de modelos (que abarca tanto las métricas como las técnicas de validación) puede unificarse bajo un único propósito: la búsqueda de un estimador estadístico fiable para el Riesgo Esperado (\\(R(f)\\)) incomputable.\n\nLas Métricas (ej. MSE, Accuracy) son la elección de la función de pérdida \\(L\\) que se considera relevante para el problema en el cálculo del riesgo.\nLas Técnicas de Validación (ej. K-Fold) son el proceso de muestreo (resampling) que se utiliza para calcular una estimación del riesgo (ej. el error de prueba o el error de validación cruzada) que sea menos sesgada que el Riesgo Empírico.\n\nEl error de entrenamiento (\\(R_{emp}\\)) es conocido por ser un estimador optimistamente sesgado del error de generalización (\\(R(f)\\)), especialmente en modelos con alta capacidad (complejos), ya que el modelo ha sido optimizado directamente sobre esos datos.[3] Las técnicas de validación (Sección IV) son, por lo tanto, metodologías diseñadas para obtener un estimador más preciso e insesgado del verdadero rendimiento del modelo.[2]"
  },
  {
    "objectID": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#ii.-métricas-de-evaluación-para-problemas-de-clasificación",
    "href": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#ii.-métricas-de-evaluación-para-problemas-de-clasificación",
    "title": "Evaluación de la Calidad de los Modelos",
    "section": "II. Métricas de Evaluación para Problemas de Clasificación",
    "text": "II. Métricas de Evaluación para Problemas de Clasificación\nEn los problemas de clasificación, la función de pérdida \\(L\\) no suele ser continua, sino que se basa en el conteo de predicciones correctas e incorrectas.\n\nSección 2.1 La Matriz de Confusión como Base Analítica\nLa Matriz de Confusión no es una métrica de rendimiento per se, sino una desagregación tabular exhaustiva de los resultados de un modelo de clasificación, permitiendo un análisis detallado de los tipos de error.[5, 6] Para un problema de clasificación binaria (Clase Positiva vs. Clase Negativa), la matriz 2x2 se define mediante cuatro conteos atómicos [5, 7]:\n\nVerdadero Positivo (TP): El modelo predijo ‘Positivo’ y la etiqueta real era ‘Positivo’.[7, 8]\nVerdadero Negativo (TN): El modelo predijo ‘Negativo’ y la etiqueta real era ‘Negativo’.[7, 8]\nFalso Positivo (FP) - Error Tipo I: El modelo predijo ‘Positivo’ pero la etiqueta real era ‘Negativo’.[5, 7, 8]\nFalso Negativo (FN) - Error Tipo II: El modelo predijo ‘Negativo’ pero la etiqueta real era ‘Positivo’.[5, 7, 8]\n\nTabla 1: Matriz de Confusión Binaria\n\n\n\n\nPredicho: Positivo\nPredicho: Negativo\nTotal Real\n\n\n\n\nReal: Positivo\n\\(TP\\)\n\\(FN\\)\n\\(P = TP + FN\\)\n\n\nReal: Negativo\n\\(FP\\)\n\\(TN\\)\n\\(N = FP + TN\\)\n\n\nTotal Predicho\n\\(TP + FP\\)\n\\(FN + TN\\)\n\\(P + N\\)\n\n\n\nEl valor fundamental de la matriz de confusión es que permite un análisis de costos asimétricos.[9] Todas las métricas de clasificación (Accuracy, Precision, Recall) son simplemente funciones de agregación de estos cuatro valores. La selección de la métrica apropiada depende enteramente del costo relativo de los Errores Tipo I (FP) vs. Tipo II (FN) en el dominio del problema.[9]\n\nEjemplo 1: Filtro de Spam.[8, 9] Un Falso Positivo (FP) ocurre cuando un email legítimo es clasificado como spam. Un Falso Negativo (FN) es un spam que llega al buzón. El costo de un FP (perder un email importante) es mucho más alto que el de un FN (borrar un email de spam). Por lo tanto, se prioriza minimizar los FP.\nEjemplo 2: Diagnóstico Médico. Un Falso Negativo (FN) ocurre cuando un paciente enfermo es diagnosticado como sano. Un Falso Positivo (FP) es un paciente sano diagnosticado como enfermo. El costo de un FN (falta de tratamiento) es catastróficamente más alto que el de un FP (realizar más pruebas). Se prioriza minimizar los FN.\n\n\n\nSección 2.2 Métricas Derivadas y su Interpretación Estadística\n\n2.2.1 Accuracy (Exactitud)\n\nDefinición Matemática: La proporción de predicciones correctas (positivas y negativas) sobre el número total de predicciones.[9]\n\\[Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\\]\nInterpretación: “¿Qué fracción del total de predicciones fue correcta?”.[9]\n\n\n\n2.2.2 La Falacia de la Exactitud: La Paradoja de los Datasets Desbalanceados\nEl Accuracy es la métrica más intuitiva, pero es profundamente engañosa e inapropiada para problemas con desbalance de clases.[9, 10, 11, 12] Un desbalance de clases ocurre cuando una clase (la mayoritaria) es mucho más frecuente que la otra (la minoritaria).[13]\nLa inutilidad del Accuracy en estos escenarios [11, 14, 15] se puede demostrar formalmente:\nConsidérese un dataset de \\(N=1000\\) muestras para la detección de una enfermedad rara, donde el 99% de la población está sana (Clase Negativa) y el 1% está enferma (Clase Positiva).\n* Total de Muestras: 1000\n* Reales Negativos (N): 990\n* Reales Positivos (P): 10\nAhora, considérese un modelo trivial (e inútil) que siempre predice ‘Negativo’ para cualquier entrada.\nEvaluemos este modelo usando la Matriz de Confusión:\n* \\(TP = 0\\) (nunca predice ‘Positivo’)\n* \\(FP = 0\\) (nunca predice ‘Positivo’)\n* \\(TN = 990\\) (predijo ‘Negativo’ para los 990 sanos, y acertó)\n* \\(FN = 10\\) (predijo ‘Negativo’ para los 10 enfermos, y falló)\nSi calculamos el Accuracy de este modelo:\n\\[Accuracy = \\frac{TP + TN}{Total} = \\frac{0 + 990}{1000} = 0.99\\]\nEl modelo obtiene un 99% de Accuracy [11, 15], lo que sugiere un rendimiento excelente. Sin embargo, el modelo es completamente inútil [9], ya que su habilidad para identificar la clase de interés (la positiva) es nula. El valor del Accuracy está dominado por el término \\(TN\\) (la habilidad de identificar correctamente la clase mayoritaria) [14], ocultando el fallo total en la clase minoritaria.\n\n\n2.2.3 Precision (Precisión)\n\nDefinición Matemática: También conocido como Valor Predictivo Positivo (PPV).[16] Es la fracción de predicciones positivas que fueron realmente correctas.[9, 10]\n\\[Precision = \\frac{TP}{TP + FP}\\]\nInterpretación Conceptual: “De todas las veces que el modelo dijo ‘Positivo’, ¿qué porcentaje realmente era ‘Positivo’?”.[10]\nContexto de Uso: Métrica crítica cuando el costo de un Falso Positivo (FP) es alto (ej. Filtro de Spam [8], recomendaciones de inversión).[9, 17]\n\n\n\n2.2.4 Recall (Sensibilidad)\n\nDefinición Matemática: También conocido como Sensibilidad (Sensitivity) o Tasa de Verdaderos Positivos (TPR).[10, 18] Es la fracción de todos los casos reales positivos que el modelo identificó correctamente.[9, 10]\n\\[Recall = \\frac{TP}{TP + FN}\\]\nInterpretación Conceptual: “De todos los casos que eran realmente ‘Positivos’, ¿qué porcentaje encontró el modelo?”.[10]\nContexto de Uso: Métrica crítica cuando el costo de un Falso Negativo (FN) es alto (ej. Diagnóstico médico, detección de fraude).[9]\n\n\n\n\nSección 2.3 El Tradeoff Precisión-Recall y la Métrica F1\n\n2.3.1 El Tradeoff Dependiente del Umbral\nLa mayoría de los algoritmos de clasificación (ej. Regresión Logística, Redes Neuronales) no emiten una clase discreta (0 o 1), sino una puntuación o probabilidad continua (ej. 0.85). Se requiere un umbral de decisión (threshold) para convertir esta puntuación en una predicción de clase (ej. si &gt; 0.5, predecir ‘Positivo’).[9, 17]\nLas métricas de Precisión y Recall no son propiedades estáticas de un modelo; son funciones de este umbral de decisión.[9, 17] Existe un tradeoff inevitable entre ellas [19]:\n\nSi se aumenta el Umbral (ej. a 0.9): El modelo se vuelve más “cauteloso” [19] y solo predice ‘Positivo’ si está extremadamente seguro.\n\n\\(FP\\) disminuyen drásticamente (pocos negativos alcanzan el umbral). Esto aumenta la Precision.\n\\(FN\\) aumentan (muchos positivos verdaderos no alcanzan el umbral). Esto disminuye el Recall.\n\nSi se disminuye el Umbral (ej. a 0.1): El modelo se vuelve más “sensible” [19] y predice ‘Positivo’ con facilidad.\n\n\\(FN\\) disminuyen (casi todos los positivos son “atrapados”). Esto aumenta el Recall.\n\\(FP\\) aumentan (muchos negativos se “cuelan” por encima del umbral). Esto disminuye la Precision.\n\n\n\n\n2.3.2 F1-Score: La Media Armónica\nDado el tradeoff P-R, se necesita una métrica única que balancee ambas, especialmente útil en datasets desbalanceados donde el Accuracy falla.[9, 10]\n\nDefinición Matemática: El F1-Score es la media armónica de Precision y Recall.[9, 18]\n\\[F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}\\]\n\n\n\n2.3.3 Justificación Estadística del Uso de la Media Armónica\nEl uso de la media armónica [20] (en lugar de una media aritmética simple) es una elección estadística deliberada y fundamental. La media armónica es la forma matemáticamente correcta de promediar tasas [21, 22] y su propiedad clave es que penaliza fuertemente el desequilibrio extremo entre los valores.[21, 23]\nAnalicemos por qué la media aritmética (\\(\\frac{P+R}{2}\\)) es una métrica pobre:\n\nModelo A (Desbalanceado, Malo):\n\nPrecision = 1.0 (perfecta)\nRecall = 0.02 (terrible)\nMedia Aritmética: \\(\\frac{1.0 + 0.02}{2} = 0.51\\) (Esto sugiere falsamente que el modelo es “decente”).\nMedia Armónica (F1): \\(2 \\cdot \\frac{1.0 \\cdot 0.02}{1.0 + 0.02} = \\frac{0.04}{1.02} \\approx 0.039\\) (Esto refleja correctamente que el modelo es malo).\n\nModelo B (Balanceado, Bueno):\n\nPrecision = 0.9\nRecall = 0.8\nMedia Aritmética: \\(\\frac{0.9 + 0.8}{2} = 0.85\\)\nMedia Armónica (F1): \\(2 \\cdot \\frac{0.9 \\cdot 0.8}{0.9 + 0.8} = \\frac{1.44}{1.7} \\approx 0.847\\) (El valor es similar cuando P y R están balanceados).\n\n\nLa media aritmética puede ser alta incluso si uno de sus componentes es cercano a cero. La media armónica es arrastrada hacia el valor más bajo.[23] Por lo tanto, un F1-Score alto garantiza que tanto Precision como Recall tienen valores altos.[21]\nTabla 2: Resumen de Métricas de Clasificación\n\n\n\n\n\n\n\n\nMétrica\nFórmula Matemática\nPregunta Conceptual que Responde\n\n\n\n\nAccuracy\n\\(\\frac{TP+TN}{Total}\\)\n¿Qué fracción de todas las predicciones fue correcta? [9]\n\n\nPrecision\n\\(\\frac{TP}{TP+FP}\\)\nDe lo que predije como positivo, ¿cuánto acerté? [10]\n\n\nRecall\n\\(\\frac{TP}{TP+FN}\\)\nDe lo que era positivo, ¿cuánto encontré? [10]\n\n\nF1-Score\n\\(2 \\frac{Precision \\cdot Recall}{Precision+Recall}\\)\n¿Cuál es el balance (media armónica) entre Precision y Recall? [9]"
  },
  {
    "objectID": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#iii.-métricas-de-evaluación-para-problemas-de-regresión",
    "href": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#iii.-métricas-de-evaluación-para-problemas-de-regresión",
    "title": "Evaluación de la Calidad de los Modelos",
    "section": "III. Métricas de Evaluación para Problemas de Regresión",
    "text": "III. Métricas de Evaluación para Problemas de Regresión\nEn regresión, la salida es un valor continuo. Las métricas evalúan la magnitud de la diferencia entre el valor real (\\(y_i\\)) y el valor predicho (\\(\\hat{y}_i\\)). El error (o residual) se define como \\(e_i = y_i - \\hat{y}_i\\).\n\nSección 3.1 Métricas Basadas en la Magnitud del Error\n\n3.1.1 Mean Absolute Error (MAE)\n\nDefinición Matemática: El promedio de las magnitudes absolutas de los errores. Esto corresponde a la Pérdida L1.[24]\n\\[MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| = \\frac{1}{n} \\sum_{i=1}^{n} |e_i|\\]\nPropiedades:\n\nInterpretabilidad: El MAE se expresa en las mismas unidades que la variable objetivo \\(y\\).[25, 26, 27] Si \\(y\\) se mide en Dólares, el MAE es Dólares, representando el error promedio.[25]\nRobustez: Es robusto (menos sensible) a los outliers.[25, 26, 28, 29] Un error grande (outlier) contribuye de forma lineal (no cuadrática) al error total.\n\n\n\n\n3.1.2 Mean Squared Error (MSE)\n\nDefinición Matemática: El promedio de los errores al cuadrado. Esto corresponde a la Pérdida L2.[24, 30, 31]\n\\[MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\frac{1}{n} \\sum_{i=1}^{n} e_i^2\\]\nPropiedades:\n\nSensibilidad a Outliers: Es altamente sensible a outliers.[28, 29, 31, 32, 33]\nPenalización Cuadrática: La naturaleza del cuadrado (\\(e_i^2\\)) significa que los errores grandes son penalizados desproporcionadamente más que los pequeños.[31, 34] Un error de 10 unidades contribuye 100 al MSE, mientras que un error de 2 contribuye 4.\nDiferenciabilidad: La función \\(e^2\\) es suave y diferenciable en \\(e=0\\), lo que la hace matemáticamente conveniente para la optimización (ej. descenso de gradiente).[28, 33]\nInterpretabilidad: Las unidades están al cuadrado (ej. Dólares\\(^2\\)), lo cual carece de interpretación física directa.[29, 30]\n\n\n\n\n3.1.3 Root Mean Squared Error (RMSE)\n\nDefinición Matemática: Es simplemente la raíz cuadrada del MSE, diseñada para resolver el problema de interpretabilidad de las unidades.[24, 35, 36, 37]\n\\[RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} = \\sqrt{MSE}\\]\nPropiedades:\n\nInterpretabilidad: Resuelve el problema de unidades del MSE. RMSE se expresa en las mismas unidades que \\(y\\), al igual que MAE.[27, 34, 37, 38]\nSensibilidad a Outliers: Al ser una transformación monotónica de MSE, conserva la misma alta sensibilidad a los outliers.[29, 34]\n\n\n\n\n3.1.4 Análisis Comparativo: MAE vs. RMSE (MSE)\nLa elección entre MAE y RMSE (o MSE) no es trivial y va más allá de la simple robustez. Implica una elección fundamental sobre el objetivo del modelo y un supuesto estadístico sobre la distribución de los errores (\\(e_i\\)).[28, 39]\n\nMinimizar MSE (Pérdida L2): Desde una perspectiva estadística, el valor que minimiza la suma de errores al cuadrado es la media de la distribución.\n\nConsecuencia: Si los errores siguen (o se asume que siguen) una distribución Gaussiana (Normal), MSE (y RMSE) es la métrica óptima.[39] El modelo se verá fuertemente penalizado por los outliers y se esforzará por predecirlos, ya que estos tienen un gran impacto en la media.[28, 32]\n\nMinimizar MAE (Pérdida L1): El valor que minimiza la suma de diferencias absolutas es la mediana de la distribución.\n\nConsecuencia: Si los errores siguen (o se asume que siguen) una distribución Laplaciana (con colas más pesadas que la Gaussiana), MAE es la métrica óptima.[39] El modelo es robusto a los outliers [25], ya que prefiere ajustarse a la mediana de la tendencia central e ignorar los valores extremos.[28]\n\n\nEn resumen, se debe usar RMSE [27] si los errores grandes son particularmente indeseables y deben ser penalizados fuertemente. Se debe usar MAE [27] si los outliers se consideran ruido que el modelo debe ignorar.[26]\nTabla 3: Comparativa de Métricas de Error en Regresión\n\n\n\n\n\n\n\n\n\n\nMétrica\nFórmula Matemática\nUnidades (relativas a \\(y\\))\nSensibilidad a Outliers\nPropiedad Estadística\n\n\n\n\nMAE\n\\(\\frac{1}{n} \\sum |y_i - \\hat{y}_i|\\)\n\\(y\\) [26]\nBaja (Robusta) [25, 28]\nAsociada a la Mediana del error [28, 39]\n\n\nMSE\n\\(\\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\\)\n\\(y^2\\) [29, 30]\nAlta [28, 31, 32]\nAsociada a la Media del error [28, 39]\n\n\nRMSE\n\\(\\sqrt{MSE}\\)\n\\(y\\) [37, 38]\nAlta [34]\nAsociada a la Media del error [39]\n\n\n\n\n\n\nSección 3.2 Coeficiente de Determinación (R²)\n\n3.2.1 Interpretación Conceptual\nA diferencia de MAE/MSE/RMSE (que miden el error absoluto en unidades de \\(y\\)), el Coeficiente de Determinación (R²) es una métrica relativa y adimensional.[40, 41] Su valor está típicamente acotado entre 0 y 1 [41, 42] (aunque puede ser negativo para modelos peores que el promedio).\n\nInterpretación: R² mide la proporción de la varianza en la variable dependiente (\\(y\\)) que es predecible (o “explicada”) por las variables independientes (\\(X\\)) a través del modelo.[40, 41, 43]\nUn R² = 0.75 significa que el 75% de la variabilidad en \\(y\\) (respecto a su media) es explicada por el modelo, y el 25% restante es varianza residual (error).[41]\n\n\n\n3.2.2 Derivación Matemática Formal (Descomposición de la Varianza)\nLa fórmula de R² no es arbitraria; se deriva directamente de la descomposición de la varianza en el análisis de regresión.[44, 45]\n\nPaso 1: Suma Total de Cuadrados (TSS): Mide la varianza total de \\(y\\). Esto es equivalente al error de un “modelo base” (ingenuo) que siempre predice la media \\(\\bar{y}\\).\n\\[TSS = \\sum_{i=1}^n (y_i - \\bar{y})^2\\].[45]\nPaso 2: Suma de Cuadrados Residuales (RSS): Mide el error inexplicado por nuestro modelo \\(f\\).[45] (También conocido como SSE, Sum of Squared Errors [46, 47]).\n\\[RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\].[45]\nPaso 3: Descomposición (para OLS): Se puede demostrar que la varianza total se descompone en la varianza explicada y la no explicada [44, 45]:\n\\[TSS = ESS + RSS\\]\n(Donde \\(ESS = \\sum (\\hat{y}_i - \\bar{y})^2\\) es la Suma de Cuadrados Explicada).[45]\nPaso 4: Definición de R²: R² se define conceptualmente como la proporción de varianza explicada.[44, 45]\n\\[R^2 = \\frac{ESS}{TSS}\\]\nPaso 5: Fórmula Práctica: Sustituyendo \\(ESS = TSS - RSS\\):\n\\[R^2 = \\frac{TSS - RSS}{TSS} = 1 - \\frac{RSS}{TSS}\\].[40, 45, 46, 47]\n\nEsta fórmula compara el error de nuestro modelo (RSS) con el error del modelo base (TSS).[40] Si \\(RSS=0\\) (ajuste perfecto), \\(R^2=1\\). Si \\(RSS=TSS\\) (nuestro modelo no es mejor que predecir la media), \\(R^2=0\\).[47]\n\n\n3.2.3 Limitaciones Críticas y Malas Interpretaciones de R²\nR² es una de las métricas más frecuentemente malinterpretadas en la práctica.[48, 49]\n\nLimitación 1: R² no mide la “bondad de ajuste”.[48] Un R² alto no significa que el modelo sea correcto. Un modelo con una forma funcional incorrecta (ej. lineal cuando la relación es cuadrática) puede tener un R² alto.\nLimitación 2: R² no mide el error de predicción.[48] Un R² de 0.90 suena bien, pero si la varianza (TSS) de \\(y\\) es masiva, el 10% de error restante (RMSE) puede ser inaceptablemente alto en términos prácticos.\nLimitación 3: Sensibilidad al Overfitting.[50] R² siempre aumenta (o, en el peor caso, se mantiene) cuando se añade una nueva variable predictora al modelo, incluso si esa variable es ruido aleatorio.[50] El modelo usa esta variable para explicar una porción minúscula del ruido en la muestra de entrenamiento.\n\nConsecuencia: Esto fomenta el sobreajuste.[49, 50] (Nota: El Adjusted R² [45, 46] fue creado para penalizar la inclusión de predictores \\(p\\) irrelevantes, pero R² estándar no lo hace).\n\nLimitación 4: Invalidez en Comparaciones.[51] R² no puede usarse para comparar modelos donde la variable \\(y\\) ha sido transformada (ej. \\(R^2\\) de un modelo que predice \\(y\\) no es comparable al \\(R^2\\) de un modelo que predice \\(\\log(y)\\)), ya que el TSS es diferente.\nLimitación 5: Sensibilidad a Outliers.[50] Al estar basado en cuadrados (TSS y RSS), el valor de R² puede ser fuertemente influenciado por unos pocos outliers.\nLimitación 6: Correlación no implica causalidad.[43, 50] Un R² alto no dice nada sobre la relación causal entre \\(X\\) e \\(Y\\)."
  },
  {
    "objectID": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#iv.-metodologías-de-validación-para-la-estimación-del-error-de-generalización",
    "href": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#iv.-metodologías-de-validación-para-la-estimación-del-error-de-generalización",
    "title": "Evaluación de la Calidad de los Modelos",
    "section": "IV. Metodologías de Validación para la Estimación del Error de Generalización",
    "text": "IV. Metodologías de Validación para la Estimación del Error de Generalización\nComo se estableció en la Sección I, el error de entrenamiento (\\(R_{emp}\\)) es un estimador sesgado. Necesitamos técnicas de muestreo para obtener un estimador más fiable del error de generalización (\\(R(f)\\)).\n\nSección 4.1 El Método Holdout (Train/Test Split)\n\n4.1.1 Procedimiento Conceptual\nEs la técnica de validación más simple.[1] El conjunto de datos original \\(D\\) se divide una vez de forma aleatoria en dos subconjuntos [1]:\n\nConjunto de Entrenamiento (Training Set): La porción más grande (ej. 70%, 80%), usada para entrenar el modelo (aprender los parámetros).[1, 52]\nConjunto de Prueba (Test Set): La porción restante (ej. 30%, 20%), usada para evaluar el modelo entrenado en datos no vistos y estimar el error de generalización.[1, 52, 53]\n\n\n\n4.1.2 El Imperativo del Conjunto de Validación (Train/Validation/Test Split)\nEl uso del Test Set para tomar decisiones de modelado (ej. seleccionar hiperparámetros como max_depth [1], o elegir qué variables incluir) es un error metodológico grave.[3, 53]\nSi se usa el Test Set repetidamente para “ajustar” el modelo (“Tweak model” en [53]), el modelo comienza a sobreajustarse a la información específica de ese Test Set.[3, 53] El Test Set “se desgasta” (“wear out”) [53] y deja de ser una medida insesgada de generalización; la estimación del error reportada será optimistamente sesgada.\nProtocolo Correcto (3 Particiones) [52, 53]:\n1. Training Set (ej. 60%): Para entrenar los modelos (aprender parámetros).\n2. Validation Set (ej. 20%): Para ajustar hiperparámetros (ej. comparar \\(k=3\\) vs \\(k=5\\)) y realizar la selección del modelo.[52, 53]\n3. Test Set (Holdout) (ej. 20%): Se mantiene “bloqueado” y aislado. Se usa una sola vez al final del proyecto para reportar el error de generalización insesgado del modelo final seleccionado.[3, 53]\n\n\n4.1.3 Limitación Fundamental: Alta Varianza del Estimador\nLa debilidad principal del método Holdout es que la estimación del error (medida en el validation o test set) depende fuertemente de la partición aleatoria específica que se realizó.[54, 55] Si, por mala suerte, la partición de prueba contiene muestras “difíciles” u outliers, el error estimado será pesimista. Si contiene muestras “fáciles”, será optimista.[56]\nLa estimación del error del método Holdout tiene una alta varianza.[56] No es una estimación robusta, especialmente en datasets pequeños.[56]\n\n\n\nSección 4.2 Validación Cruzada K-Fold (K-Fold Cross-Validation)\nK-Fold CV es un procedimiento de resampling [2, 57] diseñado para mitigar la alta varianza del método Holdout, proporcionando una estimación del error más robusta.[56, 58]\n\n4.2.1 Descripción Algorítmica\n\nBarajar (Shuffle) aleatoriamente el conjunto de datos \\(D\\).\nParticionar \\(D\\) en \\(k\\) subconjuntos (folds) de tamaño (aproximadamente) igual: \\(D_1, D_2,..., D_k\\).[57, 59]\nPara \\(i\\) desde \\(1\\) hasta \\(k\\):\n\nUsar \\(D_i\\) como el fold de validación (hold-out fold).[57, 60]\nUsar los \\(k-1\\) folds restantes (\\(D - D_i\\)) como el conjunto de entrenamiento.[57, 60]\nEntrenar un modelo \\(M_i\\) en \\(D - D_i\\) y calcular su error \\(E_i\\) en \\(D_i\\).\n\nDescartar los \\(k\\) modelos entrenados (\\(M_1...M_k\\)) [57] (el objetivo es evaluar el proceso de modelado, no los modelos individuales).\nEl estimador del error de generalización (\\(E_{CV}\\)) es el promedio de los \\(k\\) errores:\n\\[E_{CV} = \\frac{1}{k} \\sum_{i=1}^k E_i\\].[59, 60]\n\nValores comunes son \\(k=5\\) o \\(k=10\\).[59, 61]\n\n\n4.2.2 Ventajas sobre Holdout\n\nEstimación Robusta (Baja Varianza): Al promediar \\(k\\) estimaciones de error de \\(k\\) particiones diferentes, la estimación final \\(E_{CV}\\) es mucho más estable (menor varianza) y menos dependiente de una única partición aleatoria.[2, 58, 61, 62]\nUso Eficiente de los Datos: Todas las muestras del dataset se utilizan tanto para entrenamiento como para validación (en diferentes iteraciones).[58, 59, 61] Esto es una ventaja crítica en datasets pequeños donde no se puede “desperdiciar” datos en un gran test set.[56, 59]\n\n\n\n\nSección 4.3 Variantes Esenciales de la Validación Cruzada\n\n4.3.1 Stratified K-Fold (CV Estratificada)\nEl K-Fold estándar (aleatorio) [57] falla en problemas de clasificación desbalanceada.[63]\nSi un dataset es 99% Clase A y 1% Clase B, el muestreo aleatorio para crear los \\(k\\) folds no garantiza que esta proporción se mantenga en cada fold.[63] Es estadísticamente posible (y probable en datasets pequeños) que un fold (el fold de validación) termine conteniendo cero muestras de la Clase B.[63] En esa iteración \\(i\\), el modelo \\(M_i\\) será evaluado en un fold sin la clase minoritaria. Métricas como Recall o F1 no podrán calcularse o serán 0, sesgando el promedio final \\(E_{CV}\\).\nDefinición de Stratified K-Fold: Es una modificación del Paso 2 del algoritmo. La partición en \\(k\\) folds no es aleatoria, sino estratificada.[64, 65, 66] El algoritmo asegura que la distribución de clases (la probabilidad a priori \\(P(y)\\)) en cada uno de los \\(k\\) folds sea (lo más cercanamente posible) idéntica a la distribución de clases en el dataset completo \\(D\\).[63, 64] Esta es la metodología mandatoria para la validación en clasificación desbalanceada.\n\n\n4.3.2 Leave-One-Out Cross-Validation (LOOCV)\n\nDefinición: Es el caso extremo de K-Fold CV donde \\(k\\) es igual al número total de muestras, \\(N\\) (\\(k=N\\)).[59]\nAlgoritmo [67]:\n\nPara \\(i\\) desde \\(1\\) hasta \\(N\\):\n\nEntrenar el modelo \\(M_i\\) en todas las muestras excepto la muestra \\(i\\) (tamaño de entrenamiento \\(N-1\\)).[59]\nEvaluar (testear) el modelo \\(M_i\\) en la única muestra \\(i\\) que se omitió.[59, 67]\n\nEl error \\(E_{LOOCV}\\) es el promedio de los \\(N\\) errores.\n\nPropiedad: El proceso es determinista (no hay aleatoriedad en las particiones, ya que solo hay una forma de omitir un punto).[68]"
  },
  {
    "objectID": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#v.-análisis-teórico-comparativo-de-las-técnicas-de-validación",
    "href": "recursos/documentos/ASIM/EvaluacionModelosMachineLearning.html#v.-análisis-teórico-comparativo-de-las-técnicas-de-validación",
    "title": "Evaluación de la Calidad de los Modelos",
    "section": "V. Análisis Teórico Comparativo de las Técnicas de Validación",
    "text": "V. Análisis Teórico Comparativo de las Técnicas de Validación\nLa selección de una técnica de validación (Holdout, K-Fold, LOOCV) implica un tradeoff de sesgo-varianza en la estimación del error de generalización. Es crucial no confundir esto con el sesgo-varianza del modelo en sí.\n\nSección 5.1 Análisis del Sesgo (Precisión del Estimador)\nEl sesgo del estimador de error mide qué tan lejos está el error estimado (\\(E_{CV}\\)) del verdadero error de generalización (\\(R(f)\\)) que tendría un modelo entrenado en todos los datos (\\(N\\)).[61]\nTodos los métodos de validación (Holdout, K-Fold) entrenan modelos en subconjuntos de los datos (ej. 70% de \\(N\\), o \\((k-1)/k\\) de \\(N\\)). Los modelos entrenados con menos datos son, en promedio, peores (tienen mayor error) que el modelo final entrenado con el 100% de los datos.[59]\nConsecuencia: El error estimado (\\(E_{CV}\\)) es pesimista, es decir, sobreestima el verdadero error del modelo final.\n\nHoldout (ej. 70/30): Entrena en el 70% de los datos. El tamaño del entrenamiento es significativamente menor que \\(N\\). El sesgo pesimista es alto.\nK-Fold (k=10): Entrena en el 90% de los datos. El sesgo pesimista es pequeño.[69]\nLOOCV: Entrena en \\(N-1\\) datos (casi el 100%). El modelo es casi idéntico al modelo final. El sesgo es casi cero.[68] LOOCV es un estimador casi insesgado del error de generalización.\n\n\n\nSección 5.2 Análisis de la Varianza (Estabilidad del Estimador)\nLa varianza del estimador de error mide qué tan sensible es la estimación (\\(E_{CV}\\)) a la composición del dataset. Si repitiéramos el proceso en un dataset \\(D'\\) diferente (muestreado de la misma \\(P(x,y)\\)), ¿cuánto cambiaría \\(E_{CV}\\)?.[61]\n\nHoldout: Varianza alta.[56] La estimación depende totalmente de una única partición aleatoria.\nK-Fold (k=5, k=10): Varianza baja.[61, 69] El promedio sobre \\(k\\) folds estabiliza la estimación.[62]\nLOOCV: Varianza alta.[59, 67, 69]\n\nLa Paradoja de LOOCV (Bajo Sesgo, Alta Varianza):\nEsto es un resultado teórico fundamental y contraintuitivo. ¿Cómo puede LOOCV (que promedia \\(N\\) resultados) tener alta varianza?.[59, 69]\nLa razón es la correlación. En LOOCV, los \\(N\\) modelos entrenados son casi idénticos. El modelo \\(M_1\\) (entrenado en \\(D - \\{d_1\\}\\)) y el modelo \\(M_2\\) (entrenado en \\(D - \\{d_2\\}\\)) comparten \\(N-2\\) de sus \\(N-1\\) puntos de entrenamiento. Por lo tanto, los \\(N\\) modelos están altamente correlacionados.[59]\nEstadísticamente, la varianza del promedio de variables altamente correlacionadas no se reduce significativamente. (La fórmula \\(\\frac{\\sigma^2}{N}\\) para la varianza de la media solo aplica si las variables son independientes). LOOCV promedia \\(N\\) estimaciones de error que están muy correlacionadas, resultando en un estimador final \\(E_{LOOCV}\\) con alta varianza.[59, 69]\n\n\nSección 5.3 Análisis del Costo Computacional\n\nHoldout: Costo \\(O(1)\\). Se entrena 1 modelo.\nK-Fold: Costo \\(O(k)\\). Se entrenan \\(k\\) modelos.[59]\nLOOCV: Costo \\(O(N)\\). Se entrenan \\(N\\) modelos.[59, 67, 70]\n\nConsecuentemente, LOOCV es computacionalmente inviable para datasets grandes (ej. \\(N &gt; 10,000\\)) o para modelos cuyo entrenamiento es costoso (ej. Redes Neuronales Profundas).[70]\n\n\nSección 5.4 Síntesis y Recomendación Práctica\nEl tradeoff en la selección de la técnica de validación es triple: Sesgo vs. Varianza vs. Costo.\n\nHoldout: Rápido (O(1)), pero alto sesgo y alta varianza. No recomendado, excepto para datasets masivos donde el test set es suficientemente grande.\nLOOCV: Sesgo casi nulo, pero alta varianza y costo computacional O(N). No recomendado, excepto para datasets muy pequeños donde maximizar los datos de entrenamiento es la única prioridad.[68, 70]\nK-Fold (k=5 o k=10): Es el estándar empírico y teórico.[59, 61, 69] Proporciona el mejor compromiso [69]:\n\nBajo sesgo (entrena en 80%-90% de los datos).\nBaja varianza (promedia sobre \\(k\\) folds suficientemente diferentes).\nCosto computacional manejable (O(k)).\n\n\nTabla 4: Comparativa Teórica de Técnicas de Validación\n\n\n\n\n\n\n\n\n\n\nTécnica\nSesgo del Estimador de Error\nVarianza del Estimador de Error\nCosto Computacional\nTamaño del Set de Entrenamiento\n\n\n\n\nHoldout\nAlto (Pesimista)\nAlta (Inestable) [56]\n\\(O(1)\\) (Bajo)\n(ej. 70% N)\n\n\nK-Fold (k=5, 10)\nBajo (Pesimista) [69]\nBaja (Estable) [61, 69]\n\\(O(k)\\) (Moderado) [59]\n\\(\\frac{k-1}{k} N\\)\n\n\nLOOCV (k=N)\nMuy Bajo (Casi Insesgado) [68]\nAlta (Inestable) [59, 69]\n\\(O(N)\\) (Alto) [67, 70]\n\\(N-1\\)"
  },
  {
    "objectID": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html",
    "href": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html",
    "title": "Redes Neuronales Recurrentes en Series Temporales Biomédicas",
    "section": "",
    "text": "[cite_start]La medicina contemporánea se caracteriza por la generación masiva de datos con dependencia temporal intrínseca, provenientes de fuentes como electroencefalogramas (EEG) y Unidades de Medición Inercial (IMU)[cite: 9, 10]. [cite_start]A diferencia de las imágenes estáticas, estos datos encapsulan la dinámica fisiológica, donde el estado actual \\(x_t\\) está causalmente vinculado a su historial \\(x_{t-1}, \\dots, x_{t-k}\\)[cite: 11, 13].\n[cite_start]El presente reporte técnico aborda la ineficacia de las redes feedforward convencionales para tratar esta autocorrelación y propone el uso de Redes Neuronales Recurrentes (RNN), específicamente arquitecturas LSTM, para mitigar el problema del desvanecimiento del gradiente en secuencias largas[cite: 12, 36]. [cite_start]Asimismo, se discute la necesidad imperativa de superar la naturaleza de “caja negra” mediante técnicas de Inteligencia Artificial Explicable (XAI) como ShaTS y Causalidad de Granger Neural[cite: 18, 22]."
  },
  {
    "objectID": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#introducción-secuencialidad-en-biomedicina",
    "href": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#introducción-secuencialidad-en-biomedicina",
    "title": "Redes Neuronales Recurrentes en Series Temporales Biomédicas",
    "section": "",
    "text": "[cite_start]La medicina contemporánea se caracteriza por la generación masiva de datos con dependencia temporal intrínseca, provenientes de fuentes como electroencefalogramas (EEG) y Unidades de Medición Inercial (IMU)[cite: 9, 10]. [cite_start]A diferencia de las imágenes estáticas, estos datos encapsulan la dinámica fisiológica, donde el estado actual \\(x_t\\) está causalmente vinculado a su historial \\(x_{t-1}, \\dots, x_{t-k}\\)[cite: 11, 13].\n[cite_start]El presente reporte técnico aborda la ineficacia de las redes feedforward convencionales para tratar esta autocorrelación y propone el uso de Redes Neuronales Recurrentes (RNN), específicamente arquitecturas LSTM, para mitigar el problema del desvanecimiento del gradiente en secuencias largas[cite: 12, 36]. [cite_start]Asimismo, se discute la necesidad imperativa de superar la naturaleza de “caja negra” mediante técnicas de Inteligencia Artificial Explicable (XAI) como ShaTS y Causalidad de Granger Neural[cite: 18, 22]."
  },
  {
    "objectID": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#fundamentos-matemáticos",
    "href": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#fundamentos-matemáticos",
    "title": "Redes Neuronales Recurrentes en Series Temporales Biomédicas",
    "section": "2. Fundamentos Matemáticos",
    "text": "2. Fundamentos Matemáticos\n\n2.1. Dinámica de la RNN Estándar\nUna RNN procesa una secuencia de entrada \\(x=(x_1, ..., x_T)\\) manteniendo un estado oculto \\(h_t\\). [cite_start]La actualización se define formalmente como[cite: 29]:\n\\[\nh_t = \\tanh(W_{hh}h_{t-1} + W_{xh}x_t + b_h)\n\\]\n[cite_start]Donde \\(W_{hh}\\) modula la memoria a corto plazo y \\(W_{xh}\\) proyecta la entrada al espacio latente[cite: 31, 32]. [cite_start]Sin embargo, durante la retropropagación a través del tiempo (BPTT), la multiplicación repetida de \\(W_{hh}\\) conduce al desvanecimiento o explosión del gradiente, impidiendo el aprendizaje de dependencias temporales extensas, como precursores tempranos de caídas[cite: 37, 40].\n\n\n2.2. Arquitectura LSTM (Long Short-Term Memory)\n[cite_start]La arquitectura LSTM introduce una celda de memoria \\(c_t\\) y un mecanismo de compuertas para regular el flujo de información, permitiendo que el gradiente fluya sin perturbaciones multiplicativas severas[cite: 42, 43]. [cite_start]Las ecuaciones que rigen una celda LSTM en el instante \\(t\\) son [cite: 46-60]:\n\nCompuerta de Olvido (\\(f_t\\)): Determina la información irrelevante del estado anterior.\n\\[f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\\]\nCompuerta de Entrada (\\(i_t\\)) y Estado Candidato (\\(\\tilde{c}_t\\)):\n\\[i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\\]\n\\[\\tilde{c}_t = \\tanh(W_c \\cdot [h_{t-1}, x_t] + b_c)\\]\nActualización de la Celda (\\(c_t\\)): Operación lineal aditiva crítica para la preservación del gradiente.\n\\[c_t = f_t \\odot c_{t-1} + i_t \\odot \\tilde{c}_t\\]\nSalida (\\(h_t\\)):\n\\[o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\\]\n\\[h_t = o_t \\odot \\tanh(c_t)\\]"
  },
  {
    "objectID": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#metodología-e-implementación-técnica",
    "href": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#metodología-e-implementación-técnica",
    "title": "Redes Neuronales Recurrentes en Series Temporales Biomédicas",
    "section": "3. Metodología e Implementación Técnica",
    "text": "3. Metodología e Implementación Técnica\n[cite_start]El flujo de trabajo se basa en el análisis del dataset SisFall, considerando la física de los sensores (acelerometría y giroscopía) y la ubicación biomecánica en la zona lumbar (L4-L5) para aproximar el Centro de Masa (CoM)[cite: 70, 81].\n\n3.1. Ingeniería de Datos: Ventanas Deslizantes\n[cite_start]Dado el requisito de Lead Time (~400ms) para sistemas de protección activa, se segmentan las señales continuas utilizando ventanas deslizantes[cite: 97, 108].\n\n[cite_start]Nota Técnica: Se recomienda un tamaño de ventana entre 1.28s y 2.0s (128-200 muestras a 100Hz) con una superposición del 50%-90% para evitar perder eventos en los bordes de la ventana[cite: 111, 112].\n\n\n\n3.2. Arquitectura del Modelo en PyTorch\nLa implementación de la clase BiomedicalLSTM hereda de nn.Module. [cite_start]Es crítico configurar batch_first=True para alinear la entrada con el formato \\((N, L, H_{in})\\) generado en el preprocesamiento[cite: 119]. [cite_start]Para tareas de clasificación, se extrae el último estado oculto \\(h_n\\) o output[:, -1, :][cite: 126].\n\n\n3.3. Estrategia de Entrenamiento y Función de Pérdida\n[cite_start]El desequilibrio de clases (caídas son eventos raros frente a ADLs) requiere estrategias de ponderación. Se implementa el uso de pos_weight en la función de pérdida para penalizar fuertemente los falsos negativos[cite: 102, 131]."
  },
  {
    "objectID": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#interpretabilidad-y-análisis-causal",
    "href": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#interpretabilidad-y-análisis-causal",
    "title": "Redes Neuronales Recurrentes en Series Temporales Biomédicas",
    "section": "4. Interpretabilidad y Análisis Causal",
    "text": "4. Interpretabilidad y Análisis Causal\n\n4.1. ShaTS: Superando las limitaciones de SHAP\n[cite_start]SHAP estándar asume independencia entre características, una premisa violada en series temporales donde \\(x_t \\approx x_{t-1}\\)[cite: 139]. [cite_start]Para mitigar esto, se emplea ShaTS (Shapley Values for Time Series), que implementa estrategias de agrupamiento[cite: 141]:\n\nAgrupamiento Temporal: Analiza la relevancia de intervalos de tiempo específicos (ej. fase de impacto).\nAgrupamiento de Sensores: Determina si la decisión se basó en acelerometría o giroscopía.\n\n[cite_start]Figura 1: (Descripción Teórica) Heatmaps poblacionales que revelan patrones biomecánicos, como la mayor relevancia del eje vertical (\\(Acel_Z\\)) en poblaciones geriátricas frente a jóvenes[cite: 156, 157].\n\n\n4.2. Causalidad de Granger Neural\nMás allá de la correlación, se busca establecer causalidad (si el pasado de \\(X\\) mejora la predicción de \\(Y\\)). Se utilizan arquitecturas Component-wise LSTM (cLSTM). [cite_start]A diferencia de los modelos feedforward, las cLSTM utilizan \\(T-1\\) puntos de la secuencia, ofreciendo mayor robustez en eventos cortos[cite: 168].\n[cite_start]Para descubrir la estructura causal (Matriz de Adyacencia), se aplican penalizaciones de esparcidad durante el entrenamiento, como Group Lasso, forzando a cero los pesos de conexiones irrelevantes entre series temporales[cite: 172]."
  },
  {
    "objectID": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#conclusiones",
    "href": "recursos/documentos/ASIM/Resumen_RNN_LSTM.html#conclusiones",
    "title": "Redes Neuronales Recurrentes en Series Temporales Biomédicas",
    "section": "5. Conclusiones",
    "text": "5. Conclusiones\n[cite_start]El análisis confirma a las LSTM como la arquitectura superior para datos IMU debido a su gestión de dependencias temporales[cite: 180]. [cite_start]No obstante, la implementación exitosa depende críticamente de una ingeniería de datos alineada con la física (ventanas, manejo de desequilibrio) y de la integración de módulos de interpretabilidad (ShaTS) y causalidad (Neural Granger) para garantizar la confiabilidad clínica del sistema[cite: 181, 183]."
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "",
    "text": "La evaluación de la calidad de los datos es una etapa crítica del análisis exploratorio, pues condiciona la validez estadística y la interpretabilidad de los modelos. Este documento se basa en el archivo injury risk. En este documento se operacionalizan criterios y procedimientos para:\n\nRegresión: knee_flex_deg (continua).\nClasificación: Risk_Lesion (categórica).\n\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Knee_Flex_deg      1000 non-null   float64\n 1   EMG_Quad_RMS_mV    1000 non-null   float64\n 2   EMG_Ham_RMS_mV     1000 non-null   float64\n 3   GRF_Vert_Norm_BW   1000 non-null   float64\n 4   Omega_Shank_deg_s  1000 non-null   float64\n 5   Hip_Flex_deg       1000 non-null   float64\n 6   Risk_Lesion        1000 non-null   float64\ndtypes: float64(7)\nmemory usage: 54.8 KB"
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#introducción",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#introducción",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "",
    "text": "La evaluación de la calidad de los datos es una etapa crítica del análisis exploratorio, pues condiciona la validez estadística y la interpretabilidad de los modelos. Este documento se basa en el archivo injury risk. En este documento se operacionalizan criterios y procedimientos para:\n\nRegresión: knee_flex_deg (continua).\nClasificación: Risk_Lesion (categórica).\n\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Knee_Flex_deg      1000 non-null   float64\n 1   EMG_Quad_RMS_mV    1000 non-null   float64\n 2   EMG_Ham_RMS_mV     1000 non-null   float64\n 3   GRF_Vert_Norm_BW   1000 non-null   float64\n 4   Omega_Shank_deg_s  1000 non-null   float64\n 5   Hip_Flex_deg       1000 non-null   float64\n 6   Risk_Lesion        1000 non-null   float64\ndtypes: float64(7)\nmemory usage: 54.8 KB"
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#identificación-de-valores-faltantes",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#identificación-de-valores-faltantes",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "1. Identificación de valores faltantes",
    "text": "1. Identificación de valores faltantes\nSe cuantifican porcentajes de celdas vacías y se priorizan acciones: eliminar (&gt;60%), imputar (30–60%), o evaluar impacto (&lt;30%).\n\nmissing_tbl = (df.isna().mean().sort_values(ascending=False)*100.0).round(2).to_frame(\"Porc_Faltantes_%\")\nmissing_tbl.head(20)\n\n                   Porc_Faltantes_%\nKnee_Flex_deg                   0.0\nEMG_Quad_RMS_mV                 0.0\nEMG_Ham_RMS_mV                  0.0\nGRF_Vert_Norm_BW                0.0\nOmega_Shank_deg_s               0.0\nHip_Flex_deg                    0.0\nRisk_Lesion                     0.0\n\n\n\nVisualización de valores faltantes por variable\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, max(3, len(missing_tbl)*0.25)))\nvals = missing_tbl[\"Porc_Faltantes_%\"].values\nlabs = missing_tbl.index.values\nypos = np.arange(len(labs))\nplt.barh(ypos, vals)\nplt.yticks(ypos, labs)\n\n([&lt;matplotlib.axis.YTick object at 0x76cfa8adacf0&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa8acb250&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa8963250&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa89639d0&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa899c190&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa899c910&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa899d090&gt;], [Text(0, 0, 'Knee_Flex_deg'), Text(0, 1, 'EMG_Quad_RMS_mV'), Text(0, 2, 'EMG_Ham_RMS_mV'), Text(0, 3, 'GRF_Vert_Norm_BW'), Text(0, 4, 'Omega_Shank_deg_s'), Text(0, 5, 'Hip_Flex_deg'), Text(0, 6, 'Risk_Lesion')])\n\nplt.xlabel(\"% de celdas faltantes\")\nplt.title(\"Porcentaje de valores faltantes por variable\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#detección-de-cardinalidad-irregular",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#detección-de-cardinalidad-irregular",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "2. Detección de cardinalidad irregular",
    "text": "2. Detección de cardinalidad irregular\nSe inspecciona el número de valores únicos por variable para detectar: cardinalidad 1 (sin información), codificaciones erróneas o cardinalidad excesiva.\n\ncard_tbl = df.nunique(dropna=False).sort_values(ascending=True).to_frame(\"Cardinalidad\")\ncard_tbl.head(20)\n\n                   Cardinalidad\nRisk_Lesion                   2\nKnee_Flex_deg               772\nEMG_Ham_RMS_mV             1000\nEMG_Quad_RMS_mV            1000\nGRF_Vert_Norm_BW           1000\nOmega_Shank_deg_s          1000\nHip_Flex_deg               1000\n\n\n\nDistribución de cardinalidad (todas las columnas)\n\nplt.figure(figsize=(10, max(3, len(card_tbl)*0.25)))\nvals = card_tbl[\"Cardinalidad\"].values\nlabs = card_tbl.index.values\nypos = np.arange(len(labs))\nplt.barh(ypos, vals)\nplt.yticks(ypos, labs)\n\n([&lt;matplotlib.axis.YTick object at 0x76cfa89cb9d0&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa8835f90&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa8836710&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa8836e90&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa8837610&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa8837d90&gt;, &lt;matplotlib.axis.YTick object at 0x76cfa885c550&gt;], [Text(0, 0, 'Risk_Lesion'), Text(0, 1, 'Knee_Flex_deg'), Text(0, 2, 'EMG_Ham_RMS_mV'), Text(0, 3, 'EMG_Quad_RMS_mV'), Text(0, 4, 'GRF_Vert_Norm_BW'), Text(0, 5, 'Omega_Shank_deg_s'), Text(0, 6, 'Hip_Flex_deg')])\n\nplt.xlabel(\"Número de valores únicos\")\nplt.title(\"Cardinalidad por variable\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#detección-de-valores-atípicos-outliers",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#detección-de-valores-atípicos-outliers",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "3. Detección de valores atípicos (Outliers)",
    "text": "3. Detección de valores atípicos (Outliers)\nSe consideran dos enfoques: IQR de Tukey y z-score.\n\nfrom typing import Tuple, Dict\n\ndef outlier_bounds_iqr(series: pd.Series, k: float = 1.5) -&gt; Tuple[float, float]:\n    s = series.dropna().astype(float)\n    q1 = np.percentile(s, 25)\n    q3 = np.percentile(s, 75)\n    iqr = q3 - q1\n    lo = q1 - k*iqr\n    hi = q3 + k*iqr\n    return lo, hi\n\ndef outlier_summary(df_num: pd.DataFrame, method: str = \"iqr\", k: float = 1.5, z: float = 3.0) -&gt; pd.DataFrame:\n    rows = []\n    for col in df_num.columns:\n        s = df_num[col].dropna().astype(float)\n        if s.empty:\n            continue\n        if method == \"iqr\":\n            lo, hi = outlier_bounds_iqr(s, k=k)\n            out = ((df_num[col] &lt; lo) | (df_num[col] &gt; hi)).sum()\n            rows.append((col, lo, hi, int(out)))\n        else:\n            m = s.mean(); sd = s.std(ddof=0)\n            if sd == 0:\n                rows.append((col, np.nan, np.nan, 0))\n            else:\n                out = ((np.abs((df_num[col]-m)/sd)) &gt; z).sum()\n                rows.append((col, m - z*sd, m + z*sd, int(out)))\n    return pd.DataFrame(rows, columns=[\"Variable\", \"Límite_inferior\", \"Límite_superior\", \"Conteo_outliers\"])\n\ndf_num = df.select_dtypes(include=[np.number])\niqr_tbl = outlier_summary(df_num, method=\"iqr\", k=1.5).sort_values(\"Conteo_outliers\", ascending=False)\nz_tbl   = outlier_summary(df_num, method=\"z\",   z=3.0).sort_values(\"Conteo_outliers\", ascending=False)\n\niqr_tbl.head(15), z_tbl.head(15)\n\n(            Variable  Límite_inferior  Límite_superior  Conteo_outliers\n0      Knee_Flex_deg      -101.289727       164.359342                0\n1    EMG_Quad_RMS_mV        -0.101106         0.366573                0\n2     EMG_Ham_RMS_mV        -0.092222         0.302515                0\n3   GRF_Vert_Norm_BW        -0.630861         1.957452                0\n4  Omega_Shank_deg_s      -801.247432       784.800697                0\n5       Hip_Flex_deg       -34.877758        64.126131                0\n6        Risk_Lesion        -1.500000         2.500000                0,             Variable  Límite_inferior  Límite_superior  Conteo_outliers\n0      Knee_Flex_deg       -74.265149       147.551616                0\n1    EMG_Quad_RMS_mV        -0.068715         0.334233                0\n2     EMG_Ham_RMS_mV        -0.060132         0.272798                0\n3   GRF_Vert_Norm_BW        -0.479935         1.786190                0\n4  Omega_Shank_deg_s      -694.930515       679.530591                0\n5       Hip_Flex_deg       -28.294709        57.705241                0\n6        Risk_Lesion        -0.993892         2.005892                0)\n\n\n\nBoxplots univariados seleccionados (matplotlib)\n\ncols_plot = [c for c in df_num.columns if c.lower() in [\"knee_flex_deg\", \"bodymass\", \"height\"]]\nif not cols_plot:\n    # Selección automática de hasta 3 numéricas\n    cols_plot = df_num.columns.tolist()[:3]\n\nfig, axes = plt.subplots(nrows=len(cols_plot), ncols=1, figsize=(9, 4*len(cols_plot)))\nif len(cols_plot) == 1:\n    axes = [axes]\n\nfor ax, col in zip(axes, cols_plot):\n    ax.boxplot(df_num[col].dropna().astype(float), vert=True, showmeans=True)\n    ax.set_title(f\"Boxplot: {col}\")\n    ax.set_ylabel(col)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#validez-contextual-reglas-de-plausibilidad",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#validez-contextual-reglas-de-plausibilidad",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "4. Validez contextual (reglas de plausibilidad)",
    "text": "4. Validez contextual (reglas de plausibilidad)\nSe definen reglas de plausibilidad fisiológica/experimental y se generan banderas de validación.\n\nflags = {}\nif \"knee_flex_deg\" in df.columns:\n    s = pd.to_numeric(df[\"knee_flex_deg\"], errors=\"coerce\")\n    flags[\"knee_flex_deg_out_of_range\"] = ~s.between(0, 180)  # rango articular plausible (ajuste si aplica)\n\nif \"bodymass\" in df.columns:\n    s = pd.to_numeric(df[\"bodymass\"], errors=\"coerce\")\n    flags[\"bodymass_out_of_range\"] = ~s.between(30, 300)      # ejemplo amplio; ajuste según protocolo\n\nval_flags = pd.DataFrame(flags) if flags else pd.DataFrame()\nval_flags.sum() if not val_flags.empty else \"No se definieron reglas de plausibilidad para las variables presentes.\"\n\n'No se definieron reglas de plausibilidad para las variables presentes.'"
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#análisis-de-correlación-soporte-a-decisiones",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#análisis-de-correlación-soporte-a-decisiones",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "5. Análisis de correlación (soporte a decisiones)",
    "text": "5. Análisis de correlación (soporte a decisiones)\nPara orientar transformaciones o selección de variables se explora la correlación entre numéricas.\n\ncorr = df_num.corr(numeric_only=True)\ncorr.round(3).iloc[:8, :8]  # vista parcial\n\n                   Knee_Flex_deg  EMG_Quad_RMS_mV  ...  Hip_Flex_deg  Risk_Lesion\nKnee_Flex_deg              1.000            0.028  ...         0.178        0.118\nEMG_Quad_RMS_mV            0.028            1.000  ...         0.035       -0.446\nEMG_Ham_RMS_mV            -0.063            0.029  ...         0.033        0.273\nGRF_Vert_Norm_BW           0.087            0.015  ...        -0.009        0.037\nOmega_Shank_deg_s          0.940           -0.029  ...        -0.045        0.066\nHip_Flex_deg               0.178            0.035  ...         1.000        0.050\nRisk_Lesion                0.118           -0.446  ...         0.050        1.000\n\n[7 rows x 7 columns]\n\n\n\nMapa de calor de correlaciones (matplotlib, sin seaborn)\n\nplt.figure(figsize=(8,6))\nim = plt.imshow(corr, interpolation='nearest', aspect='auto')\n_ = plt.colorbar(im, fraction=0.046, pad=0.04)\n_ = plt.xticks(ticks=np.arange(len(corr.columns)), labels=corr.columns, rotation=90)\n_ = plt.yticks(ticks=np.arange(len(corr.index)), labels=corr.index)\n_ = plt.title(\"Matriz de correlación (numéricas)\")\n_ = plt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#estructura-de-clases-para-risk_lesion-si-aplica",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#estructura-de-clases-para-risk_lesion-si-aplica",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "6. Estructura de clases para Risk_Lesion (si aplica)",
    "text": "6. Estructura de clases para Risk_Lesion (si aplica)\nSe inspecciona balance de clases y su impacto potencial en métricas y validación.\n\nif \"Risk_Lesion\" in df.columns:\n    vc = df[\"Risk_Lesion\"].value_counts(dropna=False)\n    vcp = df[\"Risk_Lesion\"].value_counts(normalize=True, dropna=False).mul(100).round(2)\n    display_tbl = pd.DataFrame({\"Conteo\": vc, \"Porcentaje_%\": vcp})\n    display_tbl\nelse:\n    \"La variable 'Risk_Lesion' no está presente en el dataset.\"\n\n             Conteo  Porcentaje_%\nRisk_Lesion                      \n1.0             506          50.6\n0.0             494          49.4\n\n\n\nBarras de distribución de clases (matplotlib)\n\n\n&lt;Figure size 600x400 with 0 Axes&gt;\n&lt;BarContainer object of 2 artists&gt;\nText(0.5, 0, 'Clase')\nText(0, 0.5, 'Frecuencia')\nText(0.5, 1.0, 'Distribución de clases: Risk_Lesion')"
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#plan-de-calidad-de-datos-plantilla",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#plan-de-calidad-de-datos-plantilla",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "7. Plan de Calidad de Datos (plantilla)",
    "text": "7. Plan de Calidad de Datos (plantilla)\nUse la siguiente plantilla para documentar problemas detectados y acciones.\n\n\n\n\n\n\n\n\n\n\n\nVariable\nProblema detectado\nEvidencia/Regla\nAcción propuesta\nResponsable\nFecha\n\n\n\n\nknee_flex_deg\nOutliers (&gt;p99)\nIQR/Z-score\nValidar en ficha clínica / Winsorizar\nEquipo clínico\nAAAA-MM-DD\n\n\nRisk_Lesion\nDesequilibrio\nConteo de clases\nMuestreo estratificado / Umbrales\nEquipo DS\nAAAA-MM-DD\n\n\nbodymass\nFaltantes 8%\n% faltantes\nImputación mediana\nEquipo DS\nAAAA-MM-DD\n\n\nDominancia\nCodificación heterogénea\nCardinalidad/etiquetas\nNormalizar etiquetas\nEquipo DS\nAAAA-MM-DD"
  },
  {
    "objectID": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#recomendaciones-para-el-modelado-posterior",
    "href": "recursos/documentos/ASIM/AnalisisExploratorioDatos_Basico.html#recomendaciones-para-el-modelado-posterior",
    "title": "Evaluación de la Calidad de los Datos",
    "section": "8. Recomendaciones para el modelado posterior",
    "text": "8. Recomendaciones para el modelado posterior\n\nRegresión (knee_flex_deg): evaluar transformaciones (log/sqrt) si hay asimetría marcada; controlar outliers (winsorización o RobustScaler).\nClasificación (Risk_Lesion): balancear clases si hay desproporción; definir métrica principal (AUC/F1) y validación estratificada."
  },
  {
    "objectID": "recursos/documentos/SYSB/TransformadaLaplaceZ.html",
    "href": "recursos/documentos/SYSB/TransformadaLaplaceZ.html",
    "title": "Transformada de Laplace y Transformada Z en el Análisis de Señales Biomédicas",
    "section": "",
    "text": "El cuerpo humano es un sistema complejo que genera una multitud de señales fisiológicas. La captura y el análisis de estas señales biomédicas, como el Electrocardiograma (ECG), el Electroencefalograma (EEG) o el Electromiograma (EMG), son cruciales para la medicina moderna. Estas señales, en su forma cruda, están frecuentemente contaminadas por ruido (artefactos) o contienen información superpuesta que debe ser separada y analizada [1].\nEl procesamiento digital y analógico de señales ofrece un conjunto de herramientas matemáticas para aislar componentes de interés, diseñar filtros y modelar sistemas fisiológicos. Históricamente, el análisis se realizaba en el dominio del tiempo, observando la evolución de la señal cronológicamente. Sin embargo, muchas propiedades de las señales y de los sistemas que las procesan (como los filtros) son mucho más fáciles de entender y manipular en un dominio transformado.\n\n\n\nEl objetivo de este reporte es presentar los fundamentos teóricos y las aplicaciones prácticas de dos de las herramientas de transformación más importantes en la ingeniería: la Transformada de Laplace (TL) y la Transformada Z (TZ).\nLa Transformada de Laplace es la herramienta por excelencia para el análisis de señales y sistemas en tiempo continuo (CT). Permite modelar componentes analógicos, analizar la estabilidad de sistemas y resolver ecuaciones diferenciales lineales que describen fenómenos fisiológicos.\nPor otro lado, la Transformada Z es la contraparte directa de la TL para el análisis de señales y sistemas en tiempo discreto (DT). Dado que el procesamiento moderno de señales se realiza casi exclusivamente en computadoras digitales, la TZ es fundamental para diseñar, implementar y analizar filtros digitales que operan sobre señales biomédicas muestreadas.\nEste documento está dirigido a estudiantes de pregrado en ingeniería biomédica y asume un conocimiento básico de cálculo y estadística descriptiva."
  },
  {
    "objectID": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#contexto-general",
    "href": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#contexto-general",
    "title": "Transformada de Laplace y Transformada Z en el Análisis de Señales Biomédicas",
    "section": "",
    "text": "El cuerpo humano es un sistema complejo que genera una multitud de señales fisiológicas. La captura y el análisis de estas señales biomédicas, como el Electrocardiograma (ECG), el Electroencefalograma (EEG) o el Electromiograma (EMG), son cruciales para la medicina moderna. Estas señales, en su forma cruda, están frecuentemente contaminadas por ruido (artefactos) o contienen información superpuesta que debe ser separada y analizada [1].\nEl procesamiento digital y analógico de señales ofrece un conjunto de herramientas matemáticas para aislar componentes de interés, diseñar filtros y modelar sistemas fisiológicos. Históricamente, el análisis se realizaba en el dominio del tiempo, observando la evolución de la señal cronológicamente. Sin embargo, muchas propiedades de las señales y de los sistemas que las procesan (como los filtros) son mucho más fáciles de entender y manipular en un dominio transformado."
  },
  {
    "objectID": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#objetivo-del-reporte",
    "href": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#objetivo-del-reporte",
    "title": "Transformada de Laplace y Transformada Z en el Análisis de Señales Biomédicas",
    "section": "",
    "text": "El objetivo de este reporte es presentar los fundamentos teóricos y las aplicaciones prácticas de dos de las herramientas de transformación más importantes en la ingeniería: la Transformada de Laplace (TL) y la Transformada Z (TZ).\nLa Transformada de Laplace es la herramienta por excelencia para el análisis de señales y sistemas en tiempo continuo (CT). Permite modelar componentes analógicos, analizar la estabilidad de sistemas y resolver ecuaciones diferenciales lineales que describen fenómenos fisiológicos.\nPor otro lado, la Transformada Z es la contraparte directa de la TL para el análisis de señales y sistemas en tiempo discreto (DT). Dado que el procesamiento moderno de señales se realiza casi exclusivamente en computadoras digitales, la TZ es fundamental para diseñar, implementar y analizar filtros digitales que operan sobre señales biomédicas muestreadas.\nEste documento está dirigido a estudiantes de pregrado en ingeniería biomédica y asume un conocimiento básico de cálculo y estadística descriptiva."
  },
  {
    "objectID": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#transformada-de-laplace-tl",
    "href": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#transformada-de-laplace-tl",
    "title": "Transformada de Laplace y Transformada Z en el Análisis de Señales Biomédicas",
    "section": "2.1. Transformada de Laplace (TL)",
    "text": "2.1. Transformada de Laplace (TL)\nLa Transformada de Laplace es una generalización de la Transformada de Fourier de Tiempo Continuo (CTFT). Mientras que la CTFT analiza una señal en términos de sus componentes senoidales (frecuencia \\(j\\omega\\)), la TL la analiza en términos de exponenciales complejas (frecuencia compleja \\(s = \\sigma + j\\omega\\)). Este componente \\(\\sigma\\) (sigma) permite a la TL analizar no solo la respuesta en frecuencia estacionaria, sino también el comportamiento transitorio y la estabilidad de los sistemas.\n\n2.1.1. Definición\nPara una señal en tiempo continuo \\(f(t)\\), la Transformada de Laplace unilateral (que asume \\(f(t) = 0\\) para \\(t &lt; 0\\), común en sistemas causales) se define como:\n\\[\nF(s) = \\mathcal{L}\\{f(t)\\} = \\int_{0^{-}}^{\\infty} f(t) e^{-st} dt\n\\]\nDonde \\(s\\) es la variable de frecuencia compleja, \\(s = \\sigma + j\\omega\\). La función \\(F(s)\\) resultante existe en el “plano s” (s-plane).\n\n\n2.1.2. Región de Convergencia (ROC)\nLa integral de Laplace no converge para todos los valores de \\(s\\). El conjunto de valores \\(s\\) para los cuales la integral converge se denomina Región de Convergencia (ROC). La ROC es crucial para definir unívocamente la señal en el tiempo, ya que diferentes señales \\(f(t)\\) pueden tener la misma expresión \\(F(s)\\) pero diferir en sus ROCs. Para sistemas causales y estables, la ROC siempre incluye el eje \\(j\\omega\\) (el eje imaginario).\n\n\n2.1.3. Propiedades Clave de la TL\nLa utilidad de la TL proviene de sus propiedades algebraicas, que convierten operaciones complejas en el dominio del tiempo (como la diferenciación, integración y convolución) en operaciones algebraicas simples en el dominio \\(s\\).\n\n\n2.1.4. Ejemplo Básico: Función Exponencial\nConsideremos una función exponencial decreciente, \\(f(t) = e^{-at}u(t)\\), donde \\(u(t)\\) es la función escalón unitario. Esta forma es la base de muchas respuestas de sistemas (p.ej., la descarga de un capacitor).\n\\[\nF(s) = \\int_{0}^{\\infty} e^{-at} e^{-st} dt = \\int_{0}^{\\infty} e^{-(s+a)t} dt\n\\]\n\\[\nF(s) = \\left[ \\frac{-1}{s+a} e^{-(s+a)t} \\right]_{0}^{\\infty}\n\\]\nEsta integral converge solo si la parte real de \\((s+a)\\) es positiva, es decir, \\(Re\\{s\\} + a &gt; 0\\) o \\(Re\\{s\\} &gt; -a\\). Esta es la ROC.\n\\[\nF(s) = 0 - \\left( \\frac{-1}{s+a} e^{0} \\right) = \\frac{1}{s+a}\n\\]"
  },
  {
    "objectID": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#transformada-z-tz",
    "href": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#transformada-z-tz",
    "title": "Transformada de Laplace y Transformada Z en el Análisis de Señales Biomédicas",
    "section": "2.2. Transformada Z (TZ)",
    "text": "2.2. Transformada Z (TZ)\nLa Transformada Z es la contraparte de la Transformada de Laplace para señales y sistemas de tiempo discreto (DT). Es la herramienta matemática fundamental para el procesamiento digital de señales.\n\n2.2.1. Definición\nPara una secuencia de tiempo discreto \\(x[n]\\) (una señal muestreada), la Transformada Z bilateral se define como:\n\\[\nX(z) = \\mathcal{Z}\\{x[n]\\} = \\sum_{n=-\\infty}^{\\infty} x[n] z^{-n}\n\\]\nDonde \\(z\\) es una variable compleja. En la práctica, para secuencias causales (que inician en \\(n=0\\)), se usa la TZ unilateral:\n\\[\nX(z) = \\sum_{n=0}^{\\infty} x[n] z^{-n}\n\\]\n\n\n2.2.2. Región de Convergencia (ROC)\nAl igual que la TL, la TZ tiene una ROC, que es el conjunto de valores \\(z\\) (en el “plano z”) para los cuales la suma converge. Para señales DT, la estabilidad se relaciona con la circunferencia unitaria (el círculo de radio 1 en el plano z). Un sistema LTI (Lineal e Invariante en el Tiempo) discreto es estable si y solo si su ROC incluye la circunferencia unitaria.\n\n\n2.2.3. Propiedades Clave de la TZ\nLas propiedades de la TZ son análogas a las de la TL y son igualmente poderosas para el análisis de sistemas discretos (como los filtros digitales).\n\n\n2.2.4. Ejemplo Básico: Exponencial Discreta\nConsideremos la secuencia exponencial causal \\(x[n] = a^n u[n]\\).\n\\[\nX(z) = \\sum_{n=0}^{\\infty} a^n z^{-n} = \\sum_{n=0}^{\\infty} (a z^{-1})^n\n\\]\nEsta es una serie geométrica. Converge a \\(\\frac{1}{1-r}\\) si \\(|r| &lt; 1\\). En nuestro caso, \\(r = a z^{-1}\\).\nLa serie converge si \\(|a z^{-1}| &lt; 1\\), o \\(|z| &gt; |a|\\). Esta es la ROC.\n\\[\nX(z) = \\frac{1}{1 - a z^{-1}} = \\frac{z}{z-a}\n\\]"
  },
  {
    "objectID": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#caso-1-análisis-de-ecg-y-transformada-de-laplace",
    "href": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#caso-1-análisis-de-ecg-y-transformada-de-laplace",
    "title": "Transformada de Laplace y Transformada Z en el Análisis de Señales Biomédicas",
    "section": "3.1. Caso 1: Análisis de ECG y Transformada de Laplace",
    "text": "3.1. Caso 1: Análisis de ECG y Transformada de Laplace\nAunque la mayoría del procesamiento de ECG hoy en día es digital, la Transformada de Laplace es indispensable para modelar el sistema de adquisición y los filtros analógicos (anti-aliasing) que preceden a la digitalización [1].\nProblema: Una señal de ECG está contaminada con ruido de alta frecuencia (p.ej., interferencia de la línea de alimentación de 60 Hz o ruido muscular EMG). Antes de muestrear la señal (digitalizarla), se debe usar un filtro analógico pasa-bajos.\nSolución con TL: Se puede diseñar un filtro RC (Resistor-Capacitor) simple. Este es un sistema LTI de tiempo continuo.\n[Image of RC low-pass filter circuit diagram]\nLa ecuación diferencial que describe este circuito es:\n\\(V_{in}(t) = R \\cdot i(t) + V_{out}(t)\\)\n\\(i(t) = C \\frac{d V_{out}(t)}{dt}\\)\nSustituyendo \\(i(t)\\):\n\\(V_{in}(t) = RC \\frac{d V_{out}(t)}{dt} + V_{out}(t)\\)\nAplicamos la Transformada de Laplace (usando la propiedad de diferenciación \\(s F(s)\\) y asumiendo condiciones iniciales cero):\n\\(V_{in}(s) = RC \\cdot s V_{out}(s) + V_{out}(s)\\)\n\\(V_{in}(s) = V_{out}(s) (RCs + 1)\\)\nLa Función de Transferencia \\(H(s)\\) del sistema es la relación entre la salida y la entrada en el dominio \\(s\\):\n\\[\nH(s) = \\frac{V_{out}(s)}{V_{in}(s)} = \\frac{1}{RCs + 1}\n\\]\nEsta \\(H(s)\\) describe completamente el filtro. La frecuencia de corte (frecuencia a la cual la potencia de la señal se reduce a la mitad) es \\(\\omega_c = 1/RC\\). Al elegir \\(R\\) y \\(C\\) apropiados, se puede establecer una frecuencia de corte (p.ej., 100 Hz) para atenuar el ruido de alta frecuencia antes de que la señal ECG sea digitalizada, previniendo el fenómeno de aliasing. La TL permite analizar la estabilidad y la respuesta en frecuencia de este componente analógico de forma sencilla."
  },
  {
    "objectID": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#caso-2-análisis-de-eeg-y-transformada-z",
    "href": "recursos/documentos/SYSB/TransformadaLaplaceZ.html#caso-2-análisis-de-eeg-y-transformada-z",
    "title": "Transformada de Laplace y Transformada Z en el Análisis de Señales Biomédicas",
    "section": "3.2. Caso 2: Análisis de EEG y Transformada Z",
    "text": "3.2. Caso 2: Análisis de EEG y Transformada Z\nEl EEG mide la actividad eléctrica cerebral. El análisis clínico y de investigación requiere aislar bandas de frecuencia específicas (Delta: 0.5-4 Hz, Theta: 4-8 Hz, Alpha: 8-12 Hz, Beta: 12-30 Hz) [2]. Este filtrado se realiza digitalmente después de que la señal ha sido muestreada.\nProblema: Aislar la banda Alpha (8-12 Hz) de una señal EEG muestreada a 250 Hz.\nSolución con TZ: Se debe diseñar un filtro digital pasa-banda. Los filtros digitales se describen mediante ecuaciones de diferencia (la contraparte discreta de las ecuaciones diferenciales).\nUn filtro digital simple (aunque no muy selectivo) es un filtro de media móvil (Moving Average, MA), que es un tipo de filtro de Respuesta Finita al Impulso (FIR):\n\\(y[n] = \\frac{1}{M} \\sum_{k=0}^{M-1} x[n-k]\\)\nAplicando la Transformada Z (usando la propiedad de retardo \\(z^{-k}X(z)\\)):\n\\(Y(z) = \\frac{1}{M} \\sum_{k=0}^{M-1} z^{-k} X(z)\\)\n\\(Y(z) = X(z) \\cdot \\left[ \\frac{1}{M} \\sum_{k=0}^{M-1} (z^{-1})^k \\right]\\)\nLa Función de Transferencia \\(H(z)\\) es:\n\\[\nH(z) = \\frac{Y(z)}{X(z)} = \\frac{1}{M} \\frac{1 - (z^{-1})^M}{1 - z^{-1}}\n\\]\nAunque este filtro es pasa-bajos, filtros más complejos (como los IIR, Infinite Impulse Response, p.ej., Butterworth o Chebyshev) se diseñan directamente en el dominio \\(z\\) (o se convierten desde el dominio \\(s\\)) para obtener la selectividad de frecuencia deseada (pasa-banda) [3]. La \\(H(z)\\) de un filtro IIR toma la forma de una función racional (un polinomio en \\(z^{-1}\\) dividido por otro), que es la base del procesamiento digital de señales:\n\\[\nH(z) = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{1 + \\sum_{k=1}^{N} a_k z^{-k}} = \\frac{B(z)}{A(z)}\n\\]\nLos coeficientes \\(b_k\\) y \\(a_k\\) son los que se implementan en el software (como Python o MATLAB) para filtrar la señal EEG."
  },
  {
    "objectID": "recursos/documentos/regresion_reporte.html",
    "href": "recursos/documentos/regresion_reporte.html",
    "title": "Modelado Estadístico Avanzado en Ingeniería Biomédica",
    "section": "",
    "text": "La ingeniería biomédica moderna se encuentra en una encrucijada fascinante donde la biología cuantitativa converge con el modelado estadístico avanzado. El desafío fundamental reside en decodificar sistemas biológicos complejos, ruidosos y variables a partir de observaciones limitadas. El análisis de datos biomédicos no es simplemente la aplicación de algoritmos a datos limpios; es un arte científico que requiere comprender la génesis fisiológica de los datos y las asunciones matemáticas subyacentes.\nEste documento desglosa la formulación matricial rigurosa de la Regresión Lineal y la Regresión Logística, contrastando la estimación por Mínimos Cuadrados Ordinarios (OLS) frente a la de Máxima Verosimilitud (MLE). Además, se aborda la inferencia causal, crucial para distinguir entre asociaciones estadísticas y mecanismos fisiológicos reales."
  },
  {
    "objectID": "recursos/documentos/regresion_reporte.html#introducción-intersección-entre-fisiología-y-estadística",
    "href": "recursos/documentos/regresion_reporte.html#introducción-intersección-entre-fisiología-y-estadística",
    "title": "Modelado Estadístico Avanzado en Ingeniería Biomédica",
    "section": "",
    "text": "La ingeniería biomédica moderna se encuentra en una encrucijada fascinante donde la biología cuantitativa converge con el modelado estadístico avanzado. El desafío fundamental reside en decodificar sistemas biológicos complejos, ruidosos y variables a partir de observaciones limitadas. El análisis de datos biomédicos no es simplemente la aplicación de algoritmos a datos limpios; es un arte científico que requiere comprender la génesis fisiológica de los datos y las asunciones matemáticas subyacentes.\nEste documento desglosa la formulación matricial rigurosa de la Regresión Lineal y la Regresión Logística, contrastando la estimación por Mínimos Cuadrados Ordinarios (OLS) frente a la de Máxima Verosimilitud (MLE). Además, se aborda la inferencia causal, crucial para distinguir entre asociaciones estadísticas y mecanismos fisiológicos reales."
  },
  {
    "objectID": "recursos/documentos/regresion_reporte.html#fundamentos-fisiológicos-y-estocasticidad-de-la-señal-emg",
    "href": "recursos/documentos/regresion_reporte.html#fundamentos-fisiológicos-y-estocasticidad-de-la-señal-emg",
    "title": "Modelado Estadístico Avanzado en Ingeniería Biomédica",
    "section": "2. Fundamentos Fisiológicos y Estocasticidad de la Señal EMG",
    "text": "2. Fundamentos Fisiológicos y Estocasticidad de la Señal EMG\nAntes de profundizar en el formalismo matemático, es imperativo establecer la naturaleza del fenómeno físico. La señal EMG es la manifestación eléctrica de la activación neuromuscular, resultante de la suma espaciotemporal de los potenciales de acción de las unidades motoras (MUAP).\n\n2.1 La Génesis Estocástica\nLa señal EMG bruta durante una contracción isométrica puede modelarse como un proceso estocástico Gaussiano de amplitud modulada. Esto es consecuencia directa del Teorema del Límite Central: la suma de muchas variables aleatorias independientes tiende a una distribución normal. Sin embargo, la varianza de esta distribución escala con la intensidad de la contracción, violando potencialmente el supuesto de homocedasticidad.\n\n\n2.2 Relación EMG-Fuerza\nUno de los objetivos primarios en biomecánica es estimar la fuerza muscular interna a partir de la señal EMG. Aunque en músculos pequeños la relación es lineal, en músculos grandes como el bíceps o deltoides, la relación suele ser no lineal (cuadrática o exponencial) debido a:\n\nReclutamiento de Unidades Motoras: Según el principio de Henneman, las fibras rápidas (Tipo II) se reclutan a mayores demandas de fuerza, incrementando desproporcionadamente la señal EMG.\nSinergias y Co-activación: La fuerza neta depende de la interacción entre músculos agonistas y antagonistas."
  },
  {
    "objectID": "recursos/documentos/regresion_reporte.html#regresión-lineal-teoría-y-estimación",
    "href": "recursos/documentos/regresion_reporte.html#regresión-lineal-teoría-y-estimación",
    "title": "Modelado Estadístico Avanzado en Ingeniería Biomédica",
    "section": "3. Regresión Lineal: Teoría y Estimación",
    "text": "3. Regresión Lineal: Teoría y Estimación\nLa regresión lineal es fundamental para modelar variables continuas. Su formulación matricial permite el manejo eficiente de grandes conjuntos de datos multivariados.\n\n3.1 Formulación del Modelo Lineal General\nPara \\(N\\) observaciones y \\(K\\) predictores, la variable de respuesta \\(y_i\\) se modela como:\n\\[ y_i = \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_K x_{iK} + \\epsilon_i \\]\nEn notación matricial compacta:\n\\[ \\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} \\]\nDonde \\(\\mathbf{y}\\) es el vector de respuesta (\\(N \\times 1\\)), \\(\\mathbf{X}\\) es la matriz de diseño (\\(N \\times (K+1)\\)), \\(\\boldsymbol{\\beta}\\) es el vector de parámetros y \\(\\boldsymbol{\\epsilon}\\) el vector de errores.\n\n\n3.2 Estimación por Mínimos Cuadrados Ordinarios (OLS)\nEl objetivo es minimizar la suma de los errores cuadrados (SSR). La función de costo \\(J(\\boldsymbol{\\beta})\\) es:\n\\[ J(\\boldsymbol{\\beta}) = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^T (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) \\]\nAl calcular el gradiente respecto a \\(\\boldsymbol{\\beta}\\) e igualarlo a cero, obtenemos las Ecuaciones Normales, que ofrecen una solución cerrada:\n\\[ \\hat{\\boldsymbol{\\beta}}_{OLS} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y} \\]\n\n\n3.3 Supuestos Críticos y Violaciones\nLa validez del estimador depende de los supuestos de Gauss-Markov:\n\nHomocedasticidad: La varianza del error debe ser constante. En biomecánica, esto se viola frecuentemente ya que el ruido aumenta con la fuerza.\nNo Autocorrelación: Los errores no deben estar correlacionados temporalmente. Las señales EMG muestreadas a alta frecuencia presentan alta autocorrelación, lo que subestima la varianza y produce p-values falsamente significativos."
  },
  {
    "objectID": "recursos/documentos/regresion_reporte.html#regresión-logística-clasificación-de-estados",
    "href": "recursos/documentos/regresion_reporte.html#regresión-logística-clasificación-de-estados",
    "title": "Modelado Estadístico Avanzado en Ingeniería Biomédica",
    "section": "4. Regresión Logística: Clasificación de Estados",
    "text": "4. Regresión Logística: Clasificación de Estados\nPara variables de respuesta binarias, como la presencia de fatiga o patología, utilizamos la Regresión Logística.\n\n4.1 Transformación Logit y Probabilidad\nModelamos la probabilidad \\(p = P(y=1|\\mathbf{x})\\) usando la función sigmoide para garantizar que esté en el intervalo \\((0, 1)\\). La relación se linealiza mediante el logit (log-odds):\n\\[ \\text{logit}(p) = \\ln \\left(\\frac{p}{1-p} \\right) = \\mathbf{x}^T\\boldsymbol{\\beta} \\]\nLos coeficientes \\(\\beta\\) se interpretan en términos de Odds Ratios (\\(e^{\\beta}\\)), indicando el cambio multiplicativo en las probabilidades de ocurrencia del evento.\n\n\n4.2 Estimación de Máxima Verosimilitud (MLE)\nDado que la relación es no lineal y los errores son binomiales, usamos MLE en lugar de OLS. Maximizamos la función de log-verosimilitud:\n\\[ \\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^{N} \\left[ y_i \\ln(h_{\\beta}(\\mathbf{x}_i)) + (1-y_i) \\ln(1-h_{\\beta}(\\mathbf{x}_i)) \\right] \\]\nLa solución se encuentra mediante métodos iterativos numéricos como Newton-Raphson:\n\\[ \\boldsymbol{\\beta}_{n+1} = \\boldsymbol{\\beta}_n - [\\mathbf{H}(\\boldsymbol{\\beta}_n)]^{-1} \\nabla \\ell(\\boldsymbol{\\beta}_n) \\]\nDonde \\(\\mathbf{H}\\) es la matriz Hessiana."
  },
  {
    "objectID": "recursos/documentos/regresion_reporte.html#implementación-computacional-en-python",
    "href": "recursos/documentos/regresion_reporte.html#implementación-computacional-en-python",
    "title": "Modelado Estadístico Avanzado en Ingeniería Biomédica",
    "section": "5. Implementación Computacional en Python",
    "text": "5. Implementación Computacional en Python\nA continuación, se presenta un flujo de trabajo utilizando statsmodels para inferencia estadística rigurosa.\n\n5.1 Simulación de Datos\nGeneramos datos sintéticos que incorporan características fisiológicas reales: no linealidad en la fuerza y cambios espectrales por fatiga.\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom typing import Tuple\n\ndef generar_datos_emg(n_samples: int = 1000) -&gt; pd.DataFrame:\n    \"\"\"\n    Simula datos de EMG, Fuerza y Fatiga con propiedades biomédicas realistas.\n\n    Args:\n        n_samples (int): Número de muestras a generar.\n\n    Returns:\n        pd.DataFrame: Dataset con columnas 'EMG', 'Fuerza', 'MDF', 'Fatiga'.\n    \"\"\"\n    np.random.seed(42)\n\n    # Variable Independiente: EMG RMS (0-100%)\n    emg_rms = np.linspace(0, 100, n_samples)\n\n    # Variable Dependiente 1: Fuerza (Modelo Cuadrático + Heterocedasticidad)\n    ruido = np.random.normal(0, 5 + 0.2 * emg_rms, n_samples)\n    fuerza = 2.0 + 3.5 * emg_rms + 0.015 * (emg_rms**2) + ruido\n\n    # Variable Dependiente 2: Fatiga (Basada en Frecuencia Mediana - MDF)\n    # La fatiga reduce la MDF (compresión espectral)\n    mdf = 100 - 0.5 * emg_rms + np.random.normal(0, 8, n_samples)\n\n    # Probabilidad de fatiga (Modelo Logístico Latente)\n    z = -10 + 0.2 * emg_rms - 0.15 * mdf\n    prob_fatiga = 1 / (1 + np.exp(-z))\n    fatiga = np.random.binomial(1, prob_fatiga)\n\n    return pd.DataFrame({\n        'EMG': emg_rms,\n        'Fuerza': fuerza,\n        'MDF': mdf,\n        'Fatiga': fatiga\n    })\n\ndata = generar_datos_emg()\n\n\n\n5.2 Regresión Lineal (Estimación de Fuerza)\n\ndef modelo_lineal_fuerza(df: pd.DataFrame):\n    \"\"\"Ajusta y resume un modelo OLS para fuerza.\"\"\"\n    # Es CRÍTICO añadir la constante manualmente en statsmodels\n    X = sm.add_constant(df['EMG'])\n    y = df['Fuerza']\n\n    model = sm.OLS(y, X).fit()\n    print(model.summary())\n\nmodelo_lineal_fuerza(data)\n\n\n\n5.3 Regresión Logística (Detección de Fatiga)\n\ndef modelo_logistico_fatiga(df: pd.DataFrame):\n    \"\"\"Ajusta un modelo Logit para predecir fatiga y calcula Odds Ratios.\"\"\"\n    X = sm.add_constant(df[['EMG', 'MDF']])\n    y = df['Fatiga']\n\n    model = sm.Logit(y, X).fit()\n    print(model.summary())\n\n    # Interpretación: Odds Ratios\n    odds_ratios = np.exp(model.params)\n    print(\"\\nOdds Ratios (Cambio multiplicativo en odds de fatiga):\")\n    print(odds_ratios)\n\nmodelo_logistico_fatiga(data)"
  },
  {
    "objectID": "recursos/documentos/regresion_reporte.html#inferencia-causal-en-datos-observacionales",
    "href": "recursos/documentos/regresion_reporte.html#inferencia-causal-en-datos-observacionales",
    "title": "Modelado Estadístico Avanzado en Ingeniería Biomédica",
    "section": "6. Inferencia Causal en Datos Observacionales",
    "text": "6. Inferencia Causal en Datos Observacionales\nEs vital recordar que los modelos de regresión son “máquinas de correlación”. En biomedicina, una asociación estadística (ej. correlación entre EMG y grasa subcutánea) no implica causalidad (la grasa atenúa la señal, no debilita el músculo per se).\nPara establecer causalidad, debemos trascender los coeficientes y aplicar el marco de inferencia causal de Pearl y Rubin, controlando las variables de confusión que abren “caminos traseros” (backdoor paths) o utilizando diseños intervencionales (ej. estimulación eléctrica funcional).\n\nGuía de Reporte (TRIPOD)\n\nTamaño de Muestra: &gt;10-15 eventos por predictor variable.\nNormalización: Estandarizar entradas (%MVC) para reducir variabilidad inter-sujeto.\nValidación: Inspeccionar residuos para descartar estructuras no aleatorias y puntos influyentes (Distancia de Cook)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "",
    "text": "Este documento resuelve el examen adjunto. Cada pregunta incluye: enunciado resumido, respuesta(s) correctas, justificación matemática y un ejemplo en Python que ilustra visualmente los conceptos. Las gráficas se generan con matplotlib (sin estilos ni colores específicos)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "2.1 Justificación matemática",
    "text": "2.1 Justificación matemática\n\nForma general: \\(y(t) = x\\big(a\\,(t-t_0)\\big)\\).\n\nSi \\(0 &lt; a &lt; 1\\), hay expansión temporal por factor \\(1/a\\). Aquí \\(a=0.5\\Rightarrow\\) expansión por 2.\nEl término \\(t-t_0\\) implica desplazamiento hacia la derecha en \\(t_0\\) (aparece más tarde). Aquí \\(t_0 = 0.2\\ \\text{s}\\).\n\nNo hay reflexión temporal porque no aparece \\(-t\\)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "2.2 Ejemplo en Python",
    "text": "2.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(-1, 3, 4000)\nx = np.cos(2*np.pi*t) + 0.5*np.cos(4*np.pi*t)\ny = np.cos(2*np.pi*(0.5*(t-0.2))) + 0.5*np.cos(4*np.pi*(0.5*(t-0.2)))\n\nplt.figure()\nplt.plot(t, x, label=\"x(t)\")\nplt.plot(t, y, label=\"y(t)=x(0.5*(t-0.2))\", linestyle=\"--\")\nplt.title(\"P1: Escala temporal (expansión ×2) y desplazamiento +0.2 s\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-1",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "3.1 Justificación matemática",
    "text": "3.1 Justificación matemática\n\nFrecuencias: \\(f_1=0.25\\ \\text{Hz}\\Rightarrow T_1=4\\ \\text{s}\\);\\(f_2=0.5\\ \\text{Hz}\\Rightarrow T_2=2\\ \\text{s}\\).\nLa suma de cosenos es periódica si la razón \\(f_2/f_1\\) es racional; aquí \\(0.5/0.25=2\\).\nEl periodo fundamental es \\(T_0=\\mathrm{mcm}(T_1,T_2)=\\mathrm{mcm}(4,2)=4\\ \\text{s}\\).\nCualquier múltiplo entero de \\(T_0\\) (p. ej., \\(8\\ \\text{s}\\)) también es periodo."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-1",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "3.2 Ejemplo en Python",
    "text": "3.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0, 12, 6000)\nx = np.cos(2*np.pi*0.25*t) + np.cos(2*np.pi*0.5*t)\n\nplt.figure()\nplt.plot(t, x, label=\"x(t)\")\nfor Tmark in [4, 8, 12]:\n    plt.axvline(Tmark, linestyle=\":\", alpha=0.7)\nplt.title(\"P2: Periodicidad con T0 = 4 s (líneas punteadas en múltiplos)\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.grid(True)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-2",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "4.1 Justificación matemática",
    "text": "4.1 Justificación matemática\nUna señal \\(x[n]=\\cos(\\omega_0 n)\\) es periódica si existe \\(N\\in\\mathbb{Z}^+\\) tal que \\(\\omega_0 N=2\\pi k\\), \\(k\\in\\mathbb{Z}\\).\n\\[\\frac{5\\pi}{6}N=2\\pi k \\;\\Longrightarrow\\; \\frac{5N}{6}=2k \\;\\Longrightarrow\\; 5N=12k.\\]\nEl menor \\(N\\) que satisface esto es \\(N_0=12\\) (con \\(k=5\\))."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-2",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "4.2 Ejemplo en Python",
    "text": "4.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nn = np.arange(0, 37)\nx = np.cos((5 * np.pi / 6) * n)\n\nplt.figure()\nmarkerline, stemlines, baseline = plt.stem(n, x)\nplt.title(\"P3: x[n]=cos((5π/6)n) con periodo N0 = 12 (marcas en 12, 24, 36)\")\nplt.xlabel(\"n\")\nplt.ylabel(\"Amplitud\")\nfor Nmark in [12, 24, 36]:\n    plt.axvline(Nmark, linestyle=\":\", alpha=0.7)\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-3",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "5.1 Justificación matemática",
    "text": "5.1 Justificación matemática\n\nProducto par·impar → impar. Producto par·par → par.\nPor tanto \\(y(t)=\\underbrace{\\text{impar}}_{x_p x_i}+\\underbrace{\\text{par}}_{x_p^2}\\).\nLa suma de una función par y una impar es ni par ni impar en general.\nCaso particular: si \\(x_i(t)=0\\Rightarrow y(t)=x_p^2(t)\\), que es par."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-3",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "5.2 Ejemplo en Python",
    "text": "5.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(-3*np.pi, 3*np.pi, 4000)\nxp = np.cos(t)        # par\nxi = np.sin(t)        # impar\ny = xp*xi + xp**2\ny_neg = np.cos(-t)*np.sin(-t) + np.cos(-t)**2  # y(-t)\n\nplt.figure()\nplt.plot(t, y, label=\"y(t)\")\nplt.plot(t, y_neg, linestyle=\"--\", label=\"y(-t)\")\nplt.title(\"P4: y(t)=cos(t)sin(t)+cos^2(t) → ni par ni impar (general)\")\nplt.xlabel(\"t\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Caso especial: xi(t)=0 ⇒ y(t)=xp^2(t) es par\nplt.figure()\nplt.plot(t, xp**2, label=\"y(t)=cos^2(t) (par)\")\nplt.title(\"P4 (caso especial): si xi(t)=0 ⇒ y(t)=cos^2(t) es par\")\nplt.xlabel(\"t\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-4",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "6.1 Justificación matemática",
    "text": "6.1 Justificación matemática\n\nRepresentación estándar de un rectángulo activo en \\([t_1,t_2)\\) con amplitud \\(A\\):\n\\[A\\,[u(t-t_1)-u(t-t_2)].\\]\nCon \\(A=2\\), \\(t_1=1\\), \\(t_2=1.2\\):\n\\[2\\,[u(t-1)-u(t-1.2)].\\]"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-4",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "6.2 Ejemplo en Python",
    "text": "6.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef u(t):\n    return (t &gt;= 0).astype(float)\n\nt = np.linspace(0, 2, 4000)\nrect = 2*(u(t-1) - u(t-1.2))\n\nplt.figure()\nplt.plot(t, rect)\nplt.title(\"P5: Pulso rectangular 2[u(t-1) - u(t-1.2)]\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "",
    "text": "En el ámbito de la Ingeniería Biomédica, el procesamiento de imágenes no es simplemente una manipulación estética, sino un proceso de extracción de información biológica fidedigna. Este reporte detalla los contenidos de las sesiones 1 y 2, centrados en cómo la representación digital y las métricas de calidad impactan la interpretabilidad diagnóstica y la confiabilidad de los sistemas de Inteligencia Artificial."
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html#modelado-de-la-digitalización",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html#modelado-de-la-digitalización",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "Modelado de la Digitalización",
    "text": "Modelado de la Digitalización\nUna imagen médica continua \\(f(x, y)\\) debe ser transformada en una matriz discreta \\(I[m, n]\\). Este proceso se divide en:\n\nMuestreo Espacial: Determina la resolución espacial. En radiografía digital, el tamaño del píxel suele oscilar entre 100 y 200 \\(\\mu m\\).\nCuantización de Intensidad: Define la resolución de contraste. Mientras que las imágenes comerciales usan 8 bits, los estándares clínicos requieren entre 12 y 16 bits para representar adecuadamente la escala de unidades Hounsfield (HU) en Tomografía o niveles de gris en Rayos X.\n\n\nImplementación en Python: Simulación de Profundidad de Bits\nEl siguiente código demuestra el efecto de la reducción de la profundidad de bits (cuantización) sobre una imagen médica, evidenciando el artefacto de “falso contorneo”.\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import data, img_as_float, color\n\ndef simulate_quantization(image, bits):\n    \"\"\"\n    Simula el efecto de reducir la profundidad de bits.\n    \"\"\"\n    levels = 2**bits\n    return np.round(image * (levels - 1)) / (levels - 1)\n\n# Cargamos una imagen de prueba y la normalizamos\nimage = img_as_float(data.camera()) \n\n# Simulamos diferentes profundidades\nq_8bit = simulate_quantization(image, 8)\nq_4bit = simulate_quantization(image, 4)\nq_2bit = simulate_quantization(image, 2)\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\naxes[0].imshow(q_8bit, cmap='gray')\naxes[0].set_title('Resolución Estándar (8-bit)')\naxes[1].imshow(q_4bit, cmap='gray')\naxes[1].set_title('Cuantización 4-bit (16 niveles)')\naxes[2].imshow(q_2bit, cmap='gray')\naxes[2].set_title('Cuantización 2-bit (4 niveles)')\nfor ax in axes: ax.axis('off')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html#espacios-de-color-en-aplicaciones-biomédicas",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html#espacios-de-color-en-aplicaciones-biomédicas",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "Espacios de Color en Aplicaciones Biomédicas",
    "text": "Espacios de Color en Aplicaciones Biomédicas\nAunque el diagnóstico radiológico es monocromático, la patología digital y la endoscopia dependen críticamente del color. El espacio RGB no es adecuado para el análisis cuantitativo debido a su falta de uniformidad perceptual. Se prefiere el espacio CIELAB, donde la luminosidad (\\(L^*\\)) está desacoplada de la información cromática (\\(a^*, b^*\\)).\n\nImplementación en Python: Conversión Perceptual\nfrom skimage.color import rgb2lab, lab2rgb\n\n# Ejemplo con imagen de retina\nretina_rgb = data.retina()\nretina_lab = rgb2lab(retina_rgb)\n\n# Extracción de componentes\nL_channel = retina_lab[:, :, 0] # Luminosidad (información estructural)\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.imshow(retina_rgb)\nplt.title('Imagen Original (RGB)')\nplt.subplot(1, 2, 2)\nplt.imshow(L_channel, cmap='gray')\nplt.title('Componente de Luminosidad (L*)')\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html#naturaleza-estocástica-del-ruido",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html#naturaleza-estocástica-del-ruido",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "Naturaleza Estocástica del Ruido",
    "text": "Naturaleza Estocástica del Ruido\nEn imagenología médica, el ruido no es una señal aditiva simple; es un proceso dependiente de la física de adquisición:\n\nRuido de Poisson (Cuántico): Domina en Rayos X y TC. Surge debido a la llegada aleatoria de fotones al detector. Su varianza es proporcional a la intensidad de la señal.\nRuido Gaussiano (Electrónico): Originado por la instrumentación del detector y la digitalización.\n\n\nImplementación en Python: Modelado de Ruido Clínico\ndef add_poisson_noise(image):\n    \"\"\"\n    Simula el ruido cuántico típico de adquisiciones de Rayos X.\n    \"\"\"\n    # Ajuste de escala para simular flujo de fotones\n    peak = 50 \n    noisy = np.random.poisson(image * peak) / peak\n    return np.clip(noisy, 0, 1)\n\nphantom = data.shepp_logan_phantom()\nnoisy_phantom = add_poisson_noise(phantom)\n\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(phantom, cmap='gray')\nplt.title('Fantoma Ideal')\nplt.subplot(1, 2, 2)\nplt.imshow(noisy_phantom, cmap='gray')\nplt.title('Fantoma con Ruido de Poisson (Cuántico)')\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html#métricas-de-desempeño-snr-y-cnr",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html#métricas-de-desempeño-snr-y-cnr",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "Métricas de Desempeño: SNR y CNR",
    "text": "Métricas de Desempeño: SNR y CNR\nPara que un algoritmo de IA o un radiólogo identifique una patología, la lesión debe ser distinguible del fondo ruidoso.\n\nSNR (Signal-to-Noise Ratio): Relación entre la intensidad media de la señal y la desviación estándar del ruido en una región de interés (ROI).\nCNR (Contrast-to-Noise Ratio): Evalúa la diferencia de intensidad entre dos tejidos (ej. tumor vs. parénquima sano) normalizada por el ruido.\n\n\\[CNR = \\frac{|\\mu_{tumor} - \\mu_{sano}|}{\\sigma_{ruido}}\\]\n\nImplementación en Python: Cálculo Automático de Métricas\ndef get_metrics(img, roi_sig, roi_bg):\n    \"\"\"\n    Calcula SNR y CNR basadas en coordenadas [y1, y2, x1, x2].\n    \"\"\"\n    signal = img[roi_sig[0]:roi_sig[1], roi_sig[2]:roi_sig[3]]\n    background = img[roi_bg[0]:roi_bg[1], roi_bg[2]:roi_bg[3]]\n    \n    mu_s = np.mean(signal)\n    mu_b = np.mean(background)\n    sigma_b = np.std(background)\n    \n    snr = mu_s / sigma_b\n    cnr = np.abs(mu_s - mu_b) / sigma_b\n    \n    return snr, cnr\n\n# Definición de ROIs sobre el fantoma (ejemplo ilustrativo)\n# ROI señal: elipse central; ROI fondo: área negra superior\nsnr, cnr = get_metrics(noisy_phantom, [180, 220, 180, 220], [10, 40, 10, 40])\n\nprint(f\"Métricas de Calidad:\\nSNR: {snr:.4f}\\nCNR: {cnr:.4f}\")"
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html#resolución-espacial-y-la-mtf",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html#resolución-espacial-y-la-mtf",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "Resolución Espacial y la MTF",
    "text": "Resolución Espacial y la MTF\n\nIntroducción a la Calidad de Imagen desde la Frecuencia\nEn el procesamiento avanzado de imágenes médicas (PAIM), la resolución espacial suele malinterpretarse como el simple número de píxeles o el tamaño de la matriz de adquisición. Sin embargo, para un ingeniero biomédico, la resolución es una propiedad dinámica que depende de la capacidad del sistema para transferir el contraste del objeto real a la imagen digital.\nLa Función de Transferencia de Modulación (MTF) es la métrica reina para caracterizar esta capacidad. Representa la fidelidad de un sistema de imagen en función de la frecuencia espacial, cuantificando cómo se degrada el contraste a medida que las estructuras se vuelven más pequeñas y densas.\nEste reporte desglosa la MTF desde sus fundamentos matemáticos hasta su implementación computacional, proporcionando una visión integral esencial para el desarrollo de algoritmos de restauración e IA confiable.\n\n\n\nFundamentos Matemáticos: De la PSF a la MTF\nPara entender la MTF, primero debemos definir la Función de Dispersión de Punto (Point Spread Function - PSF).\n\nLa Función de Dispersión de Punto (PSF)\nSi capturamos la imagen de un punto infinitesimal (una delta de Dirac \\(\\delta(x, y)\\)), el sistema no devolverá un punto perfecto, sino una mancha borrosa debido a la difracción, el tamaño del foco en Rayos X o el movimiento del paciente. Esta mancha es la PSF.\nMatemáticamente, la imagen \\(g(x, y)\\) es la convolución del objeto \\(f(x, y)\\) con la PSF \\(h(x, y)\\):\n\\[g(x, y) = f(x, y) * h(x, y)\\]\n\n\nLa Función de Transferencia Óptica (OTF)\nAl aplicar la Transformada de Fourier a la PSF, pasamos del dominio espacial al dominio de la frecuencia. El resultado es la OTF:\n\\[OTF(u, v) = \\mathcal{F}\\{h(x, y)\\}\\]\nDonde \\((u, v)\\) son las frecuencias espaciales (ciclos/mm o lp/mm).\n\n\nDefinición de MTF\nLa MTF es simplemente la magnitud (módulo) de la OTF, usualmente normalizada a la unidad en frecuencia cero:\n\\[MTF(u, v) = \\frac{|OTF(u, v)|}{|OTF(0, 0)|}\\]"
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html#visualización-de-la-psf-y-su-relación-con-la-resolución",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html#visualización-de-la-psf-y-su-relación-con-la-resolución",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "Visualización de la PSF y su relación con la resolución",
    "text": "Visualización de la PSF y su relación con la resolución\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft2, fftshift\n\ndef generate_psf(sigma, size=128):\n    \"\"\"Genera una PSF Gaussiana que simula el desenfoque del sistema.\"\"\"\n    x = np.linspace(-size//2, size//2, size)\n    y = np.linspace(-size//2, size//2, size)\n    x, y = np.meshgrid(x, y)\n    psf = np.exp(-(x**2 + y**2) / (2 * sigma**2))\n    return psf / np.sum(psf)\n\npsf_sharp = generate_psf(sigma=1)\npsf_blur = generate_psf(sigma=5)\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 5))\nax[0].imshow(psf_sharp, cmap='hot'); ax[0].set_title('PSF Sistema Alta Resolución')\nax[1].imshow(psf_blur, cmap='hot'); ax[1].set_title('PSF Sistema Baja Resolución')\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html#determinación-práctica-de-la-mtf-el-método-del-borde",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html#determinación-práctica-de-la-mtf-el-método-del-borde",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "Determinación Práctica de la MTF: El Método del Borde",
    "text": "Determinación Práctica de la MTF: El Método del Borde\nMedir una PSF directamente es difícil porque no existen “puntos perfectos” en la práctica clínica. Por ello, utilizamos la Función de Respuesta al Borde (Edge Response Function - ERF)."
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html#el-proceso-de-cálculo",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html#el-proceso-de-cálculo",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "El Proceso de Cálculo",
    "text": "El Proceso de Cálculo\n\nAdquisición: Se toma la imagen de un borde afilado (ej. una placa de plomo).\nERF: Se extrae el perfil de intensidades perpendicular al borde.\nLSF (Line Spread Function): Se deriva la ERF para obtener la respuesta a una línea.\n\\[LSF(x) = \\frac{d}{dx}ERF(x)\\]\nMTF: Se aplica la Transformada de Fourier a la LSF.\n\n\nImplementación en Python: Cálculo de MTF desde un Borde\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter1d\nfrom scipy.fft import fft\n\ndef calculate_mtf_from_edge(edge_profile):\n    \"\"\"\n    Calcula la MTF a partir de un perfil de borde (ERF).\n    \"\"\"\n    # 1. Derivada para obtener la LSF\n    lsf = np.diff(edge_profile)\n    \n    # 2. Ventaneo (Hanning) para reducir ruido en los extremos\n    lsf = lsf * np.hanning(len(lsf))\n    \n    # 3. Transformada de Fourier\n    mtf = np.abs(fft(lsf))\n    \n    # 4. Normalización\n    mtf = mtf / mtf[0]\n    \n    return mtf[:len(mtf)//2]\n\n# Simulación de un perfil de borde con ruido\nx = np.linspace(0, 100, 1000)\nerf_ideal = np.where(x &lt; 50, 0, 1)\nerf_real = gaussian_filter1d(erf_ideal, sigma=5) + np.random.normal(0, 0.01, 1000)\n\nmtf_result = calculate_mtf_from_edge(erf_real)\n\nplt.figure(figsize=(10, 5))\nplt.plot(mtf_result, label='MTF Sistema Simulado')\nplt.xlabel('Frecuencia Espacial (unidades relativas)')\nplt.ylabel('Modulación (Contraste)')\nplt.grid(True)\nplt.legend()\nplt.title('Curva MTF calculada vía Método del Borde')\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/PAIM/s1s2_academic_report.html#interpretación-clínica-de-la-curva-mtf",
    "href": "recursos/documentos/PAIM/s1s2_academic_report.html#interpretación-clínica-de-la-curva-mtf",
    "title": "Reporte Académico Detallado: Fundamentos y Calidad en Imagen Médica",
    "section": "Interpretación Clínica de la Curva MTF",
    "text": "Interpretación Clínica de la Curva MTF\nUna curva MTF se lee de la siguiente manera:\n\nFrecuencia 0 (DC): Siempre es 1.0. Representa objetos infinitamente grandes donde el contraste se preserva totalmente.\nFrecuencia de Corte (\\(f_c\\)): La frecuencia donde la MTF cae a cero. Es el límite físico de resolución.\nMTF al 50% (\\(f_{50}\\)): Indica la frecuencia donde el sistema pierde la mitad de su contraste original. Es un buen indicador de la nitidez percibida.\nMTF al 10% (\\(f_{10}\\)): Se considera a menudo el límite de resolución detectable por el ojo humano en condiciones clínicas.\n\n\nAplicación en Mamografía vs. TC Corporal\nEn mamografía, donde se buscan microcalcificaciones (\\(\\sim 100 \\mu m\\)), se requiere una MTF alta en frecuencias elevadas (ej. hasta 10-15 lp/mm). En un TC de abdomen, nos interesan frecuencias más bajas para distinguir órganos"
  },
  {
    "objectID": "rubricas/Rubrica_EDA.html",
    "href": "rubricas/Rubrica_EDA.html",
    "title": "Rúbrica: Análisis Exploratorio de Datos",
    "section": "",
    "text": "Indicador\nBueno\nSuficiente\nInsuficiente\n\n\n\n\nLimpieza del Dataset\nEl dataset no presenta ni registros nulos, ni vacíos. Existe una estrategia para manejo de atípicos (100%)\nEl dataset no presenta ni registros nulos, ni vacíos (50%)\nEl dataset presenta registros nulos y/o vacíos. No existe una estrategia para manejo de atípicos (0%)\n\n\nConsumo de información\nSe consumen al menos 2 fuentes de datos provenientes de las sugerencias de los organizadores (100%)\nSe consume una fuente de datos proveniente de las sugerencias de los organizadores (50%)\nNo se consume ninguna fuente de datos conocida (0%)\n\n\nEDA sobre nuevas variables\nSe plantean correctamente las relaciones entre la variables y estas se demuestran a plenitud utilizando matemática y/o estadística (100%)\nSe plantean dos relaciones entre las variables (50%)\nNo se plantean las relaciones entre las variables (0%)\n\n\nUso de plantilla\nUsan la plantilla rmarkdown (100%)\n\nNo se usa la plantilla rmarkdown(0%)\n\n\nVisualización de la informacion\nLa información de TODAS las gráficas se observa plenamente (100%)\nLa información de las gráficas se observa parcialmente(50%)\nLa información de la gráfica no se observa (0%)\n\n\nJustificación del problema\nExiste una justificación del problema(100%)\n\nNo Existe justificación al problema resuelto (0%)\n\n\nUbicación del problema\nSe plantea correctamente la ubicación del problema 100%\n\nNo se plantea correctamente la ubicación del problema 0%"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Preparar una Presentación | 5 PASOS para una CONFERENCIA EXITOSA por Sebastián Lora.\n¿Cómo estructurar una presentación? por Espacio Ñ de la Universidad del Norte\n\n\n\n\n\nCómo Hacer una Buena Presentación de Diapositivas (Tips) por Javier Muñiz.\nConsejos para una buena presentación en POWER POINT por NiboKids en el cole!.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentación\nNo se siguen ninguno de los consejos de los videos adjuntos para la creación de la presentación\nSe siguen algunos de los consejos de los videos adjuntos para la creación  de la presentación\nSe siguen todos los consejos de los videos adjuntos para la creación  de la presentación\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificación de los ejemplos\nNo se describe el código utilizado para los ejemplos\nSe describe parcialmente el código de los ejemplos\nSe describe a cabalidad el código de los ejemplos\n\n\nCalidad del código\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl código utilizado es completamente desarrollado por los estudiantes a excepción del manejo de datos (NUMPY array y las funciones matemáticas elementales) y la graficación (MATPLOTLIB)"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generación-de-presentaciones",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generación-de-presentaciones",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Preparar una Presentación | 5 PASOS para una CONFERENCIA EXITOSA por Sebastián Lora.\n¿Cómo estructurar una presentación? por Espacio Ñ de la Universidad del Norte"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generación-de-dipostivas",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generación-de-dipostivas",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Hacer una Buena Presentación de Diapositivas (Tips) por Javier Muñiz.\nConsejos para una buena presentación en POWER POINT por NiboKids en el cole!."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#rúbrica-de-evaluación",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#rúbrica-de-evaluación",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Indicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentación\nNo se siguen ninguno de los consejos de los videos adjuntos para la creación de la presentación\nSe siguen algunos de los consejos de los videos adjuntos para la creación  de la presentación\nSe siguen todos los consejos de los videos adjuntos para la creación  de la presentación\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificación de los ejemplos\nNo se describe el código utilizado para los ejemplos\nSe describe parcialmente el código de los ejemplos\nSe describe a cabalidad el código de los ejemplos\n\n\nCalidad del código\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl código utilizado es completamente desarrollado por los estudiantes a excepción del manejo de datos (NUMPY array y las funciones matemáticas elementales) y la graficación (MATPLOTLIB)"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Linear Regression",
    "text": "Linear Regression"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#linear-regression-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Linear Regression",
    "text": "Linear Regression\nIn the example, in previous slide, data was modelled as a linear function. The difference (error) between the modelled data \\(\\left( \\hat{y}_n \\right)\\) and actual data \\(\\left( y_n \\right)\\) can be written as\n\n\n\n\n\n\n\nCost function\n\n\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#some-other-examples-of-cost-function",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Some other examples of cost function",
    "text": "Some other examples of cost function\n\\[E = \\sqrt{\\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\hat{y}_n - y_n \\right)^2}}\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left| \\hat{y}_n - y_n \\right| }\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nLooking the cost surface, we notices that this surface has a global minimum. If we could have an algorithm which automatically finds it.\n\nCost Surface"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\nIndeed, there are multiples algorithms for minima searching. The most famous is the one named as least squares but in this course we will use the gradient descent algorithm.\nAssuming that the data model is a function \\(f\\left(\\theta_i, x_n, y_n\\right)\\), where \\(\\theta\\) is known as model parameter.\n\n\n\n\n\n\n\nThe gradient descent algorithm\n\n\n\\[\\boldsymbol{\\theta}_{i,j+1} =  \\boldsymbol{\\theta}_{i,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{i}}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-2",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\nAssumptions\n\n\n\nLinear model for the Regression\nMean square error as cost function\n\\(\\eta = 1\\)\n\n\n\n\n\n\\[\\boldsymbol{\\theta}_i = \\left[ \\theta_1, \\theta_0 \\right]^T\\]\n\\[\\hat{y}_n  = \\theta_1 x_n + \\theta_0\\]\n\\[E = \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-3",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_1\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{1,j+1} = \\boldsymbol{\\theta}_{1,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{1}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right) x_n}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#gradient-descent-algorithm-4",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Gradient Descent algorithm",
    "text": "Gradient Descent algorithm\n\n\n\n\n\n\n\n\nFor \\(\\theta_0\\) estimation\n\n\n\\[\\boldsymbol{\\theta}_{0,j+1} = \\boldsymbol{\\theta}_{0,j} - \\eta \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\frac{1}{N} \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left(  \\sum_{n=1}^{N}{\\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2} \\right) \\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{\\frac{\\partial}{\\partial \\boldsymbol{\\theta}_{0}} \\left( \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)^2\\right)}\\]\n\\[\\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}}= \\frac{1}{N}  \\sum_{n=1}^{N}{2 \\left( \\theta_1 x_n + \\theta_0 - y_n \\right)}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  E & = & \\frac{1}{N} \\sqrt{u}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{1}{2 N \\sqrt{u}} \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}}\\\\\n  \\frac{\\partial u}{\\partial \\boldsymbol{\\theta}_{0}} &=& 2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{2\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{2 N \\sqrt{u}}\n\\end{eqnarray}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "href": "presentaciones/ASIM/Lect003_IntroductionMachineLearning.html#changing-the-cost-function-and-the-data-model-1",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Changing the cost function and the data model",
    "text": "Changing the cost function and the data model\n\\[\n\\begin{eqnarray}\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{0}} &=& \\frac{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{1}} &=& \\frac{\\sum_{n=1}^{N}{x_n \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\\\\\n  \\frac{\\partial E}{\\partial \\boldsymbol{\\theta}_{2}} &=& \\frac{\\sum_{n=1}^{N}{x_n^2 \\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)}}{N \\sqrt{\\sum_{n=1}^{N}{\\left( \\theta_2 x_{n}^{2} + \\theta_1 x_n + \\theta_0 - y_n \\right)^2}}}\n\\end{eqnarray}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#objetivos-de-la-sesión",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#objetivos-de-la-sesión",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Objetivos de la sesión",
    "text": "Objetivos de la sesión\n\nEntender el principio del descenso de gradiente (GD) como método de optimización.\nAplicar GD a regresión lineal múltiple (objetivo continuo) y regresión logística (clasificación 0/1).\nAnalizar decisiones de ingeniería: tasa de aprendizaje, escalado/normalización, batch vs. mini-batch vs. SGD.\nInterpretar resultados en contextos biomédicos (diagnóstico, pronóstico y evaluación de riesgo).\n\n\nEstructura sugerida: 4 bloques de ~45+45+45+30 min. Actividades cortas para mantener la atención."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#agenda",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#agenda",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Agenda",
    "text": "Agenda\n\nFundamentos de GD y funciones de costo\nCaso 1: Regresión lineal múltiple con GD\nCaso 2: Regresión logística con GD\nBuenas prácticas, diagnósticos y discusión aplicada"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#motivación-biomédica",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#motivación-biomédica",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Motivación biomédica",
    "text": "Motivación biomédica\n\nAjustar parámetros de un modelo fisiológico o un predictor clínico con datos reales.\nEjemplos típicos:\n\nEstimar gasto energético a partir de IMC, edad y FC.\nEstimar edad vascular con variables de laboratorio.\nClasificar presencia/ausencia de una condición (0/1) con biomarcadores.\n\n\n\nEnfatizar que el GD es base de la mayoría de métodos de AA actuales, incluidas redes neuronales."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#regresión-lineal",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#regresión-lineal",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Regresión Lineal",
    "text": "Regresión Lineal"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#regresión-lineal-1",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#regresión-lineal-1",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Regresión Lineal",
    "text": "Regresión Lineal"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#función-de-costo-error",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#función-de-costo-error",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Función de costo (error)",
    "text": "Función de costo (error)\n\n\nRegresión (continuo): \\[\nJ(\\mathbf{w}) \\;=\\; \\frac{1}{2m}\\sum_{i=1}^{m}\\left(y_j - \\hat{y}_j\\right)^2\n\\] donde \\(\\hat{y}_j = \\mathbf{w}^\\top \\mathbf{x}_j\\).\n\nClasificación binaria: Entropía cruzada (log-loss): \\[\nJ(\\mathbf{w}) \\;=\\; -\\frac{1}{m}\\sum_{i=1}^{m}\\left[\\,y_i\\log\\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i)\\,\\right]\n\\] donde \\(\\hat{p}_i=\\sigma(\\mathbf{w}^\\top \\mathbf{x}_i)=\\frac{1}{1+e^{-\\mathbf{w}^\\top\\mathbf{x}_i}}\\).\n\n\nConectar con la interpretación probabilística en logística y con el MSE en lineal."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#función-de-costo-error-1",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#función-de-costo-error-1",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Función de costo (error)",
    "text": "Función de costo (error)\n\n\n\n\n\n\n\n… Para el caso de ejemplo (un modelo tipo lineal)\n\n\n\\[\n\\mathbf{w_{j}}^\\top \\;=\\; \\left[w_{j,1}, w_{j,0}\\right]\n\\]\n\\[\nsalary_i = x_i\n\\]\n\\[\n\\hat{y}_j  \\;=\\; w_{j,1}*x_j + w_{j,0}\n\\]\n\\[\nJ(\\mathbf{w}) \\;=\\; \\frac{1}{2m}\\sum_{i=1}^{m}\\left(y_j - w_{j,1}*x_i - w_{j,0}\\right)^2\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#idea-central-del-gd",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#idea-central-del-gd",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Idea central del GD",
    "text": "Idea central del GD\n\nPartimos de \\(\\mathbf{w}_{(0)}\\) (p. ej., aleatorio).\nIteramos: \\[\n\\mathbf{w}_{(t+1)} \\;=\\; \\mathbf{w}_{(t)} \\;-\\; \\alpha\\, \\nabla_{\\mathbf{w}} J(\\mathbf{w}_{(t)})\n\\]\n\\(\\alpha\\) = tasa de aprendizaje: grande → rápido pero inestable; pequeña → estable pero lento.\nConvergencia: buscamos \\(\\nabla J \\approx \\mathbf{0}\\).\n\nVisualización conceptual: “valle” del error y trayectoria en zig-zag hacia el mínimo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#algoritmo-de-descenso-de-gradiente",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#algoritmo-de-descenso-de-gradiente",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Algoritmo de Descenso de Gradiente",
    "text": "Algoritmo de Descenso de Gradiente\n\n\n\n\n\n\n\n\nPara la estimación de \\(w_{j,0}\\)\n\n\n\\[\nw_{j+1,0} = w_{j,0} - \\alpha \\frac{\\partial J}{\\partial w_{j,0}}\n\\]\n\\[\n\\frac{\\partial J}{\\partial w_{j,0}} =\n\\frac{\\partial}{\\partial w_{j,0}}\n\\left(\n\\frac{1}{2m} \\sum_{i=1}^{m}\n\\left( y_i - w_{j,1} x_i - w_{j,0} \\right)^2\n\\right)\n\\]\n\\[\n\\frac{\\partial}{\\partial w_{j,0}}\n\\left(\n\\frac{1}{2m}\n\\sum_{i=1}^{m}\n\\left(\ny_i - w_{j,1}x_i - w_{j,0}\n\\right)^2\n\\right)\n=\n\\frac{1}{m}\n\\sum_{i=1}^{m}\n\\left(\nw_{j,1}x_i + w_{j,0} - y_i\n\\right)\n\\]\n\n\n\n\n\n\n\n\n\n\n\nPara la estimación de \\(w_{j,1}\\)\n\n\n\\[\nw_{j+1,1} = w_{j,1} - \\alpha \\frac{\\partial J}{\\partial w_{j,1}}\n\\]\n\\[\n\\frac{\\partial J}{\\partial w_{j,1}} =\n\\frac{\\partial}{\\partial w_{j,1}}\n\\left(\n\\frac{1}{2m} \\sum_{i=1}^{m}\n\\left( y_i - w_{j,1} x_i - w_{j,0} \\right)^2\n\\right)\n\\]\n\\[\n\\frac{\\partial J}{\\partial w_{j,1}}\n=\n\\frac{1}{m}\n\\sum_{i=1}^{m}\n\\left(\nw_{j,1}x_i + w_{j,0} - y_i\n\\right)x_i\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#variantes-batch-mini-batch-sgd",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#variantes-batch-mini-batch-sgd",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Variantes: batch, mini-batch, SGD",
    "text": "Variantes: batch, mini-batch, SGD\n\nBatch GD: usa todo el conjunto en cada actualización (costo alto por iteración).\nMini-batch GD: usa lotes pequeños (compromiso eficiencia/ruido).\nSGD (estocástico): actualiza con una sola muestra por paso (barato, ruidoso, puede escapar de óptimos pobres).\n\nPráctica recomendada: mini-batch (p. ej., 32–256)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#preprocesamiento-y-escalado",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#preprocesamiento-y-escalado",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Preprocesamiento y escalado",
    "text": "Preprocesamiento y escalado\n\nEstandarizar o normalizar las \\(x_j\\) acelera y estabiliza GD.\nCentrar: \\(x_j \\leftarrow (x_j - \\mu_j)/\\sigma_j\\).\nManejo de outliers y transformaciones (log, Box–Cox) cuando aplique.\n\n\nConectar con mediciones biomédicas heterogéneas y escalas físicas."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#eda",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#eda",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "1.5 EDA",
    "text": "1.5 EDA\nEmpezar a usar jupyter."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#planteamiento",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#planteamiento",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Planteamiento",
    "text": "Planteamiento\nObjetivo biomédico (ejemplo): predecir gasto energético (kcal) a partir de edad, IMC y FC.\nModelo lineal: \\[\n\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} = w_0 + w_1 x_1 + \\cdots + w_p x_p\n\\]\nCosto (MSE): \\[\nJ(\\mathbf{w}) = \\frac{1}{2m}\\sum_{i=1}^{m}(y_i - \\hat{y}_i)^2\n\\]\nGradiente: \\[\n\\frac{\\partial J}{\\partial w_j} = -\\frac{1}{m}\\sum_{i=1}^{m}(y_i - \\hat{y}_i)\\,x_{ij}\n\\]\nActualización: \\[\nw_j \\leftarrow w_j - \\alpha\\,\\frac{\\partial J}{\\partial w_j}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#pseudocódigo-mini-batch",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#pseudocódigo-mini-batch",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Pseudocódigo (mini-batch)",
    "text": "Pseudocódigo (mini-batch)\nin: X (m×p), y (m), α, batch_size, epochs\npreprocess: X ← standardize(X)\n\ninitialize w ← zeros(p+1)  # incluye sesgo w0 si se usa X̃ con columna 1\n\nfor epoch in 1..epochs:\n    for B in iterate_minibatches(X, y, batch_size, shuffle=True):\n        Xb, yb ← B\n        yhat ← Xb · w\n        grad ← (1/|B|) · (Xbᵀ · (yhat - yb))\n        w ← w - α · grad\n\nreturn w\n\nDiscutir convergencia, criterio de parada (máx. iteraciones o ΔJ pequeño)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#diagnóstico-y-validación",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#diagnóstico-y-validación",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Diagnóstico y validación",
    "text": "Diagnóstico y validación\n\nCurva \\(J\\) vs. iteraciones (entrenamiento y validación).\nErrores residuales: homocedasticidad, estructura vs. predicción.\nInterpretación clínica de coeficientes \\(w_j\\) y unidades.\nComparar con ecuaciones normales (solución cerrada) y discutir condicionamiento numérico."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#planteamiento-1",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#planteamiento-1",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Planteamiento",
    "text": "Planteamiento\nObjetivo biomédico (ejemplo): clasificar riesgo de enfermedad (0/1) con panel de biomarcadores.\nModelo: \\[\n\\hat{p} = \\sigma(\\mathbf{w}^\\top\\mathbf{x}),\\quad \\sigma(z)=\\frac{1}{1+e^{-z}}\n\\]\nCosto (entropía cruzada): \\[\nJ(\\mathbf{w}) = -\\frac{1}{m}\\sum_{i=1}^{m}\\Big[y_i\\log \\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i)\\Big]\n\\]\nGradiente: \\[\n\\frac{\\partial J}{\\partial w_j} = \\frac{1}{m}\\sum_{i=1}^{m}(\\hat{p}_i - y_i)\\,x_{ij}\n\\]\nActualización: \\[\nw_j \\leftarrow w_j - \\alpha\\,\\frac{\\partial J}{\\partial w_j}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#pseudocódigo-mini-batch-1",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#pseudocódigo-mini-batch-1",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Pseudocódigo (mini-batch)",
    "text": "Pseudocódigo (mini-batch)\nin: X (m×p), y∈{0,1}^m, α, batch_size, epochs\npreprocess: X ← standardize(X)\n\ninitialize w ← zeros(p+1)\n\nfor epoch in 1..epochs:\n    for B in iterate_minibatches(X, y, batch_size, shuffle=True):\n        Xb, yb ← B\n        z ← Xb · w\n        p ← sigmoid(z)\n        grad ← (1/|B|) · (Xbᵀ · (p - yb))\n        w ← w - α · grad\n\nreturn w\nInferencia: clasificar con umbral \\(\\hat{p} \\ge \\tau\\) (clínico/operativo)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#métricas-y-curvas",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#métricas-y-curvas",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Métricas y curvas",
    "text": "Métricas y curvas\n\nAUC-ROC, AUPRC, sensibilidad, especificidad, F1.\nElección del umbral \\(\\tau\\) por criterio clínico (p. ej., maximizar sensibilidad bajo límite de FPs).\nCalibración: curvas de confiabilidad.\n\n\nRelaciones costo-beneficio y prevalencia en biomédica."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#visualización-de-la-frontera-de-decisión",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#visualización-de-la-frontera-de-decisión",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Visualización de la frontera de decisión",
    "text": "Visualización de la frontera de decisión\n\nCon dos características (\\(x_1, x_2\\)), la frontera es una línea (hiperplano en general).\nDurante GD, la frontera rota/traslada hasta estabilizarse.\nAñadir términos polinomiales o bases para fronteras no lineales; GD sigue aplicando."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#hiperparámetros-y-trucos-prácticos",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#hiperparámetros-y-trucos-prácticos",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Hiperparámetros y trucos prácticos",
    "text": "Hiperparámetros y trucos prácticos\n\nTasa de aprendizaje (\\(\\alpha\\)): búsqueda en rejilla o programación de tasa (decay).\nInicialización: pequeña aleatoria (cero puede estancar con ciertas variantes).\nBarajado por época y mini-batches estratificados si la clase es rara.\nRegularización (L2/L1) para estabilidad e interpretabilidad: \\[\nJ_{\\lambda} = J + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|_2^2 \\quad \\text{(Ridge)}\n\\]\nDetección de fuga de datos y validación por sujeto en estudios clínicos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#checklist-de-la-sesión-rápido",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#checklist-de-la-sesión-rápido",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Checklist de la sesión (rápido)",
    "text": "Checklist de la sesión (rápido)\n\nEstandarizaste variables de entrada.\nDefiniste costo adecuado (MSE vs. CE).\nElegiste mini-batch y \\(\\alpha\\) razonables.\nVerificaste convergencia con curva de \\(J\\).\nEvaluaste con métricas adecuadas al objetivo clínico.\nDocumentaste supuestos y limitaciones."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#objetivos-de-aprendizaje",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#objetivos-de-aprendizaje",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Objetivos de aprendizaje",
    "text": "Objetivos de aprendizaje\n\nComprender los fundamentos de la Regresión Lineal, Regresión Logística y Perceptrón Multicapa (MLP).\nAplicar estos modelos al contexto de salud fetal con datos de cardiotocografía (CTG).\nEvaluar el desempeño con métricas adecuadas (MSE, AUC/Log-Loss, matriz de confusión, F1).\n\n\n\n\nRegresión Lineal\nRegresión Logística\nPerceptrón Multicapa\nCierre y discusión\n\n\nDataset: fetal_health.csv (UCI CTG). Contexto clínico: interpretación de CTG (normal, sospechoso, patológico)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#contexto-clínico-ctg",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#contexto-clínico-ctg",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Contexto clínico (CTG)",
    "text": "Contexto clínico (CTG)\n\n\n\n\n\n\n\nDefición\n\n\nPrueba médica que monitoriza simultáneamente la frecuencia cardíaca del feto y la actividad contráctil del útero. Se realiza generalmente durante el tercer trimestre del embarazo y el parto, colocando dos transductores externos (uno para la frecuencia cardíaca fetal y otro para las contracciones) sobre el abdomen de la madre\n\n\n\n\n\nGenerada con Gemini"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#contexto-clínico-ctg-1",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#contexto-clínico-ctg-1",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Contexto clínico (CTG)",
    "text": "Contexto clínico (CTG)\n\n\n\n\n\n\n\nCaracterística (Variable en CSV)\nCálculo o Descripción\n\n\n\n\nParámetros Basales\n\n\n\nbaseline value\nEs la frecuencia cardíaca fetal (FCF) media aproximada en un segmento de 10 minutos, excluyendo aceleraciones, deceleraciones y períodos de variabilidad marcada (&gt;25 lpm). Se redondea a incrementos de 5 latidos por minuto (lpm).[4, 5, 6, 7, 8] El rango normal se considera entre 110 y 160 lpm.[9, 10]\n\n\nfetal_movement\nNúmero de movimientos fetales detectados por segundo.[1, 11, 12]\n\n\nuterine_contractions\nNúmero de contracciones uterinas por segundo. Se considera normal tener 5 o menos contracciones en 10 minutos.[1, 4, 11, 12]\n\n\nEventos Transitorios (Aceleraciones y Deceleraciones)\n\n\n\naccelerations\nNúmero de aceleraciones por segundo. Una aceleración es un aumento abrupto de la FCF por encima de la línea de base de al menos 15 lpm, que dura 15 segundos o más, pero menos de 2 minutos.[5, 9, 10]\n\n\nlight_decelerations\nNúmero de deceleraciones leves por segundo. Una deceleración es una caída de la FCF de más de 15 lpm que dura más de 15 segundos.[5] La categoría “leve” se refiere a su duración, típicamente menor a 120 segundos.[3]\n\n\nsevere_decelerations\nNúmero de deceleraciones severas por segundo. Se refiere a deceleraciones de larga duración, a menudo definidas como aquellas que superan los 300 segundos.[3]\n\n\nprolongued_decelerations\nNúmero de deceleraciones prolongadas por segundo. Son caídas de la FCF que duran más de 2 o 3 minutos pero menos de 10 minutos.[3, 6, 13]\n\n\nVariabilidad de la FCF\n\n\n\nabnormal_short_term_variability\nPorcentaje de tiempo en que la variabilidad a corto plazo (latido a latido) es anormal. La variabilidad se considera anormal si es mínima (≤5 lpm) o marcada (&gt;25 lpm).[6, 8]\n\n\nmean_value_of_short_term_variability\nValor medio de la variabilidad a corto plazo (STV), que describe las fluctuaciones de la FCF latido a latido.[3, 6]\n\n\npercentage_of_time_with_abnormal_long_term_variability\nPorcentaje de tiempo en que la variabilidad a largo plazo es anormal. Se calcula sobre las fluctuaciones de la FCF en un período de un minuto.[5]\n\n\nmean_value_of_long_term_variability\nValor medio de la variabilidad a largo plazo (LTV), que mide la amplitud (diferencia entre el pico y el valle) de las fluctuaciones de la FCF en un minuto.[3, 5]\n\n\nCaracterísticas del Histograma de FCF\nEstas son propiedades estadísticas calculadas a partir de la distribución de todos los valores de FCF registrados durante el período de monitorización.[1, 11, 12]\n\n\nhistogram_width\nEl ancho del histograma, calculado como la diferencia entre el valor máximo (histogram_max) y el mínimo (histogram_min) de la FCF.\n\n\nhistogram_min\nEl valor mínimo de la FCF registrado en el histograma.\n\n\nhistogram_max\nEl valor máximo de la FCF registrado en el histograma.\n\n\nhistogram_number_of_peaks\nEl número de picos en la distribución del histograma.\n\n\nhistogram_number_of_zeroes\nEl número de “ceros” o bins con frecuencia cero en el histograma.\n\n\nhistogram_mode\nEl valor de FCF que aparece con mayor frecuencia (la moda estadística).\n\n\nhistogram_mean\nEl valor medio de la FCF en el histograma (la media estadística).\n\n\nhistogram_median\nEl valor central de la FCF en el histograma (la mediana estadística).\n\n\nhistogram_variance\nLa varianza de los valores de FCF, que mide su dispersión alrededor de la media.\n\n\nhistogram_tendency\nIndica la simetría o sesgo del histograma. Puede interpretarse como: 1 para tendencia a la derecha (positiva), -1 para tendencia a la izquierda (negativa) y 0 para una distribución simétrica."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#contexto-clínico-ctg-2",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#contexto-clínico-ctg-2",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Contexto clínico (CTG)",
    "text": "Contexto clínico (CTG)\n\nCTG registra FCF y contracciones uterinas.\nClasificación clínica (FIGO): normal / sospechoso / patológico.\nVariabilidad, aceleraciones y desaceleraciones son claves."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#regresión-lineal-2",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#regresión-lineal-2",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Regresión Lineal",
    "text": "Regresión Lineal\nIdea clave\nAproxima una relación lineal \\(\\hat{y} = \\beta_0 + \\sum_j \\beta_j x_j\\)minimizando MSE.\nEjemplo didáctico (CTG)\nUsamos una variable continua de CTG como respuesta (p. ej., histogram_width) para ilustrar ajuste y residuales.\n\nDiscusión: supuestos (linealidad, homocedasticidad, independencia), diagnóstico con residuales."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#regresión-logística",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#regresión-logística",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "Regresión Logística",
    "text": "Regresión Logística\nIdea clave\nModela \\(P(Y=1 \\mid \\mathbf{x}) = \\sigma(\\beta_0 + \\mathbf{x}^\\top \\beta)\\) con sigmoide \\(\\sigma(z)=1/(1+e^{-z})\\)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#definición-de-regresión-logística",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#definición-de-regresión-logística",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "1. Definición de Regresión Logística",
    "text": "1. Definición de Regresión Logística\nLa Regresión Logística es un algoritmo de aprendizaje automático supervisado utilizado fundamentalmente para problemas de clasificación binaria.\nA pesar de su nombre, su objetivo no es predecir un valor continuo, sino modelar la probabilidad (\\(P\\)) de que una observación pertenezca a una clase específica (usualmente denotada como \\(Y=1\\)).\nEl modelo toma variables de entrada (features) \\(x_1, \\dots, x_n\\) y estima \\(P(Y=1 | \\mathbf{x})\\)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#el-mecanismo-central-del-modelo",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#el-mecanismo-central-del-modelo",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "2. El Mecanismo Central del Modelo",
    "text": "2. El Mecanismo Central del Modelo\nEl modelo logístico opera en dos pasos cruciales:\n2.1. El Componente Lineal (Logit)\nPrimero, el modelo calcula una suma ponderada de las entradas, exactamente igual que en una regresión lineal. A este resultado (\\(z\\)) se le conoce como logit o, más formalmente, log-odds.\n\\[\nz = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n\\]\n\n\\(\\beta_0\\) es el intercepto (sesgo).\n\\(\\beta_{1 \\dots n}\\) son los coeficientes (pesos) que el modelo aprende.\nEl rango de salida de \\(z\\) es el de todos los números reales: \\((-\\infty, +\\infty)\\).\n\n2.2. La Función Sigmoide (Logística)\nDado que una probabilidad debe estar en el rango \\([0, 1]\\), \\(z\\) no puede ser el resultado final. La regresión logística aplica la función sigmoide (\\(\\sigma\\)) a \\(z\\) para “aplastar” (squash) la salida lineal al rango de probabilidad.\n\\[\nP = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n\\]\n\nSi \\(z \\to +\\infty\\), \\(e^{-z} \\to 0\\), y \\(P \\to 1\\).\nSi \\(z \\to -\\infty\\), \\(e^{-z} \\to +\\infty\\), y \\(P \\to 0\\).\nSi \\(z = 0\\), \\(e^{-0} = 1\\), y \\(P = 0.5\\)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#la-relación-clave-probabilidad-y-log-odds",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#la-relación-clave-probabilidad-y-log-odds",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "3. La Relación Clave: Probabilidad y Log-Odds",
    "text": "3. La Relación Clave: Probabilidad y Log-Odds\nEl concepto central que conecta el modelo lineal con la probabilidad es el log-odds. Esta transformación es necesaria para mapear un espacio acotado \\([0, 1]\\) a un espacio no acotado \\([-\\infty, +\\infty]\\).\n3.1. De Probabilidad a Log-Odds\nLa transformación se realiza en dos pasos:\n\nProbabilidad (\\(P\\)): La probabilidad del evento.\n\nRango: \\([0, 1]\\)\n\nOdds (Momios): La razón entre la probabilidad de que ocurra (\\(P\\)) y la de que no ocurra (\\(1-P\\)). \\[\nOdds = \\frac{P}{1-P}\n\\]\n\nRango: \\([0, +\\infty]\\)\n\nLog-Odds (Logit): El logaritmo natural de los odds. \\[\nLogit(P) = \\ln(Odds) = \\ln\\left(\\frac{P}{1-P}\\right)\n\\]\n\nRango: \\([-\\infty, +\\infty]\\)\n\n\nEl modelo de regresión logística es, por tanto, un modelo lineal que predice el log-odds:\n\\[\nz = \\ln\\left(\\frac{P}{1-P}\\right) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n\n\\]\n3.2. De Log-Odds a Probabilidad (La Inversa)\nPara obtener la probabilidad \\(P\\) a partir del log-odds \\(z\\), simplemente revertimos la transformación Logit. Este proceso de despejar \\(P\\) de la ecuación del logit da origen a la función sigmoide:\n\nEcuación base: \\[\nz = \\ln\\left(\\frac{P}{1-P}\\right)\n\\]\nAplicar exponencial (inversa del logaritmo): \\[\ne^z = \\frac{P}{1-P}\n\\]\nDespejar \\(P\\): \\[\ne^z (1-P) = P\n\\] \\[\ne^z - e^z P = P\n\\] \\[\ne^z = P + e^z P\n\\] \\[\ne^z = P (1 + e^z)\n\\]\nProbabilidad \\(P\\) en función de \\(z\\): \\[\nP = \\frac{e^z}{1 + e^z}\n\\]\nForma sigmoide alternativa (dividiendo numerador y denominador por \\(e^z\\)): \\[\nP = \\frac{e^z/e^z}{(1 + e^z)/e^z} = \\frac{1}{e^{-z} + 1} = \\frac{1}{1 + e^{-z}}\n\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#interpretación-de-coeficientes",
    "href": "presentaciones/ASIM/v2Lect002_AlgoritmoDescensoGradiente.html#interpretación-de-coeficientes",
    "title": "Descenso de Gradiente en Ciencias Biomédicas",
    "section": "4. Interpretación de Coeficientes",
    "text": "4. Interpretación de Coeficientes\nDebido a esta relación, los coeficientes (\\(\\beta_i\\)) del modelo tienen una interpretación específica:\n\nCoeficiente \\(\\beta_i\\): Un incremento de una unidad en la variable \\(x_i\\) (manteniendo las demás constantes) genera un cambio de \\(\\beta_i\\) en el log-odds de la predicción.\nOdds Ratio (OR): Para una interpretación más intuitiva, se utiliza \\(e^{\\beta_i}\\). Un incremento de una unidad en \\(x_i\\) multiplica los odds por un factor de \\(e^{\\beta_i}\\).\n\n\n\n\n\n\n\n\n\n\nClasificación binaria (Normal vs No‑Normal)\n\n\n              precision    recall  f1-score   support\n\n           0      0.778     0.745     0.761        94\n           1      0.929     0.940     0.934       332\n\n    accuracy                          0.897       426\n   macro avg      0.853     0.842     0.848       426\nweighted avg      0.895     0.897     0.896       426"
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent.html",
    "href": "presentaciones/ASIM/Cod001_GradientDescent.html",
    "title": "Importar datos",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nprint(\"CWD =\", Path.cwd())\ndata_path = \"./data\"\n\nCWD = /home/sylph/Data_Cantatio/pablocaicedor.github.io\ndf = pd.read_csv(data_path+\"/Injury_Risk/Injury_Risk.csv\")"
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent.html#metadatos",
    "href": "presentaciones/ASIM/Cod001_GradientDescent.html#metadatos",
    "title": "Importar datos",
    "section": "Metadatos",
    "text": "Metadatos\n\nEntradas (X):\n\nEMG_Quad_RMS_mV (mV): RMS EMG cuádriceps.\nEMG_Ham_RMS_mV (mV): RMS EMG isquiotibiales.\nGRF_Vert_Norm_BW (BW): Fuerza de reacción vertical (normalizada).\nOmega_Shank_deg_s (deg/s): Velocidad angular de la pierna (IMU).\nHip_Flex_deg (deg): Flexión de cadera.\n\n\n\nObjetivos (y):\n\nKnee_Flex_deg (deg): Ángulo de flexión de rodilla (regresión).\nRisk_Lesion (0/1): Riesgo alto de lesión (clasificación)."
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent.html#información-inicial",
    "href": "presentaciones/ASIM/Cod001_GradientDescent.html#información-inicial",
    "title": "Importar datos",
    "section": "1. Información Inicial",
    "text": "1. Información Inicial\n\nIdentificar tipo de variable: numérica, categórica, ordinal, binaria.\nEstablecer unidad de análisis (por sujeto o por medición).\nDocumentar el diccionario de variables.\n\n\ndf.head()\n\n\n\n\n\n\n\n\nKnee_Flex_deg\nEMG_Quad_RMS_mV\nEMG_Ham_RMS_mV\nGRF_Vert_Norm_BW\nOmega_Shank_deg_s\nHip_Flex_deg\nRisk_Lesion\n\n\n\n\n0\n57.301317\n0.106144\n0.045175\n0.340217\n138.162395\n18.599794\n0.0\n\n\n1\n80.432556\n0.238664\n0.112961\n0.321072\n237.345118\n30.271616\n0.0\n\n\n2\n15.173465\n0.188359\n0.175860\n1.178131\n-199.625681\n28.008046\n0.0\n\n\n3\n33.732813\n0.157691\n0.149123\n0.324410\n99.899280\n-2.305005\n0.0\n\n\n4\n16.810117\n0.055884\n0.163247\n0.353535\n57.396787\n-2.537527\n1.0\n\n\n\n\n\n\n\n\ndf[\"Risk_Lesion\"] = df[\"Risk_Lesion\"].astype(\"category\")\ndf.info()\nnumregistros, numvariables = df.shape\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Knee_Flex_deg      1000 non-null   float64\n 1   EMG_Quad_RMS_mV    1000 non-null   float64\n 2   EMG_Ham_RMS_mV     1000 non-null   float64\n 3   GRF_Vert_Norm_BW   1000 non-null   float64\n 4   Omega_Shank_deg_s  1000 non-null   float64\n 5   Hip_Flex_deg       1000 non-null   float64\n 6   Risk_Lesion        1000 non-null   float64\ndtypes: float64(7)\nmemory usage: 54.8 KB\n\n\n\ntbl_missing = df.isna().sum()\ntbl_missing = 100*tbl_missing/numregistros\nlbls = tbl_missing.index.values\nvals = tbl_missing.values\nplt.figure(figsize=(10,6))\nsns.barplot(x=lbls, y=vals)\nplt.xticks(rotation=90)\nplt.ylabel(\"% of missing values\")\nplt.title(\"Percentage of Missing Values per Variable\")\nplt.show()\nvals.shape"
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent.html#calidad-de-los-datos",
    "href": "presentaciones/ASIM/Cod001_GradientDescent.html#calidad-de-los-datos",
    "title": "Importar datos",
    "section": "2. Calidad de los datos",
    "text": "2. Calidad de los datos\n\nValores faltantes: porcentaje, patrón y manejo (eliminación, imputación o modelado).\nCardinalidad irregular: detectar columnas con un solo valor o codificación errónea.\nOutliers: aplicar criterio de Tukey o z-score (&gt;3σ).\n-Validez contextual: verificar rangos fisiológicos (e.g., knee_flex_deg ∈ [0,180]).\n\n\n100*(df.nunique().astype(np.float64)/numregistros)\n\nKnee_Flex_deg         77.2\nEMG_Quad_RMS_mV      100.0\nEMG_Ham_RMS_mV       100.0\nGRF_Vert_Norm_BW     100.0\nOmega_Shank_deg_s    100.0\nHip_Flex_deg         100.0\nRisk_Lesion            0.2\ndtype: float64\n\n\n\ndf[\"z_score_knee_flex\"]=(df[\"Knee_Flex_deg\"]-df[\"Knee_Flex_deg\"].mean())/df[\"Knee_Flex_deg\"].std()\ndf.loc[df[\"z_score_knee_flex\"].abs()&gt;3, \"Knee_Flex_deg\"].value_counts()\n\nQ3 = df[\"Knee_Flex_deg\"].quantile(0.75)\nQ1 = df[\"Knee_Flex_deg\"].quantile(0.25)\nIQR = Q3 - Q1\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\noutliers = df[(df[\"Knee_Flex_deg\"] &lt; lower_bound) | (df[\"Knee_Flex_deg\"] &gt; upper_bound)]\noutliers[\"Knee_Flex_deg\"].value_counts()\n\nSeries([], Name: count, dtype: int64)"
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent.html#análisis-univariado",
    "href": "presentaciones/ASIM/Cod001_GradientDescent.html#análisis-univariado",
    "title": "Importar datos",
    "section": "3. Análisis univariado",
    "text": "3. Análisis univariado\n\nVariables numéricas: histograma, densidad, simetría, curtosis.\nVariables categóricas: frecuencia y proporciones.\nObjetivo de regresión: distribución y normalidad de knee_flex_deg.\nObjetivo de clasificación: balance de clases en Risk_Lesion.\nIndicadores sugeridos\n\nAsimetría (skew), curtosis (kurt).\nTest de normalidad: Shapiro–Wilk o Kolmogorov–Smirnov.\nDetección de colas largas\n\n\n\ndf[\"Risk_Lesion\"].value_counts()\n\nRisk_Lesion\n1.0    506\n0.0    494\nName: count, dtype: int64"
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent.html#análisis-bivariado",
    "href": "presentaciones/ASIM/Cod001_GradientDescent.html#análisis-bivariado",
    "title": "Importar datos",
    "section": "4. Análisis bivariado",
    "text": "4. Análisis bivariado\n\n4.1 Regresión (knee_flex_deg)\n\nCorrelaciones (Pearson/Spearman) entre knee_flex_deg y las variables predictoras.\nDispersión y relación lineal/no lineal.\nPosibles transformaciones (log, sqrt, normalización z-score).\n\n\nsns.scatterplot(data=df, x=\"Knee_Flex_deg\", y=\"Hip_Flex_deg\", hue=\"Risk_Lesion\")\n\n\n\n\n\n\n\n\n\n\n4.2 Clasificación (Risk_Lesion)\n\nComparación de medias por grupo (t-test o ANOVA).\nVisualización de separación de clases: sns.pairplot(hue=‘Risk_Lesion’).\nMatriz de correlación de variables relevantes para discriminación.\n\n\ndf.corr()\n\n\n\n\n\n\n\n\nKnee_Flex_deg\nEMG_Quad_RMS_mV\nEMG_Ham_RMS_mV\nGRF_Vert_Norm_BW\nOmega_Shank_deg_s\nHip_Flex_deg\nRisk_Lesion\nz_score_knee_flex\n\n\n\n\nKnee_Flex_deg\n1.000000\n0.028383\n-0.062662\n0.087365\n0.939718\n0.177873\n0.118338\n1.000000\n\n\nEMG_Quad_RMS_mV\n0.028383\n1.000000\n0.029310\n0.014518\n-0.029424\n0.034785\n-0.446479\n0.028383\n\n\nEMG_Ham_RMS_mV\n-0.062662\n0.029310\n1.000000\n0.027262\n-0.005791\n0.032911\n0.272992\n-0.062662\n\n\nGRF_Vert_Norm_BW\n0.087365\n0.014518\n0.027262\n1.000000\n-0.013560\n-0.008858\n0.037039\n0.087365\n\n\nOmega_Shank_deg_s\n0.939718\n-0.029424\n-0.005791\n-0.013560\n1.000000\n-0.044812\n0.066284\n0.939718\n\n\nHip_Flex_deg\n0.177873\n0.034785\n0.032911\n-0.008858\n-0.044812\n1.000000\n0.049999\n0.177873\n\n\nRisk_Lesion\n0.118338\n-0.446479\n0.272992\n0.037039\n0.066284\n0.049999\n1.000000\n0.118338\n\n\nz_score_knee_flex\n1.000000\n0.028383\n-0.062662\n0.087365\n0.939718\n0.177873\n0.118338\n1.000000"
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent.html#análisis-multivariado",
    "href": "presentaciones/ASIM/Cod001_GradientDescent.html#análisis-multivariado",
    "title": "Importar datos",
    "section": "5. Análisis multivariado",
    "text": "5. Análisis multivariado\n\nReducción de dimensionalidad: PCA, t-SNE, o UMAP (para inspección visual).\nEvaluación de colinealidad: VIF &gt; 5 sugiere eliminar variables redundantes.\nMapeo estructural: identificar clústeres naturales y relaciones no lineales."
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent.html#preparación-del-abt-analytical-base-table",
    "href": "presentaciones/ASIM/Cod001_GradientDescent.html#preparación-del-abt-analytical-base-table",
    "title": "Importar datos",
    "section": "6. Preparación del ABT (Analytical Base Table)",
    "text": "6. Preparación del ABT (Analytical Base Table)\n\nEliminar variables con &gt;60% de valores nulos.\nCodificar variables categóricas (one-hot o label encoding).\nEscalar numéricas (StandardScaler o MinMaxScaler).\nDividir entre train / test sin fuga de información."
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent.html#eda-orientado-al-modelado",
    "href": "presentaciones/ASIM/Cod001_GradientDescent.html#eda-orientado-al-modelado",
    "title": "Importar datos",
    "section": "7. EDA orientado al modelado",
    "text": "7. EDA orientado al modelado\n\nPara regresión: identificar relaciones no lineales → explorar transformaciones de knee_flex_deg.\nPara clasificación: verificar separabilidad y métricas de desequilibrio (balanced_accuracy, AUC)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-machine-learning-ml",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-machine-learning-ml",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "¿Qué es Machine Learning (ML)?",
    "text": "¿Qué es Machine Learning (ML)?\n\nEl Machine Learning (Aprendizaje Automático) es un proceso automatizado que se encarga de extraer patrones a partir de los datos.\n\n\nEs un campo de conocimiento crucial y una tecnología omnipresente.\n\n\nSu objetivo fundamental es ajustar modelos a los datos proporcionados para permitir la predicción y clasificación."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-rol-de-la-predicción",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-rol-de-la-predicción",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "El Rol de la Predicción",
    "text": "El Rol de la Predicción\n\nEl ML busca aprender a predecir (estimar o aproximar) la etiqueta de un punto de datos basándose exclusivamente en sus características (features).\n\n\nImplementa el principio científico de “prueba y error”.\n\n\nEsto se logra refinando continuamente un modelo de forma iterativa, basándose en la pérdida incurrida por sus predicciones frente a los datos reales observados."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#componentes-esenciales",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#componentes-esenciales",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Componentes Esenciales",
    "text": "Componentes Esenciales\nLa teoría del Machine Learning se presenta como la combinación de tres componentes básicos e interdependientes:\n\nDatos (Data): La materia prima a partir de la cual el sistema aprende.\nModelo (Model): La estructura matemática que se ajusta a los datos (ej. red neuronal, árbol de decisión).\nFunción de Pérdida (Loss Function): Mide la discrepancia entre las predicciones del modelo y los valores reales observados."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-machine-learning-ml-y-la-sanidad",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-machine-learning-ml-y-la-sanidad",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "El Machine Learning (ML) y la Sanidad",
    "text": "El Machine Learning (ML) y la Sanidad\nEl Machine Learning (ML) es un proceso automatizado que se dedica a extraer patrones complejos de los datos. En el sector salud, el objetivo es utilizar el ML para apoyar la toma de decisiones clínicas y operacionales.\nEl ML supervisado aprende un modelo a partir de un conjunto de características descriptivas y una característica objetivo, basándose en un conjunto de ejemplos históricos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#tipos-de-modelos-de-ml",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#tipos-de-modelos-de-ml",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Tipos de Modelos de ML",
    "text": "Tipos de Modelos de ML\n\nModelos Predictivos: Permiten asignar un valor a cualquier variable desconocida, incluso si no tiene un aspecto temporal (como predecir un diagnóstico).\nRedes Neuronales Convolucionales (CNNs): Modelos de Deep Learning ideales para procesar datos con estructura de cuadrícula, como las imágenes, cruciales en el diagnóstico médico.\nIA Causal: Utilizada para hacer inferencias sobre causa y efecto, lo cual es vital en la biología, la medicina y el desarrollo de fármacos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#casos-de-uso-en-el-diagnóstico-médico",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#casos-de-uso-en-el-diagnóstico-médico",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Casos de Uso en el Diagnóstico Médico",
    "text": "Casos de Uso en el Diagnóstico Médico\nLa analítica predictiva se utiliza para construir modelos que asisten en el diagnóstico, aprovechando grandes colecciones de ejemplos históricos que superan lo que un solo individuo vería en su carrera.\n\nClasificación de Imágenes: Las CNNs son adecuadas para tareas que involucran datos con estructuras de cuadrícula fija.\nDetección de Cáncer: Los modelos se pueden construir para la identificación de especies bacterianas o la clasificación de muestras de tejido para el cáncer de mama.\nPredicción de Riesgo Cardiovascular (CVD): Los modelos de regresión logística pueden predecir la probabilidad de que un paciente tenga una enfermedad.\nMedicina de Precisión: Las distribuciones de probabilidad se usan para modelar poblaciones y subpoblaciones, lo cual ayuda a dirigir tratamientos específicos a grupos de pacientes que podrían beneficiarse, por ejemplo, los que tienen diabetes."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#desafíos-del-ml-en-el-sector-salud",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#desafíos-del-ml-en-el-sector-salud",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Desafíos del ML en el Sector Salud",
    "text": "Desafíos del ML en el Sector Salud\nLa IA Causal es fundamental para ir más allá de la correlación y estimar los efectos de una acción.\n\nOptimización de Dosis: Los modelos pueden predecir las dosis óptimas de un medicamento basándose en datos históricos de tratamientos y resultados asociados.\nCostos de I+D: El desarrollo de nuevos fármacos es costoso (puede llegar a USD 2-3 mil millones) y tiene una alta tasa de fracaso (95% en ensayos clínicos).\nErrores de Atribución: Una parte significativa de los fracasos en el desarrollo de medicamentos se atribuye a errores de atribución causal, como la mala selección de objetivos farmacológicos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#estimación-de-efectos-y-robustez",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#estimación-de-efectos-y-robustez",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Estimación de Efectos y Robustez",
    "text": "Estimación de Efectos y Robustez\n\nEfectos Heterogéneos del Tratamiento (CATEs): Miden cómo varían los efectos de un tratamiento en diferentes segmentos de la población.\nRobutsez Adversarial: En aplicaciones sensibles, la seguridad de los modelos debe ser evaluada frente a ataques, como la manipulación de imágenes médicas."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#la-necesidad-de-modelos-interpretables",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#la-necesidad-de-modelos-interpretables",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "La Necesidad de Modelos Interpretables",
    "text": "La Necesidad de Modelos Interpretables\nLa interpretación es esencial para garantizar que los modelos sean seguros, justos y fiables.\n\nTransparencia y Explicación: La interpretabilidad reduce la brecha entre los complejos algoritmos y los usuarios humanos.\nDecisiones Cruciales: En ámbitos como el diagnóstico de cáncer, la interpretación del modelo es crucial para justificar las predicciones.\nEquidad y Rendición de Cuentas (FAT): La interpretación ayuda a asegurar que las predicciones se hagan sin sesgos discernibles (equidad) y a explicar por qué se tomaron ciertas decisiones (rendición de cuentas).\nModelos de Caja Blanca: Modelos como la regresión logística son inherentemente interpretables (intrínsecamente interpretables) porque su lógica es transparente."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-problema-fundamental-búsqueda-y-bias",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#el-problema-fundamental-búsqueda-y-bias",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "El Problema Fundamental: Búsqueda y Bias",
    "text": "El Problema Fundamental: Búsqueda y Bias\nLos algoritmos de ML funcionan buscando entre un conjunto de modelos posibles para encontrar aquel que mejor se ajusta a los datos.\n\nProblema Mal Planteado (Ill-Posed Problem): La muestra de datos de entrenamiento es limitada. Como resultado, muchos modelos pueden ser consistentes con los datos, haciendo imposible elegir una solución única solo por la consistencia.\nSin una guía, un modelo solo memorizaría los datos (un extremo de sobreajuste)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#guía-para-la-selección-del-modelo",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#guía-para-la-selección-del-modelo",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Guía para la Selección del Modelo",
    "text": "Guía para la Selección del Modelo\nPara encontrar el modelo que mejor generaliza, los algoritmos utilizan un conjunto de suposiciones llamado Bias Inductivo.\nEste bias dirige la búsqueda del algoritmo hacia modelos específicos que se asumen más apropiados para el dominio.\n\n\nTipos de Bias\n\nBias de Restricción: Limita el conjunto de modelos posibles (ej. solo considerar modelos lineales).\nBias de Preferencia: Prefiere modelos con ciertas características (ej. preferir modelos más simples o menos complejos).\n\n\nErrores Comunes\nSi el bias inductivo es inapropiado, el modelo cometerá errores de generalización: - Underfitting (Subajuste): Modelo demasiado simplista que no captura la relación subyacente. - Overfitting (Sobreajuste): Modelo demasiado complejo que se ajusta al ruido en los datos de entrenamiento."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-error",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-error",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Paradigmas de Aprendizaje: Modelos Basados en Error",
    "text": "Paradigmas de Aprendizaje: Modelos Basados en Error\nEstos modelos buscan un conjunto de parámetros que minimice el error total en las predicciones con respecto al conjunto de entrenamiento.\n\nConcepto Central: Descenso de Gradiente (Gradient Descent). Es un algoritmo de búsqueda guiada que ajusta iterativamente los parámetros del modelo (pesos) para moverse hacia el mínimo global en una superficie de error.\nFunción de Pérdida: Típicamente el Error Cuadrático Sumado (\\(L2\\)) o la Pérdida de Entropía Cruzada.\nEjemplo: Regresión Logística/Lineal. El modelo se define mediante una combinación lineal de las características descriptivas multiplicadas por un conjunto de pesos.\nRegla de Actualización: El ajuste del peso (\\(\\Delta w\\)) es proporcional a la tasa de aprendizaje (\\(\\alpha\\)) y al gradiente de error."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-similitud",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-similitud",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Paradigmas de Aprendizaje: Modelos Basados en Similitud",
    "text": "Paradigmas de Aprendizaje: Modelos Basados en Similitud\nSe basan en la idea de que si una instancia es similar a instancias históricas, tendrá la misma etiqueta o valor objetivo.\n\nAlgoritmos: k-Vecinos Más Cercanos (k-NN).\nEspacio de Características: Las instancias se representan como puntos en un espacio de características, y la distancia entre ellas mide su disimilitud.\nFuncionamiento: Para una nueva consulta, el modelo identifica los \\(k\\) vecinos más cercanos y predice la clase por voto mayoritario o el valor por promedio de sus vecinos.\nMétricas: Comúnmente se usa la Distancia Euclidiana o la Distancia Mahalanobis (que considera la covarianza entre características)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-información",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#paradigmas-de-aprendizaje-modelos-basados-en-información",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Paradigmas de Aprendizaje: Modelos Basados en Información",
    "text": "Paradigmas de Aprendizaje: Modelos Basados en Información\nEstos modelos determinan qué características son las más informativas para realizar una secuencia de pruebas.\n\nAlgoritmos: Árboles de Decisión (Decision Trees).\nEstructura: Se construye una estructura jerárquica donde los nodos internos representan pruebas de características y los nodos hoja representan la predicción.\nMedida Clave: La Ganancia de Información (Information Gain), calculada a partir de la Entropía, mide la reducción en la impureza del conjunto de datos al dividirlo por una característica.\nBias: Los algoritmos (como ID3) prefieren los árboles más superficiales (menos complejos)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-crisp-dm",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-crisp-dm",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "¿Qué es CRISP-DM?",
    "text": "¿Qué es CRISP-DM?\n\nEstándar de facto para proyectos analíticos.\n6 fases iterativas: Entendimiento del negocio, Entendimiento de los datos, Preparación de los datos, Modelado, Evaluación, Despliegue.\nCiclo no lineal; retroalimentación entre fases."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-diagrama",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-diagrama",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Visión general (diagrama)",
    "text": "Visión general (diagrama)\n\n\n\n\n\n\n\nArtefactos\n\n\ncluster0\n\n1. Negocio\n\n\ncluster1\n\n2. Datos\n\n\ncluster2\n\n3. Preparación\n\n\ncluster3\n\n4. Modelado\n\n\ncluster4\n\n5. Evaluación\n\n\ncluster5\n\n6. Despliegue\n\n\n\nN1\n\n\n\nPICO/PECO\n\n\n\nD1\n\n\n\nInventario de fuentes\n\n\n\nN1-&gt;D1\n\n\nrequisitos\n de datos\n\n\n\nN2\n\n\n\nKPIs & Umbrales\n\n\n\nN3\n\n\n\nRiesgos & Ética\n\n\n\nD2\n\n\n\nData Dictionary\n\n\n\nD3\n\n\n\nData Quality Report\n\n\n\nP1\n\n\n\nLimpieza/Imputación\n\n\n\nD3-&gt;P1\n\n\ncalidad\n\n\n\nP1-&gt;D2\n\n\nmetadatos\n\n\n\nP2\n\n\n\nIngeniería de features\n\n\n\nP3\n\n\n\nSplits anti-fuga\n\n\n\nM1\n\n\n\nBaselines\n\n\n\nP3-&gt;M1\n\n\ndataset\n modelable\n\n\n\nM1-&gt;P2\n\n\nfeatures\n\n\n\nM2\n\n\n\nTuning & CV\n\n\n\nM3\n\n\n\nArtefacto de inferencia\n\n\n\nE1\n\n\n\nROC/PR/Calibración\n\n\n\nM3-&gt;E1\n\n\nmodelo\n\n\n\nE1-&gt;M1\n\n\najustes\n\n\n\nE2\n\n\n\nErrores críticos\n\n\n\nE3\n\n\n\nAnálisis por subgrupos\n\n\n\nS1\n\n\n\nContenedor/Package\n\n\n\nE3-&gt;S1\n\n\ngo/no-go\n\n\n\nS2\n\n\n\nMonitoreo & Alertas\n\n\n\nS3\n\n\n\nPlan de retraining"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entendimiento del negocio",
    "text": "Entendimiento del negocio\n\nProblema clínico/laboral y población objetivo.\nMetas analíticas: clasificación, regresión, segmentación, detección.\nKPIs y restricciones: seguridad, costo, tiempo, privacidad.\nCriterio de éxito: p. ej., AUC ≥ 0.90, sensibilidad ≥ 0.95 en clase minoritaria.\nPlan del proyecto: roles, riesgos, cronograma y datos requeridos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 1)",
    "text": "Entregables (Fase 1)\n\nDeclaración PICO/PECO del problema.\nMapa de stakeholders y requisitos.\nMétricas primarias/secundarias y umbrales mínimos.\nProtocolos de ética y gobernanza de datos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#pico-ensayos-clínicos-intervenciones",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#pico-ensayos-clínicos-intervenciones",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "PICO (ensayos clínicos / intervenciones)",
    "text": "PICO (ensayos clínicos / intervenciones)\n\nPopulation (Población): ¿en quiénes? (pacientes, criterios de inclusión/exclusión).\nIntervention (Intervención): ¿qué intervención/exposición activa? (tratamiento, protocolo, dispositivo).\nComparator (Comparador): ¿contra qué se compara? (placebo, estándar de cuidado, otra intervención).\nOutcome (Resultado): ¿qué desenlaces medimos? (clínicos, funcionales, seguridad), con definición operacional y horizonte temporal.\n\nCuándo usarlo: preguntas de efectividad/eficacia de una intervención (típico en ECA o cuasi-experimentos).\nEjemplo (biomédico – señales)\n\nP: Adultos con sospecha de fibrilación auricular en monitoreo Holter.\nI: Algoritmo de detección basado en ECG de 1 derivación con filtro adaptativo.\nC: Lectura por cardiólogo + algoritmo convencional validado.\nO: Sensibilidad ≥ 0.95 y valor predictivo positivo ≥ 0.90 para episodios ≥ 30 s, en validación ciega."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#peco-observacionales-exposiciones",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#peco-observacionales-exposiciones",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "PECO (observacionales / exposiciones)",
    "text": "PECO (observacionales / exposiciones)\n\nPopulation (Población): ¿en quiénes?\nExposure (Exposición): ¿qué factor de exposición? (p. ej., carga mecánica, turno nocturno, tabaquismo).\nComparator (Comparador): nivel de exposición de referencia (no expuestos / menos expuestos).\nOutcome (Resultado): desenlaces (incidencia, progresión, biomarcadores), con definición y ventana temporal.\n\nCuándo usarlo: preguntas de asociación causal o riesgo en estudios cohortes/casos y controles/transversales.\nEjemplo (biomecánica – LCA)\n\nP: Deportistas amateur 18–35 años post-reconstrucción de LCA.\nE: Asimetría de momento extensor de rodilla &gt; 15% durante salto con caída.\nC: Asimetría ≤ 15%.\nO: Re-lesión contralateral o ipsilateral a 12 meses."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#consejos-operativos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#consejos-operativos",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Consejos operativos",
    "text": "Consejos operativos\n\nDefinir Outcomes con métricas, umbrales y ventana temporal (p. ej., “∆IKDC ≥ 10 puntos a 6 meses”).\nEn PECO, describir la medición de la exposición (instrumento, frecuencia, umbral) para minimizar sesgo de clasificación.\nEspecificar a priori confusores y plan de ajuste (edad, sexo, dominio lateral, centro).\nEvitar outcomes compuestos mal justificados; priorizar uno primario y secundarios jerárquicos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#plantillas-rápidas",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#plantillas-rápidas",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Plantillas rápidas",
    "text": "Plantillas rápidas\n\nPICO: “En P, ¿la I comparada con C mejora O en T?”\nPECO: “En P, ¿la E frente a C se asocia con O en T, controlando por confusores?”"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entendimiento de los datos",
    "text": "Entendimiento de los datos\n\nInventario de fuentes: dispositivos, HIS/RIS, PACS, cuadernos de campo.\nExploración: tipos de variables, distribución, cardinalidad, valores faltantes.\nCalidad de datos: outliers, inconsistencias, sesgos de muestreo.\nPlan de calidad (qué corregir ahora vs. más adelante).\n\n\n\nRecomendación: elaborar un Data Quality Report y un diccionario de datos versionado."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 2)",
    "text": "Entregables (Fase 2)\n\nData Quality Report (resumen estadístico + visualizaciones clave).\nDiccionario de datos y esquema de metadatos.\nLista de riesgos de validez (fuga de datos, leakage temporal, etc.)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparación-de-los-datos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparación-de-los-datos",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Preparación de los datos",
    "text": "Preparación de los datos\n\nLimpieza: imputación, manejo de atípicos, corrección de etiquetas.\nTransformaciones: normalización/estandarización, codificación categórica.\nIngeniería de características: ventanas temporales, espectro, texturas, ROI.\nParticiones: train/val/test con reglas anti-fuga (por paciente/centro).\n\n\n\nBiomédico: documente pipelines reproducibles con scripts y seed fijo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 3)",
    "text": "Entregables (Fase 3)\n\nABT (Analytical Base Table) o dataset modelable, con versión.\nPipelines de preproceso (código + parámetros + pruebas).\nEvidencia de no-fuga y balance/clase."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Modelado",
    "text": "Modelado\n\nBaselines robustos y trazables (p. ej., regresión logística, NB, SVM).\nModelos avanzados: árboles/ensembles, deep learning si aplica.\nValidación: K-fold estratificado por sujeto/centro; early stopping.\nTuning: búsqueda de hiperparámetros; ablation de features."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 4)",
    "text": "Entregables (Fase 4)\n\nReporte de experimentos (configuraciones, semillas, versiones).\nCurvas y tablas: ROC/PR, aprendizaje, calibración, importancia de variables.\nModelo empaquetado (artefacto + inference script + schema de I/O)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluación",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Evaluación",
    "text": "Evaluación\n\nValidez técnica: desempeño, incertidumbre, estabilidad temporal.\nValidez clínica/operacional: umbrales de decisión, impacto, costos.\nExplicabilidad: errores críticos, análisis por subgrupos (equidad).\nRevisión de riesgos: seguridad, privacidad, robustez, shift de dominio."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 5)",
    "text": "Entregables (Fase 5)\n\nInforme de evaluación con estratificación por subpoblaciones.\nMatriz de confusión, curvas ROC/PR, lift/gain si hay casos raros.\nDecisiones de go/no-go y plan de mitigación de riesgos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Despliegue",
    "text": "Despliegue\n\nMVP en entorno controlado (sandbox/val clínica) con monitoreo.\nMLOps: versionado de datos/modelos, CI/CD, model registry.\nMonitoreo post-despliegue: drift, desempeño, alertas.\nCiclo de mantenimiento: retraining, gobernanza, auditoría."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 6)",
    "text": "Entregables (Fase 6)\n\nPaquete de despliegue (contenedor o wheel), manual de integración.\nTablero de monitoreo y protocolo de incidentes.\nPlan de actualización y retiro seguro del modelo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Checklist resumido",
    "text": "Checklist resumido\n\nProblema y métricas claros.\nDatos caracterizados y limpios.\nParticiones sin fuga.\nBaseline y SOTA comparables.\nEvaluación por subgrupos.\nPlan de despliegue y monitoreo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-crisp-dm-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#qué-es-crisp-dm-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "¿Qué es CRISP-DM?",
    "text": "¿Qué es CRISP-DM?\n\nEstándar de facto para proyectos analíticos.\n6 fases iterativas: Entendimiento del negocio, Entendimiento de los datos, Preparación de los datos, Modelado, Evaluación, Despliegue.\nCiclo no lineal; retroalimentación entre fases.\n\n\n\nConsejo: marque explícitamente supuestos, riesgos y decisiones en actas breves por fase."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-diagrama-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-diagrama-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Visión general (diagrama)",
    "text": "Visión general (diagrama)\n\n\n\n\n\n\n\nCRISPDM\n\n\n\nA\n\nEntendimiento\n del negocio\n\n\n\nB\n\nEntendimiento\n de los datos\n\n\n\nA-&gt;B\n\n\n\n\n\nC\n\nPreparación\n de los datos\n\n\n\nB-&gt;C\n\n\n\n\n\nC-&gt;B\n\n\nretrabajo\n\n\n\nD\n\nModelado\n\n\n\nC-&gt;D\n\n\n\n\n\nD-&gt;B\n\n\ndiagnósticos\n\n\n\nE\n\nEvaluación\n\n\n\nD-&gt;E\n\n\n\n\n\nE-&gt;A\n\n\nredefinir metas\n\n\n\nF\n\nDespliegue\n\n\n\nE-&gt;F"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-artefactos-por-fase",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#visión-general-artefactos-por-fase",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Visión general (artefactos por fase)",
    "text": "Visión general (artefactos por fase)\n\n\n\n\n\n\n\nArtefactos\n\n\ncluster5\n\n6. Despliegue\n\n\ncluster1\n\n2. Datos\n\n\ncluster2\n\n3. Preparación\n\n\ncluster3\n\n4. Modelado\n\n\ncluster0\n\n1. Negocio\n\n\ncluster4\n\n5. Evaluación\n\n\n\nN1\n\n\n\nPICO/PECO\n\n\n\nD1\n\n\n\nInventario de fuentes\n\n\n\nN1-&gt;D1\n\n\nrequisitos\n de datos\n\n\n\nN2\n\n\n\nKPIs & Umbrales\n\n\n\nN3\n\n\n\nRiesgos & Ética\n\n\n\nD2\n\n\n\nData Dictionary\n\n\n\nD3\n\n\n\nData Quality Report\n\n\n\nP1\n\n\n\nLimpieza/Imputación\n\n\n\nD3-&gt;P1\n\n\ncalidad\n\n\n\nP1-&gt;D2\n\n\nmetadatos\n\n\n\nP2\n\n\n\nIngeniería de features\n\n\n\nP3\n\n\n\nSplits anti-fuga\n\n\n\nM1\n\n\n\nBaselines\n\n\n\nP3-&gt;M1\n\n\ndataset\n modelable\n\n\n\nM1-&gt;P2\n\n\nfeatures\n\n\n\nM2\n\n\n\nTuning & CV\n\n\n\nM3\n\n\n\nArtefacto de inferencia\n\n\n\nE1\n\n\n\nROC/PR/Calibración\n\n\n\nM3-&gt;E1\n\n\nmodelo\n\n\n\nE1-&gt;M1\n\n\najustes\n\n\n\nE2\n\n\n\nErrores críticos\n\n\n\nE3\n\n\n\nAnálisis por subgrupos\n\n\n\nS1\n\n\n\nContenedor/Package\n\n\n\nE3-&gt;S1\n\n\ngo/no-go\n\n\n\nS2\n\n\n\nMonitoreo & Alertas\n\n\n\nS3\n\n\n\nPlan de retraining"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-del-negocio-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "1) Entendimiento del negocio",
    "text": "1) Entendimiento del negocio\n\nProblema clínico/laboral y población objetivo.\nMetas analíticas: clasificación, regresión, segmentación, detección.\nKPIs y restricciones: seguridad, costo, tiempo, privacidad.\nCriterio de éxito: p. ej., AUC ≥ 0.90, sensibilidad ≥ 0.95 en clase minoritaria.\nPlan del proyecto: roles, riesgos, cronograma y datos requeridos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-1-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 1)",
    "text": "Entregables (Fase 1)\n\nDeclaración PICO/PECO del problema.\nMapa de stakeholders y requisitos.\nMétricas primarias/secundarias y umbrales mínimos.\nProtocolos de ética y gobernanza de datos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entendimiento-de-los-datos-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "2) Entendimiento de los datos",
    "text": "2) Entendimiento de los datos\n\nInventario de fuentes: dispositivos, HIS/RIS, PACS, cuadernos de campo.\nExploración: tipos de variables, distribución, cardinalidad, valores faltantes.\nCalidad de datos: outliers, inconsistencias, sesgos de muestreo.\nPlan de calidad (qué corregir ahora vs. más adelante).\n\n\n\nRecomendación: elaborar un Data Quality Report y un diccionario de datos versionado."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-2-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 2)",
    "text": "Entregables (Fase 2)\n\nData Quality Report (resumen estadístico + visualizaciones clave).\nDiccionario de datos y esquema de metadatos.\nLista de riesgos de validez (fuga de datos, leakage temporal, etc.)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparación-de-los-datos-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#preparación-de-los-datos-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "3) Preparación de los datos",
    "text": "3) Preparación de los datos\n\nLimpieza: imputación, manejo de atípicos, corrección de etiquetas.\nTransformaciones: normalización/estandarización, codificación categórica.\nIngeniería de características: ventanas temporales, espectro, texturas, ROI.\nParticiones: train/val/test con reglas anti-fuga (por paciente/centro).\n\n\n\nBiomédico: documente pipelines reproducibles con scripts y seed fijo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-3-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 3)",
    "text": "Entregables (Fase 3)\n\nABT (Analytical Base Table) o dataset modelable, con versión.\nPipelines de preproceso (código + parámetros + pruebas).\nEvidencia de no-fuga y balance/clase."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#modelado-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "4) Modelado",
    "text": "4) Modelado\n\nBaselines robustos y trazables (p. ej., regresión logística, NB, SVM).\nModelos avanzados: árboles/ensembles, deep learning si aplica.\nValidación: K-fold estratificado por sujeto/centro; early stopping.\nTuning: búsqueda de hiperparámetros; ablation de features."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-4-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 4)",
    "text": "Entregables (Fase 4)\n\nReporte de experimentos (configuraciones, semillas, versiones).\nCurvas y tablas: ROC/PR, aprendizaje, calibración, importancia de variables.\nModelo empaquetado (artefacto + inference script + schema de I/O)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#evaluación-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "5) Evaluación",
    "text": "5) Evaluación\n\nValidez técnica: desempeño, incertidumbre, estabilidad temporal.\nValidez clínica/operacional: umbrales de decisión, impacto, costos.\nExplicabilidad: errores críticos, análisis por subgrupos (equidad).\nRevisión de riesgos: seguridad, privacidad, robustez, shift de dominio."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-5-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 5)",
    "text": "Entregables (Fase 5)\n\nInforme de evaluación con estratificación por subpoblaciones.\nMatriz de confusión, curvas ROC/PR, lift/gain si hay casos raros.\nDecisiones de go/no-go y plan de mitigación de riesgos."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#despliegue-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "6) Despliegue",
    "text": "6) Despliegue\n\nMVP en entorno controlado (sandbox/val clínica) con monitoreo.\nMLOps: versionado de datos/modelos, CI/CD, model registry.\nMonitoreo post-despliegue: drift, desempeño, alertas.\nCiclo de mantenimiento: retraining, gobernanza, auditoría."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#entregables-fase-6-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Entregables (Fase 6)",
    "text": "Entregables (Fase 6)\n\nPaquete de despliegue (contenedor o wheel), manual de integración.\nTablero de monitoreo y protocolo de incidentes.\nPlan de actualización y retiro seguro del modelo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido-1",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#checklist-resumido-1",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Checklist resumido",
    "text": "Checklist resumido\n\nProblema y métricas claros.\nDatos caracterizados y limpios.\nParticiones sin fuga.\nBaseline y SOTA comparables.\nEvaluación por subgrupos.\nPlan de despliegue y monitoreo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-1-negocio",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-1-negocio",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 1 — Negocio",
    "text": "Fase 1 — Negocio\n1.1 Declaración PICO/PECO\n**Tipo**: PICO | PECO\n**Población (P)**:\n**Intervención/Exposición (I/E)**:\n**Comparador (C)**:\n**Outcomes (O)**:\n**Horizonte temporal (T)**:\n**Confusores a controlar**:\n**Criterio de éxito** (umbral y justificación):\n1.2 Mapa de stakeholders y requisitos\n**Stakeholders clave**: clínica, ingeniería, TI, ética, pacientes.\n**Requisitos funcionales**:\n- RF1:\n- RF2:\n**Requisitos no funcionales** (seguridad, latencia, costo):\n- RNF1:\n- RNF2:\n**Riesgos y supuestos**:\n- R1:\n- S1:\n1.3 Métricas primarias/ secundarias\n**Tarea**: clasificación | regresión | segmentación | detección\n**Métrica primaria**: (p. ej., Sensibilidad@95% especificidad)\n**Métricas secundarias**: (AUC, F1, Brier, MAE, Dice/IoU)\n**Umbrales mínimos**:\n**Justificación clínica/operativa**:\n1.4 Ética y gobernanza de datos\n**Base legal** (consentimiento/anonimización):\n**Evaluación de riesgo** (privacidad, sesgo, seguridad):\n**Controles** (pseudonimización, control de acceso, auditoría):\n**Plan de datos** (retención, eliminación, transferencia):"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-2-datos",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-2-datos",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 2 — Datos",
    "text": "Fase 2 — Datos\n2.1 Data Quality Report (DQR)\n**Origen de datos**: dispositivos/HIS/PACS/CSV/etc.\n**Cobertura temporal**:\n**Resumen por variable**:\n| Variable | Tipo | Unidades | % NA | Únicos | Min | Q1 | Mediana | Q3 | Max |\n|---|---|---|---:|---:|---:|---:|---:|---:|---:|\n| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n\n**Chequeos de reglas** (rangos plausibles, consistencia):\n- R1:\n- R2:\n**Outliers y tratamiento propuesto**:\n**Sesgos potenciales** (selección, medición):\n2.2 Diccionario de datos\n| Nombre | Descripción | Tipo | Dominio/Unidades | Fuente | Notas |\n|---|---|---|---|---|---|\n| ... | ... | ... | ... | ... | ... |\n2.3 Riesgos de validez\n**Fugas potenciales**: por paciente, por tiempo, por sitio.\n**Dependencias**: variables derivadas del futuro.\n**Mitigaciones**: reglas de partición, ventanas estrictas."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-3-preparación",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-3-preparación",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 3 — Preparación",
    "text": "Fase 3 — Preparación\n3.1 ABT / Dataset modelable (versión)\n**ID de versión**: abt_vYYYYMMDD\n**Clave de unidad analítica**: (p. ej., paciente, estudio, ventana)\n**Target**:\n**Features**: listado y fuente de cada una\n**Partición**: train/val/test con conteos por clase y por paciente\n3.2 Pipelines de preprocesamiento\n# pipeline_prepro.yaml\nversion: 1\nstages:\n  - name: limpieza\n    steps:\n      - imputacion: {estrategia: median, variables: [x1, x2]}\n      - winsorizacion: {p: 0.01}\n  - name: transformaciones\n    steps:\n      - estandarizacion: {método: zscore, by: train}\n      - pca: {var_explicada: 0.95}\nartifacts:\n  logs_dir: logs/\n  seed: 42\n3.3 Evidencia de no-fuga y balance\n**Regla anti-fuga**: split por paciente/centro/fecha.\n**Chequeo**: 0 pacientes compartidos entre train/val/test.\n**Distribución de clases**:\n| Partición | n | Clase+ | Clase- | %+ |\n|---|---:|---:|---:|---:|\n| Train | | | | |\n| Val   | | | | |\n| Test  | | | | |"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-4-modelado",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-4-modelado",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 4 — Modelado",
    "text": "Fase 4 — Modelado\n4.1 Reporte de experimentos\n**ID experimento**: exp_YYYYMMDD_hhmm\n**Código/commit**:\n**Semilla**: 42\n**Modelo**: (p. ej., LogisticRegression, ResNet18)\n**Features/inputs**:\n**Hiperparámetros**:\n**Esquema de validación**: K-fold estratificado (por paciente)\n4.2 Resultados\n**Curvas**: ROC, PR, calibración (con bandas de confianza)\n**Tablas**: métricas por fold y promedio ± IC95%\n**Importancia de variables/atributos**: SHAP/coeficientes\n4.3 Artefacto de inferencia\n**Formato**: .pt | .onnx | .joblib | contenedor\n**Schema I/O**: tipos, unidades, validaciones\n**Script**: `inference.py` con prepro + postpro\n**Checksum y versión**:"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-5-evaluación",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-5-evaluación",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 5 — Evaluación",
    "text": "Fase 5 — Evaluación\n5.1 Informe técnico de evaluación\n**Desempeño en test**: tabla principal de métricas\n**Estratificación**: por sexo/edad/centro/dispositivo\n**Análisis de errores**: casos representativos, costos\n**Equidad**: diferencias absolutas/relativas entre subgrupos\n5.2 Matrices y curvas\n**Matriz de confusión**: umbral óptimo/operativo\n**Curvas**: ROC/PR; métricas agregadas (AUC, AP)\n**Lift/Gain** (si prevalencia baja)\n5.3 Decisión y riesgos\n**Go/No-Go**: criterio y evidencia\n**Riesgos residuales**: lista y mitigaciones\n**Plan de validación externa**: sitio/fecha/muestra"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-6-despliegue",
    "href": "presentaciones/ASIM/v2Lect001_Presentacion.html#fase-6-despliegue",
    "title": "ML para Señales e Imágenes Médicas",
    "section": "Fase 6 — Despliegue",
    "text": "Fase 6 — Despliegue\n6.1 Paquete de despliegue\n**Estrategia**: contenedor | wheel | servicio\n**Infra**: CPU/GPU, RAM, almacenamiento\n**Integración**: API/HL7/DICOM, autenticación\n**Rollback**: versión estable y procedimiento\n6.2 Monitoreo y respuesta a incidentes\n**KPIs en producción**: latencia, tasa de error, drift, desempeño\n**Alertas**: umbrales y canal (email/ops)\n**Runbooks**: pasos ante fallo de modelo/datos/infra\n6.3 Mantenimiento y retiro\n**Retraining**: criterio de activación, datos y frecuencia\n**Auditoría**: trazabilidad de versiones y accesos\n**Retiro seguro**: plan de sustitución y archivo de modelos"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#introduction",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#introduction",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\nMotivation\n\n\nStandard Feedforward Networks (MLPs) fail to scale for high-dimensional data like images due to:\n\nFull Connectivity: Exploding parameter count.\nSpatial Invariance: Ignorance of local spatial topology.\n\n\n\n\n\nConvolutional Neural Networks (CNNs) introduce:\n\nLocal Connectivity: Neurons connect only to a local receptive field.\nParameter Sharing: Same weights (filters) applied across the input.\nEquivariance: Translation of input results in translation of output."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#the-convolution-operation",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#the-convolution-operation",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "The Convolution Operation",
    "text": "The Convolution Operation\n\n\nIn the context of CNNs, the operation is technically a cross-correlation, but conventionally termed convolution.\nGiven an input image \\(I\\) and a kernel (filter) \\(K\\), the feature map \\(S\\) is defined as:\n\n\n\n\\[S(i, j) = (I * K)(i, j) = \\sum_{m} \\sum_{n} I(i+m, j+n) K(m, n)\\]\nWhere: * \\((i, j)\\) are the pixel coordinates. * \\((m, n)\\) are the kernel offsets."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#hyperparameters",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#hyperparameters",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Hyperparameters",
    "text": "Hyperparameters\nThe spatial dimensions of the output feature map depend on:\n\nFilter Size (\\(F\\)): Receptive field dimensions (e.g., \\(3 \\times 3\\)).\nStride (\\(S\\)): Step size of the filter convolution.\nPadding (\\(P\\)): Zero-padding around the border to preserve dimensions.\n\nOutput Dimension Formula: Given input size \\(W_{in} \\times H_{in}\\):\n\\[W_{out} = \\frac{W_{in} - F + 2P}{S} + 1\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#pooling-layers",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#pooling-layers",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Pooling Layers",
    "text": "Pooling Layers\nPooling provides invariance to small translations and reduces dimensionality (downsampling).\nMax Pooling\nSelects the maximum activation in the receptive field: \\[y_{i,j,k} = \\max_{(p,q) \\in \\mathcal{R}_{i,j}} x_{p,q,k}\\]\nAverage Pooling\nCalculates the arithmetic mean. Generally, Max Pooling performs better for identifying dominant features (edges, textures)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#activation-functions",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#activation-functions",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Activation Functions",
    "text": "Activation Functions\nLinear convolution is insufficient for approximating non-linear functions.\nReLU (Rectified Linear Unit): \\[f(x) = \\max(0, x)\\]\n\nSparsity: Activations \\(&lt; 0\\) are zeroed out.\nGradient Propagation: Mitigates vanishing gradient problem compared to Sigmoid/Tanh.\n\nVariants: Leaky ReLU, ELU, GELU (Gaussian Error Linear Unit)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#architecture-overview",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#architecture-overview",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Architecture Overview",
    "text": "Architecture Overview\nA typical CNN architecture follows a hierarchical pattern:\n\nFeature Extraction Block:\n\n[Conv \\(\\rightarrow\\) ReLU \\(\\rightarrow\\) Pooling] \\(\\times N\\)\n\nClassification Head:\n\nFlattening\nFully Connected Layers (Dense)\nSoftmax (for multi-class classification)\n\n\n\\[P(y=j | \\mathbf{x}) = \\frac{e^{\\mathbf{w}_j^T \\mathbf{h} + b_j}}{\\sum_{k=1}^K e^{\\mathbf{w}_k^T \\mathbf{h} + b_k}}\\]"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#backpropagation-in-cnns",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#backpropagation-in-cnns",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Backpropagation in CNNs",
    "text": "Backpropagation in CNNs\nTraining requires computing gradients w.r.t weights \\(W\\) using the Chain Rule.\nFor a convolution layer \\(l\\): \\[\\frac{\\partial L}{\\partial W^{(l)}} = \\frac{\\partial L}{\\partial \\text{out}^{(l)}} * \\text{in}^{(l)}\\]\nWhere the gradient is computed via convolution between the incoming error signal and the input activations from the previous layer."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#implementation-pytorch-snippet",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#implementation-pytorch-snippet",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Implementation: PyTorch Snippet",
    "text": "Implementation: PyTorch Snippet\n\nimport torch\nimport torch.nn as nn\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        # Feature Extraction\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)\n        )\n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 7 * 7, 128), # Assuming 28x28 input\n            nn.ReLU(),\n            nn.Linear(128, 10)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#por-qué-rnns",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#por-qué-rnns",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "¿Por qué RNNs?",
    "text": "¿Por qué RNNs?\nLas redes neuronales tradicionales (MLP, CNN) asumen que las entradas y salidas son independientes.\n\nEl problema: ¿Cómo procesamos datos donde el orden importa?\n\n\nTraducción de idiomas (La gramática depende del contexto previo).\nAudio y Voz (La onda sonora es continua).\nSeries de Tiempo (El valor de hoy depende de ayer).\nGenómica (Secuencias de ADN)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#la-celda-recurrente-rnn-cell",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#la-celda-recurrente-rnn-cell",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "La Celda Recurrente (RNN Cell)",
    "text": "La Celda Recurrente (RNN Cell)\nLa diferencia fundamental es la memoria. La RNN procesa la entrada actual (\\(x_t\\)) considerando el estado anterior (\\(a_{t-1}\\)).\n\n\nFigura 1"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#formulación-matemática",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#formulación-matemática",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Formulación Matemática",
    "text": "Formulación Matemática\n\n\\[\n% Definición de colores semánticos (Modelo HTML para compatibilidad)\n\\newcommand{\\cState}[1]{\\color[HTML]{D35400}{#1}}\n\\newcommand{\\cWeight}[1]{\\color[HTML]{C0392B}{#1}}\n\\newcommand{\\cInput}[1]{\\color[HTML]{00796B}{#1}}\n\\]\n\nAnalicemos las ecuaciones clave utilizando el código de color:\n\\[\na_t = g_1(W_{aa}a_{t-1} + W_{ax}x_t + b_a)\n\\]\n\\[\n\\hat{y}_t = g_2(W_{ya}a_t + b_y)\n\\]\n\n\n\n\n\n\nNota\n\n\n\n\\(\\textcolor{#D35400}{a_t}\\): Estado oculto (Hidden State). Es la “memoria” del paso \\(t\\).\n\\(\\textcolor{#C0392B}{W_{ax}, W_{aa}, W_{ya}}\\): Pesos compartidos. Son los mismos para cada paso de tiempo.\n\\(g_1\\): Usualmente tanh o ReLU.\n\\(g_2\\): Usualmente Softmax (clasificación) o Lineal (regresión)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#desenrollando-en-el-tiempo-unrolling",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#desenrollando-en-el-tiempo-unrolling",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Desenrollando en el Tiempo (Unrolling)",
    "text": "Desenrollando en el Tiempo (Unrolling)\nUna RNN es simplemente la misma celda ejecutada múltiples veces. \\(a_t\\) pasa información de un paso al siguiente.\n\n\nFigura 2"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#arquitecturas-flexibles",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#arquitecturas-flexibles",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Arquitecturas Flexibles",
    "text": "Arquitecturas Flexibles\nLas RNN permiten procesar secuencias de longitudes variables en diferentes configuraciones.\n\n\n\nTipos:\n\n\n\nMany-to-Many (\\(T_x = T_y\\)): Clasificación de entidades nombradas (NER), Generación de texto.\nMany-to-One: Análisis de sentimiento, Clasificación de actividad.\nOne-to-Many: Generación de música, Captioning de imágenes (Input = Imagen CNN).\nMany-to-Many (\\(T_x \\neq T_y\\)): Traducción automática (Encoder-Decoder)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#retropropagación-en-el-tiempo-bptt",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#retropropagación-en-el-tiempo-bptt",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Retropropagación en el Tiempo (BPTT)",
    "text": "Retropropagación en el Tiempo (BPTT)\nPara entrenar, calculamos el gradiente de la pérdida \\(L\\) respecto a los parámetros \\(W\\).\n\\[ \\frac{\\partial L}{\\partial W} = \\sum_{t} \\frac{\\partial L_t}{\\partial W} \\]\n\n\n\n\n\n\n\nEl Reto del Gradiente\n\n\nAl multiplicar gradientes muchas veces (por la regla de la cadena a través del tiempo), estos pueden:\n\nDesvanecerse (Vanishing): La red olvida el pasado lejano. (Solución: LSTM/GRU).\nExplotar (Exploding): El entrenamiento diverge. (Solución: Gradient Clipping)."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#resumen-visual",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#resumen-visual",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Resumen Visual",
    "text": "Resumen Visual\n\n\n\nFigura 3\nConclusión: Las RNNs unifican el aprendizaje sobre datos secuenciales aprendiendo parámetros (\\(W\\)) que se comparten a través del tiempo."
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#basic-concepts",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#basic-concepts",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Basic Concepts",
    "text": "Basic Concepts\n\n\n\nFigura 4"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#basic-concepts-1",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#basic-concepts-1",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Basic Concepts",
    "text": "Basic Concepts\n\n\n\n\n\n\n\nGeneral Schema\n\n\nLet’s make a general structure of the problem\n\n\n\n\n\n\n\nFigura 5"
  },
  {
    "objectID": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#basic-concepts-2",
    "href": "presentaciones/ASIM/v2Lect004_CNN_LSTM.html#basic-concepts-2",
    "title": "Redes Neuronales Convolucionales & Redes Recurrentes",
    "section": "Basic Concepts",
    "text": "Basic Concepts\n\n\n\n\nFigura 6"
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html",
    "href": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html",
    "title": "Importar datos",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nprint(\"CWD =\", Path.cwd())\ndata_path = \"./data\""
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#metadatos",
    "href": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#metadatos",
    "title": "Importar datos",
    "section": "Metadatos",
    "text": "Metadatos\n\nEntradas (X):\n\nEMG_Quad_RMS_mV (mV): RMS EMG cuádriceps.\nEMG_Ham_RMS_mV (mV): RMS EMG isquiotibiales.\nGRF_Vert_Norm_BW (BW): Fuerza de reacción vertical (normalizada).\nOmega_Shank_deg_s (deg/s): Velocidad angular de la pierna (IMU).\nHip_Flex_deg (deg): Flexión de cadera.\n\n\n\nObjetivos (y):\n\nKnee_Flex_deg (deg): Ángulo de flexión de rodilla (regresión).\nRisk_Lesion (0/1): Riesgo alto de lesión (clasificación)."
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#información-inicial",
    "href": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#información-inicial",
    "title": "Importar datos",
    "section": "1. Información Inicial",
    "text": "1. Información Inicial\n\nIdentificar tipo de variable: numérica, categórica, ordinal, binaria.\nEstablecer unidad de análisis (por sujeto o por medición).\nDocumentar el diccionario de variables."
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#calidad-de-los-datos",
    "href": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#calidad-de-los-datos",
    "title": "Importar datos",
    "section": "2. Calidad de los datos",
    "text": "2. Calidad de los datos\n\nValores faltantes: porcentaje, patrón y manejo (eliminación, imputación o modelado).\nCardinalidad irregular: detectar columnas con un solo valor o codificación errónea.\nOutliers: aplicar criterio de Tukey o z-score (&gt;3σ).\n-Validez contextual: verificar rangos fisiológicos (e.g., knee_flex_deg ∈ [0,180])."
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#análisis-univariado",
    "href": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#análisis-univariado",
    "title": "Importar datos",
    "section": "3. Análisis univariado",
    "text": "3. Análisis univariado\n\nVariables numéricas: histograma, densidad, simetría, curtosis.\nVariables categóricas: frecuencia y proporciones.\nObjetivo de regresión: distribución y normalidad de knee_flex_deg.\nObjetivo de clasificación: balance de clases en Risk_Lesion.\nIndicadores sugeridos\n\nAsimetría (skew), curtosis (kurt).\nTest de normalidad: Shapiro–Wilk o Kolmogorov–Smirnov.\nDetección de colas largas"
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#análisis-bivariado",
    "href": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#análisis-bivariado",
    "title": "Importar datos",
    "section": "4. Análisis bivariado",
    "text": "4. Análisis bivariado\n\n4.1 Regresión (knee_flex_deg)\n\nCorrelaciones (Pearson/Spearman) entre knee_flex_deg y las variables predictoras.\nDispersión y relación lineal/no lineal.\nPosibles transformaciones (log, sqrt, normalización z-score).\n\n\n\n4.2 Clasificación (Risk_Lesion)\n\nComparación de medias por grupo (t-test o ANOVA).\nVisualización de separación de clases: sns.pairplot(hue=‘Risk_Lesion’).\nMatriz de correlación de variables relevantes para discriminación."
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#análisis-multivariado",
    "href": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#análisis-multivariado",
    "title": "Importar datos",
    "section": "5. Análisis multivariado",
    "text": "5. Análisis multivariado\n\nReducción de dimensionalidad: PCA, t-SNE, o UMAP (para inspección visual).\nEvaluación de colinealidad: VIF &gt; 5 sugiere eliminar variables redundantes.\nMapeo estructural: identificar clústeres naturales y relaciones no lineales."
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#preparación-del-abt-analytical-base-table",
    "href": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#preparación-del-abt-analytical-base-table",
    "title": "Importar datos",
    "section": "6. Preparación del ABT (Analytical Base Table)",
    "text": "6. Preparación del ABT (Analytical Base Table)\n\nEliminar variables con &gt;60% de valores nulos.\nCodificar variables categóricas (one-hot o label encoding).\nEscalar numéricas (StandardScaler o MinMaxScaler).\nDividir entre train / test sin fuga de información."
  },
  {
    "objectID": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#eda-orientado-al-modelado",
    "href": "presentaciones/ASIM/Cod001_GradientDescent_Clase.html#eda-orientado-al-modelado",
    "title": "Importar datos",
    "section": "7. EDA orientado al modelado",
    "text": "7. EDA orientado al modelado\n\nPara regresión: identificar relaciones no lineales → explorar transformaciones de knee_flex_deg.\nPara clasificación: verificar separabilidad y métricas de desequilibrio (balanced_accuracy, AUC)."
  },
  {
    "objectID": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html",
    "href": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html",
    "title": "Guía metodológica de cálculo de variables (Biomecánica) — Injury_Risk",
    "section": "",
    "text": "Knee_Flex_deg (deg): Ángulo de flexión de rodilla (variable objetivo).\nEMG_Quad_RMS_mV (mV): RMS del EMG del cuádriceps (rectificado y promediado).\nEMG_Ham_RMS_mV (mV): RMS del EMG de isquiotibiales.\nGRF_Vert_Norm_BW (BW): Componente vertical de la fuerza de reacción del suelo, normalizada por peso corporal.\nOmega_Shank_deg_s (deg/s): Velocidad angular del segmento pierna (shank) medida/estimada con IMU.\nHip_Flex_deg (deg): Ángulo de flexión de cadera.\n\n\n\n\n\nNota: El CSV ofrece valores ya procesados. A continuación se describe cómo se obtendrían a partir de señales crudas estándar.\n\n\n\nEntradas crudas: EMG diferencial (µV) por canal (cuádriceps / isquiotibiales).\nSalida: RMS en mV de ventana deslizante.\n\nFiltrado pasa-banda (artefactos de movimiento y línea):\n\nTípico: 20–450 Hz (Butterworth 4º orden, bidireccional).\n\nNotch (si hay ruido de red): 50/60 Hz (y armónicos si procede).\nRectificación: valor absoluto, \\(x_r(t) = |x(t)|\\).\nRMS por ventana de \\(N\\) muestras (p.ej., 100 ms):\n\\[x*{\\mathrm{RMS}}[k] \\,=\\, \\sqrt{\\frac{1}{N} \\sum*{i=0}^{N-1} x_r^2[k-i]} \\]\nConversión de unidades a mV (si procede) y normalización opcional (p.ej., a MVC).\n\nObservaciones didácticas:\n\nLa RMS reduce sensibilidad a fase y captura “energía” muscular.\nElegir ventana (50–250 ms) equilibra suavizado vs. latencia.\nDocumentar MVC, electrodos, piel, tasa de muestreo y filtros.\n\n\n\n\nEntradas crudas: fuerza vertical de plataforma (N), masa corporal \\(m\\).\nSalida: GRF vertical normalizada por peso (BW).\n\nFuerza vertical cruda \\(F_z(t)\\) (ya calibrada).\nFiltrado pasa-bajo (p.ej., 20–50 Hz, Butterworth 4º orden, bidireccional) para reducir ruido.\nNormalización a BW:\n\\[\\mathrm{GRF_Vert_Norm_BW}(t) \\,=\\, \\frac{F_z(t)}{m\\,g}\\]\ndonde \\(g = 9.81\\,\\mathrm{m/s^2}\\).\n\nObservaciones:\n\nPermite comparar individuos con distinta masa.\nRevisar offset (fuerza en quietud ≈ 1 BW de pie).\nEn gestos de impacto usar cortes de fase (contacto/no contacto) por umbral.\n\n\n\n\nEntradas crudas: giroscopio de IMU en la pierna (rad/s), orientación del sensor.\nSalida: velocidad angular en deg/s respecto al eje relevante (flexo-extensión).\n\nSelección de eje (p.ej., eje mediolateral para flexión sagital).\nCorrección de deriva/bias del giroscopio (estimado en reposo).\nFiltrado pasa-bajo (5–20 Hz) si se requiere suavizado.\nConversión a deg/s: \\(\\omega*{deg/s} = \\omega*{rad/s} \\times 180/\\pi\\).\n\nObservaciones:\n\nPara ángulo se integraría \\(\\omega\\) con fusión sensorial (Madgwick/Kalman) para limitar deriva.\nCuidar alineación sensor-segmento (matriz de rotación/calibración funcional).\n\n\n\n\nEntradas crudas: cinemática 3D (sistema óptico o IMU fusionadas).\nSalida: ángulo de flexión en grados.\n\nDefinir marcos anatómicos (ISB) para pelvis, muslo y pierna.\nCalcular orientación segmentaria (cuaterniones/matrices).\nÁngulo relativo en plano sagital:\n\nCadera: muslo vs. pelvis.\nRodilla: pierna vs. muslo.\n\nExtracción del componente sagital (flexo-extensión) y conversión a grados.\n\nObservaciones:\n\nCon IMUs, usar métodos de fusión (Madgwick/Kalman).\nCon mocap, aplicar filtros (6–12 Hz) a marcadores y IK.\nReportar convención de signos y rango fisiológico.\n\n\n\n\n\n\nLa variable Knee_Flex_deg del CSV fue simulada con la siguiente relación no lineal (\\(a\\) = ángulo de rodilla), recortada a \\([-5, 140]\\,deg\\), con ruido mixto gaussiano + t de Student:\n$$\n\\[\\begin{aligned}\na \\,=&\\; 15\n\n- 25\\,\\sigma\\!\\big(1.6\\,(\\mathrm{GRF}-0.6)\\big)\n- 0.06\\,\\operatorname{sign}(\\omega)\\,|\\omega|^{1.2}\n- 0.55\\,\\mathrm{Hip} + 9\\,\\sin(\\mathrm{Hip}^\\circ) \\\\\n  &- 10\\,\\frac{\\mathrm{EMG}_{ham}}{\\mathrm{EMG}_{quad}+0.05}\n- 6\\,\\mathrm{EMG}\\_{quad}\\,\\mathrm{GRF}\n\n* 40\\,(\\mathrm{EMG}\\_{quad}-0.12)^2\n\n- 8\\,\\mathrm{GRF}\\,\\sin(\\mathrm{Hip}^\\circ)\n- \\varepsilon\n  \\end{aligned}\\]\n$$\ndonde \\(\\sigma(x)=1/(1+e^{-x})\\) y \\(\\omega=\\Omega\\_\\mathrm{Shank}\\). Propósito didáctico: mostrar cómo interacciones (p.ej., EMG×GRF) y no linealidades afectan una salida biomecánica.\n\n\n\n\nSincronización: alinear plataformas de fuerza, IMUs y mocap (pulsos TTL o cross-correlation).\nResampleo: llevar todas las series a una misma tasa (interpolación/anti-aliasing).\nFiltros: documentar orden, frecuencias de corte y método (cero-fase).\nAnotación de fases: contacto/no-contacto a partir de GRF (umbral p.ej., 20 N) o cinemática.\nOutliers: inspección visual + z-score/IQR.\nUnidades: verificar SI y consistencia (deg, deg/s, mV, BW).\nNormalizaciones: a BW (fuerzas) y a MVC (EMG) si se comparan sujetos.\n\n\n\n\n\nSuponga señales crudas emg_quad, emg_ham (V), fz (N), gyro (rad/s), y orientaciones segmentarias ya estimadas.\n\nimport numpy as np\nfrom scipy.signal import butter, filtfilt\n\ndef bandpass(sig, fs, f1=20, f2=450, order=4):\n    b, a = butter(order, [f1/(fs/2), f2/(fs/2)], btype='band')\n    return filtfilt(b, a, sig)\n\ndef rms_window(x, fs, win_ms=100):\n    N = int(win_ms*fs/1000)\n    N = max(N, 1)\n    # Convolución eficiente de x^2 con ventana uniforme\n    power = np.convolve(x**2, np.ones(N)/N, mode='same')\n    return np.sqrt(np.maximum(power, 0))\n\n# EMG → RMS (mV)\nfs_emg = 1000\nemg_bp = bandpass(emg_quad, fs_emg, 20, 450)\nemg_rect = np.abs(emg_bp)\nemg_quad_rms_mV = rms_window(emg_rect, fs_emg, 100) * 1e3\n\n# GRF → normalizada por BW\nm = 70.0  # kg\ng = 9.81\nfs_f = 1000\nfz_filt = filtfilt(*butter(4, 50/(fs_f/2), btype='low'), fz)\ngrf_vert_norm_bw = fz_filt / (m*g)\n\n# Gyro → deg/s\nomega_deg_s = gyro * 180/np.pi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nKnee_Flex_deg\n1000\n36.6432\n36.988\n-5\n-1.6713\n30.6706\n64.7409\n129.671\n\n\nEMG_Quad_RMS_mV\n1000\n0.1328\n0.0672\n0.0211\n0.0743\n0.1343\n0.1912\n0.2499\n\n\nEMG_Ham_RMS_mV\n1000\n0.1063\n0.0555\n0.0106\n0.0558\n0.1086\n0.1545\n0.1999\n\n\nGRF_Vert_Norm_BW\n1000\n0.6531\n0.3779\n0\n0.3398\n0.6508\n0.9868\n1.2972\n\n\nOmega_Shank_deg_s\n1000\n-7.7\n229.191\n-399.477\n-206.479\n-12.5766\n190.033\n399.646\n\n\nHip_Flex_deg\n1000\n14.7053\n14.3405\n-9.9985\n2.2487\n14.7299\n26.9997\n39.8875\n\n\n\n\n\n\n\nEste dataset es sintético y no reemplaza mediciones clínicas.\nLas fórmulas de cálculo son estándares en biomecánica, pero los parámetros (ventanas/filtros) deben ajustarse a cada laboratorio y tarea.\nLa interpretación de EMG depende de colocación de electrodos, crosstalk y normalización (MVC)."
  },
  {
    "objectID": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#diccionario-de-datos-recordatorio",
    "href": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#diccionario-de-datos-recordatorio",
    "title": "Guía metodológica de cálculo de variables (Biomecánica) — Injury_Risk",
    "section": "",
    "text": "Knee_Flex_deg (deg): Ángulo de flexión de rodilla (variable objetivo).\nEMG_Quad_RMS_mV (mV): RMS del EMG del cuádriceps (rectificado y promediado).\nEMG_Ham_RMS_mV (mV): RMS del EMG de isquiotibiales.\nGRF_Vert_Norm_BW (BW): Componente vertical de la fuerza de reacción del suelo, normalizada por peso corporal.\nOmega_Shank_deg_s (deg/s): Velocidad angular del segmento pierna (shank) medida/estimada con IMU.\nHip_Flex_deg (deg): Ángulo de flexión de cadera."
  },
  {
    "objectID": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#cómo-se-calcula-cada-variable-en-un-pipeline-real",
    "href": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#cómo-se-calcula-cada-variable-en-un-pipeline-real",
    "title": "Guía metodológica de cálculo de variables (Biomecánica) — Injury_Risk",
    "section": "",
    "text": "Nota: El CSV ofrece valores ya procesados. A continuación se describe cómo se obtendrían a partir de señales crudas estándar.\n\n\n\nEntradas crudas: EMG diferencial (µV) por canal (cuádriceps / isquiotibiales).\nSalida: RMS en mV de ventana deslizante.\n\nFiltrado pasa-banda (artefactos de movimiento y línea):\n\nTípico: 20–450 Hz (Butterworth 4º orden, bidireccional).\n\nNotch (si hay ruido de red): 50/60 Hz (y armónicos si procede).\nRectificación: valor absoluto, \\(x_r(t) = |x(t)|\\).\nRMS por ventana de \\(N\\) muestras (p.ej., 100 ms):\n\\[x*{\\mathrm{RMS}}[k] \\,=\\, \\sqrt{\\frac{1}{N} \\sum*{i=0}^{N-1} x_r^2[k-i]} \\]\nConversión de unidades a mV (si procede) y normalización opcional (p.ej., a MVC).\n\nObservaciones didácticas:\n\nLa RMS reduce sensibilidad a fase y captura “energía” muscular.\nElegir ventana (50–250 ms) equilibra suavizado vs. latencia.\nDocumentar MVC, electrodos, piel, tasa de muestreo y filtros.\n\n\n\n\nEntradas crudas: fuerza vertical de plataforma (N), masa corporal \\(m\\).\nSalida: GRF vertical normalizada por peso (BW).\n\nFuerza vertical cruda \\(F_z(t)\\) (ya calibrada).\nFiltrado pasa-bajo (p.ej., 20–50 Hz, Butterworth 4º orden, bidireccional) para reducir ruido.\nNormalización a BW:\n\\[\\mathrm{GRF_Vert_Norm_BW}(t) \\,=\\, \\frac{F_z(t)}{m\\,g}\\]\ndonde \\(g = 9.81\\,\\mathrm{m/s^2}\\).\n\nObservaciones:\n\nPermite comparar individuos con distinta masa.\nRevisar offset (fuerza en quietud ≈ 1 BW de pie).\nEn gestos de impacto usar cortes de fase (contacto/no contacto) por umbral.\n\n\n\n\nEntradas crudas: giroscopio de IMU en la pierna (rad/s), orientación del sensor.\nSalida: velocidad angular en deg/s respecto al eje relevante (flexo-extensión).\n\nSelección de eje (p.ej., eje mediolateral para flexión sagital).\nCorrección de deriva/bias del giroscopio (estimado en reposo).\nFiltrado pasa-bajo (5–20 Hz) si se requiere suavizado.\nConversión a deg/s: \\(\\omega*{deg/s} = \\omega*{rad/s} \\times 180/\\pi\\).\n\nObservaciones:\n\nPara ángulo se integraría \\(\\omega\\) con fusión sensorial (Madgwick/Kalman) para limitar deriva.\nCuidar alineación sensor-segmento (matriz de rotación/calibración funcional).\n\n\n\n\nEntradas crudas: cinemática 3D (sistema óptico o IMU fusionadas).\nSalida: ángulo de flexión en grados.\n\nDefinir marcos anatómicos (ISB) para pelvis, muslo y pierna.\nCalcular orientación segmentaria (cuaterniones/matrices).\nÁngulo relativo en plano sagital:\n\nCadera: muslo vs. pelvis.\nRodilla: pierna vs. muslo.\n\nExtracción del componente sagital (flexo-extensión) y conversión a grados.\n\nObservaciones:\n\nCon IMUs, usar métodos de fusión (Madgwick/Kalman).\nCon mocap, aplicar filtros (6–12 Hz) a marcadores y IK.\nReportar convención de signos y rango fisiológico."
  },
  {
    "objectID": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#función-generativa-dataset-sintético",
    "href": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#función-generativa-dataset-sintético",
    "title": "Guía metodológica de cálculo de variables (Biomecánica) — Injury_Risk",
    "section": "",
    "text": "La variable Knee_Flex_deg del CSV fue simulada con la siguiente relación no lineal (\\(a\\) = ángulo de rodilla), recortada a \\([-5, 140]\\,deg\\), con ruido mixto gaussiano + t de Student:\n$$\n\\[\\begin{aligned}\na \\,=&\\; 15\n\n- 25\\,\\sigma\\!\\big(1.6\\,(\\mathrm{GRF}-0.6)\\big)\n- 0.06\\,\\operatorname{sign}(\\omega)\\,|\\omega|^{1.2}\n- 0.55\\,\\mathrm{Hip} + 9\\,\\sin(\\mathrm{Hip}^\\circ) \\\\\n  &- 10\\,\\frac{\\mathrm{EMG}_{ham}}{\\mathrm{EMG}_{quad}+0.05}\n- 6\\,\\mathrm{EMG}\\_{quad}\\,\\mathrm{GRF}\n\n* 40\\,(\\mathrm{EMG}\\_{quad}-0.12)^2\n\n- 8\\,\\mathrm{GRF}\\,\\sin(\\mathrm{Hip}^\\circ)\n- \\varepsilon\n  \\end{aligned}\\]\n$$\ndonde \\(\\sigma(x)=1/(1+e^{-x})\\) y \\(\\omega=\\Omega\\_\\mathrm{Shank}\\). Propósito didáctico: mostrar cómo interacciones (p.ej., EMG×GRF) y no linealidades afectan una salida biomecánica."
  },
  {
    "objectID": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#preprocesamiento-sincronización-y-control-de-calidad-qc",
    "href": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#preprocesamiento-sincronización-y-control-de-calidad-qc",
    "title": "Guía metodológica de cálculo de variables (Biomecánica) — Injury_Risk",
    "section": "",
    "text": "Sincronización: alinear plataformas de fuerza, IMUs y mocap (pulsos TTL o cross-correlation).\nResampleo: llevar todas las series a una misma tasa (interpolación/anti-aliasing).\nFiltros: documentar orden, frecuencias de corte y método (cero-fase).\nAnotación de fases: contacto/no-contacto a partir de GRF (umbral p.ej., 20 N) o cinemática.\nOutliers: inspección visual + z-score/IQR.\nUnidades: verificar SI y consistencia (deg, deg/s, mV, BW).\nNormalizaciones: a BW (fuerzas) y a MVC (EMG) si se comparan sujetos."
  },
  {
    "objectID": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#cómo-replicar-mini-ejemplos-en-python",
    "href": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#cómo-replicar-mini-ejemplos-en-python",
    "title": "Guía metodológica de cálculo de variables (Biomecánica) — Injury_Risk",
    "section": "",
    "text": "Suponga señales crudas emg_quad, emg_ham (V), fz (N), gyro (rad/s), y orientaciones segmentarias ya estimadas.\n\nimport numpy as np\nfrom scipy.signal import butter, filtfilt\n\ndef bandpass(sig, fs, f1=20, f2=450, order=4):\n    b, a = butter(order, [f1/(fs/2), f2/(fs/2)], btype='band')\n    return filtfilt(b, a, sig)\n\ndef rms_window(x, fs, win_ms=100):\n    N = int(win_ms*fs/1000)\n    N = max(N, 1)\n    # Convolución eficiente de x^2 con ventana uniforme\n    power = np.convolve(x**2, np.ones(N)/N, mode='same')\n    return np.sqrt(np.maximum(power, 0))\n\n# EMG → RMS (mV)\nfs_emg = 1000\nemg_bp = bandpass(emg_quad, fs_emg, 20, 450)\nemg_rect = np.abs(emg_bp)\nemg_quad_rms_mV = rms_window(emg_rect, fs_emg, 100) * 1e3\n\n# GRF → normalizada por BW\nm = 70.0  # kg\ng = 9.81\nfs_f = 1000\nfz_filt = filtfilt(*butter(4, 50/(fs_f/2), btype='low'), fz)\ngrf_vert_norm_bw = fz_filt / (m*g)\n\n# Gyro → deg/s\nomega_deg_s = gyro * 180/np.pi"
  },
  {
    "objectID": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#estadísticos-descriptivos-del-csv",
    "href": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#estadísticos-descriptivos-del-csv",
    "title": "Guía metodológica de cálculo de variables (Biomecánica) — Injury_Risk",
    "section": "",
    "text": "Variable\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nKnee_Flex_deg\n1000\n36.6432\n36.988\n-5\n-1.6713\n30.6706\n64.7409\n129.671\n\n\nEMG_Quad_RMS_mV\n1000\n0.1328\n0.0672\n0.0211\n0.0743\n0.1343\n0.1912\n0.2499\n\n\nEMG_Ham_RMS_mV\n1000\n0.1063\n0.0555\n0.0106\n0.0558\n0.1086\n0.1545\n0.1999\n\n\nGRF_Vert_Norm_BW\n1000\n0.6531\n0.3779\n0\n0.3398\n0.6508\n0.9868\n1.2972\n\n\nOmega_Shank_deg_s\n1000\n-7.7\n229.191\n-399.477\n-206.479\n-12.5766\n190.033\n399.646\n\n\nHip_Flex_deg\n1000\n14.7053\n14.3405\n-9.9985\n2.2487\n14.7299\n26.9997\n39.8875"
  },
  {
    "objectID": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#supuestos-y-limitaciones",
    "href": "presentaciones/ASIM/data/Injury_Risk/Injury_Risk.html#supuestos-y-limitaciones",
    "title": "Guía metodológica de cálculo de variables (Biomecánica) — Injury_Risk",
    "section": "",
    "text": "Este dataset es sintético y no reemplaza mediciones clínicas.\nLas fórmulas de cálculo son estándares en biomecánica, pero los parámetros (ventanas/filtros) deben ajustarse a cada laboratorio y tarea.\nLa interpretación de EMG depende de colocación de electrodos, crosstalk y normalización (MVC)."
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "El Profesor",
    "text": "El Profesor\n\n\nEducación\nDoctor en Ciencias de la Electrónica. Magister en Ingeniería Electrónica y Telecomunicaciones Ingeniero en Electrónica y Telecomunicaciones\nIntereses\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\nDesempeño\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\nContacto:\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Contenido del curso",
    "text": "Contenido del curso\n\n\n\n\n\nIntroducción a inteligencia artificial en el borde (EDGE AI).\nHardware y software para EDGE AI.\nEl flujo de trabajo de EDGE AI.\nDiseño, desarrollo y evaluación de sistemas EDGE AI."
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Estrategías de Aprendizaje",
    "text": "Estrategías de Aprendizaje\n\nClases magistrales\nDesarrollo de ejercicios en clase\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluación",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\nLaboratorios (60%)\nProyecto Final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluación-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (30%)\nLaboratorios (30%)\nProyecto final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Recursos",
    "text": "Recursos\n\n\nClases\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201.\n\nInterpretes: R y python.\nOS: Linux\nLenguajes: C/C++\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#bibliografía",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bibliografía",
    "text": "Bibliografía\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980.\n[42] D. Situnayake y J. Plunkett, AI at the Edge: solving real-world problems with embedded machine learning. Sebastopol: O’Reilly, 2023.\n[43] X. Wang, Y. Han, V. C. M. Leung, D. Niyato, X. Yan, y X. Chen, Edge AI: Convergence of Edge Computing and Artificial Intelligence. Singapore: Springer Singapore, 2020. doi: 10.1007/978-981-15-6186-3.\n[44] A. Koul, S. Ganju, y M. Kasam, «Practical Deep Learning for Cloud, Mobile, and Edge».\n[45] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[46] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[47] V. Subramanian, Deep learning with PyTorch: a practical approach to building neural network models using PyTorch. Birmingham, UK: Packt Publishing, 2018.\n[48] Diagnostic Biomedical Signal and Image Processing Applications with Deep Learning Methods. Elsevier, 2023. doi: 10.1016/C2021-0-02190-8.\n[49] J. D. Kelleher, B. Mac Namee, y A. D’Arcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed. Cambridge: The MIT press, 2020.\n[50] A. A. Patel, «Hands-On Unsupervised Learning Using Python».\n[51] P. Raj, P. B. Soundarabai, y P. Augustine, Machine Intelligence: Computer Vision and Natural Language Processing, 1.ª ed. Boca Raton: Auerbach Publications, 2023. doi: 10.1201/9781003424550.\n[52] M. Roy y L. R. Gupta, Eds., Machine Learning and Data Analytics for Predicting, Managing, and Monitoring Disease: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2021. doi: 10.4018/978-1-7998-7188-0.\n[53] A. R. Jha, Mastering PyTorch: create and deploy deep learning models from CNNs to multimodal models, LLMs, and beyond, Second edition. en Expert insight. Birmingham: Packt Publishing Limited, 2024.\n[54] V. K. Ayyadevara y Y. Reddy, Modern computer vision with PyTorch: a practical roadmap from deep learning fundamentals to advanced applications and Generative AI, Second edition. Birmingham, UK: Packt Publishing Ltd., 2024.\n[55] E. Priya y V. Rajinikanth, Eds., Signal and Image Processing Techniques for the Development of Intelligent Healthcare Systems. Singapore: Springer Singapore, 2021. doi: 10.1007/978-981-15-6141-2.\n[56] M. M. Richter, S. Paul, V. Këpuska, y M. Silaghi, Signal Processing and Machine Learning with Applications. Cham: Springer International Publishing, 2022. doi: 10.1007/978-3-319-45372-9."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nMachine Learning (ML) is a data-driven approach to building predictive models.\nIt is used in various applications such as healthcare, finance, and automation.\nIt is based on identifying patterns in data to make predictions or decisions."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nML enables systems to learn from experience without being explicitly programmed.\nKey application areas include image recognition, natural language processing, and autonomous systems."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Supervised Learning",
    "text": "Types of Machine Learning – Supervised Learning\nSupervised Learning: - Uses labeled data to train models. - Example: Spam detection in emails (spam vs. non-spam). - Common algorithms: Linear Regression, Decision Trees, Support Vector Machines (SVM), Neural Networks."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Unsupervised Learnin",
    "text": "Types of Machine Learning – Unsupervised Learnin\nUnsupervised Learning: - Finds patterns in unlabeled data. - Example: Customer segmentation in marketing. - Common algorithms: K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Reinforcement Learning",
    "text": "Types of Machine Learning – Reinforcement Learning\nReinforcement Learning: - Optimizes decision-making through rewards. - Example: Training an AI to play a game like Chess or Go. - Key components: Agent, Environment, Reward Signal."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nData:\n\nThe quality and quantity of data are fundamental.\nData preprocessing (cleaning, normalization, feature extraction) is crucial.\n\nModel:\n\nA mathematical representation of the problem.\nChosen based on the problem type (classification, regression, clustering)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nError function:\n\nEvaluates the difference between prediction and actual value.\nExample: Mean Squared Error (MSE) for regression, Cross-Entropy Loss for classification.\n\nOptimization:\n\nAlgorithms that adjust the model parameters to minimize error.\nCommon optimization techniques: Gradient Descent, Adam Optimizer."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nInductive Bias:\n\nPrior assumptions that the model uses to generalize.\nExample: Linear models assume data relationships are linear.\n\nSample Bias:\n\nDifferences between training data and real-world data.\nExample: A face recognition system trained on a specific demographic may perform poorly on others."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nBias-Variance Tradeoff:\n\nHigh Bias (Underfitting): The model is too simple, failing to capture patterns.\nHigh Variance (Overfitting): The model memorizes training data but fails on new data."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Example of Bias and Variance",
    "text": "Example of Bias and Variance"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n1. Linear Regression (Supervised Learning - Regression)\n\nPredicts a continuous value based on input features.\nEquation: ( y = mx + b )\nExample: Predicting house prices based on square footage.\n\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\n\n\n\n\n\nfit_intercept fit_intercept: bool, default=True\n\nWhether to calculate the intercept for this model. If set\nto False, no intercept will be used in calculations\n(i.e. data is expected to be centered).\nTrue\n\n\n\ncopy_X copy_X: bool, default=True\n\nIf True, X will be copied; else, it may be overwritten.\nTrue\n\n\n\ntol tol: float, default=1e-6\n\nThe precision of the solution (`coef_`) is determined by `tol` which\nspecifies a different convergence criterion for the `lsqr` solver.\n`tol` is set as `atol` and `btol` of :func:`scipy.sparse.linalg.lsqr` when\nfitting on sparse training data. This parameter has no effect when fitting\non dense data.\n\n.. versionadded:: 1.7\n1e-06\n\n\n\nn_jobs n_jobs: int, default=None\n\nThe number of jobs to use for the computation. This will only provide\nspeedup in case of sufficiently large problems, that is if firstly\n`n_targets &gt; 1` and secondly `X` is sparse or if `positive` is set\nto `True`. ``None`` means 1 unless in a\n:obj:`joblib.parallel_backend` context. ``-1`` means using all\nprocessors. See :term:`Glossary ` for more details.\nNone\n\n\n\npositive positive: bool, default=False\n\nWhen set to ``True``, forces the coefficients to be positive. This\noption is only supported for dense arrays.\n\nFor a comparison between a linear regression model with positive constraints\non the regression coefficients and a linear regression without such constraints,\nsee :ref:`sphx_glr_auto_examples_linear_model_plot_nnls.py`.\n\n.. versionadded:: 0.24\nFalse\n\n\n\n\n            \n        \n    \n\n\nSlope: [0.6]\n\n\nIntercept: 2.2"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n2. Decision Trees (Supervised Learning - Classification & Regression)\n\nSplits data into decision nodes to make predictions.\nExample: Diagnosing a disease based on symptoms.\n\n\n\nDecisionTreeClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFitted\n        \n            \n                Parameters\n                \n\n\n\n\n\n\n\n\n\ncriterion criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n\nThe function to measure the quality of a split. Supported criteria are\n\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\nShannon information gain, see :ref:`tree_mathematical_formulation`.\n'gini'\n\n\n\nsplitter splitter: {\"best\", \"random\"}, default=\"best\"\n\nThe strategy used to choose the split at each node. Supported\nstrategies are \"best\" to choose the best split and \"random\" to choose\nthe best random split.\n'best'\n\n\n\nmax_depth max_depth: int, default=None\n\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nNone\n\n\n\nmin_samples_split min_samples_split: int or float, default=2\n\nThe minimum number of samples required to split an internal node:\n\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n\n.. versionchanged:: 0.18\nAdded float values for fractions.\n2\n\n\n\nmin_samples_leaf min_samples_leaf: int or float, default=1\n\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n\n.. versionchanged:: 0.18\nAdded float values for fractions.\n1\n\n\n\nmin_weight_fraction_leaf min_weight_fraction_leaf: float, default=0.0\n\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\n0.0\n\n\n\nmax_features max_features: int, float or {\"sqrt\", \"log2\"}, default=None\n\nThe number of features to consider when looking for the best split:\n\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`max(1, int(max_features * n_features_in_))` features are considered at\neach split.\n- If \"sqrt\", then `max_features=sqrt(n_features)`.\n- If \"log2\", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\n\n.. note::\n\nThe search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nNone\n\n\n\nrandom_state random_state: int, RandomState instance or None, default=None\n\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``\"best\"``. When ``max_features &lt; n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary ` for details.\nNone\n\n\n\nmax_leaf_nodes max_leaf_nodes: int, default=None\n\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nNone\n\n\n\nmin_impurity_decrease min_impurity_decrease: float, default=0.0\n\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\n\nThe weighted impurity decrease equation is the following::\n\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\n\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n\n.. versionadded:: 0.19\n0.0\n\n\n\nclass_weight class_weight: dict, list of dict or \"balanced\", default=None\n\nWeights associated with classes in the form ``{class_label: weight}``.\nIf None, all classes are supposed to have weight one. For\nmulti-output problems, a list of dicts can be provided in the same\norder as the columns of y.\n\nNote that for multioutput (including multilabel) weights should be\ndefined for each class of every column in its own dict. For example,\nfor four-class multilabel classification weights should be\n[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n[{1:1}, {2:5}, {3:1}, {4:1}].\n\nThe \"balanced\" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``\n\nFor multi-output, the weights of each column of y will be multiplied.\n\nNote that these weights will be multiplied with sample_weight (passed\nthrough the fit method) if sample_weight is specified.\nNone\n\n\n\nccp_alpha ccp_alpha: non-negative float, default=0.0\n\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details. See\n:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`\nfor an example of such pruning.\n\n.. versionadded:: 0.22\n0.0\n\n\n\nmonotonic_cst monotonic_cst: array-like of int of shape (n_features), default=None\n\nIndicates the monotonicity constraint to enforce on each feature.\n- 1: monotonic increase\n- 0: no constraint\n- -1: monotonic decrease\n\nIf monotonic_cst is None, no constraints are applied.\n\nMonotonicity constraints are not supported for:\n- multiclass classifications (i.e. when `n_classes &gt; 2`),\n- multioutput classifications (i.e. when `n_outputs_ &gt; 1`),\n- classifications trained on data with missing values.\n\nThe constraints hold over the probability of the positive class.\n\nRead more in the :ref:`User Guide `.\n\n.. versionadded:: 1.4\nNone\n\n\n\n\n            \n        \n    \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n3. K-Means Clustering (Unsupervised Learning)\n\nGroups similar data points together.\nExample: Customer segmentation in marketing.\n\n\n\nCluster Centers: [[10.  2.]\n [ 1.  2.]]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n4. Support Vector Machines (SVM) (Supervised Learning - Classification)\n\nFinds a hyperplane that best separates different classes.\nExample: Classifying tumors as benign or malignant.\n\n\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVC?Documentation for SVCiFitted\n        \n            \n                Parameters\n                \n\n\n\n\n\n\n\n\n\nC C: float, default=1.0\n\nRegularization parameter. The strength of the regularization is\ninversely proportional to C. Must be strictly positive. The penalty\nis a squared l2 penalty. For an intuitive visualization of the effects\nof scaling the regularization parameter C, see\n:ref:`sphx_glr_auto_examples_svm_plot_svm_scale_c.py`.\n1.0\n\n\n\nkernel kernel: {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable, default='rbf'\n\nSpecifies the kernel type to be used in the algorithm. If\nnone is given, 'rbf' will be used. If a callable is given it is used to\npre-compute the kernel matrix from data matrices; that matrix should be\nan array of shape ``(n_samples, n_samples)``. For an intuitive\nvisualization of different kernel types see\n:ref:`sphx_glr_auto_examples_svm_plot_svm_kernels.py`.\n'rbf'\n\n\n\ndegree degree: int, default=3\n\nDegree of the polynomial kernel function ('poly').\nMust be non-negative. Ignored by all other kernels.\n3\n\n\n\ngamma gamma: {'scale', 'auto'} or float, default='scale'\n\nKernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n\n- if ``gamma='scale'`` (default) is passed then it uses\n1 / (n_features * X.var()) as value of gamma,\n- if 'auto', uses 1 / n_features\n- if float, must be non-negative.\n\n.. versionchanged:: 0.22\nThe default value of ``gamma`` changed from 'auto' to 'scale'.\n'scale'\n\n\n\ncoef0 coef0: float, default=0.0\n\nIndependent term in kernel function.\nIt is only significant in 'poly' and 'sigmoid'.\n0.0\n\n\n\nshrinking shrinking: bool, default=True\n\nWhether to use the shrinking heuristic.\nSee the :ref:`User Guide `.\nTrue\n\n\n\nprobability probability: bool, default=False\n\nWhether to enable probability estimates. This must be enabled prior\nto calling `fit`, will slow down that method as it internally uses\n5-fold cross-validation, and `predict_proba` may be inconsistent with\n`predict`. Read more in the :ref:`User Guide `.\nFalse\n\n\n\ntol tol: float, default=1e-3\n\nTolerance for stopping criterion.\n0.001\n\n\n\ncache_size cache_size: float, default=200\n\nSpecify the size of the kernel cache (in MB).\n200\n\n\n\nclass_weight class_weight: dict or 'balanced', default=None\n\nSet the parameter C of class i to class_weight[i]*C for\nSVC. If not given, all classes are supposed to have\nweight one.\nThe \"balanced\" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``.\nNone\n\n\n\nverbose verbose: bool, default=False\n\nEnable verbose output. Note that this setting takes advantage of a\nper-process runtime setting in libsvm that, if enabled, may not work\nproperly in a multithreaded context.\nFalse\n\n\n\nmax_iter max_iter: int, default=-1\n\nHard limit on iterations within solver, or -1 for no limit.\n-1\n\n\n\ndecision_function_shape decision_function_shape: {'ovo', 'ovr'}, default='ovr'\n\nWhether to return a one-vs-rest ('ovr') decision function of shape\n(n_samples, n_classes) as all other classifiers, or the original\none-vs-one ('ovo') decision function of libsvm which has shape\n(n_samples, n_classes * (n_classes - 1) / 2). However, note that\ninternally, one-vs-one ('ovo') is always used as a multi-class strategy\nto train models; an ovr matrix is only constructed from the ovo matrix.\nThe parameter is ignored for binary classification.\n\n.. versionchanged:: 0.19\ndecision_function_shape is 'ovr' by default.\n\n.. versionadded:: 0.17\n*decision_function_shape='ovr'* is recommended.\n\n.. versionchanged:: 0.17\nDeprecated *decision_function_shape='ovo' and None*.\n'ovr'\n\n\n\nbreak_ties break_ties: bool, default=False\n\nIf true, ``decision_function_shape='ovr'``, and number of classes &gt; 2,\n:term:`predict` will break ties according to the confidence values of\n:term:`decision_function`; otherwise the first class among the tied\nclasses is returned. Please note that breaking ties comes at a\nrelatively high computational cost compared to a simple predict. See\n:ref:`sphx_glr_auto_examples_svm_plot_svm_tie_breaking.py` for an\nexample of its usage with ``decision_function_shape='ovr'``.\n\n.. versionadded:: 0.22\nFalse\n\n\n\nrandom_state random_state: int, RandomState instance or None, default=None\n\nControls the pseudo random number generation for shuffling the data for\nprobability estimates. Ignored when `probability` is False.\nPass an int for reproducible output across multiple function calls.\nSee :term:`Glossary `.\nNone\n\n\n\n\n            \n        \n    \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n5. Reinforcement Learning Example\n\nUses rewards and penalties to train an agent to make optimal decisions.\nExample: A robot learning to navigate a maze.\n\n\n\nTrained Q-Table:\n [[0.2101055  0.26290837 0.33031396 0.4694757  0.54616518]\n [0.29863574 0.39522138 0.48877163 0.63420958 0.90034533]\n [0.38771367 0.5453337  0.75510799 1.46886398 2.11506581]\n [0.45020663 0.73138269 1.30329813 2.32862416 5.7296461 ]\n [0.5913093  0.91675229 2.42871664 6.08487224 0.        ]]"
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "href": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Methodology for designing an edge ai device",
    "text": "Methodology for designing an edge ai device\n\nProblem Definition & Use Case Analysis\nData Collection & Preprocessing\nModel Selection & Optimization\nHardware Selection\nDeployment & Model Inference\nTesting, Validation, and Continuous Improvement\nFinal Deployment & Scaling"
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Problem Definition & Use Case Analysis",
    "text": "Problem Definition & Use Case Analysis\n\nIdentify the specific AI task (e.g., real-time ECG analysis, fall detection, predictive maintenance in IoT).\nDetermine operational constraints, including:\n\nPower consumption (battery-operated vs. wired).\nLatency requirements (real-time processing vs. periodic updates).\nCommunication needs (Wi-Fi, Bluetooth, LoRa, standalone processing)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Collection & Preprocessing",
    "text": "Data Collection & Preprocessing\n\nSensor Selection: Choose sensors relevant to the application (e.g., accelerometers for motion tracking, biosensors for health monitoring).\nEdge-Compatible Data Acquisition: Optimize data formats to reduce memory and computational load.\nPreprocessing on Edge:\n\nSignal filtering (e.g., noise reduction in biomedical signals).\nFeature extraction (e.g., time-series features for motion classification)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Model Selection & Optimization",
    "text": "Model Selection & Optimization\n\nModel Selection:\n\nLightweight CNNs (for image processing).\nRecurrent Neural Networks (RNNs) / LSTMs (for time-series data like ECG).\nTinyML models optimized for microcontrollers (e.g., TensorFlow Lite, PyTorch Mobile).\n\nModel Optimization for Edge Deployment:\n\nQuantization: Convert floating-point models to int8 or int16 to reduce size and computation load.\nPruning: Remove unnecessary neurons or layers while preserving accuracy.\nDistillation: Train a smaller model using knowledge from a larger one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Hardware Selection",
    "text": "Hardware Selection\n\nProcessing Unit:\n\nMicrocontrollers (MCUs) (e.g., ARM Cortex-M, ESP32) → Low-power, simple AI tasks.\nEdge AI Accelerators (e.g., Google Edge TPU, NVIDIA Jetson Nano) → More complex AI processing.\nFPGAs (Field-Programmable Gate Arrays) → Custom AI workloads for high-speed processing.\n\nMemory & Storage:\n\nRAM Optimization: Choose embedded SRAM or external DRAM depending on model size.\nFlash Storage: Store inference models efficiently.\n\nConnectivity:\n\nOffline processing for low-latency applications.\nEdge-to-cloud integration for periodic updates."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Deployment & Model Inference",
    "text": "Deployment & Model Inference\n\nConvert trained AI models into optimized edge-compatible formats (e.g., TensorFlow Lite, ONNX).\nImplement real-time inference using hardware-accelerated libraries (e.g., TensorRT, OpenVINO).\nOptimize firmware for energy efficiency using duty-cycling techniques (process only when necessary)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Testing, Validation, and Continuous Improvement",
    "text": "Testing, Validation, and Continuous Improvement\n\nEdge Benchmarking:\n\nMeasure inference speed and power consumption.\nValidate model accuracy on real-world edge-generated data.\n\nSecurity & Reliability:\n\nImplement secure boot & firmware updates to prevent cyber threats.\nEnsure robust error handling for sensor malfunctions.\n\nFeedback & Model Updating:\n\nIf connected to a cloud system, update models periodically using federated learning.\nOptimize AI pipelines with incremental learning on-device where feasible."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Final Deployment & Scaling",
    "text": "Final Deployment & Scaling\n\nDeploy at scale, ensuring the Edge AI model adapts to different environments.\nImplement remote monitoring & diagnostics for predictive maintenance.\nEnable over-the-air (OTA) updates to improve AI models post-deployment."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "href": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Abstract",
    "text": "Abstract\nThe hardware-software co-design approach is the most widely used methodology for Edge AI device development. It ensures:\n\nReal-time performance with optimized AI models.\nEnergy-efficient processing for battery-operated or low-power devices.\nScalability and security in edge environments.\n\nThis methodology is industry-standard and used by leading companies in healthcare, automotive, and industrial IoT, ensuring robust and reliable Edge AI solutions."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "href": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Example of application",
    "text": "Example of application\n\n\n\n\n\n\n\nUse case\n\n\nA wearable ECG monitoring device designed for continuous heart health tracking and arrhythmia detection. This Edge AI-based solution analyzes ECG signals in real-time on a low-power microcontroller, providing instant alerts for cardiac irregularities without relying on cloud computing."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 1: Problem Definition & Use Case Analysis",
    "text": "Step 1: Problem Definition & Use Case Analysis\n\n\n\n\n\n\n\nObjective\n\n\nDetect abnormal heart rhythms (arrhythmias) in real-time using a wearable ECG device.\n\n\n\n\nOperational Constraints:\n\nMust be energy-efficient (battery-operated, low power consumption).\nNeeds real-time inference for immediate alerts.\nShould operate offline, but sync with mobile apps for periodic review.\n\nKey Challenges:\n\nProcessing ECG data on a low-power Edge device.\nMinimizing false positives/negatives in arrhythmia detection.\nEnsuring high reliability and accuracy."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 2: Data Collection & Preprocessing",
    "text": "Step 2: Data Collection & Preprocessing\nSensor Selection:\n\nECG sensor (e.g., AD8232) captures raw heart signals.\nAccelerometer (optional) for motion artifacts reduction.\n\nEdge-Compatible Data Acquisition:\n\nSample rate: 250 Hz (sufficient for arrhythmia detection).\nUse on-device filtering (low-pass filters) to remove noise.\n\nPreprocessing on Edge:\n\nApply Butterworth filters for noise reduction.\nR-peak detection using Pan-Tompkins algorithm for heart rate calculation.\nExtract features like RR intervals, QRS width, and HR variability."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 3: Model Selection & Optimization",
    "text": "Step 3: Model Selection & Optimization\nAI Model:\n\nUse 1D CNN + LSTM hybrid model (efficient for ECG signal processing).\nTrain the model using MIT-BIH Arrhythmia Database.\n\nModel Optimization for Edge AI:\n\nQuantization: Convert model to int8 precision using TensorFlow Lite.\nPruning: Remove redundant neurons to reduce computation load.\nKnowledge Distillation: Train a smaller model from a high-performing one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 4: Hardware Selection",
    "text": "Step 4: Hardware Selection\nMicrocontroller (MCU):\n\nNordic nRF52840 (low-power ARM Cortex-M4 + BLE connectivity).\nAlternative: ESP32 (for low-cost AI inference).\n\nMemory & Storage:\n\nRAM: 512KB (optimized for Edge AI processing).\nFlash storage: 4MB (stores ECG data logs for later analysis).\n\nConnectivity:\n\nBluetooth Low Energy (BLE) for periodic sync with mobile apps.\nCan function offline with real-time alerts."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 5: Deployment & Model Inference",
    "text": "Step 5: Deployment & Model Inference\n\nConvert trained TensorFlow model → TensorFlow Lite for Edge AI inference.\nDeploy on the Nordic nRF52840 MCU using TensorFlow Lite for Microcontrollers.\nUse hardware-accelerated inference for efficient processing.\nImplement event-driven processing (AI runs only on abnormal detections to save power)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 6: Testing, Validation, and Continuous Improvement",
    "text": "Step 6: Testing, Validation, and Continuous Improvement\nEdge Benchmarking:\n\nReal-time inference latency: &lt;10 ms per ECG segment.\nPower consumption: 5mW (optimized for long battery life).\n\nSecurity & Reliability:\n\nSecure Boot & Firmware Updates to prevent hacking.\nAdaptive AI Models: Learns individual patient heart patterns to reduce false alarms.\n\nFeedback & Model Updating:\n\nSync detected arrhythmia events with a cloud server for validation.\nUse federated learning to improve AI models without sharing raw patient data."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Step 7: Final Deployment & Scaling",
    "text": "Step 7: Final Deployment & Scaling\n\nMass production of the device for hospitals, clinics, and home use.\nIntegration with mobile apps for patient-doctor communication.\nRegulatory Approval: Submit for FDA/CE certification for medical device compliance.\nOver-the-Air (OTA) Updates: Allow model updates based on new ECG patterns."
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\n\nBio - That came from a biological being\nSignal - A signal is a function that conveys information about a physical phenomenon.\nBiosignals - The search for information from living systems to know its health state"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-1",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\nBiosignals\n\n\nThe codification of biosignals into variations: * Electrical * Mechanical * Chemical * Thermal"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-2",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-3",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#introduction-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nTaken from Semmlow et al"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1791: Luigi Galvani discovers electrical signals in living tissues (frog legs)\n1830s: Carlo Matteucci studies electrical signals in the heart\n1887: Willem Einthoven invents the first electrocardiograph (ECG)\n1900s: James Mackenzie develops the first clinical ECG machine"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-1",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1920s: Electroencephalography (EEG) is developed by Hans Berger\n1930s: Electromyography (EMG) is developed by John Humphrey and others\n1940s: Development of the first commercial ECG machines\n1950s: Signal processing techniques are applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-2",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n1960s: Digital signal processing and computer analysis of biomedical signals emerge\n1970s: Biomedical signal processing becomes a recognized field\n1980s: Development of Holter monitoring (24-hour ECG)\n1990s: Advances in signal processing and machine learning applied to biomedical signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-3",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Signals:\n\n2000s: Development of wearable devices and mobile health (mHealth) technologies\n2010s: Emergence of big data analytics and cloud computing in biomedical signal processing\n2020s: Integration of artificial intelligence (AI) and machine learning (ML) in biomedical signal processing"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-4",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-4",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1895: Wilhelm Roentgen discovers X-rays, leading to medical imaging\n1900s: X-ray technology improves with development of modern X-ray tubes\n1913: Albert Salomon develops mammography\n1920s: Ultrasound technology is developed by Karl Dussik and others"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-5",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1930s: Nuclear medicine emerges with development of radioactive tracers\n1950s: Computed Tomography (CT) scans are developed by Godfrey Hounsfield and Allan McLeod Cormack\n1960s: Development of medical ultrasound imaging\n1970s: Magnetic Resonance Imaging (MRI) is developed by Richard Ernst and others"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-6",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-6",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nBiomedical Images:\n\n1980s: Digital image processing and analysis techniques are applied to biomedical images\n1990s: Advances in MRI and CT scan technology, including 3D imaging\n2000s: Development of functional MRI (fMRI), diffusion tensor imaging (DTI), and other advanced MRI techniques\n2010s: Emergence of artificial intelligence (AI) and machine learning in medical imaging"
  },
  {
    "objectID": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-7",
    "href": "presentaciones/SYSB/Lect002_Intro_SYSB.html#time-line-7",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time line",
    "text": "Time line\nAdditional Milestones:\n\n1950s: Development of medical electronics and instrumentation\n1960s: First medical imaging computers are developed\n1970s: Development of digital image processing and analysis software\n1980s: Emergence of medical imaging informatics and PACS (Picture Archiving and Communication Systems)\n1990s: Development of telemedicine and teleradiology\n2000s: Emergence of electronic health records (EHRs) and health information exchanges (HIEs)\n2010s: Development of personalized medicine and precision health initiatives"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-step",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-step",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Unit Step",
    "text": "Unit Step\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[u(t) =\n\\begin{cases}\n0, & t &lt; 0 \\\\\n1, & t \\geq 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[u[n] =\n\\begin{cases}\n0, & n &lt; 0 \\\\\n1, & n \\geq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-ramp",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#unit-ramp",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Unit Ramp",
    "text": "Unit Ramp\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[u(t) =\n\\begin{cases}\n0, & t &lt; 0 \\\\\nt, & t \\geq 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[u[n] =\n\\begin{cases}\n0, & n &lt; 0 \\\\\nn, & n \\geq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#sync-function",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#sync-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sync Function",
    "text": "Sync Function\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[\\text{sinc}(t) =\n\\begin{cases}\n\\frac{\\sin(\\pi t)}{\\pi t}, & t \\neq 0 \\\\\n1, & t = 0\n\\end{cases}\\]\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\text{sinc}[n] =\n\\begin{cases}\n\\frac{\\sin(\\pi n)}{\\pi n}, & n \\neq 0 \\\\\n1, & n = 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#diracs-delta",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#diracs-delta",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Dirac’s Delta",
    "text": "Dirac’s Delta\n\n\n\n\n\n\n\n\n\nContinous\n\n\n\\[\\delta(t) =\n\\begin{cases}\n+\\infty, & t = 0 \\\\\n0, & t \\neq 0\n\\end{cases}\\]\n\\(\\int_{-\\infty}^{\\infty} \\delta(t) dt = 1\\)\n\n\n\n\n\n\n\n\n\n\n\nDiscrete\n\n\n\\[\\delta[n] =\n\\begin{cases}\n1, & n = 0 \\\\\n0, & n \\neq 0\n\\end{cases}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-time",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-time",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – Translation in time",
    "text": "Basic Transformations on Singular signals – Translation in time"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-amplitude",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-translation-in-amplitude",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – Translation in amplitude",
    "text": "Basic Transformations on Singular signals – Translation in amplitude"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-time",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-time",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – scailing in time",
    "text": "Basic Transformations on Singular signals – scailing in time"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-amplitude",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#basic-transformations-on-singular-signals-scailing-in-amplitude",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Basic Transformations on Singular signals – scailing in amplitude",
    "text": "Basic Transformations on Singular signals – scailing in amplitude"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#example",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\n\nQuestionSolutionCode for the graph 1/2Code for the graph 2/2\n\n\nHow can i create the following signal using only singular signals\n\n\n\n\n\n\n\n\n\n\n\n\\[x(t) = 5u(t) - 5(t-3)\\]\n\n\n\nt = np.linspace(-10,10,1000)\nx = np.zeros(t.shape)\n\nx[t&gt;=0]=5\nx[t&gt;=3]=0\n\nplt.figure(figsize=(16,6.75))\nplt.plot(t,x)\nplt.grid()\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Amplitude\")\n\n\n\n\nt = np.linspace(-10,10,1000)\nx = np.zeros(t.shape)\n\nx=5*np.heaviside(t,1)-5*np.heaviside(t-3,1)\n\nplt.figure(figsize=(16,6.75))\nplt.plot(t,x)\nplt.grid()\nplt.xlabel(\"Time(s)\")\nplt.ylabel(\"Amplitude\")"
  },
  {
    "objectID": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#exercisae-singular-signals",
    "href": "presentaciones/SYSB/Lect004_Intro_SennalesNotables.html#exercisae-singular-signals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Exercisae Singular Signals",
    "text": "Exercisae Singular Signals\n\nQuestion\n\n\nHow can i create the following signal using only singular signals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition",
    "text": "Introduction to data adquisition\n\n\n\nThere are two main roles in data: capture the information and encode the data in a form tha machine can process.\nData adquisition has three stages:\n\nTransduction\nSignal conditioning\nAnalog-to-digital conversion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Transduction",
    "text": "Introduction to data adquisition - Transduction\n\n\n\nTransduction is the conversion from one form of energy to another.\nThe only energy suitable for computer processing is the electrical\nTherefore signals need to be converted to analog voltages whose waveforms are ideally the same as those of the original signals.\nExist two components a captured signal: one component carries the information (signal), the other one is a probabilistic distorsion of the information(noise)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nNoise refers to any unwanted or random variations in a signal that interfere with the desired information. It is an unpredictable disturbance that can distort or obscure the actual data, making it harder to interpret or analyze.\n\n\n\n\nTypes of noise\n\nThermal Noise (Random Noise)\nElectromagnetic Interference (EMI)\nMotion Artifacts\nPhysiological Noise\nQuantization Noise"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\nModelling the noise\n\nAdditive White Gaussian Noise (AWGN): Modeled as a random process with a normal distribution.\nBand-limited Noise: Affects only specific frequency ranges and can be removed with filters.\nAdditive Noise: Adds directly to the original signal.\nMultiplicative Noise: Multiplies the original signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\nGraphsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros de la señal\nduration = 2  # Duración en segundos\nfs = 1000  # Frecuencia de muestreo en Hz\nt = np.linspace(0, duration, duration * fs, endpoint=False)  # Vector de tiempo\n\n# Señal senoidal de 10 Hz\nfreq = 10\nsine_wave = np.sin(2 * np.pi * freq * t)\n\n# Señal de ruido aleatorio con distribución normal\nnoise_normal = np.random.normal(0, 1, len(t))\n\n# Señal con ruido aleatorio de 2 a 5 Hz\nlow_freq_noise = np.sin(2 * np.pi * np.random.uniform(2, 5) * t)\nsignal_with_low_freq_noise = sine_wave + low_freq_noise\n\n# Señal con ruido aleatorio uniforme sumado\nuniform_noise = np.random.uniform(-0.5, 0.5, len(t))\nsignal_with_uniform_noise = sine_wave + uniform_noise\n\n# Señal con ruido aleatorio uniforme multiplicado\nmultiplicative_noise = np.random.uniform(0.5, 1.5, len(t))\nsignal_with_mult_noise = sine_wave * multiplicative_noise\n\n# Graficamos las señales\nfig, axes = plt.subplots(5, 1, figsize=(10, 10), sharex=True)\n\naxes[0].plot(t, sine_wave, label=\"Sine wave (10 Hz)\")\naxes[0].set_title(\"Sine Wave (10 Hz)\")\naxes[0].legend()\n\naxes[1].plot(\n    t, noise_normal, label=\"Random Noise (Normal Distribution)\", color=\"orange\"\n)\naxes[1].set_title(\"Random Noise (Normal Distribution)\")\naxes[1].legend()\n\naxes[2].plot(\n    t, signal_with_low_freq_noise, label=\"Sine + Low Freq Noise (2-5 Hz)\", color=\"green\"\n)\naxes[2].set_title(\"Sine + Low Freq Noise (2-5 Hz)\")\naxes[2].legend()\n\naxes[3].plot(t, signal_with_uniform_noise, label=\"Sine + Uniform Noise\", color=\"red\")\naxes[3].set_title(\"Sine + Uniform Noise\")\naxes[3].legend()\n\naxes[4].plot(t, signal_with_mult_noise, label=\"Sine * Uniform Noise\", color=\"purple\")\naxes[4].set_title(\"Sine * Uniform Noise\")\naxes[4].legend()\n\nplt.xlabel(\"Time [s]\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - ASP",
    "text": "Introduction to data adquisition - ASP\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAnalog signal processing (ASP) refers to the manipulation of continuous-time signals after they have been acquired from a transducer but before digital conversion. This type of processing is performed using electronic circuits that modify the signal in the analog domain to enhance its quality, extract useful information, or prepare it for further processing.\n\n\n\n\n\n\n\n\n\n\n\nCommon tasks\n\n\n\nAmplification: Increases the signal strength to match the required voltage levels. Example: ECG signals are weak (~1 mV) and need to be amplified before analysis.\nFiltering: Removes unwanted frequency components such as noise or interference.\nModulation/Demodulation: Used for communication systems where signals are modulated onto a higher-frequency carrier wave. Example: Biomedical telemetry systems use amplitude modulation (AM) or frequency modulation (FM) to transmit patient data wirelessly.\nDifferentiation & Integration: Differentiation: Highlights rapid changes in the signal. Example: Used in QRS detection for ECG signal analysis. Integration: Smooths out signals and accumulates values over time. Example: Used in electromyography (EMG) processing to estimate muscle activation.\nSignal Conditioning: Includes impedance matching, offset correction, and dynamic range adjustments. Example: Removing DC offsets in biosignals before digitization."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - analog-to-digital convertion",
    "text": "Introduction to data adquisition - analog-to-digital convertion\n\n\n\n\n\n\n\nDefinition\n\n\nAn analog-to-digital converter (ADC) is a device that converts a continuous-time signal, obtained through a transducer, into a digital signal that can be processed by a computer. This process consists of two fundamental operations, which occur simultaneously in practical implementations: sampling and quantization.\n\n\n\n\nOperations\n\nSampling involves converting the continuous-time analog signal into a discrete-time signal, where the amplitude remains unrestricted.\nQuantization then maps this continuous-amplitude signal to a finite set of discrete values, making it fully digital."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-in-dsp-purpose-and-context",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-in-dsp-purpose-and-context",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Quantization in DSP: Purpose and Context",
    "text": "Quantization in DSP: Purpose and Context\n\nQuantization maps continuous amplitudes to a finite set of levels to enable digital representation.\nIn acquisition chains: anti-alias filter → sampling → ADC quantization.\nQuantization introduces an error that behaves like noise under standard assumptions.\nBiomedical relevance: ECG, EEG, EMG, and PPG require appropriate bit depth, gain, and dynamic range to preserve diagnostically relevant features."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#uniform-quantizer-definitions",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#uniform-quantizer-definitions",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Uniform Quantizer: Definitions",
    "text": "Uniform Quantizer: Definitions\n\nInput range: \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\), bit depth \\(b\\), levels \\(L=2^b\\), step size (LSB)\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nMid-tread (round-to-nearest): \\(Q(x)=\\Delta,\\mathrm{round}!\\big(x/\\Delta\\big)\\).\nMid-rise (truncate + half-step): \\(Q(x)=\\Delta\\big(\\lfloor x/\\Delta\\rfloor+\\tfrac12\\big)\\).\nOverload/clipping outside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\): \\(\\tilde{x}=V\\_{\\max}\\) or \\(V\\_{\\min}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#decision-thresholds-and-codebook",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#decision-thresholds-and-codebook",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Decision Thresholds and Codebook",
    "text": "Decision Thresholds and Codebook\n\nDecision thresholds at \\(k\\Delta\\); reconstruction levels at:\n\n\\(k\\Delta\\) (mid-tread), or\n\\((k+\\tfrac12)\\Delta\\) (mid-rise).\n\nPractical note: choose mid-tread for rounding semantics; mid-rise for deterministic staircase without zero level."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-error-model-and-power",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-error-model-and-power",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Quantization Error: Model and Power",
    "text": "Quantization Error: Model and Power\n\nError \\(e=x-Q(x)\\). Under high-resolution assumptions (no clipping, sufficiently dense input):\n\n\\(e=x-Q(x)\\sim\\mathcal{U}\\left[-\\tfrac{\\Delta}{2},\\tfrac{\\Delta}{2}\\right]\\), \\(\\mathbb{E}\\left[e\\right]=0\\), \\(\\mathrm{Var}(e)=\\Delta^2/12\\).\n\nFor a full-scale sinusoid:\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nWith RMS usage fraction \\(\\rho\\) of full scale (FS):\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#effective-number-of-bits-enob",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#effective-number-of-bits-enob",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Effective Number of Bits (ENOB)",
    "text": "Effective Number of Bits (ENOB)\n\nFrom a measured in-band SNR (RMS, same bandwidth):\n\\[\n\\mathrm{ENOB}\\approx\\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]\nUse ENOB to compare real converters (including clock jitter, distortion) against ideal \\(b\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#input-range-analog-gain-and-clipping",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#input-range-analog-gain-and-clipping",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Input Range, Analog Gain, and Clipping",
    "text": "Input Range, Analog Gain, and Clipping\n\nAnalog gain \\(G\\) maps input to ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\Delta/G\\).\nDesign goals:\n\nAvoid overload for rare peaks; 2) Use a large fraction of FS (e.g., \\(50\\)–\\(80%\\)) to improve SNR."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#biomedical-example-ecg-acquisition",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#biomedical-example-ecg-acquisition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Biomedical Example: ECG Acquisition",
    "text": "Biomedical Example: ECG Acquisition\n\nSuppose electrode-level ECG peaks \\(\\approx \\pm 5,\\mathrm{mV}\\). Choose \\(G=200\\) so \\(\\pm 5,\\mathrm{mV}\\mapsto \\pm 1,\\mathrm{V}\\) at ADC (\\(V\\_{\\min,\\max}=\\pm 1,\\mathrm{V}\\)).\nWith \\(b=12\\):\n\n\\(\\Delta=\\dfrac{2,\\mathrm{V}}{2^{12}}\\approx 0.488,\\mathrm{mV}\\) (ADC domain).\n\\(\\Delta\\_{\\text{in}}=\\Delta/G\\approx 2.44,\\mu\\mathrm{V}\\).\nInput-referred noise RMS \\(\\sigma\\_q=\\Delta\\_{\\text{in}}/\\sqrt{12}\\approx 0.704,\\mu\\mathrm{V}\\_{\\mathrm{RMS}}\\).\n\nIf \\(\\rho\\approx 0.5\\), then \\(\\mathrm{SNR}\\approx 6.02\\cdot 12 + 1.76 - 6 \\approx 68,\\mathrm{dB}\\) → typically adequate for diagnostic ECG."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#non-uniform-quantization-and-companding-brief",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#non-uniform-quantization-and-companding-brief",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Non-Uniform Quantization and Companding (Brief)",
    "text": "Non-Uniform Quantization and Companding (Brief)\n\nFor highly non-uniform amplitude distributions, companding allocates effective resolution to small amplitudes.\n\\(\\mu\\)-law (telephony):\n\\[\ny=\\mathrm{sgn}(x)\\,\\frac{\\ln\\big(1+\\mu |x|/X_{\\max}\\big)}{\\ln(1+\\mu)},\\quad \\mu\\approx 255.\n\\]\nIn biomedicine, primary acquisition usually remains linear; companding is more relevant to low-bit-rate telemetry or storage."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#dither-when-and-why",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#dither-when-and-why",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Dither: When and Why",
    "text": "Dither: When and Why\n\nAdd small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization to decorrelate error, eliminate bias/patterning at low levels, and linearize averages.\nSlight SNR penalty but improved fidelity for low-level features (e.g., EEG baselines)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#practical-design-checklist",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#practical-design-checklist",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Practical Design Checklist",
    "text": "Practical Design Checklist\n\nChoose \\(b\\) to exceed clinical SNR requirements by \\(10\\)–\\(20,\\mathrm{dB}\\).\nSet \\(G\\) so typical peaks use \\(50\\)–\\(80%\\) FS; verify worst-case spikes do not clip.\nFull noise budget: electrode + amplifier + ADC quantization + clock jitter (for high \\(f\\)).\nValidate with calibrated sources and report ENOB over the intended bandwidth."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#python-demo-ecg-quantization-at-multiple-bit-depths",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#python-demo-ecg-quantization-at-multiple-bit-depths",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Python Demo: ECG Quantization at Multiple Bit Depths",
    "text": "Python Demo: ECG Quantization at Multiple Bit Depths\n\n# Synthetic ECG, quantization at 8/10/12 bits, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nfs = 360.0\nT = 5.0\nt = np.arange(0, T, 1/fs)\n\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\ndef ecg_template(t):\n    P = g(t, 0.20, 0.045,  0.10)\n    Q = g(t, 0.36, 0.010, -0.25)\n    R = g(t, 0.40, 0.012,  1.00)\n    S = g(t, 0.44, 0.016, -0.35)\n    Tn= g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + Tn\n\nhr = 60.0\nRR = 60.0/hr\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    ecg_mV += ecg_template(t - k*RR)\n\nwander = 0.05*np.sin(2*np.pi*0.3*t)\nnoise  = 0.02*np.random.randn(len(t))\necg_mV = ecg_mV + wander + noise\n\nG = 200.0\nVfs = 1.0\nVmin, Vmax = -Vfs, Vfs\nx_adc = (ecg_mV/1000.0)*G  # mV -&gt; V and gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)\n    return y, Delta\n\ndef snr_db(x, y):\n    e = x - y\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\nprint(\"Summary (ADC domain):\")\n\nSummary (ADC domain):\n\nfor b in bits_list:\n    print(f\"{b:2d}-bit -&gt; LSB Δ = {results[b]['Delta']*1e3:.3f} mV, Measured SNR ≈ {results[b]['snr_db']:5.1f} dB\")\n\n 8-bit -&gt; LSB Δ = 7.812 mV, Measured SNR ≈  24.1 dB\n10-bit -&gt; LSB Δ = 1.953 mV, Measured SNR ≈  36.0 dB\n12-bit -&gt; LSB Δ = 0.488 mV, Measured SNR ≈  48.1 dB\n\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Δ_in = {Delta_in*1e6:.3f} µV, σ_q ≈ {sigma_q_in*1e6:.3f} µV RMS\")\n\n\nInput-referred (12-bit): Δ_in = 2.441 µV, σ_q ≈ 0.705 µV RMS\n\n# Plot 1: original vs quantized (10-bit)\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n# Plot 2: quantization error histogram (8-bit)\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\nTo explain the analog-to-digital conversion process, we will assume that the input signal is a cosine wave with frequency \\(F\\), angular frequency \\(\\Omega\\) and amplitude \\(a\\).\n\\[x\\left(t\\right) = a \\cos\\left(\\Omega t + \\phi\\right) = a \\cos\\left(2\\pi F t + \\phi\\right)\\]\nObtaining\n\\[x\\left[n\\right] = a \\cos\\left(\\omega n + \\phi\\right) = a \\cos\\left(2\\pi f n + \\phi\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\n\n\n\n\n\n\n\nWhat?\n\n\nMathematically, the sampling process is:\n\\[x[n] = x(nT_s), \\quad -\\infty &lt; n &lt; \\infty\\]\n\n\n\n\nReplacing in previous equations, we have the expression:\n\\[x[n] = x(nT_s) = a \\cos\\left( 2\\pi F n T_s + \\phi \\right) = a \\cos\\left( 2\\pi n \\frac{F}{F_s} + \\phi \\right)\n\\]\nWhere:\n\\[\\omega = \\Omega T_s, \\quad f = \\frac{F}{F_s}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sample and quantization of an ECG signal",
    "text": "Sample and quantization of an ECG signal\n\nTaskGraphCode\n\n\n\nGenerate a synthetic ECG-like signal.\nSample it at different rates.\nApply quantization with different bit depths.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import chirp\n\n# Generate a synthetic ECG-like signal (chirp function as approximation)\nfs_original = 10000  # High sampling rate (Hz) - \"continuous\" signal\nt = np.linspace(0, 1, fs_original, endpoint=False)  # 1-second signal\nsignal = np.sin(2 * np.pi * 1.7 * (t**2))  # Simulated chirp (similar to ECG waves)\n\n# Downsample (Sampling Process)\nfs_sampled = 200  # Sampling frequency in Hz (e.g., ECG sampled at 200 Hz)\nt_sampled = np.arange(0, 1, 1/fs_sampled)\nsignal_sampled = np.sin(2 * np.pi * 1.7 * (t_sampled**2))\n\n# Quantization (8-bit and 4-bit)\ndef quantize(signal, bits):\n    levels = 2**bits\n    min_val, max_val = signal.min(), signal.max()\n    step = (max_val - min_val) / levels\n    quantized_signal = np.round((signal - min_val) / step) * step + min_val\n    return quantized_signal\n\nsignal_quantized_8bit = quantize(signal_sampled, 8)\nsignal_quantized_4bit = quantize(signal_sampled, 4)\n\n# Plot Results\nplt.figure(figsize=(12, 6))\n\n# Original vs Sampled Signal\nplt.subplot(2, 1, 1)\nplt.plot(t, signal, 'k', alpha=0.3, label='Original Signal (High Resolution)')\nplt.plot(t_sampled, signal_sampled, 'ro-', label=f'Sampled Signal ({fs_sampled} Hz)')\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Sampling Process\")\n\n# Quantized Signals\nplt.subplot(2, 1, 2)\nplt.plot(t_sampled, signal_sampled, 'bo-', alpha=0.5, label=\"Original Sampled\")\nplt.plot(t_sampled, signal_quantized_8bit, 'go-', label=\"Quantized 8-bit\")\nplt.plot(t_sampled, signal_quantized_4bit, 'ro-', label=\"Quantized 4-bit\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Quantization Effect\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#objective",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#objective",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Objective",
    "text": "Objective\n\nTo demonstrate, in the time domain, how a Linear Time-Invariant (LTI) system responds to a sinusoidal input.\nWe will start from the convolution integral and use Euler’s identity to show that the steady-state output remains sinusoidal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#system-definition",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#system-definition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "1. System Definition",
    "text": "1. System Definition\nA continuous-time LTI system is defined by:\n\\[\ny(t) = x(t) * h(t) = \\int_{-\\infty}^{\\infty} h(\\tau)\\,x(t - \\tau)\\,d\\tau\n\\]\nwhere -\\(x(t)\\)is the input, -\\(h(t)\\)is the impulse response, -\\(y(t)\\)is the output."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#sinusoidal-input",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#sinusoidal-input",
    "title": "Sistemas y Señales Biomédicos",
    "section": "2. Sinusoidal Input",
    "text": "2. Sinusoidal Input\nLet the input be a sinusoid:\n\\[\nx(t) = A \\cos(\\omega_0 t + \\phi)\n\\]\nUsing Euler’s identity:\n\\[\nx(t) = \\frac{A}{2} \\left[e^{j(\\omega_0 t + \\phi)} + e^{-j(\\omega_0 t + \\phi)}\\right]\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity-of-the-convolution-integral",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity-of-the-convolution-integral",
    "title": "Sistemas y Señales Biomédicos",
    "section": "3. Linearity of the Convolution Integral",
    "text": "3. Linearity of the Convolution Integral\nBecause the system is linear, we can treat each exponential term separately:\n\\[\ny(t) = \\frac{A}{2}\\left[ y_1(t) + y_2(t) \\right]\n\\] where \\[\ny_1(t) = e^{j\\phi} \\int_{-\\infty}^{\\infty} h(\\tau)\\, e^{j\\omega_0(t-\\tau)}\\, d\\tau\n\\] \\[\ny_2(t) = e^{-j\\phi} \\int_{-\\infty}^{\\infty} h(\\tau)\\, e^{-j\\omega_0(t-\\tau)}\\, d\\tau\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#simplifying-each-integral",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#simplifying-each-integral",
    "title": "Sistemas y Señales Biomédicos",
    "section": "4. Simplifying Each Integral",
    "text": "4. Simplifying Each Integral\nWe can factor out the term\\(e^{j\\omega_0 t}\\):\n\\[\ny_1(t) = e^{j\\phi} e^{j\\omega_0 t} \\int_{-\\infty}^{\\infty} h(\\tau)\\, e^{-j\\omega_0 \\tau}\\, d\\tau\n\\]\nLet \\[\nH_1 = \\int_{-\\infty}^{\\infty} h(\\tau)\\, e^{-j\\omega_0 \\tau}\\, d\\tau\n\\]\nThen, \\[\ny_1(t) = e^{j\\phi} H_1 e^{j\\omega_0 t}\n\\]\nSimilarly, \\[\ny_2(t) = e^{-j\\phi} H_1^* e^{-j\\omega_0 t}\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#combine-the-two-parts",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#combine-the-two-parts",
    "title": "Sistemas y Señales Biomédicos",
    "section": "5. Combine the Two Parts",
    "text": "5. Combine the Two Parts\nThe total output is:\n\\[\ny(t) = \\frac{A}{2}\\left[e^{j\\phi} H_1 e^{j\\omega_0 t} + e^{-j\\phi} H_1^* e^{-j\\omega_0 t}\\right]\n\\]\nIf we express\\(H_1\\)in polar form: \\[\nH_1 = |H_1| e^{j\\theta}\n\\]\nThen, \\[\ny(t) = A |H_1| \\cos(\\omega_0 t + \\phi + \\theta)\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#interpretation-in-time-domain",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#interpretation-in-time-domain",
    "title": "Sistemas y Señales Biomédicos",
    "section": "6. Interpretation in Time Domain",
    "text": "6. Interpretation in Time Domain\n\nThe output is a cosine at the same frequency\\(\\omega_0\\)as the input.\nIts amplitude is scaled by\\(|H_1|\\), which depends on\\(h(t)\\).\nIts phase is shifted by\\(\\theta\\), the argument of\\(H_1\\).\n\n\\[\n\\boxed{y(t) = A |H_1| \\cos(\\omega_0 t + \\phi + \\theta)}\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#system-definition-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#system-definition-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "1. System Definition",
    "text": "1. System Definition\nA discrete-time LTI system is defined by the convolution sum:\n\\[\ny[n] = \\sum_{k=-\\infty}^{\\infty} h[k]\\,x[n - k]\n\\]\nwhere - \\(x[n]\\) is the input sequence, - \\(h[k]\\) is the impulse response, - \\(y[n]\\) is the output sequence."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#sinusoidal-input-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#sinusoidal-input-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "2. Sinusoidal Input",
    "text": "2. Sinusoidal Input\nLet the input be a discrete sinusoid:\n\\[\nx[n] = A \\cos(\\omega_0 n + \\phi)\n\\]\nUsing Euler’s identity:\n\\[\nx[n] = \\frac{A}{2}\\left[e^{j(\\omega_0 n + \\phi)} + e^{-j(\\omega_0 n + \\phi)}\\right]\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity-of-the-convolution-sum",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity-of-the-convolution-sum",
    "title": "Sistemas y Señales Biomédicos",
    "section": "3. Linearity of the Convolution Sum",
    "text": "3. Linearity of the Convolution Sum\nBecause the system is linear, each exponential term can be treated independently:\n\\[\ny[n] = \\frac{A}{2}\\left[y_1[n] + y_2[n]\\right]\n\\]\nwhere \\[\ny_1[n] = e^{j\\phi} \\sum_{k=-\\infty}^{\\infty} h[k]\\, e^{j\\omega_0 (n - k)}\n\\] \\[\ny_2[n] = e^{-j\\phi} \\sum_{k=-\\infty}^{\\infty} h[k]\\, e^{-j\\omega_0 (n - k)}\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#simplifying-each-sum",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#simplifying-each-sum",
    "title": "Sistemas y Señales Biomédicos",
    "section": "4. Simplifying Each Sum",
    "text": "4. Simplifying Each Sum\nWe can factor out \\(e^{j\\omega_0 n}\\):\n\\[\ny_1[n] = e^{j\\phi} e^{j\\omega_0 n} \\sum_{k=-\\infty}^{\\infty} h[k]\\, e^{-j\\omega_0 k}\n\\]\nLet \\[\nH_1 = \\sum_{k=-\\infty}^{\\infty} h[k]\\, e^{-j\\omega_0 k}\n\\]\nThen, \\[\ny_1[n] = e^{j\\phi} H_1 e^{j\\omega_0 n}\n\\]\nSimilarly, \\[\ny_2[n] = e^{-j\\phi} H_1^* e^{-j\\omega_0 n}\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#combine-the-two-parts-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#combine-the-two-parts-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "5. Combine the Two Parts",
    "text": "5. Combine the Two Parts\nThe total output becomes:\n\\[\ny[n] = \\frac{A}{2}\\left[e^{j\\phi} H_1 e^{j\\omega_0 n} + e^{-j\\phi} H_1^* e^{-j\\omega_0 n}\\right]\n\\]\nIf we write \\(H_1\\) in polar form: \\[\nH_1 = |H_1| e^{j\\theta}\n\\]\nThen, \\[\ny[n] = A |H_1| \\cos(\\omega_0 n + \\phi + \\theta)\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#interpretation-in-time-domain-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#interpretation-in-time-domain-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "6. Interpretation in Time Domain",
    "text": "6. Interpretation in Time Domain\n\nThe output remains sinusoidal with the same frequency \\(\\omega_0\\).\nIts amplitude is scaled by \\(|H_1|\\).\nIts phase is shifted by \\(\\theta\\).\n\n\\[\n\\boxed{y[n] = A |H_1| \\cos(\\omega_0 n + \\phi + \\theta)}\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction",
    "text": "Introduction\n\nSignals can be analyzed in both time domain and frequency domain.\nThe frequency content of a signal describes how different frequency components contribute to the overall signal.\nApplications in biomedical signals, audio processing, communications, and image processing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-in-time-domain",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-in-time-domain",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution in Time Domain",
    "text": "Convolution in Time Domain\n\nConvolution is a fundamental operation in signal processing.\nGiven two signals\\(x(t)\\)and\\(h(t)\\), their convolution is defined as:\n\n\\[y(t) = x(t) * h(t) = \\int_{-\\infty}^{\\infty} x(\\tau) h(t - \\tau) d\\tau\\]\n\nIn discrete-time, convolution is:\n\n\\[y[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n-k]\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-theorem",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution Theorem",
    "text": "Convolution Theorem\n\nConvolution in time domain corresponds to multiplication in frequency domain:\n\n\\[X(f) H(f) = Y(f)\\]\n\nThis property is crucial in filter design and system analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\n\n(-1.0, 4.0)\n\n\n(-1.0, 4.0)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#introduction-to-fourier-series-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to Fourier Series",
    "text": "Introduction to Fourier Series\n\nConvolution requiere the representation of the signal in a sum of impulse functions.\nFourier series represents periodic signals as a sum of sinusoids:\n\n\\[x(t) = \\sum_{n=-\\infty}^{\\infty} C_n e^{jn\\omega_0 t}\\]\nwhere\\(C_n\\)are the Fourier coefficients.\n\nDecomposing a signal into sinusoidal components allows frequency analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#fourier-coefficients",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#fourier-coefficients",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Fourier Coefficients",
    "text": "Fourier Coefficients\n\nThe Fourier coefficients\\(C_n\\)are computed as:\n\n\\[C_n = \\frac{1}{T} \\int_{0}^{T} x(t) e^{-jn\\omega_0 t} dt\\]\n\nDetermines how much of each frequency is present in the signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-fourier-series-expansion",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-fourier-series-expansion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example of Fourier Series Expansion",
    "text": "Example of Fourier Series Expansion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#definition-of-the-complex-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#definition-of-the-complex-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "1. Definition of the Complex Fourier Series",
    "text": "1. Definition of the Complex Fourier Series\nFor a periodic signal \\(x(t)\\) with period \\(T\\):\n\\[\nx(t) = \\sum_{k=-\\infty}^{\\infty} c_k e^{j k \\Omega_0 t},\n\\]\nwhere:\n\\[\nc_k = \\frac{1}{T} \\int_{T_0}^{T_0 + T} x(t)e^{-jk\\Omega_0 t}\\,dt, \\quad\n\\Omega_0 = \\frac{2\\pi}{T}.\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-signal",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-signal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "2. Example Signal",
    "text": "2. Example Signal\nWe define a periodic signal \\(x(t)\\) with period \\(2\\pi\\):\n\\[\nx(t) =\n\\begin{cases}\n0, & -\\pi \\le t &lt; 0,\\\\\n1, & 0 \\le t &lt; \\pi.\n\\end{cases}\n\\]\nThis corresponds to a 50% duty cycle pulse."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#symbolic-derivation-using-sympy",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#symbolic-derivation-using-sympy",
    "title": "Sistemas y Señales Biomédicos",
    "section": "3. Symbolic Derivation using SymPy",
    "text": "3. Symbolic Derivation using SymPy\nExpected result:\n\\[\nc_k =\n\\begin{cases}\n\\dfrac{1}{2}, & k=0,\\\\[4pt]\n\\dfrac{j\\left((-1)^k - 1\\right)}{2\\pi k}, & k \\ne 0.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#numerical-evaluation-numpy",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#numerical-evaluation-numpy",
    "title": "Sistemas y Señales Biomédicos",
    "section": "4. Numerical Evaluation (NumPy)",
    "text": "4. Numerical Evaluation (NumPy)\n\nimport numpy as np\nimport pandas as pd\n\ndef ck_numeric(k):\n    k = np.asarray(k, dtype=float)\n    return np.where(\n        k != 0,\n        1j*(np.exp(1j*np.pi*k)-1)/(2*np.pi*k),\n        0.5\n    )\n\nK = 10\nks = np.arange(-K, K+1)\ncks = ck_numeric(ks)\n\npd.DataFrame({\n    \"k\": ks,\n    \"Re{c_k}\": np.real(cks),\n    \"Im{c_k}\": np.imag(cks),\n    \"|c_k|\": np.abs(cks)\n})\n\n     k       Re{c_k}   Im{c_k}         |c_k|\n0  -10  1.949086e-17 -0.000000  1.949086e-17\n1   -9 -1.949086e-17  0.035368  3.536777e-02\n2   -8  1.949086e-17 -0.000000  1.949086e-17\n3   -7 -1.949086e-17  0.045473  4.547284e-02\n4   -6  1.949086e-17 -0.000000  1.949086e-17\n5   -5 -1.949086e-17  0.063662  6.366198e-02\n6   -4  1.949086e-17 -0.000000  1.949086e-17\n7   -3 -1.949086e-17  0.106103  1.061033e-01\n8   -2  1.949086e-17 -0.000000  1.949086e-17\n9   -1 -1.949086e-17  0.318310  3.183099e-01\n10   0  5.000000e-01  0.000000  5.000000e-01\n11   1 -1.949086e-17 -0.318310  3.183099e-01\n12   2  1.949086e-17  0.000000  1.949086e-17\n13   3 -1.949086e-17 -0.106103  1.061033e-01\n14   4  1.949086e-17  0.000000  1.949086e-17\n15   5 -1.949086e-17 -0.063662  6.366198e-02\n16   6  1.949086e-17  0.000000  1.949086e-17\n17   7 -1.949086e-17 -0.045473  4.547284e-02\n18   8  1.949086e-17  0.000000  1.949086e-17\n19   9 -1.949086e-17 -0.035368  3.536777e-02\n20  10  1.949086e-17  0.000000  1.949086e-17"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#partial-sum-reconstruction",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#partial-sum-reconstruction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "5. Partial Sum Reconstruction",
    "text": "5. Partial Sum Reconstruction\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_numeric(t):\n    # Original pulse over [-π, π): 0 on [-π,0), 1 on [0,π).\n    tw = ((t + np.pi) % (2*np.pi)) - np.pi\n    return np.where((tw &gt;= 0) & (tw &lt; np.pi), 1.0, 0.0)\n\ndef partial_sum(t, N):\n    ks = np.arange(-N, N+1)\n    cks = ck_numeric(ks)\n    return np.sum(cks[:, None] * np.exp(1j*np.outer(ks, t)), axis=0)\n\ntgrid = np.linspace(-2*np.pi, 2*np.pi, 4000, endpoint=False)\nxg = x_numeric(tgrid)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#reconstruction-for-n-5",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#reconstruction-for-n-5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "6. Reconstruction for N = 5",
    "text": "6. Reconstruction for N = 5\n\nN1 = 5\nsN1 = partial_sum(tgrid, N1).real\n\nplt.figure(figsize=(8,3))\nplt.plot(tgrid, xg, label='x(t) original')\nplt.plot(tgrid, sN1, label=f'N={N1}')\nplt.xlim([-2*np.pi, 2*np.pi])\n\n(-6.283185307179586, 6.283185307179586)\n\nplt.legend()\nplt.title(\"Partial Sum Reconstruction (N=5)\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#reconstruction-for-n-20",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#reconstruction-for-n-20",
    "title": "Sistemas y Señales Biomédicos",
    "section": "7. Reconstruction for N = 20",
    "text": "7. Reconstruction for N = 20\n\n\n(-6.283185307179586, 6.283185307179586)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#reconstruction-for-n-100",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#reconstruction-for-n-100",
    "title": "Sistemas y Señales Biomédicos",
    "section": "7. Reconstruction for N = 100",
    "text": "7. Reconstruction for N = 100\n\n\n(-6.283185307179586, 6.283185307179586)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#discussion",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#discussion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "8. Discussion",
    "text": "8. Discussion\n\nThe average value \\(c_0 = 0.5\\) matches the mean level of the pulse.\nAs \\(N\\) increases, the reconstruction converges except near discontinuities.\nThe Gibbs phenomenon appears at the jump discontinuities.\nThe error \\(\\lVert x(t)-S_N(t)\\rVert_2\\) decreases with \\(N\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#summary",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#summary",
    "title": "Sistemas y Señales Biomédicos",
    "section": "9. Summary",
    "text": "9. Summary\n\n\n\n\n\n\n\nConcept\nExpression\n\n\n\n\nFundamental frequency\n\\(\\Omega_0 = \\frac{2\\pi}{T}\\)\n\n\nCoefficient \\(c_k\\)\n\\(\\frac{1}{T}\\int x(t)e^{-jk\\Omega_0 t}dt\\)\n\n\nReconstructed signal\n\\(S_N(t) = \\sum_{k=-N}^{N} c_k e^{jk\\Omega_0 t}\\)\n\n\nExample \\(x(t)\\)\nHalf-wave pulse in \\([-\\pi, \\pi)\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example 2 of Fourier Series",
    "text": "Example 2 of Fourier Series\n\n\n(array([-5.,  0.,  5., 10., 15., 20., 25., 30., 35.]), [Text(-5.0, 0, '−5'), Text(0.0, 0, '0'), Text(5.0, 0, '5'), Text(10.0, 0, '10'), Text(15.0, 0, '15'), Text(20.0, 0, '20'), Text(25.0, 0, '25'), Text(30.0, 0, '30'), Text(35.0, 0, '35')])\n\n\n(array([4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5]), [Text(0, 4.5, '4.5'), Text(0, 5.0, '5.0'), Text(0, 5.5, '5.5'), Text(0, 6.0, '6.0'), Text(0, 6.5, '6.5'), Text(0, 7.0, '7.0'), Text(0, 7.5, '7.5'), Text(0, 8.0, '8.0'), Text(0, 8.5, '8.5')])"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series-1",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-2-of-fourier-series-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example 2 of Fourier Series",
    "text": "Example 2 of Fourier Series\n\n\n(array([-40., -30., -20., -10.,   0.,  10.,  20.,  30.,  40.]), [Text(-40.0, 0, '−40'), Text(-30.0, 0, '−30'), Text(-20.0, 0, '−20'), Text(-10.0, 0, '−10'), Text(0.0, 0, '0'), Text(10.0, 0, '10'), Text(20.0, 0, '20'), Text(30.0, 0, '30'), Text(40.0, 0, '40')])\n\n\n(array([4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5, 8. , 8.5]), [Text(0, 4.5, '4.5'), Text(0, 5.0, '5.0'), Text(0, 5.5, '5.5'), Text(0, 6.0, '6.0'), Text(0, 6.5, '6.5'), Text(0, 7.0, '7.0'), Text(0, 7.5, '7.5'), Text(0, 8.0, '8.0'), Text(0, 8.5, '8.5')])"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#linearity",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Linearity",
    "text": "Linearity\n\nIf\\(f_1(x)\\)and\\(f_2(x)\\)have Fourier series,\nThen for any constants\\(a, b\\), -\\(a f_1(x) + b f_2(x)\\)has a Fourier series,\nWith coefficients scaled accordingly."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#time-shifting",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#time-shifting",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Time Shifting",
    "text": "Time Shifting\n\nIf\\(f(x)\\)has Fourier coefficients\\(a_n, b_n\\),\nThen\\(f(x - x_0)\\)has coefficients: -\\(a_n \\cos(n\\omega x_0) + b_n \\sin(n\\omega x_0)\\),\nAnd\\(b_n \\cos(n\\omega x_0) - a_n \\sin(n\\omega x_0)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-scaling",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-scaling",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Frequency Scaling",
    "text": "Frequency Scaling\n\nIf\\(g(x) = f(cx)\\),\nThen the period scales by\\(c\\),\nThe fundamental frequency changes to\\(c\\omega\\),\nFourier coefficients adjust accordingly."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#differentiation-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#differentiation-property",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Differentiation Property",
    "text": "Differentiation Property\n\nIf\\(f(x)\\)is differentiable,\nThen\\(f'(x)\\)has Fourier series,\nWith coefficients scaled as\\(n a_n, n b_n\\),\nHigher frequencies get amplified."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#integration-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#integration-property",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Integration Property",
    "text": "Integration Property\n\nIf\\(f(x)\\)has a Fourier series,\nThen\\(\\int f(x) dx\\)has a Fourier series,\nWith coefficients scaled as\\(\\frac{a_n}{n}, \\frac{b_n}{n}\\),\nLower frequencies get emphasized."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#parsevals-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#parsevals-theorem",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Parseval’s Theorem",
    "text": "Parseval’s Theorem\n\nThe total signal energy is conserved,\nEnergy in time domain equals energy in frequency domain,\nGiven by: -\\(\\sum (a_n^2 + b_n^2) = \\frac{1}{T} \\int |f(x)|^2 dx\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-property",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#convolution-property",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Convolution Property",
    "text": "Convolution Property\n\nConvolution in time domain,\nIs multiplication in Fourier series coefficients,\nIf\\(f_1\\)and\\(f_2\\)are convoluted,\nTheir Fourier coefficients multiply component-wise."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#discrete-time-fourier-series",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#discrete-time-fourier-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Discrete Time Fourier Series",
    "text": "Discrete Time Fourier Series\n\nRepresents periodic discrete signals using harmonics.\nExtends Fourier series to discrete-time domain.\nFundamental in digital signal processing.\nBasis for the Discrete Fourier Transform (DFT)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-expression",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-expression",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Mathematical Expression",
    "text": "Mathematical Expression\n\nA periodic sequence\\(x[n]\\)can be expressed as: -\\[x[n] = \\sum_{k=0}^{N-1} C_k e^{j(2\\pi k n / N)}\\].\nThe coefficients\\(C_k\\)are computed as: -\\(C_k = \\frac{1}{N} \\sum_{n=0}^{N-1} x[n] e^{-j(2\\pi k n / N)}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#periodicity-and-symmetry",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#periodicity-and-symmetry",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Periodicity and Symmetry",
    "text": "Periodicity and Symmetry\n\nThe coefficients\\(C_k\\)repeat every\\(N\\).\nEnsures correct reconstruction of signals.\nExplains frequency domain representation.\nBasis for spectral analysis."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#key-properties",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#key-properties",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Key Properties",
    "text": "Key Properties\n\nLinearity: Superposition holds.\nTime Shift: Causes phase shift in coefficients.\nParseval’s Theorem: Energy conservation.\nConvolution: Time convolution → Frequency multiplication."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-domain-interpretation",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-domain-interpretation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Frequency Domain Interpretation",
    "text": "Frequency Domain Interpretation\n-\\(C_k\\)represents discrete frequency content. - The spectrum consists of\\(N\\)harmonics. - Resolution improves with larger\\(N\\). - Essential for analyzing periodic discrete signals."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#comparison-with-continuous-case",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#comparison-with-continuous-case",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Comparison with Continuous Case",
    "text": "Comparison with Continuous Case\n\nDTFS applies to discrete periodic signals.\nContinuous Fourier series applies to continuous functions.\nBoth represent signals as sums of sinusoids.\nDTFS is used in digital communications and audio processing."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-th-dtfs",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-of-th-dtfs",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example of th DTFS",
    "text": "Example of th DTFS\n\n\n\nDTFS Coefficients:\n\n\nC[0] = 2.0000+0.0000j\nC[1] = -0.6036-0.6036j\nC[2] = 0.0000+0.0000j\nC[3] = 0.1036-0.1036j\nC[4] = 0.0000+0.0000j\nC[5] = 0.1036+0.1036j\nC[6] = 0.0000+0.0000j\nC[7] = -0.6036+0.6036j"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-02",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#example-02",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example 02",
    "text": "Example 02"
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#conceptual-foundation",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#conceptual-foundation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Conceptual Foundation",
    "text": "Conceptual Foundation\n\nFourier Series represents periodic signals in terms of sinusoids.\nAs period\\(T \\to \\infty\\), the signal becomes aperiodic.\nThe Fourier Transform generalizes Fourier Series to aperiodic signals.\nTransforms signals from time to frequency domain."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-transition",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#mathematical-transition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Mathematical Transition",
    "text": "Mathematical Transition\n\nFourier Series of a periodic signal: -\\[f(x) = \\sum_{n=-\\infty}^{\\infty} C_n e^{j(2\\pi n x / T)}\\].\nAs\\(T \\to \\infty\\), frequency spacing\\(\\frac{1}{T}\\)→ differential.\nLeads to the Fourier Transform: -\\[F(\\omega) = \\int_{-\\infty}^{\\infty} f(x) e^{-j\\omega x} dx\\]."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-spectrum-interpretation",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#frequency-spectrum-interpretation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Frequency Spectrum Interpretation",
    "text": "Frequency Spectrum Interpretation\n\nFourier Series: discrete frequency spectrum.\nFourier Transform: continuous frequency spectrum.\nCoefficients\\(C_n\\)become the function\\(F(\\omega)\\).\nAllows analysis of arbitrary signals in frequency domain."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#inverse-fourier-transform",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#inverse-fourier-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Inverse Fourier Transform",
    "text": "Inverse Fourier Transform\n\nRecovers time-domain signal from\\(F(\\omega)\\).\nDefined as: -\\[f(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} F(\\omega) e^{j\\omega x} d\\omega\\].\nEnsures complete information preservation.\nBasis for signal reconstruction in DSP."
  },
  {
    "objectID": "presentaciones/SYSB/Lect008_FrequencyContent.html#energy-and-parsevals-theorem",
    "href": "presentaciones/SYSB/Lect008_FrequencyContent.html#energy-and-parsevals-theorem",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Energy and Parseval’s Theorem",
    "text": "Energy and Parseval’s Theorem\n\nEnergy conservation in time and frequency domains.\nParseval’s theorem states: -\\[\\int |f(x)|^2 dx = \\frac{1}{2\\pi} \\int |F(\\omega)|^2 d\\omega\\]\nEnsures no energy loss between domains."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#review-ft-continuous-vs.-dtft-discrete",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#review-ft-continuous-vs.-dtft-discrete",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Review: FT (Continuous) vs. DTFT (Discrete)",
    "text": "Review: FT (Continuous) vs. DTFT (Discrete)\n\n\n\nFourier Transform (FT)\n(Continuous-Time)\n. . .\nSignal Domain: Continuous signal: \\(x(t)\\)\n. . .\nDefinition (Analysis): \\[X(j\\Omega) = \\int_{-\\infty}^{\\infty} x(t) e^{-j\\Omega t} dt\\]\n. . .\nFrequency Variable: \\(\\Omega\\) (Continuous frequency, [rad/s])\n. . .\nSpectrum Nature: The spectrum \\(X(j\\Omega)\\) is: * Continuous * Aperiodic\n. . .\n\nDiscrete-Time Fourier Transform (DTFT)\n. . .\nSignal Domain: Discrete signal: \\(x[n]\\)\n. . .\nDefinition (Analysis): \\[X(e^{j\\omega}) = \\sum_{n=-\\infty}^{\\infty} x[n] e^{-j\\omega n}\\]\n. . .\nFrequency Variable: \\(\\omega\\) (Normalized frequency, [rad/sample])\n. . .\nSpectrum Nature: The spectrum \\(X(e^{j\\omega})\\) is: * Continuous * Periodic (with period \\(2\\pi\\))\n. . .\n\n\n\nThe Bridge: The DTFT is the Z-Transform, \\(X(z)\\), evaluated precisely on the unit circle (\\(z = e^{j\\omega}\\))."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-the-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-the-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Why the Z-Transform?",
    "text": "Why the Z-Transform?\n\nThe Fourier Transform assumes signals are stable and well-behaved\nBut some biosignals or systems may not be absolutely summable\nThe Z-Transform generalizes the Fourier Transform\nUseful for analyzing discrete-time systems, especially when stability and causality matter"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#definition",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#definition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Definition",
    "text": "Definition\nLet \\(x[n]\\) be a discrete-time signal.\nThe Z-Transform is defined as:\n\\[X(z) = \\sum_{n=-\\infty}^{\\infty} x[n] z^{-n}\\]\nWhere: - \\(z \\in \\mathbb{C}\\) is a complex variable - \\(z = re^{j\\omega}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#region-of-convergence-roc",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#region-of-convergence-roc",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Region of Convergence (ROC)",
    "text": "Region of Convergence (ROC)\n\nThe Z-Transform converges only for certain values of \\(z\\)\nThe set of \\(z\\) for which the series converges is the ROC\nROC is critical for system stability and causality\n\n\n\nCausal Signals ROC is outside outermost pole\nAnti-Causal Signals ROC is inside innermost pole"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-plane-representation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-plane-representation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Z-Plane Representation",
    "text": "Z-Plane Representation\n\nPoles: values of \\(z\\) where \\(X(z) \\to \\infty\\)\nZeros: values where \\(X(z) = 0\\)\nVisualization of poles and zeros helps in understanding system behavior\n\n\nTransfer functionZPK (Zero-Pole-Kernel) Representation\n\n\n\\[H(z) = 1.00 \\cdot \\frac{(z - 0.50)}{(z - 0.90)}\\]\n\n\n\n\n(-1.5, 1.5)\n\n\n(-1.5, 1.5)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relationship-with-fourier-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relationship-with-fourier-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Relationship with Fourier Transform",
    "text": "Relationship with Fourier Transform\nIf the ROC includes the unit circle, \\(|z| = 1\\), then:\n\\[X(e^{j\\omega}) = \\sum_{n=-\\infty}^{\\infty} x[n] e^{-j\\omega n}\\]\nSo the Fourier Transform is a special case of the Z-Transform."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-signal",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-signal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example Signal",
    "text": "Example Signal\nLet:\n\\[x[n] = a^n u[n]\\]\nWhere: - \\(a \\in \\mathbb{R}\\) - \\(u[n]\\) is the unit step function (0 for \\(n&lt;0\\), 1 for \\(n\\geq 0\\))"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Z-Transform",
    "text": "Step 1: Z-Transform\nApply the definition:\n\\[X(z) = \\sum_{n=0}^{\\infty} a^n z^{-n}\n= \\sum_{n=0}^{\\infty} (az^{-1})^n\\]\nThis is a geometric series:\n\\[X(z) = \\frac{1}{1 - az^{-1}} = \\frac{z}{z - a}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#what-is-a-geometric-series",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#what-is-a-geometric-series",
    "title": "Sistemas y Señales Biomédicos",
    "section": "What is a Geometric Series?",
    "text": "What is a Geometric Series?\nA geometric series is a sum of terms where each term is multiplied by the same constant:\n\\[S = \\sum_{n=0}^{\\infty} r^n = 1 + r + r^2 + r^3 + \\cdots\\]\nThe value of \\(r\\) determines whether this sum converges (has a finite limit) or diverges."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#goal",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#goal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Goal",
    "text": "Goal\nUnderstand why this series:\n\\[\\sum_{n=0}^{\\infty} r^n\\]\nconverges if and only if:\n\\[\\boxed{|r| &lt; 1}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#partial-sums",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#partial-sums",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Partial Sums",
    "text": "Partial Sums\nLet’s consider the sum up to the \\(N\\)-th term:\n\\[S_N = \\sum_{n=0}^{N} r^n = 1 + r + r^2 + \\cdots + r^N\\]\nThis has a closed-form expression:\n\\[S_N = \\frac{1 - r^{N+1}}{1 - r} \\quad \\text{for } r \\neq 1\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#taking-the-limit",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#taking-the-limit",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Taking the Limit",
    "text": "Taking the Limit\nTo find the sum of the infinite series, take the limit as \\(N \\to \\infty\\):\n\\[S = \\lim_{N \\to \\infty} S_N = \\lim_{N \\to \\infty} \\frac{1 - r^{N+1}}{1 - r}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-1-r-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-1-r-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Case 1: \\(|r| < 1\\)",
    "text": "Case 1: \\(|r| &lt; 1\\)\nIf \\(|r| &lt; 1\\), then:\n\\[r^{N+1} \\to 0 \\quad \\text{as } N \\to \\infty\\]\nSo the sum becomes:\n\\[S = \\frac{1}{1 - r}\\]\n✅ The geometric series converges."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-2-r-geq-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#case-2-r-geq-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Case 2: \\(|r| \\geq 1\\)",
    "text": "Case 2: \\(|r| \\geq 1\\)\n\nIf \\(r = 1\\), then \\(S_N = N + 1 \\to \\infty\\)\nIf \\(r = -1\\), the sum oscillates: \\(1 - 1 + 1 - 1 + \\cdots\\)\nIf \\(|r| &gt; 1\\), then \\(r^{N+1} \\to \\infty\\)\n\n❌ In all cases: the series diverges"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#intuition",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#intuition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Intuition",
    "text": "Intuition\n\nWhen \\(|r| &lt; 1\\), each term \\(r^n\\) gets smaller and smaller\nTheir total sum settles to a finite number\nWhen \\(|r| \\geq 1\\), the terms don’t vanish — the sum keeps growing or oscillating"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-r-0.5",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-r-0.5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example: \\(r = 0.5\\)",
    "text": "Example: \\(r = 0.5\\)\n\\[S = 1 + 0.5 + 0.25 + 0.125 + \\cdots = \\frac{1}{1 - 0.5} = 2\\]\nEvery term adds less. The sum “flattens out.”"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-this-matters",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#why-this-matters",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Why This Matters",
    "text": "Why This Matters\nThe Z-Transform often gives us geometric series like:\n\\[\\sum_{n=0}^{\\infty} (az^{-1})^n\\]\nThis converges only if:\n\\[|az^{-1}| &lt; 1 \\Rightarrow |z| &gt; |a|\\]\nSo, understanding convergence of geometric series = understanding ROC in Z-transforms."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary",
    "text": "Summary\n\n\n\nCondition\nBehavior\nResult\n\n\n\n\n\\(|r| &lt; 1\\)\nTerms shrink\nSeries converges\n\n\n\\(|r| \\geq 1\\)\nTerms grow or oscillate\nDiverges\n\n\n\n\\[\\sum_{n=0}^{\\infty} r^n = \\frac{1}{1 - r} \\quad \\text{if } |r| &lt; 1\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-region-of-convergence-roc",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-region-of-convergence-roc",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Region of Convergence (ROC)",
    "text": "Step 2: Region of Convergence (ROC)\nFor convergence of the geometric series:\n\\[|az^{-1}| &lt; 1 \\Rightarrow |z| &gt; |a|\\]\nTherefore, the ROC is:\n\\[\\boxed{|z| &gt; |a|}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#interpretation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#interpretation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Interpretation",
    "text": "Interpretation\n\nCausal signal (defined for \\(n \\geq 0\\))\nROC is outside the outermost pole\nStable system only if ROC includes the unit circle \\(|z| = 1\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-a-0.5",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-a-0.5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example: \\(a = 0.5\\)",
    "text": "Example: \\(a = 0.5\\)\n\\[x[n] = (0.5)^n u[n]\\]\nZ-Transform:\n\\[X(z) = \\sum_{n=0}^{\\infty} (0.5)^n z^{-n} = \\frac{z}{z - 0.5}\\]\nRegion of Convergence:\n\\[\\boxed{|z| &gt; 0.5}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\nSignal\nZ-Transform\nROC\n\n\n\n\n\\(x[n] = a^n u[n]\\)\n\\(\\frac{z}{z - a}\\)\n\\(|z| &gt; |a|\\)\n\n\nExample: \\(a = 0.5\\)\n\\(\\frac{z}{z - 0.5}\\)\n\\(|z| &gt; 0.5\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#properties-of-the-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#properties-of-the-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Properties of the Z-Transform",
    "text": "Properties of the Z-Transform\n\nLinearity: \\(a x[n] + b y[n] \\to aX(z) + bY(z)\\)\nTime shifting: \\(x[n - k] \\to z^{-k} X(z)\\)\nScaling in the z-domain: \\(a^n x[n] \\to X(z/a)\\)\nConvolution: \\(x[n] * h[n] \\to X(z)H(z)\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\nLet \\(x[n] = a^n u[n]\\), where \\(|a| &lt; 1\\)\n\\[X(z) = \\sum_{n=0}^{\\infty} a^n z^{-n} = \\frac{1}{1 - az^{-1}}, \\quad \\text{ROC: } |z| &gt; |a|\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#difference-equations-in-dsp",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#difference-equations-in-dsp",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Difference Equations in DSP",
    "text": "Difference Equations in DSP\nA difference equation relates input and output values at different time steps.\n\\[y[n] - a_1 y[n-1] - a_2 y[n-2] = b_0 x[n] + b_1 x[n-1]\\]\nCommon in: - Digital filters (FIR, IIR) - Signal models in ECG, EEG analysis - Implementation in real-time biosignal systems"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-transform-of-time-shifted-terms",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#z-transform-of-time-shifted-terms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Z-Transform of Time-Shifted Terms",
    "text": "Z-Transform of Time-Shifted Terms\nThe Z-Transform turns time shifts into powers of \\(z^{-1}\\):\n\n\n\nTime Domain\nZ-Domain\n\n\n\n\n\\(x[n]\\)\n\\(X(z)\\)\n\n\n\\(x[n-k]\\)\n\\(z^{-k} X(z)\\)\n\n\n\\(y[n-k]\\)\n\\(z^{-k} Y(z)\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-apply-z-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-apply-z-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Apply Z-Transform",
    "text": "Step 1: Apply Z-Transform\nGiven:\n\\[y[n] - a_1 y[n-1] - a_2 y[n-2] = b_0 x[n] + b_1 x[n-1]\\]\nApply \\(\\mathcal{Z} \\{ \\cdot \\}\\):\n\\[Y(z) - a_1 z^{-1} Y(z) - a_2 z^{-2} Y(z) = b_0 X(z) + b_1 z^{-1} X(z)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-factor-and-solve-for-hz",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-factor-and-solve-for-hz",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Factor and Solve for \\(H(z)\\)",
    "text": "Step 2: Factor and Solve for \\(H(z)\\)\nGroup:\n\\[Y(z)(1 - a_1 z^{-1} - a_2 z^{-2}) = X(z)(b_0 + b_1 z^{-1})\\]\nDivide both sides:\n\\[H(z) = \\frac{Y(z)}{X(z)} = \\frac{b_0 + b_1 z^{-1}}{1 - a_1 z^{-1} - a_2 z^{-2}}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#example-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Example",
    "text": "Example\nGiven:\n\\[y[n] - 0.9 y[n-1] = x[n] - 0.5 x[n-1]\\]\nZ-Transform:\n\\[Y(z)(1 - 0.9 z^{-1}) = X(z)(1 - 0.5 z^{-1})\\]\nTransfer Function:\n\\[H(z) = \\frac{1 - 0.5 z^{-1}}{1 - 0.9 z^{-1}}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#poles-and-zeros",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#poles-and-zeros",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Poles and Zeros",
    "text": "Poles and Zeros\nLet’s analyze \\(H(z)\\):\n\nZeros: Roots of the numerator \\(\\Rightarrow z = 0.5\\)\nPoles: Roots of the denominator \\(\\Rightarrow z = 0.9\\)\n\n\n\nPole-Zero Plot Visualizes system behavior Check for: - Stability (poles inside unit circle) - Frequency shaping"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#practice",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#practice",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Practice",
    "text": "Practice\nConvert this equation:\n\\[y[n] = 0.6 y[n-1] + x[n] + x[n-1]\\]\nFind: - \\(H(z)\\) - Poles and zeros - Plot them in the Z-plane"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#application-in-biosignal-processing",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#application-in-biosignal-processing",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Application in Biosignal Processing",
    "text": "Application in Biosignal Processing\n\nAnalysis of digital filters for ECG, EEG, etc.\nDesign of stable and causal filtering systems\nUseful in difference equation modeling of biosignals"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-2",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary",
    "text": "Summary\n\nZ-Transform is a powerful tool for analyzing discrete systems\nProvides insight into stability, causality, and system behavior\nA generalization of the Fourier Transform\nCrucial in digital signal processing of biosignals\nZ-Transform converts difference equations into algebraic expressions\nTransfer function \\(H(z)\\) tells us how the system responds to inputs\nKey for digital filter design in biosignal processing"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#next-steps",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#next-steps",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Next Steps",
    "text": "Next Steps\n\nPractice Z-Transform computations\nPole-zero plotting exercises\nApplication to real biosignal filtering problems"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n\n\n\n\n\n\nNotch Filter\n\n\nA common issue in biosignal processing is removing power‐line interference (50/60 Hz) from, for example, EEG or ECG signals. A simple digital filter to eliminate 60 Hz interference (assuming a sampling frequency \\(f_s = 5000\\) Hz) is to place complex‐conjugate zeros at\n\\[\nz = e^{\\pm j 2\\pi\\frac{60}{5000}}.\n\\]\nThe resulting transfer function can be written as\n\\[\nH(z) = 1 \\;-\\; 2\\cos\\!\\Bigl(2\\pi\\frac{60}{5000}\\Bigr)\\,z^{-1} \\;+\\; z^{-2}.\n\\]\nThis \\(H(z)\\) has zeros at \\(e^{\\pm j2\\pi(60/5000)}\\) that precisely cancel the 60 Hz component, thereby implementing a notch filter. Moreover, it is a second‐order FIR filter with symmetric coefficients, which grants it linear phase (important to avoid waveform distortion)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\ndef design_filter(zeros=None, poles=None, gain=1.0):\n    \"\"\"\n    Diseña un filtro digital a partir de ceros y/o polos y una ganancia.\n\n    Parámetros:\n    - zeros: lista de ceros (raíces del numerador), o None para no incluir\n    - poles: lista de polos (raíces del denominador), o None para no incluir\n    - gain: ganancia escalar del filtro\n\n    Devuelve:\n    - b: coeficientes del numerador\n    - a: coeficientes del denominador\n    \"\"\"\n    # Si no se pasan ceros, asumimos un FIR trivial (b = [gain])\n    if zeros:\n        b = gain * np.poly(zeros)\n    else:\n        b = np.array([gain], dtype=float)\n\n    # Si no se pasan polos, asumimos sistema FIR (a = [1])\n    if poles:\n        a = np.poly(poles)\n    else:\n        a = np.array([1.0], dtype=float)\n\n    return b, a"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-2",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\ndef gaussian(x, mu, sigma, A):\n    \"\"\"\n    Genera una función gaussiana.\n\n    Parámetros:\n    - x: array de tiempos\n    - mu: posición central de la gaussiana\n    - sigma: desviación estándar\n    - A: amplitud\n    \"\"\"\n    return A * np.exp(-((x - mu) ** 2) / (2 * sigma**2))"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-3",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-3",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\ndef simulate_ecg(duration=10.0, fs=500, heart_rate=60):\n    \"\"\"\n    Simula un ECG sintético basado en la superposición de ondas gaussianas.\n\n    Parámetros:\n    - duration: duración de la señal en segundos\n    - fs: frecuencia de muestreo en Hz\n    - heart_rate: frecuencia cardiaca en latidos por minuto\n\n    Devuelve:\n    - t: vector de tiempos\n    - ecg: señal simulada de ECG en mV\n    \"\"\"\n    dt = 1 / fs\n    t = np.arange(0, duration, dt)\n    rr = 60 / heart_rate  # intervalo RR en segundos\n\n    # Inicializar señal\n    ecg = np.zeros_like(t)\n\n    # Parámetros de las ondas (posiciones relativas en segundos)\n    # P wave\n    p_amp, p_dur, p_delay = 0.25, 0.09, 0.16\n    # Q wave\n    q_amp, q_dur, q_delay = -0.05, 0.066, 0.166\n    # R wave\n    r_amp, r_dur, r_delay = 1.6, 0.1, 0.166\n    # S wave\n    s_amp, s_dur, s_delay = -0.25, 0.066, 0.19\n    # T wave\n    t_amp, t_dur, t_delay = 0.35, 0.142, 0.36\n\n    # Generar cada latido\n    for beat_start in np.arange(0, duration, rr):\n        mask = (t &gt;= beat_start) & (t &lt; beat_start + rr)\n        tb = t[mask] - beat_start\n        ecg[mask] += gaussian(tb, p_delay, p_dur / 2, p_amp)\n        ecg[mask] += gaussian(tb, q_delay, q_dur / 2, q_amp)\n        ecg[mask] += gaussian(tb, r_delay, r_dur / 2, r_amp)\n        ecg[mask] += gaussian(tb, s_delay, s_dur / 2, s_amp)\n        ecg[mask] += gaussian(tb, t_delay, t_dur / 2, t_amp)\n\n    return t, ecg+0.1*np.cos(2*np.pi*60*t)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-4",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-4",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n# Parámetros de simulación\nDURATION = 10    # segundos\nFS = 500         # Hz\nHR = 70          # latidos por minuto\n\n# Generar señal\nt, ecg_signal = simulate_ecg(duration=DURATION, fs=FS, heart_rate=HR)\n\n# Graficar resultado\nplt.figure(figsize=(12, 4))\nplt.plot(t, ecg_signal, linewidth=1)\nplt.title(f'Señal de ECG sintética ({HR} bpm)')\nplt.xlabel('Tiempo (s)')\nplt.ylabel('Amplitud (mV)')\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-5",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-5",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\nn = len(ecg_signal)\nyf = np.fft.fft(ecg_signal)\nxf = np.fft.fftfreq(n, 1/fs)[:n//2]\nplt.plot(xf, 2.0/n * np.abs(yf[0:n//2]))\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-6",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-6",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\nfc = 60\nb,a =design_filter(zeros=[np.exp(1j*2*np.pi*fc/fs), np.exp(-1j*2*np.pi*fc/fs)])\nprint(a)\nprint(b)\n\nw, h = sig.freqz(a, b, worN=8000)\nplt.plot(w/np.pi*fs/2, 20*np.log10(abs(h)))\nplt.grid()\nplt.xlabel('Frequency (Hz)')"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-7",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-7",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n\n\n\n\n\n\nFIR filters\n\n\nFIR filters (Finite Impulse Response) are widely used in biomedical processing because they can be designed to have linear phase response, avoiding phase distortion in the filtered signal (which is useful for preserving the morphology of ECG waves, for example)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-8",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-8",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\n\n\n\n\n\n\nFilter Design Process\n\n\n\nDefining the desired ideal frequency response \\(H_d(e^{j\\omega})\\).\nObtaining the ideal impulse response \\(h_d[n]\\) as the inverse Fourier transform of \\(H_d\\).\nTruncating \\(h_d[n]\\) (which is usually infinite or very long) with a window function \\(w[n]\\) to obtain a realizable FIR filter\n\\[\nh[n] = h_d[n]\\,w[n].\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-9",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-9",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\nYou obtain \\(h_d[n]\\) as the inverse discrete–time Fourier transform of your ideal frequency response \\(H_d(e^{j\\omega})\\). For a low-pass filter with cutoff \\(\\omega_c\\),\n\\[\nH_d(e^{j\\omega}) =\n\\begin{cases}\n1, & |\\omega|\\le\\omega_c,\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\]\nBy definition of the inverse DTFT,\n\\[\nh_d[n] \\;=\\; \\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi} H_d(e^{j\\omega})\\,e^{j\\omega n}\\,d\\omega\n\\;=\\;\\frac{1}{2\\pi}\\int_{-\\omega_c}^{\\omega_c} e^{j\\omega n}\\,d\\omega.\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-10",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-10",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\nCarry out the integral in two cases:\n\nFor \\(n\\neq 0\\):\n\\[\nh_d[n]\n=\\frac{1}{2\\pi}\\,\\frac{e^{j\\omega n}}{j\\,n}\\Biggr|_{-\\omega_c}^{\\omega_c}\n=\\frac{1}{2\\pi}\\,\\frac{e^{j\\omega_c n}-e^{-j\\omega_c n}}{j\\,n}\n=\\frac{\\sin(\\omega_c\\,n)}{\\pi\\,n}.\n\\]\nFor \\(n=0\\):\n\\[\nh_d[0]\n=\\frac{1}{2\\pi}\\int_{-\\omega_c}^{\\omega_c} 1\\,d\\omega\n=\\frac{2\\,\\omega_c}{2\\pi}\n=\\frac{\\omega_c}{\\pi}.\n\\]\n\nPutting both together,\n\\[\nh_d[n]\n=\\begin{cases}\n\\dfrac{\\sin(\\omega_c\\,n)}{\\pi\\,n}, & n\\neq 0,\\\\[1em]\n\\dfrac{\\omega_c}{\\pi},                & n=0.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relating-to-sampling-frequency",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#relating-to-sampling-frequency",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Relating to sampling frequency",
    "text": "Relating to sampling frequency\nIf your cutoff is specified in Hz, \\(f_c\\), and sampling rate is \\(f_s\\), then\n\\[\n\\omega_c = 2\\pi\\,\\frac{f_c}{f_s},\n\\]\nso you can write\n\\[\nh_d[n]\n=\\frac{\\sin\\!\\bigl(2\\pi \\frac{f_c}{f_s}\\,n\\bigr)}{\\pi\\,n}\n=\\;2\\;\\frac{f_c}{f_s}\\;\\frac{\\sin\\!\\bigl(2\\pi \\frac{f_c}{f_s}\\,n\\bigr)}{2\\pi \\frac{f_c}{f_s}\\,n}\n=2\\frac{f_c}{f_s}\\,\\mathrm{sinc}\\!\\Bigl(2\\frac{f_c}{f_s}\\,n\\Bigr),\n\\]\nwhere we define the normalized sinc as \\(\\mathrm{sinc}(x)=\\frac{\\sin(\\pi x)}{\\pi x}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#key-takeaway",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#key-takeaway",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Key takeaway",
    "text": "Key takeaway\n\n\\(h_d[n]\\) is exactly the inverse‐DTFT of the ideal (“brick‐wall”) frequency specification.\nIt produces a sinc-shaped impulse response of infinite length.\nTruncation (with a window) makes it realizable as a finite-length FIR."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-11",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-11",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\nThe typical characteristics of classic windows are:\n\nRectangular: narrowest main lobe (width ≈ 4π/M rad) but highest sidelobes (first sidelobe ≈ –13 dB, stop-band attenuation ≈ 21 dB). It gives the steepest transition for a given filter order, at the expense of poorer stop-band rejection.\nBartlett (triangular): somewhat wider main lobe (≈ 8π/M), sidelobes ≈ –25 dB.\nHann: main lobe ≈ 8π/M, sidelobes ≈ –31 dB (better rejection than rectangular but smoother transitions).\nHamming: main lobe ≈ 8π/M, sidelobes ≈ –41 dB (minimum stop-band attenuation ≈ 53 dB). Very popular for its good compromise between transition width and stop-band attenuation.\nBlackman: wider main lobe (≈ 12π/M) but very low sidelobes (≈ –57 dB, attenuation ≈ 74 dB).\nKaiser: allows selection of a parameter β to control sidelobe attenuation, offering flexibility. Approximately, to achieve A dB of attenuation,\n\\[\n  \\beta \\approx 0.1102\\,(A - 8.7)\\quad(\\text{for }A&gt;50),\n\\]\nand the normalized transition width Δω relates to the order M and β by\n\\[\n  M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\n\\]\n\nThese formulas stem from Kaiser’s approximations and help in sizing the filter."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#windows-forms",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#windows-forms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Windows Forms",
    "text": "Windows Forms\n\nTimeFrequencyCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(-100.0, 5.0)\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal.windows import (\n    boxcar,       # Rectangular\n    bartlett,    # Triangular\n    hann,        # Hann\n    hamming,     # Hamming\n    blackman,    # Blackman\n    kaiser       # Kaiser\n)\n\n# Parameters\nM = 64               # window length\nbeta = 8.6           # Kaiser parameter for moderate sidelobe attenuation\nnfft = 512           # FFT length for frequency response\nfs = 1.0             # normalized sampling rate\n\n# Generate windows\nwindows = {\n    'Rectangular': boxcar(M),\n    'Bartlett':    bartlett(M),\n    'Hann':        hann(M),\n    'Hamming':     hamming(M),\n    'Blackman':    blackman(M),\n    f'Kaiser (β={beta})': kaiser(M, beta)\n}\n\n# Time-domain plot\nplt.figure(figsize=(8, 4))\nfor name, w in windows.items():\n    plt.plot(np.arange(M), w, label=name)\nplt.title('Window Functions — Time Domain')\nplt.xlabel('Sample index n')\nplt.ylabel('Amplitude')\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.tight_layout()\n\n# Frequency-domain plot\nplt.figure(figsize=(8, 4))\nfor name, w in windows.items():\n    # Compute normalized frequency response\n    W = np.fft.fft(w, nfft)\n    W_mag = 20 * np.log10(np.abs(W) / np.max(np.abs(W)))\n    freqs = np.fft.fftfreq(nfft, d=1/fs)\n    # Only plot 0 ≤ f ≤ 0.5 (normalized Nyquist)\n    idx = np.logical_and(freqs &gt;= 0, freqs &lt;= 0.5)\n    plt.plot(freqs[idx], W_mag[idx], label=name)\nplt.title('Window Functions — Frequency Response')\nplt.xlabel('Normalized Frequency (cycles/sample)')\nplt.ylabel('Magnitude (dB)')\nplt.ylim(-100, 5)\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.tight_layout()\n\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-12",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#filter-design-12",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Filter Design",
    "text": "Filter Design\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nN = 101\nfc = 30\n\n# 2. Compute the ideal impulse response h_d[n] of a low-pass filter\nn = np.arange(N)\nM = (N - 1) / 2\n# Using the normalized sinc: sinc(x) = sin(pi*x)/(pi*x)\nh_d = (2 * fc / FS) * np.sinc(2 * fc * (n - M) / FS)\n\n# 3. Choose a window w[n] (here: Hamming) and truncate\nw = np.hamming(N)\nh = h_d * w\n\n# 4. Normalize to ensure unity gain at DC\nh /= np.sum(h)\n\n# 6. Filter it (only allowed library call)\ny = sig.lfilter(h, 1.0, ecg_signal)\n\n# 7. Plot input vs. output\nplt.figure(figsize=(8, 4))\nplt.plot(t, ecg_signal, label='Original signal')\nplt.plot(t, y, label='Filtered signal', linewidth=2)\nplt.xlabel('Time [s]')\nplt.ylabel('Amplitude')\nplt.title('Low-pass FIR (window method) – Cutoff 100 Hz')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-iir-filter-design-strategy",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#introduction-iir-filter-design-strategy",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction: IIR Filter Design Strategy",
    "text": "Introduction: IIR Filter Design Strategy\n\nGoal: Design digital Infinite Impulse Response (IIR) filters.\nApproach: Leverage well-established theory and techniques from analog filter design.\nMethod:\n\nDesign a suitable analog filter prototype \\(H(s)\\).\nTransform this analog design into a digital filter \\(H(z)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---laplace-transform",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---laplace-transform",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 0: The Analog Domain - Laplace Transform",
    "text": "Step 0: The Analog Domain - Laplace Transform\n\nContext: Continuous-time signals and Linear Time-Invariant (LTI) systems.\nTool: The Laplace Transform converts differential equations (time domain) to algebraic equations (s-domain).\nTransfer Function \\(H(s)\\): Represents the system in the s-domain. \\[H(s) = \\frac{Y(s)}{X(s)}\\] where \\(s = \\sigma + j\\Omega\\) is the complex frequency (\\(\\Omega\\) = analog angular frequency)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---s-plane-analysis",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---s-plane-analysis",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 0: The Analog Domain - s-Plane Analysis",
    "text": "Step 0: The Analog Domain - s-Plane Analysis\n\ns-Plane: Complex plane where \\(H(s)\\) is analyzed.\nPoles & Zeros: Roots of the denominator & numerator of \\(H(s)\\), respectively. Their locations determine filter behavior.\nFrequency Response: Determined by \\(H(j\\Omega)\\) (evaluating \\(H(s)\\) on the imaginary axis).\nStability: For a causal system to be stable, all poles must be in the Left-Half Plane (LHP), i.e., \\(\\text{Re}\\{s\\} &lt; 0\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---filter-prototypes",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-0-the-analog-domain---filter-prototypes",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 0: The Analog Domain - Filter Prototypes",
    "text": "Step 0: The Analog Domain - Filter Prototypes\n\nStandardized, well-understood analog filter approximations:\n\nButterworth: Maximally flat passband.\nChebyshev Type I: Equiripple passband, monotonic stopband.\nChebyshev Type II: Monotonic passband, equiripple stopband.\nElliptic (Cauer): Equiripple in both passband and stopband (sharpest transition for a given order).\n\nDesign usually starts with a normalized low-pass prototype."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#the-bridge-analog-to-digital-mapping",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#the-bridge-analog-to-digital-mapping",
    "title": "Sistemas y Señales Biomédicos",
    "section": "The Bridge: Analog-to-Digital Mapping",
    "text": "The Bridge: Analog-to-Digital Mapping\n\nCore Task: Convert the analog filter \\(H(s)\\) (s-plane) into a digital filter \\(H(z)\\) (z-plane).\nNeed a mapping that relates the continuous frequency \\(\\Omega\\) to the discrete frequency \\(\\omega\\).\nCrucially, the stable region (LHP in s-plane) should map to the stable region (inside the unit circle in z-plane)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Digital Filter Specifications",
    "text": "Step 1: Digital Filter Specifications\n\nDefine the desired characteristics of the digital filter:\n\nCritical Frequencies:\n\nPassband edge: \\(\\omega_p\\)\nStopband edge: \\(\\omega_s\\)\n(Normalized digital angular frequencies, e.g., \\(0 \\le \\omega \\le \\pi\\))\n\nTolerances:\n\nMax. passband ripple/attenuation: \\(A_p\\) (dB) or \\(\\delta_p\\)\nMin. stopband attenuation: \\(A_s\\) (dB) or \\(\\delta_s\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-transformation-methods---overview",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-transformation-methods---overview",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Transformation Methods - Overview",
    "text": "Step 2: Transformation Methods - Overview\n\nMathematical mappings from the s-plane to the z-plane.\nTwo primary methods:\n\nImpulse Invariance\nBilinear Transformation"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-1---impulse-invariance",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-1---impulse-invariance",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Method 1 - Impulse Invariance",
    "text": "Step 2: Method 1 - Impulse Invariance\n\nConcept: Match the impulse response: \\(h_{digital}[n] \\approx T \\cdot h_{analog}(nT)\\).\nMapping: Maps s-plane pole \\(s_k\\) to z-plane pole \\(z_k = e^{s_k T}\\).\n\nUses partial fraction expansion of \\(H(s)\\).\n\nPros: Preserves impulse response shape.\nCons: Suffers from frequency aliasing if \\(H(j\\Omega)\\) is not bandlimited below Nyquist frequency (\\(F_s/2\\)). Best for low-pass/band-pass filters."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-2---bilinear-transformation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-2-method-2---bilinear-transformation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 2: Method 2 - Bilinear Transformation",
    "text": "Step 2: Method 2 - Bilinear Transformation\n\nConcept: An algebraic substitution mapping the \\(j\\Omega\\) axis onto the unit circle.\nMapping Formula: \\[s = \\frac{2}{T} \\frac{1 - z^{-1}}{1 + z^{-1}}\\] (T = sampling period, often set to 2 for simplicity during derivation).\nPros:\n\nNo aliasing: Maps entire \\(j\\Omega\\) axis to the unit circle (\\(-\\pi \\le \\omega \\le \\pi\\)).\nPreserves stability: Maps LHP (stable s-region) to inside the unit circle (stable z-region).\n\nCons: Introduces non-linear frequency warping."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#understanding-frequency-warping-bilinear",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#understanding-frequency-warping-bilinear",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Understanding Frequency Warping (Bilinear)",
    "text": "Understanding Frequency Warping (Bilinear)\n\nThe relationship between analog (\\(\\Omega\\)) and digital (\\(\\omega\\)) frequencies is non-linear: \\[\\Omega = \\frac{2}{T} \\tan\\left(\\frac{\\omega T}{2}\\right)\\] or equivalently: \\[\\omega = 2 \\arctan\\left(\\frac{\\Omega T}{2}\\right)\\]\nThis compresses the infinite analog frequency axis onto the finite digital frequency range \\([-\\pi, \\pi]\\).\nThe mapping is non-uniform, most distorted near \\(\\omega = \\pm \\pi\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-3-frequency-pre-warping-bilinear-only",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-3-frequency-pre-warping-bilinear-only",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 3: Frequency Pre-warping (Bilinear Only)",
    "text": "Step 3: Frequency Pre-warping (Bilinear Only)\n\nProblem: Frequency warping distorts the locations of \\(\\omega_p\\) and \\(\\omega_s\\).\nSolution: Pre-warp the digital specifications (\\(\\omega_p, \\omega_s\\)) into corresponding analog frequencies (\\(\\Omega_p, \\Omega_s\\)) before designing the analog filter.\nFormula: Use the warping relationship: \\[\\Omega_p = \\frac{2}{T} \\tan\\left(\\frac{\\omega_p T}{2}\\right)\\] \\[\\Omega_s = \\frac{2}{T} \\tan\\left(\\frac{\\omega_s T}{2}\\right)\\]\nUse these \\(\\Omega_p, \\Omega_s\\) values for the analog design step."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-4-analog-prototype-design-workflow",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-4-analog-prototype-design-workflow",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 4: Analog Prototype Design Workflow",
    "text": "Step 4: Analog Prototype Design Workflow\n\nSelect Prototype: Choose Butterworth, Chebyshev, Elliptic based on specs (ripple, transition width) using the (pre-warped) \\(\\Omega_p, \\Omega_s, A_p, A_s\\).\nDetermine Order (N) & Cutoff (\\(\\Omega_c\\)): Calculate required analog filter order and cutoff frequency using prototype-specific formulas.\nFind Normalized LP \\(H_{LP}(s)\\): Obtain the transfer function for the normalized low-pass prototype.\nFrequency Transformation (Analog): If needed, transform \\(H_{LP}(s)\\) to target type (HP, BP, BS) using analog transformations.\n\nResult: The final analog filter transfer function \\(H_a(s)\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#analog-filter-design-overview",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#analog-filter-design-overview",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog Filter Design: Overview",
    "text": "Analog Filter Design: Overview\nDesigning an analog filter translates desired signal filtering characteristics into a physical electronic circuit.\nKey Stages:\n\nDefine Specifications\nChoose an Approximation Method\nDetermine Filter Order\nFind Normalized Low-Pass Prototype (Conceptual)\nDenormalize & Transform (Conceptual)\nSynthesize the Circuit\nComponent Selection & Simulation\n\nWe’ll illustrate steps 1, 3, and aspects of 4/5 using Python’s scipy.signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#define-filter-specifications",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#define-filter-specifications",
    "title": "Sistemas y Señales Biomédicos",
    "section": "1. Define Filter Specifications",
    "text": "1. Define Filter Specifications\nThis is the most crucial first step.\n\nType: Low-Pass (LPF), High-Pass (HPF), Band-Pass (BPF), Band-Stop (BSF).\nCritical Frequencies (Analog, \\(\\Omega\\) in rad/s or \\(f\\) in Hz):\n\nCutoff (\\(\\Omega_c, f_c\\))\nPassband Edge(s) (\\(\\Omega_p, f_p\\))\nStopband Edge(s) (\\(\\Omega_s, f_s\\))\n\nAttenuation Levels (dB):\n\nMax. Passband Attenuation/Ripple (\\(A_{max}\\) or gpass)\nMin. Stopband Attenuation (\\(A_{min}\\) or gstop)\n\nPhase Response: Linear phase (e.g., Bessel) or not critical.\nImpedance: Source/Load matching."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#specifications-python-example-low-pass",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#specifications-python-example-low-pass",
    "title": "Sistemas y Señales Biomédicos",
    "section": "1. Specifications: Python Example (Low-Pass)",
    "text": "1. Specifications: Python Example (Low-Pass)\nLet’s define specs for an analog low-pass filter. Frequencies for analog filters in scipy are typically in rad/s.\n\n\nPassband edge: 6283.19 rad/s (1000 Hz)\n\n\nStopband edge: 9424.78 rad/s (1500 Hz)\n\n\nMax Passband Loss: 1.0 dB\n\n\nMin Stopband Attenuation: 40.0 dB"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#choose-an-approximation-method-filter-family",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#choose-an-approximation-method-filter-family",
    "title": "Sistemas y Señales Biomédicos",
    "section": "2. Choose an Approximation Method (Filter Family)",
    "text": "2. Choose an Approximation Method (Filter Family)\nSelect based on trade-offs (roll-off, ripple, phase).\n\nButterworth: Maximally flat passband, smooth roll-off.\nChebyshev Type I: Steeper roll-off than Butterworth, passband ripple.\nChebyshev Type II: Steeper roll-off, stopband ripple, flat passband.\nElliptic (Cauer): Steepest roll-off, ripple in both bands.\nBessel-Thomson: Best phase linearity (constant group delay), slowest roll-off.\n\nFor our Python examples, we’ll use Butterworth."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-filter-fundamentals",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-filter-fundamentals",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth Filter Fundamentals",
    "text": "Butterworth Filter Fundamentals\nThe Butterworth filter is maximally flat in the passband.\nThe normalized prototype has a cutoff frequency \\(\\omega_c = 1\\) rad/s.\nPoles are placed on the unit circle in the \\(s\\)-plane at angles: \\[s_k = e^{j\\pi\\frac{2k + n - 1}{2n}}, \\quad k = 1,2,\\ldots,n.\\]\nThe Butterworth polynomial of order \\(n\\) is: \\[B_n(s) = \\prod_{k=1}^{n} (s - s_k).\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-lp-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-lp-transfer-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Lowpass (LP) Transfer Function",
    "text": "Normalized Lowpass (LP) Transfer Function\nThe normalized \\(n\\)th-order lowpass prototype is: \\[H_{LP}(s) = \\frac{1}{B_n(s)} = \\frac{1}{\\prod_{k=1}^n (s - s_k)}.\\] This yields a cutoff at \\(|H_{LP}(j1)| = 1/\\sqrt{2}\\) (the –3 dB point)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-highpass-hp-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-highpass-hp-transfer-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Highpass (HP) Transfer Function",
    "text": "Normalized Highpass (HP) Transfer Function\nApply the frequency transformation \\(s \\to 1/s\\) and multiply by \\(s^n\\): \\[H_{HP}(s) = H_{LP}(1/s)\\,s^n = \\frac{s^n}{B_n(1/s)} = \\frac{s^n}{\\prod_{k=1}^n (1/s - s_k)} = \\frac{\\prod_{k=1}^n(-s_k)\\;s^n}{\\prod_{k=1}^n(s - s_k^{-1})}.\\] This prototype has a normalized cutoff at \\(\\omega=1\\) rad/s in the highpass sense."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandpass-bp-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandpass-bp-transfer-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Bandpass (BP) Transfer Function",
    "text": "Normalized Bandpass (BP) Transfer Function\nUse the bandpass transformation: \\[s \\to \\frac{s^2 + \\Omega_0^2}{B\\,s},\\] where \\(\\Omega_0 = \\sqrt{\\omega_1\\omega_2}\\) and \\(B = \\omega_2 - \\omega_1\\).\nFor a normalized prototype, we set \\(\\Omega_0 = 1\\), \\(B = 1\\), giving: \\[H_{BP}(s) = H_{LP}\\left(\\frac{s^2 + 1}{s}\\right) = \\frac{(s)^n}{\\prod_{k=1}^n\\left(\\frac{s^2 + 1}{s} - s_k\\right)} = \\frac{s^n}{\\prod_{k=1}^n\\left(s^2 + 1 - s\\,s_k\\right)}.\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandstop-bs-transfer-function",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-bandstop-bs-transfer-function",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Bandstop (BS) Transfer Function",
    "text": "Normalized Bandstop (BS) Transfer Function\nUse the bandstop transformation: \\[s \\to \\frac{s}{\\frac{s^2 + 1}{s}} = \\frac{s^2}{s^2 + 1},\\] or equivalently \\(s \\to (B\\,s)/(s^2 + \\Omega_0^2)\\) with \\(B=1\\), \\(\\Omega_0=1\\). Then: \\[H_{BS}(s) = H_{LP}\\left(\\frac{s}{s^2 + 1}\\right) = \\frac{1}{B_n\\left(\\frac{s}{s^2+1}\\right)} = \\frac{1}{\\prod_{k=1}^n\\left(\\frac{s}{s^2+1} - s_k\\right)} = \\frac{(s^2+1)^n}{\\prod_{k=1}^n\\left(s - s_k(s^2+1)\\right)} = \\frac{(s^2+1)^n}{\\prod_{k=1}^n\\left(s - s_ks^2 - s_k\\right)}.\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n",
    "title": "Sistemas y Señales Biomédicos",
    "section": "3. Determine the Filter Order (N)",
    "text": "3. Determine the Filter Order (N)\nEstimating the filter order (\\(N\\)) is a crucial first step in analog filter design after defining specifications. The order determines the filter’s complexity and steepness of its frequency response roll-off.\nThese equations are for Butterworth filters. The calculated \\(N\\) is a real number and must be rounded up to the next integer.\nCommon Variables: * \\(N\\): Filter order (integer, result of formula is rounded up). * \\(A_{min}\\): Minimum stopband attenuation (dB, positive value, e.g., 40 dB). * \\(A_{max}\\): Maximum passband attenuation/ripple (dB, positive value, e.g., 1 dB). * \\(\\log_{10}\\): Base-10 logarithm. * All \\(\\Omega\\) values are angular frequencies in rad/s."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-low-pass-lp-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-low-pass-lp-filter-order",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth Low-Pass (LP) Filter Order",
    "text": "Butterworth Low-Pass (LP) Filter Order\n\\[N \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\frac{\\Omega_s}{\\Omega_p}\\right)}\\]\nExplanation of LP-Specific Variables: * \\(\\Omega_p\\): Passband edge angular frequency. The frequency up to which signals pass with at most \\(A_{max}\\) attenuation. * \\(\\Omega_s\\): Stopband edge angular frequency. The frequency from which signals are attenuated by at least \\(A_{min}\\). * For a low-pass filter, \\(\\Omega_s &gt; \\Omega_p\\). The term \\(\\frac{\\Omega_s}{\\Omega_p}\\) is the transition ratio."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-high-pass-hp-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-high-pass-hp-filter-order",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth High-Pass (HP) Filter Order",
    "text": "Butterworth High-Pass (HP) Filter Order\n\\[N \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\frac{\\Omega_p}{\\Omega_s}\\right)}\\]\nExplanation of HP-Specific Variables: * \\(\\Omega_p\\): Passband edge angular frequency. The frequency from which signals pass with at most \\(A_{max}\\) attenuation. * \\(\\Omega_s\\): Stopband edge angular frequency. The frequency down to which signals are attenuated by at least \\(A_{min}\\). * For a high-pass filter, \\(\\Omega_p &gt; \\Omega_s\\). The term \\(\\frac{\\Omega_p}{\\Omega_s}\\) is the transition ratio (inverted compared to LP to keep it &gt;1 for the logarithm)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-pass-bp-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-pass-bp-filter-order",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth Band-Pass (BP) Filter Order",
    "text": "Butterworth Band-Pass (BP) Filter Order\nThe order \\(N_{BP}\\) is the same as an equivalent Low-Pass Prototype. \\[N_{BP} \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\Omega_{s,LP_equiv}\\right)}\\]\nExplanation of BP-Specific Variables: * \\(\\Omega_{p1}, \\Omega_{p2}\\): Passband edge angular frequencies (\\(\\Omega_{p1} &lt; \\Omega_{p2}\\)). * \\(\\Omega_{s1}, \\Omega_{s2}\\): Stopband edge angular frequencies (\\(\\Omega_{s1} &lt; \\Omega_{p1}\\) and \\(\\Omega_{s2} &gt; \\Omega_{p2}\\)). * \\(\\Omega_0 = \\sqrt{\\Omega_{p1}\\Omega_{p2}}\\): Geometric center frequency of the passband. * \\(B = \\Omega_{p2} - \\Omega_{p1}\\): Bandwidth of the passband. * \\(\\Omega_{s,LP_equiv} = \\min\\left( \\left| \\frac{\\Omega_{s1}^2 - \\Omega_0^2}{\\Omega_{s1} B} \\right|, \\left| \\frac{\\Omega_{s2}^2 - \\Omega_0^2}{\\Omega_{s2} B} \\right| \\right)\\) * This \\(\\Omega_{s,LP_equiv}\\) is the stopband edge of an equivalent low-pass prototype whose passband edge is normalized to 1 rad/s. It represents the more stringent of the two possible transitions from the passband edges to the stopband edges."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-stop-bs-filter-order",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#butterworth-band-stop-bs-filter-order",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Butterworth Band-Stop (BS) Filter Order",
    "text": "Butterworth Band-Stop (BS) Filter Order\nThe order \\(N_{BS}\\) is the same as an equivalent Low-Pass Prototype. \\[N_{BS} \\ge \\frac{\\log_{10}\\left(\\frac{10^{A_{min}/10}-1}{10^{A_{max}/10}-1}\\right)}{2 \\log_{10}\\left(\\Omega_{trans,LP_equiv}\\right)}\\]\nExplanation of BS-Specific Variables: * \\(\\Omega_{s1}, \\Omega_{s2}\\): Stopband edge angular frequencies defining the rejected band (\\(\\Omega_{s1} &lt; \\Omega_{s2}\\)). \\(A_{min}\\) is the attenuation in this band. * \\(\\Omega_{p1}, \\Omega_{p2}\\): Passband edge angular frequencies outside the stopband (\\(\\Omega_{p1} &lt; \\Omega_{s1}\\) and \\(\\Omega_{p2} &gt; \\Omega_{s2}\\)). \\(A_{max}\\) is the ripple in these passbands. * \\(\\Omega_0 = \\sqrt{\\Omega_{s1}\\Omega_{s2}}\\): Geometric center frequency of the stopband. * \\(B = \\Omega_{s2} - \\Omega_{s1}\\): Bandwidth of the stopband. * \\(\\Omega_{p,LP_i} = \\left| \\frac{\\Omega_{pi} B}{\\Omega_{pi}^2 - \\Omega_0^2} \\right|\\) for \\(i=1\\) (using \\(\\Omega_{p1}\\)) and \\(i=2\\) (using \\(\\Omega_{p2}\\)). * These are the passband edges of an equivalent low-pass prototype whose stopband edge is normalized to 1 rad/s. * \\(\\Omega_{trans,LP_equiv} = \\frac{1}{\\min(\\Omega_{p,LP1}, \\Omega_{p,LP2})}\\) * This is the effective transition ratio (stopband edge / passband edge) for the equivalent low-pass prototype."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization",
    "title": "Sistemas y Señales Biomédicos",
    "section": "3. Determine the Filter Order (N) & Denormalization",
    "text": "3. Determine the Filter Order (N) & Denormalization\nCalculated based on specs and chosen filter type. scipy.signal.buttord (and similar for other types) can find this for analog filters.\n\n\n\nRequired Butterworth Filter Order (N): 14\n\n\nButterworth Natural Frequency (Wn_buttord): 6593.83 rad/s\n\n\n\nWn_buttord is the natural angular frequency (\\(\\Omega_n\\)) for the filter. For Butterworth, this is the -3dB cutoff frequency \\(\\Omega_c\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#determine-the-filter-order-n-denormalization-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "3. Determine the Filter Order (N) & Denormalization",
    "text": "3. Determine the Filter Order (N) & Denormalization\nNormalized Lowpass to Denormalized Lowpass\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized LP with cutoff \\(\\Omega_c\\).\nTransformation: Replace \\(s_{norm}\\) with \\(s / \\Omega_c\\). \\[s_{norm} \\to \\frac{s}{\\Omega_c}\\]\nDenormalized Transfer Function: \\[H_{LP}(s) = H_{norm}\\left(\\frac{s}{\\Omega_c}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-highpass",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-highpass",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Lowpass to Denormalized Highpass",
    "text": "Normalized Lowpass to Denormalized Highpass\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized HP with cutoff \\(\\Omega_c\\).\nTransformation: Replace \\(s_{norm}\\) with \\(\\Omega_c / s\\). \\[s_{norm} \\to \\frac{\\Omega_c}{s}\\]\nDenormalized Transfer Function: \\[H_{HP}(s) = H_{norm}\\left(\\frac{\\Omega_c}{s}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandpass",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandpass",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Lowpass to Denormalized Bandpass",
    "text": "Normalized Lowpass to Denormalized Bandpass\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized BP with center frequency \\(\\Omega_0\\) and bandwidth \\(B\\).\nTransformation: Replace \\(s_{norm}\\) with \\(\\frac{s^2 + \\Omega_0^2}{B s}\\). \\[s_{norm} \\to \\frac{s^2 + \\Omega_0^2}{B s}\\]\nParameters:\n\n\\(\\Omega_0 = \\sqrt{\\Omega_1 \\Omega_2}\\) (geometric mean)\n\\(B = \\Omega_2 - \\Omega_1\\) (bandwidth) (\\(\\Omega_1, \\Omega_2\\) are the desired band edges in rad/s)\n\nDenormalized Transfer Function: \\[H_{BP}(s) = H_{norm}\\left(\\frac{s^2 + \\Omega_0^2}{B s}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandstop",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#normalized-lowpass-to-denormalized-bandstop",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Normalized Lowpass to Denormalized Bandstop",
    "text": "Normalized Lowpass to Denormalized Bandstop\n\nGoal: Transform a normalized LP (\\(\\omega_c = 1\\)) to a denormalized BS with center frequency \\(\\Omega_0\\) and bandwidth \\(B\\).\nTransformation: Replace \\(s_{norm}\\) with \\(\\frac{B s}{s^2 + \\Omega_0^2}\\). \\[s_{norm} \\to \\frac{B s}{s^2 + \\Omega_0^2}\\]\nParameters:\n\n\\(\\Omega_0 = \\sqrt{\\Omega_1 \\Omega_2}\\)\n\\(B = \\Omega_2 - \\Omega_1\\)\n\nDenormalized Transfer Function: \\[H_{BS}(s) = H_{norm}\\left(\\frac{B s}{s^2 + \\Omega_0^2}\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#obtain-analog-filter-transfer-function-h_as",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#obtain-analog-filter-transfer-function-h_as",
    "title": "Sistemas y Señales Biomédicos",
    "section": "4 & 5. Obtain Analog Filter Transfer Function \\(H_a(s)\\)",
    "text": "4 & 5. Obtain Analog Filter Transfer Function \\(H_a(s)\\)\nConceptually: Find normalized LP prototype \\(\\rightarrow\\) Denormalize \\(\\rightarrow\\) Transform.\nscipy.signal functions like butter, cheby1, etc., (with analog=True) perform these steps internally to give the final analog filter transfer function \\(H_a(s)\\).\n\\(H_a(s)\\) can be represented as: 1. Numerator (\\(b\\)) and Denominator (\\(a\\)) coefficients: \\(H_a(s) = \\frac{b_0 s^M + b_1 s^{M-1} + \\dots + b_M}{a_0 s^N + a_1 s^{N-1} + \\dots + a_N}\\) 2. Zeros (\\(z\\)), Poles (\\(p\\)), and Gain (\\(k\\)): \\(H_a(s) = k \\frac{\\prod (s-z_i)}{\\prod (s-p_j)}\\)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#python-design-h_as-butterworth-lpf",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#python-design-h_as-butterworth-lpf",
    "title": "Sistemas y Señales Biomédicos",
    "section": "4 & 5. Python: Design \\(H_a(s)\\) (Butterworth LPF)",
    "text": "4 & 5. Python: Design \\(H_a(s)\\) (Butterworth LPF)\nUsing signal.butter with analog=True. The Wn parameter here should be the cutoff frequency \\(\\Omega_c\\). For buttord, the returned Wn_buttord is exactly this \\(\\Omega_c\\).\n\n\n\nAnalog Filter Coefficients (Numerator b, Denominator a):\n\n\nb_analog = [2.93718174e+53]\n\n\na_analog = [1.00000000e+00 5.88921844e+04 1.73414469e+09 3.37531810e+13\n 4.84169654e+17 5.40639098e+21 4.84125527e+25 3.52958830e+29\n 2.10491137e+33 1.02201934e+37 3.97946840e+40 1.20619642e+44\n 2.69441500e+47 3.97843852e+50 2.93718174e+53]\n\n\n\nAnalog Filter Zeros, Poles, Gain (ZPK):\n\n\nZeros (z_analog) = []\n\n\nPoles (p_analog) = [ -738.27500968+6552.37193897j -2177.8048373 +6223.80864963j\n -3508.13043664+5583.15760623j -4662.54372722+4662.54372722j\n -5583.15760623+3508.13043664j -6223.80864963+2177.8048373j\n -6552.37193897 +738.27500968j -6552.37193897 -738.27500968j\n -6223.80864963-2177.8048373j  -5583.15760623-3508.13043664j\n -4662.54372722-4662.54372722j -3508.13043664-5583.15760623j\n -2177.8048373 -6223.80864963j  -738.27500968-6552.37193897j]\n\n\nGain (k_analog) = 293718173729774468825490597908032846661500110135885824.00"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-analog-frequency-response-python",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-analog-frequency-response-python",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Visualizing Analog Frequency Response (Python)",
    "text": "Visualizing Analog Frequency Response (Python)\nUse scipy.signal.freqs to compute the frequency response of an analog filter given its \\(b,a\\) coefficients.\n\n\n(100.0, 7500)\n\n\n(-60.0, 5.0)\n\n\n(100.0, 7500)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#synthesize-the-circuit-realization",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#synthesize-the-circuit-realization",
    "title": "Sistemas y Señales Biomédicos",
    "section": "6. Synthesize the Circuit (Realization)",
    "text": "6. Synthesize the Circuit (Realization)\nConvert the mathematical \\(H_a(s)\\) into a physical electronic circuit. This step is not done by scipy.signal. It requires circuit design knowledge.\n\nPassive Filters:\n\nResistors (R), Inductors (L), Capacitors (C).\nCommonly “ladder” structures.\nInductors can be bulky/non-ideal, especially at low frequencies.\n\nActive Filters:\n\nOp-Amps, Resistors (R), Capacitors (C) (avoids inductors).\nCan provide gain, easy to cascade.\nRequires power. Limited by op-amp performance.\nCommon topologies: Sallen-Key, Multiple Feedback (MFB), State-Variable/Biquad.\nHigher-order filters are often cascaded 2nd-order sections."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#component-selection-and-simulation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#component-selection-and-simulation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "7. Component Selection and Simulation",
    "text": "7. Component Selection and Simulation\n\nComponent Values: Choose standard, available component values (R, C, L, Op-Amps) that are close to calculated ideals.\nTolerances: Account for component variations.\nNon-Idealities: Consider real-world behavior of components.\nCircuit Simulation (Essential):\n\nUse SPICE-based simulators (LTspice, QUCS, PSpice, etc.).\nVerify performance against specifications.\nIterate on design and component values as needed.\n\n\nThis is also outside the scope of scipy.signal but critical for hardware implementation."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#tools-for-analog-filter-design",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#tools-for-analog-filter-design",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Tools for Analog Filter Design",
    "text": "Tools for Analog Filter Design\n\nMathematical Software:\n\nPython with scipy.signal: Excellent for determining filter parameters (\\(N, \\Omega_c\\)) and transfer functions (\\(b,a\\) or \\(z,p,k\\)), and plotting responses.\nMATLAB (Signal Processing Toolbox), Octave.\n\nFilter Design Calculators/Software:\n\nTexas Instruments FilterPro™, Analog Devices Filter Wizard®.\nOnline calculators and dedicated filter design suites.\n\nCircuit Simulators:\n\nLTspice, QUCS, PSpice, NI Multisim™, Keysight ADS.\n\nFilter Design Handbooks:\n\nClassic texts (e.g., by Van Valkenburg, Zverev) provide theory, tables, and formulas."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#conclusion-for-analog-filter-design",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#conclusion-for-analog-filter-design",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Conclusion – For Analog Filter Design",
    "text": "Conclusion – For Analog Filter Design\nAnalog filter design is a multi-step process:\n\nSpecs \\(\\rightarrow\\) Theory \\(\\rightarrow\\) Math (\\(H_a(s)\\)) \\(\\rightarrow\\) Circuit \\(\\rightarrow\\) Verification.\nscipy.signal in Python is a powerful tool for the mathematical parts: determining order, calculating transfer function coefficients/poles/zeros, and analyzing frequency response for various analog filter prototypes.\nRealizing the physical circuit requires additional circuit design knowledge and simulation tools."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-apply-digital-transformation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-apply-digital-transformation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 5: Apply Digital Transformation",
    "text": "Step 5: Apply Digital Transformation\n\nConvert the designed analog filter \\(H_a(s)\\) to the digital domain \\(H(z)\\):\n\nIf Impulse Invariance: Use partial fractions and the \\(s_k \\rightarrow e^{s_k T}\\) mapping.\nIf Bilinear Transformation: Substitute \\(s = \\frac{2}{T} \\frac{1 - z^{-1}}{1 + z^{-1}}\\) into \\(H_a(s)\\) and simplify algebraically.\n\nResult: The digital filter transfer function: \\[H(z) = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{1 + \\sum_{k=1}^{N} a_k z^{-k}}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-implementation",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-implementation",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 6: Realization (Implementation)",
    "text": "Step 6: Realization (Implementation)\n\nThe transfer function \\(H(z)\\) corresponds directly to a difference equation: \\[y[n] = \\sum_{k=0}^{M} b_k x[n-k] - \\sum_{k=1}^{N} a_k y[n-k]\\]\n\\(x[n]\\): Input sequence\n\\(y[n]\\): Output sequence\n\\(b_k, a_k\\): Filter coefficients derived from \\(H(z)\\).\nThe feedback term (sum involving \\(y[n-k]\\)) makes the impulse response potentially infinite (IIR)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary: IIR Design Process",
    "text": "Summary: IIR Design Process\n\nDefine Digital Specs (\\(\\omega_p, \\omega_s, A_p, A_s\\)).\nSelect Transformation (e.g., Bilinear).\nPre-warp Frequencies (if Bilinear: \\(\\omega \\rightarrow \\Omega\\)).\nDesign Analog Filter \\(H_a(s)\\) (using prototypes & transformations).\nTransform to Digital \\(H(z)\\) (apply Bilinear or Impulse Invariance).\nRealize as Difference Equation for Implementation."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications-1",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-digital-filter-specifications-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Digital Filter Specifications",
    "text": "Step 1: Digital Filter Specifications\n\nDefine the desired characteristics of the digital filter:\n\nSampling Frequency: \\(F_s\\) (Hz)\nCritical Frequencies (Digital):\n\nPassband edge: \\(f_p\\) (Hz) \\(\\implies \\omega_p = 2\\pi f_p / F_s\\) (radians/sample)\nStopband edge: \\(f_s\\) (Hz) \\(\\implies \\omega_s = 2\\pi f_s / F_s\\) (radians/sample)\nNote: Scipy often uses frequencies normalized to Nyquist: \\(W_p = f_p / (F_s/2)\\), \\(W_s = f_s / (F_s/2)\\)\n\nTolerances:\n\nMax. passband ripple/attenuation: \\(A_p\\) or gpass (dB)\nMin. stopband attenuation: \\(A_s\\) or gstop (dB)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-example-specifications-python",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-1-example-specifications-python",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 1: Example Specifications (Python)",
    "text": "Step 1: Example Specifications (Python)\n\n\nSampling Frequency: 10000 Hz\n\n\nNormalized Passband Edge: 0.200 (pi rad/sample)\n\n\nNormalized Stopband Edge: 0.300 (pi rad/sample)\n\n\nMax Passband Loss: 1 dB\n\n\nMin Stopband Attenuation: 40 dB"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-designing-conceptual",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-designing-conceptual",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Steps 2-4: Finding Order & Designing (Conceptual)",
    "text": "Steps 2-4: Finding Order & Designing (Conceptual)\n\nTransformation: Bilinear Transform is implicitly used by many scipy.signal functions for IIR design.\nFrequency Pre-warping: Handled internally by Scipy when given digital frequency specs.\nAnalog Design: Scipy calculates the required analog prototype order and parameters based on the (internally pre-warped) specs.\nGoal: Find filter order \\(N\\) and digital cutoff frequency \\(W_n\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-wn-python---butterworth-example",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#steps-2-4-finding-order-wn-python---butterworth-example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Steps 2-4: Finding Order & Wn (Python - Butterworth Example)",
    "text": "Steps 2-4: Finding Order & Wn (Python - Butterworth Example)\n\nUse scipy.signal.buttord to find the minimum order and cutoff frequency for a digital Butterworth filter meeting the specs.\n\n\n\n\nMinimum Filter Order (N): 12\n\n\nButterworth Natural Frequency (Wn): 0.211 (pi rad/sample)\n\n\n\nanalog=False specifies we want parameters for a digital filter.\nWn is the digital cutoff frequency (scalar for LP/HP, tuple for BP/BS) required by the butter function. It’s often close to wp."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-designing-the-digital-filter-python---butterworth",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-5-designing-the-digital-filter-python---butterworth",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 5: Designing the Digital Filter (Python - Butterworth)",
    "text": "Step 5: Designing the Digital Filter (Python - Butterworth)\n\nUse scipy.signal.butter (or cheby1, cheby2, ellip) to get the filter coefficients \\(b\\) (numerator) and \\(a\\) (denominator) of \\(H(z)\\).\n\n\n\n\nFilter Coefficients:\n\n\nNumerator (b): [0.0e+00 0.0e+00 1.0e-05 4.0e-05 1.0e-04 1.6e-04 1.9e-04 1.6e-04 1.0e-04\n 4.0e-05 1.0e-05 0.0e+00 0.0e+00]\n\n\nDenominator (a): [ 1.000000e+00 -6.930840e+00  2.271843e+01 -4.632962e+01  6.523097e+01\n -6.662310e+01  5.050575e+01 -2.858485e+01  1.197050e+01 -3.612930e+00\n  7.452400e-01 -9.424000e-02  5.520000e-03]\n\n\n\noutput='ba' gives numerator/denominator coefficients. Other options: 'sos' (second-order sections - numerically better), 'zpk' (zeros, poles, gain)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-frequency-response-python",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#visualizing-frequency-response-python",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Visualizing Frequency Response (Python)",
    "text": "Visualizing Frequency Response (Python)\n\nCalculate the frequency response using scipy.signal.freqz.\nPlot magnitude (in dB) and phase.\n\n\n\n(0.0, 5000.0)\n\n\n(-60.0, 5.0)\n\n\n(0.0, 5000.0)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-filtering-python-example",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#step-6-realization-filtering-python-example",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Step 6: Realization & Filtering (Python Example)",
    "text": "Step 6: Realization & Filtering (Python Example)\n\nThe coefficients b, a define the difference equation.\nUse scipy.signal.lfilter to apply the filter to a signal.\n\n\n\n(-1.5, 1.5)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process-with-scipy",
    "href": "presentaciones/SYSB/Lect009_DigitalFilters_ztransform.html#summary-iir-design-process-with-scipy",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Summary: IIR Design Process (with Scipy)",
    "text": "Summary: IIR Design Process (with Scipy)\n\nDefine Digital Specs (\\(f_p, f_s, gpass, gstop, F_s\\)). Normalize frequencies (\\(W_p, W_s\\)).\nSelect Filter Type (e.g., Butterworth) & find order/cutoff using buttord (digital).\nDesign Filter to get coefficients (\\(b, a\\)) using butter (digital).\nAnalyze Frequency Response using freqz.\nImplement/Apply Filter using lfilter (uses the difference equation implicitly).\n\n\nScipy handles the underlying analog prototype mapping, pre-warping, and bilinear transformation internally."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#áreas-de-aplicación-del-procesamiento-de-señales-e-imágenes",
    "href": "presentaciones/TALLERES/Promise.html#áreas-de-aplicación-del-procesamiento-de-señales-e-imágenes",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Áreas de aplicación del procesamiento de señales e imágenes",
    "text": "Áreas de aplicación del procesamiento de señales e imágenes\n\n\n\nDiagnóstico automatizado\nIdentificación de enfermedades en ECG, EEG o imágenes médicas.\nMonitoreo en tiempo real\nVigilancia en UCI con señales continuas de corazón, respiración y cerebro.\nTelemedicina\nTransmisión y compresión de señales para consultas a distancia.\nRehabilitación y prótesis inteligentes\nUso de señales EMG para controlar prótesis y exoesqueletos.\n\n\n\nDetección temprana de eventos críticos\nAnticipación de arritmias, crisis epilépticas o caídas.\nBiometría y seguridad\nReconocimiento de voz, rostro o iris.\nImagenología avanzada\nSegmentación de órganos o tumores en 3D para cirugía o radioterapia.\nEntretenimiento y multimedia\nFiltros en fotos y videos, mejora de audio y realidad aumentada."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "href": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Plataforma para el monitoreo de salud de adultos mayores",
    "text": "Plataforma para el monitoreo de salud de adultos mayores\n\n\n\nDetección ambulatoria de actividades diarias.\nDetección ambulatoria de riesgo de caída.\nDetección ambulatoria de riesgo neuronal.\n\n\n\n\n\n\n\n\n\n\nProfesora Auxiliar\n\n\nPh.D. Jenny Carolina Castiblanco S."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores-1",
    "href": "presentaciones/TALLERES/Promise.html#plataforma-para-el-monitoreo-de-salud-de-adultos-mayores-1",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Plataforma para el monitoreo de salud de adultos mayores",
    "text": "Plataforma para el monitoreo de salud de adultos mayores\n\n\n\nDetección ambulatoria de riesgo psico-social.\nDetección ambulatoria de riesgo cardíaco\nMonitorización de terapias ambulatorias para la rehabilitación de adultos mayores\n\n\n\n\n\n\n\n\n\n\nProfesora Auxiliar\n\n\nPh.D. Jenny Carolina Castiblanco S."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#creación-de-ambientes-de-habitación-saludables-usando-realimentación-sensorial",
    "href": "presentaciones/TALLERES/Promise.html#creación-de-ambientes-de-habitación-saludables-usando-realimentación-sensorial",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Creación de ambientes de habitación saludables usando realimentación sensorial",
    "text": "Creación de ambientes de habitación saludables usando realimentación sensorial\n\n\n\n\n\nNeurofeedback emocional usando música.\nNeurofeedback de memoria procedimental.\nNeurofeedback en automotores.\nMonitorización ambulatoria de estado emocional.\nMonitorización ambulatoria de terapias emocionales"
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#apoyo-tecnológico-mediante-ia-a-intervenciones-clínicas",
    "href": "presentaciones/TALLERES/Promise.html#apoyo-tecnológico-mediante-ia-a-intervenciones-clínicas",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Apoyo tecnológico mediante IA a intervenciones clínicas",
    "text": "Apoyo tecnológico mediante IA a intervenciones clínicas\n\n\n\nDetección de anomalías en imágenes mediante segmentación heurística.\nPlaneación pre-operatoria mediante el uso de inteligencia artificial.\nPlanificación operatoria de sistemas robóticos.\nEvaluación de espasticidad mediante el uso tecnología."
  },
  {
    "objectID": "presentaciones/TALLERES/Promise.html#rehabilitación-y-prótesis-inteligentes",
    "href": "presentaciones/TALLERES/Promise.html#rehabilitación-y-prótesis-inteligentes",
    "title": "Semillero en Procesamiento de Señales e Imagenes",
    "section": "Rehabilitación y prótesis inteligentes",
    "text": "Rehabilitación y prótesis inteligentes\n\n\n\n\n\n\n\n\n\n\nProfesora Auxiliar\n\n\nPh.D. Jenny Carolina Castiblanco S.\n\n\n\n\n\n\nGeneración de interfaces cerebro-computador\nGeneración de algoritmos de clasificación de intención de movimiento\nMonitorización de terapias de rehabilitación.\nUso de señales DE origen biológico para controlar prótesis y exoesqueletos."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#importance-of-frequency-response-filters",
    "href": "presentaciones/PSIM/prueba.html#importance-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Importance of Frequency-Response Filters",
    "text": "Importance of Frequency-Response Filters\n\nFrequency-response filters are critical for enhancing specific features or reducing noise in images.\nWidely used in MRI, CT, and ultrasound imaging."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#what-is-a-frequency-response-filter",
    "href": "presentaciones/PSIM/prueba.html#what-is-a-frequency-response-filter",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is a Frequency-Response Filter?",
    "text": "What is a Frequency-Response Filter?\n\nA frequency-response filter modifies the frequency components of a signal.\nApplied in image processing to control which frequencies (details) pass or are suppressed."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#types-of-frequency-response-filters",
    "href": "presentaciones/PSIM/prueba.html#types-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Types of Frequency-Response Filters",
    "text": "Types of Frequency-Response Filters\n\nLow-pass filters: Allow low frequencies, suppress high frequencies (smoothes image).\nHigh-pass filters: Allow high frequencies, suppress low frequencies (sharpens image).\nBand-pass filters: Allow frequencies in a certain range."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#spatial-vs.-frequency-domain",
    "href": "presentaciones/PSIM/prueba.html#spatial-vs.-frequency-domain",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Spatial vs. Frequency Domain",
    "text": "Spatial vs. Frequency Domain\n\nSpatial domain: Operations on pixel values directly.\nFrequency domain: Operations on the image’s frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#fourier-transform",
    "href": "presentaciones/PSIM/prueba.html#fourier-transform",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Fourier Transform",
    "text": "Fourier Transform\n\nConverts an image from the spatial domain to the frequency domain.\nFormula: \\[F\\left(u,v\\right) = \\sum\\sum f\\left(x,y\\right) e^{-j2\\pi(\\frac{ux}{M} + \\frac{vy}{N})}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#low-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#low-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low-Pass Filters",
    "text": "Low-Pass Filters\n\nRemoves high-frequency components (e.g., noise, sharp edges).\nExample: Gaussian filter, Butterworth filter."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#high-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#high-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "High-Pass Filters",
    "text": "High-Pass Filters\n\nEnhances edges and high-frequency details.\nExample: Laplacian filter."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#band-pass-filters",
    "href": "presentaciones/PSIM/prueba.html#band-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Band-Pass Filters",
    "text": "Band-Pass Filters\n\nAllows frequencies within a specific range.\nUseful for isolating specific image features."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#noise-reduction-in-mri",
    "href": "presentaciones/PSIM/prueba.html#noise-reduction-in-mri",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Noise Reduction in MRI",
    "text": "Noise Reduction in MRI\n\nLow-pass filters reduce noise and artifacts in MRI scans.\nSmoothes the image without losing crucial details."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#edge-enhancement-in-ultrasound-images",
    "href": "presentaciones/PSIM/prueba.html#edge-enhancement-in-ultrasound-images",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge Enhancement in Ultrasound Images",
    "text": "Edge Enhancement in Ultrasound Images\n\nHigh-pass filters help in detecting tissue boundaries by enhancing edges.\nImproves clarity of anatomical structures."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#feature-extraction-in-ct-scans",
    "href": "presentaciones/PSIM/prueba.html#feature-extraction-in-ct-scans",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Feature Extraction in CT Scans",
    "text": "Feature Extraction in CT Scans\n\nFilters can help in extracting features like tumors or vessels.\nBand-pass filters isolate structures of interest at specific frequency ranges."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "href": "presentaciones/PSIM/prueba.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process",
    "text": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process\n\nLoad MRI image.\nApply Fourier Transform to move the image into the frequency domain.\nDesign and apply a low-pass filter.\nPerform Inverse Fourier Transform to return to the spatial domain.\nVisualize the result."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#summary",
    "href": "presentaciones/PSIM/prueba.html#summary",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Summary",
    "text": "Summary\n\nFrequency-response filters play a crucial role in biomedical image processing.\nHelp enhance key features and suppress unwanted noise."
  },
  {
    "objectID": "presentaciones/PSIM/prueba.html#future-trends",
    "href": "presentaciones/PSIM/prueba.html#future-trends",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Future Trends",
    "text": "Future Trends\n\nDeep learning integration with traditional filters.\nDevelopment of adaptive filters for real-time processing."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Introduction",
    "text": "Introduction\n\n\nData acquisition is to capture the signal and encode in a form suitable for computer processing.\nSignal conditioning is to remove noise and artifacts from the signal.\nFeature extraction is to extract relevant information from the signal.\nHypothesis testing is to test the hypothesis based on the extracted features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal condtioning",
    "text": "Signal condtioning\n\n\n\n\n\n\n\nBase Information\n\n\n\nA 12-lead electrocardiogram for arrhythmia study - Article\nA 12-lead electrocardiogram for arrhythmia study - Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning\n\ndata  = sio.loadmat(path_ecg+\"/JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\nprint(data.keys())\n\ndict_keys(['val'])\n\nprint(type(data['val']))\n\n&lt;class 'numpy.ndarray'&gt;\n\nprint(data['val'].shape)\n\n(12, 5000)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Signal conditioning",
    "text": "Signal conditioning"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "NotaDefinition\n\n\n\n\nTwo-dimensional function, f(x, y)\nWhere x and y are spatial coordinates.\nThe amplitude of f at any pair of coordinates (x, y) is called the intensity.\n\n\n\n\n\n\n\n\n\nAdvertenciaThe digital image\n\n\n\nIf the coordinates and the intensity are discrete quantities the image turns into a digital image."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipDefinition\n\n\n\nA digital image is composed by a finite number of elements called PIXEL.\n\n\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\nTipDepth\n\n\n\n\nA digital image is composed by a finite number of elements called PIXEL. Bpp( Bits per pixel)\n\n1bpp. B/W image, monochrome.\n2bpp. CGA Image.\n4bpp. Minimun for VGA standard.\n8bpp. Super-VGA image.\n24bpp. Truecolor image.\n48bpp. Professional-level images."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "https://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\nTipColor Space\n\n\n\nHow can i represent the color\n\nRGB.\nCMYK.\nHSV.\nCieLab\nAmong others."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#what-is-digital-image-processing-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "import cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"image01.tif\")\nfig001 = plt.figure()\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"lena.tif\")\nRGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig002 = plt.figure()\nplt.imshow(RGB_img)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "The paradigm surrounding the conceptualization of light and perception has undergone significant evolution.\nInitially, the prevailing understanding within humanity posited that visual stimuli emanated from the eye itself.\nHowever, contemporary knowledge has elucidated that light originates from external sources, undergoes reflection from objects within the environment, and is subsequently captured by the eye."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "NotaImportant\n\n\n\nWe also understand that light is a type of electromagnetic radiation, and its wavelength falls within a range from 400 nanometers to 700 nanometers.\n\n\n\n\n\nTaken from Corke 2023"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "NotaImportant\n\n\n\n\nThe most common way light is made is by something getting really hot. This makes energy that comes out as light.\nSome important term are:\n\nAbsortion: It is the fraction of light which a body absorbs depending on the wavelength.\nReflectance: It is the fraction of the incoming light which a body reflects. It’s a number between 0 to 1 and also depends on wavelength.\nLuminance: It is the fraction of the incoming light which a surface reflects. It’s a function of absortion and reflectance, and because of that luminance depends on wavelength."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipThe eye\n\n\n\n\nOur eye has two types of cells. Cones and Rods.\nCones are the most sensitive cells but above all these are color sensitive.\nRods responds only two intensity and they used on night, mostly.\nHumans, like most primates, are trichomats. This means that humans have three types of cones (Long, Medium and shorts).\n\n65% of longs (Sense red)\n33% of mediums (Sense green)\n2% of shortsv(Sense blue)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipThe artificial eye\n\n\n\n\n\n\nTaken from Corke 2023\n\n\n\n\nThe currents from each sensor are function of the luminance and the spectral response filter."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-5",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Taken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-6",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Taken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-7",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Taken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-8",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Taken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#images-and-vision-9",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Taken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipDefinition\n\n\n\nSampling: Digitalization of the spatial coordinates.\n\n\n\n\n\n\n\n\nTipDefinition\n\n\n\nQuantiazation: Digitalization of the light intensity (amplitude)."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Tomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Sampling and quantization",
    "text": "Sampling and quantization"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "1bit\n\n\n\n\n\n\n\n\n\n2bit\n\n\n\n\n\n\n\n\n\n3bit\n\n\n\n\n\n\n\n\n\n4bit\n\n\n\n\n\n\n\n\n\n\n\n5bit\n\n\n\n\n\n\n\n\n\n6bit\n\n\n\n\n\n\n\n\n\n7bit\n\n\n\n\n\n\n\n\n\n8bit"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#sampling-and-quantization-4",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Tomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#linear-indexing",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Tomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\n\n\nTipFrom normal to linear\n\n\n\n\\[\\alpha = My+x\\]\n\n\n\n\n\n\n\n\n\nTipFrom linear to normal\n\n\n\n\\[x = \\alpha \\bmod M\\]\n\\[y = \\frac{\\alpha - x}{M}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#spatial-resolution",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Tomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Tomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#intensity-resolution-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Tomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Tomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#a-simple-problem-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Tomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipNeighborhood\n\n\n\n\n\n\n\n\n\n\n\nN4\n\n\n\n\n\n\n\nND\n\n\n\n\n\n\n\nN8\n\n\n\n\n\n\nFigura 1"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-neighborhood",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipNeighborhood\n\n\n\n\n\n\n\n\n\n\n\nN4-\\(N_4\\left(p\\right)\\)\n\n\n\n\n\n\n\nND-\\(N_D\\left(p\\right)\\)\n\n\n\n\n\n\n\nN8-\\(N_8\\left(p\\right)\\)\n\n\n\n\n\n\nFigura 2: Neighborhoods"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-adjacency",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipRules for adjecency\n\n\n\n\n4-Adjecncy: Two pixels p and q with values from V are 4-adjacent if q is in the set \\(N_4\\left(p\\right)\\)\n8-adjacency. Two pixels p and q with values from V are 8-adjacent if q is in the set \\(N_8\\left(p\\right)\\)\nm-adjacency (also called mixed adjacency). Two pixels p and q with values from V are m-adjacent if:\n\nq is in \\(N_4\\left(p\\right)\\).\nq is in \\(N_D\\left(p\\right)\\) and the set \\(N_4\\left(p\\right) \\cap N_4\\left(q\\right)\\) has no pixels whose values are from V."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-1",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Adjacency"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-2",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "A4\n\n\n\n\n\n\n\n\n\n\n\nA8\n\n\n\n\n\n\n\n\n\n\n\n\n\nA-m"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipDigital path\n\n\n\nIt is a sequence of adjacent pixels.\n\\[\\left(x_0, y_0\\right), \\left(x_1, y_1\\right), \\left(x_2, y_2\\right), \\dots \\left(x_n, y_n\\right)\\]\nIf \\(\\left(x_0, y_0\\right)=\\left(x_n, y_n\\right)\\) the path is known as closed path\nLet S represent a subset of pixels in an image. Two pixels p and q are said to be connected in S if there exists a path between them consisting entirely of pixels in S."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-path-connected-subset",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Path, Connected Subset",
    "text": "Relationships between pixels – Path, Connected Subset"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-regions",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Regions",
    "text": "Relationships between pixels – Regions"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-boundary",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "Relationships between pixels – Boundary",
    "text": "Relationships between pixels – Boundary"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-distance",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipDistance\n\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html#relationships-between-pixels-3",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "TipDistance\n\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#importance-of-frequency-response-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#importance-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Importance of Frequency-Response Filters",
    "text": "Importance of Frequency-Response Filters\n\nFrequency-response filters are critical for enhancing specific features or reducing noise in images.\nWidely used in MRI, CT, and ultrasound imaging."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#what-is-a-frequency-response-filter",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#what-is-a-frequency-response-filter",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is a Frequency-Response Filter?",
    "text": "What is a Frequency-Response Filter?\n\nA frequency-response filter modifies the frequency components of a signal.\nApplied in image processing to control which frequencies (details) pass or are suppressed."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#types-of-frequency-response-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#types-of-frequency-response-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Types of Frequency-Response Filters",
    "text": "Types of Frequency-Response Filters\n\nLow-pass filters: Allow low frequencies, suppress high frequencies (smoothes image).\nHigh-pass filters: Allow high frequencies, suppress low frequencies (sharpens image).\nBand-pass filters: Allow frequencies in a certain range."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#spatial-vs.-frequency-domain",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#spatial-vs.-frequency-domain",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Spatial vs. Frequency Domain",
    "text": "Spatial vs. Frequency Domain\n\nSpatial domain: Operations on pixel values directly.\nFrequency domain: Operations on the image’s frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#fourier-transform",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#fourier-transform",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Fourier Transform",
    "text": "Fourier Transform\n\nConverts an image from the spatial domain to the frequency domain.\nFormula: \\[F\\left(u,v\\right) = \\sum\\sum f\\left(x,y\\right) e^{-j2\\pi(\\frac{ux}{M} + \\frac{vy}{N})}\\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#low-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#low-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Low-Pass Filters",
    "text": "Low-Pass Filters\n\nRemoves high-frequency components (e.g., noise, sharp edges).\nExample: Gaussian filter, Butterworth filter."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#high-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#high-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "High-Pass Filters",
    "text": "High-Pass Filters\n\nEnhances edges and high-frequency details.\nExample: Laplacian filter."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#band-pass-filters",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#band-pass-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Band-Pass Filters",
    "text": "Band-Pass Filters\n\nAllows frequencies within a specific range.\nUseful for isolating specific image features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#noise-reduction-in-mri",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#noise-reduction-in-mri",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Noise Reduction in MRI",
    "text": "Noise Reduction in MRI\n\nLow-pass filters reduce noise and artifacts in MRI scans.\nSmoothes the image without losing crucial details."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#edge-enhancement-in-ultrasound-images",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#edge-enhancement-in-ultrasound-images",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Edge Enhancement in Ultrasound Images",
    "text": "Edge Enhancement in Ultrasound Images\n\nHigh-pass filters help in detecting tissue boundaries by enhancing edges.\nImproves clarity of anatomical structures."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#feature-extraction-in-ct-scans",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#feature-extraction-in-ct-scans",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Feature Extraction in CT Scans",
    "text": "Feature Extraction in CT Scans\n\nFilters can help in extracting features like tumors or vessels.\nBand-pass filters isolate structures of interest at specific frequency ranges."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#case-study-applying-a-low-pass-filter-in-mri.-step-by-step-process",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process",
    "text": "Case Study: Applying a Low-Pass Filter in MRI. Step-by-step Process\n\nLoad MRI image.\nApply Fourier Transform to move the image into the frequency domain.\nDesign and apply a low-pass filter.\nPerform Inverse Fourier Transform to return to the spatial domain.\nVisualize the result."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#summary",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#summary",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Summary",
    "text": "Summary\n\nFrequency-response filters play a crucial role in biomedical image processing.\nHelp enhance key features and suppress unwanted noise."
  },
  {
    "objectID": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#future-trends",
    "href": "presentaciones/PSIM/Lect007_Imag_Proc_003.html#future-trends",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Future Trends",
    "text": "Future Trends\n\nDeep learning integration with traditional filters.\nDevelopment of adaptive filters for real-time processing."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\n\n(-1.0, 6.0)\n\n\n(-1.0, 5.0)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\nIt’s a mathematical tool for signal decomposition, like Fourier’s Transform.\nJust as the Fourier transform decomposes a signal into a series of sine and cosine functions, the wavelet transform does so using a set of functions known as wavelets.\nWavelets are functions generated by scaling and shifting a base function known as the mother wavelet."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\nMorlet: Popular for time-frequency analysis in EEG and ECG.\nMexican Hat (Ricker): Often used in spike detection in neural signals.\nHaar: Useful in quick decomposition of signals and feature extraction.\nDaubechies: Frequently used in ECG signal denoising and compression.\nSymlet: Another option for signal processing and feature extraction in EEG.\nCoiflet: Useful for denoising and baseline correction in biomedical signals."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-4",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-4",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction",
    "text": "Introduction\n\nConditionsIIIIIIIVV\n\n\n\nHave a mean of zero (to capture details in the signal).\nBe square integrable (finite energy).\nSatisfy the admissibility condition on its Fourier transform.\nBe oscillatory to capture frequency information.\n(Optionally) have compact support for efficient computation and localization.\n\n\n\n\n\n\n\n\n\n\nZero Mean (Admissibility Condition)\n\n\nThe function must have an average value of zero. Mathematically, this is expressed as:\n\\[\\int_{-\\infty}^{\\infty} \\psi(t) \\, dt = 0\\]\nThis condition ensures that the wavelet can detect changes or “details” in the signal rather than its average or constant components.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSquare Integrability\n\n\nThe function \\(\\psi(t)\\) must be square integrable, meaning it has finite energy:\n\\[\\int_{-\\infty}^{\\infty} |\\psi(t)|^2 \\, dt &lt; \\infty\\]\nThis requirement ensures that the wavelet’s energy is finite, making it possible to localize the function in both time and frequency domains. Functions that satisfy this belong to the \\(L^2(\\rm I\\!R)\\) space, which is the space of all functions with finite energy.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdmissibility Constant\n\n\nThe wavelet’s Fourier transform, \\(\\hat{\\psi}(\\omega)\\), should satisfy the admissibility condition:\n\\[C_\\psi = \\int_{-\\infty}^{\\infty} \\frac{|\\hat{\\psi}(\\omega)|^2}{|\\omega|} \\, d\\omega &lt; \\infty\\]\nwhere \\(\\hat{\\psi}(\\omega)\\) is the Fourier transform of \\(\\psi(t)\\), and \\(\\omega\\) represents angular frequency. This condition implies that \\(\\hat{\\psi}(\\omega)\\) must approach zero as \\(\\omega \\rightarrow 0\\) meaning the wavelet has no component at zero frequency (or DC component). This condition is crucial for ensuring that the wavelet transform is invertible.\n\n\n\n\n\n\n\n\n\n\n\n\n\nOscillatory Nature\n\n\nA mother wavelet should generally be oscillatory or “wavelike” (hence the term “wavelet”). This oscillatory behavior allows the wavelet to capture variations in the signal. For example, wavelets like the Morlet wavelet resemble decaying sinusoids. This oscillatory nature helps the wavelet capture both high-frequency and low-frequency components effectively.\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompact Support\n\n\nAlthough not strictly necessary, compact support is often a desirable property. Compact support means that the function is non-zero only over a finite interval, making it well-localized in time. This allows for efficient computation and good localization in the time domain. For example, the Haar wavelet has compact support, while others, like the Morlet wavelet, do not have strict compact support but still decay rapidly."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "A wavelet transformation",
    "text": "A wavelet transformation\n\n\n(0.0, 1.0)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#a-wavelet-transformation-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "A wavelet transformation",
    "text": "A wavelet transformation"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe continuous wavelet transform of a signal \\(f(t)\\) is defined as:\n\\[W_f(a, b) = \\int_{-\\infty}^{\\infty} f(t) \\, \\psi^*\\left(\\frac{t - b}{a}\\right) \\, dt\\]\nwhere:\n\n\\(f(t)\\) is the input signal,\n\\(\\psi\\) is the mother wavelet,\n\\(a\\) is the scale parameter (controls the width of the wavelet),\n\\(b\\) is the translation parameter (controls the position of the wavelet),\n\\(\\psi^*\\) denotes the complex conjugate of the mother wavelet. ## Mathematical Expressions\n\nThe continuous wavelet transform of a signal \\(f(t)\\) is defined as:\n\\[W_f(a, b) = \\int_{-\\infty}^{\\infty} f(t) \\, \\psi^*\\left(\\frac{t - b}{a}\\right) \\, dt\\]\nwhere:\n\n\\(f(t)\\) is the input signal,\n\\(\\psi\\) is the mother wavelet,\n\\(a\\) is the scale parameter (controls the width of the wavelet),\n\\(b\\) is the translation parameter (controls the position of the wavelet),\n\\(\\psi^*\\) denotes the complex conjugate of the mother wavelet."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe inverse continuous wavelet transform is given by:\n\\[f(t) = \\frac{1}{C_{\\psi}} \\int_{0}^{\\infty} \\int_{-\\infty}^{\\infty} W_f(a, b) \\, \\psi\\left(\\frac{t - b}{a}\\right) \\frac{db \\, da}{a^2}\\]\nwhere:\nwhere \\(C_{\\psi}\\) is a normalization constant, defined as:\n\\[C_{\\psi} = \\int_{0}^{\\infty} \\frac{|\\hat{\\psi}(\\omega)|^2}{\\omega} \\, d\\omega\\]\nand \\(\\hat{\\psi}(\\omega)\\) is the Fourier transform of the wavelet \\(\\psi(t)\\)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe discrete wavelet transform decomposes the signal at discrete levels of scale. For a signal \\(x[n]\\), the wavelet decomposition is defined as:\n\\[c_{j, k} = \\sum_{n} x[n] \\, \\psi_{j, k}(n)\\]\nwhere:\n\n\\(\\psi_{j, k}(n)= \\frac{1}{\\sqrt{2}}\\psi\\left(\\frac{n-2^{j}k}{2^{j}}\\right)\\) represents the scaled and translated versions of the mother wavelet \\(\\psi\\)\n\\(j\\) is the scale index, and \\(k\\) is the translation index.\n\nThe decomposition typically consists of approximation and detail coefficients at each scale:\nApproximation coefficients \\(a_j\\): capture the low-frequency components. Detail coefficients \\(d_j\\) capture the high-frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mathematical-expressions-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mathematical Expressions",
    "text": "Mathematical Expressions\nThe inverse discrete wavelet transform reconstructs the original signal from its approximation and detail coefficients: \\[x[n] = \\sum_{j} \\sum_{k} c_{j, k} \\, \\psi_{j, k}(n)\\]\nThis reconstruction process involves upsampling and filtering of the approximation and detail coefficients at each scale."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#using-cwt",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#using-cwt",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Using CWT",
    "text": "Using CWT\n\nPurpose: The CWT is used when you need a highly detailed, continuous analysis of a signal over all possible scales and positions.\nOutput: CWT gives you a “heatmap” of wavelet coefficients, showing which frequencies (or scales) are present in the signal at each point in time. This allows for a continuous representation.\nApplications: CWT is useful for analyzing signals where you want to see the evolution of frequencies over time, such as:\n\nDetecting subtle changes in frequencies over time (like brainwave analysis in EEG).\nSignals with non-repeating, transient features (like spikes in biomedical signals, e.g., ECG).\n\nTrade-Off: CWT is more computationally expensive because it analyzes all scales and translations continuously. It gives lots of data but is slower and requires more memory.\n\n\n\n\n\n\n\n\nUse CWT when:\n\n\n\nYou need a detailed, continuous representation.\nYou want to detect subtle or fast-changing features across time.\nYou’re okay with higher computational costs to get very fine-grained analysis."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#using-dwt",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#using-dwt",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Using DWT",
    "text": "Using DWT\n\nPurpose: The DWT is used when you want a compact, efficient representation of a signal, usually for compression or feature extraction. It analyzes only specific scales (powers of two), not continuously.\nOutput: DWT gives you a set of coefficients at each level (or scale), capturing information at that specific scale. It’s efficient and uses fewer data points.\nApplications: DWT is ideal when you want to reduce the size of data or focus on a smaller set of frequencies, such as:\n\nImage and audio compression (like JPEG 2000 or MP3 formats).\nFeature extraction for machine learning (e.g., identifying specific patterns).\nDe-noising signals by discarding certain scales that contain noise.\n\nTrade-Off: DWT is computationally cheaper but less detailed than CWT. It doesn’t give a continuous heatmap but rather a discrete set of scales.\n\n\n\n\n\n\n\n\nUse DWT when:\n\n\n\nYou need a compact and efficient representation.\nYou’re focused on data compression, de-noising, or feature extraction.\nYou want faster computations with less data storage requirements."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-analyzing-complex-signals",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#introduction-analyzing-complex-signals",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Introduction: Analyzing Complex Signals",
    "text": "Introduction: Analyzing Complex Signals\n\nSignals like ECG are often non-stationary.\nTheir frequency content and characteristics change over time.\nTraditional methods (e.g., Fourier Transform) analyze the signal globally, losing temporal information.\nNeed a method to analyze signals at different time scales and frequency bands simultaneously."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#what-is-multiresolution-analysis-mra",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#what-is-multiresolution-analysis-mra",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "What is Multiresolution Analysis (MRA)?",
    "text": "What is Multiresolution Analysis (MRA)?\n\nA mathematical framework to decompose a signal into components at different levels of resolution or detail.\nThink of it like looking at a picture:\n\nCoarse view (low resolution): See the overall structure.\nFine view (high resolution): See small details.\n\nMRA decomposes a signal into a series of approximations and details, capturing information across various scales.\nOften implemented using Wavelet Transforms (specifically the Discrete Wavelet Transform - DWT)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mra-the-nested-subspace-concept",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mra-the-nested-subspace-concept",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "MRA: The Nested Subspace Concept",
    "text": "MRA: The Nested Subspace Concept\n\nMRA is built upon a sequence of nested subspaces \\(V_j\\) in \\(L^2(\\mathbb{R})\\).\nThese subspaces represent approximations of the signal at different resolutions.\nKey Properties:\n\nNesting: \\(\\dots \\subset V_2 \\subset V_1 \\subset V_0 \\subset V_{-1} \\subset V_{-2} \\subset \\dots\\)\nDensity: The union of \\(V_j\\) is dense in \\(L^2(\\mathbb{R})\\).\nSeparation: The intersection of \\(V_j\\) is \\(\\{0\\}\\).\nScaling: \\(f(t) \\in V_j \\iff f(2t) \\in V_{j-1}\\)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#the-scaling-function-phi",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#the-scaling-function-phi",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The Scaling Function (\\(\\phi\\))",
    "text": "The Scaling Function (\\(\\phi\\))\n\nEach subspace \\(V_j\\) is generated by scaled and translated versions of a single function called the scaling function, \\(\\phi(t)\\).\n\\(\\{\\phi(t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(V_0\\).\n\\(\\{\\sqrt{2^j}\\phi(2^j t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(V_j\\).\nThe scaling function captures the “smooth” or low-frequency components – the approximation of the signal at a given scale."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#the-wavelet-function-psi",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#the-wavelet-function-psi",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "The Wavelet Function (\\(\\psi\\))",
    "text": "The Wavelet Function (\\(\\psi\\))\n\nThe difference in information between two successive approximation spaces (\\(V_j\\) and \\(V_{j-1}\\)) is captured by the detail spaces, \\(W_j\\).\n\\(V_{j-1} = V_j \\oplus W_j\\), where \\(W_j\\) is the orthogonal complement of \\(V_j\\) in \\(V_{j-1}\\).\nThere exists a function \\(\\psi(t) \\in W_0\\), the wavelet function (or mother wavelet).\n\\(\\{\\psi(t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(W_0\\).\n\\(\\{\\sqrt{2^j}\\psi(2^j t-k) : k \\in \\mathbb{Z}\\}\\) forms an orthonormal basis for \\(W_j\\).\nThe wavelet function captures the “details” or high-frequency components."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#linking-phi-and-psi-two-scale-equations",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#linking-phi-and-psi-two-scale-equations",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Linking \\(\\phi\\) and \\(\\psi\\): Two-Scale Equations",
    "text": "Linking \\(\\phi\\) and \\(\\psi\\): Two-Scale Equations\n\nThe scaling and wavelet functions are related through coefficients \\(h_k\\) and \\(g_k\\).\n\\(\\phi(t) = \\sqrt{2} \\sum_k h_k \\phi(2t - k)\\)\n\\(\\psi(t) = \\sqrt{2} \\sum_k g_k \\phi(2t - k)\\)\nThese equations show how functions at one scale (left side) are constructed from functions at a finer scale (right side).\nThe coefficients \\(h_k\\) and \\(g_k\\) are critical – they define the specific wavelet and are the impulse responses of filters used in discrete implementations."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#from-math-to-practice-filters",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#from-math-to-practice-filters",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "From Math to Practice: Filters",
    "text": "From Math to Practice: Filters\n\nThe sequences \\(h_k\\) and \\(g_k\\) correspond to digital filters:\n\n\\(H = \\{h_k\\}\\) is a low-pass filter.\n\\(G = \\{g_k\\}\\) is a high-pass filter.\n\nThese filters are designed such that \\(G\\) is derived from \\(H\\) (for orthonormal wavelets, \\(g_k = (-1)^k h_{N-1-k}\\)).\nApplying the low-pass filter and downsampling corresponds to projecting the signal onto \\(V_j\\).\nApplying the high-pass filter and downsampling corresponds to projecting the signal onto \\(W_j\\)."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#discrete-mra-mallats-algorithm",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#discrete-mra-mallats-algorithm",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Discrete MRA: Mallat’s Algorithm",
    "text": "Discrete MRA: Mallat’s Algorithm\n\nThe discrete implementation of MRA is efficiently computed using Mallat’s Algorithm (or the Fast Wavelet Transform - FWT).\nIt’s a pyramidal algorithm based on filter banks and downsampling/upsampling.\nDecomposes the discrete signal into approximation (\\(A\\)) and detail (\\(D\\)) coefficients at successive levels."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-decomposition",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-decomposition",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mallat’s Algorithm: Decomposition",
    "text": "Mallat’s Algorithm: Decomposition\nStarting with signal \\(x[n]\\) (considered \\(A_0\\)):\n\nConvolve \\(A_j\\) with low-pass filter \\(H\\) and high-pass filter \\(G\\).\nDownsample outputs by 2 (\\(\\downarrow 2\\)).\n\nOutput of \\(H \\to \\downarrow 2\\) gives approximation coefficients \\(A_{j+1}\\).\nOutput of \\(G \\to \\downarrow 2\\) gives detail coefficients \\(D_{j+1}\\).\n\nRepeat the process on the approximation coefficients \\(A_{j+1}\\) for the next level.\n\n\\[ A_{j+1} = (A_j * H) \\downarrow 2 \\] \\[ D_{j+1} = (A_j * G) \\downarrow 2 \\]"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-reconstruction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mallats-algorithm-reconstruction",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Mallat’s Algorithm: Reconstruction",
    "text": "Mallat’s Algorithm: Reconstruction\nReconstructing signal \\(A_j\\) from \\(A_{j+1}\\) and \\(D_{j+1}\\):\n\nUpsample \\(A_{j+1}\\) and \\(D_{j+1}\\) by 2 (\\(\\uparrow 2\\), insert zeros).\nConvolve upsampled coefficients with reconstruction filters \\(H'\\) and \\(G'\\).\nAdd the results to get \\(A_j\\).\nRepeat until the original signal \\(A_0\\) is reconstructed.\n\n\\[ A_j = (A_{j+1} \\uparrow 2 * H') + (D_{j+1} \\uparrow 2 * G') \\] (For orthonormal wavelets, \\(H'\\) and \\(G'\\) are time-reversed \\(H\\) and \\(G\\))"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#mra-architecture",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#mra-architecture",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "MRA Architecture",
    "text": "MRA Architecture"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#why-mra-for-ecg",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#why-mra-for-ecg",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Why MRA for ECG?",
    "text": "Why MRA for ECG?\n\nECG signals are non-stationary and have features at different scales:\n\nQRS complex: Sharp, high frequency, short duration.\nP and T waves: Broader, lower frequency, longer duration.\nBaseline wander: Very low frequency.\nMuscle noise: High frequency.\n\nMRA naturally separates these components into different frequency bands (detail levels), making analysis easier."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-denoising",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-denoising",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Applications of MRA in ECG: Denoising",
    "text": "Applications of MRA in ECG: Denoising\n\nNoise (powerline, muscle, baseline wander) occupies different frequency bands.\nDecompose noisy ECG using MRA.\nNoise components are isolated in specific detail coefficients:\n\nHigh-frequency noise in fine detail levels.\nBaseline wander in coarse approximation/detail levels.\n\nApply thresholding to the noise-dominated coefficients (e.g., set small values to zero).\nReconstruct the signal from the modified coefficients to get a denoised ECG."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-feature-extraction",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#applications-of-mra-in-ecg-feature-extraction",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Applications of MRA in ECG: Feature Extraction",
    "text": "Applications of MRA in ECG: Feature Extraction\n\nDifferent ECG waves are highlighted in different MRA levels:\n\nQRS complex: Often prominent in mid-to-high frequency detail coefficients.\nP and T waves: Appear in lower frequency detail coefficients or approximation coefficients.\n\nAnalyze coefficients at relevant scales:\n\nDetect QRS peaks by finding local maxima in specific detail levels.\nDelineate P and T waves by analyzing the shape and zero-crossings of coefficients at coarser scales.\n\nExtract clinically relevant features (intervals, amplitudes) from the detected waves."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#other-applications-in-ecg",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#other-applications-in-ecg",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Other Applications in ECG",
    "text": "Other Applications in ECG\n\nCompression: MRA provides a sparse representation; many coefficients are small and can be discarded or quantized, reducing data size.\nAbnormality Detection and Classification: Features derived from the distribution or patterns of coefficients across different MRA levels can be used as input for machine learning algorithms to classify arrhythmias or other heart conditions."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#practical-implementation-steps",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#practical-implementation-steps",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Practical Implementation Steps",
    "text": "Practical Implementation Steps\n\nAcquisition & Preprocessing: Get digitized ECG data. Basic filtering might precede MRA if necessary.\nChoose Wavelet: Select a wavelet family (e.g., Daubechies ‘dbN’, Symlets ‘symN’). Consider similarity of wavelet shape to ECG features (e.g., QRS) and vanishing moments.\nDetermine Decomposition Levels: Choose the number of levels (\\(J\\)) based on sampling frequency (\\(F_s\\)) and the frequency bands of interest. Detail level \\(j\\) covers frequencies approx. \\([F_s/2^{j+1}, F_s/2^j]\\).\nPerform Decomposition: Apply Mallat’s algorithm (DWT) to get approximation and detail coefficients.\nAnalyze/Process Coefficients: Apply denoising (thresholding) or feature extraction techniques to the relevant coefficients.\nReconstruct (Optional): Reconstruct the signal if a filtered or modified ECG is needed."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#implementation-wavelet-choice-levels",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#implementation-wavelet-choice-levels",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Implementation: Wavelet Choice & Levels",
    "text": "Implementation: Wavelet Choice & Levels\n\nWavelet Family: Daubechies (db) and Symlets (sym) are common for ECG. ‘db4’ is often cited for its similarity to the QRS complex.\nNumber of Levels (\\(J\\)):\n\nHigher levels give coarser approximations and lower frequency details.\nChoose \\(J\\) so that key ECG features fall into specific, separable detail levels.\nE.g., for a 360 Hz ECG, QRS (10-50 Hz) might be in D3-D5, P/T (1-10 Hz) in D5-D7, baseline wander (&lt;1 Hz) in A7 or D8+."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#conclusion",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#conclusion",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Conclusion",
    "text": "Conclusion\n\nMultiresolution Analysis is a powerful technique for analyzing non-stationary signals like ECG.\nIt decomposes the signal into different frequency bands/scales using scaling and wavelet functions.\nImplemented efficiently via Mallat’s algorithm (DWT).\nEnables effective ECG denoising by isolating noise at specific levels.\nFacilitates robust feature extraction (P, QRS, T) by highlighting them in different detail coefficients.\nA fundamental tool in modern automated ECG analysis systems."
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis\n\n# Elegir wavelet y nivel de descomposición\nwavelet = \"db4\"\nmax_level = 3\n\n# Descomposición multiresolución\ncoeffs = pywt.wavedec(ecg001, wavelet, level=max_level)\n# coeffs[0]: coeficientes de aproximación al nivel 3 (cA3)\n# coeffs[1:], coeficientes de detalle en niveles 3, 2, 1 (cD3, cD2, cD1)\n\n# Reconstruir aproximación al nivel máximo\narr_approx = [coeffs[0]] + [np.zeros_like(c) for c in coeffs[1:]]\napprox = pywt.waverec(arr_approx, wavelet)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-1",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-1",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis\n\n\n# Reconstruir detalles por cada nivel\ndetails = []\nfor i in range(1, max_level + 1):\n    arr_detail = [np.zeros_like(c) for c in coeffs]\n    arr_detail[i] = coeffs[i]\n    detail = pywt.waverec(arr_detail, wavelet)\n    details.append(detail)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-2",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-2",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-3",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-3",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis"
  },
  {
    "objectID": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-4",
    "href": "presentaciones/PSIM/Lect008_Wavelet.html#ecg-analysis-4",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "ECG Analysis",
    "text": "ECG Analysis"
  },
  {
    "objectID": "clases/Class_SYSB.html",
    "href": "clases/Class_SYSB.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "El estudio del procesamiento de señales es fundamental en la ingeniería biomédica debido a la amplia variedad de aplicaciones que tiene en el análisis, interpretación y mejora de datos biomédicos. A continuación, se presenta una justificación estructurada de su relevancia:\nNaturaleza de las señales biomédicas\nLas señales biomédicas, como las señales electrocardiográficas (ECG), electromiográficas (EMG), electroencefalográficas (EEG), o incluso imágenes médicas (resonancias magnéticas o tomografías), son complejas y están afectadas por ruido y artefactos.\nEl procesamiento de señales permite extraer información útil, filtrar interferencias y maximizar la calidad de los datos obtenidos.\nDiagnóstico y monitoreo\nLas señales biomédicas son esenciales para el diagnóstico de enfermedades y el monitoreo continuo de pacientes. Por ejemplo, el procesamiento de un ECG ayuda a detectar arritmias, mientras que el análisis de un EEG puede identificar epilepsia o trastornos del sueño.\nEn entornos de cuidado intensivo, el procesamiento en tiempo real de señales vitales garantiza decisiones clínicas rápidas y precisas.\nOptimización de dispositivos biomédicos\nEl diseño de dispositivos biomédicos como marcapasos, desfibriladores implantables y prótesis inteligentes requiere algoritmos avanzados de procesamiento de señales para interpretar datos en tiempo real y responder adecuadamente a las necesidades del paciente.\nAvances en tecnología médica\nTecnologías emergentes como el análisis de datos en telemedicina, dispositivos portátiles (wearables) y sistemas de salud móvil (mHealth) dependen del procesamiento de señales para garantizar la precisión y la utilidad de la información presentada.\nIntegración con otras disciplinas\nEl procesamiento de señales se combina con inteligencia artificial y aprendizaje automático para desarrollar modelos predictivos, clasificar patrones patológicos y personalizar tratamientos.\nInvestigación en fisiología y biomecánica\nEl análisis avanzado de señales contribuye a la comprensión profunda de procesos fisiológicos complejos, como la dinámica del corazón, el cerebro o el sistema musculoesquelético.\nEducación y competencias profesionales\nLa formación en procesamiento de señales biomédicas dota a los futuros ingenieros de herramientas matemáticas y computacionales para enfrentar problemas del mundo real, desarrollar soluciones innovadoras y avanzar en el campo de la ingeniería biomédica.\nEl curso está dividido en 5 partes:\n1. Introducción al procesado de señales.\n2. Conceptos de señales contínuas & discretas.\n3. Muestreo.\n4. Extracción de características de una señal.\n5. Filtraje de señales."
  },
  {
    "objectID": "clases/Class_SYSB.html#presentaciones",
    "href": "clases/Class_SYSB.html#presentaciones",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción\nClasificacion de señales\nSeñales Notables 1/2\nSeñales Notables 2/2\nAdquisición y Muestreo\nFiltros Digitales\nContenido Frecuencial\nTransformada Z"
  },
  {
    "objectID": "clases/Class_SYSB.html#datos",
    "href": "clases/Class_SYSB.html#datos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_SYSB.html#recursos",
    "href": "clases/Class_SYSB.html#recursos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Recursos",
    "text": "Recursos\n\nTransformada de Laplace y Transformada Z"
  },
  {
    "objectID": "clases/Class_SYSB.html#códigos",
    "href": "clases/Class_SYSB.html#códigos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorios",
    "href": "clases/Class_SYSB.html#laboratorios",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLAB01: Código python, estadística, y números complejos.\nLAB02: El electrocardiograma. Fundamentos Teóricos.\nLAB03: Análisis de información base del dataset (Demografía y estadística inicial)\nLAB003A: Análisis de información base del dataset (Alineación de información)\nLAB04: Convolución\nLab05: Modelo estadístico para la clasificación de arritmias"
  },
  {
    "objectID": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nTaller1: Introduccion al procesamiento de señales\nTaller2: Sistemas LTI, Convolución, Series de FOURIER\nTaller3: Análisis y diseños de filtros\nPrimer Parcial 2025-1 A\nPrimer Parcial 2025-1 B\nSegundo Parcial 2025-2"
  },
  {
    "objectID": "clases/Class_SYSB.html#clases",
    "href": "clases/Class_SYSB.html#clases",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Clases",
    "text": "Clases\n\nLunes: 10:00am-11:30am. F204.\nJueves: 10:00am-11:30am. F206."
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorio",
    "href": "clases/Class_SYSB.html#laboratorio",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laboratorio",
    "text": "Laboratorio\n\nMartes: 10:00am-11:30am. I1-308."
  },
  {
    "objectID": "clases/Class_SYSB.html#atención-a-estudiantes",
    "href": "clases/Class_SYSB.html#atención-a-estudiantes",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes\nGrupo 80:\nGrupo 81:"
  },
  {
    "objectID": "clases/Class_ASIM.html",
    "href": "clases/Class_ASIM.html",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "",
    "text": "Aprender procesamiento de señales e imágenes con aprendizaje automático en medicina es crucial para mejorar la precisión y eficiencia en el diagnóstico y tratamiento de enfermedades. El aprendizaje automático permite analizar grandes cantidades de datos de imágenes médicas y señales biomédicas, como rayos X, tomografías computarizadas, resonancia magnética, ECG, EEG y EMG, para identificar patrones y anomalías que pueden indicar la presencia de enfermedades. Esto puede llevar a un diagnóstico más preciso y temprano, lo que a su vez puede mejorar los resultados para los pacientes y reducir la morbilidad y mortalidad.\nAdemás, el aprendizaje automático puede ayudar a personalizar tratamientos para pacientes individuales según sus características únicas de imágenes médicas y señales. También puede automatizar tareas clínicas rutinarias, como segmentación de imágenes, extracción de características y análisis de datos, lo que permite a los médicos centrarse en la toma de decisiones de alto nivel.\nLa aplicación del aprendizaje automático en medicina también puede facilitar la investigación médica, analizando grandes conjuntos de datos para identificar tendencias y patrones que pueden revelar nuevos conocimientos sobre enfermedades y tratamientos. Además, puede permitir la monitorización remota de pacientes y la telemedicina, ampliando el acceso a servicios de atención médica."
  },
  {
    "objectID": "clases/Class_ASIM.html#presentaciones",
    "href": "clases/Class_ASIM.html#presentaciones",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nClase 001: Introducción al machine learning\nClase 002: El algoritmo de descenso de gradiente\nClase 003: Regresiones & RNN\nClase 004: Redes CNN & Recurrentes\nClases 005: RNN, LSTM, GRU"
  },
  {
    "objectID": "clases/Class_ASIM.html#recursos-para-clase",
    "href": "clases/Class_ASIM.html#recursos-para-clase",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Recursos para Clase",
    "text": "Recursos para Clase\n\nAnálisis Exploratorio de datos\nEvaluación de modelos de machine learning\nIntroducción a las Redes Neuronales Convolucionales\nRNN, LSTM, GRU"
  },
  {
    "objectID": "clases/Class_ASIM.html#laboratorios",
    "href": "clases/Class_ASIM.html#laboratorios",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLab00: Conducta de entrada\nLab01: Programación orientada a objetos\nProyecto Final: Del Problema Clínico a la Solución de Aprendizaje Profundo"
  },
  {
    "objectID": "clases/Class_ASIM.html#atención-a-estudiantes",
    "href": "clases/Class_ASIM.html#atención-a-estudiantes",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes"
  },
  {
    "objectID": "clases/talleres.html",
    "href": "clases/talleres.html",
    "title": "Talleres",
    "section": "",
    "text": "Taller Primer Semestre"
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 6, 2025. The defense will be carried out by one of the team members chosen at random."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 1: Mean and Median",
    "text": "Exercise 1: Mean and Median\nWrite a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g. normal, binomial)."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes’ Theorem",
    "text": "Exercise 6: Bayes’ Theorem\nWrite a Python program that applies Bayes’ theorem to update the probability of a hypothesis given new evidence."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g. normal, uniform)."
  },
  {
    "objectID": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "href": "laboratorios/ASIM/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10:Function visualization - I",
    "text": "Exercise 10:Function visualization - I\nGenerate a python code that allows the visualization (in one figure) of the real (blue) part and the imaginary (red) part, magnitude (green) and phase of the following signals:\n\\[f\\left(t\\right) = e^{-j10 \\pi t}\\]\n\\[g\\left(t\\right) = 10cos\\left(2 \\pi t\\right) + j10sin\\left(2 \\pi t\\right)\\]\nThe visualization must be in the range of t \\(\\left[-10, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/ASIM/ProyectoFinal.html",
    "href": "laboratorios/ASIM/ProyectoFinal.html",
    "title": "Proyecto Integrador Final en IA Biomédica",
    "section": "",
    "text": "Propósito: Este es un proyecto integrador diseñado bajo la estrategia de aprendizaje basada en retos. Simula un ciclo completo de investigación y desarrollo (I+D) en ingeniería biomédica.\nObjetivo General: Desarrollar, validar y documentar un sistema de aprendizaje automático que resuelva un problema clínico relevante, cubriendo el pipeline completo.\nResultados de Aprendizaje (RAE) Evaluados:\n* RAE 1.1: Implementar algoritmos de deep learning.\n* RAE 1.2: Evaluar algoritmos en el contexto médico.\n* RAE 1.3/1.4: Identificar componentes teóricos y prácticos del sistema.\n* RAE Transversales: Comunicar, innovar y aplicar herramientas modernas."
  },
  {
    "objectID": "laboratorios/ASIM/ProyectoFinal.html#objetivos-del-proyecto-final",
    "href": "laboratorios/ASIM/ProyectoFinal.html#objetivos-del-proyecto-final",
    "title": "Proyecto Integrador Final en IA Biomédica",
    "section": "",
    "text": "Propósito: Este es un proyecto integrador diseñado bajo la estrategia de aprendizaje basada en retos. Simula un ciclo completo de investigación y desarrollo (I+D) en ingeniería biomédica.\nObjetivo General: Desarrollar, validar y documentar un sistema de aprendizaje automático que resuelva un problema clínico relevante, cubriendo el pipeline completo.\nResultados de Aprendizaje (RAE) Evaluados:\n* RAE 1.1: Implementar algoritmos de deep learning.\n* RAE 1.2: Evaluar algoritmos en el contexto médico.\n* RAE 1.3/1.4: Identificar componentes teóricos y prácticos del sistema.\n* RAE Transversales: Comunicar, innovar y aplicar herramientas modernas."
  },
  {
    "objectID": "laboratorios/ASIM/ProyectoFinal.html#el-escenario-el-reto-clínico",
    "href": "laboratorios/ASIM/ProyectoFinal.html#el-escenario-el-reto-clínico",
    "title": "Proyecto Integrador Final en IA Biomédica",
    "section": "🏥 El Escenario: El Reto Clínico",
    "text": "🏥 El Escenario: El Reto Clínico\nComo ingenieros biomédicos senior, su equipo desarrollará una solución de IA para uno de los siguientes problemas. Deben seleccionar uno:\n\n\nReto A: Análisis de Señales 🧠\n\nProblema: Predicción de series temporales médicas.\nDatos: Señales fisiológicas (p.ej., EEG, ECG).\nObjetivo: Desarrollar un modelo basado en CNN que clasifique un estado patológico a partir de la señal.\nDataset: Buscar un dataset con una afección de su elección.\n\n\nReto B: Análisis de Imágenes 🖼️\n\nProblema: Segmentación de estructuras anatómicas o patologías.\nDatos: Imágenes médicas (p.ej., MRI, CT, Rayos X).\nObjetivo: Implementar un modelo basado en CNN para la segmentación semántica precisa de una región de interés.\nDataset: Buscar un dataset con una afección de su elección."
  },
  {
    "objectID": "laboratorios/ASIM/ProyectoFinal.html#fases-del-proyecto-el-entregable",
    "href": "laboratorios/ASIM/ProyectoFinal.html#fases-del-proyecto-el-entregable",
    "title": "Proyecto Integrador Final en IA Biomédica",
    "section": "🛠️ Fases del Proyecto (El Entregable)",
    "text": "🛠️ Fases del Proyecto (El Entregable)\nEl proyecto se divide en 3 Fases de entrega, alineadas con los criterios de evaluación.\n\nFase 1: Formulación y Procesamiento de Datos\n(Criterios 1 y 2)\nSu primera entrega debe definir:\n\nFormulación del Problema:\n\n¿Cómo tradujo el “reto clínico” a un problema de ML (p.ej., clasificación, regresión, segmentación)?.\n¿Cuál es la hipótesis de su proyecto?\n\nAnálisis y Preprocesamiento de Datos:\n\nJustificación de las técnicas de preprocesamiento (p.ej., filtrado, normalización, data augmentation).\nManejo de artefactos y formatos médicos (p.ej., DICOM, EDF, NIfTI)."
  },
  {
    "objectID": "laboratorios/ASIM/ProyectoFinal.html#fases-del-proyecto-el-entregable-1",
    "href": "laboratorios/ASIM/ProyectoFinal.html#fases-del-proyecto-el-entregable-1",
    "title": "Proyecto Integrador Final en IA Biomédica",
    "section": "🛠️ Fases del Proyecto (El Entregable)",
    "text": "🛠️ Fases del Proyecto (El Entregable)\n\nFase 2: Modelado y Evaluación Rigurosa\n(Criterios 3 y 4)\nEl núcleo de su implementación debe incluir:\n\nJustificación del Modelo (RAE 1.4):\n\n¿Por qué esta arquitectura (p.ej., CNN, LSTM, U-Net)? Justifique teóricamente su elección sobre modelos más simples.\nSi usa Transfer Learning, ¿por qué y cómo?\n\nEvaluación Rigurosa (RAE 1.2):\n\nMétricas: No se aceptará solo accuracy. Debe usar métricas relevantes al contexto clínico (Sensibilidad, Especificidad, F1, Coeficiente de Dice, IoU).\nValidación: Estrategia de validación robusta (p.ej., Cross-validation por paciente, no por muestra)."
  },
  {
    "objectID": "laboratorios/ASIM/ProyectoFinal.html#fases-del-proyecto-el-entregable-2",
    "href": "laboratorios/ASIM/ProyectoFinal.html#fases-del-proyecto-el-entregable-2",
    "title": "Proyecto Integrador Final en IA Biomédica",
    "section": "🛠️ Fases del Proyecto (El Entregable)",
    "text": "🛠️ Fases del Proyecto (El Entregable)\n\nFase 3: Análisis Crítico y Comunicación\n(Criterios 5 y 6)\nEl proyecto no termina en la métrica; termina en la interpretación:\n\nAnálisis Crítico (RAE 4.5):\n\n¿Dónde falla su modelo? (Análisis de falsos positivos/negativos).\n¿Qué limitaciones tiene? (Interpretación).\n\nConsideraciones Éticas:\n\n¿Qué sesgos puede tener su modelo?\n¿Cuál es el riesgo de un fallo en la práctica clínica?\n\nComunicación (RAE 4.0):\n\nEntregar un informe en formato de artículo científico o idea de negocio.\nCódigo 100% reproducible (en Colab o similar)."
  },
  {
    "objectID": "laboratorios/ASIM/ProyectoFinal.html#rúbrica-de-evaluación-del-proyecto",
    "href": "laboratorios/ASIM/ProyectoFinal.html#rúbrica-de-evaluación-del-proyecto",
    "title": "Proyecto Integrador Final en IA Biomédica",
    "section": "📊 Rúbrica de Evaluación del Proyecto",
    "text": "📊 Rúbrica de Evaluación del Proyecto\nEl proyecto se evaluará sobre 5.0, basado en los 6 criterios de diseño.\n\n\n\n\n\n\n\n\n\n\nCriterio\nInsuficiente (0-2.4)\nAceptable (2.5-3.7)\nSobresaliente (3.8-5.0)\n\n\n\n\n1. Formulación del Problema\nNo define un problema de ML claro o no se alinea con el reto clínico.\nDefine un problema de ML, pero la conexión con el reto clínico es débil o la hipótesis es vaga.\nTraduce el reto clínico en un problema de ML preciso, con una hipótesis robusta y medible.\n\n\n2. Procesamiento de Datos\nAplica técnicas genéricas sin justificación. No maneja artefactos o formatos médicos.\nAplica técnicas de preprocesamiento, pero la justificación es débil o no es específica del dominio biomédico.\nJustifica y aplica preprocesamiento avanzado y específico para la modalidad (p.ej., filtrado de ECG, registro de MRI), manejando artefactos.\n\n\n3. Implementación del Modelo\nEl modelo no es de aprendizaje profundo o es una copia de un tutorial sin adaptación. El código no funciona.\nImplementa un modelo de DL funcional, pero la arquitectura no está justificada o es subóptima para el problema.\nImplementa una arquitectura de DL avanzada (p.ej., LSTM, U-Net), justifica teóricamente su elección y adapta el modelo al problema.\n\n\n4. Evaluación Rigurosa\nUsa solo accuracy o aplica mal la validación (p.ej., data leakage).\nUsa métricas adecuadas (p.ej., F1), pero no las interpreta en el contexto clínico. La validación es simple.\nAplica y justifica un conjunto de métricas relevantes (Dice, Sensibilidad) y una estrategia de validación robusta (p.ej., k-fold por paciente).\n\n\n5. Análisis Crítico y Ética\nNo hay análisis de errores ni discusión de limitaciones o ética.\nEl análisis es superficial. Menciona la ética solo de pasada, sin conectarla al proyecto.\nProvee un análisis profundo de los fallos del modelo, sus limitaciones reales y una discusión ética contextualizada (sesgos, riesgos).\n\n\n6. Comunicación y Reproducibilidad\nEl informe es incomprensible o el código no es reproducible.\nEl informe es claro pero carece de estructura científica. El código se puede ejecutar con esfuerzo.\nEl informe está escrito como un artículo científico. El código es 100% reproducible (p.ej., Colab) con un solo clic."
  },
  {
    "objectID": "laboratorios/ASIM/ProyectoFinal.html#preguntas",
    "href": "laboratorios/ASIM/ProyectoFinal.html#preguntas",
    "title": "Proyecto Integrador Final en IA Biomédica",
    "section": "¿Preguntas?",
    "text": "¿Preguntas?\nRecursos:\n* Python, VSCode, Google Colab\n* Bibliografía del curso\nHerramientas y Prerrequisitos:\n* Señales y Sistemas\n* Procesamiento de Señales e Imágenes Médicas (PSIM)\n¡A trabajar!"
  },
  {
    "objectID": "laboratorios/ASIM/lab002_CNN.html",
    "href": "laboratorios/ASIM/lab002_CNN.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import sys\nsys.executable\n\n'/home/sylph/Data_Cantatio/CausalXplicative_AI/FallingRisk__Arturo/.venv/bin/python'\n\n\n\nimport torch\nimport torchvision\n\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import DataLoader\n\nimport torch.nn as nn\n\nfrom torch import utils\nfrom torch import optim\nfrom torch import device\nfrom torch import inference_mode\n\nimport tqdm\n\nfrom timeit import default_timer as timer\nfrom tqdm.auto import tqdm\n\nfrom torchmetrics import ConfusionMatrix\nimport mlxtend\nfrom mlxtend.plotting import plot_confusion_matrix\nimport numpy\nfrom torchvision.transforms.v2 import (\n    ConvertImageDtype,\n    Normalize,\n    Resize,\n    CenterCrop,\n    ToTensor,\n    ToImage,\n    Compose\n)\n\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce RTX 4070 Laptop GPU\nGPU selection: NVIDIA GeForce RTX 4070 Laptop GPU\nUsing device: cuda:0\n\n\n\ntransformacion = Compose([\n    ToTensor(),\n    Normalize(mean=[0.5], std=[0.5])\n    ])\n\n/home/pablo/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n  warnings.warn(\n\n\n\ndata_flag = \"pathmnist\"\ninfo = INFO[data_flag]\nDataClass = getattr(medmnist, info[\"python_class\"])\n\n# Load the training and testing datasets\ntrain_data = DataClass(split=\"train\", transform=transformacion, download=True)\nval_data = DataClass(split=\"val\", transform=transformacion, download=True)\ntest_data = DataClass(split=\"test\", transform=transformacion, download=True)\n\nDownloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /home/pablo/.medmnist/pathmnist.npz\n\n\n100%|██████████| 205615438/205615438 [00:20&lt;00:00, 10059790.46it/s]\n\n\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\nUsing downloaded and verified file: /home/pablo/.medmnist/pathmnist.npz\n\n\n\n# check data properties\nimg = train_data[0][0]\nlabel = train_data[0][1]\n\nprint(f\"Image:\\n {img}\")\nprint(f\"Label:\\n {label}\")\n\nprint(f\"Image shape: {img.shape}\")\nprint(f\"Label: {label}\")\n\nImage:\n tensor([[[0.7255, 0.7176, 0.7255,  ..., 0.7255, 0.7176, 0.7333],\n         [0.7098, 0.7255, 0.7176,  ..., 0.5451, 0.5059, 0.4902],\n         [0.7255, 0.7255, 0.7176,  ..., 0.6314, 0.6235, 0.6392],\n         ...,\n         [0.7098, 0.7020, 0.7333,  ..., 0.7333, 0.7255, 0.7333],\n         [0.6706, 0.7020, 0.7333,  ..., 0.7333, 0.7333, 0.7333],\n         [0.6863, 0.7255, 0.7333,  ..., 0.7255, 0.7333, 0.7412]],\n\n        [[0.6314, 0.6235, 0.6235,  ..., 0.6314, 0.6235, 0.6314],\n         [0.6157, 0.6235, 0.6157,  ..., 0.3882, 0.3490, 0.3176],\n         [0.6314, 0.6235, 0.6078,  ..., 0.4980, 0.5059, 0.5216],\n         ...,\n         [0.6078, 0.5765, 0.6314,  ..., 0.6314, 0.6314, 0.6392],\n         [0.5059, 0.5686, 0.6314,  ..., 0.6314, 0.6392, 0.6314],\n         [0.5294, 0.6235, 0.6314,  ..., 0.6314, 0.6314, 0.6392]],\n\n        [[0.7804, 0.7804, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7725, 0.7725, 0.7725,  ..., 0.5843, 0.5451, 0.5294],\n         [0.7725, 0.7725, 0.7647,  ..., 0.6706, 0.6706, 0.6941],\n         ...,\n         [0.7647, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7098, 0.7412, 0.7804,  ..., 0.7804, 0.7804, 0.7804],\n         [0.7255, 0.7725, 0.7804,  ..., 0.7804, 0.7804, 0.7882]]])\nLabel:\n [0]\nImage shape: torch.Size([3, 28, 28])\nLabel: [0]\n\n\n\n# Number of image channels\nn_channels = info[\"n_channels\"]\nprint(f\"number of channels: {n_channels}\")\n\n# Number of classes\nn_classes = len(info[\"label\"])\nprint(f\"number of classes: {n_classes}\")\n\n# Get the class names from the dataset\nclass_names = info[\"label\"]\nprint(f\"class names: {class_names}\")\n\nnumber of channels: 3\nnumber of classes: 9\nclass names: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n\n\n\nfor i in range(3):\n    img = train_data[i][0]\n    label = train_data[i][1]\n    plt.figure(figsize=(3, 3))\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(label)\n    plt.axis(False)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.6313726..0.84313726].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.372549..0.85882354].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# change data into dataloader form\nBATCH_SIZE = 128\ntrain_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n\n\n# check dataloader\nprint(f\"Dataloaders: {train_dataloader, test_dataloader}\")\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")\n\nDataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53cd0&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x7fd88dd53490&gt;)\nLength of train dataloader: 704 batches of 128\nLength of test dataloader: 57 batches of 128\nLength of val dataloader: 79 batches of 128\n\n\n\n# define training loop functions\ndef train_step(\n    model: torch.nn.Module,\n    data_loader: torch.utils.data.DataLoader,\n    loss_fn: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    train_loss, train_acc = 0, 0\n    model.to(device)\n\n    for batch, (X, y) in enumerate(data_loader):\n        # need to change target shape for this medmnist data\n        y = y.squeeze().long()\n\n        # Send data to selected device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. loss and accuracy\n        loss = loss_fn(y_pred, y)\n        train_loss += loss\n        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n    # Calculate loss and accuracy per epoch\n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n\n    return train_loss, train_acc\n\n\ndef test_step(\n    data_loader: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    test_loss, test_acc = 0, 0\n    model.to(device)\n\n    model.eval()  # eval mode for testing\n    with torch.inference_mode():  # Inference context manager\n        for X, y in data_loader:\n            # need to change target shape for this medmnist data\n            y = y.squeeze().long()\n\n            # Send data to selected device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred = model(X)\n\n            # 2. Calculate loss and accuracy\n            test_loss += loss_fn(test_pred, y)\n            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n\n        # Adjust metrics and print out\n        test_loss /= len(data_loader)\n        test_acc /= len(data_loader)\n\n        return test_loss, test_acc\n\n\ndef eval_func(\n    data_loader: torch.utils.data.DataLoader,\n    model: torch.nn.Module,\n    loss_fn: torch.nn.Module,\n    accuracy_fn,\n    device: torch.device = device,\n):\n\n    eval_loss, eval_acc = 0, 0\n    model.to(device)\n\n    model.eval()\n    y_preds = []\n    y_targets = []\n    with torch.inference_mode():\n        for batch, (X, y) in tqdm(enumerate(data_loader)):\n            # need to change target shape for this medmnist data\n            y = y.squeeze().long()\n\n            # Send data to selected device\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass\n            eval_pred = model(X)\n\n            # Find loss and accuracy\n            eval_loss += loss_fn(eval_pred, y)\n            eval_acc += accuracy_fn(y_true=y, y_pred=eval_pred.argmax(dim=1))\n\n            # Add prediction and target labels to list\n            eval_labels = torch.argmax(torch.softmax(eval_pred, dim=1), dim=1)\n            y_preds.append(eval_labels)\n            y_targets.append(y)\n\n        # Scale loss and acc\n        eval_loss /= len(data_loader)\n        eval_acc /= len(data_loader)\n\n        # Put predictions on CPU for evaluation\n        y_preds = torch.cat(y_preds).cpu()\n        y_targets = torch.cat(y_targets).cpu()\n\n        return {\n            \"model_name\": model.__class__.__name__,\n            \"loss\": eval_loss.item(),\n            \"accuracy\": eval_acc,\n            \"predictions\": y_preds,\n            \"targets\": y_targets,\n        }\n\n\ndef print_train_time(start: float, end: float, device: torch.device = None):\n    total_time = end - start\n    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n    return total_time\n\n\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct / len(y_pred)) * 100\n    return acc\n\n\nclass cnn(torch.nn.Module):\n    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n        super().__init__()\n\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=input_shape, out_channels=hidden_units, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n        )\n\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units, out_channels=hidden_units, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units, out_channels=hidden_units * 4, kernel_size=3\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n        )\n\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units * 4,\n                out_channels=hidden_units * 4,\n                kernel_size=3,\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n        )\n\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=hidden_units * 4,\n                out_channels=hidden_units * 4,\n                kernel_size=3,\n                padding=1,\n            ),\n            nn.BatchNorm2d(hidden_units * 4),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_units * 4 * 4 * 4, hidden_units * 8),\n            nn.ReLU(),\n            nn.Linear(hidden_units * 8, hidden_units * 8),\n            nn.ReLU(),\n            nn.Linear(hidden_units * 8, n_classes),\n        )\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\n# Define Model\nmodel = cnn(input_shape=n_channels, hidden_units=16, output_shape=n_classes).to(device)\n\n\n# Setup loss and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# View Model\nmodel\n\ncnn(\n  (layer1): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer2): Sequential(\n    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (layer3): Sequential(\n    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer4): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer5): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=1024, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=128, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=128, out_features=9, bias=True)\n  )\n)\n\n\n\ntorch.manual_seed(42)\n\n# Measure Time\n\ntrain_time_start_model = timer()\n\niteration_loss_list = []\niteration_accuracy_list = []\n\n# set parameters\nepochs = 10\nbest_loss = 10\n\n# call train and test function\nfor epoch in tqdm(range(epochs)):\n    train_loss, train_acc = train_step(\n        data_loader=train_dataloader,\n        model=model,\n        loss_fn=loss_fn,\n        optimizer=optimizer,\n        accuracy_fn=accuracy_fn,\n        device=device1,\n    )\n\n    test_loss, test_acc = test_step(\n        data_loader=test_dataloader,\n        model=model,\n        loss_fn=loss_fn,\n        accuracy_fn=accuracy_fn,\n        device=device1,\n    )\n\n    for iteration, (x, y) in enumerate(train_dataloader):\n        iteration_loss_list.append(train_loss.item())\n        iteration_accuracy_list.append(train_acc)\n\n    print(\n        f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\"\n    )\n\n    # save best model instance\n\n    if test_loss &lt; best_loss:\n        best_loss = test_loss\n        print(f\"Saving best model for epoch: {epoch}\")\n        torch.save(obj=model.state_dict(), f=\"./model.pth\")\n\n\ntrain_time_end_model = timer()\ntotal_train_time_model = print_train_time(\n    start=train_time_start_model, end=train_time_end_model, device=device1\n)\n\n\n\n\n\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[17], line 33\n     16 train_loss, train_acc = train_step(\n     17     data_loader=train_dataloader,\n     18     model=model,\n   (...)\n     22     device=device1,\n     23 )\n     25 test_loss, test_acc = test_step(\n     26     data_loader=test_dataloader,\n     27     model=model,\n   (...)\n     30     device=device1,\n     31 )\n---&gt; 33 for iteration, (x, y) in enumerate(train_dataloader):\n     34     iteration_loss_list.append(train_loss.item())\n     35     iteration_accuracy_list.append(train_acc)\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630, in _BaseDataLoaderIter.__next__(self)\n    627 if self._sampler_iter is None:\n    628     # TODO(https://github.com/pytorch/pytorch/issues/76750)\n    629     self._reset()  # type: ignore[call-arg]\n--&gt; 630 data = self._next_data()\n    631 self._num_yielded += 1\n    632 if self._dataset_kind == _DatasetKind.Iterable and \\\n    633         self._IterableDataset_len_called is not None and \\\n    634         self._num_yielded &gt; self._IterableDataset_len_called:\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673, in _SingleProcessDataLoaderIter._next_data(self)\n    671 def _next_data(self):\n    672     index = self._next_index()  # may raise StopIteration\n--&gt; 673     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    674     if self._pin_memory:\n    675         data = _utils.pin_memory.pin_memory(data, self._pin_memory_device)\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52, in _MapDatasetFetcher.fetch(self, possibly_batched_index)\n     50         data = self.dataset.__getitems__(possibly_batched_index)\n     51     else:\n---&gt; 52         data = [self.dataset[idx] for idx in possibly_batched_index]\n     53 else:\n     54     data = self.dataset[possibly_batched_index]\n\nFile ~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52, in &lt;listcomp&gt;(.0)\n     50         data = self.dataset.__getitems__(possibly_batched_index)\n     51     else:\n---&gt; 52         data = [self.dataset[idx] for idx in possibly_batched_index]\n     53 else:\n     54     data = self.dataset[possibly_batched_index]\n\nFile ~/.local/lib/python3.10/site-packages/medmnist/dataset.py:138, in MedMNIST2D.__getitem__(self, index)\n    132 \"\"\"\n    133 return: (without transform/target_transofrm)\n    134     img: PIL.Image\n    135     target: np.array of `L` (L=1 for single-label)\n    136 \"\"\"\n    137 img, target = self.imgs[index], self.labels[index].astype(int)\n--&gt; 138 img = Image.fromarray(img)\n    140 if self.as_rgb:\n    141     img = img.convert(\"RGB\")\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3304, in fromarray(obj, mode)\n   3301         msg = \"'strides' requires either tobytes() or tostring()\"\n   3302         raise ValueError(msg)\n-&gt; 3304 return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3206, in frombuffer(mode, size, data, decoder_name, *args)\n   3203         im.readonly = 1\n   3204         return im\n-&gt; 3206 return frombytes(mode, size, data, decoder_name, args)\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:3138, in frombytes(mode, size, data, decoder_name, *args)\n   3135 _check_size(size)\n   3137 im = new(mode, size)\n-&gt; 3138 if im.width != 0 and im.height != 0:\n   3139     decoder_args: Any = args\n   3140     if len(decoder_args) == 1 and isinstance(decoder_args[0], tuple):\n   3141         # may pass tuple instead of argument list\n\nFile ~/.local/lib/python3.10/site-packages/PIL/Image.py:559, in Image.height(self)\n    555 @property\n    556 def width(self) -&gt; int:\n    557     return self.size[0]\n--&gt; 559 @property\n    560 def height(self) -&gt; int:\n    561     return self.size[1]\n    563 @property\n    564 def size(self) -&gt; tuple[int, int]:\n\nKeyboardInterrupt: \n\n\n\n\n# Load model\nloaded_model = cnn(input_shape=n_channels, hidden_units=16, output_shape=n_classes).to(\n    device\n)\n\nloaded_model.load_state_dict(torch.load(f=\"./model.pth\"))\n\n# get results\nmodel_results = eval_func(\n    data_loader=val_dataloader,\n    model=loaded_model,\n    loss_fn=loss_fn,\n    accuracy_fn=accuracy_fn,\n    device=device,\n)\n\nmodel_results\n\n\n# Get Model predictions and true targets\ny_targets = model_results[\"targets\"]\ny_preds = model_results[\"predictions\"]\n\n# Setup confusion matrix\nconfmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\nconfmat_tensor = confmat(preds=y_preds, target=y_targets)\n\n# Plot the confusion matrix\nfix, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), class_names=class_names, figsize=(10, 7)\n)\n\n\n# Get Model predictions and true targets\ny_targets = model_results[\"targets\"]\ny_preds = model_results[\"predictions\"]\n\n# Setup confusion matrix\nconfmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\nconfmat_tensor = confmat(preds=y_preds, target=y_targets)\n\n# Plot the confusion matrix\nfix, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(), class_names=class_names, figsize=(10, 7)\n)"
  },
  {
    "objectID": "laboratorios/APSB/lab01_IniciandoJetsonNano.html",
    "href": "laboratorios/APSB/lab01_IniciandoJetsonNano.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Download the Jetson Nano 2GB Developer Kit SD Card Image and note where it was saved on the computer.\nDownload, install, and launchSD Memory Card Formatter for Windows\nDownload, install, and launch Etcher."
  },
  {
    "objectID": "laboratorios/APSB/lab01_IniciandoJetsonNano.html#requiered-downloads",
    "href": "laboratorios/APSB/lab01_IniciandoJetsonNano.html#requiered-downloads",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Download the Jetson Nano 2GB Developer Kit SD Card Image and note where it was saved on the computer.\nDownload, install, and launchSD Memory Card Formatter for Windows\nDownload, install, and launch Etcher."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "",
    "text": "Create a Jupyter notebook and solve each exercise in an individual cell.\nEach team must submit the Jupyter notebook and defend it on February 3, 2026. The defense will be carried out by one of the team members chosen at random.\nThe python libraries allow for this laboratory are: matplotlib and random"
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-1-mean-and-median",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 1: Mean and Median",
    "text": "Exercise 1: Mean and Median\nWrite a Python program that calculates the mean and median of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-2-standard-deviation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 2: Standard Deviation",
    "text": "Exercise 2: Standard Deviation\nWrite a Python program that calculates the standard deviation of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-3-data-visualization",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 3: Data Visualization",
    "text": "Exercise 3: Data Visualization\nWrite a Python program that uses the matplotlib library to visualize a histogram of a list of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-4-probability-distribution",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 4: Probability Distribution",
    "text": "Exercise 4: Probability Distribution\nWrite a Python program that calculates the probability of an event occurring given a probability distribution (e.g. normal, binomial)."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-5-conditional-probability",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 5: Conditional Probability",
    "text": "Exercise 5: Conditional Probability\nWrite a Python program that calculates the conditional probability of an event occurring given another event."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-6-bayes-theorem",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 6: Bayes’ Theorem",
    "text": "Exercise 6: Bayes’ Theorem\nWrite a Python program that applies Bayes’ theorem to update the probability of a hypothesis given new evidence."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-7-correlation-coefficient",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 7: Correlation Coefficient",
    "text": "Exercise 7: Correlation Coefficient\nWrite a Python program that calculates the correlation coefficient between two lists of numbers."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-8-regression-analysis",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 8: Regression Analysis",
    "text": "Exercise 8: Regression Analysis\nWrite a Python program that performs a simple linear regression analysis on a dataset."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-9-random-number-generation",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 9: Random Number Generation",
    "text": "Exercise 9: Random Number Generation\nWrite a Python program that generates random numbers from a specified probability distribution (e.g. normal, uniform)."
  },
  {
    "objectID": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "href": "laboratorios/SYSB/eval001_ConductaEntrada.html#exercise-10function-visualization---i",
    "title": "Basic Concepts of Statistics, Probability and Python",
    "section": "Exercise 10:Function visualization - I",
    "text": "Exercise 10:Function visualization - I\nGenerate a python code that allows the visualization (in one figure) of the real (blue) part and the imaginary (red) part, magnitude (green) and phase of the following signals:\n\\[f\\left(t\\right) = e^{-j10 \\pi t}\\]\n\\[g\\left(t\\right) = 10cos\\left(2 \\pi t\\right) + j10sin\\left(2 \\pi t\\right)\\]\nThe visualization mus be in the range \\(\\left[-10, 10\\right]\\)"
  },
  {
    "objectID": "laboratorios/SYSB/lab03a_ExtraccionCaracteristicasECG.html",
    "href": "laboratorios/SYSB/lab03a_ExtraccionCaracteristicasECG.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Actividad de Aprendizaje: Análisis de información base del dataset (Alineación de información)\nEl proyecto consiste en el desarrollo de un script en Python capaz de realizar la alineación temporal de múltiples complejos PQRST obtenidos a partir de diferentes derivaciones de electrocardiogramas (ECG).\nEl estudiante deberá implementar un procedimiento computacional que permita comparar morfologías y sincronizar los ciclos cardíacos de distintas señales, con el propósito de facilitar el análisis cuantitativo y la extracción de características relevantes para estudios biomédicos.\nLa entrega del proyecto se formaliza mediante una presentación oral de 15 minutos, en la cual el estudiante expondrá durante 10 minutos los fundamentos teóricos, el diseño del algoritmo y los resultados obtenidos, seguidos de 5 minutos destinados a preguntas y discusión técnica.\nDurante la exposición, se espera que el participante evidencie tanto su comprensión del fenómeno electrofisiológico como su capacidad para aplicar herramientas de programación científica en el procesamiento de señales biomédicas.\nEsta actividad integra de manera práctica los conocimientos adquiridos en el curso, al vincular los fundamentos teóricos de la señal electrocardiográfica con la resolución computacional de un problema real en ingeniería biomédica.\nEl proceso de alineación de complejos PQRST representa una tarea fundamental en la comparación interpaciente, detección de anomalías morfológicas y análisis de sincronía cardíaca, por lo cual su implementación favorece la comprensión del comportamiento dinámico del sistema cardiovascular.\nDesde el punto de vista formativo, la actividad fomenta el razonamiento analítico, la programación orientada al procesamiento de biosenales y la comunicación científica oral, competencias esenciales para el ejercicio profesional en ingeniería biomédica. Además, promueve la integración entre teoría y práctica, al exigir una fundamentación fisiológica sólida y una implementación computacional verificable.\n\n\n\nCriterios de evaluación\nLa evaluación se realizará mediante una presentación oral de 15 minutos, distribuidos en 10 minutos de exposición técnica y 5 minutos de preguntas.\nEl trabajo deberá evidenciar tanto comprensión teórica del fenómeno electrofisiológico como solidez técnica en la implementación computacional.\n\n\n\n\n\n\n\n\n\nCriterio\nDescripción\nIndicadores de desempeño\nPeso (%)\n\n\n\n\n1. Fundamentación teórica\nEvalúa la comprensión sobre la fisiología del ECG, la morfología del complejo PQRST y la relevancia biomédica de la alineación.\n- Explica correctamente la morfología y función del complejo PQRST.- Justifica la importancia de la alineación en el análisis de señales cardíacas.- Sustenta con referencias científicas válidas y actualizadas.\n20\n\n\n2. Implementación computacional\nEvalúa la calidad técnica, legibilidad y funcionalidad del script Python desarrollado.\n- Código documentado y estructurado.- Aplica correctamente técnicas de filtrado, segmentación y normalización.- Implementa un método de alineación apropiado (correlación cruzada, detección de picos, DTW, etc.).- Resultados reproducibles y consistentes.\n25\n\n\n3. Análisis y visualización de resultados\nEvalúa la capacidad de representar e interpretar los resultados del alineamiento.\n- Muestra comparaciones visuales antes y después del alineamiento.- Incluye métricas o gráficos de desempeño.- Interpreta resultados con lenguaje técnico y biomédico adecuado.\n20\n\n\n4. Comunicación científica oral\nEvalúa la claridad, estructura y rigor de la exposición.\n- Estructura lógica (introducción, objetivos, desarrollo, conclusiones).- Uso adecuado de terminología técnica.- Cumple con el tiempo estipulado (10 + 5 minutos).\n15\n\n\n5. Razonamiento crítico y defensa oral\nEvalúa la capacidad para justificar decisiones técnicas y discutir limitaciones.\n- Responde con fundamento teórico y técnico.- Reconoce limitaciones y propone mejoras.- Evidencia dominio del código y de los resultados.\n15\n\n\n6. Trabajo individual o en equipo\nEvalúa la equidad en la participación y la coherencia grupal.\n- Cada integrante demuestra conocimiento del trabajo global.- Presentación coherente y articulada.\n5\n\n\n\n\n\n\nEscala de calificación\n\n\n\n\n\n\n\n\nNivel de desempeño\nRango numérico\nDescripción\n\n\n\n\nExcelente\n4.6 – 5.0\nComprensión profunda del fenómeno, dominio técnico sobresaliente y comunicación científica impecable.\n\n\nSobresaliente\n4.0 – 4.5\nCumple todos los criterios con claridad, mostrando rigor técnico y conceptual.\n\n\nAceptable\n3.0 – 3.9\nEvidencia comprensión básica y una implementación funcional, con limitaciones teóricas o comunicativas.\n\n\nInsuficiente\n&lt; 3.0\nPresenta vacíos notables en comprensión, implementación o justificación de resultados.\n\n\n\n\n\n\nCorrespondencia con resultados de aprendizaje\n\n\n\n\n\n\n\nResultado de aprendizaje\nCriterios asociados\n\n\n\n\nComprender, evaluar y sintetizar información científica.\n1, 3, 5\n\n\nElaborar composiciones y exposiciones científicas comprensibles.\n4, 5\n\n\nAnalizar el comportamiento físico de la materia y energía en el contexto biomédico.\n1, 3\n\n\nResolver problemas y diseñar procesos mediante herramientas computacionales.\n2\n\n\nFormular hipótesis y generar conclusiones a partir de la experimentación.\n3, 5\n\n\nTrabajar individualmente y en equipo con responsabilidad.\n6\n\n\n\n\n\n\nIndicaciones adicionales\n\nSe valorará especialmente la capacidad de relacionar los resultados computacionales con la fisiología cardíaca subyacente.\nEl script debe ejecutarse correctamente y producir visualizaciones claras del alineamiento.\nLas respuestas durante la fase de preguntas deben evidenciar razonamiento crítico y dominio conceptual.\nEl material de apoyo (diapositivas, gráficas, ejemplos) debe ser propio y respetar las normas de uso ético de la información.\n\n\nDuración total: 15 minutos (10 exposición + 5 preguntas)\nPonderación total: 100%"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "El electrocardiograma (ECG o EKG) es una grabación de la actividad eléctrica cardíaca en la superficie de la piel, durante un período de tiempo determinado. En cada ciclo cardíaco, un corazón sano presenta una secuencia de señales eléctricas que se generan en el nodo sinoauricular y se distribuyen en el corazón hasta alcanzar los ventrículos. Estas señales tienen una forma característica que se muestra en la figura 1.\n\n\n\nFigura 1. ECG durante un ciclo cardíaco normal\n\n\nA través de un ECG, un profesional de la salud entrenado es capaz de obtener información relevante sobre el funcionamiento del corazón; por ejemplo, se puede determinar la frecuencia cardíaca, la presencia de daño en el músculo cardíaco, los efectos de medicamentos y la función de marcapasos implantados.\n\n\nLos estudiantes conocerán las principales teorías concernientes a la generación del electrocardiograma y su relación con el funcionamiento del corazón.\n\n\n\n4.5 horas\n\n\n\n\nComputador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#objetivo-de-aprendizaje",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#objetivo-de-aprendizaje",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Los estudiantes conocerán las principales teorías concernientes a la generación del electrocardiograma y su relación con el funcionamiento del corazón."
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#duración",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#duración",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "4.5 horas"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#materiales",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#materiales",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Computador.\nZheng, J., Zhang, J., Danioko, S. et al. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci Data 7, 48 (2020). https://doi.org/10.1038/s41597-020-0386-x\nDataset\nZheng, J., Chu, H., Struppa, D. et al. Optimal Multi-Stage Arrhythmia Classification Approach. Sci Rep 10, 2898 (2020). https://doi.org/10.1038/s41598-020-59821-7"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-1-revisión-al-electrocardiograms",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-1-revisión-al-electrocardiograms",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 1: Revisión al electrocardiograms",
    "text": "Actividad 1: Revisión al electrocardiograms\n\n¿Qué es un electrocardiograma (ECG) y cuál es su importancia en el diagnóstico clínico?\n¿Qué información electrofisiológica proporciona un ECG y cómo se relaciona con la actividad del corazón?\n¿Qué es una derivación (lead) en el contexto de un ECG y cuál es su función?\n¿Cuántas derivaciones existen en un ECG estándar y cómo se clasifican?\nObserve la Figura 1 proporcionada y determine a qué derivación corresponde el diagrama mostrado. Justifique su respuesta.\n¿Qué es una arritmia y qué tipos existen? Describa las características de cada tipo de arritmia."
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-2-análisis-del-articulo",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-2-análisis-del-articulo",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 2: Análisis del articulo",
    "text": "Actividad 2: Análisis del articulo\n\n¿Cuáles son las principales clases de arritmias que el artículo estudia y cómo se agrupan?\n¿Qué impacto tienen las arritmias en la salud pública según el artículo? Mencione datos estadísticos relevantes.\n¿Por qué es importante mejorar la precisión en la clasificación automática de arritmias?\n¿Cuáles son las principales fuentes de ruido en una señal de ECG y qué técnicas se utilizaron en el artículo para reducirlas?\n¿Por qué se aplicó normalización a las señales ECG? ¿Qué impacto tuvo en la clasificación? Explique el método de normalización.\n¿Cuáles son las principales características extraídas de la señal ECG en este estudio?\n¿Por qué es importante la selección de características para el entrenamiento de un algoritmo de clasificación?"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-3-análisis-de-la-base-de-datos",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#actividad-3-análisis-de-la-base-de-datos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Actividad 3: Análisis de la base de datos",
    "text": "Actividad 3: Análisis de la base de datos\n\n¿Cuáles fueron los criterios de selección de los pacientes?\n¿Cuántos registros de ECG se recopilaron en total y qué duración tienen las señales analizadas?\n¿Cómo se realizó la toma de datos del ECG? Especifique el número de derivaciones, la duración del registro y la frecuencia de muestreo.\n¿Cuáles fueron las características demográficas de la población estudiada? Describa la distribución por edad y género.\n¿Cuál fue la prevalencia de cada tipo de arritmia en la base de datos? ¿Qué arritmias fueron las más frecuentes y cuáles fueron las menos comunes?"
  },
  {
    "objectID": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#criterios-de-evaluación",
    "href": "laboratorios/SYSB/lab02_Introduccion_Proc_Sennales.html#criterios-de-evaluación",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Criterios de Evaluación",
    "text": "Criterios de Evaluación\n\n\n\n\n\n\n\n\n\n\n\nCriterio\nNivel Excelente (5.0 - 4.5)\nNivel Satisfactorio (4.4 - 3.5)\nNivel Aceptable (3.4 - 2.5)\nNivel Deficiente (&lt;2.5)\nPeso (%)\n\n\n\n\nComprensión teórica del ECG y su relevancia clínica\nExplica de manera clara y detallada la importancia del ECG, su función diagnóstica y la información electrofisiológica que proporciona. Responde con precisión todas las preguntas teóricas.\nResponde la mayoría de las preguntas con claridad, pero algunas respuestas pueden carecer de profundidad o detalles.\nResponde las preguntas de manera parcial o con imprecisiones conceptuales. Falta claridad en algunos conceptos.\nRespuestas incompletas o con errores fundamentales en la comprensión del ECG y su relevancia.\n20%\n\n\nAnálisis del artículo de Zheng et al.\nIdentifica y sintetiza correctamente las clases de arritmias, impacto en salud pública, técnicas de reducción de ruido y normalización. Argumenta con evidencia del artículo.\nPresenta un buen análisis, aunque algunas respuestas carecen de profundidad o precisión. Uso adecuado pero limitado de la evidencia.\nMuestra dificultad en identificar o explicar correctamente algunos conceptos clave del artículo.\nAnálisis deficiente, respuestas vagas o incorrectas, falta de relación con el artículo.\n20%\n\n\nAnálisis de la base de datos de ECG\nDescribe con precisión los criterios de selección, número de registros, condiciones de adquisición y características demográficas. Utiliza correctamente los datos del artículo.\nExplica la mayoría de los aspectos, aunque con algunas omisiones o falta de precisión en los datos.\nResponde parcialmente, con confusión en algunos aspectos metodológicos o demográficos.\nNo logra describir correctamente los criterios de la base de datos o presenta errores graves en su interpretación.\n20%\n\n\nJustificación y análisis de derivaciones\nIdentifica correctamente la derivación del ECG mostrado en la Figura 1, justificando con base en conocimientos teóricos.\nIdentifica la derivación con una justificación aceptable, aunque podría ser más clara.\nPresenta una identificación incorrecta o incompleta con una justificación débil.\nNo justifica o identifica erróneamente la derivación.\n15%\n\n\nPresentación y redacción del informe\nInforme bien estructurado, sin errores gramaticales o de formato. Uso adecuado de referencias. Argumentación clara y precisa.\nInforme organizado, aunque con algunos errores menores de gramática o formato. Argumentación adecuada.\nPresentación con errores de redacción y formato. Explicaciones poco estructuradas.\nInforme desorganizado, con errores graves de gramática y sin referencias adecuadas.\n15%\n\n\nParticipación y trabajo en equipo\nDemuestra alto compromiso y participación en la sesión de laboratorio. Contribuye activamente al desarrollo del informe.\nParticipa en la mayoría de las actividades, aunque con algunas intervenciones limitadas.\nParticipa de forma esporádica o depende en exceso del grupo para completar las actividades.\nNo participa o su aporte al equipo es mínimo.\n10%\n\n\n\nTotal: 100% puntos."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab04_sol_ImagProc02.html",
    "href": "laboratorios/PSIM/Previous/lab04_sol_ImagProc02.html",
    "title": "Algoritmos básicos de procesamiento de imágenes",
    "section": "",
    "text": "Usando la imagen fresas.png la cual fue tomada de la página Geeks for geeks resuelva las siguientes cuestiones.\n\nAplique las siguientes transformaciones y describa el efecto de cada transformación:\n\nTransformación n-potencial con \\(1&lt;n&lt;2\\)\nTransformación n-potencial con \\(0.5&lt;n&lt;1\\)\nTransformación LOG (Logaritmo Natural)\nTransformación exponencial\nDescriba en un diagrama de bloques el algoritmo necesario para realizar este tipo de transformaciones.\nInvestigue y desarrolle el algoritmo de la transformación \\(\\Gamma\\). La información básica la puede encontrar aqui\n\n\nRecuerde: Si una imagen queda completamente blanca o completamente negra, es probable que sea por mal manejo de rangos de intensidad\n\nimport pydicom as pyimag1\nimport cv2 as pyimag2\nimport matplotlib.pyplot as pyimag3\nimport numpy as pyimag4\n\nruta = \"../../data/imagen_dicom.dcm\"\n\n\ndata_imagen = pyimag1.dcmread(ruta)\nimage = data_imagen.pixel_array\npyimag3.imshow(image, cmap=\"gray\")\npyimag3.axis(\"off\")\n\npatient_name= data_imagen.PatientID\nprint(f\"Nombre del paciente: {patient_name}\")\n\nNombre del paciente: 239\n\n\n\n\n\n\n\n\n\n\nSea los siguientes kernels de convolución:\n\n\\(\\begin{bmatrix}\n1 & 1 & 1 \\\\\n1 & -8 & 1 \\\\\n1 & 1 & 1\n\\end{bmatrix}\\)\n\\(\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n-1 & 8 & -1 \\\\\n-1 & -1 & -1\n\\end{bmatrix}\\)\n\n\nExplique las siguientes cuestiones:\n\nInvestigue las formas de realizar la convolución con opencv.\nAplique cada uno de los kernels de convolución y compare los resultados.\nExplique cuales son las respectivas resoluciónes de pixel de las imagenes resultantes así como su máximo y su mínimo.\n\n\nkernel1 = (1 / 9) * pyimag4.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\nkernel2 = pyimag4.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\nconv1 = pyimag2.filter2D(image, ddepth=-1, kernel=kernel1)\nconv1_normalized = pyimag2.normalize(conv1, None, 0, 255, pyimag2.NORM_MINMAX)\nconv2 = pyimag2.filter2D(image, ddepth=-1, kernel=kernel2)\nconv2_normalized = pyimag2.normalize(conv2, None, 0, 255, pyimag2.NORM_MINMAX)\npyimag3.imshow(pyimag4.concatenate(\n    (conv1_normalized, conv2_normalized), \n    axis=1), \n    cmap=\"gray\")\npyimag3.axis(\"off\")\n\n\n\n\n\n\n\n\n\nrows, cols = image.shape\nangle = 45\nM = pyimag2.getRotationMatrix2D((cols//2, rows//2), angle, 1)\ntransformed_image = pyimag2.warpAffine(image, M, (cols, rows))\npyimag3.imshow(transformed_image, cmap=\"gray\")\npyimag3.axis(\"off\")\n\n\n\n\n\n\n\n\n\nUtilizando la imagen radiografía, aplique cada tipo de matriz afine presente en las diapositivas de clase\nDeterminar proyecto final para PSIM.\n\nDeterminar el problema a resolver.\nDeterminar el objetivo a alcanzar\nDeterminar el dataset\n\n\nRecuerde, en su proyecto final, NO podrá hacer uso de algoritmos de machine learning."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/lab04_ImagProc02.html",
    "href": "laboratorios/PSIM/Previous/lab04_ImagProc02.html",
    "title": "Algoritmos básicos de procesamiento de imágenes",
    "section": "",
    "text": "Usando la imagen fresas.png la cual fue tomada de la página Geeks for geeks resuelva las siguientes cuestiones.\n\nAplique las siguientes transformaciones y describa el efecto de cada transformación:\n\nTransformación n-potencial con \\(1&lt;n&lt;2\\)\nTransformación n-potencial con \\(0.5&lt;n&lt;1\\)\nTransformación LOG (Logaritmo Natural)\nTransformación exponencial\nDescriba en un diagrama de bloques el algoritmo necesario para realizar este tipo de transformaciones.\nInvestigue y desarrolle el algoritmo de la transformación \\(\\Gamma\\). La información básica la puede encontrar aqui\n\n\nRecuerde: Si una imagen queda completamente blanca o completamente negra, es probable que sea por mal manejo de rangos de intensidad\n\nSea los siguientes kernels de convolución:\n\n\\(\\begin{bmatrix}\n1 & 1 & 1 \\\\\n1 & -8 & 1 \\\\\n1 & 1 & 1\n\\end{bmatrix}\\)\n\\(\\begin{bmatrix}\n-1 & -1 & -1 \\\\\n-1 & 8 & -1 \\\\\n-1 & -1 & -1\n\\end{bmatrix}\\)\n\n\nExplique las siguientes cuestiones:\n\nInvestigue las formas de realizar la convolución con opencv.\nAplique cada uno de los kernels de convolución y compare los resultados.\nExplique cuales son las respectivas resoluciónes de pixel de las imagenes resultantes así como su máximo y su mínimo.\n\n\nUtilizando la imagen radiografía, aplique cada tipo de matriz afine presente en las diapositivas de clase\nDeterminar proyecto final para PSIM.\n\nDeterminar el problema a resolver.\nDeterminar el objetivo a alcanzar\nDeterminar el dataset\n\n\nRecuerde, en su proyecto final, NO podrá hacer uso de algoritmos de machine learning."
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#data-creation",
    "title": "Numerical Calculus Review",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return x**4 - 4*x**2 + 4\n\nt = np.linspace(-10, 10, 1000)\nf_t = f(t)\n\nplt.plot(t,f_t)\nplt.xlabel(\"t(s)\")\n\nText(0.5, 0, 't(s)')"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-diferentation",
    "title": "Numerical Calculus Review",
    "section": "Numerical Diferentation",
    "text": "Numerical Diferentation\nDetermine the numerical derivative of the function f, represented as \\(\\left(\\frac{df}{dt}\\right)\\), via finite difference approximation. Subsequently, contrast this result with the numerical evaluation of the symbolic derivative, derived through analytical differentiation, to assess the precision of the numerical approach\n\ndef f_hat(x):\n    return 4*(x**3) - 8*x\n\ndef shift(xs, n):\n    if n &gt;= 0:\n        return np.concatenate((np.full(n, xs[0]), xs[:-n]))\n    else:\n        return np.concatenate((xs[-n:], np.full(-n, xs[-1])))\n\ndef f_hat_num(x,t):\n    delta = shift(t, -1) - t\n    salida = (shift(x, -1) - x) / np.mean(delta[:-1])\n    return np.concatenate((salida[:-1], [salida[-2]]))\n\n\ntemp = np.array([0,1,2,3,4,5,6])\nnp.concatenate([temp, [temp[-1]]])\n\narray([0, 1, 2, 3, 4, 5, 6, 6])\n\n\n\nplt.plot(t, f_hat(t))\nplt.plot(t, f_hat_num(f(t), t))"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-integration",
    "title": "Numerical Calculus Review",
    "section": "Numerical Integration",
    "text": "Numerical Integration\nDetermine the numerical integration of the function f, represented as \\(\\left(\\int_{-10}^{10}{f(t)dt}\\right)\\), via trapezoidal rule. Subsequently, contrast this result with the numerical evaluation of the symbolic integral, derived through analytical differentiation, to assess the precision of the numerical approach\n\nimport sympy as sp\n\n# Define the variable and the expression\nx1 = sp.symbols(\"x1\")\nexpr = x1**4 - 4 * x1**2 + 4\n\nresult = sp.integrate(expr, (x1, -10, 10)).evalf()\n\n# Print the LaTeX representation\nprint(sp.latex(expr))\nprint(result)\n\nx_{1}^{4} - 4 x_{1}^{2} + 4\n37413.3333333333\n\n\n\n# Define the limits of integration\na = -10\nb = 10\n\n# Define the number of subintervals\nn = 100\n\n# Calculate the width of each subinterval\nh = (b - a) / n\n\n# Initialize the sum\nsum = 0.5 * (f(a) + f(b))\n\n# Apply the Trapezoid Rule\nfor i in range(1, n):\n    sum += f(a + i * h)\n\n# Calculate the integral\nintegral = h * sum\n\nprint(\"Approximate integral:\", integral)\n\nApproximate integral: 37439.465599999996"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-solutions-of-ordinary-differential-equations-odes",
    "title": "Numerical Calculus Review",
    "section": "Numerical solutions of ordinary differential equations (ODEs)",
    "text": "Numerical solutions of ordinary differential equations (ODEs)\nSolve the ODE \\(\\frac{dy}{dx} = 2x - 3y\\) with initial condition y(0) = 1 using Euler’s Method. With a step 0f 0.1. Suppose that: \\(x \\in \\left[0, 10\\right]\\) and \\(y \\in \\left[1, 10\\right]\\)\n\n# Define the derivative function\ndef f1(x, y):\n    return 2 * x - 3 * y\n\n\n# Initial condition\nx0 = 0\ny0 = 1\n\n# Step size\nh = 0.1\n\n# Total steps\nn = int(10 / h)\n\n# Create arrays to store x and y values\nx = [0] * (n + 1)\ny = [0] * (n + 1)\n\n# Initialize x and y arrays\nx[0] = x0\ny[0] = y0\n\n# Euler's Method\nfor i in range(n):\n    x[i + 1] = x[i] + h\n    y[i + 1] = y[i] + h * f1(x[i], y[i])"
  },
  {
    "objectID": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "href": "laboratorios/PSIM/Previous/sol_lab01_ReviewNumericalCalc.html#numerical-optimization",
    "title": "Numerical Calculus Review",
    "section": "Numerical optimization",
    "text": "Numerical optimization\nMinimize the function f(x) = x^4 - 4x^2 + 4 using Gradient Descent.\n\nt1= np.linspace(-2,2,1000)\nplt.plot(t1, f(t1))\n\n\n\n\n\n\n\n\n\n# Initial guess\nx0 = 10 * (np.random.rand() - 0.5)\n\n# Learning rate\nalpha = 0.01\n\n# Number of iterations\nn_iter = 1000\n\n# Gradient Descent\nxg = x0\nfor i in range(n_iter):\n    xg = xg - alpha * f_hat(xg)\n\n# Print the minimum\nprint(\"Time of the minimum:\", xg)\nprint(\"Function value at minimum:\", f(xg))\n\nTime of the minimum: -1.4142135623730956\nFunction value at minimum: 8.881784197001252e-16"
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Comprender la estructura digital de una imagen como matriz de píxeles.\nAplicar técnicas básicas de manipulación de imágenes usando Python.\nDesarrollar funciones para codificar y decodificar información textual en imágenes.\nReflexionar sobre la importancia del procesamiento de imágenes en aplicaciones biomédicas.\n\n\n\n\n\nLenguaje: Python 3\nLibrerías: opencv-python (cv2), numpy, matplotlib, pydicom.\n\n\n\n\n\nCarga y visualización de imágenes dicom\nConversión de texto a binario\nCodificación de bits en el canal de color\nRecuperación del mensaje codificado\nGeneración de la imagen dicom\n\n\n\n\nCada grupo trabajará una variante distinta del laboratorio base. Esto garantiza diversidad de enfoques y evita el plagio entre equipos.\n\n\n\n\n\n\n\n\nGrupo\nVariante asignada\nDescripción\n\n\n\n\nA\nCanal rojo\nSolo puede usar el canal rojo para codificar.\n\n\nB\nOrden inverso\nEl mensaje se codifica recorriendo los píxeles en orden inverso.\n\n\nC\nDos mensajes\nCodifica dos mensajes distintos: uno en azul y otro en verde.\n\n\nD\nCompresión básica\nComprime el mensaje antes de insertarlo.\n\n\nE\nEscala de grises\nUtiliza imágenes en escala de grises para codificación.\n\n\nF\nAlto contraste\nSolo se permite codificar en píxeles con alto contraste respecto a sus vecinos.\n\n\nG\nPatrón de ajedrez\nEl mensaje se codifica en píxeles alternos como patrón de ajedrez.\n\n\nH\nTres bits\nSe usan los tres bits menos significativos para codificar cada carácter.\n\n\nI\nBaja variabilidad local\nEl mensaje solo se codifica en zonas donde los valores de píxel son muy similares entre vecinos.\n\n\n\n\n\n\nCodifica el siguiente mensaje dentro de una imagen asignada por el docente:\n\"Paciente Juan Pérez, ID: 203911, ECG normal, sin antecedentes\"\nCada grupo deberá:\n\nEntregar el código Python funcional.\nComparar la imagen original y la modificada.\nRecuperar correctamente el mensaje.\nEntregar un informe breve explicando el proceso y los retos del grupo.\n\n\n\n\n\n\n\nCriterio\nPuntaje\n\n\n\n\nManipulación básica de imágenes\n20 pts\n\n\nCodificación y recuperación funcional\n40 pts\n\n\nAdaptación a la variante del grupo\n30 pts\n\n\nInforme técnico claro y bien escrito\n10 pt\n\n\nTotal\n100 pts\n\n\n\n\n\n\n\n¿Qué aplicaciones biomédicas podrían beneficiarse del ocultamiento de datos en imágenes? Explica una situación clínica concreta donde esta técnica sería útil."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#objetivos-del-laboratorio",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#objetivos-del-laboratorio",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Comprender la estructura digital de una imagen como matriz de píxeles.\nAplicar técnicas básicas de manipulación de imágenes usando Python.\nDesarrollar funciones para codificar y decodificar información textual en imágenes.\nReflexionar sobre la importancia del procesamiento de imágenes en aplicaciones biomédicas."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#herramientas",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#herramientas",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Lenguaje: Python 3\nLibrerías: opencv-python (cv2), numpy, matplotlib, pydicom."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#actividades-comunes-a-todos-los-grupos",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#actividades-comunes-a-todos-los-grupos",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Carga y visualización de imágenes dicom\nConversión de texto a binario\nCodificación de bits en el canal de color\nRecuperación del mensaje codificado\nGeneración de la imagen dicom"
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#variantes-del-laboratorio-por-grupo",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#variantes-del-laboratorio-por-grupo",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Cada grupo trabajará una variante distinta del laboratorio base. Esto garantiza diversidad de enfoques y evita el plagio entre equipos.\n\n\n\n\n\n\n\n\nGrupo\nVariante asignada\nDescripción\n\n\n\n\nA\nCanal rojo\nSolo puede usar el canal rojo para codificar.\n\n\nB\nOrden inverso\nEl mensaje se codifica recorriendo los píxeles en orden inverso.\n\n\nC\nDos mensajes\nCodifica dos mensajes distintos: uno en azul y otro en verde.\n\n\nD\nCompresión básica\nComprime el mensaje antes de insertarlo.\n\n\nE\nEscala de grises\nUtiliza imágenes en escala de grises para codificación.\n\n\nF\nAlto contraste\nSolo se permite codificar en píxeles con alto contraste respecto a sus vecinos.\n\n\nG\nPatrón de ajedrez\nEl mensaje se codifica en píxeles alternos como patrón de ajedrez.\n\n\nH\nTres bits\nSe usan los tres bits menos significativos para codificar cada carácter.\n\n\nI\nBaja variabilidad local\nEl mensaje solo se codifica en zonas donde los valores de píxel son muy similares entre vecinos."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#ejercicio-integrador",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#ejercicio-integrador",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Codifica el siguiente mensaje dentro de una imagen asignada por el docente:\n\"Paciente Juan Pérez, ID: 203911, ECG normal, sin antecedentes\"\nCada grupo deberá:\n\nEntregar el código Python funcional.\nComparar la imagen original y la modificada.\nRecuperar correctamente el mensaje.\nEntregar un informe breve explicando el proceso y los retos del grupo."
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#evaluación",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#evaluación",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "Criterio\nPuntaje\n\n\n\n\nManipulación básica de imágenes\n20 pts\n\n\nCodificación y recuperación funcional\n40 pts\n\n\nAdaptación a la variante del grupo\n30 pts\n\n\nInforme técnico claro y bien escrito\n10 pt\n\n\nTotal\n100 pts"
  },
  {
    "objectID": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#pregunta-de-reflexión",
    "href": "laboratorios/PSIM/lab04_ManipulacionImagenes.html#pregunta-de-reflexión",
    "title": "Laboratorio 004: Manipulacion de Imágenes",
    "section": "",
    "text": "¿Qué aplicaciones biomédicas podrían beneficiarse del ocultamiento de datos en imágenes? Explica una situación clínica concreta donde esta técnica sería útil."
  },
  {
    "objectID": "laboratorios/PSIM/lab05_EDA_Convolucion.html",
    "href": "laboratorios/PSIM/lab05_EDA_Convolucion.html",
    "title": "Laboratorio 004: EDA de Imágenes de Tórax + Convolución (Efecto del Ancla",
    "section": "",
    "text": "Servicio de Radiología – Auditoría de calidad en la ronda de la mañana\nComo ingeniero(a) biomédico(a) del Servicio de Radiología, cada mañana debes auditar la calidad de radiografías de tórax antes de liberar agenda clínica. Trabajarás con un subconjunto balanceado del dataset Chest X-Ray Images (Pneumonia) (clases: NORMAL y PNEUMONIA). Cita la fuente y fecha de descarga en tu primera diapositiva."
  },
  {
    "objectID": "laboratorios/PSIM/lab05_EDA_Convolucion.html#reglas-de-la-práctica",
    "href": "laboratorios/PSIM/lab05_EDA_Convolucion.html#reglas-de-la-práctica",
    "title": "Laboratorio 004: EDA de Imágenes de Tórax + Convolución (Efecto del Ancla",
    "section": "Reglas de la práctica",
    "text": "Reglas de la práctica\n\nSolo OpenCV (cv2); se permite NumPy como soporte de arreglos.\nLa evaluación es por presentación (no por informe escrito).\nDebes usar explícitamente las funciones: cv.calcHist, cv.compareHist, cv.filter2D con anchor, y cv.Laplacian para enfoque.\nMuestra seudocódigo y resultados (figuras/tablas) en las diapositivas. Evita código ejecutable en la presentación.\nTodas las funciones deben ser comprendidas desde el punto de vista matemático y computacional."
  },
  {
    "objectID": "laboratorios/PSIM/lab05_EDA_Convolucion.html#objetivos-de-aprendizaje",
    "href": "laboratorios/PSIM/lab05_EDA_Convolucion.html#objetivos-de-aprendizaje",
    "title": "Laboratorio 004: EDA de Imágenes de Tórax + Convolución (Efecto del Ancla",
    "section": "Objetivos de aprendizaje",
    "text": "Objetivos de aprendizaje\n\nEjecutar un EDA por clase (NORMAL vs PNEUMONIA) con estadísticas descriptivas e histogramas.\nComparar histogramas globales y por ROIs, justificando la métrica más informativa.\nEstimar calidad (enfoque por Laplaciano; contraste) con operadores de OpenCV.\nDemostrar el efecto del píxel de anclaje (anchor) en una convolución 2D y discutir su impacto en mapas de bordes/mediciones."
  },
  {
    "objectID": "laboratorios/PSIM/lab05_EDA_Convolucion.html#datos-obligatorio",
    "href": "laboratorios/PSIM/lab05_EDA_Convolucion.html#datos-obligatorio",
    "title": "Laboratorio 004: EDA de Imágenes de Tórax + Convolución (Efecto del Ancla",
    "section": "Datos (obligatorio)",
    "text": "Datos (obligatorio)\n\nFuente: Kaggle – Chest X-Ray Images (Pneumonia)\nhttps://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\nClases: NORMAL y PNEUMONIA.\nMuestreo sugerido: 60 imágenes por clase (balanceado) para auditoría (no entrenamiento).\nBuenas prácticas: Trabaja sobre copias; no modifiques originales. Documenta toda normalización/realce en una bitácora.\n\nSlide 1 (requisito): Equipo y roles, fuente del dataset, fecha de descarga, estructura de carpetas y riesgos de sesgo (edad, equipo Rx, proyección, etc.)."
  },
  {
    "objectID": "laboratorios/PSIM/lab05_EDA_Convolucion.html#entregable-y-logística-de-evaluación",
    "href": "laboratorios/PSIM/lab05_EDA_Convolucion.html#entregable-y-logística-de-evaluación",
    "title": "Laboratorio 004: EDA de Imágenes de Tórax + Convolución (Efecto del Ancla",
    "section": "Entregable y logística de evaluación",
    "text": "Entregable y logística de evaluación\n\nPresentación por equipos: 6–8 minutos + 2 minutos de preguntas. Máximo 8 diapositivas.\nSecuencia sugerida de slides:\n\nPortada y datos.\nMuestreo y control de sesgos.\nEDA global (estadísticos + histogramas por clase).\nComparación de histogramas (global y ROIs).\nCalidad (enfoque, contraste) con lectura clínica.\nConvolución + ancla (delta + ROI real).\nRecomendaciones de QA y límites.\nApéndice: funciones usadas e hiperparámetros."
  },
  {
    "objectID": "laboratorios/PSIM/lab05_EDA_Convolucion.html#rúbrica-de-evaluación-100-pts",
    "href": "laboratorios/PSIM/lab05_EDA_Convolucion.html#rúbrica-de-evaluación-100-pts",
    "title": "Laboratorio 004: EDA de Imágenes de Tórax + Convolución (Efecto del Ancla",
    "section": "Rúbrica de evaluación (100 pts)",
    "text": "Rúbrica de evaluación (100 pts)\n\n\n\n\n\n\n\n\n\nCriterio\nDescripción\nEvidencia esperada en la presentación\nPuntos\n\n\n\n\nContexto clínico y datos\nCita del dataset (Kaggle), clases, balance, riesgos de sesgo, trazabilidad.\nSlides 1–2 bien documentadas.\n10\n\n\nEDA descriptivo\nEstadísticos (min, max, media, mediana, p5/p95, std, IQR/MAD) por clase; histogramas claros. Uso obligatorio: cv.calcHist.\nSlide 3 (tablas/figuras) + interpretación breve.\n20\n\n\nComparación de histogramas\nUso obligatorio: cv.compareHist con ≥2 métricas (p. ej., Correlación, Chi-cuadrado, Intersección, Bhattacharyya); global y en ROIs comparables.\nSlide 4 con tabla de métricas y conclusión justificada.\n20\n\n\nCalidad (enfoque/contraste)\nEnfoque por varianza del Laplaciano (cv.Laplacian) y al menos una medida de contraste (p. ej., Michelson o std/mean).\nSlide 5 con resultados y lectura clínica.\n20\n\n\nConvolución y ancla\nUso obligatorio: cv.filter2D con anchor variado. Demostración con imagen delta y ROI real; explicación del desplazamiento espacial e impacto en mediciones.\nSlide 6 con figuras claras + explicación.\n25\n\n\nRecomendaciones y límites\nAcciones de QA (umbrales/alertas), riesgos del posprocesado (p. ej., CLAHE), límites y próximos pasos.\nSlide 7–8 con lista accionable.\n5\n\n\n\nAprobación mínima: 60 pts. Penaliza exceder tiempo, no citar dataset o no usar las funciones requeridas."
  },
  {
    "objectID": "laboratorios/PSIM/lab05_EDA_Convolucion.html#guía-técnica",
    "href": "laboratorios/PSIM/lab05_EDA_Convolucion.html#guía-técnica",
    "title": "Laboratorio 004: EDA de Imágenes de Tórax + Convolución (Efecto del Ancla",
    "section": "Guía técnica",
    "text": "Guía técnica\n\nFunciones OpenCV a utilizar (obligatorias):\ncv.calcHist (histogramas), cv.compareHist (comparación), cv.filter2D + anchor (convolución), cv.Laplacian (enfoque).\n\n\n1) EDA por clase (NORMAL vs PNEUMONIA)\nTareas:\n- Calcular, por clase, min, max, media, mediana, p5/p95, std, IQR/MAD.\n- Generar histogramas (bins=256, rango 0–255) y visualizarlos de forma comparable.\nSeudocódigo:\nfor CLASS in [NORMAL, PNEUMONIA]:\n    IMGS = read_all_grayscale(CLASS)              // cv.imread(..., cv.IMREAD_GRAYSCALE)\n    IMGS_8U = normalize_to_8bit(IMGS)             // asegurar 0–255\n    STATS[CLASS] = descriptive_stats(IMGS_8U)     // min, max, mean, median, p5/p95, std, IQR/MAD\n    H_CLASS = mean_histogram(IMGS_8U)             // cv.calcHist por imagen y promedio\nplot_overlaid(H_NORMAL, H_PNEUMONIA)              // comparar curvas en un mismo eje\nPregunta con context:\nEn la ronda de Urgencias, se reportan placas con posible bajo rango dinámico. A partir de tus histogramas y percentiles p5/p95, ¿hay evidencia de saturación o subexposición en alguna clase? ¿Qué implicaría para la lectura del radiólogo de guardia?\n\n\n\n2) Comparación de histogramas (global y por ROI)\nTareas:\n- Comparar histogramas globales y de ROIs equivalentes entre clases.\n- Usar al menos dos métricas de cv.compareHist (p. ej., Correlación y Bhattacharyya).\nSeudocódigo:\nROI_A = center_crop(select_example(NORMAL))\nROI_B = center_crop(select_example(PNEUMONIA))\n\nH_A = normalized_histogram(ROI_A)   // cv.calcHist + normalización\nH_B = normalized_histogram(ROI_B)\n\nSCORES = {\n  \"CORRELATION\": compareHist(H_A, H_B, METHOD_CORREL),\n  \"BHATTACHARYYA\": compareHist(H_A, H_B, METHOD_BHATTACHARYYA)\n}\nrender_table(SCORES)\nPregunta con contexto:\nEn regiones hiliares la comparación muestra alta intersección entre clases. ¿Lo atribuyes a superposición anatómica o a variabilidad de exposición? ¿Qué acción de QA propones (reencuadre, repetición, anotación del técnico)?\n\n\n\n3) Calidad: enfoque (Laplaciano) y contraste\nTareas:\n- Estimar enfoque con cv.Laplacian y reportar la varianza de la respuesta (FOCUS).\n- Reportar una medida de contraste (p. ej., Michelson = (max−min)/(max+min) o std/mean).\nSeudocódigo:\nROI = center_crop(select_example(any_class))\nLAP = Laplacian(ROI, ddepth=32F, ksize=3)    // cv.Laplacian\nFOCUS = variance(LAP)\nCONTRAST = contrast_metric(ROI)              // Michelson o std/mean\n\nreport({\"FOCUS\": FOCUS, \"CONTRAST\": CONTRAST})\nPregunta con contexto (colocar textual en la slide):\nEn un turno nocturno con posible movimiento del paciente, ¿qué umbral de enfoque (FOCUS) propondrías para repetir la Rx minimizando dosis? ¿Cómo lo comunicarías al técnico?\n\n\n\n4) Convolución 2D y efecto del ancla (anchor)\nTareas:\n- Usar cv.filter2D variando anchor y mostrar el desplazamiento de la respuesta.\nDiseño experimental mínimo (dos partes):\nA) Imagen “delta” (7×7, con un 1 en (3,3))\nDELTA = zeros(7,7); DELTA[3,3] = 1\nK = ones(3,3) / 9\n\nfor ANCHOR in [(-1,-1), (0,0), (2,1)]:\n    OUT = filter2D(DELTA, ddepth=-1, kernel=K, anchor=ANCHOR, borderType=BORDER_CONSTANT)\n    visualize_matrix(OUT, title=\"anchor=\"+str(ANCHOR))\nB) ROI real (Rx) + Laplaciano (realce de bordes)\nROI = center_crop(select_example(NORMAL))\nLAP_K = [[0,-1,0],[-1,4,-1],[0,-1,0]]\n\nfor ANCHOR in [(-1,-1), (0,0), (2,2)]:\n    EDGES = filter2D(ROI, ddepth=32F, kernel=LAP_K, anchor=ANCHOR, borderType=BORDER_REFLECT_101)\n    show_abs(EDGES, same_scale=True)\nConclusión esperada:\nEl ancla selecciona qué píxel de la ventana se alinea con la coordenada de salida. Cambiarla no altera la combinación lineal local, pero sí la ubicación de la respuesta (desfase espacial). En QA, un ancla errónea puede desalinear bordes/mediciones (p. ej., diámetro cardiotorácico) o desplazar mapas de atención.\nPregunta con contexto:\nSi tu pipeline de detección de bordes costales usa un ancla mal configurada y desplaza bordes ~1–2 px, ¿cómo afectaría el cálculo del diámetro cardiotorácico o la detección de consolidaciones en seguimiento? Propón una verificación de QA automatizada."
  },
  {
    "objectID": "laboratorios/PSIM/lab05_EDA_Convolucion.html#checklist-previo-a-la-presentación",
    "href": "laboratorios/PSIM/lab05_EDA_Convolucion.html#checklist-previo-a-la-presentación",
    "title": "Laboratorio 004: EDA de Imágenes de Tórax + Convolución (Efecto del Ancla",
    "section": "Checklist previo a la presentación",
    "text": "Checklist previo a la presentación\n\nSlides numeradas (≤8), fuentes legibles, títulos claros.\nCitas al dataset y a las funciones usadas.\nHistogramas por clase (cv.calcHist) y tabla de estadísticos.\nComparación de histogramas (cv.compareHist) con ≥2 métricas y conclusión.\nMétricas de calidad (enfoque por Laplaciano; contraste) con lectura clínica.\nDemostración del ancla (delta + ROI real) con cv.filter2D y explicación del desplazamiento.\nRecomendaciones de QA y límites del análisis."
  },
  {
    "objectID": "laboratorios/PSIM/lab05_EDA_Convolucion.html#referencias-para-consulta-del-equipo",
    "href": "laboratorios/PSIM/lab05_EDA_Convolucion.html#referencias-para-consulta-del-equipo",
    "title": "Laboratorio 004: EDA de Imágenes de Tórax + Convolución (Efecto del Ancla",
    "section": "Referencias (para consulta del equipo)",
    "text": "Referencias (para consulta del equipo)\n\nDataset: Kaggle – Chest X-Ray Images (Pneumonia)\nhttps://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\nOpenCV – Histogramas: cv.calcHist (documentación oficial)\nOpenCV – Comparación de histogramas: cv.compareHist (documentación oficial)\nOpenCV – Convolución: cv.filter2D y parámetro anchor (documentación oficial)\nOpenCV – Operador Laplaciano: cv.Laplacian (documentación oficial)"
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#descripción-de-la-actividad",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "",
    "text": "Se busca desarrollar proyectos educativos que apliquen técnicas de procesamiento de señales (1D) para abordar problemas de salud, contribuyendo así a los Objetivos de Desarrollo Sostenible (ODS) de las Naciones Unidas."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#requisitos",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Requisitos:",
    "text": "Requisitos:\n\nIdentificar un problema de salud específico y relevante, relacionado con los ODS.\nJustificar la importancia del problema y la necesidad de una solución innovadora.\nEstablecer objetivos claros y medibles para el proyecto.\nElegir un dataset apropiado de señales (1D).\nDesarrollar una solución técnica que satisfaga los indicadores de solución de problema, con descripción matemática, física y/o estadística.\nImplementar la solución en Python."
  },
  {
    "objectID": "laboratorios/PSIM/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "href": "laboratorios/PSIM/lab02_SignalProcessing.html#rúbrica-de-evaluación",
    "title": "Labóratorio 002. “Desarrollo de soluciones innovadoras en procesamiento de señales para abordar problemas de salud y contribuir a los Objetivos de Desarrollo Sostenible”",
    "section": "Rúbrica de evaluación",
    "text": "Rúbrica de evaluación\n\n\n\n\n\n\n\n\n\n\nCriterio\nPuntos\nBueno\nRegular\nMalo\n\n\n\n\nProblema de salud identificado\n15\nProblema claro, relevante y bien justificado (15puntos)\nProblema claro, pero justificación débil (7puntos)\nProblema no claro o no relevante (0puntos)\n\n\nJustificación y objetivos\n15\nJustificación sólida y objetivos claros y medibles (15puntos)\nJustificación débil y objetivos poco claros (7puntos)\nJustificación y objetivos no claros (0puntos)\n\n\nSolución técnica\n20\nSolución innovadora, bien fundamentada y correctamente implementada en Python (20puntos)\nSolución adecuada, pero con errores en la implementación (10puntos)\nSolución no innovadora o con errores graves (0puntos)\n\n\nDiseño de indicadores\n20\nIndicadores bien definidos, con descripción matemática, médica y estadística clara y precisa (20puntos)\nIndicadores bien definidos, pero con descripción no clara o incompleta (10puntos)\nIndicadores no bien definidos o sin descripción (0puntos)\n\n\nContribución a los ODS\n10\nContribución clara y significativa a los ODS (10puntos)\nContribución moderada a los ODS (7puntos)\nContribución no clara o nula a los ODS (0puntos)\n\n\nImpacto potencial en la salud\n10\nImpacto potencial alto y bien justificado (10puntos)\nImpacto potencial moderado y justificación débil (7puntos)\nImpacto potencial bajo o no justificado (0puntos)\n\n\nPresentación y documentación\n10\nPresentación clara y documentación precisa y completa (10puntos)\nPresentación clara, pero documentación no precisa (7puntos)\nPresentación no clara o documentación no está presente (0puntos)"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‘Machine Learning with R’ by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book’s specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book’s examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\n\n2. Visualizing distributions\n\n\n3. Exploring relationships between variables\n\n\n4. Analyzing categorical variables"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "Model Implementation",
    "text": "Model Implementation"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "Train Model",
    "text": "Train Model"
  },
  {
    "objectID": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance"
  },
  {
    "objectID": "codigo/ASIM/cod002_LinearRegression.html",
    "href": "codigo/ASIM/cod002_LinearRegression.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport numpy as np\n\n# Generate some random data\nnp.random.seed(0)\nX = np.random.rand(100,1)\ny = 3 + 2 * X + np.random.randn(100,1) / 1.5\nX\n\narray([[0.5488135 ],\n       [0.71518937],\n       [0.60276338],\n       [0.54488318],\n       [0.4236548 ],\n       [0.64589411],\n       [0.43758721],\n       [0.891773  ],\n       [0.96366276],\n       [0.38344152],\n       [0.79172504],\n       [0.52889492],\n       [0.56804456],\n       [0.92559664],\n       [0.07103606],\n       [0.0871293 ],\n       [0.0202184 ],\n       [0.83261985],\n       [0.77815675],\n       [0.87001215],\n       [0.97861834],\n       [0.79915856],\n       [0.46147936],\n       [0.78052918],\n       [0.11827443],\n       [0.63992102],\n       [0.14335329],\n       [0.94466892],\n       [0.52184832],\n       [0.41466194],\n       [0.26455561],\n       [0.77423369],\n       [0.45615033],\n       [0.56843395],\n       [0.0187898 ],\n       [0.6176355 ],\n       [0.61209572],\n       [0.616934  ],\n       [0.94374808],\n       [0.6818203 ],\n       [0.3595079 ],\n       [0.43703195],\n       [0.6976312 ],\n       [0.06022547],\n       [0.66676672],\n       [0.67063787],\n       [0.21038256],\n       [0.1289263 ],\n       [0.31542835],\n       [0.36371077],\n       [0.57019677],\n       [0.43860151],\n       [0.98837384],\n       [0.10204481],\n       [0.20887676],\n       [0.16130952],\n       [0.65310833],\n       [0.2532916 ],\n       [0.46631077],\n       [0.24442559],\n       [0.15896958],\n       [0.11037514],\n       [0.65632959],\n       [0.13818295],\n       [0.19658236],\n       [0.36872517],\n       [0.82099323],\n       [0.09710128],\n       [0.83794491],\n       [0.09609841],\n       [0.97645947],\n       [0.4686512 ],\n       [0.97676109],\n       [0.60484552],\n       [0.73926358],\n       [0.03918779],\n       [0.28280696],\n       [0.12019656],\n       [0.2961402 ],\n       [0.11872772],\n       [0.31798318],\n       [0.41426299],\n       [0.0641475 ],\n       [0.69247212],\n       [0.56660145],\n       [0.26538949],\n       [0.52324805],\n       [0.09394051],\n       [0.5759465 ],\n       [0.9292962 ],\n       [0.31856895],\n       [0.66741038],\n       [0.13179786],\n       [0.7163272 ],\n       [0.28940609],\n       [0.18319136],\n       [0.58651293],\n       [0.02010755],\n       [0.82894003],\n       [0.00469548]])\n\n\n\n\n# Convert data to PyTorch tensors\nX_tensor = torch.from_numpy(X.astype(np.float32))\ny_tensor = torch.from_numpy(y.astype(np.float32))\n\n\n# Define the linear regression model\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\n# Initialize the model, loss function, and optimizer\nmodel = LinearRegression()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# Train the model\nfor epoch in range(1000):\n    optimizer.zero_grad()\n    outputs = model(X_tensor)\n    loss = criterion(outputs, y_tensor)\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 100 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n# Print the learned parameters\n\nm = model.linear.weight.item()\nb = model.linear.bias.item()\n\nprint(\"Learned parameters:\")\nprint(\"Weight:\", m)\nprint(\"Bias:\", b )\n\nEpoch 1, Loss: 17.11027717590332\nEpoch 101, Loss: 0.5529825687408447\nEpoch 201, Loss: 0.4432789981365204\nEpoch 301, Loss: 0.44221213459968567\nEpoch 401, Loss: 0.4419429302215576\nEpoch 501, Loss: 0.4417407214641571\nEpoch 601, Loss: 0.44158604741096497\nEpoch 701, Loss: 0.44146785140037537\nEpoch 801, Loss: 0.4413774013519287\nEpoch 901, Loss: 0.4413083791732788\nLearned parameters:\nWeight: 1.91282320022583\nBias: 3.170973062515259\n\n\n\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0 , 1, 200)\nfig001 = plt.figure()\nplt.plot(t, m*t+b)\nplt.plot(X, y, 'r*')"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html",
    "title": "Health Care Cost Predictor",
    "section": "",
    "text": "The data for this example is located in Kaggle in the following URL, but the modified file for this class is located here"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#context-of-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Context of the data",
    "text": "Context of the data\nThe content is adapted from kaggle.\nThe datasets utilized in ‘Machine Learning with R’ by Brett Lantz are a valuable resource for learners, providing a foundation for hands-on experience with machine learning concepts. Although Packt Publishing does not make these datasets readily available online, they can be accessed through public domain sources, requiring only minor preprocessing and formatting to match the book’s specifications. This presents an opportunity for readers to engage deeply with the material, reproducing and building upon the book’s examples to reinforce their understanding of machine learning principles."
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#variables",
    "title": "Health Care Cost Predictor",
    "section": "Variables",
    "text": "Variables\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight \\(\\left(kg / m^2\\right)\\) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking\nsalary: Salary of the insurance contractor\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.\ncharges: Individual medical costs billed by health insurance"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#configuration-of-solution",
    "title": "Health Care Cost Predictor",
    "section": "Configuration of solution",
    "text": "Configuration of solution\n\ndata_path = \"../../data/\""
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#library-load",
    "title": "Health Care Cost Predictor",
    "section": "Library Load",
    "text": "Library Load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#data-load",
    "title": "Health Care Cost Predictor",
    "section": "Data Load",
    "text": "Data Load\n\ndata = pd.read_csv(data_path+\"insurance_2.csv\")\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\nNumber of GPUs available: 1\nGPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#understanding-the-data",
    "title": "Health Care Cost Predictor",
    "section": "Understanding the data",
    "text": "Understanding the data\n\nLoading and summarizing data\nVisualizing distributions\nExploring relationships between variables\nAnalyzing categorical variables\n\n\n1. Loading and summarizing data\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   salary    1338 non-null   float64\n 6   region    1338 non-null   object \n 7   charges   1338 non-null   float64\ndtypes: float64(3), int64(2), object(3)\nmemory usage: 83.8+ KB\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\ncount\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n1338.000000\n\n\nmean\n39.207025\n30.663397\n1.094918\n159064.411451\n13270.422265\n\n\nstd\n14.049960\n6.098187\n1.205493\n41741.994963\n12110.011237\n\n\nmin\n18.000000\n15.960000\n0.000000\n104622.922023\n1121.873900\n\n\n25%\n27.000000\n26.296250\n0.000000\n130087.161933\n4740.287150\n\n\n50%\n39.000000\n30.400000\n1.000000\n146740.897257\n9382.033000\n\n\n75%\n51.000000\n34.693750\n2.000000\n171897.191284\n16639.912515\n\n\nmax\n64.000000\n53.130000\n5.000000\n338460.517246\n63770.428010\n\n\n\n\n\n\n\n\ndata.select_dtypes(\"object\")\n\n\n\n\n\n\n\n\nsex\nsmoker\nregion\n\n\n\n\n0\nfemale\nyes\nsouthwest\n\n\n1\nmale\nno\nsoutheast\n\n\n2\nmale\nno\nsoutheast\n\n\n3\nmale\nno\nnorthwest\n\n\n4\nmale\nno\nnorthwest\n\n\n...\n...\n...\n...\n\n\n1333\nmale\nno\nnorthwest\n\n\n1334\nfemale\nno\nnortheast\n\n\n1335\nfemale\nno\nsoutheast\n\n\n1336\nfemale\nno\nsouthwest\n\n\n1337\nfemale\nyes\nnorthwest\n\n\n\n\n1338 rows × 3 columns\n\n\n\n\ndata[\"sex\"] = data[\"sex\"].astype(\"category\")\ndata[\"smoker\"] = data[\"smoker\"].astype(\"category\")\ndata[\"region\"] = data[\"region\"].astype(\"category\")\n\n\ndata.select_dtypes(\"number\")\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsalary\ncharges\n\n\n\n\n0\n19\n27.900\n0\n159272.812482\n16884.92400\n\n\n1\n18\n33.770\n1\n117088.625944\n1725.55230\n\n\n2\n28\n33.000\n3\n129043.852213\n4449.46200\n\n\n3\n33\n22.705\n0\n194635.486180\n21984.47061\n\n\n4\n32\n28.880\n0\n113585.904592\n3866.85520\n\n\n...\n...\n...\n...\n...\n...\n\n\n1333\n50\n30.970\n3\n145933.927725\n10600.54830\n\n\n1334\n18\n31.920\n0\n117665.917758\n2205.98080\n\n\n1335\n18\n36.850\n0\n133402.353115\n1629.83350\n\n\n1336\n21\n25.800\n0\n133975.682996\n2007.94500\n\n\n1337\n61\n29.070\n0\n216658.755628\n29141.36030\n\n\n\n\n1338 rows × 5 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   age       1338 non-null   int64   \n 1   sex       1338 non-null   category\n 2   bmi       1338 non-null   float64 \n 3   children  1338 non-null   int64   \n 4   smoker    1338 non-null   category\n 5   salary    1338 non-null   float64 \n 6   region    1338 non-null   category\n 7   charges   1338 non-null   float64 \ndtypes: category(3), float64(3), int64(2)\nmemory usage: 56.8 KB\n\n\n\n\n2. Visualizing distributions\n\nsns.histplot(data[\"bmi\"], stat=\"probability\")\n\n\n\n\n\n\n\n\n\n\n3. Exploring relationships between variables\n\nsns.scatterplot(data=data, x=\"bmi\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\n\n4. Analyzing categorical variables\n\nsns.countplot(data=data, x=\"smoker\", stat=\"probability\")\n\n\n\n\n\n\n\n\n\nsns.boxplot(data=data, y=\"charges\", x=\"smoker\")\n\n\n\n\n\n\n\n\n\nsns.pointplot(data=data, x=\"sex\", y=\"charges\", hue=\"smoker\")\n\n\n\n\n\n\n\n\n\ng001 = sns.FacetGrid(data=data, col=\"smoker\", row=\"sex\")\ng001.map(plt.scatter, \"bmi\", \"charges\")\n\n\n\n\n\n\n\n\n\nsns.regplot(data=data, x=\"salary\", y=\"charges\",\n            scatter_kws={\"color\": \"blue\"},  # Color de los puntos\n            line_kws={\"color\": \"red\"})"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#checking-availability-of-gpu",
    "title": "Health Care Cost Predictor",
    "section": "5. Checking availability of GPU",
    "text": "5. Checking availability of GPU\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\ndevice1\n\nUsing device: cuda:0\n\n\ndevice(type='cuda', index=0)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#splitting-data",
    "title": "Health Care Cost Predictor",
    "section": "6. Splitting data",
    "text": "6. Splitting data\n\nentrada = data[\"salary\"].to_numpy().reshape(-1, 1)\nsalida = data[\"charges\"].to_numpy().reshape(-1, 1)\n\n\nstandarScaler_features = StandardScaler().fit(entrada)\nstandarScaler_output = StandardScaler().fit(salida)\n\n\nsalary_train, salary_test, charges_train, charges_test = train_test_split(\n    standarScaler_features.transform(entrada),\n    standarScaler_output.transform(salida),\n    train_size=0.7,\n    shuffle=True,\n)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#converting-data-to-tensor",
    "title": "Health Care Cost Predictor",
    "section": "7. Converting Data To Tensor",
    "text": "7. Converting Data To Tensor\n\nt_salary_train = torch.tensor(salary_train, dtype=torch.float32, device=device1)\nt_salary_test = torch.tensor(salary_test, dtype=torch.float32, device=device1)\nt_charges_train = torch.tensor(charges_train, dtype=torch.float32, device=device1)\nt_charges_test = torch.tensor(charges_test, dtype=torch.float32, device=device1)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-implementation",
    "title": "Health Care Cost Predictor",
    "section": "8. Model Implementation",
    "text": "8. Model Implementation\n\nclass LinearRegression(nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.linear(x)\n\n\nmodel = LinearRegression().to(device1)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#train-model",
    "title": "Health Care Cost Predictor",
    "section": "10. Train Model",
    "text": "10. Train Model\n\nnum_epochs = 1000\nfor epoch in range(num_epochs):\n\n     # Fordward Pass and loss\n\n     charges_predicted = model(t_salary_train)\n     loss = criterion(charges_predicted, t_charges_train)\n\n     # Backward pass\n     loss.backward()\n\n     #wweights update\n     optimizer.step()\n     optimizer.zero_grad()\n\n     # Progress tracking\n\n     if (epoch+1)%10 ==0:\n          print(f\"Epoch: {epoch+1}, loss={loss.item():.4f}\")\n\nEpoch: 10, loss=1.2763\nEpoch: 20, loss=0.8460\nEpoch: 30, loss=0.5655\nEpoch: 40, loss=0.3828\nEpoch: 50, loss=0.2637\nEpoch: 60, loss=0.1861\nEpoch: 70, loss=0.1355\nEpoch: 80, loss=0.1026\nEpoch: 90, loss=0.0811\nEpoch: 100, loss=0.0671\nEpoch: 110, loss=0.0579\nEpoch: 120, loss=0.0520\nEpoch: 130, loss=0.0481\nEpoch: 140, loss=0.0456\nEpoch: 150, loss=0.0439\nEpoch: 160, loss=0.0428\nEpoch: 170, loss=0.0421\nEpoch: 180, loss=0.0417\nEpoch: 190, loss=0.0414\nEpoch: 200, loss=0.0412\nEpoch: 210, loss=0.0411\nEpoch: 220, loss=0.0410\nEpoch: 230, loss=0.0409\nEpoch: 240, loss=0.0409\nEpoch: 250, loss=0.0409\nEpoch: 260, loss=0.0408\nEpoch: 270, loss=0.0408\nEpoch: 280, loss=0.0408\nEpoch: 290, loss=0.0408\nEpoch: 300, loss=0.0408\nEpoch: 310, loss=0.0408\nEpoch: 320, loss=0.0408\nEpoch: 330, loss=0.0408\nEpoch: 340, loss=0.0408\nEpoch: 350, loss=0.0408\nEpoch: 360, loss=0.0408\nEpoch: 370, loss=0.0408\nEpoch: 380, loss=0.0408\nEpoch: 390, loss=0.0408\nEpoch: 400, loss=0.0408\nEpoch: 410, loss=0.0408\nEpoch: 420, loss=0.0408\nEpoch: 430, loss=0.0408\nEpoch: 440, loss=0.0408\nEpoch: 450, loss=0.0408\nEpoch: 460, loss=0.0408\nEpoch: 470, loss=0.0408\nEpoch: 480, loss=0.0408\nEpoch: 490, loss=0.0408\nEpoch: 500, loss=0.0408\nEpoch: 510, loss=0.0408\nEpoch: 520, loss=0.0408\nEpoch: 530, loss=0.0408\nEpoch: 540, loss=0.0408\nEpoch: 550, loss=0.0408\nEpoch: 560, loss=0.0408\nEpoch: 570, loss=0.0408\nEpoch: 580, loss=0.0408\nEpoch: 590, loss=0.0408\nEpoch: 600, loss=0.0408\nEpoch: 610, loss=0.0408\nEpoch: 620, loss=0.0408\nEpoch: 630, loss=0.0408\nEpoch: 640, loss=0.0408\nEpoch: 650, loss=0.0408\nEpoch: 660, loss=0.0408\nEpoch: 670, loss=0.0408\nEpoch: 680, loss=0.0408\nEpoch: 690, loss=0.0408\nEpoch: 700, loss=0.0408\nEpoch: 710, loss=0.0408\nEpoch: 720, loss=0.0408\nEpoch: 730, loss=0.0408\nEpoch: 740, loss=0.0408\nEpoch: 750, loss=0.0408\nEpoch: 760, loss=0.0408\nEpoch: 770, loss=0.0408\nEpoch: 780, loss=0.0408\nEpoch: 790, loss=0.0408\nEpoch: 800, loss=0.0408\nEpoch: 810, loss=0.0408\nEpoch: 820, loss=0.0408\nEpoch: 830, loss=0.0408\nEpoch: 840, loss=0.0408\nEpoch: 850, loss=0.0408\nEpoch: 860, loss=0.0408\nEpoch: 870, loss=0.0408\nEpoch: 880, loss=0.0408\nEpoch: 890, loss=0.0408\nEpoch: 900, loss=0.0408\nEpoch: 910, loss=0.0408\nEpoch: 920, loss=0.0408\nEpoch: 930, loss=0.0408\nEpoch: 940, loss=0.0408\nEpoch: 950, loss=0.0408\nEpoch: 960, loss=0.0408\nEpoch: 970, loss=0.0408\nEpoch: 980, loss=0.0408\nEpoch: 990, loss=0.0408\nEpoch: 1000, loss=0.0408\n\n\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )"
  },
  {
    "objectID": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "href": "codigo/ASIM/cod003_sol_LinearRegression_InsuranceCosts.html#model-performance",
    "title": "Health Care Cost Predictor",
    "section": "Model Performance",
    "text": "Model Performance\n\nwith torch.no_grad():\n    prediction = model(t_salary_test)\n    mse = mean_squared_error(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n    r2 = r2_score(t_charges_test.cpu().numpy(), prediction.cpu().numpy())\n\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(charges_test),\n        \"ro\",\n    )\n    plt.plot(\n        standarScaler_features.inverse_transform(salary_test),\n        standarScaler_output.inverse_transform(prediction.cpu().numpy()),\n        \"b\",\n    )\n\n\n\n\n\n\n\n\n\ns_predicha = standarScaler_output.inverse_transform(prediction.cpu().numpy())\ns_real = standarScaler_output.inverse_transform(charges_test)\n\nresiduos = s_real- s_predicha\n\nsm.graphics.tsa.plot_acf(residuos, lags=100)"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#context",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#context",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "",
    "text": "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\nSmith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261–265). IEEE Computer Society Press."
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#variables",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#variables",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Variables",
    "text": "Variables\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U/ml)\nBMI: Body mass index (weight in kg/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport statsmodels.api as sm\n\n\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\nfor i in range(num_gpus):\n    print(f\"{i+1}. GPU {i}: {torch.cuda.get_device_name(i)}\")\n\ndevice = 0  # \"Select the index of the GPU you wish to use\"\ntorch.cuda.set_device(device)\nprint(f\"GPU selection: {torch.cuda.get_device_name(device)}\")\n\ndevice1 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device1}\")\n\nNumber of GPUs available: 1\n1. GPU 0: NVIDIA GeForce MX110\nGPU selection: NVIDIA GeForce MX110\nUsing device: cuda:0"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#load-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#load-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Load data",
    "text": "Load data\n\ndata = pd.read_csv(\"../../data/diabetes.csv\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#check-any-missing-values",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#check-any-missing-values",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Check any missing values",
    "text": "Check any missing values\n\ndata.describe()\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n\n\n\ncol_entradas = [\n    \"Pregnancies\",\n    \"Glucose\",\n    \"BloodPressure\",\n    \"SkinThickness\",\n    \"Insulin\",\n    \"BMI\",\n    \"DiabetesPedigreeFunction\",\n    \"Age\"\n]\ncol_salidas = [\n    \"Outcome\"\n]\n\n\ndata[col_salidas].head()\n\n\n\n\n\n\n\n\nOutcome\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n2\n1\n\n\n3\n0\n\n\n4\n1"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#explore-the-data-relationship",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#explore-the-data-relationship",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Explore the data relationship",
    "text": "Explore the data relationship\n\nsns.countplot(data=data, x=\"Outcome\")"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#normalize-and-standarize-the-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#normalize-and-standarize-the-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Normalize and standarize the data",
    "text": "Normalize and standarize the data\n\nstandarScaler_features = StandardScaler().fit(data[col_entradas])\nentradas_norm = standarScaler_features.transform(data[col_entradas])\nsalida_norm = data[col_salidas].values"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#create-neural-network-data",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#create-neural-network-data",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Create neural network data",
    "text": "Create neural network data\n\nCreate Dataset\n\nclass TabularDataset(Dataset):\n    def __init__(self, ent, sal):\n        self.inputs = torch.tensor(ent, dtype=torch.float32)\n        self.outputs = torch.tensor(sal, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, idx):\n        return self.inputs[idx], self.outputs[idx]\n\n\nconjuntoDatos = TabularDataset(ent=entradas_norm, sal=salida_norm)\n\ntrain_ds, val_ds, test_ds = random_split(conjuntoDatos, [0.7, 0.15, 0.15])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=True)\n\n\nfor batch in train_loader:\n    X_batch, y_batch = batch\n    print(X_batch.shape, y_batch.shape)\n\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([32, 8]) torch.Size([32, 1])\ntorch.Size([26, 8]) torch.Size([26, 1])"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#train-model",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#train-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Train model",
    "text": "Train model\n\nclass RedNeuronal(nn.Module):\n    def __init__(self, ent, sal):\n        super(RedNeuronal, self).__init__()\n        self.num_caract = ent\n        self.num_salidas = sal\n        self.fc1 = nn.Linear(self.num_caract, 10)  # Capa oculta 1\n        self.act1 = nn.ReLU()\n        self.fc2 = nn.Linear(10, 12) # Capa oculta 2\n        self.act2 = nn.ReLU()\n        self.fc3 = nn.Linear(12, 13)  # Capa oculta 3\n        self.act3 = nn.ReLU()\n        self.fc4 = nn.Linear(13, self.num_salidas)  # Capa de salida\n        self.act4 = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.act1(self.fc1(x))\n        x = self.act2(self.fc2(x))\n        x = self.act3(self.fc3(x))\n        x = self.act4(self.fc4(x))\n        return x\n\n\nepocas = 1000  # Número de épocas de entrenamiento\nbatch_size = 32  # Tamaño del lote\n\n\nred = RedNeuronal(8, 1)\nred = red.to(device=device1)\n\n\nprint(red.parameters())\n\n&lt;generator object Module.parameters at 0x7f7ae23a5ee0&gt;\n\n\n\ncriterio = nn.BCELoss()\noptimizador = optim.Adam(red.parameters(), lr=0.001)\n\n\n# Entrenar la red neuronal\nfor epoca in range(epocas):\n    perdida_entrenamiento = 0\n    for X_batch, y_batch in train_loader:\n        # Pasar los datos por la red neuronal\n        salida = red(X_batch.to(device=device1))\n\n        # Calcular la pérdida\n        perdida = criterio(salida, y_batch.to(device=device1))\n\n        # Actualizar los pesos\n        optimizador.zero_grad()\n        perdida.backward()\n        optimizador.step()\n        perdida_entrenamiento += perdida.item()\n\n    # Imprimir la pérdida en cada época\n    #print(f\"Época {epoca+1}, pérdida: {perdida.item():.8f}\")\n    perdida_validacion = 0\n    con_exactitud = 0\n    total = 0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            # Pasar los datos por la red neuronal\n            salida = red(X_batch.to(device=device1))\n\n            # Calcular la pérdida\n            perdida = criterio(salida, y_batch.to(device=device1))\n\n            perdida_validacion += perdida.item()\n\n            # Calcular la exactitud\n            _, predicciones = torch.max(salida, 1)\n            con_exactitud += (predicciones.cpu().numpy() == y_batch.cpu().numpy()).sum().item()\n            total += y_batch.shape[0]\n\n    # Imprimir los resultados\n    print(f\"Época {epoca+1}\")\n    print(f\"Perdida entrenamiento: {perdida_entrenamiento/len(train_loader)}\")\n    print(f\"Perdida validación: {perdida_validacion/len(val_loader)}\")\n    print(f\"Exactitud validación: {con_exactitud/total:.4f}\")\n\nÉpoca 1\nPerdida entrenamiento: 0.6791575761402354\nPerdida validación: 0.6788250803947449\nExactitud validación: 18.0609\nÉpoca 2\nPerdida entrenamiento: 0.672294301145217\nPerdida validación: 0.6751690059900284\nExactitud validación: 18.4000\nÉpoca 3\nPerdida entrenamiento: 0.6647399173063391\nPerdida validación: 0.6713864207267761\nExactitud validación: 18.7391\nÉpoca 4\nPerdida entrenamiento: 0.6535137961892521\nPerdida validación: 0.6575797200202942\nExactitud validación: 18.4000\nÉpoca 5\nPerdida entrenamiento: 0.6389946797314812\nPerdida validación: 0.6436730623245239\nExactitud validación: 18.2870\nÉpoca 6\nPerdida entrenamiento: 0.6213853324160856\nPerdida validación: 0.6348690390586853\nExactitud validación: 18.6261\nÉpoca 7\nPerdida entrenamiento: 0.5960922311334049\nPerdida validación: 0.6058164685964584\nExactitud validación: 18.5130\nÉpoca 8\nPerdida entrenamiento: 0.5712940009201274\nPerdida validación: 0.5880416631698608\nExactitud validación: 18.7391\nÉpoca 9\nPerdida entrenamiento: 0.5457583104862886\nPerdida validación: 0.5503197610378265\nExactitud validación: 18.4000\nÉpoca 10\nPerdida entrenamiento: 0.5210335955900305\nPerdida validación: 0.5285529047250748\nExactitud validación: 18.4000\nÉpoca 11\nPerdida entrenamiento: 0.4988165813333848\nPerdida validación: 0.5061830580234528\nExactitud validación: 18.2870\nÉpoca 12\nPerdida entrenamiento: 0.48283538572928486\nPerdida validación: 0.5024331212043762\nExactitud validación: 18.5130\nÉpoca 13\nPerdida entrenamiento: 0.4708527694730198\nPerdida validación: 0.5093462020158768\nExactitud validación: 18.4000\nÉpoca 14\nPerdida entrenamiento: 0.4619144955102135\nPerdida validación: 0.4764373451471329\nExactitud validación: 18.4000\nÉpoca 15\nPerdida entrenamiento: 0.4541836258243112\nPerdida validación: 0.4746478497982025\nExactitud validación: 17.9478\nÉpoca 16\nPerdida entrenamiento: 0.4520234956460841\nPerdida validación: 0.48348189145326614\nExactitud validación: 18.5130\nÉpoca 17\nPerdida entrenamiento: 0.44661900751730976\nPerdida validación: 0.47032642364501953\nExactitud validación: 18.0609\nÉpoca 18\nPerdida entrenamiento: 0.44420213033171263\nPerdida validación: 0.4675467982888222\nExactitud validación: 18.4000\nÉpoca 19\nPerdida entrenamiento: 0.44500470512053547\nPerdida validación: 0.46534235775470734\nExactitud validación: 18.5130\nÉpoca 20\nPerdida entrenamiento: 0.44122909447726083\nPerdida validación: 0.49303658306598663\nExactitud validación: 18.4000\nÉpoca 21\nPerdida entrenamiento: 0.439960497267106\nPerdida validación: 0.4710696116089821\nExactitud validación: 18.0609\nÉpoca 22\nPerdida entrenamiento: 0.43822164395276236\nPerdida validación: 0.4644882157444954\nExactitud validación: 18.4000\nÉpoca 23\nPerdida entrenamiento: 0.43539681855370016\nPerdida validación: 0.48128364980220795\nExactitud validación: 18.4000\nÉpoca 24\nPerdida entrenamiento: 0.43452516373466044\nPerdida validación: 0.49383869767189026\nExactitud validación: 18.5130\nÉpoca 25\nPerdida entrenamiento: 0.4337502367356244\nPerdida validación: 0.461711123585701\nExactitud validación: 18.1739\nÉpoca 26\nPerdida entrenamiento: 0.4328044530223398\nPerdida validación: 0.4867813438177109\nExactitud validación: 18.6261\nÉpoca 27\nPerdida entrenamiento: 0.4315945961896111\nPerdida validación: 0.49709317088127136\nExactitud validación: 18.8522\nÉpoca 28\nPerdida entrenamiento: 0.43218792361371655\nPerdida validación: 0.4762030094861984\nExactitud validación: 18.6261\nÉpoca 29\nPerdida entrenamiento: 0.42929310570744905\nPerdida validación: 0.4678042158484459\nExactitud validación: 18.4000\nÉpoca 30\nPerdida entrenamiento: 0.42652833286453695\nPerdida validación: 0.4651280418038368\nExactitud validación: 18.6261\nÉpoca 31\nPerdida entrenamiento: 0.4259583511773278\nPerdida validación: 0.48188481479883194\nExactitud validación: 18.6261\nÉpoca 32\nPerdida entrenamiento: 0.4245906016405891\nPerdida validación: 0.48621364682912827\nExactitud validación: 18.1739\nÉpoca 33\nPerdida entrenamiento: 0.4256867608603309\nPerdida validación: 0.5174973607063293\nExactitud validación: 18.6261\nÉpoca 34\nPerdida entrenamiento: 0.4248025277081658\nPerdida validación: 0.4981654956936836\nExactitud validación: 18.7391\nÉpoca 35\nPerdida entrenamiento: 0.42286987865672393\nPerdida validación: 0.4870433583855629\nExactitud validación: 18.7391\nÉpoca 36\nPerdida entrenamiento: 0.42132503057227416\nPerdida validación: 0.48050128668546677\nExactitud validación: 18.6261\nÉpoca 37\nPerdida entrenamiento: 0.422717108446009\nPerdida validación: 0.4715006574988365\nExactitud validación: 18.2870\nÉpoca 38\nPerdida entrenamiento: 0.41828276742907133\nPerdida validación: 0.4957212060689926\nExactitud validación: 18.4000\nÉpoca 39\nPerdida entrenamiento: 0.41759711153366985\nPerdida validación: 0.4781687557697296\nExactitud validación: 18.1739\nÉpoca 40\nPerdida entrenamiento: 0.4186316009830026\nPerdida validación: 0.467018261551857\nExactitud validación: 18.7391\nÉpoca 41\nPerdida entrenamiento: 0.41757552763995004\nPerdida validación: 0.47248195111751556\nExactitud validación: 18.5130\nÉpoca 42\nPerdida entrenamiento: 0.41657427479239073\nPerdida validación: 0.5107008069753647\nExactitud validación: 18.9652\nÉpoca 43\nPerdida entrenamiento: 0.41385892559500304\nPerdida validación: 0.48618149757385254\nExactitud validación: 18.6261\nÉpoca 44\nPerdida entrenamiento: 0.4130455264273812\nPerdida validación: 0.48718027025461197\nExactitud validación: 18.1739\nÉpoca 45\nPerdida entrenamiento: 0.4121672230608323\nPerdida validación: 0.49359724670648575\nExactitud validación: 18.4000\nÉpoca 46\nPerdida entrenamiento: 0.4103984973009895\nPerdida validación: 0.5008325800299644\nExactitud validación: 18.6261\nÉpoca 47\nPerdida entrenamiento: 0.40746283005265627\nPerdida validación: 0.5021576881408691\nExactitud validación: 18.4000\nÉpoca 48\nPerdida entrenamiento: 0.4073647067827337\nPerdida validación: 0.4890240281820297\nExactitud validación: 18.5130\nÉpoca 49\nPerdida entrenamiento: 0.40921850765452666\nPerdida validación: 0.5141201466321945\nExactitud validación: 18.4000\nÉpoca 50\nPerdida entrenamiento: 0.40371377503170686\nPerdida validación: 0.5138585902750492\nExactitud validación: 18.4000\nÉpoca 51\nPerdida entrenamiento: 0.40545569798525644\nPerdida validación: 0.49403806775808334\nExactitud validación: 18.7391\nÉpoca 52\nPerdida entrenamiento: 0.4029516472535975\nPerdida validación: 0.4981403201818466\nExactitud validación: 18.4000\nÉpoca 53\nPerdida entrenamiento: 0.40148040301659527\nPerdida validación: 0.470258504152298\nExactitud validación: 18.1739\nÉpoca 54\nPerdida entrenamiento: 0.4014539648504818\nPerdida validación: 0.5071394890546799\nExactitud validación: 18.5130\nÉpoca 55\nPerdida entrenamiento: 0.4001041352748871\nPerdida validación: 0.5059882402420044\nExactitud validación: 18.7391\nÉpoca 56\nPerdida entrenamiento: 0.398499013746486\nPerdida validación: 0.465816680341959\nExactitud validación: 18.1739\nÉpoca 57\nPerdida entrenamiento: 0.39581065318163705\nPerdida validación: 0.4719567634165287\nExactitud validación: 18.4000\nÉpoca 58\nPerdida entrenamiento: 0.3962685343097238\nPerdida validación: 0.49108629673719406\nExactitud validación: 17.9478\nÉpoca 59\nPerdida entrenamiento: 0.3972399699337342\nPerdida validación: 0.5343546643853188\nExactitud validación: 18.4000\nÉpoca 60\nPerdida entrenamiento: 0.39424481111414295\nPerdida validación: 0.5204134956002235\nExactitud validación: 18.0609\nÉpoca 61\nPerdida entrenamiento: 0.3933473562493044\nPerdida validación: 0.48885199427604675\nExactitud validación: 18.2870\nÉpoca 62\nPerdida entrenamiento: 0.39581848593319163\nPerdida validación: 0.5045148134231567\nExactitud validación: 18.6261\nÉpoca 63\nPerdida entrenamiento: 0.39225762381273155\nPerdida validación: 0.49928755313158035\nExactitud validación: 18.5130\nÉpoca 64\nPerdida entrenamiento: 0.39095135120784535\nPerdida validación: 0.49818097054958344\nExactitud validación: 18.4000\nÉpoca 65\nPerdida entrenamiento: 0.39278412917081046\nPerdida validación: 0.51187414675951\nExactitud validación: 18.4000\nÉpoca 66\nPerdida entrenamiento: 0.3880087408949347\nPerdida validación: 0.5048925578594208\nExactitud validación: 18.4000\nÉpoca 67\nPerdida entrenamiento: 0.3891824781894684\nPerdida validación: 0.49526503682136536\nExactitud validación: 18.6261\nÉpoca 68\nPerdida entrenamiento: 0.38694337185691385\nPerdida validación: 0.520538330078125\nExactitud validación: 18.7391\nÉpoca 69\nPerdida entrenamiento: 0.3850225508213043\nPerdida validación: 0.4962310940027237\nExactitud validación: 18.1739\nÉpoca 70\nPerdida entrenamiento: 0.3856160588124219\nPerdida validación: 0.5117396265268326\nExactitud validación: 18.6261\nÉpoca 71\nPerdida entrenamiento: 0.38290825836798725\nPerdida validación: 0.48271531239151955\nExactitud validación: 18.7391\nÉpoca 72\nPerdida entrenamiento: 0.3842119478127536\nPerdida validación: 0.5159867852926254\nExactitud validación: 18.1739\nÉpoca 73\nPerdida entrenamiento: 0.38493889570236206\nPerdida validación: 0.5417948067188263\nExactitud validación: 18.5130\nÉpoca 74\nPerdida entrenamiento: 0.38206734727410707\nPerdida validación: 0.4967944473028183\nExactitud validación: 18.4000\nÉpoca 75\nPerdida entrenamiento: 0.3789928336353863\nPerdida validación: 0.518608808517456\nExactitud validación: 18.5130\nÉpoca 76\nPerdida entrenamiento: 0.3797504796701319\nPerdida validación: 0.5038291662931442\nExactitud validación: 18.2870\nÉpoca 77\nPerdida entrenamiento: 0.3783522914437687\nPerdida validación: 0.5356133580207825\nExactitud validación: 18.1739\nÉpoca 78\nPerdida entrenamiento: 0.37765972754534555\nPerdida validación: 0.5259551480412483\nExactitud validación: 18.4000\nÉpoca 79\nPerdida entrenamiento: 0.3763415795915267\nPerdida validación: 0.5199824124574661\nExactitud validación: 18.0609\nÉpoca 80\nPerdida entrenamiento: 0.3773508159553303\nPerdida validación: 0.49937019497156143\nExactitud validación: 18.2870\nÉpoca 81\nPerdida entrenamiento: 0.37419071442940655\nPerdida validación: 0.5143114551901817\nExactitud validación: 18.6261\nÉpoca 82\nPerdida entrenamiento: 0.37580522544243755\nPerdida validación: 0.5341081693768501\nExactitud validación: 18.4000\nÉpoca 83\nPerdida entrenamiento: 0.3732707009595983\nPerdida validación: 0.5355776324868202\nExactitud validación: 18.6261\nÉpoca 84\nPerdida entrenamiento: 0.37286416923298554\nPerdida validación: 0.5186856985092163\nExactitud validación: 18.4000\nÉpoca 85\nPerdida entrenamiento: 0.3705448946532081\nPerdida validación: 0.5483004599809647\nExactitud validación: 18.4000\nÉpoca 86\nPerdida entrenamiento: 0.3727482636185253\nPerdida validación: 0.5254365280270576\nExactitud validación: 18.2870\nÉpoca 87\nPerdida entrenamiento: 0.3692259718390072\nPerdida validación: 0.5111869126558304\nExactitud validación: 18.5130\nÉpoca 88\nPerdida entrenamiento: 0.37127525315565224\nPerdida validación: 0.5337236076593399\nExactitud validación: 18.4000\nÉpoca 89\nPerdida entrenamiento: 0.37246738461887136\nPerdida validación: 0.5206818729639053\nExactitud validación: 18.1739\nÉpoca 90\nPerdida entrenamiento: 0.3690295158063664\nPerdida validación: 0.5593036413192749\nExactitud validación: 18.5130\nÉpoca 91\nPerdida entrenamiento: 0.369259593241355\nPerdida validación: 0.5117775499820709\nExactitud validación: 18.2870\nÉpoca 92\nPerdida entrenamiento: 0.3679639767198002\nPerdida validación: 0.5290718674659729\nExactitud validación: 18.4000\nÉpoca 93\nPerdida entrenamiento: 0.36736031928483176\nPerdida validación: 0.5078761726617813\nExactitud validación: 18.4000\nÉpoca 94\nPerdida entrenamiento: 0.3644753282561022\nPerdida validación: 0.5632258951663971\nExactitud validación: 18.7391\nÉpoca 95\nPerdida entrenamiento: 0.36306865776286407\nPerdida validación: 0.5218587443232536\nExactitud validación: 18.2870\nÉpoca 96\nPerdida entrenamiento: 0.3643888498053831\nPerdida validación: 0.5354526937007904\nExactitud validación: 18.2870\nÉpoca 97\nPerdida entrenamiento: 0.3653539445470361\nPerdida validación: 0.51034265011549\nExactitud validación: 18.4000\nÉpoca 98\nPerdida entrenamiento: 0.36249710707103505\nPerdida validación: 0.5734138116240501\nExactitud validación: 18.6261\nÉpoca 99\nPerdida entrenamiento: 0.36265045316780314\nPerdida validación: 0.5656266584992409\nExactitud validación: 18.7391\nÉpoca 100\nPerdida entrenamiento: 0.3610046874074375\nPerdida validación: 0.521674856543541\nExactitud validación: 18.2870\nÉpoca 101\nPerdida entrenamiento: 0.35992640081573934\nPerdida validación: 0.5487679094076157\nExactitud validación: 18.2870\nÉpoca 102\nPerdida entrenamiento: 0.3585259414771024\nPerdida validación: 0.548629879951477\nExactitud validación: 18.5130\nÉpoca 103\nPerdida entrenamiento: 0.35833654684178967\nPerdida validación: 0.5379441231489182\nExactitud validación: 18.4000\nÉpoca 104\nPerdida entrenamiento: 0.3592461680664736\nPerdida validación: 0.543404832482338\nExactitud validación: 18.4000\nÉpoca 105\nPerdida entrenamiento: 0.3567296178901897\nPerdida validación: 0.5594352409243584\nExactitud validación: 18.2870\nÉpoca 106\nPerdida entrenamiento: 0.3556781069320791\nPerdida validación: 0.5586513355374336\nExactitud validación: 18.4000\nÉpoca 107\nPerdida entrenamiento: 0.35517681609181795\nPerdida validación: 0.5655415803194046\nExactitud validación: 18.4000\nÉpoca 108\nPerdida entrenamiento: 0.35475079189328584\nPerdida validación: 0.5609813407063484\nExactitud validación: 18.8522\nÉpoca 109\nPerdida entrenamiento: 0.3557695606175591\nPerdida validación: 0.5627079755067825\nExactitud validación: 18.2870\nÉpoca 110\nPerdida entrenamiento: 0.3561686961089863\nPerdida validación: 0.5387836992740631\nExactitud validación: 18.4000\nÉpoca 111\nPerdida entrenamiento: 0.35163088756449085\nPerdida validación: 0.5590721815824509\nExactitud validación: 18.1739\nÉpoca 112\nPerdida entrenamiento: 0.35371597812456246\nPerdida validación: 0.5587764009833336\nExactitud validación: 18.2870\nÉpoca 113\nPerdida entrenamiento: 0.3535332837525536\nPerdida validación: 0.5312048122286797\nExactitud validación: 18.5130\nÉpoca 114\nPerdida entrenamiento: 0.35189832834636464\nPerdida validación: 0.6044761911034584\nExactitud validación: 18.8522\nÉpoca 115\nPerdida entrenamiento: 0.3514702092198765\nPerdida validación: 0.5321017280220985\nExactitud validación: 18.6261\nÉpoca 116\nPerdida entrenamiento: 0.351543351131327\nPerdida validación: 0.5573963150382042\nExactitud validación: 18.6261\nÉpoca 117\nPerdida entrenamiento: 0.3497464911026113\nPerdida validación: 0.5573238208889961\nExactitud validación: 18.4000\nÉpoca 118\nPerdida entrenamiento: 0.3498367386705735\nPerdida validación: 0.5645684897899628\nExactitud validación: 18.2870\nÉpoca 119\nPerdida entrenamiento: 0.35061120899284587\nPerdida validación: 0.5626191198825836\nExactitud validación: 18.5130\nÉpoca 120\nPerdida entrenamiento: 0.34882452558068666\nPerdida validación: 0.5745996534824371\nExactitud validación: 18.2870\nÉpoca 121\nPerdida entrenamiento: 0.3476862302597831\nPerdida validación: 0.5468194410204887\nExactitud validación: 18.4000\nÉpoca 122\nPerdida entrenamiento: 0.34637948432389426\nPerdida validación: 0.533638957887888\nExactitud validación: 17.9478\nÉpoca 123\nPerdida entrenamiento: 0.34753450838958516\nPerdida validación: 0.5294349901378155\nExactitud validación: 18.1739\nÉpoca 124\nPerdida entrenamiento: 0.3470301829716739\nPerdida validación: 0.5638434365391731\nExactitud validación: 18.4000\nÉpoca 125\nPerdida entrenamiento: 0.3439143107217901\nPerdida validación: 0.5707154497504234\nExactitud validación: 18.8522\nÉpoca 126\nPerdida entrenamiento: 0.34399966369656954\nPerdida validación: 0.5750905275344849\nExactitud validación: 18.5130\nÉpoca 127\nPerdida entrenamiento: 0.3459861094460768\nPerdida validación: 0.5637594535946846\nExactitud validación: 18.2870\nÉpoca 128\nPerdida entrenamiento: 0.3425804122405894\nPerdida validación: 0.5966473817825317\nExactitud validación: 18.7391\nÉpoca 129\nPerdida entrenamiento: 0.34382107065004464\nPerdida validación: 0.5452658385038376\nExactitud validación: 18.4000\nÉpoca 130\nPerdida entrenamiento: 0.3432043326251647\nPerdida validación: 0.568010963499546\nExactitud validación: 18.5130\nÉpoca 131\nPerdida entrenamiento: 0.34486333587590384\nPerdida validación: 0.5764288678765297\nExactitud validación: 18.4000\nÉpoca 132\nPerdida entrenamiento: 0.3452732370180242\nPerdida validación: 0.5937597900629044\nExactitud validación: 18.5130\nÉpoca 133\nPerdida entrenamiento: 0.343221268233131\nPerdida validación: 0.6223113089799881\nExactitud validación: 18.7391\nÉpoca 134\nPerdida entrenamiento: 0.3406377662630642\nPerdida validación: 0.6121482476592064\nExactitud validación: 18.7391\nÉpoca 135\nPerdida entrenamiento: 0.34228555770481334\nPerdida validación: 0.5532180443406105\nExactitud validación: 18.1739\nÉpoca 136\nPerdida entrenamiento: 0.3407059855320874\nPerdida validación: 0.6256612241268158\nExactitud validación: 18.6261\nÉpoca 137\nPerdida entrenamiento: 0.33841385210261626\nPerdida validación: 0.6118277311325073\nExactitud validación: 18.7391\nÉpoca 138\nPerdida entrenamiento: 0.3379518126740175\nPerdida validación: 0.5608039274811745\nExactitud validación: 18.4000\nÉpoca 139\nPerdida entrenamiento: 0.33698144818053527\nPerdida validación: 0.6184676513075829\nExactitud validación: 18.6261\nÉpoca 140\nPerdida entrenamiento: 0.3397687033695333\nPerdida validación: 0.6316100880503654\nExactitud validación: 18.5130\nÉpoca 141\nPerdida entrenamiento: 0.33633708515587973\nPerdida validación: 0.5819898918271065\nExactitud validación: 18.6261\nÉpoca 142\nPerdida entrenamiento: 0.33748694290133086\nPerdida validación: 0.6265446171164513\nExactitud validación: 18.1739\nÉpoca 143\nPerdida entrenamiento: 0.3356994197649114\nPerdida validación: 0.6239243969321251\nExactitud validación: 18.4000\nÉpoca 144\nPerdida entrenamiento: 0.33472176159129424\nPerdida validación: 0.6359140202403069\nExactitud validación: 18.4000\nÉpoca 145\nPerdida entrenamiento: 0.3353544543771183\nPerdida validación: 0.623450018465519\nExactitud validación: 18.4000\nÉpoca 146\nPerdida entrenamiento: 0.33618306412416343\nPerdida validación: 0.5927932560443878\nExactitud validación: 18.0609\nÉpoca 147\nPerdida entrenamiento: 0.3340167955440633\nPerdida validación: 0.6286558359861374\nExactitud validación: 18.6261\nÉpoca 148\nPerdida entrenamiento: 0.33400292519260855\nPerdida validación: 0.6745086014270782\nExactitud validación: 18.1739\nÉpoca 149\nPerdida entrenamiento: 0.3350304067134857\nPerdida validación: 0.6481637880206108\nExactitud validación: 18.5130\nÉpoca 150\nPerdida entrenamiento: 0.3336921281674329\nPerdida validación: 0.6298792809247971\nExactitud validación: 18.7391\nÉpoca 151\nPerdida entrenamiento: 0.3350611933890511\nPerdida validación: 0.5883950218558311\nExactitud validación: 18.0609\nÉpoca 152\nPerdida entrenamiento: 0.3336448108448702\nPerdida validación: 0.6367370784282684\nExactitud validación: 18.5130\nÉpoca 153\nPerdida entrenamiento: 0.3326067302156897\nPerdida validación: 0.6520734950900078\nExactitud validación: 18.2870\nÉpoca 154\nPerdida entrenamiento: 0.3309824501766878\nPerdida validación: 0.6116059124469757\nExactitud validación: 18.2870\nÉpoca 155\nPerdida entrenamiento: 0.3331507540800992\nPerdida validación: 0.590815544128418\nExactitud validación: 18.5130\nÉpoca 156\nPerdida entrenamiento: 0.33216743872446175\nPerdida validación: 0.6476473957300186\nExactitud validación: 18.2870\nÉpoca 157\nPerdida entrenamiento: 0.3311873867231257\nPerdida validación: 0.6468140035867691\nExactitud validación: 18.0609\nÉpoca 158\nPerdida entrenamiento: 0.32796593273387237\nPerdida validación: 0.6146449446678162\nExactitud validación: 18.1739\nÉpoca 159\nPerdida entrenamiento: 0.33034057389287386\nPerdida validación: 0.6230598539113998\nExactitud validación: 18.5130\nÉpoca 160\nPerdida entrenamiento: 0.3273730260484359\nPerdida validación: 0.6443871557712555\nExactitud validación: 18.4000\nÉpoca 161\nPerdida entrenamiento: 0.330964570536333\nPerdida validación: 0.6126606613397598\nExactitud validación: 18.6261\nÉpoca 162\nPerdida entrenamiento: 0.33085155487060547\nPerdida validación: 0.6176680326461792\nExactitud validación: 18.5130\nÉpoca 163\nPerdida entrenamiento: 0.32789769067483787\nPerdida validación: 0.5946464017033577\nExactitud validación: 18.5130\nÉpoca 164\nPerdida entrenamiento: 0.3267712610609391\nPerdida validación: 0.6227770447731018\nExactitud validación: 18.2870\nÉpoca 165\nPerdida entrenamiento: 0.3263696502236759\nPerdida validación: 0.6890445426106453\nExactitud validación: 18.2870\nÉpoca 166\nPerdida entrenamiento: 0.3250192473916447\nPerdida validación: 0.6499665081501007\nExactitud validación: 18.5130\nÉpoca 167\nPerdida entrenamiento: 0.3261696854058434\nPerdida validación: 0.6132025644183159\nExactitud validación: 18.2870\nÉpoca 168\nPerdida entrenamiento: 0.3261833287337247\nPerdida validación: 0.6634091883897781\nExactitud validación: 18.5130\nÉpoca 169\nPerdida entrenamiento: 0.32349429411046643\nPerdida validación: 0.6630931124091148\nExactitud validación: 18.6261\nÉpoca 170\nPerdida entrenamiento: 0.3271436393260956\nPerdida validación: 0.612961657345295\nExactitud validación: 18.5130\nÉpoca 171\nPerdida entrenamiento: 0.32476263098856983\nPerdida validación: 0.6598226502537727\nExactitud validación: 18.2870\nÉpoca 172\nPerdida entrenamiento: 0.324515997486956\nPerdida validación: 0.6418932229280472\nExactitud validación: 18.4000\nÉpoca 173\nPerdida entrenamiento: 0.32433526919168587\nPerdida validación: 0.7335801050066948\nExactitud validación: 18.2870\nÉpoca 174\nPerdida entrenamiento: 0.3219207516487907\nPerdida validación: 0.653811901807785\nExactitud validación: 18.2870\nÉpoca 175\nPerdida entrenamiento: 0.3205060888739193\nPerdida validación: 0.6664783358573914\nExactitud validación: 18.5130\nÉpoca 176\nPerdida entrenamiento: 0.3207370875512852\nPerdida validación: 0.6229857131838799\nExactitud validación: 18.0609\nÉpoca 177\nPerdida entrenamiento: 0.3227768680628608\nPerdida validación: 0.6437440887093544\nExactitud validación: 18.2870\nÉpoca 178\nPerdida entrenamiento: 0.3209051349583794\nPerdida validación: 0.6665943264961243\nExactitud validación: 18.4000\nÉpoca 179\nPerdida entrenamiento: 0.32111615643781777\nPerdida validación: 0.6589837148785591\nExactitud validación: 18.5130\nÉpoca 180\nPerdida entrenamiento: 0.3208710200646344\nPerdida validación: 0.6451635211706161\nExactitud validación: 18.4000\nÉpoca 181\nPerdida entrenamiento: 0.3188728216816397\nPerdida validación: 0.6509027481079102\nExactitud validación: 18.4000\nÉpoca 182\nPerdida entrenamiento: 0.3178029682706384\nPerdida validación: 0.6660331636667252\nExactitud validación: 18.2870\nÉpoca 183\nPerdida entrenamiento: 0.31673886320170236\nPerdida validación: 0.6581268012523651\nExactitud validación: 18.2870\nÉpoca 184\nPerdida entrenamiento: 0.31750109002870675\nPerdida validación: 0.6372020319104195\nExactitud validación: 18.5130\nÉpoca 185\nPerdida entrenamiento: 0.31816011930213256\nPerdida validación: 0.7313763499259949\nExactitud validación: 18.4000\nÉpoca 186\nPerdida entrenamiento: 0.3156069096396951\nPerdida validación: 0.6771089732646942\nExactitud validación: 18.4000\nÉpoca 187\nPerdida entrenamiento: 0.31772204532342796\nPerdida validación: 0.6511183455586433\nExactitud validación: 18.4000\nÉpoca 188\nPerdida entrenamiento: 0.31324949685265036\nPerdida validación: 0.6433937773108482\nExactitud validación: 18.1739\nÉpoca 189\nPerdida entrenamiento: 0.31725497894427357\nPerdida validación: 0.68333500623703\nExactitud validación: 18.1739\nÉpoca 190\nPerdida entrenamiento: 0.3123554464648752\nPerdida validación: 0.6660071387887001\nExactitud validación: 18.8522\nÉpoca 191\nPerdida entrenamiento: 0.3153311452444862\nPerdida validación: 0.7063699811697006\nExactitud validación: 18.7391\nÉpoca 192\nPerdida entrenamiento: 0.31404705433284535\nPerdida validación: 0.6741388291120529\nExactitud validación: 18.7391\nÉpoca 193\nPerdida entrenamiento: 0.31402675632168264\nPerdida validación: 0.6543318554759026\nExactitud validación: 18.1739\nÉpoca 194\nPerdida entrenamiento: 0.3119946630562053\nPerdida validación: 0.6574038416147232\nExactitud validación: 18.5130\nÉpoca 195\nPerdida entrenamiento: 0.3136322226594476\nPerdida validación: 0.7180648446083069\nExactitud validación: 18.2870\nÉpoca 196\nPerdida entrenamiento: 0.3097478344159968\nPerdida validación: 0.6812009885907173\nExactitud validación: 18.2870\nÉpoca 197\nPerdida entrenamiento: 0.3116472389768152\nPerdida validación: 0.6507846117019653\nExactitud validación: 18.4000\nÉpoca 198\nPerdida entrenamiento: 0.31110472188276406\nPerdida validación: 0.6414782479405403\nExactitud validación: 18.2870\nÉpoca 199\nPerdida entrenamiento: 0.3103514997398152\nPerdida validación: 0.6524050757288933\nExactitud validación: 18.4000\nÉpoca 200\nPerdida entrenamiento: 0.31179756802671094\nPerdida validación: 0.6920239329338074\nExactitud validación: 18.7391\nÉpoca 201\nPerdida entrenamiento: 0.3084581047296524\nPerdida validación: 0.764978215098381\nExactitud validación: 18.0609\nÉpoca 202\nPerdida entrenamiento: 0.30916617986033945\nPerdida validación: 0.7176909744739532\nExactitud validación: 18.4000\nÉpoca 203\nPerdida entrenamiento: 0.3087397515773773\nPerdida validación: 0.7063323929905891\nExactitud validación: 18.2870\nÉpoca 204\nPerdida entrenamiento: 0.3106594672974418\nPerdida validación: 0.6954813897609711\nExactitud validación: 18.4000\nÉpoca 205\nPerdida entrenamiento: 0.30759740226409016\nPerdida validación: 0.7038579732179642\nExactitud validación: 18.1739\nÉpoca 206\nPerdida entrenamiento: 0.3062534963383394\nPerdida validación: 0.7156248390674591\nExactitud validación: 18.2870\nÉpoca 207\nPerdida entrenamiento: 0.30647197278106914\nPerdida validación: 0.688948281109333\nExactitud validación: 18.5130\nÉpoca 208\nPerdida entrenamiento: 0.3078196758733076\nPerdida validación: 0.692335918545723\nExactitud validación: 18.6261\nÉpoca 209\nPerdida entrenamiento: 0.30704403011237874\nPerdida validación: 0.6741050034761429\nExactitud validación: 17.9478\nÉpoca 210\nPerdida entrenamiento: 0.30527643508770885\nPerdida validación: 0.6659369245171547\nExactitud validación: 18.5130\nÉpoca 211\nPerdida entrenamiento: 0.3071153356748469\nPerdida validación: 0.7391846030950546\nExactitud validación: 18.6261\nÉpoca 212\nPerdida entrenamiento: 0.30531730371363025\nPerdida validación: 0.7998167648911476\nExactitud validación: 18.5130\nÉpoca 213\nPerdida entrenamiento: 0.3038189893259722\nPerdida validación: 0.7052174434065819\nExactitud validación: 17.9478\nÉpoca 214\nPerdida entrenamiento: 0.30341966976137724\nPerdida validación: 0.7350720167160034\nExactitud validación: 18.5130\nÉpoca 215\nPerdida entrenamiento: 0.30246863645665784\nPerdida validación: 0.7088495343923569\nExactitud validación: 18.5130\nÉpoca 216\nPerdida entrenamiento: 0.30353131013758045\nPerdida validación: 0.6834466755390167\nExactitud validación: 18.6261\nÉpoca 217\nPerdida entrenamiento: 0.30161605074125175\nPerdida validación: 0.7241852506995201\nExactitud validación: 17.9478\nÉpoca 218\nPerdida entrenamiento: 0.3025359528906205\nPerdida validación: 0.6786011755466461\nExactitud validación: 18.1739\nÉpoca 219\nPerdida entrenamiento: 0.3013206886894563\nPerdida validación: 0.679993025958538\nExactitud validación: 18.5130\nÉpoca 220\nPerdida entrenamiento: 0.3010849926401587\nPerdida validación: 0.8055609986186028\nExactitud validación: 18.7391\nÉpoca 221\nPerdida entrenamiento: 0.299965525374693\nPerdida validación: 0.6772769540548325\nExactitud validación: 18.4000\nÉpoca 222\nPerdida entrenamiento: 0.3033907431013444\nPerdida validación: 0.736585833132267\nExactitud validación: 18.5130\nÉpoca 223\nPerdida entrenamiento: 0.3007599991910598\nPerdida validación: 0.7596707493066788\nExactitud validación: 18.2870\nÉpoca 224\nPerdida entrenamiento: 0.30001555558513193\nPerdida validación: 0.6992309913039207\nExactitud validación: 18.2870\nÉpoca 225\nPerdida entrenamiento: 0.2969650775194168\nPerdida validación: 0.7044773250818253\nExactitud validación: 18.2870\nÉpoca 226\nPerdida entrenamiento: 0.29871873557567596\nPerdida validación: 0.6746115535497665\nExactitud validación: 18.5130\nÉpoca 227\nPerdida entrenamiento: 0.2973190230481765\nPerdida validación: 0.684038981795311\nExactitud validación: 18.4000\nÉpoca 228\nPerdida entrenamiento: 0.2981330340399462\nPerdida validación: 0.7490448206663132\nExactitud validación: 18.8522\nÉpoca 229\nPerdida entrenamiento: 0.29559924935593324\nPerdida validación: 0.694603718817234\nExactitud validación: 18.4000\nÉpoca 230\nPerdida entrenamiento: 0.2944230069132412\nPerdida validación: 0.7294625043869019\nExactitud validación: 18.5130\nÉpoca 231\nPerdida entrenamiento: 0.29362457640030803\nPerdida validación: 0.7362787425518036\nExactitud validación: 18.6261\nÉpoca 232\nPerdida entrenamiento: 0.294377674074734\nPerdida validación: 0.7065712809562683\nExactitud validación: 18.5130\nÉpoca 233\nPerdida entrenamiento: 0.29613833129405975\nPerdida validación: 0.7128828167915344\nExactitud validación: 18.2870\nÉpoca 234\nPerdida entrenamiento: 0.29697078904684854\nPerdida validación: 0.7355586439371109\nExactitud validación: 18.2870\nÉpoca 235\nPerdida entrenamiento: 0.2928716233547996\nPerdida validación: 0.8148213103413582\nExactitud validación: 18.7391\nÉpoca 236\nPerdida entrenamiento: 0.2956160175449708\nPerdida validación: 0.7032250016927719\nExactitud validación: 18.5130\nÉpoca 237\nPerdida entrenamiento: 0.29322683942668576\nPerdida validación: 0.7366586253046989\nExactitud validación: 18.6261\nÉpoca 238\nPerdida entrenamiento: 0.29531940730179057\nPerdida validación: 0.716269001364708\nExactitud validación: 18.2870\nÉpoca 239\nPerdida entrenamiento: 0.29456058582838845\nPerdida validación: 0.8046405576169491\nExactitud validación: 18.6261\nÉpoca 240\nPerdida entrenamiento: 0.2919597485486199\nPerdida validación: 0.7698554992675781\nExactitud validación: 18.1739\nÉpoca 241\nPerdida entrenamiento: 0.2926513622788822\nPerdida validación: 0.6973117738962173\nExactitud validación: 18.7391\nÉpoca 242\nPerdida entrenamiento: 0.2892984853071325\nPerdida validación: 0.7638273388147354\nExactitud validación: 18.4000\nÉpoca 243\nPerdida entrenamiento: 0.29051580937469706\nPerdida validación: 0.7815098166465759\nExactitud validación: 18.7391\nÉpoca 244\nPerdida entrenamiento: 0.2899246417424258\nPerdida validación: 0.7704179286956787\nExactitud validación: 18.1739\nÉpoca 245\nPerdida entrenamiento: 0.28837614375002246\nPerdida validación: 0.7450488656759262\nExactitud validación: 18.4000\nÉpoca 246\nPerdida entrenamiento: 0.29001492174232707\nPerdida validación: 0.7398979514837265\nExactitud validación: 18.1739\nÉpoca 247\nPerdida entrenamiento: 0.28900785919497995\nPerdida validación: 0.7784785479307175\nExactitud validación: 18.0609\nÉpoca 248\nPerdida entrenamiento: 0.28841665474807515\nPerdida validación: 0.7403790205717087\nExactitud validación: 18.5130\nÉpoca 249\nPerdida entrenamiento: 0.2894595230326933\nPerdida validación: 0.7213053703308105\nExactitud validación: 18.2870\nÉpoca 250\nPerdida entrenamiento: 0.2888253462665221\nPerdida validación: 0.766401544213295\nExactitud validación: 18.2870\nÉpoca 251\nPerdida entrenamiento: 0.2866971107090221\nPerdida validación: 0.7406387180089951\nExactitud validación: 18.5130\nÉpoca 252\nPerdida entrenamiento: 0.2872468583724078\nPerdida validación: 0.7808045633137226\nExactitud validación: 18.5130\nÉpoca 253\nPerdida entrenamiento: 0.2877846333910437\nPerdida validación: 0.7809512466192245\nExactitud validación: 18.4000\nÉpoca 254\nPerdida entrenamiento: 0.2867770826115328\nPerdida validación: 0.7319426983594894\nExactitud validación: 18.1739\nÉpoca 255\nPerdida entrenamiento: 0.28648798080051646\nPerdida validación: 0.7230148687958717\nExactitud validación: 18.4000\nÉpoca 256\nPerdida entrenamiento: 0.2846994154593524\nPerdida validación: 0.7592649683356285\nExactitud validación: 18.4000\nÉpoca 257\nPerdida entrenamiento: 0.2864809036254883\nPerdida validación: 0.7423518821597099\nExactitud validación: 18.2870\nÉpoca 258\nPerdida entrenamiento: 0.2850097224992864\nPerdida validación: 0.8285829573869705\nExactitud validación: 18.2870\nÉpoca 259\nPerdida entrenamiento: 0.2860611309023464\nPerdida validación: 0.7817785143852234\nExactitud validación: 18.5130\nÉpoca 260\nPerdida entrenamiento: 0.28397778027197895\nPerdida validación: 0.7759557962417603\nExactitud validación: 18.1739\nÉpoca 261\nPerdida entrenamiento: 0.2851453958188786\nPerdida validación: 0.773240715265274\nExactitud validación: 18.1739\nÉpoca 262\nPerdida entrenamiento: 0.28346505322877097\nPerdida validación: 0.8145815879106522\nExactitud validación: 18.4000\nÉpoca 263\nPerdida entrenamiento: 0.2839648855083129\nPerdida validación: 0.8247283324599266\nExactitud validación: 18.2870\nÉpoca 264\nPerdida entrenamiento: 0.2820875758633894\nPerdida validación: 0.7470234334468842\nExactitud validación: 18.1739\nÉpoca 265\nPerdida entrenamiento: 0.2828727487255545\nPerdida validación: 0.7517593279480934\nExactitud validación: 18.4000\nÉpoca 266\nPerdida entrenamiento: 0.28342335364397836\nPerdida validación: 0.745085820555687\nExactitud validación: 18.0609\nÉpoca 267\nPerdida entrenamiento: 0.28173114271724925\nPerdida validación: 0.8318959027528763\nExactitud validación: 18.5130\nÉpoca 268\nPerdida entrenamiento: 0.28258827241028056\nPerdida validación: 0.7550449594855309\nExactitud validación: 18.5130\nÉpoca 269\nPerdida entrenamiento: 0.2806198824854458\nPerdida validación: 0.815860778093338\nExactitud validación: 17.9478\nÉpoca 270\nPerdida entrenamiento: 0.2798441560829387\nPerdida validación: 0.8292346000671387\nExactitud validación: 18.7391\nÉpoca 271\nPerdida entrenamiento: 0.28328849813517404\nPerdida validación: 0.84027498960495\nExactitud validación: 17.9478\nÉpoca 272\nPerdida entrenamiento: 0.27925308399340687\nPerdida validación: 0.8446707427501678\nExactitud validación: 18.5130\nÉpoca 273\nPerdida entrenamiento: 0.279740308137501\nPerdida validación: 0.7891214042901993\nExactitud validación: 18.4000\nÉpoca 274\nPerdida entrenamiento: 0.2804296621504952\nPerdida validación: 0.7523273676633835\nExactitud validación: 18.6261\nÉpoca 275\nPerdida entrenamiento: 0.2786500278641196\nPerdida validación: 0.8763114959001541\nExactitud validación: 18.5130\nÉpoca 276\nPerdida entrenamiento: 0.2789465942803551\nPerdida validación: 0.7518940791487694\nExactitud validación: 18.4000\nÉpoca 277\nPerdida entrenamiento: 0.2798019025255652\nPerdida validación: 0.8489273488521576\nExactitud validación: 18.7391\nÉpoca 278\nPerdida entrenamiento: 0.280226955519003\nPerdida validación: 0.766749732196331\nExactitud validación: 18.5130\nÉpoca 279\nPerdida entrenamiento: 0.2779183343929403\nPerdida validación: 0.7820227146148682\nExactitud validación: 18.4000\nÉpoca 280\nPerdida entrenamiento: 0.2765612396247247\nPerdida validación: 0.7857282161712646\nExactitud validación: 18.4000\nÉpoca 281\nPerdida entrenamiento: 0.27886566169121685\nPerdida validación: 0.8160237297415733\nExactitud validación: 18.6261\nÉpoca 282\nPerdida entrenamiento: 0.2769961637609145\nPerdida validación: 0.8009995818138123\nExactitud validación: 18.5130\nÉpoca 283\nPerdida entrenamiento: 0.2754744019578485\nPerdida validación: 0.8242090195417404\nExactitud validación: 18.2870\nÉpoca 284\nPerdida entrenamiento: 0.27566534894354205\nPerdida validación: 0.8263423070311546\nExactitud validación: 18.4000\nÉpoca 285\nPerdida entrenamiento: 0.275710387264981\nPerdida validación: 0.7984395027160645\nExactitud validación: 18.7391\nÉpoca 286\nPerdida entrenamiento: 0.2722511160023072\nPerdida validación: 0.7776636183261871\nExactitud validación: 18.7391\nÉpoca 287\nPerdida entrenamiento: 0.2785680565763922\nPerdida validación: 0.8693821281194687\nExactitud validación: 18.1739\nÉpoca 288\nPerdida entrenamiento: 0.2776385243324673\nPerdida validación: 0.8111721277236938\nExactitud validación: 18.5130\nÉpoca 289\nPerdida entrenamiento: 0.2753101648653255\nPerdida validación: 0.7979157716035843\nExactitud validación: 18.6261\nÉpoca 290\nPerdida entrenamiento: 0.2721212304690305\nPerdida validación: 0.8984339684247971\nExactitud validación: 18.1739\nÉpoca 291\nPerdida entrenamiento: 0.27208081150756164\nPerdida validación: 0.8066085278987885\nExactitud validación: 18.0609\nÉpoca 292\nPerdida entrenamiento: 0.2724810707218507\nPerdida validación: 0.858610674738884\nExactitud validación: 18.1739\nÉpoca 293\nPerdida entrenamiento: 0.2749691465321709\nPerdida validación: 0.8009930029511452\nExactitud validación: 18.4000\nÉpoca 294\nPerdida entrenamiento: 0.2745845510679133\nPerdida validación: 0.8322249576449394\nExactitud validación: 18.6261\nÉpoca 295\nPerdida entrenamiento: 0.27191179903114543\nPerdida validación: 0.8544426411390305\nExactitud validación: 18.5130\nÉpoca 296\nPerdida entrenamiento: 0.2718319112763685\nPerdida validación: 0.7973638772964478\nExactitud validación: 18.2870\nÉpoca 297\nPerdida entrenamiento: 0.27322857257197886\nPerdida validación: 0.8390850126743317\nExactitud validación: 18.2870\nÉpoca 298\nPerdida entrenamiento: 0.2706087967928718\nPerdida validación: 0.8332074135541916\nExactitud validación: 18.2870\nÉpoca 299\nPerdida entrenamiento: 0.27064647394068103\nPerdida validación: 0.7855604067444801\nExactitud validación: 18.6261\nÉpoca 300\nPerdida entrenamiento: 0.27028607620912437\nPerdida validación: 0.844075620174408\nExactitud validación: 18.5130\nÉpoca 301\nPerdida entrenamiento: 0.27047083395368915\nPerdida validación: 0.7950586900115013\nExactitud validación: 18.7391\nÉpoca 302\nPerdida entrenamiento: 0.2688707393758437\nPerdida validación: 0.8446274772286415\nExactitud validación: 18.4000\nÉpoca 303\nPerdida entrenamiento: 0.27010226337348714\nPerdida validación: 0.8923372030258179\nExactitud validación: 18.1739\nÉpoca 304\nPerdida entrenamiento: 0.26951658988700194\nPerdida validación: 0.8144352659583092\nExactitud validación: 18.7391\nÉpoca 305\nPerdida entrenamiento: 0.2690744391259025\nPerdida validación: 0.9116105735301971\nExactitud validación: 18.4000\nÉpoca 306\nPerdida entrenamiento: 0.26870520588229685\nPerdida validación: 0.8943951576948166\nExactitud validación: 18.6261\nÉpoca 307\nPerdida entrenamiento: 0.27256863783387575\nPerdida validación: 0.9162701666355133\nExactitud validación: 18.2870\nÉpoca 308\nPerdida entrenamiento: 0.26849985648604\nPerdida validación: 0.8575167655944824\nExactitud validación: 18.1739\nÉpoca 309\nPerdida entrenamiento: 0.2659115265397465\nPerdida validación: 0.8369210362434387\nExactitud validación: 18.9652\nÉpoca 310\nPerdida entrenamiento: 0.26523913004819083\nPerdida validación: 0.8102370351552963\nExactitud validación: 18.5130\nÉpoca 311\nPerdida entrenamiento: 0.26695583322468924\nPerdida validación: 0.8106616139411926\nExactitud validación: 18.5130\nÉpoca 312\nPerdida entrenamiento: 0.26486619518083687\nPerdida validación: 0.862990252673626\nExactitud validación: 18.7391\nÉpoca 313\nPerdida entrenamiento: 0.2670781770173241\nPerdida validación: 0.9409219324588776\nExactitud validación: 18.2870\nÉpoca 314\nPerdida entrenamiento: 0.26387015773969535\nPerdida validación: 0.8297825679183006\nExactitud validación: 18.5130\nÉpoca 315\nPerdida entrenamiento: 0.2630258443600991\nPerdida validación: 0.8401200473308563\nExactitud validación: 18.6261\nÉpoca 316\nPerdida entrenamiento: 0.26609305248540993\nPerdida validación: 0.8802365660667419\nExactitud validación: 18.4000\nÉpoca 317\nPerdida entrenamiento: 0.26455171406269073\nPerdida validación: 0.85386922955513\nExactitud validación: 18.7391\nÉpoca 318\nPerdida entrenamiento: 0.2650342899210313\nPerdida validación: 0.913348600268364\nExactitud validación: 18.6261\nÉpoca 319\nPerdida entrenamiento: 0.2632635078009437\nPerdida validación: 0.8332754224538803\nExactitud validación: 18.6261\nÉpoca 320\nPerdida entrenamiento: 0.2620505313662922\nPerdida validación: 0.8459868878126144\nExactitud validación: 18.1739\nÉpoca 321\nPerdida entrenamiento: 0.2629975974559784\nPerdida validación: 0.96159228682518\nExactitud validación: 18.8522\nÉpoca 322\nPerdida entrenamiento: 0.26157911384806914\nPerdida validación: 0.8396739363670349\nExactitud validación: 18.6261\nÉpoca 323\nPerdida entrenamiento: 0.2618062881862416\nPerdida validación: 0.8706338852643967\nExactitud validación: 18.1739\nÉpoca 324\nPerdida entrenamiento: 0.26290398397866416\nPerdida validación: 0.9644896686077118\nExactitud validación: 18.6261\nÉpoca 325\nPerdida entrenamiento: 0.2609732878558776\nPerdida validación: 0.9126636236906052\nExactitud validación: 18.0609\nÉpoca 326\nPerdida entrenamiento: 0.26105780110639687\nPerdida validación: 0.9232337772846222\nExactitud validación: 18.1739\nÉpoca 327\nPerdida entrenamiento: 0.26264332410167246\nPerdida validación: 0.8974900245666504\nExactitud validación: 18.4000\nÉpoca 328\nPerdida entrenamiento: 0.2613668257699293\nPerdida validación: 0.8862783759832382\nExactitud validación: 18.4000\nÉpoca 329\nPerdida entrenamiento: 0.25836709930616264\nPerdida validación: 0.8626670092344284\nExactitud validación: 18.5130\nÉpoca 330\nPerdida entrenamiento: 0.25922364522429076\nPerdida validación: 0.8830067962408066\nExactitud validación: 18.4000\nÉpoca 331\nPerdida entrenamiento: 0.26386993597535524\nPerdida validación: 0.8540544435381889\nExactitud validación: 18.2870\nÉpoca 332\nPerdida entrenamiento: 0.2593020134988953\nPerdida validación: 0.9039890021085739\nExactitud validación: 18.6261\nÉpoca 333\nPerdida entrenamiento: 0.2595018516568577\nPerdida validación: 0.8899291157722473\nExactitud validación: 17.9478\nÉpoca 334\nPerdida entrenamiento: 0.25665878986611085\nPerdida validación: 0.8394737765192986\nExactitud validación: 18.5130\nÉpoca 335\nPerdida entrenamiento: 0.25748301604214835\nPerdida validación: 0.9290647059679031\nExactitud validación: 18.7391\nÉpoca 336\nPerdida entrenamiento: 0.2590382677667281\nPerdida validación: 0.8649090602993965\nExactitud validación: 18.2870\nÉpoca 337\nPerdida entrenamiento: 0.2554243496235679\nPerdida validación: 0.9593407809734344\nExactitud validación: 18.7391\nÉpoca 338\nPerdida entrenamiento: 0.25691094906891093\nPerdida validación: 0.9706677794456482\nExactitud validación: 18.2870\nÉpoca 339\nPerdida entrenamiento: 0.25731626678915587\nPerdida validación: 0.9453080892562866\nExactitud validación: 18.6261\nÉpoca 340\nPerdida entrenamiento: 0.25507257659645644\nPerdida validación: 1.0293856039643288\nExactitud validación: 18.1739\nÉpoca 341\nPerdida entrenamiento: 0.25653984616784486\nPerdida validación: 0.9515304788947105\nExactitud validación: 18.6261\nÉpoca 342\nPerdida entrenamiento: 0.2530783467433032\nPerdida validación: 0.9056045934557915\nExactitud validación: 18.5130\nÉpoca 343\nPerdida entrenamiento: 0.25274669072207284\nPerdida validación: 0.918601781129837\nExactitud validación: 18.5130\nÉpoca 344\nPerdida entrenamiento: 0.25438859269899483\nPerdida validación: 0.8851798251271248\nExactitud validación: 18.6261\nÉpoca 345\nPerdida entrenamiento: 0.25582583599230824\nPerdida validación: 0.8939363956451416\nExactitud validación: 18.5130\nÉpoca 346\nPerdida entrenamiento: 0.25355858443414464\nPerdida validación: 0.9068932980298996\nExactitud validación: 18.5130\nÉpoca 347\nPerdida entrenamiento: 0.2524866067311343\nPerdida validación: 0.8788146674633026\nExactitud validación: 18.1739\nÉpoca 348\nPerdida entrenamiento: 0.2536166170064141\nPerdida validación: 0.9186953902244568\nExactitud validación: 18.5130\nÉpoca 349\nPerdida entrenamiento: 0.25076256341793957\nPerdida validación: 0.9136313498020172\nExactitud validación: 18.1739\nÉpoca 350\nPerdida entrenamiento: 0.2505396744784187\nPerdida validación: 0.8769859820604324\nExactitud validación: 18.1739\nÉpoca 351\nPerdida entrenamiento: 0.2476857444819282\nPerdida validación: 0.9611544162034988\nExactitud validación: 18.1739\nÉpoca 352\nPerdida entrenamiento: 0.2510046801146339\nPerdida validación: 0.8769300132989883\nExactitud validación: 18.7391\nÉpoca 353\nPerdida entrenamiento: 0.2519538367495817\nPerdida validación: 1.009942501783371\nExactitud validación: 18.6261\nÉpoca 354\nPerdida entrenamiento: 0.25590333780821634\nPerdida validación: 1.0110169053077698\nExactitud validación: 18.4000\nÉpoca 355\nPerdida entrenamiento: 0.24665287882089615\nPerdida validación: 0.963760256767273\nExactitud validación: 18.4000\nÉpoca 356\nPerdida entrenamiento: 0.24831677973270416\nPerdida validación: 0.9520362615585327\nExactitud validación: 18.4000\nÉpoca 357\nPerdida entrenamiento: 0.25036969605614157\nPerdida validación: 0.9705468714237213\nExactitud validación: 18.1739\nÉpoca 358\nPerdida entrenamiento: 0.2493774198433932\nPerdida validación: 0.9390139281749725\nExactitud validación: 18.2870\nÉpoca 359\nPerdida entrenamiento: 0.24896152755793402\nPerdida validación: 0.9668420851230621\nExactitud validación: 18.8522\nÉpoca 360\nPerdida entrenamiento: 0.24545341993079467\nPerdida validación: 0.9598726183176041\nExactitud validación: 18.4000\nÉpoca 361\nPerdida entrenamiento: 0.2458833907456959\nPerdida validación: 0.9334637522697449\nExactitud validación: 18.1739\nÉpoca 362\nPerdida entrenamiento: 0.24675725137486176\nPerdida validación: 0.9621522575616837\nExactitud validación: 18.0609\nÉpoca 363\nPerdida entrenamiento: 0.24821498946231954\nPerdida validación: 0.9556918889284134\nExactitud validación: 18.7391\nÉpoca 364\nPerdida entrenamiento: 0.24909637824577444\nPerdida validación: 0.8772937767207623\nExactitud validación: 18.4000\nÉpoca 365\nPerdida entrenamiento: 0.2441341666614308\nPerdida validación: 0.9345356523990631\nExactitud validación: 18.6261\nÉpoca 366\nPerdida entrenamiento: 0.2470776263405295\nPerdida validación: 1.1278765723109245\nExactitud validación: 18.4000\nÉpoca 367\nPerdida entrenamiento: 0.24338742038782904\nPerdida validación: 0.9173186719417572\nExactitud validación: 18.7391\nÉpoca 368\nPerdida entrenamiento: 0.24587972418350332\nPerdida validación: 0.9912368655204773\nExactitud validación: 18.0609\nÉpoca 369\nPerdida entrenamiento: 0.2427884471767089\nPerdida validación: 0.9538993611931801\nExactitud validación: 18.7391\nÉpoca 370\nPerdida entrenamiento: 0.243407864780987\nPerdida validación: 1.0761137753725052\nExactitud validación: 18.4000\nÉpoca 371\nPerdida entrenamiento: 0.24230772344505086\nPerdida validación: 0.968388170003891\nExactitud validación: 18.6261\nÉpoca 372\nPerdida entrenamiento: 0.2439663826542742\nPerdida validación: 0.9714508131146431\nExactitud validación: 18.6261\nÉpoca 373\nPerdida entrenamiento: 0.24384574592113495\nPerdida validación: 0.9771965891122818\nExactitud validación: 18.4000\nÉpoca 374\nPerdida entrenamiento: 0.24184141614857843\nPerdida validación: 0.9964085817337036\nExactitud validación: 18.4000\nÉpoca 375\nPerdida entrenamiento: 0.24101467518245473\nPerdida validación: 0.9356465041637421\nExactitud validación: 17.9478\nÉpoca 376\nPerdida entrenamiento: 0.24006997969220667\nPerdida validación: 0.9156605526804924\nExactitud validación: 18.0609\nÉpoca 377\nPerdida entrenamiento: 0.23987779985455907\nPerdida validación: 1.0531059503555298\nExactitud validación: 18.2870\nÉpoca 378\nPerdida entrenamiento: 0.24004541951067307\nPerdida validación: 1.0218062326312065\nExactitud validación: 18.6261\nÉpoca 379\nPerdida entrenamiento: 0.23972525666741765\nPerdida validación: 1.0781173408031464\nExactitud validación: 18.4000\nÉpoca 380\nPerdida entrenamiento: 0.23826756415998235\nPerdida validación: 1.0114049911499023\nExactitud validación: 18.2870\nÉpoca 381\nPerdida entrenamiento: 0.24126425473129048\nPerdida validación: 0.9385729283094406\nExactitud validación: 18.2870\nÉpoca 382\nPerdida entrenamiento: 0.23986119557829463\nPerdida validación: 1.0387549847364426\nExactitud validación: 18.5130\nÉpoca 383\nPerdida entrenamiento: 0.2385270192342646\nPerdida validación: 0.9609201848506927\nExactitud validación: 18.6261\nÉpoca 384\nPerdida entrenamiento: 0.23623030238291798\nPerdida validación: 0.9485830962657928\nExactitud validación: 18.9652\nÉpoca 385\nPerdida entrenamiento: 0.2384230853880153\nPerdida validación: 0.9416188150644302\nExactitud validación: 18.4000\nÉpoca 386\nPerdida entrenamiento: 0.23678378015756607\nPerdida validación: 0.9777514040470123\nExactitud validación: 18.5130\nÉpoca 387\nPerdida entrenamiento: 0.2363624467569239\nPerdida validación: 1.0215286016464233\nExactitud validación: 18.7391\nÉpoca 388\nPerdida entrenamiento: 0.23862669660764582\nPerdida validación: 0.9029609151184559\nExactitud validación: 18.1739\nÉpoca 389\nPerdida entrenamiento: 0.23591116070747375\nPerdida validación: 0.981246717274189\nExactitud validación: 18.6261\nÉpoca 390\nPerdida entrenamiento: 0.23835155718466816\nPerdida validación: 1.0086095109581947\nExactitud validación: 18.2870\nÉpoca 391\nPerdida entrenamiento: 0.2371460374663858\nPerdida validación: 1.0065960884094238\nExactitud validación: 18.1739\nÉpoca 392\nPerdida entrenamiento: 0.23677723285029917\nPerdida validación: 0.9826027452945709\nExactitud validación: 18.5130\nÉpoca 393\nPerdida entrenamiento: 0.23566791196079814\nPerdida validación: 1.0341725945472717\nExactitud validación: 18.7391\nÉpoca 394\nPerdida entrenamiento: 0.23627526444547317\nPerdida validación: 1.0409796610474586\nExactitud validación: 18.6261\nÉpoca 395\nPerdida entrenamiento: 0.23617835518191843\nPerdida validación: 1.6217666417360306\nExactitud validación: 18.5130\nÉpoca 396\nPerdida entrenamiento: 0.233415008029517\nPerdida validación: 0.9137831814587116\nExactitud validación: 18.4000\nÉpoca 397\nPerdida entrenamiento: 0.2343826009070172\nPerdida validación: 1.7579079121351242\nExactitud validación: 18.7391\nÉpoca 398\nPerdida entrenamiento: 0.23368020224220612\nPerdida validación: 1.0100515186786652\nExactitud validación: 18.7391\nÉpoca 399\nPerdida entrenamiento: 0.2321076200288885\nPerdida validación: 1.6793339550495148\nExactitud validación: 18.6261\nÉpoca 400\nPerdida entrenamiento: 0.23293223012896144\nPerdida validación: 1.610338568687439\nExactitud validación: 18.6261\nÉpoca 401\nPerdida entrenamiento: 0.23105231278082905\nPerdida validación: 1.6416560858488083\nExactitud validación: 18.4000\nÉpoca 402\nPerdida entrenamiento: 0.23033762372591915\nPerdida validación: 1.66363063454628\nExactitud validación: 18.4000\nÉpoca 403\nPerdida entrenamiento: 0.23017951057237737\nPerdida validación: 1.6514071226119995\nExactitud validación: 18.4000\nÉpoca 404\nPerdida entrenamiento: 0.23135478268651402\nPerdida validación: 1.703551098704338\nExactitud validación: 18.6261\nÉpoca 405\nPerdida entrenamiento: 0.23199564174694173\nPerdida validación: 1.6757195889949799\nExactitud validación: 18.2870\nÉpoca 406\nPerdida entrenamiento: 0.23011183563400717\nPerdida validación: 2.195468708872795\nExactitud validación: 18.5130\nÉpoca 407\nPerdida entrenamiento: 0.2305179115603952\nPerdida validación: 2.174595355987549\nExactitud validación: 18.7391\nÉpoca 408\nPerdida entrenamiento: 0.23433966364930658\nPerdida validación: 1.7009802162647247\nExactitud validación: 18.5130\nÉpoca 409\nPerdida entrenamiento: 0.23122593146913192\nPerdida validación: 1.6614426672458649\nExactitud validación: 18.9652\nÉpoca 410\nPerdida entrenamiento: 0.22980902212507584\nPerdida validación: 1.6923879534006119\nExactitud validación: 18.5130\nÉpoca 411\nPerdida entrenamiento: 0.2278544008731842\nPerdida validación: 1.6532950922846794\nExactitud validación: 18.4000\nÉpoca 412\nPerdida entrenamiento: 0.22777951815549066\nPerdida validación: 1.680533990263939\nExactitud validación: 18.6261\nÉpoca 413\nPerdida entrenamiento: 0.22783642744316773\nPerdida validación: 1.6505683958530426\nExactitud validación: 18.4000\nÉpoca 414\nPerdida entrenamiento: 0.22797440430697272\nPerdida validación: 1.6364076286554337\nExactitud validación: 18.2870\nÉpoca 415\nPerdida entrenamiento: 0.22762182880850398\nPerdida validación: 1.630989708006382\nExactitud validación: 18.2870\nÉpoca 416\nPerdida entrenamiento: 0.227926942793762\nPerdida validación: 1.6618505418300629\nExactitud validación: 18.6261\nÉpoca 417\nPerdida entrenamiento: 0.22629480239223032\nPerdida validación: 1.6968141943216324\nExactitud validación: 18.4000\nÉpoca 418\nPerdida entrenamiento: 0.22488318559001474\nPerdida validación: 1.7578092515468597\nExactitud validación: 18.2870\nÉpoca 419\nPerdida entrenamiento: 0.2263673219610663\nPerdida validación: 1.6131335943937302\nExactitud validación: 18.1739\nÉpoca 420\nPerdida entrenamiento: 0.22987113630070405\nPerdida validación: 1.7163729965686798\nExactitud validación: 18.1739\nÉpoca 421\nPerdida entrenamiento: 0.22674175527165918\nPerdida validación: 1.6752920597791672\nExactitud validación: 18.8522\nÉpoca 422\nPerdida entrenamiento: 0.22827263702364528\nPerdida validación: 1.7154240310192108\nExactitud validación: 18.5130\nÉpoca 423\nPerdida entrenamiento: 0.2220915402559673\nPerdida validación: 1.6310960724949837\nExactitud validación: 18.1739\nÉpoca 424\nPerdida entrenamiento: 0.22505173613043392\nPerdida validación: 1.6115675866603851\nExactitud validación: 18.1739\nÉpoca 425\nPerdida entrenamiento: 0.22220089418046615\nPerdida validación: 2.214143306016922\nExactitud validación: 18.1739\nÉpoca 426\nPerdida entrenamiento: 0.2250201561871697\nPerdida validación: 1.64544016122818\nExactitud validación: 18.1739\nÉpoca 427\nPerdida entrenamiento: 0.22550559876596227\nPerdida validación: 1.6851514726877213\nExactitud validación: 18.7391\nÉpoca 428\nPerdida entrenamiento: 0.22317052457262487\nPerdida validación: 1.7038426101207733\nExactitud validación: 18.7391\nÉpoca 429\nPerdida entrenamiento: 0.22356641993803136\nPerdida validación: 1.710338070988655\nExactitud validación: 18.4000\nÉpoca 430\nPerdida entrenamiento: 0.22142810199190588\nPerdida validación: 1.7483271360397339\nExactitud validación: 18.7391\nÉpoca 431\nPerdida entrenamiento: 0.22034293062546673\nPerdida validación: 1.6430785655975342\nExactitud validación: 18.7391\nÉpoca 432\nPerdida entrenamiento: 0.22316901824053595\nPerdida validación: 1.7672994136810303\nExactitud validación: 18.4000\nÉpoca 433\nPerdida entrenamiento: 0.22463338383856943\nPerdida validación: 1.6433425098657608\nExactitud validación: 18.4000\nÉpoca 434\nPerdida entrenamiento: 0.22231091646587148\nPerdida validación: 1.6801955252885818\nExactitud validación: 18.5130\nÉpoca 435\nPerdida entrenamiento: 0.2208845168352127\nPerdida validación: 1.6813064217567444\nExactitud validación: 18.2870\nÉpoca 436\nPerdida entrenamiento: 0.22095614584053264\nPerdida validación: 1.6760065108537674\nExactitud validación: 18.6261\nÉpoca 437\nPerdida entrenamiento: 0.22033456712961197\nPerdida validación: 1.678830772638321\nExactitud validación: 18.7391\nÉpoca 438\nPerdida entrenamiento: 0.22007577559527228\nPerdida validación: 1.6954376250505447\nExactitud validación: 18.6261\nÉpoca 439\nPerdida entrenamiento: 0.22003603507490718\nPerdida validación: 1.725928619503975\nExactitud validación: 18.8522\nÉpoca 440\nPerdida entrenamiento: 0.22195249708259807\nPerdida validación: 1.8037448972463608\nExactitud validación: 18.5130\nÉpoca 441\nPerdida entrenamiento: 0.21979504736030803\nPerdida validación: 1.6947238594293594\nExactitud validación: 18.1739\nÉpoca 442\nPerdida entrenamiento: 0.21700231205014622\nPerdida validación: 1.7131413221359253\nExactitud validación: 18.5130\nÉpoca 443\nPerdida entrenamiento: 0.21716881061301513\nPerdida validación: 1.7016572207212448\nExactitud validación: 18.2870\nÉpoca 444\nPerdida entrenamiento: 0.21755946778199253\nPerdida validación: 2.2080706506967545\nExactitud validación: 18.4000\nÉpoca 445\nPerdida entrenamiento: 0.21960881308597677\nPerdida validación: 2.2232966125011444\nExactitud validación: 18.2870\nÉpoca 446\nPerdida entrenamiento: 0.2177817536627545\nPerdida validación: 1.674214854836464\nExactitud validación: 18.2870\nÉpoca 447\nPerdida entrenamiento: 0.22076668239691677\nPerdida validación: 1.6826488673686981\nExactitud validación: 18.4000\nÉpoca 448\nPerdida entrenamiento: 0.2175587897791582\nPerdida validación: 1.684437245130539\nExactitud validación: 18.4000\nÉpoca 449\nPerdida entrenamiento: 0.21597974396803798\nPerdida validación: 1.7088166177272797\nExactitud validación: 18.2870\nÉpoca 450\nPerdida entrenamiento: 0.21813132044147043\nPerdida validación: 1.733146995306015\nExactitud validación: 18.1739\nÉpoca 451\nPerdida entrenamiento: 0.21773759976905935\nPerdida validación: 1.6941641122102737\nExactitud validación: 18.2870\nÉpoca 452\nPerdida entrenamiento: 0.21535080583656535\nPerdida validación: 1.76713265478611\nExactitud validación: 18.4000\nÉpoca 453\nPerdida entrenamiento: 0.21499554462292614\nPerdida validación: 1.725937306880951\nExactitud validación: 18.4000\nÉpoca 454\nPerdida entrenamiento: 0.21762167399420457\nPerdida validación: 1.745834544301033\nExactitud validación: 18.4000\nÉpoca 455\nPerdida entrenamiento: 0.21529359852566438\nPerdida validación: 1.7183891236782074\nExactitud validación: 18.6261\nÉpoca 456\nPerdida entrenamiento: 0.21322160959243774\nPerdida validación: 1.665738008916378\nExactitud validación: 18.5130\nÉpoca 457\nPerdida entrenamiento: 0.21297074021661982\nPerdida validación: 1.6415093056857586\nExactitud validación: 18.1739\nÉpoca 458\nPerdida entrenamiento: 0.2120342228342505\nPerdida validación: 1.6675629317760468\nExactitud validación: 18.5130\nÉpoca 459\nPerdida entrenamiento: 0.21290872377507827\nPerdida validación: 1.7062142491340637\nExactitud validación: 18.1739\nÉpoca 460\nPerdida entrenamiento: 0.2155881883466945\nPerdida validación: 1.6664244383573532\nExactitud validación: 18.6261\nÉpoca 461\nPerdida entrenamiento: 0.2123072870513972\nPerdida validación: 1.6892398595809937\nExactitud validación: 18.1739\nÉpoca 462\nPerdida entrenamiento: 0.21215057285392985\nPerdida validación: 1.71298286318779\nExactitud validación: 18.5130\nÉpoca 463\nPerdida entrenamiento: 0.2131307668545667\nPerdida validación: 2.3371381908655167\nExactitud validación: 18.4000\nÉpoca 464\nPerdida entrenamiento: 0.21063883252003612\nPerdida validación: 1.6871272176504135\nExactitud validación: 18.4000\nÉpoca 465\nPerdida entrenamiento: 0.21041779746027553\nPerdida validación: 1.7584034204483032\nExactitud validación: 18.8522\nÉpoca 466\nPerdida entrenamiento: 0.20908518573817084\nPerdida validación: 1.7399623692035675\nExactitud validación: 18.2870\nÉpoca 467\nPerdida entrenamiento: 0.20974228049025817\nPerdida validación: 1.7392813563346863\nExactitud validación: 18.0609\nÉpoca 468\nPerdida entrenamiento: 0.20860017222516677\nPerdida validación: 1.7459359467029572\nExactitud validación: 18.6261\nÉpoca 469\nPerdida entrenamiento: 0.20901529490947723\nPerdida validación: 1.6576770320534706\nExactitud validación: 18.2870\nÉpoca 470\nPerdida entrenamiento: 0.20985684850636652\nPerdida validación: 1.6809408068656921\nExactitud validación: 17.8348\nÉpoca 471\nPerdida entrenamiento: 0.20888636611840306\nPerdida validación: 1.7095791101455688\nExactitud validación: 18.4000\nÉpoca 472\nPerdida entrenamiento: 0.20915422983029308\nPerdida validación: 1.735638752579689\nExactitud validación: 18.6261\nÉpoca 473\nPerdida entrenamiento: 0.21087617295629837\nPerdida validación: 2.223282590508461\nExactitud validación: 18.8522\nÉpoca 474\nPerdida entrenamiento: 0.21059176501105814\nPerdida validación: 2.2696365863084793\nExactitud validación: 18.4000\nÉpoca 475\nPerdida entrenamiento: 0.20993135518887462\nPerdida validación: 2.3144669383764267\nExactitud validación: 18.4000\nÉpoca 476\nPerdida entrenamiento: 0.2069975641720435\nPerdida validación: 1.7147362232208252\nExactitud validación: 17.9478\nÉpoca 477\nPerdida entrenamiento: 0.20739179674316854\nPerdida validación: 1.7762307822704315\nExactitud validación: 18.4000\nÉpoca 478\nPerdida entrenamiento: 0.20736681187854095\nPerdida validación: 1.7321285605430603\nExactitud validación: 18.7391\nÉpoca 479\nPerdida entrenamiento: 0.20850269627921722\nPerdida validación: 1.7248305529356003\nExactitud validación: 18.5130\nÉpoca 480\nPerdida entrenamiento: 0.20808968561537125\nPerdida validación: 1.6793062910437584\nExactitud validación: 18.5130\nÉpoca 481\nPerdida entrenamiento: 0.2063585151644314\nPerdida validación: 2.3160250037908554\nExactitud validación: 18.4000\nÉpoca 482\nPerdida entrenamiento: 0.20922441298470779\nPerdida validación: 1.7382783144712448\nExactitud validación: 18.7391\nÉpoca 483\nPerdida entrenamiento: 0.2089783260050942\nPerdida validación: 1.675756473094225\nExactitud validación: 18.2870\nÉpoca 484\nPerdida entrenamiento: 0.20955036317600922\nPerdida validación: 1.7968875467777252\nExactitud validación: 18.5130\nÉpoca 485\nPerdida entrenamiento: 0.20719658802537358\nPerdida validación: 2.281432792544365\nExactitud validación: 18.2870\nÉpoca 486\nPerdida entrenamiento: 0.20671694988713546\nPerdida validación: 2.290306895971298\nExactitud validación: 18.5130\nÉpoca 487\nPerdida entrenamiento: 0.20706017490695505\nPerdida validación: 1.7116160094738007\nExactitud validación: 18.4000\nÉpoca 488\nPerdida entrenamiento: 0.20524413971339955\nPerdida validación: 1.8093033283948898\nExactitud validación: 18.5130\nÉpoca 489\nPerdida entrenamiento: 0.2051747401847559\nPerdida validación: 1.7765755355358124\nExactitud validación: 18.6261\nÉpoca 490\nPerdida entrenamiento: 0.20630764128530726\nPerdida validación: 1.7870673686265945\nExactitud validación: 18.2870\nÉpoca 491\nPerdida entrenamiento: 0.20644442780929453\nPerdida validación: 2.2809912860393524\nExactitud validación: 18.5130\nÉpoca 492\nPerdida entrenamiento: 0.2057285668218837\nPerdida validación: 2.258572533726692\nExactitud validación: 17.8348\nÉpoca 493\nPerdida entrenamiento: 0.2029068154447219\nPerdida validación: 1.6803431659936905\nExactitud validación: 18.7391\nÉpoca 494\nPerdida entrenamiento: 0.2028874272809309\nPerdida validación: 1.8127751350402832\nExactitud validación: 18.7391\nÉpoca 495\nPerdida entrenamiento: 0.2052424208206289\nPerdida validación: 1.7849414199590683\nExactitud validación: 18.7391\nÉpoca 496\nPerdida entrenamiento: 0.20392162791069815\nPerdida validación: 1.7237890660762787\nExactitud validación: 18.4000\nÉpoca 497\nPerdida entrenamiento: 0.20092843429130666\nPerdida validación: 2.2871531173586845\nExactitud validación: 18.6261\nÉpoca 498\nPerdida entrenamiento: 0.20234436278834061\nPerdida validación: 2.2854884639382362\nExactitud validación: 18.2870\nÉpoca 499\nPerdida entrenamiento: 0.20332733541727066\nPerdida validación: 1.7827043235301971\nExactitud validación: 18.6261\nÉpoca 500\nPerdida entrenamiento: 0.20469026092220755\nPerdida validación: 2.3745395615696907\nExactitud validación: 18.5130\nÉpoca 501\nPerdida entrenamiento: 0.20449996783452876\nPerdida validación: 1.7906746417284012\nExactitud validación: 18.6261\nÉpoca 502\nPerdida entrenamiento: 0.20517864034456365\nPerdida validación: 1.732749417424202\nExactitud validación: 18.5130\nÉpoca 503\nPerdida entrenamiento: 0.20195804273380952\nPerdida validación: 2.2683166712522507\nExactitud validación: 18.5130\nÉpoca 504\nPerdida entrenamiento: 0.2007514510084601\nPerdida validación: 1.7528420686721802\nExactitud validación: 18.4000\nÉpoca 505\nPerdida entrenamiento: 0.2026394693290486\nPerdida validación: 1.7850606441497803\nExactitud validación: 18.4000\nÉpoca 506\nPerdida entrenamiento: 0.20051894775208304\nPerdida validación: 1.7376345694065094\nExactitud validación: 18.5130\nÉpoca 507\nPerdida entrenamiento: 0.1994068114196553\nPerdida validación: 1.813426986336708\nExactitud validación: 18.2870\nÉpoca 508\nPerdida entrenamiento: 0.20079496415222392\nPerdida validación: 2.327720493078232\nExactitud validación: 18.2870\nÉpoca 509\nPerdida entrenamiento: 0.20256532158921747\nPerdida validación: 1.7458709627389908\nExactitud validación: 18.4000\nÉpoca 510\nPerdida entrenamiento: 0.20124467067858753\nPerdida validación: 1.7705589160323143\nExactitud validación: 18.5130\nÉpoca 511\nPerdida entrenamiento: 0.19941148468676737\nPerdida validación: 1.796208769083023\nExactitud validación: 18.4000\nÉpoca 512\nPerdida entrenamiento: 0.19882883394465728\nPerdida validación: 1.749910831451416\nExactitud validación: 18.4000\nÉpoca 513\nPerdida entrenamiento: 0.2000570288475822\nPerdida validación: 1.796690434217453\nExactitud validación: 18.5130\nÉpoca 514\nPerdida entrenamiento: 0.19875034295460758\nPerdida validación: 1.7634713500738144\nExactitud validación: 18.4000\nÉpoca 515\nPerdida entrenamiento: 0.19847256471129024\nPerdida validación: 1.7303752601146698\nExactitud validación: 18.2870\nÉpoca 516\nPerdida entrenamiento: 0.19714518767945907\nPerdida validación: 1.7873051464557648\nExactitud validación: 18.7391\nÉpoca 517\nPerdida entrenamiento: 0.19987665379748626\nPerdida validación: 2.3726578801870346\nExactitud validación: 18.0609\nÉpoca 518\nPerdida entrenamiento: 0.19713971062618144\nPerdida validación: 1.8600481450557709\nExactitud validación: 18.6261\nÉpoca 519\nPerdida entrenamiento: 0.19719707089311936\nPerdida validación: 1.7947774976491928\nExactitud validación: 18.5130\nÉpoca 520\nPerdida entrenamiento: 0.19800057525143905\nPerdida validación: 1.8386373445391655\nExactitud validación: 18.4000\nÉpoca 521\nPerdida entrenamiento: 0.19503561845597098\nPerdida validación: 1.86511692404747\nExactitud validación: 18.0609\nÉpoca 522\nPerdida entrenamiento: 0.19703502164167516\nPerdida validación: 2.2786576449871063\nExactitud validación: 18.7391\nÉpoca 523\nPerdida entrenamiento: 0.1965047695180949\nPerdida validación: 1.7550715208053589\nExactitud validación: 18.5130\nÉpoca 524\nPerdida entrenamiento: 0.19743618281448588\nPerdida validación: 1.7788794338703156\nExactitud validación: 18.4000\nÉpoca 525\nPerdida entrenamiento: 0.19581336571889765\nPerdida validación: 2.3412183597683907\nExactitud validación: 18.6261\nÉpoca 526\nPerdida entrenamiento: 0.19735115065294154\nPerdida validación: 1.7944573611021042\nExactitud validación: 18.5130\nÉpoca 527\nPerdida entrenamiento: 0.1972572623806841\nPerdida validación: 1.7847600281238556\nExactitud validación: 18.4000\nÉpoca 528\nPerdida entrenamiento: 0.19613027397324057\nPerdida validación: 1.8530294448137283\nExactitud validación: 18.2870\nÉpoca 529\nPerdida entrenamiento: 0.19604966395041523\nPerdida validación: 1.8482124507427216\nExactitud validación: 18.6261\nÉpoca 530\nPerdida entrenamiento: 0.19563549099599614\nPerdida validación: 1.7713856101036072\nExactitud validación: 18.6261\nÉpoca 531\nPerdida entrenamiento: 0.1955263259656289\nPerdida validación: 1.8069935888051987\nExactitud validación: 17.9478\nÉpoca 532\nPerdida entrenamiento: 0.19411977774956646\nPerdida validación: 1.8041860908269882\nExactitud validación: 18.6261\nÉpoca 533\nPerdida entrenamiento: 0.1945977715008399\nPerdida validación: 1.825106680393219\nExactitud validación: 18.2870\nÉpoca 534\nPerdida entrenamiento: 0.1952920450883753\nPerdida validación: 2.3135114312171936\nExactitud validación: 18.6261\nÉpoca 535\nPerdida entrenamiento: 0.19248855683733435\nPerdida validación: 1.8990767300128937\nExactitud validación: 18.4000\nÉpoca 536\nPerdida entrenamiento: 0.19831059960757985\nPerdida validación: 1.80620726197958\nExactitud validación: 18.2870\nÉpoca 537\nPerdida entrenamiento: 0.1929608224069371\nPerdida validación: 1.7912742048501968\nExactitud validación: 18.4000\nÉpoca 538\nPerdida entrenamiento: 0.19296798898893244\nPerdida validación: 1.7543442994356155\nExactitud validación: 18.1739\nÉpoca 539\nPerdida entrenamiento: 0.1950954786118339\nPerdida validación: 1.8118992149829865\nExactitud validación: 18.4000\nÉpoca 540\nPerdida entrenamiento: 0.1945850323228275\nPerdida validación: 1.8098999336361885\nExactitud validación: 18.2870\nÉpoca 541\nPerdida entrenamiento: 0.19389351413530462\nPerdida validación: 2.289820373058319\nExactitud validación: 18.2870\nÉpoca 542\nPerdida entrenamiento: 0.19105484468095443\nPerdida validación: 1.794912725687027\nExactitud validación: 18.0609\nÉpoca 543\nPerdida entrenamiento: 0.19384890005869024\nPerdida validación: 1.875189632177353\nExactitud validación: 18.1739\nÉpoca 544\nPerdida entrenamiento: 0.19117492963286006\nPerdida validación: 1.809283822774887\nExactitud validación: 18.4000\nÉpoca 545\nPerdida entrenamiento: 0.19236618893987992\nPerdida validación: 2.2911151945590973\nExactitud validación: 18.6261\nÉpoca 546\nPerdida entrenamiento: 0.19125396495356278\nPerdida validación: 1.7524409666657448\nExactitud validación: 18.5130\nÉpoca 547\nPerdida entrenamiento: 0.19026901047019398\nPerdida validación: 1.8327823728322983\nExactitud validación: 18.4000\nÉpoca 548\nPerdida entrenamiento: 0.1921607873895589\nPerdida validación: 2.307979680597782\nExactitud validación: 18.2870\nÉpoca 549\nPerdida entrenamiento: 0.19157351816401763\nPerdida validación: 1.8872595876455307\nExactitud validación: 18.4000\nÉpoca 550\nPerdida entrenamiento: 0.19094288480632446\nPerdida validación: 1.9153790324926376\nExactitud validación: 18.6261\nÉpoca 551\nPerdida entrenamiento: 0.19048834592103958\nPerdida validación: 1.7659415304660797\nExactitud validación: 18.5130\nÉpoca 552\nPerdida entrenamiento: 0.19038300785948248\nPerdida validación: 1.7611987218260765\nExactitud validación: 18.4000\nÉpoca 553\nPerdida entrenamiento: 0.18965064383604946\nPerdida validación: 1.871100902557373\nExactitud validación: 18.2870\nÉpoca 554\nPerdida entrenamiento: 0.19062230779844172\nPerdida validación: 1.8860596120357513\nExactitud validación: 18.2870\nÉpoca 555\nPerdida entrenamiento: 0.18969056185554056\nPerdida validación: 2.3548885583877563\nExactitud validación: 18.0609\nÉpoca 556\nPerdida entrenamiento: 0.18985140696167946\nPerdida validación: 2.386777237057686\nExactitud validación: 18.5130\nÉpoca 557\nPerdida entrenamiento: 0.19206796192071018\nPerdida validación: 1.804469645023346\nExactitud validación: 18.2870\nÉpoca 558\nPerdida entrenamiento: 0.1930651068687439\nPerdida validación: 1.8630142956972122\nExactitud validación: 18.4000\nÉpoca 559\nPerdida entrenamiento: 0.1930370124823907\nPerdida validación: 1.7798155397176743\nExactitud validación: 18.4000\nÉpoca 560\nPerdida entrenamiento: 0.1902738498414264\nPerdida validación: 1.8318945318460464\nExactitud validación: 18.4000\nÉpoca 561\nPerdida entrenamiento: 0.19049055655212963\nPerdida validación: 1.7881848067045212\nExactitud validación: 18.4000\nÉpoca 562\nPerdida entrenamiento: 0.18791185231769786\nPerdida validación: 1.8009058833122253\nExactitud validación: 18.7391\nÉpoca 563\nPerdida entrenamiento: 0.18878159409060197\nPerdida validación: 2.3612941056489944\nExactitud validación: 18.2870\nÉpoca 564\nPerdida entrenamiento: 0.18708483611836152\nPerdida validación: 1.795827567577362\nExactitud validación: 18.6261\nÉpoca 565\nPerdida entrenamiento: 0.18627881477860844\nPerdida validación: 1.8481564670801163\nExactitud validación: 18.5130\nÉpoca 566\nPerdida entrenamiento: 0.18686316863578908\nPerdida validación: 1.8827480152249336\nExactitud validación: 18.5130\nÉpoca 567\nPerdida entrenamiento: 0.18734496525105307\nPerdida validación: 2.437557488679886\nExactitud validación: 18.6261\nÉpoca 568\nPerdida entrenamiento: 0.18700052578659618\nPerdida validación: 1.8809164464473724\nExactitud validación: 18.6261\nÉpoca 569\nPerdida entrenamiento: 0.1859943498583401\nPerdida validación: 2.3979000598192215\nExactitud validación: 18.5130\nÉpoca 570\nPerdida entrenamiento: 0.1867598135243444\nPerdida validación: 2.401433676481247\nExactitud validación: 18.4000\nÉpoca 571\nPerdida entrenamiento: 0.18641008743468454\nPerdida validación: 1.8099213689565659\nExactitud validación: 18.4000\nÉpoca 572\nPerdida entrenamiento: 0.1878149176345152\nPerdida validación: 1.8095275163650513\nExactitud validación: 18.7391\nÉpoca 573\nPerdida entrenamiento: 0.1844573288279421\nPerdida validación: 1.815418690443039\nExactitud validación: 18.4000\nÉpoca 574\nPerdida entrenamiento: 0.18568310711313696\nPerdida validación: 1.7979236990213394\nExactitud validación: 18.5130\nÉpoca 575\nPerdida entrenamiento: 0.1849901847103063\nPerdida validación: 1.8825554847717285\nExactitud validación: 18.4000\nÉpoca 576\nPerdida entrenamiento: 0.18612053245306015\nPerdida validación: 1.80270117521286\nExactitud validación: 18.4000\nÉpoca 577\nPerdida entrenamiento: 0.1876081745414173\nPerdida validación: 1.8711232542991638\nExactitud validación: 18.2870\nÉpoca 578\nPerdida entrenamiento: 0.18576577305793762\nPerdida validación: 1.908687710762024\nExactitud validación: 18.2870\nÉpoca 579\nPerdida entrenamiento: 0.18641850834383683\nPerdida validación: 1.86570705473423\nExactitud validación: 17.9478\nÉpoca 580\nPerdida entrenamiento: 0.1835003499599064\nPerdida validación: 1.8697331100702286\nExactitud validación: 18.6261\nÉpoca 581\nPerdida entrenamiento: 0.18529456985347412\nPerdida validación: 1.7919117659330368\nExactitud validación: 18.2870\nÉpoca 582\nPerdida entrenamiento: 0.1841503298457931\nPerdida validación: 2.4412302374839783\nExactitud validación: 18.7391\nÉpoca 583\nPerdida entrenamiento: 0.18371729158303318\nPerdida validación: 1.8544679284095764\nExactitud validación: 18.8522\nÉpoca 584\nPerdida entrenamiento: 0.18499108140959458\nPerdida validación: 1.8232229053974152\nExactitud validación: 18.5130\nÉpoca 585\nPerdida entrenamiento: 0.1860760952181676\nPerdida validación: 1.841095194220543\nExactitud validación: 18.5130\nÉpoca 586\nPerdida entrenamiento: 0.18593923703712575\nPerdida validación: 1.8760543167591095\nExactitud validación: 18.5130\nÉpoca 587\nPerdida entrenamiento: 0.18209941509891958\nPerdida validación: 1.9005913734436035\nExactitud validación: 18.5130\nÉpoca 588\nPerdida entrenamiento: 0.18258259160553708\nPerdida validación: 1.858061134815216\nExactitud validación: 18.6261\nÉpoca 589\nPerdida entrenamiento: 0.18598782183492885\nPerdida validación: 2.420540153980255\nExactitud validación: 18.2870\nÉpoca 590\nPerdida entrenamiento: 0.1828598489656168\nPerdida validación: 1.8328881710767746\nExactitud validación: 18.6261\nÉpoca 591\nPerdida entrenamiento: 0.1841830584932776\nPerdida validación: 1.8384827971458435\nExactitud validación: 18.5130\nÉpoca 592\nPerdida entrenamiento: 0.1838392247171963\nPerdida validación: 2.3826200664043427\nExactitud validación: 18.6261\nÉpoca 593\nPerdida entrenamiento: 0.18054470770499287\nPerdida validación: 2.3773992508649826\nExactitud validación: 18.7391\nÉpoca 594\nPerdida entrenamiento: 0.18052921707139297\nPerdida validación: 1.9906710982322693\nExactitud validación: 18.0609\nÉpoca 595\nPerdida entrenamiento: 0.18146830621887655\nPerdida validación: 2.434752732515335\nExactitud validación: 18.5130\nÉpoca 596\nPerdida entrenamiento: 0.17948470089365454\nPerdida validación: 1.852248728275299\nExactitud validación: 18.7391\nÉpoca 597\nPerdida entrenamiento: 0.17860462297411525\nPerdida validación: 2.346190959215164\nExactitud validación: 18.5130\nÉpoca 598\nPerdida entrenamiento: 0.18151379288995967\nPerdida validación: 1.9093308448791504\nExactitud validación: 18.5130\nÉpoca 599\nPerdida entrenamiento: 0.17953513781814015\nPerdida validación: 1.927807793021202\nExactitud validación: 18.6261\nÉpoca 600\nPerdida entrenamiento: 0.18134287832414403\nPerdida validación: 1.8202008605003357\nExactitud validación: 17.9478\nÉpoca 601\nPerdida entrenamiento: 0.18065105510108612\nPerdida validación: 2.4191258996725082\nExactitud validación: 18.0609\nÉpoca 602\nPerdida entrenamiento: 0.17909427337786732\nPerdida validación: 2.3444060534238815\nExactitud validación: 17.9478\nÉpoca 603\nPerdida entrenamiento: 0.1807249688050326\nPerdida validación: 1.859527364373207\nExactitud validación: 18.6261\nÉpoca 604\nPerdida entrenamiento: 0.17981747581678278\nPerdida validación: 1.8991383910179138\nExactitud validación: 18.4000\nÉpoca 605\nPerdida entrenamiento: 0.18046181123046315\nPerdida validación: 1.9196833372116089\nExactitud validación: 18.2870\nÉpoca 606\nPerdida entrenamiento: 0.17735964761060827\nPerdida validación: 1.8872027397155762\nExactitud validación: 18.4000\nÉpoca 607\nPerdida entrenamiento: 0.17956263265189001\nPerdida validación: 1.8883287459611893\nExactitud validación: 18.2870\nÉpoca 608\nPerdida entrenamiento: 0.17843612239641302\nPerdida validación: 2.382715880870819\nExactitud validación: 18.2870\nÉpoca 609\nPerdida entrenamiento: 0.17757347269969828\nPerdida validación: 1.932212918996811\nExactitud validación: 18.6261\nÉpoca 610\nPerdida entrenamiento: 0.1786287356825436\nPerdida validación: 1.9283054769039154\nExactitud validación: 18.4000\nÉpoca 611\nPerdida entrenamiento: 0.17991680958691766\nPerdida validación: 2.5501490607857704\nExactitud validación: 18.2870\nÉpoca 612\nPerdida entrenamiento: 0.18011304056819746\nPerdida validación: 1.7971415668725967\nExactitud validación: 18.4000\nÉpoca 613\nPerdida entrenamiento: 0.17593874650843003\nPerdida validación: 2.426175683736801\nExactitud validación: 18.4000\nÉpoca 614\nPerdida entrenamiento: 0.17618215829133987\nPerdida validación: 2.452900141477585\nExactitud validación: 18.5130\nÉpoca 615\nPerdida entrenamiento: 0.17730087129508748\nPerdida validación: 1.8392793536186218\nExactitud validación: 18.5130\nÉpoca 616\nPerdida entrenamiento: 0.1800769615699263\nPerdida validación: 1.9838367700576782\nExactitud validación: 18.8522\nÉpoca 617\nPerdida entrenamiento: 0.17642011405790553\nPerdida validación: 1.9059662222862244\nExactitud validación: 18.7391\nÉpoca 618\nPerdida entrenamiento: 0.17710689542924657\nPerdida validación: 1.862879142165184\nExactitud validación: 18.5130\nÉpoca 619\nPerdida entrenamiento: 0.17686956814106772\nPerdida validación: 1.8814306408166885\nExactitud validación: 18.4000\nÉpoca 620\nPerdida entrenamiento: 0.17600232581881917\nPerdida validación: 1.8020828627049923\nExactitud validación: 18.1739\nÉpoca 621\nPerdida entrenamiento: 0.17544799276134548\nPerdida validación: 1.811521127820015\nExactitud validación: 18.6261\nÉpoca 622\nPerdida entrenamiento: 0.17697353485752554\nPerdida validación: 1.877358078956604\nExactitud validación: 18.5130\nÉpoca 623\nPerdida entrenamiento: 0.17406106301966837\nPerdida validación: 1.8654315024614334\nExactitud validación: 18.1739\nÉpoca 624\nPerdida entrenamiento: 0.17648298687794628\nPerdida validación: 1.8686436414718628\nExactitud validación: 18.5130\nÉpoca 625\nPerdida entrenamiento: 0.17434970179901405\nPerdida validación: 1.919616162776947\nExactitud validación: 18.9652\nÉpoca 626\nPerdida entrenamiento: 0.17567084598190644\nPerdida validación: 1.9153682887554169\nExactitud validación: 18.0609\nÉpoca 627\nPerdida entrenamiento: 0.17896952392423854\nPerdida validación: 1.8582693189382553\nExactitud validación: 18.0609\nÉpoca 628\nPerdida entrenamiento: 0.17745003915008375\nPerdida validación: 1.9257307648658752\nExactitud validación: 18.5130\nÉpoca 629\nPerdida entrenamiento: 0.1788088896257036\nPerdida validación: 1.931223213672638\nExactitud validación: 18.5130\nÉpoca 630\nPerdida entrenamiento: 0.17631110548973083\nPerdida validación: 2.3573699593544006\nExactitud validación: 18.6261\nÉpoca 631\nPerdida entrenamiento: 0.17479468860170422\nPerdida validación: 1.9445046782493591\nExactitud validación: 18.6261\nÉpoca 632\nPerdida entrenamiento: 0.1756579818971017\nPerdida validación: 1.973215788602829\nExactitud validación: 18.1739\nÉpoca 633\nPerdida entrenamiento: 0.17561784189413576\nPerdida validación: 1.9100207686424255\nExactitud validación: 18.8522\nÉpoca 634\nPerdida entrenamiento: 0.1757204962127349\nPerdida validación: 1.939280390739441\nExactitud validación: 18.1739\nÉpoca 635\nPerdida entrenamiento: 0.17755503207445145\nPerdida validación: 1.981196641921997\nExactitud validación: 18.5130\nÉpoca 636\nPerdida entrenamiento: 0.17460980178678737\nPerdida validación: 1.9405174255371094\nExactitud validación: 18.4000\nÉpoca 637\nPerdida entrenamiento: 0.17348291571525967\nPerdida validación: 1.8273062705993652\nExactitud validación: 18.4000\nÉpoca 638\nPerdida entrenamiento: 0.1731029485954958\nPerdida validación: 2.380571126937866\nExactitud validación: 18.0609\nÉpoca 639\nPerdida entrenamiento: 0.17311051268787944\nPerdida validación: 2.059565246105194\nExactitud validación: 18.4000\nÉpoca 640\nPerdida entrenamiento: 0.17420342915198384\nPerdida validación: 1.9567348062992096\nExactitud validación: 18.6261\nÉpoca 641\nPerdida entrenamiento: 0.17315113938906612\nPerdida validación: 1.9034782350063324\nExactitud validación: 18.5130\nÉpoca 642\nPerdida entrenamiento: 0.1723686158657074\nPerdida validación: 1.9813492596149445\nExactitud validación: 18.5130\nÉpoca 643\nPerdida entrenamiento: 0.1716386500526877\nPerdida validación: 1.9668281972408295\nExactitud validación: 18.4000\nÉpoca 644\nPerdida entrenamiento: 0.17454188360887415\nPerdida validación: 2.3830559104681015\nExactitud validación: 18.2870\nÉpoca 645\nPerdida entrenamiento: 0.17409280687570572\nPerdida validación: 1.8761438131332397\nExactitud validación: 18.1739\nÉpoca 646\nPerdida entrenamiento: 0.17281085559550455\nPerdida validación: 1.8756016343832016\nExactitud validación: 18.4000\nÉpoca 647\nPerdida entrenamiento: 0.17153984615031412\nPerdida validación: 1.9308282732963562\nExactitud validación: 18.7391\nÉpoca 648\nPerdida entrenamiento: 0.17411951852195404\nPerdida validación: 1.8359106853604317\nExactitud validación: 17.8348\nÉpoca 649\nPerdida entrenamiento: 0.17255713790655136\nPerdida validación: 1.8988316506147385\nExactitud validación: 18.5130\nÉpoca 650\nPerdida entrenamiento: 0.17018533541875727\nPerdida validación: 1.949387177824974\nExactitud validación: 18.6261\nÉpoca 651\nPerdida entrenamiento: 0.17180895630051107\nPerdida validación: 1.9061071127653122\nExactitud validación: 18.5130\nÉpoca 652\nPerdida entrenamiento: 0.1712561582817751\nPerdida validación: 1.9416884183883667\nExactitud validación: 18.9652\nÉpoca 653\nPerdida entrenamiento: 0.17215262353420258\nPerdida validación: 1.8685024976730347\nExactitud validación: 18.8522\nÉpoca 654\nPerdida entrenamiento: 0.16887790841214798\nPerdida validación: 1.8882263749837875\nExactitud validación: 18.2870\nÉpoca 655\nPerdida entrenamiento: 0.17128623868612683\nPerdida validación: 2.458386555314064\nExactitud validación: 18.1739\nÉpoca 656\nPerdida entrenamiento: 0.170212522149086\nPerdida validación: 1.954999327659607\nExactitud validación: 18.5130\nÉpoca 657\nPerdida entrenamiento: 0.1741621494293213\nPerdida validación: 1.9523300230503082\nExactitud validación: 18.5130\nÉpoca 658\nPerdida entrenamiento: 0.17083424548892415\nPerdida validación: 1.959117352962494\nExactitud validación: 18.7391\nÉpoca 659\nPerdida entrenamiento: 0.16970867137698567\nPerdida validación: 1.8965559303760529\nExactitud validación: 18.4000\nÉpoca 660\nPerdida entrenamiento: 0.16913258941734538\nPerdida validación: 1.9195391535758972\nExactitud validación: 18.2870\nÉpoca 661\nPerdida entrenamiento: 0.16958869686898062\nPerdida validación: 2.4342183619737625\nExactitud validación: 17.7217\nÉpoca 662\nPerdida entrenamiento: 0.1689609788796481\nPerdida validación: 1.990819126367569\nExactitud validación: 18.6261\nÉpoca 663\nPerdida entrenamiento: 0.17155426433857748\nPerdida validación: 2.4798940420150757\nExactitud validación: 18.6261\nÉpoca 664\nPerdida entrenamiento: 0.17054487940143137\nPerdida validación: 1.982157289981842\nExactitud validación: 18.5130\nÉpoca 665\nPerdida entrenamiento: 0.16904305841992884\nPerdida validación: 1.8254309445619583\nExactitud validación: 18.4000\nÉpoca 666\nPerdida entrenamiento: 0.16776984053499558\nPerdida validación: 1.9470479041337967\nExactitud validación: 18.6261\nÉpoca 667\nPerdida entrenamiento: 0.16710532982559764\nPerdida validación: 2.491328239440918\nExactitud validación: 18.8522\nÉpoca 668\nPerdida entrenamiento: 0.16992384808904984\nPerdida validación: 1.9949734210968018\nExactitud validación: 18.7391\nÉpoca 669\nPerdida entrenamiento: 0.16685624595950632\nPerdida validación: 1.8857195228338242\nExactitud validación: 18.4000\nÉpoca 670\nPerdida entrenamiento: 0.16876719979678884\nPerdida validación: 1.880652368068695\nExactitud validación: 18.8522\nÉpoca 671\nPerdida entrenamiento: 0.1676985665279276\nPerdida validación: 1.9278014451265335\nExactitud validación: 18.0609\nÉpoca 672\nPerdida entrenamiento: 0.1676903353894458\nPerdida validación: 1.950418546795845\nExactitud validación: 18.6261\nÉpoca 673\nPerdida entrenamiento: 0.1701295621254865\nPerdida validación: 1.8648300468921661\nExactitud validación: 17.9478\nÉpoca 674\nPerdida entrenamiento: 0.17001822459347107\nPerdida validación: 1.8509264029562473\nExactitud validación: 18.1739\nÉpoca 675\nPerdida entrenamiento: 0.16711394970907884\nPerdida validación: 1.954179808497429\nExactitud validación: 18.5130\nÉpoca 676\nPerdida entrenamiento: 0.16708773023941936\nPerdida validación: 1.924515724182129\nExactitud validación: 18.2870\nÉpoca 677\nPerdida entrenamiento: 0.16858496648423812\nPerdida validación: 2.000500962138176\nExactitud validación: 18.4000\nÉpoca 678\nPerdida entrenamiento: 0.16450631793807535\nPerdida validación: 2.566338747739792\nExactitud validación: 18.2870\nÉpoca 679\nPerdida entrenamiento: 0.16761167566565907\nPerdida validación: 2.0148858428001404\nExactitud validación: 18.4000\nÉpoca 680\nPerdida entrenamiento: 0.16833147757193623\nPerdida validación: 2.074228048324585\nExactitud validación: 18.6261\nÉpoca 681\nPerdida entrenamiento: 0.16532384385080898\nPerdida validación: 1.9695260673761368\nExactitud validación: 18.6261\nÉpoca 682\nPerdida entrenamiento: 0.16553058124640407\nPerdida validación: 1.9510675370693207\nExactitud validación: 18.4000\nÉpoca 683\nPerdida entrenamiento: 0.16487656051621719\nPerdida validación: 2.4368354082107544\nExactitud validación: 18.0609\nÉpoca 684\nPerdida entrenamiento: 0.1665136836030904\nPerdida validación: 1.9446289241313934\nExactitud validación: 18.6261\nÉpoca 685\nPerdida entrenamiento: 0.16706801074392655\nPerdida validación: 2.0074078142642975\nExactitud validación: 18.2870\nÉpoca 686\nPerdida entrenamiento: 0.16774573746849508\nPerdida validación: 1.9531133472919464\nExactitud validación: 18.2870\nÉpoca 687\nPerdida entrenamiento: 0.1662634378846954\nPerdida validación: 1.9650149643421173\nExactitud validación: 18.1739\nÉpoca 688\nPerdida entrenamiento: 0.165897518834647\nPerdida validación: 1.9263443648815155\nExactitud validación: 18.5130\nÉpoca 689\nPerdida entrenamiento: 0.16783844898728764\nPerdida validación: 2.5158949941396713\nExactitud validación: 18.1739\nÉpoca 690\nPerdida entrenamiento: 0.1632937078966814\nPerdida validación: 2.1293532699346542\nExactitud validación: 18.4000\nÉpoca 691\nPerdida entrenamiento: 0.16604621116729343\nPerdida validación: 1.994159609079361\nExactitud validación: 18.2870\nÉpoca 692\nPerdida entrenamiento: 0.16435301785959916\nPerdida validación: 1.955128014087677\nExactitud validación: 18.5130\nÉpoca 693\nPerdida entrenamiento: 0.16429974248304086\nPerdida validación: 1.9711505323648453\nExactitud validación: 18.4000\nÉpoca 694\nPerdida entrenamiento: 0.1655895092031535\nPerdida validación: 1.929766833782196\nExactitud validación: 18.4000\nÉpoca 695\nPerdida entrenamiento: 0.16631515455596588\nPerdida validación: 2.5120222568511963\nExactitud validación: 18.6261\nÉpoca 696\nPerdida entrenamiento: 0.16254296022302964\nPerdida validación: 2.6067320108413696\nExactitud validación: 18.5130\nÉpoca 697\nPerdida entrenamiento: 0.16614514501655803\nPerdida validación: 1.9055406600236893\nExactitud validación: 18.2870\nÉpoca 698\nPerdida entrenamiento: 0.16295288327862234\nPerdida validación: 2.6316159069538116\nExactitud validación: 18.4000\nÉpoca 699\nPerdida entrenamiento: 0.16373521878438838\nPerdida validación: 1.9525791704654694\nExactitud validación: 18.4000\nÉpoca 700\nPerdida entrenamiento: 0.16521619216484182\nPerdida validación: 2.574406772851944\nExactitud validación: 18.4000\nÉpoca 701\nPerdida entrenamiento: 0.1622587906963685\nPerdida validación: 2.044219732284546\nExactitud validación: 18.5130\nÉpoca 702\nPerdida entrenamiento: 0.16276384846252553\nPerdida validación: 2.4917390048503876\nExactitud validación: 18.2870\nÉpoca 703\nPerdida entrenamiento: 0.16085231830092037\nPerdida validación: 2.0034276843070984\nExactitud validación: 18.7391\nÉpoca 704\nPerdida entrenamiento: 0.1621255900929956\nPerdida validación: 1.8788238018751144\nExactitud validación: 18.0609\nÉpoca 705\nPerdida entrenamiento: 0.16276478811221964\nPerdida validación: 2.609136253595352\nExactitud validación: 18.7391\nÉpoca 706\nPerdida entrenamiento: 0.16290473981815226\nPerdida validación: 2.039955824613571\nExactitud validación: 18.1739\nÉpoca 707\nPerdida entrenamiento: 0.1612090832170318\nPerdida validación: 2.555538982152939\nExactitud validación: 18.6261\nÉpoca 708\nPerdida entrenamiento: 0.16272959770525203\nPerdida validación: 2.6732825934886932\nExactitud validación: 18.6261\nÉpoca 709\nPerdida entrenamiento: 0.16046422807609334\nPerdida validación: 2.65529066324234\nExactitud validación: 18.2870\nÉpoca 710\nPerdida entrenamiento: 0.1593300660743433\nPerdida validación: 2.6579330414533615\nExactitud validación: 18.1739\nÉpoca 711\nPerdida entrenamiento: 0.16260490128222635\nPerdida validación: 3.1879926919937134\nExactitud validación: 18.2870\nÉpoca 712\nPerdida entrenamiento: 0.1639710743637646\nPerdida validación: 2.5582952350378036\nExactitud validación: 18.1739\nÉpoca 713\nPerdida entrenamiento: 0.16152114859398672\nPerdida validación: 3.1042632460594177\nExactitud validación: 18.0609\nÉpoca 714\nPerdida entrenamiento: 0.16002430547686183\nPerdida validación: 2.019172251224518\nExactitud validación: 18.5130\nÉpoca 715\nPerdida entrenamiento: 0.162712872685755\nPerdida validación: 2.5908713340759277\nExactitud validación: 18.2870\nÉpoca 716\nPerdida entrenamiento: 0.16232478969237385\nPerdida validación: 3.1466260999441147\nExactitud validación: 18.6261\nÉpoca 717\nPerdida entrenamiento: 0.15897689803558238\nPerdida validación: 2.5849307030439377\nExactitud validación: 18.1739\nÉpoca 718\nPerdida entrenamiento: 0.16153902823434158\nPerdida validación: 2.647393435239792\nExactitud validación: 18.1739\nÉpoca 719\nPerdida entrenamiento: 0.16119855642318726\nPerdida validación: 2.612269088625908\nExactitud validación: 18.5130\nÉpoca 720\nPerdida entrenamiento: 0.15967204334104762\nPerdida validación: 2.601207673549652\nExactitud validación: 18.0609\nÉpoca 721\nPerdida entrenamiento: 0.15950890805791407\nPerdida validación: 2.5986678898334503\nExactitud validación: 18.4000\nÉpoca 722\nPerdida entrenamiento: 0.1589717917582568\nPerdida validación: 2.7100989818573\nExactitud validación: 18.5130\nÉpoca 723\nPerdida entrenamiento: 0.16081694338251562\nPerdida validación: 3.600108325481415\nExactitud validación: 18.2870\nÉpoca 724\nPerdida entrenamiento: 0.16270827458185308\nPerdida validación: 2.6002797037363052\nExactitud validación: 18.2870\nÉpoca 725\nPerdida entrenamiento: 0.1581830897313707\nPerdida validación: 2.6805626302957535\nExactitud validación: 18.4000\nÉpoca 726\nPerdida entrenamiento: 0.1591141451807583\nPerdida validación: 2.6532941460609436\nExactitud validación: 18.9652\nÉpoca 727\nPerdida entrenamiento: 0.157598956981126\nPerdida validación: 2.572138734161854\nExactitud validación: 18.2870\nÉpoca 728\nPerdida entrenamiento: 0.15787621149245432\nPerdida validación: 2.6060239374637604\nExactitud validación: 18.1739\nÉpoca 729\nPerdida entrenamiento: 0.15959105903611465\nPerdida validación: 2.6934962272644043\nExactitud validación: 18.2870\nÉpoca 730\nPerdida entrenamiento: 0.1582015459151829\nPerdida validación: 2.60768923163414\nExactitud validación: 18.5130\nÉpoca 731\nPerdida entrenamiento: 0.157621492357815\nPerdida validación: 3.6954606622457504\nExactitud validación: 18.6261\nÉpoca 732\nPerdida entrenamiento: 0.15893621874206207\nPerdida validación: 2.7011904567480087\nExactitud validación: 18.6261\nÉpoca 733\nPerdida entrenamiento: 0.15736218322725856\nPerdida validación: 2.8146928548812866\nExactitud validación: 18.6261\nÉpoca 734\nPerdida entrenamiento: 0.1576247026815134\nPerdida validación: 3.218151092529297\nExactitud validación: 18.4000\nÉpoca 735\nPerdida entrenamiento: 0.15623568064149687\nPerdida validación: 2.5988488644361496\nExactitud validación: 18.2870\nÉpoca 736\nPerdida entrenamiento: 0.1571689445306273\nPerdida validación: 2.706854522228241\nExactitud validación: 18.2870\nÉpoca 737\nPerdida entrenamiento: 0.15617569579797633\nPerdida validación: 2.713013231754303\nExactitud validación: 18.8522\nÉpoca 738\nPerdida entrenamiento: 0.15783894587965572\nPerdida validación: 2.7247913777828217\nExactitud validación: 18.4000\nÉpoca 739\nPerdida entrenamiento: 0.15578018676708727\nPerdida validación: 2.6655010879039764\nExactitud validación: 18.5130\nÉpoca 740\nPerdida entrenamiento: 0.15636154088903875\nPerdida validación: 3.165435329079628\nExactitud validación: 18.2870\nÉpoca 741\nPerdida entrenamiento: 0.15926396539982626\nPerdida validación: 2.5721025094389915\nExactitud validación: 18.0609\nÉpoca 742\nPerdida entrenamiento: 0.156381642774624\nPerdida validación: 2.6201601326465607\nExactitud validación: 18.2870\nÉpoca 743\nPerdida entrenamiento: 0.15768505413742626\nPerdida validación: 2.618269592523575\nExactitud validación: 18.5130\nÉpoca 744\nPerdida entrenamiento: 0.1584767182083691\nPerdida validación: 2.642210215330124\nExactitud validación: 18.2870\nÉpoca 745\nPerdida entrenamiento: 0.1547083705663681\nPerdida validación: 2.74025359749794\nExactitud validación: 18.2870\nÉpoca 746\nPerdida entrenamiento: 0.15429270661929073\nPerdida validación: 2.722310483455658\nExactitud validación: 18.9652\nÉpoca 747\nPerdida entrenamiento: 0.15567336516345248\nPerdida validación: 2.602600187063217\nExactitud validación: 18.4000\nÉpoca 748\nPerdida entrenamiento: 0.15859329021152327\nPerdida validación: 2.6595190167427063\nExactitud validación: 18.4000\nÉpoca 749\nPerdida entrenamiento: 0.1617139963542714\nPerdida validación: 2.670899897813797\nExactitud validación: 18.2870\nÉpoca 750\nPerdida entrenamiento: 0.1628905837150181\nPerdida validación: 3.219875618815422\nExactitud validación: 18.6261\nÉpoca 751\nPerdida entrenamiento: 0.16012920132454703\nPerdida validación: 3.225644052028656\nExactitud validación: 18.2870\nÉpoca 752\nPerdida entrenamiento: 0.15868979188449242\nPerdida validación: 2.67586637288332\nExactitud validación: 18.4000\nÉpoca 753\nPerdida entrenamiento: 0.1629258720752071\nPerdida validación: 2.6681269705295563\nExactitud validación: 18.4000\nÉpoca 754\nPerdida entrenamiento: 0.15711017215953155\nPerdida validación: 3.1297914385795593\nExactitud validación: 17.8348\nÉpoca 755\nPerdida entrenamiento: 0.1531862835673725\nPerdida validación: 2.726800709962845\nExactitud validación: 18.6261\nÉpoca 756\nPerdida entrenamiento: 0.15572210028767586\nPerdida validación: 2.682586520910263\nExactitud validación: 18.4000\nÉpoca 757\nPerdida entrenamiento: 0.15500885072876425\nPerdida validación: 2.609253168106079\nExactitud validación: 18.6261\nÉpoca 758\nPerdida entrenamiento: 0.1528870090842247\nPerdida validación: 2.7033819258213043\nExactitud validación: 18.4000\nÉpoca 759\nPerdida entrenamiento: 0.15350659870926073\nPerdida validación: 3.182022213935852\nExactitud validación: 18.2870\nÉpoca 760\nPerdida entrenamiento: 0.15298916180344188\nPerdida validación: 2.600184068083763\nExactitud validación: 18.4000\nÉpoca 761\nPerdida entrenamiento: 0.1532105700496365\nPerdida validación: 2.6323400884866714\nExactitud validación: 18.2870\nÉpoca 762\nPerdida entrenamiento: 0.15355657391688404\nPerdida validación: 2.684819757938385\nExactitud validación: 18.7391\nÉpoca 763\nPerdida entrenamiento: 0.15543739366180756\nPerdida validación: 3.7091951966285706\nExactitud validación: 18.4000\nÉpoca 764\nPerdida entrenamiento: 0.15140601116068222\nPerdida validación: 3.2474584877490997\nExactitud validación: 18.1739\nÉpoca 765\nPerdida entrenamiento: 0.1533643844373086\nPerdida validación: 2.633063405752182\nExactitud validación: 18.5130\nÉpoca 766\nPerdida entrenamiento: 0.15192966732908697\nPerdida validación: 3.1432758569717407\nExactitud validación: 18.1739\nÉpoca 767\nPerdida entrenamiento: 0.15253492926850037\nPerdida validación: 3.246622011065483\nExactitud validación: 18.5130\nÉpoca 768\nPerdida entrenamiento: 0.15309041738510132\nPerdida validación: 2.62382273375988\nExactitud validación: 18.6261\nÉpoca 769\nPerdida entrenamiento: 0.15307236353264136\nPerdida validación: 3.6945867389440536\nExactitud validación: 17.9478\nÉpoca 770\nPerdida entrenamiento: 0.15285500949796507\nPerdida validación: 2.6508836895227432\nExactitud validación: 18.2870\nÉpoca 771\nPerdida entrenamiento: 0.15295826271176338\nPerdida validación: 2.6306875497102737\nExactitud validación: 17.8348\nÉpoca 772\nPerdida entrenamiento: 0.15547319151022854\nPerdida validación: 2.6264542788267136\nExactitud validación: 18.2870\nÉpoca 773\nPerdida entrenamiento: 0.1503035711014972\nPerdida validación: 2.7056295573711395\nExactitud validación: 18.4000\nÉpoca 774\nPerdida entrenamiento: 0.15113376037162893\nPerdida validación: 3.1897840797901154\nExactitud validación: 18.2870\nÉpoca 775\nPerdida entrenamiento: 0.15134701746351578\nPerdida validación: 2.728394031524658\nExactitud validación: 18.4000\nÉpoca 776\nPerdida entrenamiento: 0.1525684919427423\nPerdida validación: 2.6042723059654236\nExactitud validación: 18.1739\nÉpoca 777\nPerdida entrenamiento: 0.1504207696108257\nPerdida validación: 2.600286602973938\nExactitud validación: 18.0609\nÉpoca 778\nPerdida entrenamiento: 0.14879275551613638\nPerdida validación: 3.278126984834671\nExactitud validación: 18.6261\nÉpoca 779\nPerdida entrenamiento: 0.1492233626982745\nPerdida validación: 3.162637710571289\nExactitud validación: 17.9478\nÉpoca 780\nPerdida entrenamiento: 0.15052652950672543\nPerdida validación: 3.2997718304395676\nExactitud validación: 18.5130\nÉpoca 781\nPerdida entrenamiento: 0.1493004634976387\nPerdida validación: 2.6290631741285324\nExactitud validación: 18.4000\nÉpoca 782\nPerdida entrenamiento: 0.15232405197971008\nPerdida validación: 2.6413462162017822\nExactitud validación: 18.1739\nÉpoca 783\nPerdida entrenamiento: 0.149240040603806\nPerdida validación: 3.256709098815918\nExactitud validación: 18.6261\nÉpoca 784\nPerdida entrenamiento: 0.15085110112148173\nPerdida validación: 3.1722599267959595\nExactitud validación: 18.4000\nÉpoca 785\nPerdida entrenamiento: 0.151833686101086\nPerdida validación: 2.7989502251148224\nExactitud validación: 18.6261\nÉpoca 786\nPerdida entrenamiento: 0.1522596204543815\nPerdida validación: 3.242053836584091\nExactitud validación: 18.2870\nÉpoca 787\nPerdida entrenamiento: 0.14921585799140089\nPerdida validación: 2.6283081024885178\nExactitud validación: 18.0609\nÉpoca 788\nPerdida entrenamiento: 0.14916231044951608\nPerdida validación: 2.6112345829606056\nExactitud validación: 18.5130\nÉpoca 789\nPerdida entrenamiento: 0.14993023477932987\nPerdida validación: 2.7713897675275803\nExactitud validación: 18.5130\nÉpoca 790\nPerdida entrenamiento: 0.14652396913836985\nPerdida validación: 2.666732057929039\nExactitud validación: 18.2870\nÉpoca 791\nPerdida entrenamiento: 0.14829734318396626\nPerdida validación: 2.7664362490177155\nExactitud validación: 18.5130\nÉpoca 792\nPerdida entrenamiento: 0.14896368410657435\nPerdida validación: 2.713522434234619\nExactitud validación: 18.1739\nÉpoca 793\nPerdida entrenamiento: 0.1503126388963531\nPerdida validación: 2.7845799028873444\nExactitud validación: 18.4000\nÉpoca 794\nPerdida entrenamiento: 0.1479355679715381\nPerdida validación: 3.245860606431961\nExactitud validación: 18.2870\nÉpoca 795\nPerdida entrenamiento: 0.14547785524936283\nPerdida validación: 3.1711438596248627\nExactitud validación: 17.9478\nÉpoca 796\nPerdida entrenamiento: 0.14639997482299805\nPerdida validación: 2.6832973659038544\nExactitud validación: 18.0609\nÉpoca 797\nPerdida entrenamiento: 0.14787339857395956\nPerdida validación: 3.2161754816770554\nExactitud validación: 18.8522\nÉpoca 798\nPerdida entrenamiento: 0.14859987883006825\nPerdida validación: 2.6865431666374207\nExactitud validación: 18.4000\nÉpoca 799\nPerdida entrenamiento: 0.1477495445048108\nPerdida validación: 2.63492251932621\nExactitud validación: 18.2870\nÉpoca 800\nPerdida entrenamiento: 0.14877094437970834\nPerdida validación: 2.6738118827342987\nExactitud validación: 18.1739\nÉpoca 801\nPerdida entrenamiento: 0.1459410251939998\nPerdida validación: 2.6356877088546753\nExactitud validación: 18.2870\nÉpoca 802\nPerdida entrenamiento: 0.14662704945487134\nPerdida validación: 2.6701188534498215\nExactitud validación: 18.0609\nÉpoca 803\nPerdida entrenamiento: 0.14530917300897486\nPerdida validación: 2.6025548111647367\nExactitud validación: 18.0609\nÉpoca 804\nPerdida entrenamiento: 0.14726974793216763\nPerdida validación: 2.7442044615745544\nExactitud validación: 18.6261\nÉpoca 805\nPerdida entrenamiento: 0.14796733768547282\nPerdida validación: 2.7691594064235687\nExactitud validación: 18.4000\nÉpoca 806\nPerdida entrenamiento: 0.144820795777966\nPerdida validación: 2.7950679063796997\nExactitud validación: 18.1739\nÉpoca 807\nPerdida entrenamiento: 0.1451437639839509\nPerdida validación: 2.794357866048813\nExactitud validación: 18.4000\nÉpoca 808\nPerdida entrenamiento: 0.14519775439711177\nPerdida validación: 3.242251545190811\nExactitud validación: 18.5130\nÉpoca 809\nPerdida entrenamiento: 0.14527228825232563\nPerdida validación: 3.215233623981476\nExactitud validación: 18.4000\nÉpoca 810\nPerdida entrenamiento: 0.14561747715753667\nPerdida validación: 2.7339600920677185\nExactitud validación: 18.1739\nÉpoca 811\nPerdida entrenamiento: 0.1456113238545025\nPerdida validación: 2.7056923508644104\nExactitud validación: 18.6261\nÉpoca 812\nPerdida entrenamiento: 0.14788693189620972\nPerdida validación: 2.826267398893833\nExactitud validación: 18.6261\nÉpoca 813\nPerdida entrenamiento: 0.14552707049776525\nPerdida validación: 2.6988613605499268\nExactitud validación: 18.2870\nÉpoca 814\nPerdida entrenamiento: 0.14622166621334412\nPerdida validación: 2.7413794100284576\nExactitud validación: 18.6261\nÉpoca 815\nPerdida entrenamiento: 0.143801851745914\nPerdida validación: 2.6483813747763634\nExactitud validación: 18.6261\nÉpoca 816\nPerdida entrenamiento: 0.14336932428619442\nPerdida validación: 2.7818442583084106\nExactitud validación: 18.7391\nÉpoca 817\nPerdida entrenamiento: 0.14512714743614197\nPerdida validación: 3.2018503546714783\nExactitud validación: 18.1739\nÉpoca 818\nPerdida entrenamiento: 0.14359367025249145\nPerdida validación: 3.8155419528484344\nExactitud validación: 18.4000\nÉpoca 819\nPerdida entrenamiento: 0.14185754341237686\nPerdida validación: 2.6466083750128746\nExactitud validación: 18.7391\nÉpoca 820\nPerdida entrenamiento: 0.14415400869706096\nPerdida validación: 2.8113376051187515\nExactitud validación: 18.7391\nÉpoca 821\nPerdida entrenamiento: 0.14479920443366556\nPerdida validación: 2.733074575662613\nExactitud validación: 18.2870\nÉpoca 822\nPerdida entrenamiento: 0.14300062858006535\nPerdida validación: 2.66407323628664\nExactitud validación: 17.9478\nÉpoca 823\nPerdida entrenamiento: 0.14438624636215322\nPerdida validación: 2.725124940276146\nExactitud validación: 18.6261\nÉpoca 824\nPerdida entrenamiento: 0.14179060323273435\nPerdida validación: 3.7919468730688095\nExactitud validación: 18.7391\nÉpoca 825\nPerdida entrenamiento: 0.14401953755056157\nPerdida validación: 2.940170705318451\nExactitud validación: 18.8522\nÉpoca 826\nPerdida entrenamiento: 0.14078793148784077\nPerdida validación: 2.730820268392563\nExactitud validación: 18.6261\nÉpoca 827\nPerdida entrenamiento: 0.14310375184697263\nPerdida validación: 2.7902650237083435\nExactitud validación: 18.8522\nÉpoca 828\nPerdida entrenamiento: 0.1415631906951175\nPerdida validación: 2.798295736312866\nExactitud validación: 18.5130\nÉpoca 829\nPerdida entrenamiento: 0.1424680740079459\nPerdida validación: 2.751399964094162\nExactitud validación: 18.4000\nÉpoca 830\nPerdida entrenamiento: 0.1435266877798473\nPerdida validación: 2.73421211540699\nExactitud validación: 18.1739\nÉpoca 831\nPerdida entrenamiento: 0.14105699036051245\nPerdida validación: 2.752659022808075\nExactitud validación: 18.1739\nÉpoca 832\nPerdida entrenamiento: 0.1436002629206461\nPerdida validación: 2.6599045991897583\nExactitud validación: 18.5130\nÉpoca 833\nPerdida entrenamiento: 0.14401213079690933\nPerdida validación: 2.719948261976242\nExactitud validación: 18.2870\nÉpoca 834\nPerdida entrenamiento: 0.14162796144099796\nPerdida validación: 3.2921559512615204\nExactitud validación: 18.2870\nÉpoca 835\nPerdida entrenamiento: 0.14128982319551356\nPerdida validación: 2.6709438040852547\nExactitud validación: 18.4000\nÉpoca 836\nPerdida entrenamiento: 0.14059947935097358\nPerdida validación: 2.7341255843639374\nExactitud validación: 18.4000\nÉpoca 837\nPerdida entrenamiento: 0.1398994068012518\nPerdida validación: 2.786491632461548\nExactitud validación: 18.5130\nÉpoca 838\nPerdida entrenamiento: 0.14133495618315303\nPerdida validación: 2.690669760107994\nExactitud validación: 18.2870\nÉpoca 839\nPerdida entrenamiento: 0.1424069856019581\nPerdida validación: 3.295660972595215\nExactitud validación: 18.4000\nÉpoca 840\nPerdida entrenamiento: 0.1393086116980104\nPerdida validación: 2.660525068640709\nExactitud validación: 18.5130\nÉpoca 841\nPerdida entrenamiento: 0.14105064158930497\nPerdida validación: 2.737117111682892\nExactitud validación: 18.4000\nÉpoca 842\nPerdida entrenamiento: 0.13984821671072176\nPerdida validación: 2.802027255296707\nExactitud validación: 18.5130\nÉpoca 843\nPerdida entrenamiento: 0.14101365844116492\nPerdida validación: 2.8786006718873978\nExactitud validación: 18.6261\nÉpoca 844\nPerdida entrenamiento: 0.14051969480865142\nPerdida validación: 2.7385316342115402\nExactitud validación: 18.6261\nÉpoca 845\nPerdida entrenamiento: 0.14059160868911183\nPerdida validación: 3.7438178658485413\nExactitud validación: 18.4000\nÉpoca 846\nPerdida entrenamiento: 0.1408574015778654\nPerdida validación: 3.268863081932068\nExactitud validación: 18.2870\nÉpoca 847\nPerdida entrenamiento: 0.14002320258056417\nPerdida validación: 3.4570556730031967\nExactitud validación: 18.5130\nÉpoca 848\nPerdida entrenamiento: 0.14203892955008676\nPerdida validación: 2.8030443489551544\nExactitud validación: 18.4000\nÉpoca 849\nPerdida entrenamiento: 0.14011239435742884\nPerdida validación: 2.820237874984741\nExactitud validación: 18.2870\nÉpoca 850\nPerdida entrenamiento: 0.1396850124001503\nPerdida validación: 3.243169218301773\nExactitud validación: 18.5130\nÉpoca 851\nPerdida entrenamiento: 0.13872243946089463\nPerdida validación: 2.7179784178733826\nExactitud validación: 18.5130\nÉpoca 852\nPerdida entrenamiento: 0.13912279465619257\nPerdida validación: 2.7133824974298477\nExactitud validación: 18.1739\nÉpoca 853\nPerdida entrenamiento: 0.13690624988692648\nPerdida validación: 2.8744891583919525\nExactitud validación: 18.1739\nÉpoca 854\nPerdida entrenamiento: 0.1364170865100973\nPerdida validación: 2.780077964067459\nExactitud validación: 18.4000\nÉpoca 855\nPerdida entrenamiento: 0.13848148680785122\nPerdida validación: 2.732403054833412\nExactitud validación: 18.4000\nÉpoca 856\nPerdida entrenamiento: 0.13774363828056\nPerdida validación: 2.748747408390045\nExactitud validación: 18.1739\nÉpoca 857\nPerdida entrenamiento: 0.13970747677718892\nPerdida validación: 2.7384248077869415\nExactitud validación: 18.7391\nÉpoca 858\nPerdida entrenamiento: 0.13931907012182124\nPerdida validación: 2.7981139421463013\nExactitud validación: 18.5130\nÉpoca 859\nPerdida entrenamiento: 0.13711956625475602\nPerdida validación: 2.746776044368744\nExactitud validación: 18.4000\nÉpoca 860\nPerdida entrenamiento: 0.14136996602310853\nPerdida validación: 2.961911305785179\nExactitud validación: 18.8522\nÉpoca 861\nPerdida entrenamiento: 0.1371486279017785\nPerdida validación: 2.920855939388275\nExactitud validación: 18.9652\nÉpoca 862\nPerdida entrenamiento: 0.1369148339418804\nPerdida validación: 3.3346258997917175\nExactitud validación: 17.9478\nÉpoca 863\nPerdida entrenamiento: 0.1381302679724553\nPerdida validación: 2.696602389216423\nExactitud validación: 18.1739\nÉpoca 864\nPerdida entrenamiento: 0.13654666306341395\nPerdida validación: 2.7097426876425743\nExactitud validación: 18.5130\nÉpoca 865\nPerdida entrenamiento: 0.1373768339262289\nPerdida validación: 2.822031795978546\nExactitud validación: 17.8348\nÉpoca 866\nPerdida entrenamiento: 0.1341216191649437\nPerdida validación: 2.705332897603512\nExactitud validación: 18.1739\nÉpoca 867\nPerdida entrenamiento: 0.1376872159102384\nPerdida validación: 2.7694733440876007\nExactitud validación: 18.0609\nÉpoca 868\nPerdida entrenamiento: 0.13436881759587457\nPerdida validación: 2.782355934381485\nExactitud validación: 18.6261\nÉpoca 869\nPerdida entrenamiento: 0.13662084586480083\nPerdida validación: 2.75421804189682\nExactitud validación: 18.1739\nÉpoca 870\nPerdida entrenamiento: 0.1360327185076826\nPerdida validación: 2.8113476634025574\nExactitud validación: 18.7391\nÉpoca 871\nPerdida entrenamiento: 0.13782303298220916\nPerdida validación: 2.779130682349205\nExactitud validación: 18.5130\nÉpoca 872\nPerdida entrenamiento: 0.13344334416529713\nPerdida validación: 2.784419059753418\nExactitud validación: 18.2870\nÉpoca 873\nPerdida entrenamiento: 0.13555954462465117\nPerdida validación: 2.7529250234365463\nExactitud validación: 18.2870\nÉpoca 874\nPerdida entrenamiento: 0.1355480694157236\nPerdida validación: 3.300339162349701\nExactitud validación: 18.4000\nÉpoca 875\nPerdida entrenamiento: 0.13865461638745138\nPerdida validación: 2.9780090004205704\nExactitud validación: 18.7391\nÉpoca 876\nPerdida entrenamiento: 0.1376051098546561\nPerdida validación: 2.8903158009052277\nExactitud validación: 18.2870\nÉpoca 877\nPerdida entrenamiento: 0.13494748030515277\nPerdida validación: 2.7917942702770233\nExactitud validación: 18.6261\nÉpoca 878\nPerdida entrenamiento: 0.1352824815275038\nPerdida validación: 3.3168766498565674\nExactitud validación: 18.6261\nÉpoca 879\nPerdida entrenamiento: 0.1324736436500269\nPerdida validación: 2.7636314928531647\nExactitud validación: 18.4000\nÉpoca 880\nPerdida entrenamiento: 0.13348486493615544\nPerdida validación: 2.871694028377533\nExactitud validación: 18.5130\nÉpoca 881\nPerdida entrenamiento: 0.13614112927633173\nPerdida validación: 2.82409131526947\nExactitud validación: 18.7391\nÉpoca 882\nPerdida entrenamiento: 0.13355802678886583\nPerdida validación: 2.7636439353227615\nExactitud validación: 18.4000\nÉpoca 883\nPerdida entrenamiento: 0.1327956191757146\nPerdida validación: 2.812580853700638\nExactitud validación: 18.1739\nÉpoca 884\nPerdida entrenamiento: 0.13378482684493065\nPerdida validación: 2.7658906280994415\nExactitud validación: 18.2870\nÉpoca 885\nPerdida entrenamiento: 0.1324151684256161\nPerdida validación: 2.857463538646698\nExactitud validación: 18.4000\nÉpoca 886\nPerdida entrenamiento: 0.1337796228335184\nPerdida validación: 3.4032358527183533\nExactitud validación: 18.4000\nÉpoca 887\nPerdida entrenamiento: 0.13265221697442672\nPerdida validación: 3.3464408963918686\nExactitud validación: 18.2870\nÉpoca 888\nPerdida entrenamiento: 0.13283191577476613\nPerdida validación: 2.790514573454857\nExactitud validación: 18.5130\nÉpoca 889\nPerdida entrenamiento: 0.13208355623133042\nPerdida validación: 2.8009232729673386\nExactitud validación: 18.5130\nÉpoca 890\nPerdida entrenamiento: 0.13509997550178976\nPerdida validación: 2.8039220198988914\nExactitud validación: 18.5130\nÉpoca 891\nPerdida entrenamiento: 0.13466739829848795\nPerdida validación: 2.90687495470047\nExactitud validación: 18.2870\nÉpoca 892\nPerdida entrenamiento: 0.1318563308347674\nPerdida validación: 2.8616604059934616\nExactitud validación: 18.6261\nÉpoca 893\nPerdida entrenamiento: 0.13101407315801172\nPerdida validación: 2.96872079372406\nExactitud validación: 18.6261\nÉpoca 894\nPerdida entrenamiento: 0.13524135245996363\nPerdida validación: 2.829436719417572\nExactitud validación: 18.5130\nÉpoca 895\nPerdida entrenamiento: 0.13446547616930568\nPerdida validación: 2.8921854197978973\nExactitud validación: 18.4000\nÉpoca 896\nPerdida entrenamiento: 0.13377005256274166\nPerdida validación: 2.9073114544153214\nExactitud validación: 18.5130\nÉpoca 897\nPerdida entrenamiento: 0.13366495949380539\nPerdida validación: 2.869605004787445\nExactitud validación: 18.4000\nÉpoca 898\nPerdida entrenamiento: 0.13367976116783478\nPerdida validación: 2.8357715904712677\nExactitud validación: 18.2870\nÉpoca 899\nPerdida entrenamiento: 0.13272172037292929\nPerdida validación: 3.323453515768051\nExactitud validación: 18.2870\nÉpoca 900\nPerdida entrenamiento: 0.132703357759644\nPerdida validación: 2.9263442158699036\nExactitud validación: 18.6261\nÉpoca 901\nPerdida entrenamiento: 0.13167799373759942\nPerdida validación: 3.4298669397830963\nExactitud validación: 18.0609\nÉpoca 902\nPerdida entrenamiento: 0.1339989497381098\nPerdida validación: 2.8030209839344025\nExactitud validación: 18.2870\nÉpoca 903\nPerdida entrenamiento: 0.1287992243819377\nPerdida validación: 2.8654688000679016\nExactitud validación: 18.7391\nÉpoca 904\nPerdida entrenamiento: 0.13100341444506364\nPerdida validación: 3.4879584312438965\nExactitud validación: 18.4000\nÉpoca 905\nPerdida entrenamiento: 0.1310742236673832\nPerdida validación: 2.7952137142419815\nExactitud validación: 18.2870\nÉpoca 906\nPerdida entrenamiento: 0.12950651961214402\nPerdida validación: 2.8933157920837402\nExactitud validación: 18.5130\nÉpoca 907\nPerdida entrenamiento: 0.12948743275859775\nPerdida validación: 2.920369252562523\nExactitud validación: 18.9652\nÉpoca 908\nPerdida entrenamiento: 0.12981591811951468\nPerdida validación: 2.874404937028885\nExactitud validación: 18.2870\nÉpoca 909\nPerdida entrenamiento: 0.1289715587216265\nPerdida validación: 3.2992987632751465\nExactitud validación: 18.7391\nÉpoca 910\nPerdida entrenamiento: 0.1300869676120141\nPerdida validación: 3.415118455886841\nExactitud validación: 18.1739\nÉpoca 911\nPerdida entrenamiento: 0.1314496520687552\nPerdida validación: 2.855779469013214\nExactitud validación: 18.4000\nÉpoca 912\nPerdida entrenamiento: 0.13039520207573385\nPerdida validación: 2.863826960325241\nExactitud validación: 18.2870\nÉpoca 913\nPerdida entrenamiento: 0.12854845580809257\nPerdida validación: 3.4703205823898315\nExactitud validación: 18.5130\nÉpoca 914\nPerdida entrenamiento: 0.1311737588223289\nPerdida validación: 2.8276840299367905\nExactitud validación: 18.1739\nÉpoca 915\nPerdida entrenamiento: 0.12898599926163168\nPerdida validación: 2.808225929737091\nExactitud validación: 18.2870\nÉpoca 916\nPerdida entrenamiento: 0.12826384625890674\nPerdida validación: 2.954753652215004\nExactitud validación: 18.0609\nÉpoca 917\nPerdida entrenamiento: 0.1291312752839397\nPerdida validación: 3.455663487315178\nExactitud validación: 18.2870\nÉpoca 918\nPerdida entrenamiento: 0.1272546608439263\nPerdida validación: 2.840626373887062\nExactitud validación: 18.6261\nÉpoca 919\nPerdida entrenamiento: 0.12807583589764202\nPerdida validación: 2.908486932516098\nExactitud validación: 18.7391\nÉpoca 920\nPerdida entrenamiento: 0.12984531920622377\nPerdida validación: 2.949549823999405\nExactitud validación: 18.1739\nÉpoca 921\nPerdida entrenamiento: 0.12714826140333624\nPerdida validación: 2.9026261270046234\nExactitud validación: 18.0609\nÉpoca 922\nPerdida entrenamiento: 0.12683334858978496\nPerdida validación: 3.4384027123451233\nExactitud validación: 18.4000\nÉpoca 923\nPerdida entrenamiento: 0.12668604359907262\nPerdida validación: 3.4019243717193604\nExactitud validación: 17.9478\nÉpoca 924\nPerdida entrenamiento: 0.1273968097041635\nPerdida validación: 3.4543668031692505\nExactitud validación: 18.0609\nÉpoca 925\nPerdida entrenamiento: 0.1270380519768771\nPerdida validación: 2.9080685824155807\nExactitud validación: 18.4000\nÉpoca 926\nPerdida entrenamiento: 0.12678182059351137\nPerdida validación: 2.854278191924095\nExactitud validación: 18.6261\nÉpoca 927\nPerdida entrenamiento: 0.1272417313474066\nPerdida validación: 3.409367948770523\nExactitud validación: 18.5130\nÉpoca 928\nPerdida entrenamiento: 0.12685667372801723\nPerdida validación: 4.08304163813591\nExactitud validación: 18.4000\nÉpoca 929\nPerdida entrenamiento: 0.12677246003466494\nPerdida validación: 2.8712600469589233\nExactitud validación: 18.4000\nÉpoca 930\nPerdida entrenamiento: 0.12664389434982748\nPerdida validación: 2.9682075679302216\nExactitud validación: 18.5130\nÉpoca 931\nPerdida entrenamiento: 0.12917877909015207\nPerdida validación: 2.8417866826057434\nExactitud validación: 18.1739\nÉpoca 932\nPerdida entrenamiento: 0.12731395530350068\nPerdida validación: 2.898645430803299\nExactitud validación: 18.4000\nÉpoca 933\nPerdida entrenamiento: 0.12507441157803817\nPerdida validación: 2.914635419845581\nExactitud validación: 18.5130\nÉpoca 934\nPerdida entrenamiento: 0.12594195674447453\nPerdida validación: 2.912827104330063\nExactitud validación: 18.4000\nÉpoca 935\nPerdida entrenamiento: 0.1251837317557896\nPerdida validación: 3.5243859738111496\nExactitud validación: 18.4000\nÉpoca 936\nPerdida entrenamiento: 0.12473153717377607\nPerdida validación: 2.9899864494800568\nExactitud validación: 18.6261\nÉpoca 937\nPerdida entrenamiento: 0.12627896666526794\nPerdida validación: 2.940245568752289\nExactitud validación: 17.9478\nÉpoca 938\nPerdida entrenamiento: 0.12539050552774877\nPerdida validación: 3.506003439426422\nExactitud validación: 18.6261\nÉpoca 939\nPerdida entrenamiento: 0.12461071943535525\nPerdida validación: 2.9693265557289124\nExactitud validación: 18.8522\nÉpoca 940\nPerdida entrenamiento: 0.12703695104402654\nPerdida validación: 3.0138815343379974\nExactitud validación: 18.6261\nÉpoca 941\nPerdida entrenamiento: 0.12593218640369527\nPerdida validación: 3.412371516227722\nExactitud validación: 18.8522\nÉpoca 942\nPerdida entrenamiento: 0.12484191182781668\nPerdida validación: 2.875510886311531\nExactitud validación: 18.4000\nÉpoca 943\nPerdida entrenamiento: 0.12549839157830267\nPerdida validación: 3.0640504956245422\nExactitud validación: 18.2870\nÉpoca 944\nPerdida entrenamiento: 0.1243065052172717\nPerdida validación: 3.010021924972534\nExactitud validación: 18.5130\nÉpoca 945\nPerdida entrenamiento: 0.12402418606421527\nPerdida validación: 2.888392746448517\nExactitud validación: 18.6261\nÉpoca 946\nPerdida entrenamiento: 0.12377885378458921\nPerdida validación: 2.8283270969986916\nExactitud validación: 18.1739\nÉpoca 947\nPerdida entrenamiento: 0.12332157023689326\nPerdida validación: 3.4357332587242126\nExactitud validación: 18.1739\nÉpoca 948\nPerdida entrenamiento: 0.12415540525141884\nPerdida validación: 2.9335389137268066\nExactitud validación: 18.7391\nÉpoca 949\nPerdida entrenamiento: 0.12486725640209283\nPerdida validación: 2.931018203496933\nExactitud validación: 18.6261\nÉpoca 950\nPerdida entrenamiento: 0.12408434424330206\nPerdida validación: 3.054698035120964\nExactitud validación: 18.6261\nÉpoca 951\nPerdida entrenamiento: 0.12574190032832763\nPerdida validación: 3.0038841366767883\nExactitud validación: 18.2870\nÉpoca 952\nPerdida entrenamiento: 0.12242736294865608\nPerdida validación: 4.074982047080994\nExactitud validación: 18.4000\nÉpoca 953\nPerdida entrenamiento: 0.12435674601617981\nPerdida validación: 2.973332405090332\nExactitud validación: 18.5130\nÉpoca 954\nPerdida entrenamiento: 0.12533021915484877\nPerdida validación: 3.4903931617736816\nExactitud validación: 18.5130\nÉpoca 955\nPerdida entrenamiento: 0.12362913436749402\nPerdida validación: 2.894077181816101\nExactitud validación: 18.0609\nÉpoca 956\nPerdida entrenamiento: 0.1241259554072338\nPerdida validación: 3.5641388595104218\nExactitud validación: 18.8522\nÉpoca 957\nPerdida entrenamiento: 0.12326250049997778\nPerdida validación: 2.894750624895096\nExactitud validación: 18.7391\nÉpoca 958\nPerdida entrenamiento: 0.12201590529259514\nPerdida validación: 3.554157704114914\nExactitud validación: 18.7391\nÉpoca 959\nPerdida entrenamiento: 0.12234444193103734\nPerdida validación: 3.0658498108386993\nExactitud validación: 18.7391\nÉpoca 960\nPerdida entrenamiento: 0.1225890420815524\nPerdida validación: 2.9639132916927338\nExactitud validación: 18.2870\nÉpoca 961\nPerdida entrenamiento: 0.12655563323813326\nPerdida validación: 3.4610494822263718\nExactitud validación: 18.2870\nÉpoca 962\nPerdida entrenamiento: 0.12557828514014974\nPerdida validación: 3.0472725331783295\nExactitud validación: 18.7391\nÉpoca 963\nPerdida entrenamiento: 0.12406371117514722\nPerdida validación: 3.4296689927577972\nExactitud validación: 18.5130\nÉpoca 964\nPerdida entrenamiento: 0.12306797109982547\nPerdida validación: 2.8831294775009155\nExactitud validación: 18.6261\nÉpoca 965\nPerdida entrenamiento: 0.12154533823623377\nPerdida validación: 3.0393559336662292\nExactitud validación: 18.0609\nÉpoca 966\nPerdida entrenamiento: 0.12231333071694654\nPerdida validación: 2.893571987748146\nExactitud validación: 18.2870\nÉpoca 967\nPerdida entrenamiento: 0.12442432300132863\nPerdida validación: 2.8784404695034027\nExactitud validación: 18.8522\nÉpoca 968\nPerdida entrenamiento: 0.12219117998200305\nPerdida validación: 3.0569884181022644\nExactitud validación: 18.5130\nÉpoca 969\nPerdida entrenamiento: 0.1204835956587511\nPerdida validación: 3.0531783998012543\nExactitud validación: 18.1739\nÉpoca 970\nPerdida entrenamiento: 0.12147321595865138\nPerdida validación: 3.105465844273567\nExactitud validación: 18.5130\nÉpoca 971\nPerdida entrenamiento: 0.11965199538013514\nPerdida validación: 2.9067180305719376\nExactitud validación: 18.2870\nÉpoca 972\nPerdida entrenamiento: 0.1203617955393651\nPerdida validación: 2.853972941637039\nExactitud validación: 18.2870\nÉpoca 973\nPerdida entrenamiento: 0.12197020540342611\nPerdida validación: 2.951186329126358\nExactitud validación: 18.6261\nÉpoca 974\nPerdida entrenamiento: 0.12436810749418595\nPerdida validación: 3.067672148346901\nExactitud validación: 18.6261\nÉpoca 975\nPerdida entrenamiento: 0.12134960271856364\nPerdida validación: 3.5442528426647186\nExactitud validación: 18.2870\nÉpoca 976\nPerdida entrenamiento: 0.1222062270869227\nPerdida validación: 3.071064904332161\nExactitud validación: 18.7391\nÉpoca 977\nPerdida entrenamiento: 0.12381410642581828\nPerdida validación: 2.9515878558158875\nExactitud validación: 18.1739\nÉpoca 978\nPerdida entrenamiento: 0.11919486478847616\nPerdida validación: 2.987251326441765\nExactitud validación: 18.8522\nÉpoca 979\nPerdida entrenamiento: 0.12118908982066547\nPerdida validación: 2.964499592781067\nExactitud validación: 18.2870\nÉpoca 980\nPerdida entrenamiento: 0.11982706517857664\nPerdida validación: 2.884852759540081\nExactitud validación: 18.2870\nÉpoca 981\nPerdida entrenamiento: 0.12243366482503273\nPerdida validación: 2.9526966214179993\nExactitud validación: 18.5130\nÉpoca 982\nPerdida entrenamiento: 0.12023616615025436\nPerdida validación: 2.892222762107849\nExactitud validación: 18.5130\nÉpoca 983\nPerdida entrenamiento: 0.11949533388456877\nPerdida validación: 3.0738677978515625\nExactitud validación: 18.5130\nÉpoca 984\nPerdida entrenamiento: 0.11815058308489182\nPerdida validación: 2.943865194916725\nExactitud validación: 18.1739\nÉpoca 985\nPerdida entrenamiento: 0.12010063581606921\nPerdida validación: 3.0461696088314056\nExactitud validación: 18.2870\nÉpoca 986\nPerdida entrenamiento: 0.1200608185985509\nPerdida validación: 4.0663831532001495\nExactitud validación: 18.4000\nÉpoca 987\nPerdida entrenamiento: 0.11974002442815725\nPerdida validación: 3.468088820576668\nExactitud validación: 18.1739\nÉpoca 988\nPerdida entrenamiento: 0.11906973097254248\nPerdida validación: 2.943978175520897\nExactitud validación: 18.0609\nÉpoca 989\nPerdida entrenamiento: 0.12085146150168251\nPerdida validación: 3.0875197649002075\nExactitud validación: 18.4000\nÉpoca 990\nPerdida entrenamiento: 0.11931220442056656\nPerdida validación: 3.4530164301395416\nExactitud validación: 18.2870\nÉpoca 991\nPerdida entrenamiento: 0.1200842373073101\nPerdida validación: 3.108154445886612\nExactitud validación: 18.4000\nÉpoca 992\nPerdida entrenamiento: 0.11944863528889768\nPerdida validación: 3.4121116399765015\nExactitud validación: 18.2870\nÉpoca 993\nPerdida entrenamiento: 0.11968237862867467\nPerdida validación: 2.9360441118478775\nExactitud validación: 18.2870\nÉpoca 994\nPerdida entrenamiento: 0.11799231237348388\nPerdida validación: 3.036650687456131\nExactitud validación: 18.4000\nÉpoca 995\nPerdida entrenamiento: 0.11872703187605914\nPerdida validación: 2.939451888203621\nExactitud validación: 18.4000\nÉpoca 996\nPerdida entrenamiento: 0.1186886644538711\nPerdida validación: 3.0029216408729553\nExactitud validación: 18.4000\nÉpoca 997\nPerdida entrenamiento: 0.11697329558870372\nPerdida validación: 2.912400111556053\nExactitud validación: 18.1739\nÉpoca 998\nPerdida entrenamiento: 0.11653838547713616\nPerdida validación: 3.0047235190868378\nExactitud validación: 18.1739\nÉpoca 999\nPerdida entrenamiento: 0.11792571338660576\nPerdida validación: 4.158627465367317\nExactitud validación: 18.5130\nÉpoca 1000\nPerdida entrenamiento: 0.11670456804773387\nPerdida validación: 2.9439720809459686\nExactitud validación: 18.1739"
  },
  {
    "objectID": "codigo/ASIM/cod004_sol_NeuralNetwork.html#eval-model",
    "href": "codigo/ASIM/cod004_sol_NeuralNetwork.html#eval-model",
    "title": "Predict the onset of diabetes based on diagnostic measures",
    "section": "Eval Model",
    "text": "Eval Model"
  },
  {
    "objectID": "codigo/SYSB/remuestreo.html",
    "href": "codigo/SYSB/remuestreo.html",
    "title": "Parámetros Iniciales de la señal",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\\[x\\left(t\\right) = 10\\sin\\left(2\\pi3t\\right)\\]\n\\[t\\in\\left[0, 5\\right]\\]\n\\[f_{s_1} = 20Hz\\]\n\\[f_{s_2} = 100Hz\\]\nt0 = 0\ntf = 1"
  },
  {
    "objectID": "codigo/SYSB/remuestreo.html#gráficas-iniciales",
    "href": "codigo/SYSB/remuestreo.html#gráficas-iniciales",
    "title": "Parámetros Iniciales de la señal",
    "section": "Gráficas iniciales",
    "text": "Gráficas iniciales\n\nt_graph = np.linspace(t0, tf, 1000)\nx = 10*np.sin(2*np.pi*3*t_graph)\nplt.figure(figsize=(10,6))\nplt.plot(t_graph, x)\n\n\n\n\n\n\n\n\n\nfs1 = 20\nt_1 = np.linspace(t0, tf, fs1*(tf-t0), endpoint=False)\nx_1 = 10 * np.sin(2 * np.pi * 3 * t_1)\nplt.figure(figsize=(10, 6))\nplt.plot(t_graph, x)\nplt.plot(t_1, x_1, 'r*')\nplt.grid()\n\n\n\n\n\n\n\n\n\nt_oversample = [t0]\nx_1_over = [x_1[0]]\n\ndelta_t1 = np.mean(np.diff(t_1))\n\nt_oversample = np.empty(len(t_1)+len(t_1))\nt_oversample[0::2] = t_1\nt_oversample[1::2] = t_1 + (delta_t1/2)\n\nx_1_over = np.empty(len(t_1) + len(t_1))\nx_1_over[0::2] = x_1\nx_1_over[1::2] = (x_1+np.roll(x_1,-1))/2\n\nplt.figure(figsize=(10, 6))\nplt.plot(t_graph, x, \"k\")\nplt.plot(t_oversample, x_1_over, \"g*\")\nplt.plot(t_1, x_1, \"r*\")\nplt.grid()\n\n\n\n\n\n\n\n\n\n4//2\n\n2\n\n\n\n4%3\n\n1"
  },
  {
    "objectID": "codigo/preparing_slides.html",
    "href": "codigo/preparing_slides.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport pywt\nimport matplotlib.pyplot as plt\nimport imageio\nfrom scipy import signal\n\nplt.rcParams.update(\n    {\n        \"text.usetex\": True,  # usar LaTeX real\n        \"font.family\": \"Fira Code\",       # familia general\n        \"mathtext.fontset\": \"custom\",     # fuente personalizada para fórmulas\n        \"mathtext.rm\": \"Fira Code\",       # texto “roman”\n        \"mathtext.it\": \"Fira Code:italic\",# texto itálico\n        \"mathtext.bf\": \"Fira Code:bold\",   # texto en negrita\n        \"text.latex.preamble\": r\"\\usepackage{amsmath}\",\n    }\n)\n\n# Time vector\nt = np.linspace(-3, 3, 500)\n\n# Define the original function and its components\nf_t = np.exp(t)  # Original function: e^t\nf_even = (np.exp(t) + np.exp(-t)) / 2  # Even part: cosh(t)\nf_odd = (np.exp(t) - np.exp(-t)) / 2  # Odd part: sinh(t)\n\n# Create the subplots\nfig, axs = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n\n# Plot the original function\naxs[0].plot(t, f_t, label=r\"$f(t) = e^t$\", color=\"blue\", linewidth=2)\naxs[0].set_title(\"Original Function\", fontsize=14)\naxs[0].set_ylabel(\"Amplitude\", fontsize=12)\naxs[0].legend(fontsize=12)\naxs[0].grid(True)\n\n# Plot the even part\naxs[1].plot(\n    t, f_even, label=r\"$f_{\\text{even}}(t) = \\cosh(t)$\", color=\"green\", linewidth=2\n)\naxs[1].set_title(\"Even Part of the Function\", fontsize=14)\naxs[1].set_ylabel(\"Amplitude\", fontsize=12)\naxs[1].legend(fontsize=12)\naxs[1].grid(True)\n\n# Plot the odd part\naxs[2].plot(t, f_odd, label=r\"$f_{\\text{odd}}(t) = \\sinh(t)$\", color=\"red\", linewidth=2)\naxs[2].set_title(\"Odd Part of the Function\", fontsize=14)\naxs[2].set_xlabel(\"Time (s)\", fontsize=12)\naxs[2].set_ylabel(\"Amplitude\", fontsize=12)\naxs[2].legend(fontsize=12)\naxs[2].grid(True)\n\n# Adjust layout\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time base\nnp.random.seed(7)\nfs = 500  # Hz\nT = 2.0  # s\nt = np.linspace(0, T, int(fs * T), endpoint=False)\n\n# Deterministic signal: sinusoid\nA, f0, phi = 1.0, 5.0, np.pi / 6\nx_det = A * np.cos(2 * np.pi * f0 * t + phi)\n\n# Random signal: zero-mean Gaussian sequence, smoothed to be signal-like\nnoise = np.random.randn(t.size)\nM = 25  # moving-average window length (odd)\nkernel = np.ones(M) / M\nx_rand = np.convolve(noise, kernel, mode=\"same\") * 0.8  # scaled for visibility\n\n# Plot (two panels on a single slide)\nfig, axes = plt.subplots(2, 1, figsize=(9, 5), sharex=True)\n\naxes[0].plot(t, x_det, lw=1.4)\naxes[0].set_title(r\"Deterministic signal: $x_d(t)=A\\cos(2\\pi f_0 t+\\phi)$\")\naxes[0].set_ylabel(\"Amplitude\")\naxes[0].grid(alpha=0.3)\n\naxes[1].plot(t, x_rand, lw=1.2)\naxes[1].set_title(r\"Random signal (one realization): $X(t)$ with $\\mathbb{E}[X(t)]=0$\")\naxes[1].set_xlabel(r\"Time $t$ [s]\")\naxes[1].set_ylabel(\"Amplitude\")\naxes[1].grid(alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html",
    "title": "Estudio de arritmia cardíaca",
    "section": "",
    "text": "#from google.colab import drive\n#drive.mount('/content/drive')"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librerías",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-librerías",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de librerías",
    "text": "Carga de librerías\n\nnumpy: Para manipulación numérica y funciones estadísticas básicas\nmatplotlib.pyplot: Para generación de gráficos.\nscipy.io: Para carga de datos provenientes de archivos .mat\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nimport scipy.signal as sig"
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#configuración-de-carpetas",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#configuración-de-carpetas",
    "title": "Estudio de arritmia cardíaca",
    "section": "Configuración de carpetas",
    "text": "Configuración de carpetas\n\n# data_path = \"/content/drive/MyDrive/ECG_Dataset/\"#Datapath de colab\ndata_path = \"../../data/\""
  },
  {
    "objectID": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "href": "codigo/PSIM/cod002_Fourier_Transform.html#carga-de-datos",
    "title": "Estudio de arritmia cardíaca",
    "section": "Carga de datos",
    "text": "Carga de datos\nArchivo de descarga\n\ndata = sio.loadmat(data_path+\"JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\n\n\nprint(data.keys())\n\ndict_keys(['val'])\n\n\n\nprint(type(data[\"val\"]))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\nprint(data[\"val\"].shape)\n\n(12, 5000)\n\n\n\nlead_10 = data[\"val\"][9, :]\n\n\nt0 = 0\ntf = 10\nt = np.linspace(t0, tf, 5000)\n\n\nfig01 = plt.figure()\nplt.plot(t,lead_10)\n\n\n\n\n\n\n\n\n\necg_fft = np.fft.fft(lead_10)\necg_fft\n\narray([ -50343.             +0.j        ,\n        -44427.87292792 -48118.33430899j,\n        -14003.60280291-331886.8477886j , ...,\n       -134619.87742102 -46991.97629606j,\n        -14003.60280291+331886.8477886j ,\n        -44427.87292792 +48118.33430899j])\n\n\n\nmag_ecg_fft = np.abs(ecg_fft)\nf_vect = np.fft.fftfreq(len(mag_ecg_fft))\n\n\nplt.plot(mag_ecg_fft)\n\n\n\n\n\n\n\n\n\nN = len(mag_ecg_fft)\nf_vect1 = 500*f_vect[:np.uint(N/2)]\nmag_ecg_fft1 = mag_ecg_fft[:np.uint(N/2)]\n\n\nplt.plot(f_vect1, mag_ecg_fft1)\nplt.grid()\n\n\n\n\n\n\n\n\n\nfs =  500\n\nfc1 = 0.5\nfc2 = 50\norder_fir = 51\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import freqz, windows\n\n\n# Definir el vector de frecuencias\nf_vect = np.linspace(-fs//2, fs//2, order_fir)\n\n# Definir la respuesta en frecuencia deseada\nH1 = np.zeros(len(f_vect))\nH1[(((f_vect &gt;= 0.5) & (f_vect &lt;= 50)) | ((f_vect &lt;= -0.5) & (f_vect &gt;= -50)))] =  1  # Banda de paso entre 0.5 y 50 Hz\n\nplt.figure(figsize=(10,6))\nplt.plot(f_vect, H1)\n\n# Normalizar las frecuencias con respecto a Nyquist (fs/2)\nnormalized_frequencies = f_vect / (fs / 2)\n\n# Interpolación de la respuesta deseada\nH_interp = np.interp(np.linspace(0, 1, order_fir), normalized_frequencies, H1)\n\n# Transformada Inversa de Fourier para obtener la respuesta al impulso\nh = np.fft.ifft(H_interp, order_fir).real  # Solo tomamos la parte real\n\n# Aplicar ventana de Hamming\nwindow = windows.hamming(order_fir)\nh_windowed = h * window\n\n# Normalizar la energía del filtro\nh_windowed /= np.sum(h_windowed)\n\n# Calcular la respuesta en frecuencia\nw, H_fir = freqz(h_windowed, worN=2048, fs=fs)\n\n# Graficar la respuesta al impulso\nplt.figure(figsize=(12, 5))\nplt.stem(h_windowed, basefmt=\"C0\")\nplt.title(\"Respuesta al Impulso del Filtro FIR con Especificación en Frecuencia\")\nplt.xlabel(\"n (muestras)\")\nplt.ylabel(\"h[n]\")\nplt.grid()\nplt.show()\n\n# Graficar la respuesta en frecuencia\nplt.figure(figsize=(12, 6))\nplt.subplot(2, 1, 1)\nplt.plot(w, 20 * np.log10(abs(H_fir)), \"b\")\nplt.title(\"Respuesta en Frecuencia - Magnitud\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Magnitud [dB]\")\nplt.grid()\n\nplt.subplot(2, 1, 2)\nplt.plot(w, np.angle(H_fir), \"g\")\nplt.title(\"Respuesta en Frecuencia - Fase\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Fase [radianes]\")\nplt.grid()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import firls, freqz\n\n# Parámetros del filtro\nfs = 500  # Frecuencia de muestreo en Hz\nN = 51  # Número de coeficientes del filtro (impar para centrar en cero)\n\n# Definir las bandas y la respuesta deseada\nbands = [0, 0.5, 50, fs / 2]  # Frecuencias en Hz\ndesired = [0, 10, 10, 0]  # Pasa-banda de 0.5 Hz a 50 Hz\n\n# Diseñar el filtro FIR con firls\nh_firls = firls(N, bands, desired, fs=fs)\n\n# Calcular la respuesta en frecuencia\nw, H_fir = freqz(h_firls, worN=2048, fs=fs)\n\n# Graficar la respuesta al impulso\nplt.figure(figsize=(12, 5))\nplt.stem(h_firls, basefmt=\"C0\")\nplt.title(\"Respuesta al Impulso del Filtro FIR con firls\")\nplt.xlabel(\"n (muestras)\")\nplt.ylabel(\"h[n]\")\nplt.grid()\nplt.show()\n\n# Graficar la respuesta en frecuencia\nplt.figure(figsize=(12, 6))\nplt.subplot(2, 1, 1)\nplt.plot(w, 20 * np.log10(abs(H_fir)), \"b\")\nplt.title(\"Respuesta en Frecuencia - Magnitud\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Magnitud [dB]\")\nplt.grid()\n\nplt.subplot(2, 1, 2)\nplt.plot(w, np.angle(H_fir), \"g\")\nplt.title(\"Respuesta en Frecuencia - Fase\")\nplt.xlabel(\"Frecuencia [Hz]\")\nplt.ylabel(\"Fase [radianes]\")\nplt.grid()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "codigo/PSIM/cod003_FourierImage.html",
    "href": "codigo/PSIM/cod003_FourierImage.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Step 1: Load the Ultrasound Image\nimage = cv2.imread(\n    \"../../data/malignant_breast_cancer.png\", \n    cv2.IMREAD_GRAYSCALE\n)\n\n\nsharpening_kernel1 = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\nsharpening_kernel2 = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n\nsharpened_image1 = cv2.filter2D(image, -1, sharpening_kernel1)\nsharpened_image2 = cv2.filter2D(image, -1, sharpening_kernel2)\n\n\n# Step 4: Display the Original and Sharpened Images Side-by-Side\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 3, 1)\nplt.title(\"Original Ultrasound Image\")\nplt.imshow(image, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 2)\nplt.title(\"Sharpened Ultrasound Image Kernel1\")\nplt.imshow(sharpened_image1, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 3)\nplt.title(\"Sharpened Ultrasound Image Kernel2\")\nplt.imshow(sharpened_image2, cmap=\"gray\")\nplt.axis(\"off\")\n\n\n\n\n\n\n\n\n\ndft1 = cv2.dft(np.float32(image), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift1 = np.fft.fftshift(dft1)\nmagnitude_spectrum1 = 20 * np.log(cv2.magnitude(dft_shift1[:, :, 0], dft_shift1[:, :, 1]))\n\ndft2 = cv2.dft(np.float32(sharpened_image1), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift2 = np.fft.fftshift(dft2)\nmagnitude_spectrum2 = 20 * np.log(\n    cv2.magnitude(dft_shift2[:, :, 0], dft_shift2[:, :, 1])\n)\n\ndft3 = cv2.dft(np.float32(sharpened_image2), flags=cv2.DFT_COMPLEX_OUTPUT)\ndft_shift3 = np.fft.fftshift(dft3)\nmagnitude_spectrum3 = 20 * np.log(\n    cv2.magnitude(dft_shift3[:, :, 0], dft_shift3[:, :, 1])\n)\n\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(3, 1, 1)\nplt.title(\"Magnitude Spectrum of initial image in log scale\")\nplt.imshow(magnitude_spectrum1, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(3, 1, 2)\nplt.title(\"Magnitude Spectrum of the first sharpended image in log scale\")\nplt.imshow(magnitude_spectrum2, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(3, 1, 3)\nplt.title(\"Magnitude Spectrum of the second sharpended image in log scale\")\nplt.imshow(magnitude_spectrum3, cmap=\"gray\")\nplt.axis(\"off\")\n\n\n\n\n\n\n\n\n\nrows, cols = image.shape\ncrow, ccol = rows // 2, cols // 2  # Coordenadas del centro\n\n# Crear una máscara pasa-altas\n# Empezamos con una matriz de unos\nmask = np.ones((rows, cols, 2), np.uint8)\n\n# Crear una región cuadrada en el centro de la máscara que representa las bajas frecuencias\nr = 10  # Radio de la región de bajas frecuencias que queremos eliminar\nmask[crow - r : crow + r, ccol - r : ccol + r] = (\n    0  # Zona central donde eliminamos las bajas frecuencias\n)\n\nplt.imshow(mask[:,:,1])\n\n\n\n\n\n\n\n\n\n# Aplicar la máscara pasa-altas al espectro DFT\nfshift = dft_shift1 * mask\n\n# Desplazar de vuelta las frecuencias (inverso de fftshift)\nf_ishift = np.fft.ifftshift(fshift)\n\n# Aplicar la transformada inversa de Fourier (IDFT)\nimg_back = cv2.idft(f_ishift)\n\n# Calcular la magnitud para obtener la imagen final filtrada\nimg_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n\n# Mostrar las imágenes original y filtrada\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.imshow(image, cmap=\"gray\")\nplt.title(\"Imagen Original\")\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(img_back, cmap=\"gray\")\nplt.title(\"Imagen Filtrada (Pasa-Altas)\")\nplt.axis(\"off\")\n\nplt.show()"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "",
    "text": "La leucemia linfoblástica aguda (LLA) es un tipo de cáncer hematológico caracterizado por la proliferación descontrolada de linfoblastos inmaduros en la médula ósea, la sangre y otros órganos. Este trastorno impide la producción adecuada de células sanguíneas normales, lo que provoca síntomas como anemia, infecciones recurrentes y sangrados anormales. [1]\nEl cáncer es una de las principales causas de mortalidad entre niños y adolescentes en todo el mundo; cada año se diagnostica cáncer a aproximadamente 274.000 niños de entre 0 y 19 años. [2]\nEn América Latina y el Caribe, se estima que alrededor de 30.000 niñas, niños y adolescentes menores de 19 años resultarán afectados por el cáncer anualmente. De ellos, casi 10.000 fallecerán a causa de esta enfermedad.\nEn los países de ingresos altos, más del 80% de los niños afectados de cáncer se curan, pero en muchos países de ingresos medianos y bajos la tasa de curación es de aproximadamente el 20%.[3]\nLas defunciones evitables debidas a los cánceres infantiles en los países de ingresos medianos y bajos se producen a consecuencia de la falta de diagnóstico, los diagnósticos incorrectos o tardíos, las dificultades para acceder a la atención sanitaria, el abandono del tratamiento, la muerte por toxicidad y las mayores tasas de recidivas. [3]"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#significado-en-el-contexto-del-modelo",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#significado-en-el-contexto-del-modelo",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Significado en el Contexto del Modelo",
    "text": "Significado en el Contexto del Modelo\n\nCombinación Lineal\n\nCada característica \\(x_i\\) se pondera por su importancia relativa \\(\\theta_i\\)\nEl término independiente \\(\\theta_0\\) añade un sesgo base\n\nInterpretación de los Coeficientes\n\n\\(\\theta_i &gt; 0\\): La característica aumenta la probabilidad de leucemia\n\\(\\theta_i &lt; 0\\): La característica disminuye la probabilidad de leucemia\n\\(|\\theta_i|\\): Magnitud del impacto de la característica\n\nFlujo del Modelo\n\\[\nX\\theta \\xrightarrow{\\text{producto punto}} z \\xrightarrow{\\text{sigmoide}} h_\\theta(x) = \\frac{1}{1 + e^{-z}}\n\\]\nResultado\n\n\\(z\\): Puntuación lineal (puede ser cualquier número real)\n\\(h_\\theta(x)\\): Probabilidad entre 0 y 1 después de aplicar la sigmoide\n\n\nLa regularización L1 (también conocida como LASSO - Least Absolute Shrinkage and Selection Operator) es una técnica para prevenir el sobreajuste (overfitting).\n\n¿Qué es la regularización L1?\nEs un término que se añade a la función de costo:\n\\[\n\\frac{\\lambda}{m} \\sum_{j=1}^{n} |\\theta_j|\n\\]\nDonde:\n- λ (lambda) es el parámetro que controla la fuerza de la regularización\n- m es el número de muestras\n- θj son los parámetros del modelo\n- |θj| es el valor absoluto de cada parámetro\n\n\n¿Por qué se implementa?\n\nPrevención de sobreajuste:\n\nPenaliza coeficientes muy grandes que podrían hacer que el modelo se ajuste demasiado a los datos de entrenamiento\nAyuda al modelo a generalizar mejor con nuevos datos\n\nSelección de características:\n\nLa regularización L1 tiende a producir coeficientes exactamente iguales a cero\nEsto efectivamente selecciona las características más importantes y descarta las menos relevantes\n\n\n\n\nEfectos prácticos:\n\nCon lambda_reg = 0:\n\nNo hay regularización\nEl modelo puede sobreajustarse\n\nCon lambda_reg pequeño (ej: 0.1):\n\nRegularización suave\nBalance entre ajuste y generalización\n\nCon lambda_reg grande (ej: 10):\n\nRegularización fuerte\nMás coeficientes se vuelven cero\nModelo más simple pero puede subajustarse (underfitting)\n\n\n\n\nVentajas:\n\nSelección automática de características más relevantes para detectar leucemia\nReducción del ruido en las mediciones de células\nModelo más robusto y generalizable a nuevas muestras\nInterpretabilidad mejorada al identificar las características más importantes"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#área-del-contorno",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#área-del-contorno",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "1. Área del Contorno",
    "text": "1. Área del Contorno\nEl área de un contorno cerrado se calcula utilizando la fórmula del área de un polígono mediante coordenadas:\n\\[\n\\text{Área} = \\frac{1}{2} \\sum_{i=1}^{n} (x_i y_{i+1} - y_i x_{i+1})\n\\]\nDonde:\n- \\(n\\) : Número total de puntos en el contorno\n- \\((x_i, y_i)\\) : Coordenadas del punto \\(i\\) del contorno\n- \\((x_{i+1}, y_{i+1})\\) : Coordenadas del siguiente punto en el contorno\n- El punto \\(n+1\\) se considera igual al punto 1, cerrando el polígono\nEsta fórmula:\n- Utiliza el método de triangulación para calcular el área\n- Funciona para cualquier polígono cerrado, sea cóncavo o convexo\n- El resultado es positivo si los puntos están ordenados en sentido antihorario\n- El valor absoluto del resultado da el área real"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#perímetro-del-contorno",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#perímetro-del-contorno",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "2. Perímetro del Contorno",
    "text": "2. Perímetro del Contorno\nEl perímetro se calcula sumando las distancias entre todos los puntos consecutivos del contorno:\n\\[\n\\text{Perímetro} = \\sum_{i=1}^{n} \\sqrt{(x_{i+1} - x_i)^2 + (y_{i+1} - y_i)^2}\n\\]\nDonde:\n- \\(n\\) : Número total de puntos en el contorno\n- \\((x_i, y_i)\\) : Coordenadas del punto actual\n- \\((x_{i+1}, y_{i+1})\\) : Coordenadas del siguiente punto\n- El último punto se conecta con el primero para cerrar el contorno\nEsta fórmula:\n- Utiliza la distancia euclidiana entre puntos consecutivos\n- La suma total representa la longitud del contorno completo\n- Es independiente de la orientación del contorno"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#circularidad",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#circularidad",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "3. Circularidad",
    "text": "3. Circularidad\nLa circularidad es una medida adimensional que cuantifica qué tan similar es una forma a un círculo perfecto:\n\\[\n\\text{Circularidad} = \\frac{4\\pi \\times \\text{Área}}{\\text{Perímetro}^2}\n\\]\nDonde:\n- \\(\\text{Área}\\) : Área del contorno calculada con la primera fórmula\n- \\(\\text{Perímetro}\\) : Perímetro del contorno calculado con la segunda fórmula\n- \\(\\pi\\) : Constante matemática pi (≈ 3.14159)\nInterpretación de los valores:\n- \\(\\text{Circularidad} = 1\\) : Círculo perfecto\n- \\(0 &lt; \\text{Circularidad} &lt; 1\\) : Formas no circulares\n- Valores cercanos a 1: Formas casi circulares\n- Valores cercanos a 0: Formas muy alargadas o irregulares\nPropiedades importantes:\n1. Es invariante a la escala (el tamaño no afecta el resultado)\n2. Es adimensional (no tiene unidades)\n3. Siempre es menor o igual a 1 (la igualdad solo se da en círculos perfectos)\n4. Es sensible a irregularidades en el contorno\nEjemplo de interpretación:\n- Circularidad = 0.95: Forma muy circular\n- Circularidad = 0.7: Forma moderadamente circular\n- Circularidad = 0.3: Forma muy irregular o alargadas"
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-logística",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-logística",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Función Logística",
    "text": "Función Logística\nLa función logística, o función sigmoide, se define como:\n\\[\nP(y = 1|x) = \\frac{1}{1 + e^{-(w^T x + b)}}\n\\]\nDonde:\n- ( P(y = 1|x) ) es la probabilidad de que la clase sea 1 dado un vector de características ( x ).\n- ( w ) es el vector de pesos del modelo.\n- ( b ) es el sesgo o término independiente.\n- ( x ) es el vector de características de entrada.\nLa función sigmoide convierte la salida lineal ( w^T x + b ) en un valor entre 0 y 1, que puede interpretarse como una probabilidad."
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-de-costo",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#función-de-costo",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Función de Costo",
    "text": "Función de Costo\nPara entrenar el modelo, se utiliza la función de costo de entropía cruzada:\n\\[\nJ(w, b) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(P(y^{(i)}|x^{(i)})) + (1 - y^{(i)}) \\log(1 - P(y^{(i)}|x^{(i)})) \\right]\n\\]\nDonde:\n- ( m ) es el número total de ejemplos en el conjunto de datos.\n- ( y^{(i)} ) es la etiqueta verdadera para el i-ésimo ejemplo.\n- ( P(y{(i)}|x{(i)}) ) es la probabilidad predicha para el i-ésimo ejemplo."
  },
  {
    "objectID": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#gradientes-y-actualización",
    "href": "codigo/StudentCodes/PSIM_2024_2/Proyecto_PSIM.html#gradientes-y-actualización",
    "title": "DETECCIÓN DE LA LEUCEMIA LINFOBLÁSTICA AGUDA",
    "section": "Gradientes y Actualización",
    "text": "Gradientes y Actualización\nLos gradientes de la función de costo con respecto a los parámetros ( w ) y ( b ) se utilizan para actualizar los pesos y el sesgo mediante descenso por gradiente:\n\nGradiente del peso ( w ):\n\n\\[\n\\frac{\\partial J(w, b)}{\\partial w} = \\frac{1}{m} \\sum_{i=1}^{m} (P(y^{(i)}|x^{(i)}) - y^{(i)}) x^{(i)}\n\\]\n\nGradiente del sesgo ( b ):\n\n\\[\n\\frac{\\partial J(w, b)}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (P(y^{(i)}|x^{(i)}) - y^{(i)})\n\\]\nLos parámetros se actualizan de la siguiente manera:\n\nActualización del peso ( w ):\n\n\\[\nw := w - \\alpha \\frac{\\partial J(w, b)}{\\partial w}\n\\]\n\nActualización del sesgo ( b ):\n\n\\[\nb := b - \\alpha \\frac{\\partial J(w, b)}{\\partial b}\n\\]\nDonde ( ) es la tasa de aprendizaje.\nLa precisión del modelo se evalúa comparando las predicciones con las etiquetas verdaderas en el conjunto de prueba, utilizando métricas como la precisión (accuracy), precisión (precision), sensibilidad (recall), y especificidad."
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html",
    "href": "tutoriales/tutInstallPythonR.html",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "",
    "text": "Antes de compilar Python, es necesario disponer de Ubuntu corriendo bajo WSL2 en Windows 11. Sigue estos pasos:\n\nVerificar requisitos:\n\nWindows 11 (build 22000 o superior).\nVirtualización habilitada en BIOS/UEFI (Intel VT-x o AMD SVM).\nPermisos de administrador en Windows.\n\nHabilitar WSL y plataforma de máquina virtual:\nAbre PowerShell como administrador y ejecuta:\npowershell  wsl --install\n\nEsto activa las características “Virtual Machine Platform” y “Windows Subsystem for Linux”.\nDescarga e instala Ubuntu por defecto (puedes ignorar o desinstalar luego).\nReinicia el equipo si se solicita.\n\nInstalar Ubuntu:\n\nVía PowerShell:\nwsl --install -d Ubuntu\nO desde Microsoft Store:\n\nAbre Microsoft Store.\nBusca “Ubuntu” y pulsa Instalar.\n\n\nPrimer arranque de Ubuntu:\n\nAbre Ubuntu desde el menú Inicio o Windows Terminal.\npowershell      wsl -d Ubuntu\nCrea tu usuario y contraseña de Linux.\n\nActualizar paquetes del sistema:\nsudo apt update && sudo apt upgrade -y"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-repositorios-e-instalar-dependencias-de-compilación",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-repositorios-e-instalar-dependencias-de-compilación",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "1. Actualizar repositorios e instalar dependencias de compilación",
    "text": "1. Actualizar repositorios e instalar dependencias de compilación\nEjecuta los siguientes comandos para actualizar el sistema e instalar las bibliotecas necesarias para compilar Python desde el código fuente:\nsudo apt update\nsudo apt install -y \\\n  build-essential \\\n  checkinstall \\\n  libncurses-dev \\\n  libssl-dev \\\n  zlib1g \\\n  zlib1g-dev \\\n  libreadline-dev \\\n  libsqlite3-dev \\\n  libgdbm-dev libdb5.3-dev \\\n  libbz2-dev \\\n  libexpat1-dev \\\n  libc6-dev \\\n  libffi-dev \\\n  liblzma-dev \\\n  tk-dev \\\n  dirmngr \\\n  gnupg \\\n  apt-transport-https \\\n  ca-certificates \\\n  software-properties-common wget \\\n  libxml2-dev \\\n  libharfbuzz-dev \\\n  libfribidi-dev \\\n  libcurl4-openssl-dev \\\n  libmagick++-dev \\\n  libnsl-dev \\\n  cmake\\\n  wget\\\n  fonts-jetbrains-mono\\\n  fonts-firacode\\\n  fonts-cascadia-code\\\n  fonts-inter\\\n  fonts-ibm-plex\\\n  fonts-manrope\\\n  fonts-ebgaramond\\\n  fonts-lmodern\\\n  fonts-noto\\\n  fonts-noto-mono\\\n  fonts-noto-color-emoji"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#obtener-el-kit-de-repositorio-cuda-de-nvidia",
    "href": "tutoriales/tutInstallPythonR.html#obtener-el-kit-de-repositorio-cuda-de-nvidia",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "2. Obtener el kit de repositorio CUDA de NVIDIA:",
    "text": "2. Obtener el kit de repositorio CUDA de NVIDIA:\ncd ~\nmkdir instaladores\ncd instaladores\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/12.9.1/local_installers/cuda-repo-wsl-ubuntu-12-9-local_12.9.1-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-12-9-local_12.9.1-1_amd64.deb\nsudo apt update\nsudo apt -y install cuda-toolkit-12-9"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-instalación",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-instalación",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "3. Verificar la instalación:",
    "text": "3. Verificar la instalación:\n# Verifica la versión de nvcc\nnvcc --version\n# Verifica que la GPU sea detectada\nnvidia-smi"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#instalación-de-la-versión-más-reciente-de-r",
    "href": "tutoriales/tutInstallPythonR.html#instalación-de-la-versión-más-reciente-de-r",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "4. Instalación de la versión más reciente de R",
    "text": "4. Instalación de la versión más reciente de R\nPara instalar la versión más reciente de R en Ubuntu bajo WSL2, sigue estos pasos:\n\n1. Agregar la clave y el repositorio oficial de CRAN:\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\nsudo add-apt-repository \"deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/\"\n\n\n2. Instalar R:\nsudo apt update\nsudo apt install -y r-base r-base-dev r-recommended\n\n\n3. Verificar la instalación:\nR --version    # Debe mostrar la versión de R recién instalada\nsudo R\ninstall.packages(c(\"DiagrammeR\", \"reticulate\", \"kableExtra\", \"tidyverse\", \"knitr\", \"cowplot\", \"ggfx\", \"rstatix\", \"languageserver\", \"bibliometrix\"))"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#descargar-y-extraer-python-3.12",
    "href": "tutoriales/tutInstallPythonR.html#descargar-y-extraer-python-3.12",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "5. Descargar y extraer Python 3.12",
    "text": "5. Descargar y extraer Python 3.12\n\n1. Descarga el código fuente de Python 3.12 y descomprímelo en /usr/src:\ncd /usr/src\nsudo wget https://www.python.org/ftp/python/3.12.11/Python-3.12.11.tgz\nsudo tar -xzf Python-3.12.11.tgz\ncd Python-3.12.11\n\n\n2. Configura la compilación con optimizaciones y el instalador de pip integrado:\n```bash\nsudo ./configure --enable-optimizations --with-ensurepip=install --enable-shared\n```\n\n\n3. Compila utilizando todos los núcleos disponibles:\n```bash\nsudo make -j $(nproc)\n```\n\n\n4. Instala Python 3.12 sin sobrescribir la versión del sistema por defecto:\n```bash\nsudo make altinstall\n```\nLos ejecutables quedarán en /usr/local/bin/python3.12 y /usr/local/bin/pip3.12.\n\n\n5. Verificación de la instalación\nComprueba las versiones instaladas:\n/usr/local/bin/python3.12 --version   # Debe mostrar Python 3.12.0\n/usr/local/bin/pip3.12 --version      # Debe mostrar la versión de pip correspondiente\necho 'export PATH=\"$PATH:/home/sylph/.local/bin\"' &gt;&gt; ~/.bashrc\nsource\n\n\n6. Crear y activar un entorno virtual\n\n1. Crea un directorio de trabajo\n```bash\nmkdir -p ~/proyectos\ncd ~/proyectos\n```\n\n\n2. Crea un entorno virtual (mienv) con Python 3.12:\n```bash\n/usr/local/bin/python3.12 -m venv mienv\n```\n\n\n3. Activa el entorno:\n```bash\nsource mienv/bin/activate\n```\n\n\n4. Verifica que python y pip apunten a la versión 3.12:\n```bash\npython --version   # Python 3.12.X\npip --version      # pip x.y.z\n```\n\n\n5. Instala las bibliotecas necesarias:\n```bash\npython -m pip cache purge\npython -m pip install -U --upgrade-strategy eager pip setuptools wheel packaging build\npython -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu129\npython -m pip install pandas matplotlib scikit-learn opencv-contrib-python opencv-python pywavelets statsmodels scipy seaborn plotly scikit-image scikit-image[data] scikit-image[optional] jupyter scikit-image\n```\n\n\n5. desactivar el entorno, ejecuta:\ndeactivate"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-índices-de-paquetes",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-índices-de-paquetes",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "1. Actualizar índices de paquetes",
    "text": "1. Actualizar índices de paquetes\nsudo apt update"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#descargar-el-instalador-oficial",
    "href": "tutoriales/tutInstallPythonR.html#descargar-el-instalador-oficial",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "2. Descargar el instalador oficial",
    "text": "2. Descargar el instalador oficial\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-integridad-opcional",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-integridad-opcional",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "3. Verificar la integridad (opcional)",
    "text": "3. Verificar la integridad (opcional)\nCompara el hash SHA‑256 generado con el publicado en el sitio oficial:\nsha256sum ~/miniconda.sh\n# Comprueba que el resultado coincida con el valor en https://repo.anaconda.com/miniconda/"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#ejecutar-el-instalador-en-modo-silencioso",
    "href": "tutoriales/tutInstallPythonR.html#ejecutar-el-instalador-en-modo-silencioso",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "4. Ejecutar el instalador en modo silencioso",
    "text": "4. Ejecutar el instalador en modo silencioso\nEsto instalará Miniconda en ~/miniconda sin interacción:\nbash ~/miniconda.sh -b -p $HOME/miniconda"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#inicializar-conda-en-tu-shell",
    "href": "tutoriales/tutInstallPythonR.html#inicializar-conda-en-tu-shell",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "5. Inicializar Conda en tu shell",
    "text": "5. Inicializar Conda en tu shell\nPara que conda esté disponible cada vez que abras la terminal:\neval \"$(~/miniconda/bin/conda shell.bash hook)\"\nconda init"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#recargar-la-configuración-de-shell",
    "href": "tutoriales/tutInstallPythonR.html#recargar-la-configuración-de-shell",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "6. Recargar la configuración de shell",
    "text": "6. Recargar la configuración de shell\nsource ~/.bashrc"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-conda-a-la-última-versión",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-conda-a-la-última-versión",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "7. Actualizar Conda a la última versión",
    "text": "7. Actualizar Conda a la última versión\nconda tos interactive\nconda update -n base -c defaults conda -y"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-instalación-2",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-instalación-2",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "8. Verificar la instalación",
    "text": "8. Verificar la instalación\nconda --version\n# Deberías ver algo como: conda 23.x.x"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#crear-un-entorno-virtual",
    "href": "tutoriales/tutInstallPythonR.html#crear-un-entorno-virtual",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "9. Crear un entorno virtual",
    "text": "9. Crear un entorno virtual\nconda create -n ai-env python=3.12"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#componentes",
    "href": "tutoriales/tut001_microbit.html#componentes",
    "title": "Microbit – El minicomputador",
    "section": "Componentes",
    "text": "Componentes"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "href": "tutoriales/tut001_microbit.html#como-la-puedo-programar",
    "title": "Microbit – El minicomputador",
    "section": "Como la puedo programar?",
    "text": "Como la puedo programar?"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "href": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "title": "Microbit – El minicomputador",
    "section": "Distribución e impacto",
    "text": "Distribución e impacto\n\nDistribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#problema",
    "href": "tutoriales/tut001_microbit.html#problema",
    "title": "Microbit – El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable en 0.\nMostrar el número en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "href": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "title": "Microbit – El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#lets-code",
    "href": "tutoriales/tut001_microbit.html#lets-code",
    "title": "Microbit – El minicomputador",
    "section": "Let’s Code",
    "text": "Let’s Code\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#editor",
    "href": "tutoriales/tut001_microbit.html#editor",
    "title": "Microbit – El minicomputador",
    "section": "Editor",
    "text": "Editor\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "href": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "title": "Microbit – El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable con el número a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit",
    "href": "tutoriales/tut002_IA.html#que-es-microbit",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#componentes",
    "href": "tutoriales/tut002_IA.html#componentes",
    "title": "Microbit – El minicomputador",
    "section": "Componentes",
    "text": "Componentes"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#como-la-puedo-programar",
    "href": "tutoriales/tut002_IA.html#como-la-puedo-programar",
    "title": "Microbit – El minicomputador",
    "section": "Como la puedo programar?",
    "text": "Como la puedo programar?"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "title": "Microbit – El minicomputador",
    "section": "Que es Microbit",
    "text": "Que es Microbit\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#distribución-e-impacto",
    "href": "tutoriales/tut002_IA.html#distribución-e-impacto",
    "title": "Microbit – El minicomputador",
    "section": "Distribución e impacto",
    "text": "Distribución e impacto\n\nDistribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#problema",
    "href": "tutoriales/tut002_IA.html#problema",
    "title": "Microbit – El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable en 0.\nMostrar el número en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "href": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "title": "Microbit – El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#lets-code",
    "href": "tutoriales/tut002_IA.html#lets-code",
    "title": "Microbit – El minicomputador",
    "section": "Let’s Code",
    "text": "Let’s Code\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#editor",
    "href": "tutoriales/tut002_IA.html#editor",
    "title": "Microbit – El minicomputador",
    "section": "Editor",
    "text": "Editor\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "href": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "title": "Microbit – El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\nInicializar una variable con el número a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "tutoriales/TutorialPython.html",
    "href": "tutoriales/TutorialPython.html",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Tomado del libro Ciencia de Datos para Ciencias Naturales\nSi no tiene experiencia con el lenguaje Markdown utilice esta guía para enriquecer sus celdas de texto.\n\n\n\nPlataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código\n\n\n\n\n\nNo requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos.\n\n\n\n\n\nNo se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia.\n\n\n\n\n\nCódigo: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#características",
    "href": "tutoriales/TutorialPython.html#características",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Plataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#ventajas",
    "href": "tutoriales/TutorialPython.html#ventajas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "href": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "href": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Código: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#strings",
    "href": "tutoriales/TutorialPython.html#strings",
    "title": "Tutorial de Python",
    "section": "Strings",
    "text": "Strings\n\ncadena_caracteres = \" Diplomado en Analítica para la Banca \"\n\n#Tamaño de la cadena de caracteres\nprint(len(cadena_caracteres))\n\n#Corte de variable\nprint(cadena_caracteres[0:10])\nprint(cadena_caracteres[20:30])\n\n#Convertir la variable a mayúsculas\nprint(cadena_caracteres.upper())\n\n#Convertir la variable a minúscula\nprint(cadena_caracteres.lower())\n\n#Contar cuantas veces aparece una cadena de caracteres\nprint(cadena_caracteres.count(\"ca\"))\n\n#Reemplazar en una cadena, una letra con otra\nprint(cadena_caracteres.replace(\"a\", \"0\"))\n\n#Partir la cadena de caracteres cada vez que se encuentre un caracter\nprint(cadena_caracteres.split(\" \"))\n\n#Concatenar dos cadenas de caracteres\ncadena01 = \"Pablo Eduardo\"\ncadena02 = \"Caicedo Rodríguez\"\nprint(cadena01+\" \"+cadena02)\n\n38\n Diplomado\nica para l\n DIPLOMADO EN ANALÍTICA PARA LA BANCA \n diplomado en analítica para la banca \n2\n Diplom0do en An0lític0 p0r0 l0 B0nc0 \n['', 'Diplomado', 'en', 'Analítica', 'para', 'la', 'Banca', '']\nPablo Eduardo Caicedo Rodríguez"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#listas",
    "href": "tutoriales/TutorialPython.html#listas",
    "title": "Tutorial de Python",
    "section": "Listas",
    "text": "Listas\n\nlista = [3, 2, 1, 0.5, \"hora del cafe\", \"torta chilena\", \"pinto\", \"jugo\"]\nprint(lista)\nlista.append(\"empanadita\")\nprint(lista)\n\"pinto\" in lista\n\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo']\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo', 'empanadita']\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#diccionarios",
    "href": "tutoriales/TutorialPython.html#diccionarios",
    "title": "Tutorial de Python",
    "section": "Diccionarios",
    "text": "Diccionarios\n\ntel = {'Maria': 4098, 'Jorge': 4139}\nprint(tel)\nprint(tel[\"Maria\"])\nprint(tel.keys())\nprint(tel.values)\n'Maria' in tel\n\n{'Maria': 4098, 'Jorge': 4139}\n4098\ndict_keys(['Maria', 'Jorge'])\n&lt;built-in method values of dict object at 0x734f7c989b40&gt;\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tuplas",
    "href": "tutoriales/TutorialPython.html#tuplas",
    "title": "Tutorial de Python",
    "section": "Tuplas",
    "text": "Tuplas\n\nfrutas = ('naranja', 'mango', 'sandia', 'banano', 'kiwi')\nprint(type(frutas))\nfrutas[1]\n\n&lt;class 'tuple'&gt;\n\n\n'mango'"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#numpy",
    "href": "tutoriales/TutorialPython.html#numpy",
    "title": "Tutorial de Python",
    "section": "Numpy",
    "text": "Numpy\nNumPy (Numerical Python), es una biblioteca de Python que da soporte para crear vectores y matrices grandes multidimensionales, junto con una gran colección de funciones matemáticas de alto nivel. La funcionalidad principal de NumPy es su estructura de datos ndarray (arreglos), para una matriz de n dimensiones, sobre las cuales se pueden realizar operaciones matemátias de manera eficiente.\nCrearemos una lista usando código nativo de Python y lo convertiremos en una matriz unidimensional con la función np.array()\n\nimport numpy as np\n\nlist1 = [6,8,10,12]\narray1 = np.array(list1)\nprint(array1)\n\n[ 6  8 10 12]\n\n\nLos ndarrays son estructuras de datos genéricas para almacenar datos homogéneos. Son equivalentes a las matrices y los vectores en álgebra, por lo que también se les puede aplicar operaciones matemáticas. Notar que las operaciones matemáticas se pueden realizar en todos los valores en un ndarray a la vez.\n\nprint(array1 - 2)\nprint(array1 * array1, \"\\n\\n\")\n\n[ 4  6  8 10]\n[ 36  64 100 144] \n\n\n\n\nLos arreglos se encierran entre [], pero al imprimirlos no están separados por comas. Hay diferentes formas de crear arreglos con propiedades específicas, lo que les provee bastante flexibilidad.\n\n# Crea una matriz con datos específicos\nprint(np.array([[1,2],[3,4]]),'\\n')\n# Crea una matriz con unos: tres filas y cuatro columnas\nprint(np.ones((3,4)),'\\n')\n# Crea una matriz con ceros: tres filas y cuatro columnas\nprint(np.zeros((3,4)),'\\n')\n# Crea una matriz con un dato específico: tres filas y cuatro columnas\nprint(np.full((3,4), 7.3),'\\n')\n# Crea un arreglo con datos seguidos: empieza en 10 termina en 30(sin incluir) con incrementos de 5.\nprint(np.arange(10,30,5),'\\n')\n# # Crea un arreglo con inicio y fin y una cantidad de datos: arreglo de 6 datos entre 0 y 5/3 .\nprint(np.linspace(0,5/3,6),'\\n')\n# Crea una matriz con datos aleatorios entre 0 y 1: dos filas y tres columnas\nprint(np.random.rand(2,3),'\\n')\n\n[[1 2]\n [3 4]] \n\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]] \n\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]] \n\n[[7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]] \n\n[10 15 20 25] \n\n[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] \n\n[[0.50373623 0.88307563 0.25760321]\n [0.57957561 0.16494894 0.80737306]] \n\n\n\n\narr1 = np.array([np.arange(0,5), np.arange(0,5)*5])\n#Arreglo\nprint(arr1, \"\\n\")\n# Forma\nprint(arr1.shape, \"\\n\")\n# Tamaño\nprint(arr1.size, \"\\n\")\n# Número de Dimensiones\nprint(arr1.ndim, \"\\n\")\n# Transpuesta\nprint(arr1.T, \"\\n\")\n\n[[ 0  1  2  3  4]\n [ 0  5 10 15 20]] \n\n(2, 5) \n\n10 \n\n2 \n\n[[ 0  0]\n [ 1  5]\n [ 2 10]\n [ 3 15]\n [ 4 20]] \n\n\n\n\narr = np.array([1,2,3,4,5,6,7])\n# Porcionar\nprint(arr[1:3])# de 1 al 3 en índice\nprint(arr[4:])# de la posición 4 en adelante\nprint(arr[::2])# de uno por medio\n\n[2 3]\n[5 6 7]\n[1 3 5 7]"
  },
  {
    "objectID": "proyectos/Sabana/fileProof.html",
    "href": "proyectos/Sabana/fileProof.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport scipy.io as sio\nimport scipy.signal as sig\nfrom scipy.signal import tf2zpk\nfrom scipy.spatial.transform import Rotation as R\n\npath_ecg = \"../../data\"\n\n\ndef plot_imu_frame(axis_length=1.0, arrow_ratio=0.1):\n    \"\"\"\n    Dibuja el sistema de coordenadas de una IMU en 3D.\n\n    Parámetros:\n    - axis_length: longitud de cada eje.\n    - arrow_ratio: fracción del eje destinada a la cabeza de la flecha.\n    \"\"\"\n    # Creamos la figura y el eje 3D\n    fig = plt.figure(figsize=(6, 6))\n    ax = fig.add_subplot(111, projection=\"3d\")\n\n    # Origen de los ejes\n    origin = np.array([0, 0, 0])\n\n    # Vectores unitarios para X, Y, Z\n    axes = np.eye(3) * axis_length\n    colors = [\"r\", \"g\", \"b\"]\n    labels = [\"N\", \"Y\", \"-g\"]\n\n    # Dibujar cada eje con quiver (flecha)\n    for vec, c, lab in zip(axes, colors, labels):\n        ax.quiver(\n            origin[0],\n            origin[1],\n            origin[2],\n            vec[0],\n            vec[1],\n            vec[2],\n            color=c,\n            arrow_length_ratio=arrow_ratio,\n            linewidth=2,\n        )\n        # Etiquetar el extremo del eje\n        ax.text(\n            vec[0] * 1.05,\n            vec[1] * 1.05,\n            vec[2] * 1.05,\n            lab,\n            color=c,\n            fontsize=14,\n            fontweight=\"bold\",\n        )\n\n    # Ajustes de estilo\n    ax.set_xlim(0, axis_length * 1.2)\n    ax.set_ylim(0, axis_length * 1.2)\n    ax.set_zlim(0, axis_length * 1.2)\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n    ax.set_zlabel(\"Z\")\n    ax.set_title(\"Sistema de coordenadas IMU\")\n    ax.grid(True)\n\n    # Mostrar proporción igual para los tres ejes\n    ax.set_box_aspect([1, 1, 1])\n\n    plt.tight_layout()\n    plt.show()\n\n\ndef calcular_relacion_romberg(\n    param_eyes_open: float,\n    param_eyes_close: float,\n) -&gt; float:\n    return param_eyes_close / param_eyes_open\n\n\ndef calcular_rms(signal1):\n    return np.sqrt(np.mean(np.square(signal1)))\n\n\ndef calcular_magnitud_angular_velocity(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleración global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Gyr_Global_Mag\"] = np.sqrt(\n        df[\"Gyr_X_global\"] ** 2 + df[\"Gyr_Y_global\"] ** 2 + df[\"Gyr_Z_global\"] ** 2\n    )\n    return df.copy()\n\n\ndef calcular_magnitud_aceleracion_local(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleración global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Acc_Local_Mag\"] = np.sqrt(df[\"Acc_Y\"] ** 2 + df[\"Acc_Z\"] ** 2)\n    return df.copy()\n\n\ndef calcular_magnitud_aceleracion(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleración global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Acc_Global_Mag\"] = np.sqrt(df[\"Acc_X_global\"] ** 2 + df[\"Acc_Y_global\"] ** 2)\n    return df.copy()\n\n\ndef CalculateGlobalVectors(df):\n    # Cuaterniones y aceleración local\n    quaternions = df[[\"Quat_q0\", \"Quat_q1\", \"Quat_q2\", \"Quat_q3\"]].values\n    acc_local = df[[\"Acc_X\", \"Acc_Y\", \"Acc_Z\"]].values\n    ang_vel_local = df[[\"Gyr_X\", \"Gyr_Y\", \"Gyr_Z\"]].values\n\n    sig_filtersos = sig.butter(10, 4, \"low\", fs=100, output=\"sos\")\n\n    # Aplicar filtro a las columnas de aceleración\n    acc_local = sig.sosfilt(sig_filtersos, acc_local)\n    ang_vel_local = sig.sosfilt(sig_filtersos, ang_vel_local)\n    df[[\"Acc_X\", \"Acc_Y\", \"Acc_Z\"]] = acc_local\n    df[[\"Gyr_X\", \"Gyr_Y\", \"Gyr_Z\"]] = ang_vel_local\n\n    # Rotar aceleraciones al sistema global\n    rot = R.from_quat(quaternions)\n    acc_global = rot.apply(acc_local)\n    ang_vel_global = rot.apply(ang_vel_local)\n\n    # 🔁 Normalizar Y y Z a máximo absoluto de 1\n    # acc_global[:, 1] = acc_global[:, 1] / np.max(np.abs(acc_global[:, 1]))\n    # acc_global[:, 2] = acc_global[:, 2] / np.max(np.abs(acc_global[:, 2]))\n\n    # Guardar aceleraciones normalizadas\n    df[\"Acc_X_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 0])\n    df[\"Acc_Y_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 1])\n    df[\"Acc_Z_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 2])\n    df[\"Gyr_X_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 0])\n    df[\"Gyr_Y_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 1])\n    df[\"Gyr_Z_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 2])\n    return df.copy()\n\n\ndef select_mid_segment(\n    df: pd.DataFrame,\n    time_col: str = \"Time\",\n    half_length: float = 10.0,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Selecciona el segmento de df que comprende `pre_sec` segundos\n    antes y `post_sec` segundos después del punto medio de la serie\n    temporal indicada por `time_col`.\n\n    Parámetros\n    ----------\n    df : pd.DataFrame\n        DataFrame que debe contener la columna de tiempo `time_col`.\n    time_col : str\n        Nombre de la columna de tiempo (en segundos).\n    pre_sec : float\n        Segundos a incluir antes del punto medio.\n    post_sec : float\n        Segundos a incluir después del punto medio.\n\n    Devuelve\n    -------\n    pd.DataFrame\n        Sub-DataFrame con las mismas columnas que `df`, filtrado\n        para el intervalo [midpoint - pre_sec, midpoint + post_sec].\n    \"\"\"\n    # Calcular extremo inferior y superior del tiempo\n    t_min = df[time_col].min()\n    t_max = df[time_col].max()\n    midpoint = (t_min + t_max) / 2\n\n    start_time = midpoint - half_length\n    end_time = midpoint + half_length\n\n    # Filtrar el DataFrame por el rango de tiempo\n    segment = df[(df[time_col] &gt;= start_time) & (df[time_col] &lt;= end_time)].copy()\n\n    return segment\n\n\ndataDualTask = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/dt_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeClosed = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/ec_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeOpen = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/eo_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeClosed = dataEyeClosed.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\ndataDualTask = dataDualTask.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\ndataEyeOpen = dataEyeOpen.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\nfs = 100\nTs = 1 / fs\ndataEyeOpen[\"Time\"] = Ts * np.arange(0, len(dataEyeOpen))\ndataEyeClosed[\"Time\"] = Ts * np.arange(0, len(dataEyeClosed))\ndataDualTask[\"Time\"] = Ts * np.arange(0, len(dataDualTask))\ndataDualTask = CalculateGlobalVectors(dataDualTask)\ndataEyeClosed = CalculateGlobalVectors(dataEyeClosed)\ndataEyeOpen = CalculateGlobalVectors(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_aceleracion(dataDualTask)\ndataEyeClosed = calcular_magnitud_aceleracion(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_aceleracion(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_aceleracion_local(dataDualTask)\ndataEyeClosed = calcular_magnitud_aceleracion_local(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_aceleracion_local(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_angular_velocity(dataDualTask)\ndataEyeClosed = calcular_magnitud_angular_velocity(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_angular_velocity(dataEyeOpen)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2\n\n\ndef ellipse_sway_area(x, y, confidence=0.95, plot=True):\n    \"\"\"\n    Calcula el área y dibuja la elipse de oscilación para los datos (x,y)\n    cubriendo el porcentaje de confianza dado (p.ej. 0.95 para 95%).\n\n    Parámetros:\n    - x, y: arrays de coordenadas (misma longitud).\n    - confidence: nivel de confianza (entre 0 y 1).\n    - plot: si True, dibuja los puntos y la elipse.\n\n    Retorna:\n    - area: área de la elipse.\n    - width, height: semiejes mayor y menor.\n    - angle: ángulo de rotación en grados.\n    \"\"\"\n    # Centro (media)\n    mu = np.array([np.mean(x), np.mean(y)])\n    # Matriz de covarianza\n    cov = np.cov(x, y)\n    # Eigenvalores y eigenvectores\n    vals, vecs = np.linalg.eigh(cov)\n    # Ordenar de mayor a menor\n    order = vals.argsort()[::-1]\n    vals = vals[order]\n    vecs = vecs[:, order]\n\n    # Factor de escala: chi-cuadrado inverso para 2 grados y nivel dado\n    chi2_val = chi2.ppf(confidence, df=2)\n    # Semiejes\n    a = np.sqrt(vals[0] * chi2_val)\n    b = np.sqrt(vals[1] * chi2_val)\n    area = np.pi * a * b\n\n    # Ángulo de rotación (en grados) del semieje mayor respecto al eje X\n    angle = np.degrees(np.arctan2(vecs[1, 0], vecs[0, 0]))\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(6, 6))\n        ax.scatter(x, y, s=10, alpha=0.5, label=\"Datos\")\n        # Dibujo de la elipse\n        from matplotlib.patches import Ellipse\n\n        ellipse = Ellipse(\n            xy=mu,\n            width=2 * a,\n            height=2 * b,\n            angle=angle,\n            edgecolor=\"r\",\n            facecolor=\"none\",\n            lw=2,\n            label=f\"{int(confidence*100)}% Elipse\",\n        )\n        ax.add_patch(ellipse)\n        ax.set_aspect(\"equal\")\n        ax.set_xlabel(\"X\")\n        ax.set_ylabel(\"Y\")\n        ax.set_title(\n            f\"Elipse de oscilación ({int(confidence*100)}% conf.)\\nÁrea = {area:.2f}\"\n        )\n        ax.legend()\n        plt.grid(True)\n        plt.show()\n\n    return area, a, b, angle\n\n\n# Ejemplo de uso:\nif __name__ == \"__main__\":\n    # Simulamos datos de sway\n    np.random.seed(0)\n    x = np.random.normal(0, 1, size=500)\n    y = 0.5 * x + np.random.normal(0, 0.8, size=500)\n\n    area, a, b, angle = ellipse_sway_area(\n        dataDualTask[\"Acc_X_global\"], dataDualTask[\"Acc_Y_global\"], confidence=0.95\n    )\n    print(f\"Área de la elipse al 95 %: {area:.4f}\")\n    print(f\"Semiejes: a={a:.2f}, b={b:.2f}, ángulo={angle:.1f}°\")\n\n\n\n\n\n\n\n\nÁrea de la elipse al 95 %: 0.0000\nSemiejes: a=0.00, b=0.00, ángulo=67.1°\n\n\n\nrmsAccX_eo = calcular_rms(dataEyeOpen[\"Acc_X_global\"])\nrmsAccY_eo = calcular_rms(dataEyeOpen[\"Acc_Y_global\"])\nrmsAccZ_eo = calcular_rms(dataEyeOpen[\"Acc_Z_global\"])\n\nrmsGyrX_eo = calcular_rms(dataEyeOpen[\"Gyr_X_global\"])\nrmsGyrY_eo = calcular_rms(dataEyeOpen[\"Gyr_Y_global\"])\nrmsGyrZ_eo = calcular_rms(dataEyeOpen[\"Gyr_Z_global\"])\n\npathTrajectAcc_eo = np.sum(dataEyeOpen[\"Acc_Local_Mag\"])\nareaAcc_eo, a, b, angle = ellipse_sway_area(\n    dataEyeOpen[\"Acc_X_global\"],\n    dataEyeOpen[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\n\nrmsAccX_ec = calcular_rms(dataEyeClosed[\"Acc_X_global\"])\nrmsAccY_ec = calcular_rms(dataEyeClosed[\"Acc_Y_global\"])\nrmsAccZ_ec = calcular_rms(dataEyeClosed[\"Acc_Z_global\"])\n\nrmsGyrX_ec = calcular_rms(dataEyeClosed[\"Gyr_X_global\"])\nrmsGyrY_ec = calcular_rms(dataEyeClosed[\"Gyr_Y_global\"])\nrmsGyrZ_ec = calcular_rms(dataEyeClosed[\"Gyr_Z_global\"])\n\npathTrajectAcc_ec = np.sum(dataEyeClosed[\"Acc_Local_Mag\"])\nareaAcc_ec, a, b, angle = ellipse_sway_area(\n    dataEyeClosed[\"Acc_X_global\"],\n    dataEyeClosed[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\n\nrmsAccX_dt = calcular_rms(dataDualTask[\"Acc_X_global\"])\nrmsAccY_dt = calcular_rms(dataDualTask[\"Acc_Y_global\"])\nrmsAccZ_dt = calcular_rms(dataDualTask[\"Acc_Z_global\"])\n\nrmsGyrX_dt = calcular_rms(dataDualTask[\"Gyr_X_global\"])\nrmsGyrY_dt = calcular_rms(dataDualTask[\"Gyr_Y_global\"])\nrmsGyrZ_dt = calcular_rms(dataDualTask[\"Gyr_Z_global\"])\n\npathTrajectAcc_dt = np.sum(dataDualTask[\"Acc_Local_Mag\"])\nareaAcc_dt, a, b, angle = ellipse_sway_area(\n    dataDualTask[\"Acc_X_global\"], dataDualTask[\"Acc_Y_global\"], confidence=0.95,plot=False\n)\n\n\nrmsAccX_dt = calcular_rms(dataDualTask[\"Acc_X_global\"])\nrmsAccY_dt = calcular_rms(dataDualTask[\"Acc_Y_global\"])\nrmsAccZ_dt = calcular_rms(dataDualTask[\"Acc_Z_global\"])\n\nrmsGyrX_dt = calcular_rms(dataDualTask[\"Gyr_X_global\"])\nrmsGyrY_dt = calcular_rms(dataDualTask[\"Gyr_Y_global\"])\nrmsGyrZ_dt = calcular_rms(dataDualTask[\"Gyr_Z_global\"])\n\npathTrajectAcc_dt = np.sum(dataDualTask[\"Acc_Local_Mag\"])\nareaAcc_dt, a, b, angle = ellipse_sway_area(\n    dataDualTask[\"Acc_X_global\"],\n    dataDualTask[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\nrmsAccX_ec = calcular_rms(dataEyeClosed[\"Acc_X_global\"])\nrmsAccY_ec = calcular_rms(dataEyeClosed[\"Acc_Y_global\"])\nrmsAccZ_ec = calcular_rms(dataEyeClosed[\"Acc_Z_global\"])\n\nrmsGyrX_ec = calcular_rms(dataEyeClosed[\"Gyr_X_global\"])\nrmsGyrY_ec = calcular_rms(dataEyeClosed[\"Gyr_Y_global\"])\nrmsGyrZ_ec = calcular_rms(dataEyeClosed[\"Gyr_Z_global\"])\n\npathTrajectAcc_ec = np.sum(dataEyeClosed[\"Acc_Local_Mag\"])\nareaAcc_ec, a, b, angle = ellipse_sway_area(\n    dataEyeClosed[\"Acc_X_global\"],\n    dataEyeClosed[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\nrmsAccX_eo = calcular_rms(dataEyeOpen[\"Acc_X_global\"])\nrmsAccY_eo = calcular_rms(dataEyeOpen[\"Acc_Y_global\"])\nrmsAccZ_eo = calcular_rms(dataEyeOpen[\"Acc_Z_global\"])\n\nrmsGyrX_eo = calcular_rms(dataEyeOpen[\"Gyr_X_global\"])\nrmsGyrY_eo = calcular_rms(dataEyeOpen[\"Gyr_Y_global\"])\nrmsGyrZ_eo = calcular_rms(dataEyeOpen[\"Gyr_Z_global\"])\n\npathTrajectAcc_eo = np.sum(dataEyeOpen[\"Acc_Local_Mag\"])\nareaAcc_eo, a, b, angle = ellipse_sway_area(\n    dataEyeOpen[\"Acc_X_global\"],\n    dataEyeOpen[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)"
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_RayosX.html#introducción-al-procesamiento-biomédico",
    "href": "presentaciones/PAIM/Lect002_RayosX.html#introducción-al-procesamiento-biomédico",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Introducción al Procesamiento Biomédico",
    "text": "Introducción al Procesamiento Biomédico\n\nLa imagen médica es un proceso de extracción de información biológica fidedigna.\nImpacto directo en la interpretabilidad diagnóstica.\nBase fundamental para el desarrollo de sistemas de IA Confiable."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_RayosX.html#representación-digital",
    "href": "presentaciones/PAIM/Lect002_RayosX.html#representación-digital",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "1. Representación Digital",
    "text": "1. Representación Digital\nModelado de la Digitalización\nUna imagen continua \\(f(x,y)\\) se discretiza en \\(I[m,n]\\) mediante:\n\nMuestreo Espacial: Determina el tamaño del píxel (\\(\\sim 100-200 \\mu m\\) en radiografía).\nCuantización: Resolución de contraste.\n\nEstándar Clínico: 12-16 bits (Escala Hounsfield).\nFalso contorneo: Artefacto por baja profundidad de bits."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_RayosX.html#percepción-visual-y-color",
    "href": "presentaciones/PAIM/Lect002_RayosX.html#percepción-visual-y-color",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "2. Percepción Visual y Color",
    "text": "2. Percepción Visual y Color\n\nLimitación de RGB: Falta de uniformidad perceptual para análisis cuantitativo.\nEspacio CIELAB:\n\n\\(L^*\\): Luminosidad (información estructural).\n\\(a^*, b^*\\): Componentes cromáticos.\n\nAplicación: Crítico en patología digital y endoscopia."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_RayosX.html#caracterización-del-ruido-clínico",
    "href": "presentaciones/PAIM/Lect002_RayosX.html#caracterización-del-ruido-clínico",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "3. Caracterización del Ruido Clínico",
    "text": "3. Caracterización del Ruido Clínico\nEl ruido es un proceso estocástico dependiente de la física de adquisición:\n\nRuido de Poisson (Cuántico):\n\nDominante en Rayos X y TC.\n\\(\\sigma^2 \\propto \\text{Intensidad de la señal}\\).\n\nRuido Gaussiano (Electrónico):\n\nOriginado por la instrumentación y digitalización."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_RayosX.html#métricas-de-desempeño",
    "href": "presentaciones/PAIM/Lect002_RayosX.html#métricas-de-desempeño",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "4. Métricas de Desempeño",
    "text": "4. Métricas de Desempeño\nPara que una patología sea detectable, debe superar el umbral de ruido:\nContrast-to-Noise Ratio (CNR): \\[CNR = \\frac{|\\mu_{tumor} - \\mu_{sano}|}{\\sigma_{ruido}}\\]\n\nEvalúa la diferencia de intensidad entre tejidos normalizada por el ruido ambiental."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_RayosX.html#resolución-espacial-y-la-mtf",
    "href": "presentaciones/PAIM/Lect002_RayosX.html#resolución-espacial-y-la-mtf",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "5. Resolución Espacial y la MTF",
    "text": "5. Resolución Espacial y la MTF\nLa resolución no es solo el tamaño de la matriz, es una propiedad dinámica.\n\nPSF (Point Spread Function): Respuesta del sistema a un punto infinitesimal \\(\\delta(x,y)\\).\nMTF (Modulation Transfer Function): \\[MTF(u,v) = \\frac{|\\mathcal{F}\\{PSF\\}|}{|\\mathcal{F}\\{PSF\\}_{(0,0)}|}\\]\nCuantifica la pérdida de contraste en función de la frecuencia espacial (\\(lp/mm\\))."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_RayosX.html#determinación-práctica-método-del-borde",
    "href": "presentaciones/PAIM/Lect002_RayosX.html#determinación-práctica-método-del-borde",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "6. Determinación Práctica: Método del Borde",
    "text": "6. Determinación Práctica: Método del Borde\nDado que no existen “puntos perfectos”, se utiliza el borde de una placa de plomo:\n\nERF (Edge Response Function): Perfil perpendicular al borde.\nLSF (Line Spread Function): Derivada de la ERF (\\(LSF(x) = \\frac{d}{dx}ERF(x)\\)).\nMTF: Transformada de Fourier de la LSF."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_RayosX.html#interpretación-clínica-de-la-mtf",
    "href": "presentaciones/PAIM/Lect002_RayosX.html#interpretación-clínica-de-la-mtf",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "7. Interpretación Clínica de la MTF",
    "text": "7. Interpretación Clínica de la MTF\n\n\\(f_{50}\\): Frecuencia donde se pierde el 50% del contraste (nitidez percibida).\n\\(f_{10}\\): Límite de resolución detectable por el ojo humano.\nMamografía: Requiere MTF alta en frecuencias elevadas (\\(10-15 lp/mm\\)).\nTC Corporal: Centrado en frecuencias bajas para contraste de tejidos blandos."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_RayosX.html#conclusiones",
    "href": "presentaciones/PAIM/Lect002_RayosX.html#conclusiones",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nLa cuantización limita la sensibilidad del contraste.\nEl ruido cuántico impone el límite fundamental de detectabilidad.\nLa MTF es la métrica definitiva para validar la cadena de adquisición.\nSin métricas objetivas (CNR, MTF), la validación de IA carece de sustento físico."
  },
  {
    "objectID": "presentaciones/PAIM/Lect005_Resonancia.html",
    "href": "presentaciones/PAIM/Lect005_Resonancia.html",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "",
    "text": "Procesado Avanzado de Imágenes Médicas - PAIM"
  },
  {
    "objectID": "presentaciones/PAIM/Lect004_Tomografia.html",
    "href": "presentaciones/PAIM/Lect004_Tomografia.html",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "",
    "text": "Procesado Avanzado de Imágenes Médicas - PAIM"
  },
  {
    "objectID": "presentaciones/PAIM/Lect003_RayosX.html",
    "href": "presentaciones/PAIM/Lect003_RayosX.html",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "",
    "text": "Procesado Avanzado de Imágenes Médicas - PAIM"
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#introducción-al-procesamiento-biomédico",
    "href": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#introducción-al-procesamiento-biomédico",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Introducción al Procesamiento Biomédico",
    "text": "Introducción al Procesamiento Biomédico\n\nLa imagen médica es un proceso de extracción de información biológica fidedigna.\nImpacto directo en la interpretabilidad diagnóstica.\nBase fundamental para el desarrollo de sistemas de IA Confiable."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#representación-digital",
    "href": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#representación-digital",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "1. Representación Digital",
    "text": "1. Representación Digital\nModelado de la Digitalización\nUna imagen continua \\(f(x,y)\\) se discretiza en \\(I[m,n]\\) mediante:\n\nMuestreo Espacial: Determina el tamaño del píxel (\\(\\sim 100-200 \\mu m\\) en radiografía).\nCuantización: Resolución de contraste.\n\nEstándar Clínico: 12-16 bits (Escala Hounsfield).\nFalso contorneo: Artefacto por baja profundidad de bits."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#percepción-visual-y-color",
    "href": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#percepción-visual-y-color",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "2. Percepción Visual y Color",
    "text": "2. Percepción Visual y Color\n\nLimitación de RGB: Falta de uniformidad perceptual para análisis cuantitativo.\nEspacio CIELAB:\n\n\\(L^*\\): Luminosidad (información estructural).\n\\(a^*, b^*\\): Componentes cromáticos.\n\nAplicación: Crítico en patología digital y endoscopia."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#caracterización-del-ruido-clínico",
    "href": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#caracterización-del-ruido-clínico",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "3. Caracterización del Ruido Clínico",
    "text": "3. Caracterización del Ruido Clínico\nEl ruido es un proceso estocástico dependiente de la física de adquisición:\n\nRuido de Poisson (Cuántico):\n\nDominante en Rayos X y TC.\n\\(\\sigma^2 \\propto \\text{Intensidad de la señal}\\).\n\nRuido Gaussiano (Electrónico):\n\nOriginado por la instrumentación y digitalización."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#métricas-de-desempeño",
    "href": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#métricas-de-desempeño",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "4. Métricas de Desempeño",
    "text": "4. Métricas de Desempeño\nPara que una patología sea detectable, debe superar el umbral de ruido:\nContrast-to-Noise Ratio (CNR): \\[CNR = \\frac{|\\mu_{tumor} - \\mu_{sano}|}{\\sigma_{ruido}}\\]\n\nEvalúa la diferencia de intensidad entre tejidos normalizada por el ruido ambiental."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#resolución-espacial-y-la-mtf",
    "href": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#resolución-espacial-y-la-mtf",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "5. Resolución Espacial y la MTF",
    "text": "5. Resolución Espacial y la MTF\nLa resolución no es solo el tamaño de la matriz, es una propiedad dinámica.\n\nPSF (Point Spread Function): Respuesta del sistema a un punto infinitesimal \\(\\delta(x,y)\\).\nMTF (Modulation Transfer Function): \\[MTF(u,v) = \\frac{|\\mathcal{F}\\{PSF\\}|}{|\\mathcal{F}\\{PSF\\}_{(0,0)}|}\\]\nCuantifica la pérdida de contraste en función de la frecuencia espacial (\\(lp/mm\\))."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#determinación-práctica-método-del-borde",
    "href": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#determinación-práctica-método-del-borde",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "6. Determinación Práctica: Método del Borde",
    "text": "6. Determinación Práctica: Método del Borde\nDado que no existen “puntos perfectos”, se utiliza el borde de una placa de plomo:\n\nERF (Edge Response Function): Perfil perpendicular al borde.\nLSF (Line Spread Function): Derivada de la ERF (\\(LSF(x) = \\frac{d}{dx}ERF(x)\\)).\nMTF: Transformada de Fourier de la LSF."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#interpretación-clínica-de-la-mtf",
    "href": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#interpretación-clínica-de-la-mtf",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "7. Interpretación Clínica de la MTF",
    "text": "7. Interpretación Clínica de la MTF\n\n\\(f_{50}\\): Frecuencia donde se pierde el 50% del contraste (nitidez percibida).\n\\(f_{10}\\): Límite de resolución detectable por el ojo humano.\nMamografía: Requiere MTF alta en frecuencias elevadas (\\(10-15 lp/mm\\)).\nTC Corporal: Centrado en frecuencias bajas para contraste de tejidos blandos."
  },
  {
    "objectID": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#conclusiones",
    "href": "presentaciones/PAIM/Lect002_FundamentosMatematicos.html#conclusiones",
    "title": "Procesamiento Avanzado de Imágenes Médicas",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nLa cuantización limita la sensibilidad del contraste.\nEl ruido cuántico impone el límite fundamental de detectabilidad.\nLa MTF es la métrica definitiva para validar la cadena de adquisición.\nSin métricas objetivas (CNR, MTF), la validación de IA carece de sustento físico."
  },
  {
    "objectID": "presentaciones/PSIM/lect004_Intro_ImgProc.html",
    "href": "presentaciones/PSIM/lect004_Intro_ImgProc.html",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "NotaDefinition\n\n\n\n\nTwo-dimensional function, f(x, y)\nWhere x and y are spatial coordinates.\nThe amplitude of f at any pair of coordinates (x, y) is called the intensity.\n\n\n\n\n\n\n\n\n\nAdvertenciaThe digital image\n\n\n\nIf the coordinates and the intensity are discrete quantities the image turns into a digital image.\n\n\n\n\n\n\n\n\n\n\n\nTipDefinition\n\n\n\nA digital image is composed by a finite number of elements called PIXEL.\n\n\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\nTipDepth\n\n\n\n\nA digital image is composed by a finite number of elements called PIXEL. Bpp( Bits per pixel)\n\n1bpp. B/W image, monochrome.\n2bpp. CGA Image.\n4bpp. Minimun for VGA standard.\n8bpp. Super-VGA image.\n24bpp. Truecolor image.\n48bpp. Professional-level images.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhttps://www.researchgate.net/figure/Digital-image-representation-by-pixels-vii_fig2_311806469\n\n\n\n\n\n\n\n\n\nTipColor Space\n\n\n\nHow can i represent the color\n\nRGB.\nCMYK.\nHSV.\nCieLab\nAmong others.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"image01.tif\")\nfig001 = plt.figure()\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\n\n\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg = cv2.imread(image_path+\"lena.tif\")\nRGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nfig002 = plt.figure()\nplt.imshow(RGB_img)\n\n\n\n\n\n\n\nThe paradigm surrounding the conceptualization of light and perception has undergone significant evolution.\nInitially, the prevailing understanding within humanity posited that visual stimuli emanated from the eye itself.\nHowever, contemporary knowledge has elucidated that light originates from external sources, undergoes reflection from objects within the environment, and is subsequently captured by the eye.\n\n\n\n\n\n\n\n\n\n\nNotaImportant\n\n\n\nWe also understand that light is a type of electromagnetic radiation, and its wavelength falls within a range from 400 nanometers to 700 nanometers.\n\n\n\n\n\nTaken from Corke 2023\n\n\n\n\n\n\n\n\n\n\n\nNotaImportant\n\n\n\n\nThe most common way light is made is by something getting really hot. This makes energy that comes out as light.\nSome important term are:\n\nAbsortion: It is the fraction of light which a body absorbs depending on the wavelength.\nReflectance: It is the fraction of the incoming light which a body reflects. It’s a number between 0 to 1 and also depends on wavelength.\nLuminance: It is the fraction of the incoming light which a surface reflects. It’s a function of absortion and reflectance, and because of that luminance depends on wavelength.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipThe eye\n\n\n\n\nOur eye has two types of cells. Cones and Rods.\nCones are the most sensitive cells but above all these are color sensitive.\nRods responds only two intensity and they used on night, mostly.\nHumans, like most primates, are trichomats. This means that humans have three types of cones (Long, Medium and shorts).\n\n65% of longs (Sense red)\n33% of mediums (Sense green)\n2% of shortsv(Sense blue)\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipThe artificial eye\n\n\n\n\n\n\nTaken from Corke 2023\n\n\n\n\nThe currents from each sensor are function of the luminance and the spectral response filter.\n\n\n\n\n\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf\n\n\n\n\n\n\n\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf\n\n\n\n\n\n\n\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf\n\n\n\n\n\n\n\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf\n\n\n\n\n\n\n\n\nTaken from https://web.stanford.edu/class/cs231a/course_notes/01-camera-models.pdf\n\n\n\n\n\n\n\n\n\n\n\nTipDefinition\n\n\n\nSampling: Digitalization of the spatial coordinates.\n\n\n\n\n\n\n\n\nTipDefinition\n\n\n\nQuantiazation: Digitalization of the light intensity (amplitude).\n\n\n\n\n\n\n\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1bit\n\n\n\n\n\n\n\n\n\n2bit\n\n\n\n\n\n\n\n\n\n3bit\n\n\n\n\n\n\n\n\n\n4bit\n\n\n\n\n\n\n\n\n\n\n\n5bit\n\n\n\n\n\n\n\n\n\n6bit\n\n\n\n\n\n\n\n\n\n7bit\n\n\n\n\n\n\n\n\n\n8bit\n\n\n\n\n\n\n\n\n\n\n\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\n\n\nTipFrom normal to linear\n\n\n\n\\[\\alpha = My+x\\]\n\n\n\n\n\n\n\n\n\nTipFrom linear to normal\n\n\n\n\\[x = \\alpha \\bmod M\\]\n\\[y = \\frac{\\alpha - x}{M}\\]\n\n\n\n\n\n\n\n\n\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\nTomado de Gonzalez, Rafael C., y Richard E. Woods. 2018. Digital Image Processing. New York, NY: Pearson.\n\n\n\n\n\n\n\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f\n\n\n\n\n\n\n\n\nTomado de https://medium.com/@abhishekjainindore24/semantic-vs-instance-vs-panoptic-segmentation-b1f5023da39f\n\n\n\n\n\n\n\n\n\n\n\nTipNeighborhood\n\n\n\n\n\n\n\n\n\n\n\nN4\n\n\n\n\n\n\n\nND\n\n\n\n\n\n\n\nN8\n\n\n\n\n\n\nFigura 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipNeighborhood\n\n\n\n\n\n\n\n\n\n\n\nN4-\\(N_4\\left(p\\right)\\)\n\n\n\n\n\n\n\nND-\\(N_D\\left(p\\right)\\)\n\n\n\n\n\n\n\nN8-\\(N_8\\left(p\\right)\\)\n\n\n\n\n\n\nFigura 2: Neighborhoods\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipRules for adjecency\n\n\n\n\n4-Adjecncy: Two pixels p and q with values from V are 4-adjacent if q is in the set \\(N_4\\left(p\\right)\\)\n8-adjacency. Two pixels p and q with values from V are 8-adjacent if q is in the set \\(N_8\\left(p\\right)\\)\nm-adjacency (also called mixed adjacency). Two pixels p and q with values from V are m-adjacent if:\n\nq is in \\(N_4\\left(p\\right)\\).\nq is in \\(N_D\\left(p\\right)\\) and the set \\(N_4\\left(p\\right) \\cap N_4\\left(q\\right)\\) has no pixels whose values are from V.\n\n\n\n\n\n\n\n\n\n\nAdjacency\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA4\n\n\n\n\n\n\n\n\n\n\n\nA8\n\n\n\n\n\n\n\n\n\n\n\n\n\nA-m\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipDigital path\n\n\n\nIt is a sequence of adjacent pixels.\n\\[\\left(x_0, y_0\\right), \\left(x_1, y_1\\right), \\left(x_2, y_2\\right), \\dots \\left(x_n, y_n\\right)\\]\nIf \\(\\left(x_0, y_0\\right)=\\left(x_n, y_n\\right)\\) the path is known as closed path\nLet S represent a subset of pixels in an image. Two pixels p and q are said to be connected in S if there exists a path between them consisting entirely of pixels in S.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipDistance\n\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipDistance\n\n\n\n\n\n\n\n\n\n\n\n\nCity block distance: \\(D_4\\left(p,q\\right) = \\lvert x-u\\rvert + \\lvert y-v \\rvert\\)\nChessboard distance: \\(D_8\\left(p,q\\right) = max \\left(\\lvert x-u\\rvert , \\lvert y-v \\rvert \\right)\\)\nEuclidean distance: \\(D_e\\left(p,q\\right) = \\sqrt{\\left(x-u\\right)^2 + \\left(y-v\\right)^2}\\)"
  }
]