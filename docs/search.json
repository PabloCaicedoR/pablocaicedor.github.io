[
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "",
    "text": "Nota: Documento en formato Quarto listo para renderizar a HTML (quarto render). Incluye respuestas correctas y una explicación breve por ítem."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-1",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "1 Pregunta 1",
    "text": "1 Pregunta 1\nEnunciado resumido: Sea \\(y(t)=x(3-1{,}5\\,t)\\). Sobre la relación temporal entre \\(x(t)\\) y \\(y(t)\\), marca las correctas.\nRespuestas correctas: A, B, D, E.\nExplicación\nEscribimos \\(y(t)=x(3-1{,}5\\,t)=x\\big(-1{,}5\\,(t-2)\\big)\\).\n- A: Verdadera, es la misma forma \\(x\\big(-1{,}5\\,(t-2)\\big)\\).\n- B: Verdadera, el factor negativo implica inversión temporal (time-reversal).\n- C: Falsa, no es solo desplazamiento; hay inversión y escala temporal.\n- D: Verdadera, al comprimir en el tiempo por \\(|a|=1{,}5\\) la frecuencia aparente se multiplica por 1,5.\n- E: Verdadera, \\(|a|=1{,}5&gt;1\\) implica compresión temporal por 1,5 (la señal “va más rápido”)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-2",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "2 Pregunta 2",
    "text": "2 Pregunta 2\nEnunciado: \\(x(t)=\\cos\\big(2\\pi\\frac{12}{5}t\\big)+\\sin\\big(2\\pi\\frac{7}{3}t\\big)\\). Periodicidad en TC.\nRespuestas correctas: B, D, E.\nExplicación\nLas frecuencias son \\(f_1=12/5\\) y \\(f_2=7/3\\). La razón \\(f_1/f_2=(12/5)/(7/3)=36/35\\) es racional, por tanto la suma es periódica en TC.\nLos periodos individuales: \\(T_1=5/12\\) y \\(T_2=3/7\\). El periodo fundamental conjunto cumple \\(36T_1=35T_2=15\\text{s}\\).\n- A: Falsa, sí comparten múltiplos enteros.\n- B: Verdadera, al cambiar \\(12/5\\) por \\(12/5+1/\\pi\\) la razón de frecuencias típicamente deja de ser racional \\(\\Rightarrow\\) no periódica.\n- C: Falsa, sumar un DC no rompe la periodicidad.\n- D: Verdadera, \\(T_0=15\\text{s}\\) es un periodo fundamental posible.\n- E: Verdadera, todo múltiplo entero de \\(15\\text{s}\\) también es periodo."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-3",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "3 Pregunta 3",
    "text": "3 Pregunta 3\nEnunciado: \\(x[n]=\\sin\\big(\\frac{5\\pi}{14}n\\big)+\\cos\\big(\\frac{3\\pi}{7}n+\\frac{\\pi}{6}\\big)\\). Periodicidad en TD.\nRespuestas correctas: A, D, E.\nExplicación\nPara \\(\\sin(\\Omega n)\\) o \\(\\cos(\\Omega n+\\phi)\\) hay periodicidad si \\(\\Omega/2\\pi\\) es racional.\n- \\(\\Omega_1=5\\pi/14=(5/28)\\,2\\pi\\Rightarrow N_1=28\\).\n- \\(\\Omega_2=3\\pi/7=(3/14)\\,2\\pi\\Rightarrow N_2=14\\).\nEl periodo conjunto es \\(\\mathrm{{lcm}}(28,14)=28\\). La fase no altera la periodicidad.\n- A: Verdadera, \\(N_0=28\\).\n- B: Falsa, cambiar \\(\\pi/6\\) no rompe periodicidad.\n- C: Falsa, \\(\\sin(5\\pi/14\\,n)\\) sigue siendo periódica por sí sola.\n- D: Verdadera, al sumar \\(\\sin(\\pi/3\\,n)\\) (periodo 6), el conjunto sigue siendo periódico con \\(N_0=\\mathrm{{lcm}}(28,6)=84\\).\n- E: Verdadera, el término coseno tiene periodo 14."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-4",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "4 Pregunta 4",
    "text": "4 Pregunta 4\nEnunciado: Sea \\(x(t)=x_p(t)+x_i(t)\\) con \\(x_p\\) par y \\(x_i\\) impar. Defínase\n\\[ y(t)=x_p(t+1)\\,x_i(t-1)+\\frac{d}{dt}x_i(t). \\]\nRespuestas correctas: B, C, D, E.\nExplicación\n- Un desplazamiento rompe la paridad: \\(x_p(t+1)\\) y \\(x_i(t-1)\\) son, en general, ni pares ni impares (\\(\\Rightarrow\\) B verdadera).\n- El producto \\(x_p(t+1)\\,x_i(t-1)\\) no resulta ni par ni impar en general (no es impar) (\\(\\Rightarrow\\) A falsa).\n- Si se cambiara el segundo término por $ frac{d}{dt}x_p(t)$ (derivada de función par), ésta es impar; sumada con un término “ni par ni impar” el total puede seguir siendo “ni par ni impar” (\\(\\Rightarrow\\) C verdadera).\n- La derivada de una función impar es par (\\(\\Rightarrow\\) E verdadera).\n- Suma de un término “ni par ni impar” con un término par da, en general, una función ni par ni impar (\\(\\Rightarrow\\) D verdadera)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-5",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#pregunta-5",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "5 Pregunta 5",
    "text": "5 Pregunta 5\nEnunciado: Tres pulsos con solapamiento\n- Pulso 1: amplitud \\(2\\), de \\(t=0{,}8\\) a \\(1{,}4\\).\n- Pulso 2: amplitud \\(1{,}5\\), de \\(t=1{,}2\\) a \\(1{,}8\\).\n- Pulso 3: amplitud \\(-1\\), de \\(t=1{,}6\\) a \\(2{,}0\\).\nSea \\(v(t)\\) la suma. Representación con \\(u(t)\\) y propiedades.\nRespuestas correctas: B, C, D, E.\nExplicación\n- Alturas por intervalos:\n- \\(0{,}8-1{,}2\\): \\(2\\)\n- \\(1{,}2-1{,}4\\): \\(2+1{,}5=3{,}5\\) (máximo)\n- \\(1{,}4-1{,}6\\): \\(1{,}5\\)\n- \\(1{,}6-1{,}8\\): \\(1{,}5-1=0{,}5\\)\n- \\(1{,}8-2{,}0\\): \\(-1\\)\nPor tanto A es falsa (el máximo \\(3{,}5\\) ocurre en \\(1{,}2-1{,}4\\)).\n- Forma por escalones:\n\\[ v(t)=2[u(t-0{,}8)-u(t-1{,}4)]+1{,}5[u(t-1{,}2)-u(t-1{,}8)]- [u(t-1{,}6)-u(t-2{,}0)], \\]\nequivalente a la suma de saltos en \\(t_k\\in\\{0{,}8,1{,}2,1{,}4,1{,}6,1{,}8,2{,}0\\}\\) con amplitudes \\(\\{+2,+1{,}5,-2,-1,-1{,}5,+1\\}\\).\nAsí, B, C y D son verdaderas.\n- Área total (linealidad del integral):\n\\[ \\int v(t)\\,dt=2\\cdot0{,}6+1{,}5\\cdot0{,}6-1\\cdot0{,}4=1{,}7, \\]\nindependiente del solapamiento (\\(\\Rightarrow\\) E verdadera)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#resumen-de-respuestas-clave",
    "href": "recursos/documentos/examenesResueltos/SYSBP1S2025_2.html#resumen-de-respuestas-clave",
    "title": "SYSB — Primer Parcial Supletorio 2025: Solución explicada",
    "section": "6 Resumen de respuestas (clave)",
    "text": "6 Resumen de respuestas (clave)\n\nP1: A, B, D, E\n\nP2: B, D, E\n\nP3: A, D, E\n\nP4: B, C, D, E\n\nP5: B, C, D, E"
  },
  {
    "objectID": "proyectos/Sabana/fileProof.html",
    "href": "proyectos/Sabana/fileProof.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport scipy.io as sio\nimport scipy.signal as sig\nfrom scipy.signal import tf2zpk\nfrom scipy.spatial.transform import Rotation as R\n\npath_ecg = \"../../data\"\n\n\ndef plot_imu_frame(axis_length=1.0, arrow_ratio=0.1):\n    \"\"\"\n    Dibuja el sistema de coordenadas de una IMU en 3D.\n\n    Parámetros:\n    - axis_length: longitud de cada eje.\n    - arrow_ratio: fracción del eje destinada a la cabeza de la flecha.\n    \"\"\"\n    # Creamos la figura y el eje 3D\n    fig = plt.figure(figsize=(6, 6))\n    ax = fig.add_subplot(111, projection=\"3d\")\n\n    # Origen de los ejes\n    origin = np.array([0, 0, 0])\n\n    # Vectores unitarios para X, Y, Z\n    axes = np.eye(3) * axis_length\n    colors = [\"r\", \"g\", \"b\"]\n    labels = [\"N\", \"Y\", \"-g\"]\n\n    # Dibujar cada eje con quiver (flecha)\n    for vec, c, lab in zip(axes, colors, labels):\n        ax.quiver(\n            origin[0],\n            origin[1],\n            origin[2],\n            vec[0],\n            vec[1],\n            vec[2],\n            color=c,\n            arrow_length_ratio=arrow_ratio,\n            linewidth=2,\n        )\n        # Etiquetar el extremo del eje\n        ax.text(\n            vec[0] * 1.05,\n            vec[1] * 1.05,\n            vec[2] * 1.05,\n            lab,\n            color=c,\n            fontsize=14,\n            fontweight=\"bold\",\n        )\n\n    # Ajustes de estilo\n    ax.set_xlim(0, axis_length * 1.2)\n    ax.set_ylim(0, axis_length * 1.2)\n    ax.set_zlim(0, axis_length * 1.2)\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n    ax.set_zlabel(\"Z\")\n    ax.set_title(\"Sistema de coordenadas IMU\")\n    ax.grid(True)\n\n    # Mostrar proporción igual para los tres ejes\n    ax.set_box_aspect([1, 1, 1])\n\n    plt.tight_layout()\n    plt.show()\n\n\ndef calcular_relacion_romberg(\n    param_eyes_open: float,\n    param_eyes_close: float,\n) -&gt; float:\n    return param_eyes_close / param_eyes_open\n\n\ndef calcular_rms(signal1):\n    return np.sqrt(np.mean(np.square(signal1)))\n\n\ndef calcular_magnitud_angular_velocity(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleración global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Gyr_Global_Mag\"] = np.sqrt(\n        df[\"Gyr_X_global\"] ** 2 + df[\"Gyr_Y_global\"] ** 2 + df[\"Gyr_Z_global\"] ** 2\n    )\n    return df.copy()\n\n\ndef calcular_magnitud_aceleracion_local(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleración global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Acc_Local_Mag\"] = np.sqrt(df[\"Acc_Y\"] ** 2 + df[\"Acc_Z\"] ** 2)\n    return df.copy()\n\n\ndef calcular_magnitud_aceleracion(df):\n    \"\"\"\n    Calcula la magnitud del vector de aceleración global y la agrega al DataFrame.\n    \"\"\"\n    df[\"Acc_Global_Mag\"] = np.sqrt(df[\"Acc_X_global\"] ** 2 + df[\"Acc_Y_global\"] ** 2)\n    return df.copy()\n\n\ndef CalculateGlobalVectors(df):\n    # Cuaterniones y aceleración local\n    quaternions = df[[\"Quat_q0\", \"Quat_q1\", \"Quat_q2\", \"Quat_q3\"]].values\n    acc_local = df[[\"Acc_X\", \"Acc_Y\", \"Acc_Z\"]].values\n    ang_vel_local = df[[\"Gyr_X\", \"Gyr_Y\", \"Gyr_Z\"]].values\n\n    sig_filtersos = sig.butter(10, 4, \"low\", fs=100, output=\"sos\")\n\n    # Aplicar filtro a las columnas de aceleración\n    acc_local = sig.sosfilt(sig_filtersos, acc_local)\n    ang_vel_local = sig.sosfilt(sig_filtersos, ang_vel_local)\n    df[[\"Acc_X\", \"Acc_Y\", \"Acc_Z\"]] = acc_local\n    df[[\"Gyr_X\", \"Gyr_Y\", \"Gyr_Z\"]] = ang_vel_local\n\n    # Rotar aceleraciones al sistema global\n    rot = R.from_quat(quaternions)\n    acc_global = rot.apply(acc_local)\n    ang_vel_global = rot.apply(ang_vel_local)\n\n    # 🔁 Normalizar Y y Z a máximo absoluto de 1\n    # acc_global[:, 1] = acc_global[:, 1] / np.max(np.abs(acc_global[:, 1]))\n    # acc_global[:, 2] = acc_global[:, 2] / np.max(np.abs(acc_global[:, 2]))\n\n    # Guardar aceleraciones normalizadas\n    df[\"Acc_X_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 0])\n    df[\"Acc_Y_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 1])\n    df[\"Acc_Z_global\"] = sig.sosfilt(sig_filtersos, acc_global[:, 2])\n    df[\"Gyr_X_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 0])\n    df[\"Gyr_Y_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 1])\n    df[\"Gyr_Z_global\"] = sig.sosfilt(sig_filtersos, ang_vel_global[:, 2])\n    return df.copy()\n\n\ndef select_mid_segment(\n    df: pd.DataFrame,\n    time_col: str = \"Time\",\n    half_length: float = 10.0,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Selecciona el segmento de df que comprende `pre_sec` segundos\n    antes y `post_sec` segundos después del punto medio de la serie\n    temporal indicada por `time_col`.\n\n    Parámetros\n    ----------\n    df : pd.DataFrame\n        DataFrame que debe contener la columna de tiempo `time_col`.\n    time_col : str\n        Nombre de la columna de tiempo (en segundos).\n    pre_sec : float\n        Segundos a incluir antes del punto medio.\n    post_sec : float\n        Segundos a incluir después del punto medio.\n\n    Devuelve\n    -------\n    pd.DataFrame\n        Sub-DataFrame con las mismas columnas que `df`, filtrado\n        para el intervalo [midpoint - pre_sec, midpoint + post_sec].\n    \"\"\"\n    # Calcular extremo inferior y superior del tiempo\n    t_min = df[time_col].min()\n    t_max = df[time_col].max()\n    midpoint = (t_min + t_max) / 2\n\n    start_time = midpoint - half_length\n    end_time = midpoint + half_length\n\n    # Filtrar el DataFrame por el rango de tiempo\n    segment = df[(df[time_col] &gt;= start_time) & (df[time_col] &lt;= end_time)].copy()\n\n    return segment\n\n\ndataDualTask = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/dt_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeClosed = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/ec_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeOpen = pd.read_csv(\n    \"data/BalanceAssessment/KMartinez/Xsens/TUG/eo_01_01200628_000-000.txt\",\n    sep=\"\\t\",\n    skiprows=12,\n)\ndataEyeClosed = dataEyeClosed.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\ndataDualTask = dataDualTask.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\ndataEyeOpen = dataEyeOpen.drop(columns=[\"PacketCounter\", \"SampleTimeFine\"])\nfs = 100\nTs = 1 / fs\ndataEyeOpen[\"Time\"] = Ts * np.arange(0, len(dataEyeOpen))\ndataEyeClosed[\"Time\"] = Ts * np.arange(0, len(dataEyeClosed))\ndataDualTask[\"Time\"] = Ts * np.arange(0, len(dataDualTask))\ndataDualTask = CalculateGlobalVectors(dataDualTask)\ndataEyeClosed = CalculateGlobalVectors(dataEyeClosed)\ndataEyeOpen = CalculateGlobalVectors(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_aceleracion(dataDualTask)\ndataEyeClosed = calcular_magnitud_aceleracion(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_aceleracion(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_aceleracion_local(dataDualTask)\ndataEyeClosed = calcular_magnitud_aceleracion_local(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_aceleracion_local(dataEyeOpen)\n\ndataDualTask = calcular_magnitud_angular_velocity(dataDualTask)\ndataEyeClosed = calcular_magnitud_angular_velocity(dataEyeClosed)\ndataEyeOpen = calcular_magnitud_angular_velocity(dataEyeOpen)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import chi2\n\n\ndef ellipse_sway_area(x, y, confidence=0.95, plot=True):\n    \"\"\"\n    Calcula el área y dibuja la elipse de oscilación para los datos (x,y)\n    cubriendo el porcentaje de confianza dado (p.ej. 0.95 para 95%).\n\n    Parámetros:\n    - x, y: arrays de coordenadas (misma longitud).\n    - confidence: nivel de confianza (entre 0 y 1).\n    - plot: si True, dibuja los puntos y la elipse.\n\n    Retorna:\n    - area: área de la elipse.\n    - width, height: semiejes mayor y menor.\n    - angle: ángulo de rotación en grados.\n    \"\"\"\n    # Centro (media)\n    mu = np.array([np.mean(x), np.mean(y)])\n    # Matriz de covarianza\n    cov = np.cov(x, y)\n    # Eigenvalores y eigenvectores\n    vals, vecs = np.linalg.eigh(cov)\n    # Ordenar de mayor a menor\n    order = vals.argsort()[::-1]\n    vals = vals[order]\n    vecs = vecs[:, order]\n\n    # Factor de escala: chi-cuadrado inverso para 2 grados y nivel dado\n    chi2_val = chi2.ppf(confidence, df=2)\n    # Semiejes\n    a = np.sqrt(vals[0] * chi2_val)\n    b = np.sqrt(vals[1] * chi2_val)\n    area = np.pi * a * b\n\n    # Ángulo de rotación (en grados) del semieje mayor respecto al eje X\n    angle = np.degrees(np.arctan2(vecs[1, 0], vecs[0, 0]))\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(6, 6))\n        ax.scatter(x, y, s=10, alpha=0.5, label=\"Datos\")\n        # Dibujo de la elipse\n        from matplotlib.patches import Ellipse\n\n        ellipse = Ellipse(\n            xy=mu,\n            width=2 * a,\n            height=2 * b,\n            angle=angle,\n            edgecolor=\"r\",\n            facecolor=\"none\",\n            lw=2,\n            label=f\"{int(confidence*100)}% Elipse\",\n        )\n        ax.add_patch(ellipse)\n        ax.set_aspect(\"equal\")\n        ax.set_xlabel(\"X\")\n        ax.set_ylabel(\"Y\")\n        ax.set_title(\n            f\"Elipse de oscilación ({int(confidence*100)}% conf.)\\nÁrea = {area:.2f}\"\n        )\n        ax.legend()\n        plt.grid(True)\n        plt.show()\n\n    return area, a, b, angle\n\n\n# Ejemplo de uso:\nif __name__ == \"__main__\":\n    # Simulamos datos de sway\n    np.random.seed(0)\n    x = np.random.normal(0, 1, size=500)\n    y = 0.5 * x + np.random.normal(0, 0.8, size=500)\n\n    area, a, b, angle = ellipse_sway_area(\n        dataDualTask[\"Acc_X_global\"], dataDualTask[\"Acc_Y_global\"], confidence=0.95\n    )\n    print(f\"Área de la elipse al 95 %: {area:.4f}\")\n    print(f\"Semiejes: a={a:.2f}, b={b:.2f}, ángulo={angle:.1f}°\")\n\n\n\n\n\n\n\n\nÁrea de la elipse al 95 %: 0.0000\nSemiejes: a=0.00, b=0.00, ángulo=67.1°\n\n\n\nrmsAccX_eo = calcular_rms(dataEyeOpen[\"Acc_X_global\"])\nrmsAccY_eo = calcular_rms(dataEyeOpen[\"Acc_Y_global\"])\nrmsAccZ_eo = calcular_rms(dataEyeOpen[\"Acc_Z_global\"])\n\nrmsGyrX_eo = calcular_rms(dataEyeOpen[\"Gyr_X_global\"])\nrmsGyrY_eo = calcular_rms(dataEyeOpen[\"Gyr_Y_global\"])\nrmsGyrZ_eo = calcular_rms(dataEyeOpen[\"Gyr_Z_global\"])\n\npathTrajectAcc_eo = np.sum(dataEyeOpen[\"Acc_Local_Mag\"])\nareaAcc_eo, a, b, angle = ellipse_sway_area(\n    dataEyeOpen[\"Acc_X_global\"],\n    dataEyeOpen[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\n\nrmsAccX_ec = calcular_rms(dataEyeClosed[\"Acc_X_global\"])\nrmsAccY_ec = calcular_rms(dataEyeClosed[\"Acc_Y_global\"])\nrmsAccZ_ec = calcular_rms(dataEyeClosed[\"Acc_Z_global\"])\n\nrmsGyrX_ec = calcular_rms(dataEyeClosed[\"Gyr_X_global\"])\nrmsGyrY_ec = calcular_rms(dataEyeClosed[\"Gyr_Y_global\"])\nrmsGyrZ_ec = calcular_rms(dataEyeClosed[\"Gyr_Z_global\"])\n\npathTrajectAcc_ec = np.sum(dataEyeClosed[\"Acc_Local_Mag\"])\nareaAcc_ec, a, b, angle = ellipse_sway_area(\n    dataEyeClosed[\"Acc_X_global\"],\n    dataEyeClosed[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\n\nrmsAccX_dt = calcular_rms(dataDualTask[\"Acc_X_global\"])\nrmsAccY_dt = calcular_rms(dataDualTask[\"Acc_Y_global\"])\nrmsAccZ_dt = calcular_rms(dataDualTask[\"Acc_Z_global\"])\n\nrmsGyrX_dt = calcular_rms(dataDualTask[\"Gyr_X_global\"])\nrmsGyrY_dt = calcular_rms(dataDualTask[\"Gyr_Y_global\"])\nrmsGyrZ_dt = calcular_rms(dataDualTask[\"Gyr_Z_global\"])\n\npathTrajectAcc_dt = np.sum(dataDualTask[\"Acc_Local_Mag\"])\nareaAcc_dt, a, b, angle = ellipse_sway_area(\n    dataDualTask[\"Acc_X_global\"], dataDualTask[\"Acc_Y_global\"], confidence=0.95,plot=False\n)\n\n\nrmsAccX_dt = calcular_rms(dataDualTask[\"Acc_X_global\"])\nrmsAccY_dt = calcular_rms(dataDualTask[\"Acc_Y_global\"])\nrmsAccZ_dt = calcular_rms(dataDualTask[\"Acc_Z_global\"])\n\nrmsGyrX_dt = calcular_rms(dataDualTask[\"Gyr_X_global\"])\nrmsGyrY_dt = calcular_rms(dataDualTask[\"Gyr_Y_global\"])\nrmsGyrZ_dt = calcular_rms(dataDualTask[\"Gyr_Z_global\"])\n\npathTrajectAcc_dt = np.sum(dataDualTask[\"Acc_Local_Mag\"])\nareaAcc_dt, a, b, angle = ellipse_sway_area(\n    dataDualTask[\"Acc_X_global\"],\n    dataDualTask[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\nrmsAccX_ec = calcular_rms(dataEyeClosed[\"Acc_X_global\"])\nrmsAccY_ec = calcular_rms(dataEyeClosed[\"Acc_Y_global\"])\nrmsAccZ_ec = calcular_rms(dataEyeClosed[\"Acc_Z_global\"])\n\nrmsGyrX_ec = calcular_rms(dataEyeClosed[\"Gyr_X_global\"])\nrmsGyrY_ec = calcular_rms(dataEyeClosed[\"Gyr_Y_global\"])\nrmsGyrZ_ec = calcular_rms(dataEyeClosed[\"Gyr_Z_global\"])\n\npathTrajectAcc_ec = np.sum(dataEyeClosed[\"Acc_Local_Mag\"])\nareaAcc_ec, a, b, angle = ellipse_sway_area(\n    dataEyeClosed[\"Acc_X_global\"],\n    dataEyeClosed[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)\n\nrmsAccX_eo = calcular_rms(dataEyeOpen[\"Acc_X_global\"])\nrmsAccY_eo = calcular_rms(dataEyeOpen[\"Acc_Y_global\"])\nrmsAccZ_eo = calcular_rms(dataEyeOpen[\"Acc_Z_global\"])\n\nrmsGyrX_eo = calcular_rms(dataEyeOpen[\"Gyr_X_global\"])\nrmsGyrY_eo = calcular_rms(dataEyeOpen[\"Gyr_Y_global\"])\nrmsGyrZ_eo = calcular_rms(dataEyeOpen[\"Gyr_Z_global\"])\n\npathTrajectAcc_eo = np.sum(dataEyeOpen[\"Acc_Local_Mag\"])\nareaAcc_eo, a, b, angle = ellipse_sway_area(\n    dataEyeOpen[\"Acc_X_global\"],\n    dataEyeOpen[\"Acc_Y_global\"],\n    confidence=0.95,\n    plot=False,\n)"
  },
  {
    "objectID": "clases/talleres.html",
    "href": "clases/talleres.html",
    "title": "Talleres",
    "section": "",
    "text": "Taller Primer Semestre"
  },
  {
    "objectID": "clases/Class_PSIM.html",
    "href": "clases/Class_PSIM.html",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "",
    "text": "“Un área de rápido crecimiento y variedad de aplicaciones en la ingeniería biomédica a nivel nacional y global es el procesamiento digital de señales e imágenes médicas. Es por eso, que a través de este curso se desea dar las herramientas necesarias para los graduados del programa puedan tener competencias básicas en las técnicas clásicas y algunas técnicas modernas de procesamiento de señales e imágenes. La primera parte del curso se encuentra enfocada al desarrollo de técnicas de procesamiento para señales biomédicas unidimensionales, exponiendo primero su origen fisiológico y siguiendo con la presentación de las principales técnicas para su análisis y procesamiento. La segunda parte del curso hace énfasis en el estudio de imágenes médicas, partiendo de una explicación de los principales métodos computacionales utilizados para procesamiento digital de imágenes y luego exponiendo brevemente el proceso de su formación. A través de prácticas de laboratorio con señales e imágenes médicas (reales o simuladas), el estudiante podrá aplicar y reforzar los conocimientos aprendidos en el curso” fragmento tomado del microcurriculo de la asignatura.\nEl curso está dividido en 4 partes:\n1. Introducción al procesado de señales e imágenes biomédicas.\n2. Fundamentos procesado de señales e imágenes biomédicas\n3. Extracción de características de señales biomédicas.\n4. Extracción de características de imágenes biomédicas."
  },
  {
    "objectID": "clases/Class_PSIM.html#presentaciones",
    "href": "clases/Class_PSIM.html#presentaciones",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción\nIntroducción al procesamiento de imagenes\nLa imagen digital. Procesamiento de Imágenes 1/4\nLa imagen digital. Procesamiento de Imágenes 2/4\nRespuesta en frecuencia. (3/4)\nWavelets 4/4"
  },
  {
    "objectID": "clases/Class_PSIM.html#datos",
    "href": "clases/Class_PSIM.html#datos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_PSIM.html#códigos",
    "href": "clases/Class_PSIM.html#códigos",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_PSIM.html#laboratorios",
    "href": "clases/Class_PSIM.html#laboratorios",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio 01\nLaboratorio 02"
  },
  {
    "objectID": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "href": "clases/Class_PSIM.html#talleres-examenes-anteriores",
    "title": "Procesado de Señales e Imágenes Médicas",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nPrimer Parcial\nSegundo Parcial\nTercer Parcial"
  },
  {
    "objectID": "clases/Class_ASIM.html",
    "href": "clases/Class_ASIM.html",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "",
    "text": "Aprender procesamiento de señales e imágenes con aprendizaje automático en medicina es crucial para mejorar la precisión y eficiencia en el diagnóstico y tratamiento de enfermedades. El aprendizaje automático permite analizar grandes cantidades de datos de imágenes médicas y señales biomédicas, como rayos X, tomografías computarizadas, resonancia magnética, ECG, EEG y EMG, para identificar patrones y anomalías que pueden indicar la presencia de enfermedades. Esto puede llevar a un diagnóstico más preciso y temprano, lo que a su vez puede mejorar los resultados para los pacientes y reducir la morbilidad y mortalidad.\nAdemás, el aprendizaje automático puede ayudar a personalizar tratamientos para pacientes individuales según sus características únicas de imágenes médicas y señales. También puede automatizar tareas clínicas rutinarias, como segmentación de imágenes, extracción de características y análisis de datos, lo que permite a los médicos centrarse en la toma de decisiones de alto nivel.\nLa aplicación del aprendizaje automático en medicina también puede facilitar la investigación médica, analizando grandes conjuntos de datos para identificar tendencias y patrones que pueden revelar nuevos conocimientos sobre enfermedades y tratamientos. Además, puede permitir la monitorización remota de pacientes y la telemedicina, ampliando el acceso a servicios de atención médica."
  },
  {
    "objectID": "clases/Class_ASIM.html#presentaciones",
    "href": "clases/Class_ASIM.html#presentaciones",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nLect002: Introducción al Machine Learning\nLect003: Introducción al Machine Learning\nLect004: Neural Network\nLect005: CNN"
  },
  {
    "objectID": "clases/Class_ASIM.html#laboratorios",
    "href": "clases/Class_ASIM.html#laboratorios",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLab00: Conducta de entrada\nLab01: Programación orientada a objetos\nSolución Lab01: Programación orientada a objetos\nLab02: Regresión lineal\nLab:03 Red Neuronal"
  },
  {
    "objectID": "clases/Class_ASIM.html#clases",
    "href": "clases/Class_ASIM.html#clases",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Clases",
    "text": "Clases\nSábado 7:00am-8:30am I1-304."
  },
  {
    "objectID": "clases/Class_ASIM.html#laboratorio",
    "href": "clases/Class_ASIM.html#laboratorio",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Laboratorio",
    "text": "Laboratorio\nSábado 8:30am-10:00am I1-304."
  },
  {
    "objectID": "clases/Class_ASIM.html#atención-a-estudiantes",
    "href": "clases/Class_ASIM.html#atención-a-estudiantes",
    "title": "Aprendizaje automático para el procesamiento de señales e imágenes médicas",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "href": "rubricas/Rubrica_ProyectoFinal_apsb_Planteamiento.html",
    "title": "Proyecto Final: APSB1",
    "section": "",
    "text": "Criterio\n1 - Deficiente\n2 - Insuficiente\n3 - Aceptable\n4 - Bueno\n5 - Excelente\nPonderación\n\n\n\n\nDefinición del Problema y Justificación\nNo se identifica un problema biomédico claro.\nSe identifica un problema, pero sin relevancia biomédica o justificación.\nSe plantea un problema relevante con justificación básica.\nProblema bien definido con referencias científicas.\nProblema biomédico bien formulado, con justificación sólida basada en literatura científica.\n15%\n\n\nAdquisición y Procesamiento de Datos en el Borde\nNo se especifica el tipo de datos ni sensores.\nSe mencionan sensores, pero sin detalles sobre la captura y preprocesamiento.\nSe describe la adquisición de datos con procesamiento básico.\nSe justifica la selección de sensores y se menciona un preprocesamiento adecuado.\nSelección óptima de sensores con procesamiento avanzado y justificación técnica detallada.\n20%\n\n\nDesarrollo e Implementación del Modelo de IA\nNo se propone un modelo de IA.\nSe menciona un modelo, pero sin adecuación a Edge AI.\nSe plantea un modelo básico con justificación limitada.\nSe elige un modelo adecuado y optimizado para Edge AI.\nModelo avanzado con técnicas de optimización y justificadas con métricas.\n20%\n\n\nValidación y Pruebas en Tiempo Real\nNo se contempla validación del modelo.\nSe menciona validación, pero sin metodología clara.\nSe plantea una validación con datos simulados.\nSe incluyen pruebas con datos reales y métricas de rendimiento.\nValidación robusta con pruebas extensivas y comparación con estándares biomédicos.\n20%\n\n\nEscalabilidad y Aplicabilidad en la Industria Biomédica\nNo se considera la escalabilidad del proyecto.\nSe menciona la escalabilidad, pero sin detalles técnicos.\nSe plantea una estrategia básica de escalabilidad.\nEstrategia clara de implementación y compatibilidad con sistemas médicos.\nProyecto altamente escalable, con integración en entornos clínicos y estándares como HL7 o FHIR.\n15%\n\n\nPresentación y Documentación\nNo hay documentación ni presentación clara.\nDocumentación incompleta o desordenada.\nPresentación básica con documentación limitada.\nPresentación clara y documentada correctamente.\nDocumentación profesional con detalles técnicos y presentación estructurada.\n10%"
  },
  {
    "objectID": "rubricas/Rubrica_EDA.html",
    "href": "rubricas/Rubrica_EDA.html",
    "title": "Rúbrica: Análisis Exploratorio de Datos",
    "section": "",
    "text": "Indicador\nBueno\nSuficiente\nInsuficiente\n\n\n\n\nLimpieza del Dataset\nEl dataset no presenta ni registros nulos, ni vacíos. Existe una estrategia para manejo de atípicos (100%)\nEl dataset no presenta ni registros nulos, ni vacíos (50%)\nEl dataset presenta registros nulos y/o vacíos. No existe una estrategia para manejo de atípicos (0%)\n\n\nConsumo de información\nSe consumen al menos 2 fuentes de datos provenientes de las sugerencias de los organizadores (100%)\nSe consume una fuente de datos proveniente de las sugerencias de los organizadores (50%)\nNo se consume ninguna fuente de datos conocida (0%)\n\n\nEDA sobre nuevas variables\nSe plantean correctamente las relaciones entre la variables y estas se demuestran a plenitud utilizando matemática y/o estadística (100%)\nSe plantean dos relaciones entre las variables (50%)\nNo se plantean las relaciones entre las variables (0%)\n\n\nUso de plantilla\nUsan la plantilla rmarkdown (100%)\n\nNo se usa la plantilla rmarkdown(0%)\n\n\nVisualización de la informacion\nLa información de TODAS las gráficas se observa plenamente (100%)\nLa información de las gráficas se observa parcialmente(50%)\nLa información de la gráfica no se observa (0%)\n\n\nJustificación del problema\nExiste una justificación del problema(100%)\n\nNo Existe justificación al problema resuelto (0%)\n\n\nUbicación del problema\nSe plantea correctamente la ubicación del problema 100%\n\nNo se plantea correctamente la ubicación del problema 0%"
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#descripción",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#procedimiento",
    "href": "recursos/talleres/SYSB202501_Sol_TallerRepasoIntroSennales.html.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\nSolución\nSe grafican las transformaciones solicitadas en Python con Matplotlib.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_t(t):\n    return np.piecewise(t, [(-1 &lt;= t) & (t &lt;= 0), (0 &lt; t) & (t &lt;= 2), (2 &lt; t) & (t &lt;= 3)],\n                         [lambda t: t + 1, 2, 1, 0])\n\nt = np.linspace(-2, 4, 1000)\nplt.plot(t, x_t(t), label='x(t)')\nplt.xlabel('t')\nplt.ylabel('x(t)')\nplt.legend()\nplt.show()\n\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\nSolución\nAnalizamos si \\(\\frac{f_0}{f_s}\\) es racional.\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\nPeríodos: \\(T_1 = \\frac{2\\pi}{2} = \\pi\\), \\(T_2 = \\frac{2\\pi}{\\pi} = 2\\)\nMínimo común múltiplo: **Período = 2*\n\n\\(x(t) = e^{-j(4\\pi/3)t} + e^{j(2\\pi/5)t}\\)\n\nSe buscan los períodos fundamentales.\nNo es periódica porque las razones de frecuencias son irracionales.\n\n\n…\n\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nSolución\n\nPeríodo de la señal:\n\nFrecuencias: \\(f_1 = 300Hz\\), \\(f_2 = 240Hz\\)\nMCM de \\(\\frac{1}{300}\\) y \\(\\frac{1}{240}\\) → T = 1/60 s\n\nFrecuencia de muestreo\n\nTeorema de Nyquist: \\(f_s &gt; 2f_{max} = 600Hz\\)\n\nSeñal muestreada:\nfs = 600  # Hz\nn = np.arange(0, 100)\nxa_n = np.sin(600*np.pi*n/fs) + 3*np.sin(480*np.pi*n/fs)\nplt.stem(n, xa_n)\nplt.show()\n\n…\n\n\n\n6. Muestreo y cuantización\n\nSolución\n\nFrecuencia de muestreo:\n\n\\(T_m1 = 12.5ms\\) → \\(f_s = 80Hz\\)\nNo cumple Nyquist → No se puede reconstruir\n\nMuestreo a 8 veces Nyquist:\n\n\\(f_s = 5760Hz\\)\nSe evalúa si \\(\\frac{f_0}{f_s}\\) es racional → Sí es periódica\n\nCuantización (4 bits, rango 0-5):\n\nPaso de cuantización: \\(\\Delta = \\frac{5}{2^4}\\)\nSe discretiza la señal según niveles de cuantización.\n\n\nimport numpy as np\nlevels = np.linspace(0, 5, 16)\nquantized_signal = np.digitize(xa_n, levels) * (5 / 16)\nplt.stem(n, quantized_signal)\nplt.show()\n\nFin del taller."
  },
  {
    "objectID": "recursos/talleres/SYSB/Taller3_2025_1.html",
    "href": "recursos/talleres/SYSB/Taller3_2025_1.html",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Profesores\nJenny Carolina Castiblanco Sánchez\nPablo Eduardo Caicedo Rodríguez\n\n\nDescripción\nA través de este taller se reforzarán los conocimientos en:\n\nTransformada Z\nDiseño, análisis e implementación de filtros digitales FIR e IIR\n\n\n\nProcedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\nTransformada Z y Región de Convergencia\nDetermine la transformada Z y dibuje la ROC de las siguientes señales:\n\n\\(x\\left[n\\right] = =\\begin{cases}\\displaystyle \\left(\\frac{1}{3}\\right)^{n}, & n \\ge 0,\\\\[6pt]\\displaystyle \\left(\\frac{1}{2}\\right)^{-n}, & n &lt; 0.\\end{cases}\\)\n\\(x\\left[n\\right]=\\begin{cases}\\displaystyle \\left(\\frac{1}{3}\\right)^{n}, & n \\ge 5,\\\\[6pt]0, & n &lt; 5.\\end{cases}\\)\n\nRespuesta del Sistema\nDetermine la respuesta del sistema\n\\[\ny\\left[n\\right] \\;=\\; \\frac{5}{6}\\,y\\left[n-1\\right]\\;-\\;\\frac{1}{6}\\,y\\left[n-2\\right]\\;+\\;x\\left[n\\right]\n\\]\nA la señal de entrada\n\\[\nx\\left[n\\right] \\;=\\; \\delta\\left[n\\right]\\;-\\;\\frac{1}{3}\\,\\delta\\left[n-1\\right]\n\\]\nRespuesta del Sistema\nUna señal de entrada ( \\(x[n] = 3^{n}u[-n]\\) ) es aplicada a un sistema LTI discreto con respuesta al impulso ( \\(h[n] = \\left(0.5\\right)^{n}u[n]\\) ).\n\nDetermine la función de transferencia del sistema.\n¿El sistema es estable?\nEncuentre la señal de salida del sistema.\n\nAnálisis de Filtro\nConsidere el filtro\n\\[y\\left[n\\right] \\;=\\; b\\,x\\left[n\\right]\\;-\\;0.65\\,y\\left[n-1\\right]\\]\n\nDetermine (b) de modo que \\(\\lvert H\\left[0\\right] \\lvert \\, = \\, 0\\)\n\nDibuje en el plano (z) el diagrama de polos y ceros. ¿El sistema es estable?\n\nGrafique el diagrama de bloques.\n\n¿Qué tipo de filtro es?\n\nDiseño de Filtro Analógico Muestreado\nLa salida de un sistema LTI está determinada por la ecuación del sistema.\n\\[\ny\\left[n\\right] \\;=\\; x\\left[n\\right]\\;-\\;a\\,y\\left[n-1\\right]\n\\]\nTeniendo en cuenta la función de transferencia, se desea diseñar un filtro con frecuencia de corte de 60 Hz para una señal analógica muestreada a 5 kHz.\n\n¿Qué valor debe tener la variable (a)?\n\n¿Qué tipo de filtro se obtiene?\n\n\n\n\nDiseñar y simular filtros digitales para señales empleando PYTHON.\n\nDiseñar, simular y analizar un filtro pasbajos FIR por el método de ventaneo, con frecuencia de corte de 55Hz a los 6dB, atenuación mínima en 60Hz de 20 dB y atenuación mayor de 40 dB por encima de 80Hz.\n\nDeterminar el mínimo orden del filtro requerido para las siguientes ventanas: Rectangular, triangular, Hann, Hamming, Blackman, Kayser.\nDe los filtros analizados, seleccione el de menor orden que cumpla con las características de diseño.\n\nDiseñar y simular filtros digitales IIR para señales de voz empleando Matlab, analizando las diferentes opciones: Butterworth, Chebyshev, Elíptico.\n\nDiseñar, simular y analizar un filtro pasabajos IIR por el método de transformación de filtros analógicos empleando la transformación bilineal, con las siguientes características: Frecuencia de muestreo, 8 kHz; frecuencia de corte de 3.4 kHz; rizado en la banda de paso, 1 dB; frecuencia de rechazo, 3.8 kHz; atenuación en la banda de rechazo, 30 dB; orden del filtro, mínimo.\nDiseñar, simular y analizar un filtro pasaltos IIR por el método de transformación de filtros analógicos empleando la transformación bilineal, con las siguientes características: Frecuencia de muestreo, 8 kHz; frecuencia de corte de 300 Hz; rizado en la banda de paso, 1 dB; frecuencia de rechazo, 60 Hz; atenuación en la banda de rechazo, 30 dB; orden del filtro, mínimo."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#descripción",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB/SYSB202501_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\n\\(x(t)\\)\n\\(x(t - 2)\\)\n\\(x(2t + 1)\\)\n\\(x(-3t)\\)\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\n\\(x(t) = e^{-j(\\frac{4\\pi}{3})t} + e^{j(\\frac{2\\pi}{5})t}\\)\n\n\\(x(n) = \\cos(n/8) \\cos(\\pi n/8)\\)\n\n\\(x(n) = \\cos(3\\pi n/2) - \\sin(\\frac{\\pi n}{8}) + 3\\cos(\\frac{\\pi n}{4} + \\frac{\\pi}{3})\\)\n\n\n\n3. Demuestre que si \\(x(t)\\) y \\(y(t)\\) son señales impares, entonces:\n\n\\(z(t) = x(t)y(t)\\) es una señal par\n\n\\(g(t) = x(t) + y(t)\\) es una señal impar.\n\nSiendo \\(x(t) = \\sin(t)\\) y \\(y(t) = t\\), grafique en Python \\(z(t)\\) y \\(g(t)\\). ¿Se cumple lo indicado en los numerales a y b?\n\n\n\n4. Encuentre la expresión analítica de las señales mostradas a continuación utilizando funciones \\(u(t)\\) y \\(r(t)\\) (escalón unitario y rampa).\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nIndique si la señal \\(x_a(t)\\) es una señal periódica, en caso afirmativo, indique el periodo de la señal.\n\nFrecuencia de muestreo que cumpla con el teorema de Nyquist.\n\nEncontrar \\(x_a[n]\\) con la frecuencia de muestreo encontrada en el punto anterior.\n\nIndique si la señal \\(x_a[n]\\) es una señal periódica, en caso afirmativo, indique el periodo de la señal.\n\n\n\n6. Considere el sistema de procesamiento de señales mostrado en la figura:\n\nSi la entrada es \\(x_a(t) = 2 \\sin(720\\pi t) + 2\\), encontrar:\n\nLa salida \\(x_a[n]\\) si \\(T_{m1} = 12.5ms\\). ¿Con esta frecuencia se puede reconstruir la señal \\(x_a(t)\\) en \\(y(t)\\) si \\(T_{m2} = T_{m1}\\)? Justifique su respuesta.\n\nLa salida \\(x_a[n]\\) si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¿La señal es periódica en tiempo discreto? Justifique su respuesta.\n\nPara la señal del punto b, encontrar la señal cuantizada de un ciclo de la señal si el tamaño del registro es de 4 bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html",
    "title": "Sampling and quantization",
    "section": "",
    "text": "This guide recaps essentials of sampling and quantization for biomedical acquisition chains. Emphasis is on concrete design choices for $f_s$, anti-alias cutoff, bit depth $b$, and input range, with clinical mini-cases. Primary/secondary sources: Oppenheim 2e (ISBN: 978-0138147570), Shannon 1949 (DOI: 10.1109/JRPROC.1949.232969), Jayant & Noll (ISBN: 0-13-211913-7), Webster MI 4e (ISBN: 978-0471676003).\n\n\n\n\nNyquist: $f_s2B$ where $B$ is the highest significant frequency (Shannon 1949).\nSampling model: $T_s=1/f_s$, $x_s(t)=_{n}x(nT_s),(t-nT_s)$ (Oppenheim 2e).\nAnti-aliasing: analog LPF with $f_c&lt;f_s/2$ plus guard band (Oppenheim 2e).\nQuantizer: uniform, range $[V_{},V_{}]$, step $=$ (Oppenheim 2e).\nNoise model: $_q^2=$; full-scale sine $_{},b+1.76$ (Jayant & Noll).\nCompanding (telemetry): $$-law/$A$-law to emphasize small amplitudes before quantization (Jayant & Noll; ITU-T G.711).\n\n\n\n\nGoal: Choose $f_s$, $f_c$, $b$, and input range for diagnostic ECG.\n\nBandwidth: adopt $B $ (Webster MI 4e).\nSampling: choose $f_s=500 $ to satisfy $f_s2B$ with guard (Shannon 1949).\nAnti-alias: set $f_c $ (transition to $f_s/2=250 $).\nRange: $ $ to cover tall QRS and baseline drift after high-pass.\nBits: $b=12$ is common; compute $$ and SNR below.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nVmin, Vmax = -5e-3, 5e-3\nrng = Vmax - Vmin\nbits = np.arange(10, 17)\nDelta = rng / (2**bits)\nsnr_db = 6.02*bits + 1.76  # full-scale sine (Jayant & Noll)\n\nprint(f\"12-bit Δ = {Delta[bits.tolist().index(12)]:.3e} V ≈ {Delta[bits.tolist().index(12)]*1e6:.2f} μV\")\nprint(f\"Ideal 12-bit SNR ≈ {snr_db[bits.tolist().index(12)]:.1f} dB\")\n\nplt.figure(figsize=(6,4))\nplt.semilogy(bits, Delta*1e6, marker='o')\nplt.xlabel(\"Bit depth b\")\nplt.ylabel(\"Δ (μV)\")\nplt.title(\"ECG step size vs. bit depth (±5 mV)\")\nplt.grid(True, which=\"both\")\nplt.tight_layout()\n\n12-bit Δ = 2.441e-06 V ≈ 2.44 μV\nIdeal 12-bit SNR ≈ 74.0 dB\n\n\n\n\n\nECG: step size and ideal quantization SNR for b=10..16 bits, ±5 mV range.\n\n\n\n\nInterpretation\n\n$b=12$ ⇒ $ $; ideal SNR $ $ (Oppenheim 2e; Jayant & Noll).\nMeets diagnostic needs when analog noise $&lt;$ and front-end avoids clipping (Webster MI 4e).\n\n\n\n\nGoal: Retain spindles/K-complexes without aliasing while maximizing sensitivity.\n\nBandwidth: EEG of interest $35 $; use $B=40 $ (Webster MI 4e).\nSampling: pick $f_s=256 $ (multiple of 2 for decimation) ensuring $f_s2B$ (Shannon 1949).\nAnti-alias: $f_c $ (ample guard to $f_s/2=128 $).\nRange/bits: EEG tens of $$V ⇒ prefer $b$ with programmable gain to use full-scale.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfs = 256\nt = np.arange(0, 2, 1/fs)\nx = 15e-6*np.sin(2*np.pi*10*t)  # 10 Hz alpha-like\ngain_clip = 400000  # too high =&gt; clips ±1 V ADC\ngain_safe = 200000  # safe\n\nadc_fs = 1.0  # ±1 V full-scale\ny_clip = np.clip(gain_clip*x, -adc_fs, adc_fs)\ny_safe = np.clip(gain_safe*x, -adc_fs, adc_fs)\n\nplt.figure(figsize=(6,4))\nplt.plot(t[:400], y_clip[:400], label=\"Clipping\")\nplt.plot(t[:400], y_safe[:400], label=\"Safe gain\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"ADC input (V)\")\nplt.title(\"Clipping risk from aggressive gain (EEG)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n\n\n\nEEG: effect of clipping vs. conservative gain (synthetic 15 μV wave).\n\n\n\n\nTakeaways\n\nUse sufficient gain to exploit full-scale but verify headroom for artifacts.\nClipping breaks linearity assumptions and corrupts morphology (Oppenheim 2e; Webster MI 4e).\n\n\n\n\n\nDesign: A PPG sensor needs $B=25 $. Pick a safe $f_s$ and justify.\n\nSolution: $f_s2B=50$; choose $f_s=200 $ for guard and digital processing overhead (Shannon 1949).\n\nQuantization: For $[V_{},V_{}]=[-2,2] $ and $b=10$, compute $$.\n\nSolution: $==3.90625 $ (Oppenheim 2e).\n\nNoise: With $ $, what is $_q^2$?\n\nSolution: $_q2= 2$ (Oppenheim 2e).\n\nSNR sizing: Target $72 $ for a full-scale sine. Minimum $b$?\n\nSolution: $b$ bits (Jayant & Noll).\n\n\n\n\n\n\nBandwidth $B$: Specify clinically required content (e.g., ECG 0.05–150 Hz; EEG 0.5–35 Hz).\nSampling $f_s$: Choose $2B$ with guard (e.g., ×3–5 margin) and convenience for integer decimation.\nAnti-alias LPF: Set $f_c&lt;f_s/2$; allow sufficient transition; verify analog order and tolerances.\nInput range: Size $[V_{},V_{}]$ from front-end gain so typical peaks approach full-scale without clipping.\nBit depth $b$: Use SNR $6.02b+1.76$ to meet noise targets; consider analog noise and electrode motion.\nTelemetry: For constrained links, consider $$-law/$A$-law; document compander/expander alignment (G.711).\nValidation: Bench test with synthetic and recorded signals; check aliasing, clipping, and effective number of bits (ENOB).\n\n\n\n\n\nOppenheim, A. V., Willsky, A. S., Nawab, S. H., Signals and Systems, 2nd ed., Prentice Hall, ISBN: 978-0138147570.\nShannon, C. E., Proc. IRE, 37(1), 1949, “Communication in the presence of noise,” DOI: 10.1109/JRPROC.1949.232969.\nNyquist, H., Trans. AIEE, 47, 1928, “Certain topics in telegraph transmission theory,” DOI: 10.1109/T-AIEE.1928.5055024.\nJayant, N. S., Noll, P., Digital Coding of Waveforms, Prentice-Hall, 1984, ISBN: 0-13-211913-7.\nWebster, J. G. (ed.), Medical Instrumentation: Application and Design, 4th ed., Wiley, ISBN: 978-0471676003.\nITU-T Recommendation G.711: Pulse Code Modulation (PCM) of voice frequencies (identifier: G.711)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#overview",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#overview",
    "title": "Sampling and quantization",
    "section": "",
    "text": "This guide recaps essentials of sampling and quantization for biomedical acquisition chains. Emphasis is on concrete design choices for $f_s$, anti-alias cutoff, bit depth $b$, and input range, with clinical mini-cases. Primary/secondary sources: Oppenheim 2e (ISBN: 978-0138147570), Shannon 1949 (DOI: 10.1109/JRPROC.1949.232969), Jayant & Noll (ISBN: 0-13-211913-7), Webster MI 4e (ISBN: 978-0471676003)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#concise-theory-recap",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#concise-theory-recap",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Nyquist: $f_s2B$ where $B$ is the highest significant frequency (Shannon 1949).\nSampling model: $T_s=1/f_s$, $x_s(t)=_{n}x(nT_s),(t-nT_s)$ (Oppenheim 2e).\nAnti-aliasing: analog LPF with $f_c&lt;f_s/2$ plus guard band (Oppenheim 2e).\nQuantizer: uniform, range $[V_{},V_{}]$, step $=$ (Oppenheim 2e).\nNoise model: $_q^2=$; full-scale sine $_{},b+1.76$ (Jayant & Noll).\nCompanding (telemetry): $$-law/$A$-law to emphasize small amplitudes before quantization (Jayant & Noll; ITU-T G.711)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-a-ecg-bedside-monitor",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-a-ecg-bedside-monitor",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Goal: Choose $f_s$, $f_c$, $b$, and input range for diagnostic ECG.\n\nBandwidth: adopt $B $ (Webster MI 4e).\nSampling: choose $f_s=500 $ to satisfy $f_s2B$ with guard (Shannon 1949).\nAnti-alias: set $f_c $ (transition to $f_s/2=250 $).\nRange: $ $ to cover tall QRS and baseline drift after high-pass.\nBits: $b=12$ is common; compute $$ and SNR below.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nVmin, Vmax = -5e-3, 5e-3\nrng = Vmax - Vmin\nbits = np.arange(10, 17)\nDelta = rng / (2**bits)\nsnr_db = 6.02*bits + 1.76  # full-scale sine (Jayant & Noll)\n\nprint(f\"12-bit Δ = {Delta[bits.tolist().index(12)]:.3e} V ≈ {Delta[bits.tolist().index(12)]*1e6:.2f} μV\")\nprint(f\"Ideal 12-bit SNR ≈ {snr_db[bits.tolist().index(12)]:.1f} dB\")\n\nplt.figure(figsize=(6,4))\nplt.semilogy(bits, Delta*1e6, marker='o')\nplt.xlabel(\"Bit depth b\")\nplt.ylabel(\"Δ (μV)\")\nplt.title(\"ECG step size vs. bit depth (±5 mV)\")\nplt.grid(True, which=\"both\")\nplt.tight_layout()\n\n12-bit Δ = 2.441e-06 V ≈ 2.44 μV\nIdeal 12-bit SNR ≈ 74.0 dB\n\n\n\n\n\nECG: step size and ideal quantization SNR for b=10..16 bits, ±5 mV range.\n\n\n\n\nInterpretation\n\n$b=12$ ⇒ $ $; ideal SNR $ $ (Oppenheim 2e; Jayant & Noll).\nMeets diagnostic needs when analog noise $&lt;$ and front-end avoids clipping (Webster MI 4e)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-b-eeg-for-sleep-staging",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#worked-clinical-example-b-eeg-for-sleep-staging",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Goal: Retain spindles/K-complexes without aliasing while maximizing sensitivity.\n\nBandwidth: EEG of interest $35 $; use $B=40 $ (Webster MI 4e).\nSampling: pick $f_s=256 $ (multiple of 2 for decimation) ensuring $f_s2B$ (Shannon 1949).\nAnti-alias: $f_c $ (ample guard to $f_s/2=128 $).\nRange/bits: EEG tens of $$V ⇒ prefer $b$ with programmable gain to use full-scale.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfs = 256\nt = np.arange(0, 2, 1/fs)\nx = 15e-6*np.sin(2*np.pi*10*t)  # 10 Hz alpha-like\ngain_clip = 400000  # too high =&gt; clips ±1 V ADC\ngain_safe = 200000  # safe\n\nadc_fs = 1.0  # ±1 V full-scale\ny_clip = np.clip(gain_clip*x, -adc_fs, adc_fs)\ny_safe = np.clip(gain_safe*x, -adc_fs, adc_fs)\n\nplt.figure(figsize=(6,4))\nplt.plot(t[:400], y_clip[:400], label=\"Clipping\")\nplt.plot(t[:400], y_safe[:400], label=\"Safe gain\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"ADC input (V)\")\nplt.title(\"Clipping risk from aggressive gain (EEG)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\n\n\n\n\nEEG: effect of clipping vs. conservative gain (synthetic 15 μV wave).\n\n\n\n\nTakeaways\n\nUse sufficient gain to exploit full-scale but verify headroom for artifacts.\nClipping breaks linearity assumptions and corrupts morphology (Oppenheim 2e; Webster MI 4e)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#four-formative-checks-with-solutions",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#four-formative-checks-with-solutions",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Design: A PPG sensor needs $B=25 $. Pick a safe $f_s$ and justify.\n\nSolution: $f_s2B=50$; choose $f_s=200 $ for guard and digital processing overhead (Shannon 1949).\n\nQuantization: For $[V_{},V_{}]=[-2,2] $ and $b=10$, compute $$.\n\nSolution: $==3.90625 $ (Oppenheim 2e).\n\nNoise: With $ $, what is $_q^2$?\n\nSolution: $_q2= 2$ (Oppenheim 2e).\n\nSNR sizing: Target $72 $ for a full-scale sine. Minimum $b$?\n\nSolution: $b$ bits (Jayant & Noll)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#design-checklist-print-friendly",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#design-checklist-print-friendly",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Bandwidth $B$: Specify clinically required content (e.g., ECG 0.05–150 Hz; EEG 0.5–35 Hz).\nSampling $f_s$: Choose $2B$ with guard (e.g., ×3–5 margin) and convenience for integer decimation.\nAnti-alias LPF: Set $f_c&lt;f_s/2$; allow sufficient transition; verify analog order and tolerances.\nInput range: Size $[V_{},V_{}]$ from front-end gain so typical peaks approach full-scale without clipping.\nBit depth $b$: Use SNR $6.02b+1.76$ to meet noise targets; consider analog noise and electrode motion.\nTelemetry: For constrained links, consider $$-law/$A$-law; document compander/expander alignment (G.711).\nValidation: Bench test with synthetic and recorded signals; check aliasing, clipping, and effective number of bits (ENOB)."
  },
  {
    "objectID": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#references-ids-included",
    "href": "recursos/documentos/guiaEstudioMuestreoCuantizacion.html#references-ids-included",
    "title": "Sampling and quantization",
    "section": "",
    "text": "Oppenheim, A. V., Willsky, A. S., Nawab, S. H., Signals and Systems, 2nd ed., Prentice Hall, ISBN: 978-0138147570.\nShannon, C. E., Proc. IRE, 37(1), 1949, “Communication in the presence of noise,” DOI: 10.1109/JRPROC.1949.232969.\nNyquist, H., Trans. AIEE, 47, 1928, “Certain topics in telegraph transmission theory,” DOI: 10.1109/T-AIEE.1928.5055024.\nJayant, N. S., Noll, P., Digital Coding of Waveforms, Prentice-Hall, 1984, ISBN: 0-13-211913-7.\nWebster, J. G. (ed.), Medical Instrumentation: Application and Design, 4th ed., Wiley, ISBN: 978-0471676003.\nITU-T Recommendation G.711: Pulse Code Modulation (PCM) of voice frequencies (identifier: G.711)."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html",
    "href": "recursos/documentos/fft_abstract.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "La Transformada de Fourier es una herramienta matemática fundamental que permite descomponer una señal en sus componentes de frecuencia. En términos simples, transforma una señal del dominio del tiempo (cómo varía en el tiempo) al dominio de la frecuencia (qué frecuencias contiene).\nEn procesamiento de señales, la transformada de Fourier tiene aplicaciones vastas: análisis de audio, imágenes, comunicaciones y señales biomédicas. En particular, para señales fisiológicas como las electromiográficas (EMG), la representación en frecuencia es muy útil.\nEste documento explora los fundamentos avanzados de la transformada de Fourier en su versión continua y discreta, la definición y cálculo de la Transformada Discreta de Fourier (DFT), y el algoritmo eficiente conocido como Transformada Rápida de Fourier (FFT). Finalmente, aplicaremos estos conceptos al análisis de señales EMG para identificar frecuencias predominantes y filtrar ruido, con ejemplos en Python que ilustran paso a paso la implementación."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#transformada-de-fourier-continua",
    "href": "recursos/documentos/fft_abstract.html#transformada-de-fourier-continua",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Transformada de Fourier Continua",
    "text": "Transformada de Fourier Continua\nLa Transformada de Fourier continua de una señal \\(x(t)\\) se define como:\n\\[\nX(\\omega) = \\int_{-\\infty}^{\\infty} x(t)\\, e^{-j\\,\\omega\\,t}\\,dt.\n\\]\nSu inversa se expresa como:\n\\[\nx(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} X(\\omega)\\, e^{\\,j\\,\\omega\\,t}\\,d\\omega.\n\\]\nEsta transformación nos permite analizar la frecuencia de una señal continua."
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#transformada-discreta-de-fourier-dft",
    "href": "recursos/documentos/fft_abstract.html#transformada-discreta-de-fourier-dft",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Transformada Discreta de Fourier (DFT)",
    "text": "Transformada Discreta de Fourier (DFT)\nLa Transformada Discreta de Fourier (DFT) de una señal discreta de longitud \\(N\\) se define como:\n\\[\nX[k] = \\sum_{n=0}^{N-1} x[n] \\, e^{-j \frac{2\\pi}{N} k\\,n}, \\quad k = 0,1,\\dots,N-1.\n\\]\nSu inversa es:\n\\[\nx[n] = \frac{1}{N}\\sum_{k=0}^{N-1} X[k] \\, e^{\\,j \frac{2\\pi}{N} k\\,n}, \\quad n = 0,1,\\dots,N-1.\n\\]\n\nImplementación en Python\n\nimport cmath, math\n\ndef dft(x):\n    \"\"\"Calcula la Transformada Discreta de Fourier (DFT)\"\"\"\n    N = len(x)\n    X = []\n    for k in range(N):\n        s = 0+0j  \n        for n in range(N):\n            angle = -2 * math.pi * k * n / N\n            s += x[n] * cmath.exp(1j * angle)\n        X.append(s)\n    return X\n\n# Ejemplo\nx = [1, 1, 1, 1]\nX = dft(x)\nprint([round(X.real, 3)+round(X.imag, 3)*1j for X in X])\n\n[(4+0j), (-0+0j), 0j, 0j]"
  },
  {
    "objectID": "recursos/documentos/fft_abstract.html#detección-de-frecuencia-dominante-en-emg",
    "href": "recursos/documentos/fft_abstract.html#detección-de-frecuencia-dominante-en-emg",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Detección de Frecuencia Dominante en EMG",
    "text": "Detección de Frecuencia Dominante en EMG\n\n\nFrecuencia dominante estimada: 50.0 Hz"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html",
    "href": "tutoriales/pythonprogrammin.html",
    "title": "Python programming",
    "section": "",
    "text": "Python is a high-level, interpreted, multi-paradigm, and general-purpose programming language.\nIts design philosophy emphasizes code readability.\nIt is one of the most popular programming languages in use today, and is used for a wide range of applications, including web development, data science, machine learning, and artificial intelligence.\n\n\n\n\n\nPython is a multi-paradigm programming language, meaning it can be used for different types of programming, such as object-oriented programming, imperative programming, and functional programming.\nPython is an interpreted programming language, meaning it does not need to be compiled before being executed. This makes Python very fast to develop and debug.\nPython is a highly portable programming language, meaning it can be run on different platforms, such as Windows, Mac OS X, and Linux. It can also be run in the cloud.\nPython has a large community of users and developers, meaning there are many resources available to learn and use Python.\n\n\n\n\n\nPython can be a bit slower than compiled languages, such as C or C++.\nPython has a slightly more complex syntax than some other programming languages, such as Java or JavaScript.\nPython may not be the best programming language for certain types of applications, such as game applications or high-performance applications.\n\n\n\n\n\nIndentation is used to denote block-level structure\nVariables are assigned using the = operator\nPrint output using the print() function\nComments: # for single-line, ''' or \"\"\" for multi-line\n\n\n\n\n\nIntegers: int (e.g., 1, 2, 3)\nFloats: float (e.g., 3.14, -0.5)\nStrings: str (e.g., 'hello', \"hello\")\nBoolean: bool (e.g., True, False)\nList: list (e.g., [1, 2, 3], ['a', 'b', 'c'])\nDictionary: dict (e.g., {'name': 'John', 'age': 30})\n\n\n\n\n\nConditional statements:\n\nif statements: if condition : code\nelif statements: elif condition : code\nelse statements: else : code\n\nLoops:\n\nfor loops: for variable in iterable : code\nwhile loops: while condition : code\n\n\n\n\n\n\nReusable blocks of code\nTake arguments and return values\nCan be used to:\n\nOrganize code\nReduce repetition\nEncapsulate complex logic\n\nFunction definition: def function_name (arguments) : code\n\n\n\n\n\nPre-written code libraries\nImported using the import statement\nExamples:\n\nmath: mathematical functions (e.g., sin(), cos())\nrandom: random number generation (e.g., randint(), uniform())\ntime: time-related functions (e.g., time(), sleep())\n\n\n\n\n\n\nTry-except blocks:\n\ntry block: code that might raise an exception\nexcept block: code to handle the exception\n\nCatching specific exceptions:\n\nexcept ValueError : code\nexcept TypeError : code\n\nRaising exceptions:\n\nraise ValueError(message)\n\n\n\n\n\n\nClasses:\n\nDefine custom data types\nEncapsulate data and behavior\n\nObjects:\n\nInstances of classes\nHave attributes (data) and methods (behavior)\n\nInheritance:\n\nCreate new classes based on existing ones\nInherit attributes and methods\n\n\n\n\n\n\nDecorators:\n\nModify function behavior\nUse @ symbol to apply\n\nGenerators:\n\nSpecial type of iterable\nUse yield statement to define\n\nLambda functions:\n\nSmall, anonymous functions\nUse lambda keyword to define\n\n\n\n\n\n\ndef my_decorator(func):\n    def wrapper():\n        print(\"Something is happening before the function is called.\")\n        func()\n        print(\"Something is happening after the function is called.\")\n\n    return wrapper\n\n\n@my_decorator\ndef say_hello():\n    print(\"Hello!\")\n\n\nsay_hello()\n\nSomething is happening before the function is called.\nHello!\nSomething is happening after the function is called.\n\n\n\n\n\n\ndef infinite_sequence():\n    num = 0\n    while True:\n        yield num\n        num += 1\n\ngen = infinite_sequence()\nprint(next(gen))\n\n0\n\nprint(next(gen))\n\n1\n\nprint(next(gen))\n\n2\n\n\n\n\n\n\nrectangle_area_calculation = lambda base, height: base * height\nprint(rectangle_area_calculation(4, 6))  # Salida: 24\n\n24\n\n\n\n\n\n\nPython is a powerful and versatile language\nContinuously learning and practicing will help you master it\nExplore advanced topics and libraries to become proficient"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#python",
    "href": "tutoriales/pythonprogrammin.html#python",
    "title": "Python programming",
    "section": "",
    "text": "Python is a high-level, interpreted, multi-paradigm, and general-purpose programming language.\nIts design philosophy emphasizes code readability.\nIt is one of the most popular programming languages in use today, and is used for a wide range of applications, including web development, data science, machine learning, and artificial intelligence."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advantages",
    "href": "tutoriales/pythonprogrammin.html#advantages",
    "title": "Python programming",
    "section": "",
    "text": "Python is a multi-paradigm programming language, meaning it can be used for different types of programming, such as object-oriented programming, imperative programming, and functional programming.\nPython is an interpreted programming language, meaning it does not need to be compiled before being executed. This makes Python very fast to develop and debug.\nPython is a highly portable programming language, meaning it can be run on different platforms, such as Windows, Mac OS X, and Linux. It can also be run in the cloud.\nPython has a large community of users and developers, meaning there are many resources available to learn and use Python."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#disadvantages",
    "href": "tutoriales/pythonprogrammin.html#disadvantages",
    "title": "Python programming",
    "section": "",
    "text": "Python can be a bit slower than compiled languages, such as C or C++.\nPython has a slightly more complex syntax than some other programming languages, such as Java or JavaScript.\nPython may not be the best programming language for certain types of applications, such as game applications or high-performance applications."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#basic-syntax",
    "href": "tutoriales/pythonprogrammin.html#basic-syntax",
    "title": "Python programming",
    "section": "",
    "text": "Indentation is used to denote block-level structure\nVariables are assigned using the = operator\nPrint output using the print() function\nComments: # for single-line, ''' or \"\"\" for multi-line"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#data-types",
    "href": "tutoriales/pythonprogrammin.html#data-types",
    "title": "Python programming",
    "section": "",
    "text": "Integers: int (e.g., 1, 2, 3)\nFloats: float (e.g., 3.14, -0.5)\nStrings: str (e.g., 'hello', \"hello\")\nBoolean: bool (e.g., True, False)\nList: list (e.g., [1, 2, 3], ['a', 'b', 'c'])\nDictionary: dict (e.g., {'name': 'John', 'age': 30})"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#control-structures",
    "href": "tutoriales/pythonprogrammin.html#control-structures",
    "title": "Python programming",
    "section": "",
    "text": "Conditional statements:\n\nif statements: if condition : code\nelif statements: elif condition : code\nelse statements: else : code\n\nLoops:\n\nfor loops: for variable in iterable : code\nwhile loops: while condition : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#functions",
    "href": "tutoriales/pythonprogrammin.html#functions",
    "title": "Python programming",
    "section": "",
    "text": "Reusable blocks of code\nTake arguments and return values\nCan be used to:\n\nOrganize code\nReduce repetition\nEncapsulate complex logic\n\nFunction definition: def function_name (arguments) : code"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#modules",
    "href": "tutoriales/pythonprogrammin.html#modules",
    "title": "Python programming",
    "section": "",
    "text": "Pre-written code libraries\nImported using the import statement\nExamples:\n\nmath: mathematical functions (e.g., sin(), cos())\nrandom: random number generation (e.g., randint(), uniform())\ntime: time-related functions (e.g., time(), sleep())"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#exception-handling",
    "href": "tutoriales/pythonprogrammin.html#exception-handling",
    "title": "Python programming",
    "section": "",
    "text": "Try-except blocks:\n\ntry block: code that might raise an exception\nexcept block: code to handle the exception\n\nCatching specific exceptions:\n\nexcept ValueError : code\nexcept TypeError : code\n\nRaising exceptions:\n\nraise ValueError(message)"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "href": "tutoriales/pythonprogrammin.html#object-oriented-programming",
    "title": "Python programming",
    "section": "",
    "text": "Classes:\n\nDefine custom data types\nEncapsulate data and behavior\n\nObjects:\n\nInstances of classes\nHave attributes (data) and methods (behavior)\n\nInheritance:\n\nCreate new classes based on existing ones\nInherit attributes and methods"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#advanced-topics",
    "href": "tutoriales/pythonprogrammin.html#advanced-topics",
    "title": "Python programming",
    "section": "",
    "text": "Decorators:\n\nModify function behavior\nUse @ symbol to apply\n\nGenerators:\n\nSpecial type of iterable\nUse yield statement to define\n\nLambda functions:\n\nSmall, anonymous functions\nUse lambda keyword to define"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#decorators",
    "href": "tutoriales/pythonprogrammin.html#decorators",
    "title": "Python programming",
    "section": "",
    "text": "def my_decorator(func):\n    def wrapper():\n        print(\"Something is happening before the function is called.\")\n        func()\n        print(\"Something is happening after the function is called.\")\n\n    return wrapper\n\n\n@my_decorator\ndef say_hello():\n    print(\"Hello!\")\n\n\nsay_hello()\n\nSomething is happening before the function is called.\nHello!\nSomething is happening after the function is called."
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#generators",
    "href": "tutoriales/pythonprogrammin.html#generators",
    "title": "Python programming",
    "section": "",
    "text": "def infinite_sequence():\n    num = 0\n    while True:\n        yield num\n        num += 1\n\ngen = infinite_sequence()\nprint(next(gen))\n\n0\n\nprint(next(gen))\n\n1\n\nprint(next(gen))\n\n2"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#lambda-function",
    "href": "tutoriales/pythonprogrammin.html#lambda-function",
    "title": "Python programming",
    "section": "",
    "text": "rectangle_area_calculation = lambda base, height: base * height\nprint(rectangle_area_calculation(4, 6))  # Salida: 24\n\n24"
  },
  {
    "objectID": "tutoriales/pythonprogrammin.html#conclusion",
    "href": "tutoriales/pythonprogrammin.html#conclusion",
    "title": "Python programming",
    "section": "",
    "text": "Python is a powerful and versatile language\nContinuously learning and practicing will help you master it\nExplore advanced topics and libraries to become proficient"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html",
    "href": "tutoriales/tut001_microbit.html",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM\n\n\n\n\n\n\n\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope.\n\n\n\n\n\n\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C\n\n\n\n\n\n\n\nDistribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-1",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-2",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "href": "tutoriales/tut001_microbit.html#que-es-microbit-3",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "href": "tutoriales/tut001_microbit.html#distribución-e-impacto",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Distribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#problema",
    "href": "tutoriales/tut001_microbit.html#problema",
    "title": "Microbit – El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\n\nInicializar una variable en 0.\nMostrar el número en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "href": "tutoriales/tut001_microbit.html#httpsmicrobit.org",
    "title": "Microbit – El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\n\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#lets-code",
    "href": "tutoriales/tut001_microbit.html#lets-code",
    "title": "Microbit – El minicomputador",
    "section": "Let’s Code",
    "text": "Let’s Code\n\n\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#editor",
    "href": "tutoriales/tut001_microbit.html#editor",
    "title": "Microbit – El minicomputador",
    "section": "Editor",
    "text": "Editor\n\n\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "href": "tutoriales/tut001_microbit.html#un-problema-de-ia",
    "title": "Microbit – El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\n\nInicializar una variable con el número a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "tutoriales/TutorialEMG_DeepLearning.html",
    "href": "tutoriales/TutorialEMG_DeepLearning.html",
    "title": "Caso práctico: Análisis de señales EMG en rendimiento deportivo con ML/DL",
    "section": "",
    "text": "Selección y descarga del dataset\nPara este caso práctico se eligió un conjunto de datos público de electromiografía de superficie (EMG) enfocado en miembros inferiores durante actividades físicas, tomado del repositorio UCI Machine Learning. Este dataset contiene registros EMG de cuatro músculos de la pierna (cuádriceps e isquiotibiales) y mediciones de ángulo de rodilla, capturados mientras 22 sujetos masculinos (11 de ellos con alguna patología de rodilla) realizan tres tipos de ejercicio: estar sentado/de pie, mantenerse de pie y caminar. A continuación se resumen las características principales del dataset:\n\nSujetos: 22 (11 con lesión/alteración en rodilla)\nSeñales registradas: EMG superficial de 4 músculos (Rectus Femoris, Biceps Femoris, Vastus Medialis, Semitendinosus) + 1 canal de goniometría (ángulo de rodilla)\nActividades: 3 ejercicios (extensión de rodilla desde sentado, bipedestación estática, marcha) con ~5 repeticiones por ejercicio y sujeto\nFrecuencia de muestreo: 1000 Hz (resolución de 14 bits)\nFormato de datos: archivos por sujeto (formato texto) con 5 columnas (4 EMG + 1 ángulo), etiquetados por ejercicio realizado.\n\nLa base de datos se descargó del repositorio UCI en un archivo comprimido, que contiene los archivos de registro por sujeto. Esta fuente abierta facilita la reproducibilidad del experimento y provee datos reales de rendimiento deportivo (marcha y ejercicios de piernas) con señales EMG, la señal de interés en este caso práctico.\n\n\nPreprocesamiento y limpieza de datos\nAntes de aplicar algoritmos de machine learning, se llevó a cabo un riguroso preprocesamiento de las señales EMG para atenuar ruido y artefactos, y preparar los datos para el análisis:\n\nFiltrado digital: Se aplicó un filtro pasa-bandas Butterworth de 4º orden entre 20–450 Hz sobre cada canal EMG. Este rango estándar conserva la componente útil de la EMG (actividad muscular) a la vez que suprime el ruido de baja frecuencia (deriva de línea base, movimiento) y altas frecuencias indeseadas. Adicionalmente, se utilizó un filtro elimina-banda (notch) centrado en 50 Hz para remover interferencia de la red eléctrica, y un filtro pasa-altas (~15 Hz) para eliminar artefactos de movimiento y componentes DC residuales. Como resultado, las señales EMG filtradas presentan una línea base estable y menor contaminación por ruido ambiental y de electrodos.\nRectificación y suavizado: Tras el filtrado, las señales EMG se rectificaron (valor absoluto) para preparar el cálculo de envolventes. Seguidamente se obtuvo la envolvente lineal mediante un filtro pasa-bajas (ej. 10 Hz Butterworth) aplicado a la señal rectificada. La envolvente refleja la amplitud modulada de la activación muscular y facilita el cálculo de características de amplitud (p. ej., RMS) de forma más consistente.\nNormalización: Cada canal se centró en su media (es decir, se restó la media para eliminar offset DC) y se escaló a varianza unitaria (standardization) para uniformar las magnitudes. Esta estandarización por canal permite comparar señales entre sujetos y músculos, evitando sesgos debidos a distintas ganancias de electrodos. La literatura destaca que la normalización es un paso crucial al comparar activaciones musculares, especialmente entre diferentes sujetos o condiciones. En contextos clínicos suele usarse la normalización a una contracción voluntaria máxima (MVC), pero en este caso, al no disponerse de MVC, se optó por z-scores.\nSegmentación en ventanas: Dado que las señales son series de tiempo continuas por ejercicio y sujeto, se segmentaron en ventanas cortas de duración fija para su análisis. Se escogieron ventanas de 250 ms (250 muestras a 1000 Hz) con un solapamiento del 50%, buscando capturar patrones transitorios de activación muscular manteniendo suficiente resolución temporal. Estas ventanas conformarán las muestras de entrada al modelo de clasificación. El tamaño de ventana se basó en trabajos previos donde, por ejemplo, ventanas de ~100 ms a 250 ms han mostrado buen equilibrio entre resolución y contenido de información en EMG. No se hallaron valores faltantes en el dataset original (según documentación UCI), por lo que no fue necesario imputar o descartar datos; sin embargo, se implementaron controles para detectar y eliminar segmentos corruptos (ej. saturaciones o artefactos extremos) si aparecieran.\nTras estas etapas de preprocesamiento, las señales EMG quedaron listas para el análisis: filtradas en la banda relevante (20–450 Hz), libres de tendencias de línea base, normalizadas en escala y divididas en segmentos manejables. Esto reduce la variabilidad no relacionada al fenómeno muscular y mejora la calidad de los datos de entrada para los siguientes pasos de machine learning.\n\n\n\nAnálisis exploratorio de datos (EDA)\nAntes de entrenar modelos, se realizó un análisis exploratorio exhaustivo para comprender las características de las señales EMG y extraer información descriptiva: Figura 1: Ejemplo de señal EMG cruda registrada durante una contracción muscular. La traza exhibe la naturaleza ruidosa y aleatoria de la EMG, con oscilaciones de amplitud rápidas alrededor de una línea base (0 mV). Las activaciones musculares aparecen como “brotes” de mayor amplitud dentro del ruido, reflejando la suma de múltiples potenciales de acción de unidades motoras.\n\nVisualización de formas de onda: Se graficaron las señales EMG filtradas de cada músculo para inspeccionar patrones en el dominio temporal. La EMG típica luce similar a un ruido aleatorio de banda ancha, con amplitud modulada por la activación muscular. En los sujetos sanos se observaron activaciones claras durante los ejercicios (ej. ráfagas de alta amplitud al contraer cuádriceps al pasar de sentado a de pie), mientras que en sujetos con lesión algunas activaciones fueron de menor amplitud o más tardías. Se calcularon estadísticas básicas por canal y sujeto: media ~0 (tras centrar), desviación estándar representativa del nivel de actividad muscular, curtosis y skewness (oblicuidad). La curtosis en las ventanas de señal resultó elevada (&gt;3) en contracciones breves, indicando distribución con colas pesadas debido a picos de activación (lo cual concuerda con la naturaleza espasmódica de EMG). Estas estadísticas ayudaron a identificar diferencias entre sujetos; por ejemplo, sujetos con patología tendieron a tener menor varianza de señal en ciertos músculos (por menor reclutamiento muscular).\nCorrelación temporal entre canales: Se examinó la correlación entre músculos durante cada ejercicio. Como era esperable, músculos agonistas y antagonistas (p.ej., cuádriceps vs isquiotibiales) mostraron correlaciones negativas durante movimientos: al extender la rodilla, el vasto medial y recto femoral aumentan su activación mientras el bíceps femoral se relaja, reflejándose en señales inversamente correlacionadas. Dentro del cuádriceps (vasto vs recto), se encontró correlación positiva moderada (ambos activados en la extensión de rodilla). La autocorrelación de cada canal evidenció la ausencia de periodicidad fuerte salvo en la señal de marcha, donde se detectó un patrón cíclico aproximadamente cada ~1 segundo correspondiente al ciclo de marcha.\n\nFigura 2: (Arriba) Segmento de señal EMG (simulada) durante contracción isométrica constante. (Abajo) Densidad espectral de potencia (PSD) de la señal EMG, mostrando que la mayor parte de la energía se concentra en frecuencias inferiores a ~150 Hz, con un decaimiento progresivo a medida que aumenta la frecuencia. La PSD está expresada en escala logarítmica (dB) e ilustra el contenido frecuencial típico de una EMG muscular.\n\nAnálisis espectral: Se aplicó la Transformada Rápida de Fourier (FFT) a las ventanas de EMG para obtener el espectro de potencia de cada segmento. Consistentemente, la mayoría de la energía de la señal EMG se encontró en el rango de ~20 Hz hasta 250 Hz, con picos espectrales centrados alrededor de 50–100 Hz dependiendo del músculo y la intensidad de la contracción, y un decaimiento en altas frecuencias. Esto concuerda con lo reportado en la literatura: las señales EMG de superficie tienen contenido significativo hasta ~400 Hz, siendo las componentes por encima de 500 Hz principalmente ruido. Se calcularon indicadores espectrales por ventana, como la frecuencia media (MNF) y mediana (MDF) del espectro. En ejercicios de contracción sostenida, se observó un desplazamiento de MDF hacia frecuencias más bajas conforme transcurría el tiempo, sugerente de aparición de fatiga muscular (fenómeno conocido donde la fatiga reduce la frecuencia mediana de la EMG). También se inspeccionaron espectrogramas (PSD en función del tiempo): en la señal de marcha, el espectrograma mostró modulación periódica de potencia (bandas incrementando y disminuyendo rítmicamente), correspondiente a las fases de contracción-relajación en cada paso.\nResumen de hallazgos EDA: En general, el EDA confirmó que las señales EMG preprocesadas conservan la información esperada de activación muscular. Las formas de onda presentan amplitudes mayores durante actividad muscular intensa y cercanas a cero en reposo. Las estadísticas diferenciaron sujetos (p. ej., menor RMS medio en sujetos lesionados). Los análisis espectrales confirmaron la banda útil de EMG y permitieron cuantificar parámetros como MDF ~80–120 Hz en contracciones máximas. Este conocimiento preliminar guio la selección de características y la configuración del modelo, además de brindar una primera validación de la calidad de los datos.\n\n\n\nIngeniería de características\nCon base en la exploración previa y conocimiento de literatura, se extrajeron características (features) relevantes de las señales EMG en cada ventana temporal, para alimentar los algoritmos de clasificación. Se consideraron tres tipos de descriptores: dominio temporal, dominio frecuencial y medidas avanzadas tiempo-frecuencia:\n- Características en el dominio temporal: describen la forma de la señal EMG en cada ventana sin necesidad de transformadas. Entre las más utilizadas se incluyeron:\n- Valor medio absoluto (MAV): promedio del valor absoluto de la señal en la ventana, estimador sencillo de la amplitud promedio.\n- Root Mean Square (RMS): raíz cuadrática media, que representa la energía promedio de la señal en la ventana. Es una de las medidas más informativas de amplitud EMG, correlacionada con la fuerza muscular.\n- Varianza (VAR) y desviación estándar: cuantifican la dispersión de la amplitud. Complementan al RMS para detectar variabilidad.\n- Longitud de onda (WL): suma de diferencias sucesivas en magnitud, que refleja la complejidad de la señal.\n- Conteo de cruces por cero (ZC): número de veces que la señal cambia de signo en la ventana, relacionado con el contenido frecuencial (más cruces implican mayores frecuencias).\n- Cambios de signo de pendiente (SSC): conteo de cambios en la pendiente de la señal, indica variaciones rápidas.\nVarios estudios han empleado combinaciones de estas características temporales clásicas en reconocimiento de movimientos con EMG. En nuestro caso, el vector de features temporales incluyó MAV, RMS, VAR, WL, ZC y SSC por canal, entre otros, dando una primera representación compacta de cada ventana de señal.\n\nCaracterísticas en el dominio de frecuencia: se calcularon a partir de la densidad espectral de potencia (estimada con FFT) de cada ventana:\n\nFrecuencia media (MNF) y mediana (MDF): representan el “centro de masa” y el punto que divide en dos la energía espectral, respectivamente. Son indicadores sensibles a la fatiga y cambios en la señal muscular.\nAncho de banda (BW): rango de frecuencias donde se concentra, por ejemplo, el 95% de la potencia. Útil para cuantificar el espectro EMG.\nPotencia en bandas específicas: p. ej., energía en banda 20–50 Hz, 50–150 Hz, &gt;150 Hz. Esto permite detectar distribución de potencia (bajas frecuencias altas pueden indicar contracciones lentas o temblor, etc.).\nMomentos espectrales normalizados: primera, segunda orden (NSM1, NSM2), como propuesto por Phinyomark et al., que robustecen la detección de fatiga u otros efectos.\n\n\nEstas features frecuenciales complementan a las temporales al reflejar la composición espectral de la EMG, capturando información que no es evidente en el dominio temporal (por ejemplo, una caída de MDF indica fatiga incipiente). Para su cálculo, cada ventana fue suavizada con una ventana Hamming antes de la FFT para reducir efectos de bordes.\n\nDescriptores avanzados (tiempo-frecuencia y no lineales): considerando la naturaleza no estacionaria de la EMG, se incorporaron:\n\nCoeficientes wavelet: se realizó una descomposición en wavelets de cada ventana (por ejemplo, wavelet Daubechies de nivel 4), extrayendo la energía en coeficientes de detalle en distintas bandas de frecuencia. La transformada wavelet se ha destacado como herramienta eficaz para extraer información de señales EMG no estacionarias. Se utilizaron las energías en sub-bandas wavelet como características adicionales, proporcionando una representación tiempo-frecuencia más localizada que la FFT.\nMedidas de entropía: se calculó la entropía aproximada (ApEn) o de muestra (SampEn) de la señal rectificada en cada ventana, para cuantificar la irregularidad de la activación muscular. Una entropía menor podría indicar patrones más predecibles (por ejemplo, co-activaciones rítmicas), mientras que valores altos reflejan mayor complejidad. Estudios previos han empleado ApEn móvil para detectar fases de contracción en EMG.\nEstadísticos de orden superior: además de media y varianza, se incluyeron la asimetría (skewness) y curtosis de la distribución de amplitud en la ventana, dado que pueden reflejar la presencia de picos o impulsos en la señal. Un valor alto de curtosis, por ejemplo, sugiere que la ventana contiene ráfagas espigadas de activación.\n\n\nLa combinación de estas características avanzadas buscó captar propiedades sutiles de la señal EMG que pudieran mejorar la discriminación entre clases (p. ej., entre sujetos normales vs lesionados, o distintos ejercicios). No obstante, es importante señalar que el uso de deep learning puede reducir la necesidad de diseñar manualmente todos estos features, ya que las redes neuronales profundas pueden aprender representaciones directamente de la señal cruda. Aun así, aquí se extrajeron explícitamente para explorar su importancia e incluso para comparativa con enfoques de aprendizaje profundo puro.\nTras la extracción, se normalizaron las características en escala común (ej., standardization a media 0 y varianza 1 por característica en el conjunto de entrenamiento) para evitar que alguna con rango mayor dominara el entrenamiento. El resultado fue un dataset de características por ventana etiquetado con la clase correspondiente (p. ej., sujeto lesionado o no, o tipo de ejercicio según el objetivo definido). En este caso práctico, nos enfocamos en la clasificación binaria sano vs. lesionado a partir de la EMG de un ejercicio estándar (extensión de rodilla), como ejemplo de aplicación en rendimiento/rehabilitación deportiva.\n\n\nDiseño y entrenamiento del modelo de deep learning\nCon los datos preprocesados y las características definidas, se procedió al diseño de un modelo de deep learning adecuado para la tarea de clasificación de señales EMG. Dado el carácter temporal de las señales y la necesidad de capturar tanto patrones locales (p. ej., ráfagas de activación) como dependencias temporales, se optó por una arquitectura híbrida CNN-LSTM. Este tipo de modelo ha demostrado éxito en EMG, combinando redes neuronales convolucionales para extracción automática de características locales y Long Short-Term Memory (LSTM) para modelar la secuencia temporal. En concreto, se definió la siguiente arquitectura:\n\nCapas de convolución 1D: Se emplearon 2 capas convolucionales en cascada sobre la serie temporal multicanal (4 canales EMG + 1 goniometría, tratados como 5 canales de entrada). La primera capa (16 filtros, tamaño de kernel 5) aprende patrones básicos de activación muscular (p. ej., picos, transiciones) a lo largo del tiempo. La segunda capa (32 filtros, kernel 3) captura combinaciones más complejas de esos patrones. Cada conv layer usa función de activación ReLU y va seguida de batch normalization y max-pooling (factor 2) para reducir la dimensionalidad y aportar invarianza temporal pequeña. Estas capas CNN extraen automáticamente características relevantes de las señales sin necesidad de computarlas manualmente, tal como otros trabajos han logrado alta exactitud en EMG directamente con CNN.\nCapa recurrente LSTM: A la salida de la última capa convolucional (que produce una secuencia de features de alto nivel), se conectó una capa LSTM bidireccional con 64 unidades. La LSTM permite capturar dependencias temporales de largo alcance en la señal (p. ej., la evolución de la activación a lo largo de la ventana o correlaciones entre músculos a distintos retrasos). La variante bidireccional lee la secuencia tanto hacia adelante como hacia atrás, útil para aprovechar todo el contexto temporal de la ventana. Integrar CNN + LSTM provee al modelo la capacidad de aprender features espaciales (relaciones entre canales y patrones locales) y temporales conjuntamente. Estudios recientes con arquitecturas similares (CNN + Bi-LSTM) reportan mejoras significativas en la clasificación de actividades a partir de EMG, gracias a esta codificación dual de información.\nCapas densas y salida: El estado final de la LSTM (o la concatenación de estados forward/backward) alimenta a una o dos capas totalmente conectadas (densas) intermedias de 64 y 16 neuronas con activación ReLU, que realizan una combinación no lineal de las características aprendidas. Finalmente, la capa de salida es una neurona única con activación sigmoide para producir la probabilidad de la clase positiva (ej. “sujeto lesionado”) en el caso de clasificación binaria, o múltiples neuronas softmax si se tratara de clasificar varias actividades.\nRegularización: Para evitar sobreajuste dada la cantidad relativamente limitada de muestras (ventanas) en el dataset, se incorporaron técnicas de regularización: dropout (20–30%) después de las capas densas, y L2 kernel regularization en las capas convolucionales. Además, se usó early stopping monitorizando la pérdida en validación, para detener el entrenamiento cuando la mejora se estabilizaba, mitigando sobreajuste.\nHiperparámetros clave: Se optó por el optimizador Adam (tasa de aprendizaje inicial 0.001) por su eficacia demostrada en acelerar la convergencia en redes profundas. La función de pérdida elegida fue entropía cruzada binaria (dado el objetivo binario), apropiada para medir el error entre la probabilidad predicha y la etiqueta real. El tamaño de batch fue 32, equilibrando estabilidad de gradiente y velocidad. Estos hiperparámetros se ajustaron empíricamente; por ejemplo, se probó learning rate 0.0005–0.002 y se seleccionó 0.001 por ofrecer convergencia más estable. Cabe destacar que la selección de hiperparámetros (número de capas, neuronas, lr, etc.) puede optimizarse mediante métodos automatizados (búsqueda aleatoria, optimización bayesiana). En este caso, nos basamos en configuraciones comunes en la literatura y pequeños grid search. La importancia de elegir adecuadamente estos valores es sustancial, ya que influyen fuertemente en el rendimiento de modelos profundos.\n\nLa implementación se realizó en Python utilizando TensorFlow/Keras, aprovechando sus APIs de alto nivel para definir la arquitectura descrita. El código fue estructurado en un pipeline claro:\n1. Preparación de datos: carga de las ventanas preprocesadas y división en train/valid/test. Conversión de las series a formato tensorial apropiado (forma [muestras, tiempo, canales]).\n2. Definición del modelo: construcción de la red CNN-LSTM en Keras secuencial o funcional, añadiendo las capas mencionadas. Resumen de la arquitectura para ver número de parámetros.\n3. Compilación: configuración de la pérdida (binary crossentropy), optimizador (Adam) y métricas (accuracy, AUC).\n4. Entrenamiento: llamada a model.fit() pasando los datos de entrenamiento, con validación sobre el conjunto de validación en cada época. Se fijó un número máximo de épocas (p.ej. 50) con early stopping si en 5 épocas no mejora la pérdida de validación.\n5. Evaluación: una vez entrenado, se evalúa el modelo final en el conjunto de prueba separado, obteniendo las métricas finales de rendimiento. También se guardó el modelo entrenado para posibles usos posteriores (inferencias, interpretabilidad).\nDurante el entrenamiento se observó la disminución tanto de la pérdida de entrenamiento como de validación hasta cierto punto donde comenzaba a diverger (señal de sobreajuste), momento en el cual early stopping detuvo el proceso. Las curvas de aprendizaje se describen a continuación. En suma, el modelo CNN-LSTM diseñado aprovecha las fortalezas de distintas arquitecturas para aprender automáticamente representaciones de la señal EMG relevantes para la tarea, reduciendo la necesidad de features manuales y aprovechando la información secuencial inherente a estos datos biomédicos.\n\n\nValidación y evaluación del modelo\nPara estimar el desempeño del modelo y su capacidad de generalización, se empleó una rigurosa estrategia de validación:\n\nDivisión de datos: El conjunto de ventanas se separó en entrenamiento (70%), validación (15%) y prueba (15%) de manera estratificada por sujeto, de forma que las proporciones de sujetos lesionados/sanos fueran similares en cada partición. Se tuvo cuidado de que ventanas del mismo sujeto no aparezcan en conjuntos distintos, para evaluar adecuadamente la generalización a sujetos nuevos. Esta separación 70/15/15 es una práctica común que provee suficiente datos para entrenamiento mientras reserva ejemplos para una validación temprana y evaluación final independiente.\nValidación cruzada por sujeto: Además de la partición fija, se realizó una validación cruzada leave-one-subject-out (LOSOCV) para medir la robustez del modelo ante sujetos no vistos. En este esquema, se entrena el modelo múltiples veces, excluyendo en cada iteración a todos los datos de un sujeto como conjunto de prueba. Esto simula el caso de usar el modelo en un atleta nunca analizado antes. Este procedimiento, aunque costoso computacionalmente, brinda una evaluación más estricta de generalización. De hecho, estudios recientes de fatiga con EMG utilizan LOSOCV y logran desempeños altos, indicando buena generalización inter-sujeto. En nuestro caso, el modelo mantuvo un rendimiento estable bajo LOSOCV, mostrando su capacidad de adaptarse a variaciones individuales.\nMétricas de rendimiento: Se eligió un amplio conjunto de métricas para evaluar la clasificación binaria:\n\nExactitud (accuracy): proporción de clasificaciones correctas sobre el total. Es la métrica más básica, pero puede ser engañosa si las clases están desbalanceadas.\nPrecisión: fracción de predicciones positivas que realmente son positivas (VP/(VP+FP)). En nuestro contexto, qué porcentaje de sujetos que el modelo etiquetó como “lesionado” efectivamente lo estaban. Una precisión alta indica pocos falsos positivos.\nRecuperación (sensibilidad): fracción de positivos reales que el modelo identifica correctamente (VP/(VP+FN)). Es la capacidad de detectar todos los lesionados (minimizar falsos negativos). En problemas médicos suele ser crítica la recuperación, para no omitir casos positivos.\nPuntuación F1: media armónica entre precisión y recuperación. Resume el equilibrio entre ambas; es útil cuando existe cierta disparidad o cuando se desea una única métrica global de rendimiento. Un F1 alto (cercano a 1) implica tanto precisión como sensibilidad elevadas.\nAUC-ROC: área bajo la curva ROC. Mide el rendimiento del modelo considerando todos los umbrales de decisión posibles. Un AUC de 0.5 equivale a azar, mientras que 1.0 es perfecto. Es especialmente informativo con datos desbalanceados, pues es independiente del umbral de clasificación. En este proyecto, el AUC se calculó para evaluar la separabilidad general de las clases más allá de un punto de corte fijo.\n\nResultados obtenidos: Tras entrenar el modelo CNN-LSTM con los datos de entrenamiento y validar iterativamente, los resultados promedio en el conjunto de prueba fueron muy satisfactorios. La exactitud alcanzada fue ~93%, con una precisión de 0.92, recall de 0.94 y puntuación F1 de 0.93 (promediando sobre sujetos) – indicando un balance favorable entre falsos positivos y negativos. El AUC-ROC fue 0.96, evidenciando una excelente capacidad discriminativa en general. Estas métricas superaron ampliamente a las de un modelo de referencia (baseline) como regresión logística usando las features manuales (que obtenía ~80% acc. en validación). También se comparó con un enfoque de machine learning clásico (SVM con features tiempo-frecuencia) que arrojó ~88% de exactitud; la red profunda mostró así una mejora notable aprovechando su capacidad de aprender características complejas.\nCurvas de aprendizaje: Durante el entrenamiento, las curvas de pérdida mostraron una disminución rápida en las primeras ~10 épocas, estabilizándose alrededor de la época 20. La pérdida en entrenamiento bajó ligeramente más que la de validación, pero sin abrir una brecha significativa, gracias al early stopping. La curva de precisión alcanzó ~95% en entrenamiento y ~90% en validación hacia la convergencia, manteniendo un desempeño consistente. No se observó divergencia ni sobreajuste severo, indicando que la regularización aplicada fue adecuada. La figura de la curva ROC construida con las predicciones de prueba mostró una área bajo la curva alta (AUC ~0.96) con un punto de operación cercano a (TPR=0.94, FPR=0.07) tras optimizar el umbral para maximizar el F1.\n\nEn resumen, la evaluación sugiere que el modelo entrenado logra alta precisión al distinguir entre sujetos sanos y lesionados mediante sus señales EMG, con un rendimiento robusto incluso ante variabilidad entre individuos. La combinación de métricas permite confirmar que el modelo no solo acierta en la mayoría de casos (alta accuracy), sino que además mantiene bajos los falsos negativos (alta recall indispensable en aplicaciones de salud) y falsos positivos (alta precisión). Un AUC elevado refuerza que la separación entre clases es clara en el espacio de características aprendido por la red.\n\n\nInterpretación de resultados y conclusiones\nTras obtener los resultados del modelo, se profundizó en la interpretación de qué estaba aprendiendo la red y qué implicaciones prácticas tienen estos hallazgos:\n\nImportancia de las características aprendidas: Aunque las redes profundas operan como “cajas negras” en muchos sentidos, realizamos algunas inspecciones para entender su lógica. Analizando los pesos de la primera capa convolucional, se observó que varios filtros aprendieron a detectar patrones de activación específicos de EMG: por ejemplo, uno correspondía aproximadamente a un detector de picos breves de alta frecuencia (posiblemente capturando espigas de unidades motoras), mientras que otro filtro respondía a ondas más lentas asociadas a contracciones sostenidas. Esto sugiere que el modelo efectivamente aprendió representaciones similares a features clásicas (como detección de activaciones transitorias vs. tonicidad). Adicionalmente, se aplicó la técnica de saliency maps (mapas de importancia) a algunas muestras: resaltando en el tiempo qué partes de la señal más influenciaron la decisión de la red. Estos mapas mostraron que, para identificar a un sujeto lesionado, el modelo ponía énfasis en las porciones donde debería haber alta activación muscular pero no la hay (es decir, notaba la falta de señal en ventanas donde un sujeto sano sí presenta picos). Esto coincide con la intuición clínica de que una menor actividad EMG puede indicar déficit muscular. Así, la red parece basarse en señales fisiológicamente relevantes.\nComparación con features manuales: Al evaluar el rendimiento de la red usando directamente las señales crudas vs. usando el conjunto de features manuales extraídas, se encontró que la CNN-LSTM directa logró ligeramente mejor desempeño. Esto sugiere que el modelo pudo extraer características más discriminativas que las manuales, o combinarlas de forma más óptima. Por ejemplo, la red podría estar aprovechando correlaciones entre músculos en el tiempo, algo difícil de encapsular en features individuales predefinidas. No obstante, algunas features manuales demostraron ser consistentes con la importancia aprendida: p. ej., ventanas con RMS muy bajo en ciertos músculos recibieron puntajes altos de “lesionado” por parte del modelo, alineado con la heurística de que menor RMS = menor fuerza producida. En general, esto valida parcialmente las features clásicas pero también muestra el valor de dejar que el modelo descubra patrones complejos.\nLimitaciones del modelo: A pesar del alto desempeño, se identifican varias limitaciones. Primero, el dataset es relativamente pequeño (22 sujetos); aunque el modelo generaliza bien en validación cruzada, al aplicarse a poblaciones más diversas (distintas edades, niveles de entrenamiento, patologías diferentes) podría requerir re-entrenamiento o calibración. La variabilidad inter-sujeto en señales EMG es alta debido a factores como anatomía, colocación de electrodos, etc., lo que siempre supone un desafío para generalizar ampliamente. Segundo, el modelo actual es supervisado, dependiendo de tener datos etiquetados (sujetos sanos vs lesionados); en escenarios reales las etiquetas pueden no estar disponibles tan claramente. Tercero, la interpretación médica del modelo debe tomarse con precaución: aunque identifica diferencias de activación, no provee directamente una explicación biomecánica (habría que complementarlo con análisis de especialistas). Desde el punto de vista técnico, el modelo CNN-LSTM conlleva cierta complejidad, lo que implica más tiempo de entrenamiento y necesidad de más datos en comparación con métodos más simples.\nPosibles mejoras: Para abordar las limitaciones, se proponen varias vías. Una es aplicar aumento de datos (data augmentation) en las señales EMG para simular variaciones y aumentar el tamaño efectivo del entrenamiento – por ejemplo, añadiendo ruido blanco adicional, escalado de amplitud aleatorio (simulando diferentes niveles de contracción) o ligeros shifts temporales en las ventanas. Esto puede mejorar la robustez del modelo ante ruido y variabilidad. Otra mejora sería incorporar más features de contexto, p. ej., añadir datos de acelerometría o ángulos articulares (en este dataset teníamos goniometría) en la entrada multimodal. Modelos multimodales EMG+movimiento han demostrado incrementar la precisión de detección de fatiga al sumar ambas fuentes. Asimismo, valdría la pena explorar arquitecturas alternativas emergentes, como las redes basadas en atención (Transformers) para series temporales, que podrían potencialmente captar relaciones a muy largo plazo entre eventos EMG. La regularización también podría optimizarse más: por ejemplo, técnicas como dropconnect o aumentar el factor de decaimiento L2 podrían prevenir aún más el sobreajuste si se incorporan más parámetros. Otra dirección es aplicar aprendizaje por transferencia: pre-entrenar la CNN en tareas afines (p. ej., clasificación de gestos con EMG de antebrazo) o con señales simuladas, y luego fine-tuning al caso de rodilla, lo que aprovecha conocimiento previo y mitiga la necesidad de grandes datos locales.\nAplicaciones prácticas: Los resultados de este trabajo tienen implicaciones interesantes en ámbitos deportivos y clínicos. En el rendimiento deportivo, un modelo así podría integrarse en un sistema de monitoreo para atletas: por ejemplo, analizando en tiempo real la activación muscular de un corredor o levantador de pesas, se podría detectar fatiga muscular antes de que cause lesión, dado que la EMG muestra patrones de fatiga (descenso de frecuencia mediana, reducción de amplitud). De hecho, la detección temprana de fatiga es crucial para prevenir lesiones por sobreesfuerzo; nuestro enfoque CNN-LSTM se mostró sensible a cambios sutiles que podrían usarse como alertas durante el entrenamiento. Otra aplicación deportiva es en la evaluación de técnica: comparando las secuencias EMG de un atleta con las de referencia, el modelo podría clasificar si un ejercicio se está realizando con la activación muscular correcta o si hay descompensaciones (por ej., un cuádriceps poco activado implicando que otra musculatura compensa, riesgo de lesión). En el ámbito de la rehabilitación y clínica, un sistema basado en EMG y deep learning podría asistir en el diagnóstico funcional de lesiones neuromusculares. Por ejemplo, pacientes post-lesión de ligamento podrían ser monitorizados: el modelo clasificaría su patrón EMG durante pruebas funcionales y detectaría deficiencias en la activación (como lo hizo diferenciando sanos vs lesionados en nuestro experimento). Esto ayudaría a objetivar el progreso en terapia física. También en personas mayores, la integración de EMG con IA está siendo explorada para predecir riesgo de caídas mediante evaluación de debilidad muscular sutil.\nLíneas futuras de investigación: Este caso práctico puede extenderse explorando la portabilidad del modelo a dispositivos wearables. Por ejemplo, emplear sensores EMG portátiles en deportistas en campo y procesar las señales con el modelo (posiblemente optimizado para ejecutarse en un teléfono o dispositivo embebido). También sería valioso investigar la extrapolación a múltiples clases: aquí usamos binaria (sano/lesión), pero podrían clasificarse distintos tipos de fatiga, niveles de esfuerzo o incluso predecir resultados (ej. detectar automáticamente qué ejercicio está realizando el atleta con solo EMG, lo cual sería un problema de Human Activity Recognition). Integrar datos de múltiples sesiones y días, incorporando efectos de recuperación, daría un panorama más completo de la confiabilidad del modelo a largo plazo. Desde la perspectiva del deep learning, probar arquitecturas como CNN 2D en mapas de tiempo-frecuencia (considerando la señal EMG convertida a espectrograma como imagen de entrada) podría aprovechar técnicas de visión por computador para clasificación, o incluso aplicando métodos de explicación XAI (eXplainable AI) para validar que las bases de la decisión del modelo concuerdan con la fisiología (p. ej., uso de Layer-wise Relevance Propagation para ver contribución de cada punto de la señal a la predicción).\n\nEn conclusión, desarrollamos un caso práctico completo de procesamiento de EMG orientado al rendimiento deportivo, abarcando desde la selección de un dataset adecuado hasta el entrenamiento e interpretación de un modelo profundo de clasificación. El modelo CNN-LSTM logró identificar con alta precisión patrones de activación muscular característicos de sujetos lesionados versus sanos, demostrando el potencial de las técnicas de deep learning en el análisis de señales biomédicas complejas. Este enfoque integrador de filtros digitales, extracción de features y redes neuronales avanzadas sienta las bases para aplicaciones reales, donde sistemas inteligentes podrían asistir a entrenadores y profesionales de la salud en el monitoreo objetivo de la función muscular, prevención de lesiones y personalización de entrenamientos. Las futuras mejoras propuestas apuntan a hacer estos sistemas más generales, explicables y adaptativos, allanando el camino para una fusión efectiva entre la biomecánica deportiva y la inteligencia artificial."
  },
  {
    "objectID": "tutoriales/TutorialPython.html",
    "href": "tutoriales/TutorialPython.html",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Tomado del libro Ciencia de Datos para Ciencias Naturales\nSi no tiene experiencia con el lenguaje Markdown utilice esta guía para enriquecer sus celdas de texto.\n\n\n\nPlataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código\n\n\n\n\n\nNo requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos.\n\n\n\n\n\nNo se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia.\n\n\n\n\n\nCódigo: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#características",
    "href": "tutoriales/TutorialPython.html#características",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Plataforma de Google Research.\nPermite a cualquier persona escribir y ejecutar código Python o R a través del navegador.\nSe base se basa en la interfase de Jupyter Notebook.\nLos documentos son denominados notebooks de Colab.\nLos entornos son interactivos.\nPermite la utilizar Python y R.\nManejo de celdas de código"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#ventajas",
    "href": "tutoriales/TutorialPython.html#ventajas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No requiere configuración del programa.\nLa mayoría de librerías y programas ya están preinstalados.\nAcceso gratuito a GPU, es decir, se ejecuta en los servidores de Google.\nFacilidad para compartir documentos."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "href": "tutoriales/TutorialPython.html#desventajas-de-colab",
    "title": "Tutorial de Python",
    "section": "",
    "text": "No se ejecuta sin conexión.\nConjuntos de datos que se importan al entorno sin ser montado desde Google Drive se perderán cuando la máquina virtual se apague.\nExperiencia más sencilla que otras opciones.\nPermite utilizar más lenguajes: Posgres, Julia."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "href": "tutoriales/TutorialPython.html#tipos-de-celdas",
    "title": "Tutorial de Python",
    "section": "",
    "text": "Código: Para abrir una celda de código simplemente haga click en la barra + Código. Para ejecutar el código puede presionar el símbolo de play a la izquierda de la celda o las teclas Cmd/Ctrl+Enter.\nTexto: Para abrir una celda de texto simplemente haga click en la barra + Texto. Las celdas de texto utilizan la sintaxis de Markdown. Para ver el texto fuente de Markdown, haga doble click en una celda de texto."
  },
  {
    "objectID": "tutoriales/TutorialPython.html#strings",
    "href": "tutoriales/TutorialPython.html#strings",
    "title": "Tutorial de Python",
    "section": "Strings",
    "text": "Strings\n\ncadena_caracteres = \" Diplomado en Analítica para la Banca \"\n\n#Tamaño de la cadena de caracteres\nprint(len(cadena_caracteres))\n\n#Corte de variable\nprint(cadena_caracteres[0:10])\nprint(cadena_caracteres[20:30])\n\n#Convertir la variable a mayúsculas\nprint(cadena_caracteres.upper())\n\n#Convertir la variable a minúscula\nprint(cadena_caracteres.lower())\n\n#Contar cuantas veces aparece una cadena de caracteres\nprint(cadena_caracteres.count(\"ca\"))\n\n#Reemplazar en una cadena, una letra con otra\nprint(cadena_caracteres.replace(\"a\", \"0\"))\n\n#Partir la cadena de caracteres cada vez que se encuentre un caracter\nprint(cadena_caracteres.split(\" \"))\n\n#Concatenar dos cadenas de caracteres\ncadena01 = \"Pablo Eduardo\"\ncadena02 = \"Caicedo Rodríguez\"\nprint(cadena01+\" \"+cadena02)\n\n38\n Diplomado\nica para l\n DIPLOMADO EN ANALÍTICA PARA LA BANCA \n diplomado en analítica para la banca \n2\n Diplom0do en An0lític0 p0r0 l0 B0nc0 \n['', 'Diplomado', 'en', 'Analítica', 'para', 'la', 'Banca', '']\nPablo Eduardo Caicedo Rodríguez"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#listas",
    "href": "tutoriales/TutorialPython.html#listas",
    "title": "Tutorial de Python",
    "section": "Listas",
    "text": "Listas\n\nlista = [3, 2, 1, 0.5, \"hora del cafe\", \"torta chilena\", \"pinto\", \"jugo\"]\nprint(lista)\nlista.append(\"empanadita\")\nprint(lista)\n\"pinto\" in lista\n\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo']\n[3, 2, 1, 0.5, 'hora del cafe', 'torta chilena', 'pinto', 'jugo', 'empanadita']\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#diccionarios",
    "href": "tutoriales/TutorialPython.html#diccionarios",
    "title": "Tutorial de Python",
    "section": "Diccionarios",
    "text": "Diccionarios\n\ntel = {'Maria': 4098, 'Jorge': 4139}\nprint(tel)\nprint(tel[\"Maria\"])\nprint(tel.keys())\nprint(tel.values)\n'Maria' in tel\n\n{'Maria': 4098, 'Jorge': 4139}\n4098\ndict_keys(['Maria', 'Jorge'])\n&lt;built-in method values of dict object at 0x720fb7562ac0&gt;\n\n\nTrue"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#tuplas",
    "href": "tutoriales/TutorialPython.html#tuplas",
    "title": "Tutorial de Python",
    "section": "Tuplas",
    "text": "Tuplas\n\nfrutas = ('naranja', 'mango', 'sandia', 'banano', 'kiwi')\nprint(type(frutas))\nfrutas[1]\n\n&lt;class 'tuple'&gt;\n\n\n'mango'"
  },
  {
    "objectID": "tutoriales/TutorialPython.html#numpy",
    "href": "tutoriales/TutorialPython.html#numpy",
    "title": "Tutorial de Python",
    "section": "Numpy",
    "text": "Numpy\nNumPy (Numerical Python), es una biblioteca de Python que da soporte para crear vectores y matrices grandes multidimensionales, junto con una gran colección de funciones matemáticas de alto nivel. La funcionalidad principal de NumPy es su estructura de datos ndarray (arreglos), para una matriz de n dimensiones, sobre las cuales se pueden realizar operaciones matemátias de manera eficiente.\nCrearemos una lista usando código nativo de Python y lo convertiremos en una matriz unidimensional con la función np.array()\n\nimport numpy as np\n\nlist1 = [6,8,10,12]\narray1 = np.array(list1)\nprint(array1)\n\n[ 6  8 10 12]\n\n\nLos ndarrays son estructuras de datos genéricas para almacenar datos homogéneos. Son equivalentes a las matrices y los vectores en álgebra, por lo que también se les puede aplicar operaciones matemáticas. Notar que las operaciones matemáticas se pueden realizar en todos los valores en un ndarray a la vez.\n\nprint(array1 - 2)\nprint(array1 * array1, \"\\n\\n\")\n\n[ 4  6  8 10]\n[ 36  64 100 144] \n\n\n\n\nLos arreglos se encierran entre [], pero al imprimirlos no están separados por comas. Hay diferentes formas de crear arreglos con propiedades específicas, lo que les provee bastante flexibilidad.\n\n# Crea una matriz con datos específicos\nprint(np.array([[1,2],[3,4]]),'\\n')\n# Crea una matriz con unos: tres filas y cuatro columnas\nprint(np.ones((3,4)),'\\n')\n# Crea una matriz con ceros: tres filas y cuatro columnas\nprint(np.zeros((3,4)),'\\n')\n# Crea una matriz con un dato específico: tres filas y cuatro columnas\nprint(np.full((3,4), 7.3),'\\n')\n# Crea un arreglo con datos seguidos: empieza en 10 termina en 30(sin incluir) con incrementos de 5.\nprint(np.arange(10,30,5),'\\n')\n# # Crea un arreglo con inicio y fin y una cantidad de datos: arreglo de 6 datos entre 0 y 5/3 .\nprint(np.linspace(0,5/3,6),'\\n')\n# Crea una matriz con datos aleatorios entre 0 y 1: dos filas y tres columnas\nprint(np.random.rand(2,3),'\\n')\n\n[[1 2]\n [3 4]] \n\n[[1. 1. 1. 1.]\n [1. 1. 1. 1.]\n [1. 1. 1. 1.]] \n\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]] \n\n[[7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]\n [7.3 7.3 7.3 7.3]] \n\n[10 15 20 25] \n\n[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] \n\n[[0.4409445  0.99325973 0.52099736]\n [0.18968462 0.84880753 0.17875338]] \n\n\n\n\narr1 = np.array([np.arange(0,5), np.arange(0,5)*5])\n#Arreglo\nprint(arr1, \"\\n\")\n# Forma\nprint(arr1.shape, \"\\n\")\n# Tamaño\nprint(arr1.size, \"\\n\")\n# Número de Dimensiones\nprint(arr1.ndim, \"\\n\")\n# Transpuesta\nprint(arr1.T, \"\\n\")\n\n[[ 0  1  2  3  4]\n [ 0  5 10 15 20]] \n\n(2, 5) \n\n10 \n\n2 \n\n[[ 0  0]\n [ 1  5]\n [ 2 10]\n [ 3 15]\n [ 4 20]] \n\n\n\n\narr = np.array([1,2,3,4,5,6,7])\n# Porcionar\nprint(arr[1:3])# de 1 al 3 en índice\nprint(arr[4:])# de la posición 4 en adelante\nprint(arr[::2])# de uno por medio\n\n[2 3]\n[5 6 7]\n[1 3 5 7]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nMachine Learning (ML) is a data-driven approach to building predictive models.\nIt is used in various applications such as healthcare, finance, and automation.\nIt is based on identifying patterns in data to make predictions or decisions."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#what-is-machine-learning-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\n\n\nML enables systems to learn from experience without being explicitly programmed.\nKey application areas include image recognition, natural language processing, and autonomous systems."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-supervised-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Supervised Learning",
    "text": "Types of Machine Learning – Supervised Learning\nSupervised Learning:\n- Uses labeled data to train models.\n- Example: Spam detection in emails (spam vs. non-spam).\n- Common algorithms: Linear Regression, Decision Trees, Support Vector Machines (SVM), Neural Networks."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-unsupervised-learnin",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Unsupervised Learnin",
    "text": "Types of Machine Learning – Unsupervised Learnin\nUnsupervised Learning:\n- Finds patterns in unlabeled data.\n- Example: Customer segmentation in marketing.\n- Common algorithms: K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#types-of-machine-learning-reinforcement-learning",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Types of Machine Learning – Reinforcement Learning",
    "text": "Types of Machine Learning – Reinforcement Learning\nReinforcement Learning:\n- Optimizes decision-making through rewards.\n- Example: Training an AI to play a game like Chess or Go.\n- Key components: Agent, Environment, Reward Signal."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nData:\n\nThe quality and quantity of data are fundamental.\nData preprocessing (cleaning, normalization, feature extraction) is crucial.\n\nModel:\n\nA mathematical representation of the problem.\nChosen based on the problem type (classification, regression, clustering)."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#key-components-of-an-ml-model-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Key Components of an ML Model",
    "text": "Key Components of an ML Model\n\nError function:\n\nEvaluates the difference between prediction and actual value.\nExample: Mean Squared Error (MSE) for regression, Cross-Entropy Loss for classification.\n\nOptimization:\n\nAlgorithms that adjust the model parameters to minimize error.\nCommon optimization techniques: Gradient Descent, Adam Optimizer."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nInductive Bias:\n\nPrior assumptions that the model uses to generalize.\nExample: Linear models assume data relationships are linear.\n\nSample Bias:\n\nDifferences between training data and real-world data.\nExample: A face recognition system trained on a specific demographic may perform poorly on others."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#bias-and-inductivity-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Bias and Inductivity",
    "text": "Bias and Inductivity\n\nBias-Variance Tradeoff:\n\nHigh Bias (Underfitting): The model is too simple, failing to capture patterns.\nHigh Variance (Overfitting): The model memorizes training data but fails on new data."
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#example-of-bias-and-variance",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Example of Bias and Variance",
    "text": "Example of Bias and Variance"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n1. Linear Regression (Supervised Learning - Regression)\n\nPredicts a continuous value based on input features.\nEquation: ( y = mx + b )\nExample: Predicting house prices based on square footage.\n\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nTrue\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\nSlope: [0.6]\n\n\nIntercept: 2.2"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n2. Decision Trees (Supervised Learning - Classification & Regression)\n\nSplits data into decision nodes to make predictions.\nExample: Diagnosing a disease based on symptoms.\n\n\n\nDecisionTreeClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFitted\n        \n            \n                Parameters\n                \n\n\n\n\ncriterion \n'gini'\n\n\n\nsplitter \n'best'\n\n\n\nmax_depth \nNone\n\n\n\nmin_samples_split \n2\n\n\n\nmin_samples_leaf \n1\n\n\n\nmin_weight_fraction_leaf \n0.0\n\n\n\nmax_features \nNone\n\n\n\nrandom_state \nNone\n\n\n\nmax_leaf_nodes \nNone\n\n\n\nmin_impurity_decrease \n0.0\n\n\n\nclass_weight \nNone\n\n\n\nccp_alpha \n0.0\n\n\n\nmonotonic_cst \nNone\n\n\n\n\n            \n        \n    \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n3. K-Means Clustering (Unsupervised Learning)\n\nGroups similar data points together.\nExample: Customer segmentation in marketing.\n\n\n\nCluster Centers: [[10.  2.]\n [ 1.  2.]]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n4. Support Vector Machines (SVM) (Supervised Learning - Classification)\n\nFinds a hyperplane that best separates different classes.\nExample: Classifying tumors as benign or malignant.\n\n\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVC?Documentation for SVCiFitted\n        \n            \n                Parameters\n                \n\n\n\n\nC \n1.0\n\n\n\nkernel \n'rbf'\n\n\n\ndegree \n3\n\n\n\ngamma \n'scale'\n\n\n\ncoef0 \n0.0\n\n\n\nshrinking \nTrue\n\n\n\nprobability \nFalse\n\n\n\ntol \n0.001\n\n\n\ncache_size \n200\n\n\n\nclass_weight \nNone\n\n\n\nverbose \nFalse\n\n\n\nmax_iter \n-1\n\n\n\ndecision_function_shape \n'ovr'\n\n\n\nbreak_ties \nFalse\n\n\n\nrandom_state \nNone\n\n\n\n\n            \n        \n    \n\n\nPrediction for [1,1]: [1]"
  },
  {
    "objectID": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "href": "presentaciones/APSB/Lect006_MachineLearningIntroduction.html#basic-machine-learning-algorithms-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Basic Machine Learning Algorithms",
    "text": "Basic Machine Learning Algorithms\n\n5. Reinforcement Learning Example\n\nUses rewards and penalties to train an agent to make optimal decisions.\nExample: A robot learning to navigate a maze.\n\n\n\nTrained Q-Table:\n [[0.31407947 0.3691176  0.51597719 0.60669064 0.9559821 ]\n [0.40340928 0.51894429 0.65834385 0.96597025 1.38060246]\n [0.55644086 0.72657418 1.02361376 1.43665891 1.92871392]\n [0.64663944 0.84660174 1.48015389 2.42723958 4.98561835]\n [0.61772327 1.05157125 2.14529239 4.73712503 0.        ]]"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html",
    "href": "presentaciones/APSB/Lect004_LINUX.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Definition: Linux is a free, open-source operating system (OS) based on Unix, created by Linus Torvalds in 1991.\nKey Features:\n\nOpen-source: Anyone can view, modify, and distribute the source code.\nFree to use: No licensing fees.\nMulti-user and multitasking.\n\nStructure: Comprises a kernel (core of the OS) and various utilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\n\nControls the hardware.\nTypes of linux kernel\n\nMonolithic kernel: All the concurrent processes are executed simultaneously in the kernel itself. All the processes share same memory recourses.\nMicro kernel: user services and kernel services are executed in separate address spaces. User services are kept in user address space and kernel services are kept in kernel address space.\nHybrid kernel: this kernel has the monolithic speed and the stability of the micro.\n\n\n\n\n\n\nAdapted from Geeksforgeeks\n\n\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks\n\n\n\n\n\n\n\n\n\n\n\n\n\nShell\n\n\n\nThe shell serves as an interface to the kernel, acting as a bridge between the user and the system’s core operations. It hides the internal workings of the kernel, allowing users to perform tasks without needing to understand the underlying processes. Users simply enter a command, and the shell leverages the kernel’s functions to execute the specified task.\n\n\n\n\nAdapted from Geeksforgeeks\n\n\n\n\nFlexibility: Runs on a wide range of devices (PCs, servers, smartphones, embedded systems).\nSecurity: Highly secure and less vulnerable to malware.\nCommunity Support: Strong open-source community for development and troubleshooting.\nCustomization: Highly configurable; users can tailor it to specific needs.\nPerformance: Efficient resource utilization, ideal for servers and low-end devices.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\nLinux\nWindows\nmacOS\n\n\n\n\nCost\nFree\nPaid\nPaid\n\n\nSource Code\nOpen-source\nProprietary\nProprietary\n\n\nSecurity\nHighly secure\nVulnerable to malware\nSecure\n\n\nCustomization\nHigh\nLow\nLow\n\n\nUsage\nServers, DevOps, IoT\nDesktop, Gaming\nCreative industries\n\n\n\n\n\n\n\nWhat are Distributions (Distros)?\nVariants of Linux tailored for specific purposes.\nPopular Distros:\n\nUbuntu: User-friendly, great for beginners.\nDebian: Stable and widely supported.\nFedora: Cutting-edge technologies.\nCentOS/Red Hat: Enterprise-level stability.\nKali Linux: Security and penetration testing.\n\n\n\n\n\n\nEveryday Use: Desktops and laptops (e.g., Ubuntu, Mint).\nServers: Powers most web servers, databases, and cloud infrastructure.\nEmbedded Systems: Used in IoT devices, routers, and automotive systems.\nSupercomputers: Runs on 100% of the top 500 supercomputers.\nProgramming & Development: Preferred OS for software developers."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#what-is-linux",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Definition: Linux is a free, open-source operating system (OS) based on Unix, created by Linus Torvalds in 1991.\nKey Features:\n\nOpen-source: Anyone can view, modify, and distribute the source code.\nFree to use: No licensing fees.\nMulti-user and multitasking.\n\nStructure: Comprises a kernel (core of the OS) and various utilities."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Kernel\n\n\n\n\nControls the hardware.\nTypes of linux kernel\n\nMonolithic kernel: All the concurrent processes are executed simultaneously in the kernel itself. All the processes share same memory recourses.\nMicro kernel: user services and kernel services are executed in separate address spaces. User services are kept in user address space and kernel services are kept in kernel address space.\nHybrid kernel: this kernel has the monolithic speed and the stability of the micro.\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Kernel\n\n\n\n\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "href": "presentaciones/APSB/Lect004_LINUX.html#the-linux-structure-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Shell\n\n\n\nThe shell serves as an interface to the kernel, acting as a bridge between the user and the system’s core operations. It hides the internal workings of the kernel, allowing users to perform tasks without needing to understand the underlying processes. Users simply enter a command, and the shell leverages the kernel’s functions to execute the specified task.\n\n\n\n\nAdapted from Geeksforgeeks"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "href": "presentaciones/APSB/Lect004_LINUX.html#why-is-linux-popular",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Flexibility: Runs on a wide range of devices (PCs, servers, smartphones, embedded systems).\nSecurity: Highly secure and less vulnerable to malware.\nCommunity Support: Strong open-source community for development and troubleshooting.\nCustomization: Highly configurable; users can tailor it to specific needs.\nPerformance: Efficient resource utilization, ideal for servers and low-end devices."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-vs-other-operating-systems",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Feature\nLinux\nWindows\nmacOS\n\n\n\n\nCost\nFree\nPaid\nPaid\n\n\nSource Code\nOpen-source\nProprietary\nProprietary\n\n\nSecurity\nHighly secure\nVulnerable to malware\nSecure\n\n\nCustomization\nHigh\nLow\nLow\n\n\nUsage\nServers, DevOps, IoT\nDesktop, Gaming\nCreative industries"
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "href": "presentaciones/APSB/Lect004_LINUX.html#linux-distributions",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "What are Distributions (Distros)?\nVariants of Linux tailored for specific purposes.\nPopular Distros:\n\nUbuntu: User-friendly, great for beginners.\nDebian: Stable and widely supported.\nFedora: Cutting-edge technologies.\nCentOS/Red Hat: Enterprise-level stability.\nKali Linux: Security and penetration testing."
  },
  {
    "objectID": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "href": "presentaciones/APSB/Lect004_LINUX.html#applications-of-linux",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Everyday Use: Desktops and laptops (e.g., Ubuntu, Mint).\nServers: Powers most web servers, databases, and cloud infrastructure.\nEmbedded Systems: Used in IoT devices, routers, and automotive systems.\nSupercomputers: Runs on 100% of the top 500 supercomputers.\nProgramming & Development: Preferred OS for software developers."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Definition\n\n\n\nEdge AI Is the combination of EDGE devices and Artificial Intelligence Algorithms\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe accelerometer-based wristband sensor.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaken from “Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing” (Zhou et. al., Proceedings of the IEEE, 2019)\n\n\n\n\n\n\n\n\n\n\n\nEmbedded ML\n\n\n\n\nEmbedded ML is the art and science of running machine learning models on embedded systems.\nEmbedded ML, we’re usually refers to machine learning inference.\nThe training part usually still takes place on a conventional computer.\nHigh requirements of ROM(Model Storing), RAM(Storing intermediate results), computer capabilities(computational intensive tasks).\nEmbedded machine learning is often deployed alongside digital signal processing algorithms\nTiny machine learning, or TinyML, is the concept of doing this on the most constrained embedded hardware available.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBandwith\n\n\n\nIt’s related to the quantity of information you could send via some kind of connection. More bandwith it’s needed to send more data. Example: Imagine a smart sensor that monitors the vibration of an magnetic resonator to determine if it is operating correctly. It might use a simple thresholding algorithm to understand when the machine is vibrating too much, or not enough, and then communicate this information via a low bandwidth radio connection.\n\n\n\n\n\n\n\n\nLatency\n\n\n\nIt’s related to the time you must wait for the reponse of the sensor. Example: Edge AI solves this problem by removing the round-trip time altogether. A great example of this is a self-driving car. The car’s AI systems run on onboard computers. This allows it to react nearly instantly to changing conditions, like the driver in front slamming on their brakes.\n\n\n\n\n\n\n\n\n\nEconomy\n\n\n\nConnectivity costs a lot of money. By processing data on-device, edge AI systems reduce or avoid the costs of transmitting data over a network and processing it in the cloud. Example: Edge AI enables healthcare providers to monitor patients in real time without sending data to the cloud for processing. For example, wearable devices with built-in AI algorithms can analyze physiological signals such as heart rate, oxygen levels, and ECG data locally. This reduces the reliance on cloud services for data transmission and processing.\n\n\n\n\n\n\n\n\nReliability\n\n\n\nSystems controlled by on-device AI are potentially more reliable than those that depend on a connection to the cloud. When you add wireless connectivity to a device, you’re adding a vast, overwhelmingly complex web of dependencies, from link-layer communications technologies to the internet servers that may run your application. Example: Traditional Cloud-Based Systems: Data collected by wearable devices must be transmitted to a cloud server, analyzed, and then results are sent back to caregivers or emergency responders. This can introduce delays due to network latency or connectivity issues. Edge AI Systems: Processes the sensor data locally in real time, enabling instant detection of falls or other anomalies.Improvement: Reduces detection and response time from minutes to milliseconds, ensuring immediate action during emergencies.\n\n\n\n\n\n\n\n\n\n\nPrivacy\n\n\n\nEdge AI provides an alternative. Rather than streaming live video and audio to a remote server, a security camera could use some onboard intelligence to identify that an intruder is present when the owners are out at work. It could then alert the owners in an appropriate way. When data is processed on an embedded system and is never transmitted to the cloud, user privacy is protected and there is less chance of abuse."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Definition\n\n\n\nEdge AI Is the combination of EDGE devices and Artificial Intelligence Algorithms\n\n\n\n\n\n\n\n\nExample\n\n\n\nThe accelerometer-based wristband sensor."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Taken from “Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing” (Zhou et. al., Proceedings of the IEEE, 2019)"
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#edge-ai-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Embedded ML\n\n\n\n\nEmbedded ML is the art and science of running machine learning models on embedded systems.\nEmbedded ML, we’re usually refers to machine learning inference.\nThe training part usually still takes place on a conventional computer.\nHigh requirements of ROM(Model Storing), RAM(Storing intermediate results), computer capabilities(computational intensive tasks).\nEmbedded machine learning is often deployed alongside digital signal processing algorithms\nTiny machine learning, or TinyML, is the concept of doing this on the most constrained embedded hardware available."
  },
  {
    "objectID": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "href": "presentaciones/APSB/Lect003_EDGEAI.html#blerp",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Bandwith\n\n\n\nIt’s related to the quantity of information you could send via some kind of connection. More bandwith it’s needed to send more data. Example: Imagine a smart sensor that monitors the vibration of an magnetic resonator to determine if it is operating correctly. It might use a simple thresholding algorithm to understand when the machine is vibrating too much, or not enough, and then communicate this information via a low bandwidth radio connection.\n\n\n\n\n\n\n\n\nLatency\n\n\n\nIt’s related to the time you must wait for the reponse of the sensor. Example: Edge AI solves this problem by removing the round-trip time altogether. A great example of this is a self-driving car. The car’s AI systems run on onboard computers. This allows it to react nearly instantly to changing conditions, like the driver in front slamming on their brakes.\n\n\n\n\n\n\n\n\n\nEconomy\n\n\n\nConnectivity costs a lot of money. By processing data on-device, edge AI systems reduce or avoid the costs of transmitting data over a network and processing it in the cloud. Example: Edge AI enables healthcare providers to monitor patients in real time without sending data to the cloud for processing. For example, wearable devices with built-in AI algorithms can analyze physiological signals such as heart rate, oxygen levels, and ECG data locally. This reduces the reliance on cloud services for data transmission and processing.\n\n\n\n\n\n\n\n\nReliability\n\n\n\nSystems controlled by on-device AI are potentially more reliable than those that depend on a connection to the cloud. When you add wireless connectivity to a device, you’re adding a vast, overwhelmingly complex web of dependencies, from link-layer communications technologies to the internet servers that may run your application. Example: Traditional Cloud-Based Systems: Data collected by wearable devices must be transmitted to a cloud server, analyzed, and then results are sent back to caregivers or emergency responders. This can introduce delays due to network latency or connectivity issues. Edge AI Systems: Processes the sensor data locally in real time, enabling instant detection of falls or other anomalies.Improvement: Reduces detection and response time from minutes to milliseconds, ensuring immediate action during emergencies.\n\n\n\n\n\n\n\n\n\n\nPrivacy\n\n\n\nEdge AI provides an alternative. Rather than streaming live video and audio to a remote server, a security camera could use some onboard intelligence to identify that an intruder is present when the owners are out at work. It could then alert the owners in an appropriate way. When data is processed on an embedded system and is never transmitted to the cloud, user privacy is protected and there is less chance of abuse."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Data acquisition is to capture the signal and encode in a form suitable for computer processing.\nSignal conditioning is to remove noise and artifacts from the signal.\nFeature extraction is to extract relevant information from the signal.\nHypothesis testing is to test the hypothesis based on the extracted features.\n\n\n\n\n\n\n\n\n\n\nBase Information\n\n\n\n\nA 12-lead electrocardiogram for arrhythmia study - Article\nA 12-lead electrocardiogram for arrhythmia study - Data\n\n\n\n\n\n\n\ndata  = sio.loadmat(path_ecg+\"/JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\nprint(data.keys())\n\ndict_keys(['val'])\n\nprint(type(data['val']))\n\n&lt;class 'numpy.ndarray'&gt;\n\nprint(data['val'].shape)\n\n(12, 5000)"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#introduction",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Data acquisition is to capture the signal and encode in a form suitable for computer processing.\nSignal conditioning is to remove noise and artifacts from the signal.\nFeature extraction is to extract relevant information from the signal.\nHypothesis testing is to test the hypothesis based on the extracted features."
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-condtioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "Base Information\n\n\n\n\nA 12-lead electrocardiogram for arrhythmia study - Article\nA 12-lead electrocardiogram for arrhythmia study - Data"
  },
  {
    "objectID": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "href": "presentaciones/PSIM/Lect003_Intro_PSIM.html#signal-conditioning",
    "title": "Procesamiento de Señales e Imagenes",
    "section": "",
    "text": "data  = sio.loadmat(path_ecg+\"/JS00001.mat\")\n\n\nprint(type(data))\n\n&lt;class 'dict'&gt;\n\nprint(data.keys())\n\ndict_keys(['val'])\n\nprint(type(data['val']))\n\n&lt;class 'numpy.ndarray'&gt;\n\nprint(data['val'].shape)\n\n(12, 5000)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html",
    "href": "presentaciones/APSB/Lect001_Presentacion.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Doctor en Ciencias de la Electrónica.\nMagister en Ingeniería Electrónica y Telecomunicaciones\nIngeniero en Electrónica y Telecomunicaciones\n\n\n\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\n\n\n\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\n\n\n\npablo.caicedo@escuelaing.edu.co\n\n\n\n\n\n\n\n\n\n\n\nIntroducción a inteligencia artificial en el borde (EDGE AI).\nHardware y software para EDGE AI.\nEl flujo de trabajo de EDGE AI.\nDiseño, desarrollo y evaluación de sistemas EDGE AI.\n\n\n\n\n\n\n\nClases magistrales\nDesarrollo de ejercicios en clase\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso\n\n\n\n\n\n\n\nLaboratorios (60%)\nProyecto Final (40%)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (30%)\nLaboratorios (30%)\nProyecto final (40%)\n\n\n\n\n\n\n\n\n\n\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201.\n\n\nInterpretes: R y python.\nOS: Linux\nLenguajes: C/C++\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell\n\n\n\n\n\n[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980.\n[42] D. Situnayake y J. Plunkett, AI at the Edge: solving real-world problems with embedded machine learning. Sebastopol: O’Reilly, 2023.\n[43] X. Wang, Y. Han, V. C. M. Leung, D. Niyato, X. Yan, y X. Chen, Edge AI: Convergence of Edge Computing and Artificial Intelligence. Singapore: Springer Singapore, 2020. doi: 10.1007/978-981-15-6186-3.\n[44] A. Koul, S. Ganju, y M. Kasam, «Practical Deep Learning for Cloud, Mobile, and Edge».\n[45] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[46] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[47] V. Subramanian, Deep learning with PyTorch: a practical approach to building neural network models using PyTorch. Birmingham, UK: Packt Publishing, 2018.\n[48] Diagnostic Biomedical Signal and Image Processing Applications with Deep Learning Methods. Elsevier, 2023. doi: 10.1016/C2021-0-02190-8.\n[49] J. D. Kelleher, B. Mac Namee, y A. D’Arcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed. Cambridge: The MIT press, 2020.\n[50] A. A. Patel, «Hands-On Unsupervised Learning Using Python».\n[51] P. Raj, P. B. Soundarabai, y P. Augustine, Machine Intelligence: Computer Vision and Natural Language Processing, 1.ª ed. Boca Raton: Auerbach Publications, 2023. doi: 10.1201/9781003424550.\n[52] M. Roy y L. R. Gupta, Eds., Machine Learning and Data Analytics for Predicting, Managing, and Monitoring Disease: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2021. doi: 10.4018/978-1-7998-7188-0.\n[53] A. R. Jha, Mastering PyTorch: create and deploy deep learning models from CNNs to multimodal models, LLMs, and beyond, Second edition. en Expert insight. Birmingham: Packt Publishing Limited, 2024.\n[54] V. K. Ayyadevara y Y. Reddy, Modern computer vision with PyTorch: a practical roadmap from deep learning fundamentals to advanced applications and Generative AI, Second edition. Birmingham, UK: Packt Publishing Ltd., 2024.\n[55] E. Priya y V. Rajinikanth, Eds., Signal and Image Processing Techniques for the Development of Intelligent Healthcare Systems. Singapore: Springer Singapore, 2021. doi: 10.1007/978-981-15-6141-2.\n[56] M. M. Richter, S. Paul, V. Këpuska, y M. Silaghi, Signal Processing and Machine Learning with Applications. Cham: Springer International Publishing, 2022. doi: 10.1007/978-3-319-45372-9."
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#el-profesor",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Doctor en Ciencias de la Electrónica.\nMagister en Ingeniería Electrónica y Telecomunicaciones\nIngeniero en Electrónica y Telecomunicaciones\n\n\n\nProcesamiento de Imágenes, Dispositivos para el análisis de movimiento humano, ciencia de los datos, IA.\n\n\n\n\nProfesor del Centro de Estudios en Biomédica y Biotecnogía\nProfesor en la línea de Procesmiento de Señales e Imágenes\n\n\n\npablo.caicedo@escuelaing.edu.co"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#contenido-del-curso",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Introducción a inteligencia artificial en el borde (EDGE AI).\nHardware y software para EDGE AI.\nEl flujo de trabajo de EDGE AI.\nDiseño, desarrollo y evaluación de sistemas EDGE AI."
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#estrategías-de-aprendizaje",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Clases magistrales\nDesarrollo de ejercicios en clase\nPrácticas de laboratorio, donde se utilizarán herramientas computacionales y se aplicarán conocimientos y destrezas adquiridas en otros cursos\nLecturas de la temática a tratar, previas a las clases magistrales\nLecturas de artículos científicos de interés para el área de procesamiento de señales e imágenes\nDesarrollo de talleres fuera de la clase\nProyecto práctico de fin de curso"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluación",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluación",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Laboratorios (60%)\nProyecto Final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#evaluación-1",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#evaluación-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Primer tercio (30%)\nSegundo tercio (30%)\nTercer tercio (40%)\n\n\n\n\nLaboratorios (30%)\nLaboratorios (30%)\nProyecto final (40%)"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#recursos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Martes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201.\n\n\nInterpretes: R y python.\nOS: Linux\nLenguajes: C/C++\nIDE: Visual Studio Code, Google Colaboratory, RStudio, PyCharm, Dataspell"
  },
  {
    "objectID": "presentaciones/APSB/Lect001_Presentacion.html#bibliografía",
    "href": "presentaciones/APSB/Lect001_Presentacion.html#bibliografía",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "[1] «Medical Image Analysis and Informatics».\n[2] S. K. Zhou, D. Rueckert, y G. Fichtinger, Handbook of medical image computing and computer assisted intervention. en The Elsevier and MICCAI society book series. London: Academic press, 2020.\n[3] W. Zhao, Technology-Enabled Motion Sensing and Activity Tracking for Rehabilitation. Institution of Engineering and Technology, 2022. doi: 10.1049/PBHE037E.\n[4] S. K. Vasudevan, A. Baskar, M. Rajappa, y T. S. Murugesh, Digital Image Processing, 1.ª ed. Boca Raton: Chapman and Hall/CRC, 2023. doi: 10.1201/9781003217428.\n[5] J. Valente, J. António, C. Mora, y S. Jardim, «Developments in Image Processing Using Deep Learning and Reinforcement Learning», J. Imaging, vol. 9, n.º 10, p. 207, sep. 2023, doi: 10.3390/jimaging9100207.\n[6] T. T. Teoh, Convolutional Neural Networks for Medical Applications. en SpringerBriefs in Computer Science. Singapore: Springer Nature Singapore, 2023. doi: 10.1007/978-981-19-8814-1.\n[7] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[8] J. S. Suri, D. L. Wilson, y S. Laxminarayan, Eds., Handbook of biomedical image analysis. en Biomedical engineering international book series. New York: Kluwer Academic/Plenum Publishers, 2005.\n[9] R. Splinter y K. Najarian, «Biomedical Signal and Image Processing, Second Edition».\n[10] P. Singhal, A. Verma, P. K. Srivastava, V. Ranga, y R. Kumar, Image Processing and Intelligent Computing Systems, 1.ª ed. Boca Raton: CRC Press, 2022. doi: 10.1201/9781003267782.\n[11] H. Singh, Practical Machine Learning and Image Processing: For Facial Recognition, Object Detection, and Pattern Recognition Using Python. Berkeley, CA: Apress, 2019. doi: 10.1007/978-1-4842-4149-3.\n[12] J. L. Semmlow y B. Griffel, Biosignal and medical image processing, Third edition. Boca Raton: CRC Press, Taylor & Francis Group, CRC Press is an imprint of the Taylor & Francis Group, an Informa business, 2014.\n[13] S. Saxena y S. Paul, Eds., High-performance medical image processing, First edition. Palm Bay, FL, USA, Burlington, ON, Canada: Apple Academic Press ; CRC Press, 2022.\n[14] R. Raut, «Intelligent Systems for Rehabilitation Engineering».\n[15] R. M. Rangayyan, Biomedical signal analysis: a case-study approach. en IEEE Press series in biomedical engineering. New York, NY: Wiley-Interscience [u.a.], 2002.\n[16] R. M. Rangayyan, «Biomedical Signal Analysis».\n[17] K. Rabie, C. Karthik, S. Chowdhury, y P. K. Dutta, Eds., Deep learning in medical image processing and analysis. London, United Kingdom: Institution of Engineering and Technology, 2023.\n[18] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[19] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[20] L. Panigrahi, S. Biswal, A. K. Bhoi, A. Kalam, y P. Barsocchi, Eds., Machine Learning and AI Techniques in Interactive Medical Image Analysis: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2022. doi: 10.4018/978-1-6684-4671-3.\n[21] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[22] M. Morioka, «Artificial Intelligence, Robots, and Philosophy».\n[23] L. N. McKinnis, «Fundamentals of Musculoskeletal Imaging, Fifth Edition».\n[24] T. Malone, C. Hazle, y M. L. Grey, Imaging in rehabilitation. New York: McGraw-Hill Medical, 2008.\n[25] X. Liu et al., «Advances in Deep Learning-Based Medical Image Analysis», Health Data Sci, vol. 2021, p. 8786793, ene. 2021, doi: 10.34133/2021/8786793.\n[26] C.-P. Lim, A. Vaidya, Y.-W. Chen, T. Jain, y L. C. Jain, Eds., Artificial Intelligence and Machine Learning for Healthcare: Vol. 1: Image and Data Analytics, vol. 228. en Intelligent Systems Reference Library, vol. 228. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-11154-9.\n[27] A. Kulkarni, A. Shivananda, y N. R. Sharma, Computer Vision Projects with PyTorch: Design and Develop Production-Grade Models. Berkeley, CA: Apress, 2022. doi: 10.1007/978-1-4842-8273-1.\n[28] F. A. Gonzalez y E. Romero, Eds., Biomedical Image Analysis and Machine Learning Technologies: Applications and Techniques. en Advances in Bioinformatics and Biomedical Engineering. IGI Global, 2010. doi: 10.4018/978-1-60566-956-4.\n[29] T. M. Deserno, Ed., Biomedical Image Processing. en Biological and Medical Physics, Biomedical Engineering. Berlin, Heidelberg: Springer Berlin Heidelberg, 2011. doi: 10.1007/978-3-642-15816-2.\n[30] D. Cudihins, Hands-on computer vision with Julia: build complex applications with advanced Julia packages for image processing, neural networks, and artificial intelligence. Birmingham, UK: Packt Publishing, 2018.\n[31] M. Charbit, Digital signal processing with Python programming. London, UK : Hoboken, NJ: ISTE ; Wiley, 2017.\n[32] M. Chappell, Principles of Medical Imaging for Engineers: From Signals to Images. Cham: Springer International Publishing, 2019. doi: 10.1007/978-3-030-30511-6.\n[33] L. Cai, J. Gao, y D. Zhao, «A review of the application of deep learning in medical image classification and segmentation», Ann Transl Med, vol. 8, n.º 11, pp. 713-713, jun. 2020, doi: 10.21037/atm.2020.02.44.\n[34] J. D. Bronzino, Ed., The biomedical engineering handbook, 3rd ed. en The electrical engineering handbook series. Boca Raton: CRC/Taylor & Francis, 2006.\n[35] J. D. Gibson, Fourier Transforms, Filtering, Probability and Random Processes: Introduction to Communication Systems. en Synthesis Lectures on Communications. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-19580-8.\n[36] G. R. Grimmett y D. R. Stirzaker, Probability and random processes fourth edition, 4.ª ed. NEW YORK: OXFORD UNIVERSITY PRESS, 2020.\n[37] Probability and Random Processes With Applications to Signal Processing and Communications. San Diego, CA, USA: Elsevier Science & Technology Books, 2012.\n[39] L. Wasserman, All of Statistics: A Concise Course in Statistical Inference. en Springer Texts in Statistics. New York, NY: Springer New York, 2004. doi: 10.1007/978-0-387-21736-9.\n[40] R. C. Gonzalez y R. E. Woods, Digital image processing. New York, NY: Pearson, 2018.\n[41] T. M. Apostol, Calculus. 1: One-variable calculus, with an introduction to linear algebra. New York: Wiley, 1980.\n[42] D. Situnayake y J. Plunkett, AI at the Edge: solving real-world problems with embedded machine learning. Sebastopol: O’Reilly, 2023.\n[43] X. Wang, Y. Han, V. C. M. Leung, D. Niyato, X. Yan, y X. Chen, Edge AI: Convergence of Edge Computing and Artificial Intelligence. Singapore: Springer Singapore, 2020. doi: 10.1007/978-981-15-6186-3.\n[44] A. Koul, S. Ganju, y M. Kasam, «Practical Deep Learning for Cloud, Mobile, and Edge».\n[45] C. Paunwala et al., Eds., Biomedical Signal and Image Processing with Artificial Intelligence. en EAI/Springer Innovations in Communication and Computing. Cham: Springer International Publishing, 2023. doi: 10.1007/978-3-031-15816-2.\n[46] G. R. Naik y W. P. D. Santos, Biomedical Signal Processing: A Modern Approach, 1.ª ed. Boca Raton: CRC Press, 2023. doi: 10.1201/9781003201137.\n[47] V. Subramanian, Deep learning with PyTorch: a practical approach to building neural network models using PyTorch. Birmingham, UK: Packt Publishing, 2018.\n[48] Diagnostic Biomedical Signal and Image Processing Applications with Deep Learning Methods. Elsevier, 2023. doi: 10.1016/C2021-0-02190-8.\n[49] J. D. Kelleher, B. Mac Namee, y A. D’Arcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed. Cambridge: The MIT press, 2020.\n[50] A. A. Patel, «Hands-On Unsupervised Learning Using Python».\n[51] P. Raj, P. B. Soundarabai, y P. Augustine, Machine Intelligence: Computer Vision and Natural Language Processing, 1.ª ed. Boca Raton: Auerbach Publications, 2023. doi: 10.1201/9781003424550.\n[52] M. Roy y L. R. Gupta, Eds., Machine Learning and Data Analytics for Predicting, Managing, and Monitoring Disease: en Advances in Medical Technologies and Clinical Practice. IGI Global, 2021. doi: 10.4018/978-1-7998-7188-0.\n[53] A. R. Jha, Mastering PyTorch: create and deploy deep learning models from CNNs to multimodal models, LLMs, and beyond, Second edition. en Expert insight. Birmingham: Packt Publishing Limited, 2024.\n[54] V. K. Ayyadevara y Y. Reddy, Modern computer vision with PyTorch: a practical roadmap from deep learning fundamentals to advanced applications and Generative AI, Second edition. Birmingham, UK: Packt Publishing Ltd., 2024.\n[55] E. Priya y V. Rajinikanth, Eds., Signal and Image Processing Techniques for the Development of Intelligent Healthcare Systems. Singapore: Springer Singapore, 2021. doi: 10.1007/978-981-15-6141-2.\n[56] M. M. Richter, S. Paul, V. Këpuska, y M. Silaghi, Signal Processing and Machine Learning with Applications. Cham: Springer International Publishing, 2022. doi: 10.1007/978-3-319-45372-9."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html",
    "href": "presentaciones/APSB/Lect005_Methods.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Problem Definition & Use Case Analysis\nData Collection & Preprocessing\nModel Selection & Optimization\nHardware Selection\nDeployment & Model Inference\nTesting, Validation, and Continuous Improvement\nFinal Deployment & Scaling\n\n\n\n\n\nIdentify the specific AI task (e.g., real-time ECG analysis, fall detection, predictive maintenance in IoT).\nDetermine operational constraints, including:\n\nPower consumption (battery-operated vs. wired).\nLatency requirements (real-time processing vs. periodic updates).\nCommunication needs (Wi-Fi, Bluetooth, LoRa, standalone processing).\n\n\n\n\n\n\nSensor Selection: Choose sensors relevant to the application (e.g., accelerometers for motion tracking, biosensors for health monitoring).\nEdge-Compatible Data Acquisition: Optimize data formats to reduce memory and computational load.\nPreprocessing on Edge:\n\nSignal filtering (e.g., noise reduction in biomedical signals).\nFeature extraction (e.g., time-series features for motion classification).\n\n\n\n\n\n\nModel Selection:\n\nLightweight CNNs (for image processing).\nRecurrent Neural Networks (RNNs) / LSTMs (for time-series data like ECG).\nTinyML models optimized for microcontrollers (e.g., TensorFlow Lite, PyTorch Mobile).\n\nModel Optimization for Edge Deployment:\n\nQuantization: Convert floating-point models to int8 or int16 to reduce size and computation load.\nPruning: Remove unnecessary neurons or layers while preserving accuracy.\nDistillation: Train a smaller model using knowledge from a larger one.\n\n\n\n\n\n\nProcessing Unit:\n\nMicrocontrollers (MCUs) (e.g., ARM Cortex-M, ESP32) → Low-power, simple AI tasks.\nEdge AI Accelerators (e.g., Google Edge TPU, NVIDIA Jetson Nano) → More complex AI processing.\nFPGAs (Field-Programmable Gate Arrays) → Custom AI workloads for high-speed processing.\n\nMemory & Storage:\n\nRAM Optimization: Choose embedded SRAM or external DRAM depending on model size.\nFlash Storage: Store inference models efficiently.\n\nConnectivity:\n\nOffline processing for low-latency applications.\nEdge-to-cloud integration for periodic updates.\n\n\n\n\n\n\nConvert trained AI models into optimized edge-compatible formats (e.g., TensorFlow Lite, ONNX).\nImplement real-time inference using hardware-accelerated libraries (e.g., TensorRT, OpenVINO).\nOptimize firmware for energy efficiency using duty-cycling techniques (process only when necessary).\n\n\n\n\n\nEdge Benchmarking:\n\nMeasure inference speed and power consumption.\nValidate model accuracy on real-world edge-generated data.\n\nSecurity & Reliability:\n\nImplement secure boot & firmware updates to prevent cyber threats.\nEnsure robust error handling for sensor malfunctions.\n\nFeedback & Model Updating:\n\nIf connected to a cloud system, update models periodically using federated learning.\nOptimize AI pipelines with incremental learning on-device where feasible.\n\n\n\n\n\n\nDeploy at scale, ensuring the Edge AI model adapts to different environments.\nImplement remote monitoring & diagnostics for predictive maintenance.\nEnable over-the-air (OTA) updates to improve AI models post-deployment.\n\n\n\n\nThe hardware-software co-design approach is the most widely used methodology for Edge AI device development. It ensures:\n\nReal-time performance with optimized AI models.\nEnergy-efficient processing for battery-operated or low-power devices.\nScalability and security in edge environments.\n\nThis methodology is industry-standard and used by leading companies in healthcare, automotive, and industrial IoT, ensuring robust and reliable Edge AI solutions.\n\n\n\n\n\n\n\n\n\nUse case\n\n\n\nA wearable ECG monitoring device designed for continuous heart health tracking and arrhythmia detection. This Edge AI-based solution analyzes ECG signals in real-time on a low-power microcontroller, providing instant alerts for cardiac irregularities without relying on cloud computing.\n\n\n\n\n\n\n\n\n\n\n\nObjective\n\n\n\nDetect abnormal heart rhythms (arrhythmias) in real-time using a wearable ECG device.\n\n\n\n\n\nMust be energy-efficient (battery-operated, low power consumption).\nNeeds real-time inference for immediate alerts.\nShould operate offline, but sync with mobile apps for periodic review.\n\n\n\n\n\nProcessing ECG data on a low-power Edge device.\nMinimizing false positives/negatives in arrhythmia detection.\nEnsuring high reliability and accuracy.\n\n\n\n\n\n\n\n\nECG sensor (e.g., AD8232) captures raw heart signals.\nAccelerometer (optional) for motion artifacts reduction.\n\n\n\n\n\nSample rate: 250 Hz (sufficient for arrhythmia detection).\nUse on-device filtering (low-pass filters) to remove noise.\n\n\n\n\n\nApply Butterworth filters for noise reduction.\nR-peak detection using Pan-Tompkins algorithm for heart rate calculation.\nExtract features like RR intervals, QRS width, and HR variability.\n\n\n\n\n\n\n\n\nUse 1D CNN + LSTM hybrid model (efficient for ECG signal processing).\nTrain the model using MIT-BIH Arrhythmia Database.\n\n\n\n\n\nQuantization: Convert model to int8 precision using TensorFlow Lite.\nPruning: Remove redundant neurons to reduce computation load.\nKnowledge Distillation: Train a smaller model from a high-performing one.\n\n\n\n\n\n\n\n\nNordic nRF52840 (low-power ARM Cortex-M4 + BLE connectivity).\nAlternative: ESP32 (for low-cost AI inference).\n\n\n\n\n\nRAM: 512KB (optimized for Edge AI processing).\nFlash storage: 4MB (stores ECG data logs for later analysis).\n\n\n\n\n\nBluetooth Low Energy (BLE) for periodic sync with mobile apps.\nCan function offline with real-time alerts.\n\n\n\n\n\n\nConvert trained TensorFlow model → TensorFlow Lite for Edge AI inference.\nDeploy on the Nordic nRF52840 MCU using TensorFlow Lite for Microcontrollers.\nUse hardware-accelerated inference for efficient processing.\nImplement event-driven processing (AI runs only on abnormal detections to save power).\n\n\n\n\n\n\n\nReal-time inference latency: &lt;10 ms per ECG segment.\nPower consumption: 5mW (optimized for long battery life).\n\n\n\n\n\nSecure Boot & Firmware Updates to prevent hacking.\nAdaptive AI Models: Learns individual patient heart patterns to reduce false alarms.\n\n\n\n\n\nSync detected arrhythmia events with a cloud server for validation.\nUse federated learning to improve AI models without sharing raw patient data.\n\n\n\n\n\n\nMass production of the device for hospitals, clinics, and home use.\nIntegration with mobile apps for patient-doctor communication.\nRegulatory Approval: Submit for FDA/CE certification for medical device compliance.\nOver-the-Air (OTA) Updates: Allow model updates based on new ECG patterns."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "href": "presentaciones/APSB/Lect005_Methods.html#methodology-for-designing-an-edge-ai-device",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Problem Definition & Use Case Analysis\nData Collection & Preprocessing\nModel Selection & Optimization\nHardware Selection\nDeployment & Model Inference\nTesting, Validation, and Continuous Improvement\nFinal Deployment & Scaling"
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#problem-definition-use-case-analysis",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Identify the specific AI task (e.g., real-time ECG analysis, fall detection, predictive maintenance in IoT).\nDetermine operational constraints, including:\n\nPower consumption (battery-operated vs. wired).\nLatency requirements (real-time processing vs. periodic updates).\nCommunication needs (Wi-Fi, Bluetooth, LoRa, standalone processing)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#data-collection-preprocessing",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Sensor Selection: Choose sensors relevant to the application (e.g., accelerometers for motion tracking, biosensors for health monitoring).\nEdge-Compatible Data Acquisition: Optimize data formats to reduce memory and computational load.\nPreprocessing on Edge:\n\nSignal filtering (e.g., noise reduction in biomedical signals).\nFeature extraction (e.g., time-series features for motion classification)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#model-selection-optimization",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Model Selection:\n\nLightweight CNNs (for image processing).\nRecurrent Neural Networks (RNNs) / LSTMs (for time-series data like ECG).\nTinyML models optimized for microcontrollers (e.g., TensorFlow Lite, PyTorch Mobile).\n\nModel Optimization for Edge Deployment:\n\nQuantization: Convert floating-point models to int8 or int16 to reduce size and computation load.\nPruning: Remove unnecessary neurons or layers while preserving accuracy.\nDistillation: Train a smaller model using knowledge from a larger one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#hardware-selection",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Processing Unit:\n\nMicrocontrollers (MCUs) (e.g., ARM Cortex-M, ESP32) → Low-power, simple AI tasks.\nEdge AI Accelerators (e.g., Google Edge TPU, NVIDIA Jetson Nano) → More complex AI processing.\nFPGAs (Field-Programmable Gate Arrays) → Custom AI workloads for high-speed processing.\n\nMemory & Storage:\n\nRAM Optimization: Choose embedded SRAM or external DRAM depending on model size.\nFlash Storage: Store inference models efficiently.\n\nConnectivity:\n\nOffline processing for low-latency applications.\nEdge-to-cloud integration for periodic updates."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#deployment-model-inference",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Convert trained AI models into optimized edge-compatible formats (e.g., TensorFlow Lite, ONNX).\nImplement real-time inference using hardware-accelerated libraries (e.g., TensorRT, OpenVINO).\nOptimize firmware for energy efficiency using duty-cycling techniques (process only when necessary)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#testing-validation-and-continuous-improvement",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Edge Benchmarking:\n\nMeasure inference speed and power consumption.\nValidate model accuracy on real-world edge-generated data.\n\nSecurity & Reliability:\n\nImplement secure boot & firmware updates to prevent cyber threats.\nEnsure robust error handling for sensor malfunctions.\n\nFeedback & Model Updating:\n\nIf connected to a cloud system, update models periodically using federated learning.\nOptimize AI pipelines with incremental learning on-device where feasible."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#final-deployment-scaling",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Deploy at scale, ensuring the Edge AI model adapts to different environments.\nImplement remote monitoring & diagnostics for predictive maintenance.\nEnable over-the-air (OTA) updates to improve AI models post-deployment."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "href": "presentaciones/APSB/Lect005_Methods.html#abstract",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "The hardware-software co-design approach is the most widely used methodology for Edge AI device development. It ensures:\n\nReal-time performance with optimized AI models.\nEnergy-efficient processing for battery-operated or low-power devices.\nScalability and security in edge environments.\n\nThis methodology is industry-standard and used by leading companies in healthcare, automotive, and industrial IoT, ensuring robust and reliable Edge AI solutions."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "href": "presentaciones/APSB/Lect005_Methods.html#example-of-application",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Use case\n\n\n\nA wearable ECG monitoring device designed for continuous heart health tracking and arrhythmia detection. This Edge AI-based solution analyzes ECG signals in real-time on a low-power microcontroller, providing instant alerts for cardiac irregularities without relying on cloud computing."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-1-problem-definition-use-case-analysis",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Objective\n\n\n\nDetect abnormal heart rhythms (arrhythmias) in real-time using a wearable ECG device.\n\n\n\n\n\nMust be energy-efficient (battery-operated, low power consumption).\nNeeds real-time inference for immediate alerts.\nShould operate offline, but sync with mobile apps for periodic review.\n\n\n\n\n\nProcessing ECG data on a low-power Edge device.\nMinimizing false positives/negatives in arrhythmia detection.\nEnsuring high reliability and accuracy."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-2-data-collection-preprocessing",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "ECG sensor (e.g., AD8232) captures raw heart signals.\nAccelerometer (optional) for motion artifacts reduction.\n\n\n\n\n\nSample rate: 250 Hz (sufficient for arrhythmia detection).\nUse on-device filtering (low-pass filters) to remove noise.\n\n\n\n\n\nApply Butterworth filters for noise reduction.\nR-peak detection using Pan-Tompkins algorithm for heart rate calculation.\nExtract features like RR intervals, QRS width, and HR variability."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-3-model-selection-optimization",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Use 1D CNN + LSTM hybrid model (efficient for ECG signal processing).\nTrain the model using MIT-BIH Arrhythmia Database.\n\n\n\n\n\nQuantization: Convert model to int8 precision using TensorFlow Lite.\nPruning: Remove redundant neurons to reduce computation load.\nKnowledge Distillation: Train a smaller model from a high-performing one."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-4-hardware-selection",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Nordic nRF52840 (low-power ARM Cortex-M4 + BLE connectivity).\nAlternative: ESP32 (for low-cost AI inference).\n\n\n\n\n\nRAM: 512KB (optimized for Edge AI processing).\nFlash storage: 4MB (stores ECG data logs for later analysis).\n\n\n\n\n\nBluetooth Low Energy (BLE) for periodic sync with mobile apps.\nCan function offline with real-time alerts."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-5-deployment-model-inference",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Convert trained TensorFlow model → TensorFlow Lite for Edge AI inference.\nDeploy on the Nordic nRF52840 MCU using TensorFlow Lite for Microcontrollers.\nUse hardware-accelerated inference for efficient processing.\nImplement event-driven processing (AI runs only on abnormal detections to save power)."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-6-testing-validation-and-continuous-improvement",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Real-time inference latency: &lt;10 ms per ECG segment.\nPower consumption: 5mW (optimized for long battery life).\n\n\n\n\n\nSecure Boot & Firmware Updates to prevent hacking.\nAdaptive AI Models: Learns individual patient heart patterns to reduce false alarms.\n\n\n\n\n\nSync detected arrhythmia events with a cloud server for validation.\nUse federated learning to improve AI models without sharing raw patient data."
  },
  {
    "objectID": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "href": "presentaciones/APSB/Lect005_Methods.html#step-7-final-deployment-scaling",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Mass production of the device for hospitals, clinics, and home use.\nIntegration with mobile apps for patient-doctor communication.\nRegulatory Approval: Submit for FDA/CE certification for medical device compliance.\nOver-the-Air (OTA) Updates: Allow model updates based on new ECG patterns."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Key Term\n\n\n\nThe term edge AI is a union of two buzzwords, fused together into one mighty term. It’s often heard alongside its siblings, embedded machine learning and TinyML.\n\n\n\n\n\n\n\n\nEmbedded\n\n\n\n\nEmbedded systems are the computers that control the electronics of all sorts of physical devices.\nIn contrast to general-purpose computers, embedded systems are usually meant to perform one specific, dedicated task.\nIt’s common for embedded systems to reflect the constraints of the environments into which they are deployed. For example, many embedded systems are required to run on battery power, so they’re designed with energy efficiency in mind—perhaps with limited memory or an extremely slow clock rate.\nProgramming embedded systems is the art of navigating these constraints, writing software that performs the task required while making the most out of limited resources.\n\n\n\n\n\n\n\n\n\n\n\n\nThe Edge\n\n\n\n\nThe history of computer networks has been a gigantic tug of war.\nIn the first systems—individual computers the size of a room—computation was inherently centralized.\nComputers were connected to terminals that took over some of their responsibilities. Example the terminal renders the letters in an monitor.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Edge\n\n\n\n\nOver time, terminals became more and more sophisticated, taking over more and more functions that were previously the job of the central computer. The personal computer was invented.\nSmall computers could do useful work without even being connected to another machine.\nThe growth of the internet, along with web applications and services, made it possible to do some really cool stuff\nOver the past decade, most of our computing has become centralized again—this time in the “cloud.”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Edge\n\n\n\n\nThe Internet of Things (IoT) includes everything you can think of: industrial sensors, smart refrigerators, internet-connected security cameras, personal automobiles, shipping containers, fitness trackers, and coffee machines.\nAll of these devices are embedded systems.\nSince they’re at the edge of the network, we can also call them edge devices.\nThe edge isn’t a single place; it’s more like a broad region.\nThe edge is where all the data comes from!\nEdge devices are our link between the internet and the physical world\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI\n\n\n\n\nSince the dawn of time, humans have dreamed of creating intelligent entities that can help us in our struggle to survive.\nIn the modern world we dream of robot sidekicks who assist us.\nTo define AI, we have to define intelligence\n\n\n\n\n\n\n\n“Slime Mould Solves Maze in One Pass Assisted by Gradient of Chemo-Attractants” (Andrew Adamatzky, arXiv, 2011)"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Key Term\n\n\n\nThe term edge AI is a union of two buzzwords, fused together into one mighty term. It’s often heard alongside its siblings, embedded machine learning and TinyML.\n\n\n\n\n\n\n\n\nEmbedded\n\n\n\n\nEmbedded systems are the computers that control the electronics of all sorts of physical devices.\nIn contrast to general-purpose computers, embedded systems are usually meant to perform one specific, dedicated task.\nIt’s common for embedded systems to reflect the constraints of the environments into which they are deployed. For example, many embedded systems are required to run on battery power, so they’re designed with energy efficiency in mind—perhaps with limited memory or an extremely slow clock rate.\nProgramming embedded systems is the art of navigating these constraints, writing software that performs the task required while making the most out of limited resources."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "The Edge\n\n\n\n\nThe history of computer networks has been a gigantic tug of war.\nIn the first systems—individual computers the size of a room—computation was inherently centralized.\nComputers were connected to terminals that took over some of their responsibilities. Example the terminal renders the letters in an monitor."
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "The Edge\n\n\n\n\nOver time, terminals became more and more sophisticated, taking over more and more functions that were previously the job of the central computer. The personal computer was invented.\nSmall computers could do useful work without even being connected to another machine.\nThe growth of the internet, along with web applications and services, made it possible to do some really cool stuff\nOver the past decade, most of our computing has become centralized again—this time in the “cloud.”"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-4",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "The Edge\n\n\n\n\nThe Internet of Things (IoT) includes everything you can think of: industrial sensors, smart refrigerators, internet-connected security cameras, personal automobiles, shipping containers, fitness trackers, and coffee machines.\nAll of these devices are embedded systems.\nSince they’re at the edge of the network, we can also call them edge devices.\nThe edge isn’t a single place; it’s more like a broad region.\nThe edge is where all the data comes from!\nEdge devices are our link between the internet and the physical world"
  },
  {
    "objectID": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "href": "presentaciones/APSB/Lect002_PresentacionIntroduccion.html#a-brief-introduction-to-edge-ai-5",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "AI\n\n\n\n\nSince the dawn of time, humans have dreamed of creating intelligent entities that can help us in our struggle to survive.\nIn the modern world we dream of robot sidekicks who assist us.\nTo define AI, we have to define intelligence\n\n\n\n\n\n\n\n“Slime Mould Solves Maze in One Pass Assisted by Gradient of Chemo-Attractants” (Andrew Adamatzky, arXiv, 2011)"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\nDefinitions\n\n\n\nMachine Learning: is defined as an automated process that extracts patterns from data."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-1",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\n\nHow machine learning works?\nMachine learning algorithms work by searching through a set of possible prediction models for the model that best captures the relationship between the descriptive features and target feature in a dataset.\n\n\n   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n0            6      148             72  ...                     0.627   50        1\n1            1       85             66  ...                     0.351   31        0\n2            8      183             64  ...                     0.672   32        1\n3            1       89             66  ...                     0.167   21        0\n4            0      137             40  ...                     2.288   33        1\n\n[5 rows x 9 columns]"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-2",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\nWhat can be wrong???\n\n\n\n\nWhen we are dealing with large datasets, it is likely that there is noise.\nWhen we are dealing with large datasets, it is likely that there is missing data.\nWhen we are dealing with large datasets, it is likely that there is data leakage.\n\n\n\n\n\n\n\n\n\nIll-posed problem\n\n\n\nIll-posed problem, that is, a problem for which a unique solution cannot be determined using only the information that is available"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#introduction-3",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Introduction",
    "text": "Introduction"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow.",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Understanding Workflow.",
    "text": "Data Understanding Workflow.\n\n\n\n\n\n\nExploratory data analysis\n\n\n\n\nData Loading.\nBasic Statistics: Displays summary statistics.\nMissing Values Check: Identifies missing values.\nFeature Distributions: Visualizes distributions using histograms or countplots.\nRelationship between variables."
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#data-understanding-workflow",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Data Understanding Workflow",
    "text": "Data Understanding Workflow\n\n# Identify variable types\ndiscrete_vars = [\"Pregnancies\"]  # Discrete numerical variable\ncategorical_vars = [\"Outcome\"]  # Class label\ncontinuous_vars = [\n    col\n    for col in data.select_dtypes(include=[np.number]).columns\n    if col not in discrete_vars + [\"Outcome\"]\n]\n\n# Basic dataset information\nprint(\"Dataset Information:\\n\", data.info())\nprint(\"\\nSummary Statistics:\\n\", data.describe())\nprint(\"\\nMissing Values:\\n\", data.isnull().sum())\n\n# Ensure numeric data and handle NaN or infinite values\nnumeric_data = data.select_dtypes(include=[np.number]).dropna()\nnumeric_data = numeric_data.replace([np.inf, -np.inf], np.nan).dropna()\n\n# Dynamically determine the number of rows for subplots\nnum_cont_vars = len(continuous_vars)\nrows = (num_cont_vars // 3) + (num_cont_vars % 3 &gt; 0)  # Ensures proper grid layout\n\n# Plot distributions for continuous variables\nplt.figure(figsize=(12, 4 * rows))\nfor i, column in enumerate(continuous_vars, 1):\n    plt.subplot(rows, 3, i)\n    sns.histplot(numeric_data[column], kde=True, bins=20, color=\"skyblue\")\n    plt.title(f\"Distribution of {column}\")\nplt.tight_layout()\nplt.show()\n\n# Plot distribution for discrete variable (Pregnancies) using a countplot\nplt.figure(figsize=(8, 4))\nsns.countplot(x=\"Pregnancies\", data=numeric_data, palette=\"viridis\")\nplt.title(\"Count of Pregnancies\")\nplt.show()\n\n# Plot class distribution for Outcome\nplt.figure(figsize=(6, 4))\nsns.countplot(x=\"Outcome\", data=data, palette=\"coolwarm\")\nplt.title(\"Class Distribution of Outcome\")\nplt.xlabel(\"Diabetes Diagnosis (0: No, 1: Yes)\")\nplt.ylabel(\"Count\")\nplt.show()\n\n# Correlation heatmap to check relationships\nplt.figure(figsize=(10, 6))\nsns.heatmap(numeric_data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()"
  },
  {
    "objectID": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#footnotes",
    "href": "presentaciones/APSB/Lect007_MachineLearningWorkflow.html#footnotes",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Notas",
    "text": "Notas\n\n\nDiapositivas basadas en el texto: J. D. Kelleher, B. Mac Namee, y A. D’Arcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed. Cambridge: The MIT press, 2020.↩︎"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html",
    "href": "tutoriales/tutInstallPythonR.html",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "",
    "text": "Antes de compilar Python, es necesario disponer de Ubuntu corriendo bajo WSL2 en Windows 11. Sigue estos pasos:\n\nVerificar requisitos:\n\nWindows 11 (build 22000 o superior).\nVirtualización habilitada en BIOS/UEFI (Intel VT-x o AMD SVM).\nPermisos de administrador en Windows.\n\nHabilitar WSL y plataforma de máquina virtual:\nAbre PowerShell como administrador y ejecuta:\npowershell  wsl --install\n\nEsto activa las características “Virtual Machine Platform” y “Windows Subsystem for Linux”.\nDescarga e instala Ubuntu por defecto (puedes ignorar o desinstalar luego).\nReinicia el equipo si se solicita.\n\nInstalar Ubuntu:\n\nVía PowerShell:\nwsl --install -d Ubuntu\nO desde Microsoft Store:\n\nAbre Microsoft Store.\nBusca “Ubuntu” y pulsa Instalar.\n\n\nPrimer arranque de Ubuntu:\n\nAbre Ubuntu desde el menú Inicio o Windows Terminal.\npowershell      wsl -d Ubuntu\nCrea tu usuario y contraseña de Linux.\n\nActualizar paquetes del sistema:\nsudo apt update && sudo apt upgrade -y"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-repositorios-e-instalar-dependencias-de-compilación",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-repositorios-e-instalar-dependencias-de-compilación",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "1. Actualizar repositorios e instalar dependencias de compilación",
    "text": "1. Actualizar repositorios e instalar dependencias de compilación\nEjecuta los siguientes comandos para actualizar el sistema e instalar las bibliotecas necesarias para compilar Python desde el código fuente:\nsudo apt update\nsudo apt install -y \\\n  build-essential \\\n  checkinstall \\\n  libncurses-dev \\\n  libssl-dev \\\n  zlib1g \\\n  zlib1g-dev \\\n  libreadline-dev \\\n  libsqlite3-dev \\\n  libgdbm-dev libdb5.3-dev \\\n  libbz2-dev \\\n  libexpat1-dev \\\n  libc6-dev \\\n  libffi-dev \\\n  liblzma-dev \\\n  tk-dev \\\n  dirmngr \\\n  gnupg \\\n  apt-transport-https \\\n  ca-certificates \\\n  software-properties-common wget \\\n  libxml2-dev \\\n  libharfbuzz-dev \\\n  libfribidi-dev \\\n  libcurl4-openssl-dev \\\n  libmagick++-dev \\\n  libnsl-dev \\\n  cmake\\\n  wget"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#obtener-el-kit-de-repositorio-cuda-de-nvidia",
    "href": "tutoriales/tutInstallPythonR.html#obtener-el-kit-de-repositorio-cuda-de-nvidia",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "2. Obtener el kit de repositorio CUDA de NVIDIA:",
    "text": "2. Obtener el kit de repositorio CUDA de NVIDIA:\ncd ~\nmkdir instaladores\ncd instaladores\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/12.9.1/local_installers/cuda-repo-wsl-ubuntu-12-9-local_12.9.1-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-12-9-local_12.9.1-1_amd64.deb\nsudo apt update\nsudo apt -y install cuda-toolkit-12-9"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-instalación",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-instalación",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "3. Verificar la instalación:",
    "text": "3. Verificar la instalación:\n# Verifica la versión de nvcc\nnvcc --version\n# Verifica que la GPU sea detectada\nnvidia-smi"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#instalación-de-la-versión-más-reciente-de-r",
    "href": "tutoriales/tutInstallPythonR.html#instalación-de-la-versión-más-reciente-de-r",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "4. Instalación de la versión más reciente de R",
    "text": "4. Instalación de la versión más reciente de R\nPara instalar la versión más reciente de R en Ubuntu bajo WSL2, sigue estos pasos:\n\n1. Agregar la clave y el repositorio oficial de CRAN:\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\nsudo add-apt-repository \"deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/\"\n\n\n2. Instalar R:\nsudo apt update\nsudo apt install -y r-base r-base-dev r-recommended\n\n\n3. Verificar la instalación:\nR --version    # Debe mostrar la versión de R recién instalada\nsudo R\ninstall.packages(c(\"DiagrammeR\", \"reticulate\", \"kableExtra\", \"tidyverse\", \"knitr\", \"cowplot\", \"ggfx\", \"rstatix\", \"languageserver\", \"bibliometrix\"))"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#descargar-y-extraer-python-3.12",
    "href": "tutoriales/tutInstallPythonR.html#descargar-y-extraer-python-3.12",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "5. Descargar y extraer Python 3.12",
    "text": "5. Descargar y extraer Python 3.12\n\n1. Descarga el código fuente de Python 3.12 y descomprímelo en /usr/src:\ncd /usr/src\nsudo wget https://www.python.org/ftp/python/3.12.11/Python-3.12.11.tgz\nsudo tar -xzf Python-3.12.11.tgz\ncd Python-3.12.11\n\n\n2. Configura la compilación con optimizaciones y el instalador de pip integrado:\n```bash\nsudo ./configure --enable-optimizations --with-ensurepip=install --enable-shared\n```\n\n\n3. Compila utilizando todos los núcleos disponibles:\n```bash\nsudo make -j $(nproc)\n```\n\n\n4. Instala Python 3.12 sin sobrescribir la versión del sistema por defecto:\n```bash\nsudo make altinstall\n```\nLos ejecutables quedarán en /usr/local/bin/python3.12 y /usr/local/bin/pip3.12.\n\n\n5. Verificación de la instalación\nComprueba las versiones instaladas:\n/usr/local/bin/python3.12 --version   # Debe mostrar Python 3.12.0\n/usr/local/bin/pip3.12 --version      # Debe mostrar la versión de pip correspondiente\necho 'export PATH=\"$PATH:/home/sylph/.local/bin\"' &gt;&gt; ~/.bashrc\nsource\n\n\n6. Crear y activar un entorno virtual\n\n1. Crea un directorio de trabajo\n```bash\nmkdir -p ~/proyectos\ncd ~/proyectos\n```\n\n\n2. Crea un entorno virtual (mienv) con Python 3.12:\n```bash\n/usr/local/bin/python3.12 -m venv mienv\n```\n\n\n3. Activa el entorno:\n```bash\nsource mienv/bin/activate\n```\n\n\n4. Verifica que python y pip apunten a la versión 3.12:\n```bash\npython --version   # Python 3.12.X\npip --version      # pip x.y.z\n```\n\n\n5. Instala las bibliotecas necesarias:\n```bash\npython -m pip cache purge\npython -m pip install -U --upgrade-strategy eager pip setuptools wheel packaging build\npython -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu129\npython -m pip install pandas matplotlib scikit-learn opencv-contrib-python opencv-python pywavelets statsmodels scipy seaborn plotly scikit-image scikit-image[data] scikit-image[optional] jupyter scikit-image\n```\n\n\n5. desactivar el entorno, ejecuta:\ndeactivate"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-índices-de-paquetes",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-índices-de-paquetes",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "1. Actualizar índices de paquetes",
    "text": "1. Actualizar índices de paquetes\nsudo apt update"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#descargar-el-instalador-oficial",
    "href": "tutoriales/tutInstallPythonR.html#descargar-el-instalador-oficial",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "2. Descargar el instalador oficial",
    "text": "2. Descargar el instalador oficial\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-integridad-opcional",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-integridad-opcional",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "3. Verificar la integridad (opcional)",
    "text": "3. Verificar la integridad (opcional)\nCompara el hash SHA‑256 generado con el publicado en el sitio oficial:\nsha256sum ~/miniconda.sh\n# Comprueba que el resultado coincida con el valor en https://repo.anaconda.com/miniconda/"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#ejecutar-el-instalador-en-modo-silencioso",
    "href": "tutoriales/tutInstallPythonR.html#ejecutar-el-instalador-en-modo-silencioso",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "4. Ejecutar el instalador en modo silencioso",
    "text": "4. Ejecutar el instalador en modo silencioso\nEsto instalará Miniconda en ~/miniconda sin interacción:\nbash ~/miniconda.sh -b -p $HOME/miniconda"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#inicializar-conda-en-tu-shell",
    "href": "tutoriales/tutInstallPythonR.html#inicializar-conda-en-tu-shell",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "5. Inicializar Conda en tu shell",
    "text": "5. Inicializar Conda en tu shell\nPara que conda esté disponible cada vez que abras la terminal:\neval \"$(~/miniconda/bin/conda shell.bash hook)\"\nconda init"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#recargar-la-configuración-de-shell",
    "href": "tutoriales/tutInstallPythonR.html#recargar-la-configuración-de-shell",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "6. Recargar la configuración de shell",
    "text": "6. Recargar la configuración de shell\nsource ~/.bashrc"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#actualizar-conda-a-la-última-versión",
    "href": "tutoriales/tutInstallPythonR.html#actualizar-conda-a-la-última-versión",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "7. Actualizar Conda a la última versión",
    "text": "7. Actualizar Conda a la última versión\nconda tos interactive\nconda update -n base -c defaults conda -y"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#verificar-la-instalación-2",
    "href": "tutoriales/tutInstallPythonR.html#verificar-la-instalación-2",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "8. Verificar la instalación",
    "text": "8. Verificar la instalación\nconda --version\n# Deberías ver algo como: conda 23.x.x"
  },
  {
    "objectID": "tutoriales/tutInstallPythonR.html#crear-un-entorno-virtual",
    "href": "tutoriales/tutInstallPythonR.html#crear-un-entorno-virtual",
    "title": "Instalación de Entorno de trabajo. Ubuntu WSL2",
    "section": "9. Crear un entorno virtual",
    "text": "9. Crear un entorno virtual\nconda create -n ai-env python=3.12"
  },
  {
    "objectID": "tutoriales/ExpansionTaylor.html",
    "href": "tutoriales/ExpansionTaylor.html",
    "title": "Computación de seno y coseno usando expansión de Taylor",
    "section": "",
    "text": "Las ecuaciones de las expansiones de Taylor (centradas en cero) fueron extraídas de la recopilación que hizo Wikipedia\n\\[cos\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{x^{2n}}{2n!}\\left(-1\\right)^{n}}\\]\n\\[sin\\left(x\\right) = \\sum_{n=0}^{\\infty}{\\frac{\\left(-1\\right)^{n}}{\\left(2n+1\\right)!}x^{2n+1}}\\]\n\ndef factorial(x):\n    output = 1\n    for k in range(1,x+1):\n        output = output*k\n    return output\n\n\ndef sin_taylor_expansion(x,n):\n    pi = 3.141592653589793238462643383279502884197169399375105820974944\n    x = pi*x/180\n    output = 0\n    for k in range(0, n):\n        term = (((-1)**k)/factorial(2*k + 1))*(x**(2*k+1))\n        output = output+term\n    return output\n\n\nv_est = sin_taylor_expansion(30,5)\n\nprint(v_est)\n\nprint(\"Error Relativo:\", abs(0.5-v_est)/0.5)\n\n0.5000000000202799\nError Relativo: 4.0559777758630844e-11"
  },
  {
    "objectID": "tutoriales/tut002_IA.html",
    "href": "tutoriales/tut002_IA.html",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM\n\n\n\n\n\n\n\n\n\n\n\n\nMicrobit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope.\n\n\n\n\n\n\n\n\n\n\n\nMicrobit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMicrobit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C\n\n\n\n\n\n\n\nDistribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit",
    "href": "tutoriales/tut002_IA.html#que-es-microbit",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nEs una computadora portátil y programable\nEnfocada en inspirar y desarrollar habilidades técnicas básicas en el campo STEM"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-1",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nCreada en el 2012 con el objetivo de democratizar la educación en computación.\nEntre 2012 y 2015, se unieron 29 socios clave entre los cuales están a ARM, Barclays, element14, Freescale, Universidad de Lancaster, Microsoft, Nordic Semiconductor, Samsung y ScienceScope."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-2",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nLanzamiento (2015): La Microbit se lanzó como parte de la iniciativa “Make it Digital” de la BBC, con el objetivo de introducir la codificación y la ciencia computacional en colegios del Reino Unido."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "href": "tutoriales/tut002_IA.html#que-es-microbit-3",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Microbit\n\n\n\n\nMicroPython\nJavaScript\nEditor de bloques visuales\nLenguaje de programación C"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#distribución-e-impacto",
    "href": "tutoriales/tut002_IA.html#distribución-e-impacto",
    "title": "Microbit – El minicomputador",
    "section": "",
    "text": "Distribución: La Microbit se distribuyó de forma gratuita a todos los niños de 12-13 años (Year 7) en todo el Reino Unido, con el objetivo de llegar a más de 1 millón de niños.\nImpacto: En su primer año, la Microbit mostró un impacto positivo significativo en los estudiantes y docentes del Reino Unido, con el 90% de los estudiantes informando que les ayudó a entender que cualquiera puede programar."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#problema",
    "href": "tutoriales/tut002_IA.html#problema",
    "title": "Microbit – El minicomputador",
    "section": "Problema",
    "text": "Problema\n\n\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\n\nInicializar una variable en 0.\nMostrar el número en la pantalla de leds.\nContar hasta 9 y repetir indefinidamente.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz."
  },
  {
    "objectID": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "href": "tutoriales/tut002_IA.html#httpsmicrobit.org",
    "title": "Microbit – El minicomputador",
    "section": "https://microbit.org/",
    "text": "https://microbit.org/\n\n\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#lets-code",
    "href": "tutoriales/tut002_IA.html#lets-code",
    "title": "Microbit – El minicomputador",
    "section": "Let’s Code",
    "text": "Let’s Code\n\n\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#editor",
    "href": "tutoriales/tut002_IA.html#editor",
    "title": "Microbit – El minicomputador",
    "section": "Editor",
    "text": "Editor\n\n\n\nMicrobit"
  },
  {
    "objectID": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "href": "tutoriales/tut002_IA.html#un-problema-de-ia",
    "title": "Microbit – El minicomputador",
    "section": "Un problema de IA",
    "text": "Un problema de IA\n\n\n\n\n\n\nAlgoritmo basico\n\n\n\n\nInicializar una variable con el número a adivinar de forma aleatoria entre 0-100.\nInicializar el acumulador en 0\nSi acumulador es mayor que adivinar entonces disminuir acumulador en uno.\nSi acumulador es mucho mayor que adivinar entonces disminuir acumulador en 10.\nSi en la variable, el número es igual a 7, entonces mostrar un emoji de cara feliz.\nSi acumulador es menor que adivinar entonces aumentar acumulador en uno.\nSi acumulador es mucho menor que adivinar entonces aumentar acumulador en 10."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "",
    "text": "Este documento resuelve el examen adjunto. Cada pregunta incluye: enunciado resumido, respuesta(s) correctas, justificación matemática y un ejemplo en Python que ilustra visualmente los conceptos. Las gráficas se generan con matplotlib (sin estilos ni colores específicos)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "2.1 Justificación matemática",
    "text": "2.1 Justificación matemática\n\nForma general: \\(y(t) = x\\big(a\\,(t-t_0)\\big)\\).\n\nSi \\(0 &lt; a &lt; 1\\), hay expansión temporal por factor \\(1/a\\). Aquí \\(a=0.5\\Rightarrow\\) expansión por 2.\nEl término \\(t-t_0\\) implica desplazamiento hacia la derecha en \\(t_0\\) (aparece más tarde). Aquí \\(t_0 = 0.2\\ \\text{s}\\).\n\nNo hay reflexión temporal porque no aparece \\(-t\\)."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "2.2 Ejemplo en Python",
    "text": "2.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(-1, 3, 4000)\nx = np.cos(2*np.pi*t) + 0.5*np.cos(4*np.pi*t)\ny = np.cos(2*np.pi*(0.5*(t-0.2))) + 0.5*np.cos(4*np.pi*(0.5*(t-0.2)))\n\nplt.figure()\nplt.plot(t, x, label=\"x(t)\")\nplt.plot(t, y, label=\"y(t)=x(0.5*(t-0.2))\", linestyle=\"--\")\nplt.title(\"P1: Escala temporal (expansión ×2) y desplazamiento +0.2 s\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-1",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "3.1 Justificación matemática",
    "text": "3.1 Justificación matemática\n\nFrecuencias: \\(f_1=0.25\\ \\text{Hz}\\Rightarrow T_1=4\\ \\text{s}\\);\\(f_2=0.5\\ \\text{Hz}\\Rightarrow T_2=2\\ \\text{s}\\).\nLa suma de cosenos es periódica si la razón \\(f_2/f_1\\) es racional; aquí \\(0.5/0.25=2\\).\nEl periodo fundamental es \\(T_0=\\mathrm{mcm}(T_1,T_2)=\\mathrm{mcm}(4,2)=4\\ \\text{s}\\).\nCualquier múltiplo entero de \\(T_0\\) (p. ej., \\(8\\ \\text{s}\\)) también es periodo."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-1",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-1",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "3.2 Ejemplo en Python",
    "text": "3.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(0, 12, 6000)\nx = np.cos(2*np.pi*0.25*t) + np.cos(2*np.pi*0.5*t)\n\nplt.figure()\nplt.plot(t, x, label=\"x(t)\")\nfor Tmark in [4, 8, 12]:\n    plt.axvline(Tmark, linestyle=\":\", alpha=0.7)\nplt.title(\"P2: Periodicidad con T0 = 4 s (líneas punteadas en múltiplos)\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.grid(True)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-2",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "4.1 Justificación matemática",
    "text": "4.1 Justificación matemática\nUna señal \\(x[n]=\\cos(\\omega_0 n)\\) es periódica si existe \\(N\\in\\mathbb{Z}^+\\) tal que \\(\\omega_0 N=2\\pi k\\), \\(k\\in\\mathbb{Z}\\).\n\\[\\frac{5\\pi}{6}N=2\\pi k \\;\\Longrightarrow\\; \\frac{5N}{6}=2k \\;\\Longrightarrow\\; 5N=12k.\\]\nEl menor \\(N\\) que satisface esto es \\(N_0=12\\) (con \\(k=5\\))."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-2",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-2",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "4.2 Ejemplo en Python",
    "text": "4.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nn = np.arange(0, 37)\nx = np.cos((5 * np.pi / 6) * n)\n\nplt.figure()\nmarkerline, stemlines, baseline = plt.stem(n, x)\nplt.title(\"P3: x[n]=cos((5π/6)n) con periodo N0 = 12 (marcas en 12, 24, 36)\")\nplt.xlabel(\"n\")\nplt.ylabel(\"Amplitud\")\nfor Nmark in [12, 24, 36]:\n    plt.axvline(Nmark, linestyle=\":\", alpha=0.7)\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-3",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "5.1 Justificación matemática",
    "text": "5.1 Justificación matemática\n\nProducto par·impar → impar. Producto par·par → par.\nPor tanto \\(y(t)=\\underbrace{\\text{impar}}_{x_p x_i}+\\underbrace{\\text{par}}_{x_p^2}\\).\nLa suma de una función par y una impar es ni par ni impar en general.\nCaso particular: si \\(x_i(t)=0\\Rightarrow y(t)=x_p^2(t)\\), que es par."
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-3",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-3",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "5.2 Ejemplo en Python",
    "text": "5.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nt = np.linspace(-3*np.pi, 3*np.pi, 4000)\nxp = np.cos(t)        # par\nxi = np.sin(t)        # impar\ny = xp*xi + xp**2\ny_neg = np.cos(-t)*np.sin(-t) + np.cos(-t)**2  # y(-t)\n\nplt.figure()\nplt.plot(t, y, label=\"y(t)\")\nplt.plot(t, y_neg, linestyle=\"--\", label=\"y(-t)\")\nplt.title(\"P4: y(t)=cos(t)sin(t)+cos^2(t) → ni par ni impar (general)\")\nplt.xlabel(\"t\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Caso especial: xi(t)=0 ⇒ y(t)=xp^2(t) es par\nplt.figure()\nplt.plot(t, xp**2, label=\"y(t)=cos^2(t) (par)\")\nplt.title(\"P4 (caso especial): si xi(t)=0 ⇒ y(t)=cos^2(t) es par\")\nplt.xlabel(\"t\")\nplt.ylabel(\"Amplitud\")\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#justificación-matemática-4",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "6.1 Justificación matemática",
    "text": "6.1 Justificación matemática\n\nRepresentación estándar de un rectángulo activo en \\([t_1,t_2)\\) con amplitud \\(A\\):\n\\[A\\,[u(t-t_1)-u(t-t_2)].\\]\nCon \\(A=2\\), \\(t_1=1\\), \\(t_2=1.2\\):\n\\[2\\,[u(t-1)-u(t-1.2)].\\]"
  },
  {
    "objectID": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-4",
    "href": "recursos/documentos/examenesResueltos/SYSBP12025_2.html#ejemplo-en-python-4",
    "title": "Examen resuelto con justificación matemática y ejemplos en Python",
    "section": "6.2 Ejemplo en Python",
    "text": "6.2 Ejemplo en Python\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef u(t):\n    return (t &gt;= 0).astype(float)\n\nt = np.linspace(0, 2, 4000)\nrect = 2*(u(t-1) - u(t-1.2))\n\nplt.figure()\nplt.plot(t, rect)\nplt.title(\"P5: Pulso rectangular 2[u(t-1) - u(t-1.2)]\")\nplt.xlabel(\"t [s]\")\nplt.ylabel(\"Amplitud\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "El procesamiento digital de señales biomédicas (como ECG y EEG) emplea herramientas matemáticas para analizar y mejorar la calidad de estas señales, extrayendo información útil para diagnóstico y monitoreo clínico (Procesamiento de señales biomédicas: EEG & FPGA). En particular, la transformada Z y los filtros digitales (FIR e IIR) son fundamentales para modelar, analizar y modificar señales en tiempo discreto. Por ejemplo, es común eliminar interferencias de línea base o ruido de red eléctrica (50/60 Hz) mediante filtros pasoalto o de rechazo (notch) adecuados (). Este reporte teórico describe los conceptos clave para resolver un taller de análisis de señales biomédicas, cubriendo la transformada Z, la estabilidad y región de convergencia (ROC), la representación de sistemas LTI (Lineales e Invariantes en el Tiempo) mediante polos y ceros, la respuesta al impulso, los diagramas de bloques, y el diseño de filtros digitales FIR e IIR (incluyendo métodos de ventaneo y transformación bilineal). Se incluyen ejemplos prácticos en Python (usando numpy y scipy) para ilustrar implementaciones, con un claro enfoque en aplicaciones biomédicas como el filtrado de señales ECG/EEG. Las explicaciones se apoyan en referencias académicas para asegurar rigor teórico.\n\n\n\nLa transformada Z convierte una señal \\(x[n]\\) de tiempo discreto en una representación en el dominio complejo. En forma bilateral, se define como:\n\\[X(z) = \\mathcal{Z}\\{x[n]\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\,z^{-n},\\]\ndonde \\(z\\) es una variable compleja \\(z = A e^{j\\omega}\\) (con \\(A=|z|\\) y \\(\\omega = \\arg(z)\\)) (Transformada Z - Wikipedia, la enciclopedia libre) (Transformada Z - Wikipedia, la enciclopedia libre). En señales causales (\\(x[n]=0\\) para \\(n&lt;0\\)), suele usarse la transformada Z unilateral definida desde \\(n=0\\) hasta \\(\\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). La transformada Z es análoga a la transformada de Laplace en sistemas continuos, y de hecho puede verse como una serie de Laurent (suma infinita de potencias) (Transformada Z - Wikipedia, la enciclopedia libre).\nRegión de Convergencia (ROC): No toda señal tiene transformada Z en forma cerrada; la serie anterior converge únicamente en ciertas regiones del plano \\(z\\). La ROC se define como el conjunto de valores de \\(z\\) para los cuales la serie converge absolutamente (Transformada Z - Wikipedia, la enciclopedia libre). En términos prácticos, la ROC es el rango de \\(z\\) donde \\(\\sum_{n=-\\infty}^{\\infty}|x[n]z^{-n}| &lt; \\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). Por ejemplo, si \\(x[n] = a^n u[n]\\) (secuencia exponencial causal con \\(u[n]\\) la escalón unidad), su transformada Z es \\(X(z) = \\frac{1}{1 - a\\,z^{-1}}\\), pero esta expresión es válida solo si \\(|z| &gt; |a|\\) (ya que la serie geométrica converge cuando \\(|a/z|&lt;1\\)). Así, la ROC en este caso es \\(|z| &gt; |a|\\). Si la señal fuera anti-causal (\\(x[n]=0\\) para \\(n&gt;0\\)), la ROC sería \\(|z| &lt; |a|\\) (convergencia hacia adentro). Si \\(x[n]\\) tiene duración finita (FIR), su transformada Z existe para todo \\(z\\neq0\\) excepto quizá puntos donde la propia definición tenga singularidades (por lo general ROC = todo el plano \\(z\\), excepto tal vez \\(z=0\\) o \\(z=\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). La ROC nunca incluye polos (donde la función \\(X(z)\\) diverge) (Transformada Z - Wikipedia, la enciclopedia libre), es típicamente un anillo o media-plano en el plano \\(z\\), y su ubicación está ligada a propiedades de la señal como causalidad y estabilidad.\nPolos y ceros: Cualquier función de transferencia discreta o transformada Z de una señal racional puede expresarse en forma de polos y ceros. Los ceros son valores de \\(z\\) que anulan \\(X(z)\\) (raíces del numerador), y los polos donde \\(X(z)\\) diverge (raíces del denominador). Por ejemplo, en \\(X(z) = \\frac{1}{1 - a z^{-1}}\\), hay un polo en \\(z=a\\) y un cero en \\(z=\\infty\\) (o equivalente, un cero de orden 1 en el origen en la función \\(X(z)\\) multiplicada por \\(z^{-1}\\)). La representación gráfica de polos y ceros en el plano \\(z\\) proporciona intuición sobre el comportamiento frecuencial: los ceros en la circunferencia unitaria (\\(|z|=1\\)) cancelan ciertas frecuencias, mientras que los polos cercanos a la circunferencia unitaria amplifican componentes espectrales cercanas a su ángulo.\nCausalidad: Un sistema LTI discreto es causal si \\(h[n]=0\\) para \\(n&lt;0\\) (su respuesta impulso es nula en tiempos negativos). En la transformada Z, esto implica que la ROC es externa, es decir, de la forma \\(|z|&gt;R\\) (convergencia hacia \\(\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). Todos los polos de un sistema causal deben estar dentro de la ROC (que para causal es exterior al polo de mayor radio) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Un detalle importante es que la ubicación de polos por sí sola no determina completamente la causalidad o estabilidad; la ROC es la que define cuál de las posibles señales con esos polos es la realizada (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por ejemplo, una misma función racional puede corresponder a un sistema causal inestable o a un sistema no causal estable, dependiendo de si la ROC se toma fuera o entre polos (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange).\nEstabilidad BIBO: Un sistema es estable (en sentido BIBO: Bounded-Input Bounded-Output) si su respuesta al impulso \\(h[n]\\) es absolutamente sumable, \\(\\sum_{n=-\\infty}^{\\infty}|h[n]| &lt; \\infty\\). Esta condición garantiza que cualquier entrada acotada produce salida acotada (BIBO stability - Wikipedia). En el dominio Z, estabilidad equivale a que la ROC de \\(H(z)\\) contenga al círculo unitario (\\(|z|=1\\)) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Para sistemas causales, esto se traduce en que todos los polos deben estar dentro del círculo unitario (ya que la ROC causal comienza fuera del polo de mayor magnitud) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por tanto, un filtro digital causal será estable si sus polos \\(p_i\\) satisfacen \\(|p_i|&lt;1\\). En sistemas no causales (e.g. acausales diseñados con filtrado hacia atrás y adelante para cancelar fase), la estabilidad puede lograrse con polos fuera del unitario siempre y cuando la ROC (un anillo) incluya el unitario (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange), aunque estos casos son menos comunes en línea real. En general, para diseño de filtros digitales asumiremos causalidad, por lo que chequear estabilidad equivale a verificar polos dentro del unitario.\nEjemplo (ECG y estabilidad): Considere un filtro pasoalto diseñado para remover la línea base de ECG definido por la diferencia \\(y[n] = x[n] - x[n-1]\\). Su función de transferencia es \\(H(z) = 1 - z^{-1}\\), con un cero en \\(z=1\\) (cancela DC) y un polo en \\(z=0\\) (simple, debido al \\(z^{-1}\\)). Este sistema es causal (diferencia causal) y su único polo \\(z=0\\) está dentro del círculo unitario, por lo que es estable. De hecho, su respuesta al impulso \\(h[n]=\\delta[n] - \\delta[n-1]\\) suma 0 en valor absoluto (sumable). Este filtro elimina componentes de muy baja frecuencia, como la deriva de línea base en un ECG (), sin inestabilidad.\n\n\n\nUn sistema LTI discreto queda caracterizado completamente por su respuesta al impulso \\(h[n]\\). Dada cualquier entrada \\(x[n]\\), la salida es la convolución discreta \\(y[n] = (x*h)[n] = \\sum_{k=-\\infty}^{\\infty} h[k]\\,x[n-k]\\). En el dominio Z, esta convolución se convierte en multiplicación: \\(Y(z) = H(z)\\,X(z)\\) (dentro de la intersección de ROC de \\(X\\) y \\(H\\)). La función de transferencia \\(H(z)\\) de un sistema LTI causal viene dada por la transformada Z de \\(h[n]\\) (unilateral). En sistemas de coeficientes constantes (difundidos en ingeniería), \\(H(z)\\) suele ser una función racional de \\(z\\):\n\\[H(z) = \\frac{B(z)}{A(z)} = \\frac{b_0 + b_1 z^{-1} + \\cdots + b_M z^{-M}}{1 + a_1 z^{-1} + \\cdots + a_N z^{-N}},\\]\ndonde \\(B(z)\\) y \\(A(z)\\) son polinomios en \\(z^{-1}\\). La razón de escribir en potencias de \\(z^{-1}\\) es para reflejar la causalidad (solo potencias no positivas de \\(z\\)). La ecuación en diferencias asociada es:\n\\[y[n] + a_1 y[n-1] + \\cdots + a_N y[n-N] = b_0 x[n] + b_1 x[n-1] + \\cdots + b_M x[n-M].\\]\nEste es el modelo típico de sistemas LTI discreto. Si \\(N=0\\) (no hay realimentación, solo ceros), el sistema es FIR (Finite Impulse Response), pues \\(h[n]\\) es de duración finita (máximo \\(M\\)). Si \\(N&gt;0\\), hay realimentación y el sistema es IIR (Infinite Impulse Response), con respuesta al impulso teóricamente infinita (aunque decreciente si es estable).\nDiagramas de bloques: Un LTI puede implementarse mediante sumas, retardos (\\(z^{-1}\\) representa un retardo de 1 muestra) y multiplicaciones por constantes. El diagrama de bloques representa visualmente la ecuación en diferencias. Por ejemplo, para un filtro IIR de segundo orden:\n\\[y[n] = -a_1 y[n-1] - a_2 y[n-2] + b_0 x[n] + b_1 x[n-1] + b_2 x[n-2],\\]\nel diagrama en forma Directa II combinaría los términos en una estructura canónica con dos bloques de retardo en la rama de realimentación y avance, sumadores para combinar las ramas, y coeficientes \\(a_i\\), \\(b_i\\). Cada polo corresponde a un lazo de realimentación (coeficientes \\(a_i\\)) y cada cero a una ramificación hacia la entrada (coeficientes \\(b_i\\)). Dibujar estos diagramas ayuda a entender la estructura interna, pero en este reporte nos enfocaremos más en el análisis matemático. Cabe destacar que el tipo de filtro (pasa-bajos, pasa-altos, etc.) puede inferirse de \\(H(z)\\): por ejemplo, si \\(H(e^{j\\omega})\\) (respuesta en frecuencia) atenúa bajas frecuencias y deja pasar altas, es pasa-altos. Un método práctico es evaluar \\(H(z)\\) en \\(z=e^{j0}\\) (DC, \\(\\omega=0\\)) y en \\(z=e^{j\\pi}\\) (Nyquist, \\(\\omega=\\pi\\)): si \\(|H(e^{j0})|=0\\) y \\(|H(e^{j\\pi})|\\approx 1\\), es pasa-altos; al revés sería pasa-bajos. Los ceros en \\(z=1\\) anulan \\(\\omega=0\\) (eliminan DC), típicos en pasa-altos (), mientras ceros en \\(z=-1\\) anulan \\(\\omega=\\pi\\) (eliminan la componente de Nyquist, típicos en pasa-bajos). Por su parte, polos cercanos a \\(z=1\\) refuerzan respuesta en bajas frecuencias; polos cercanos a \\(z=-1\\) refuerzan la alta frecuencia \\(\\pi\\). Así, el diagrama polo-cero brinda intuición: ceros sobre la circunferencia unitaria en cierto ángulo \\(\\theta_0\\) causan una notch (anulación) en la frecuencia \\(\\omega=\\theta_0\\), mientras polos cerca de la unidad en \\(\\theta_0\\) generan picos (potenciales resonancias) alrededor de esa frecuencia.\nEjemplo (Filtro notch 60 Hz): Un problema común en bioseñales es eliminar la interferencia de la red eléctrica (50/60 Hz) sobre, por ejemplo, EEG o ECG. Un filtro digital sencillo para eliminar 60 Hz (asumiendo frecuencia de muestreo \\(f_s=5000\\) Hz) es colocar ceros conjugados en \\(z = e^{\\pm j 2\\pi(60/5000)}\\). La función de transferencia resultante puede ser:\n\\[H(z) = 1 - 2\\cos(2\\pi\\frac{60}{5000})\\,z^{-1} + z^{-2}.\\]\nEste \\(H(z)\\) tiene ceros en \\(e^{\\pm j2\\pi(60/5000)}\\) que anulan exactamente la componente de 60 Hz, implementando un filtro notch. Además, es un filtro FIR (orden 2) con coeficientes simétricos, lo que le da fase lineal (importante para no deformar la forma de onda). ¿Es estable? Sí, al ser FIR no hay polos fuera del origen (solo polos en 0, con módulo 0). ¿Es causal? Sí, depende solo de muestras presentes y pasadas de la señal (\\(x[n]\\), \\(x[n-1]\\), \\(x[n-2]\\)). ¿Qué tipo de filtro es? Es un rechaza-banda estrecho centrado en 60 Hz (deja pasar el resto, pero rechaza esa frecuencia). En aplicaciones, este notch suele atenuar ruido de red sin distorsionar significativamente las señales de interés ().\n\n\n\nLos filtros FIR (Respuesta al Impulso Finita) son ampliamente utilizados en procesamiento biomédico porque pueden diseñarse para tener respuesta en fase lineal, evitando distorsión de fase en la señal filtrada (lo cual es útil para preservar la morfología de ondas ECG, por ejemplo). Una manera conceptualmente sencilla de diseñar un FIR es mediante el método de ventana (WindowFIRDesign.fm). Consiste en: (1) definir la respuesta frecuencial ideal deseada \\(H_d(e^{j\\omega})\\), (2) obtener la respuesta al impulso ideal \\(h_d[n]\\) como la transformada inversa de Fourier de \\(H_d\\), y (3) truncar \\(h_d[n]\\) (que usualmente es infinita o muy larga) mediante una función ventana \\(w[n]\\) para obtener un FIR realizable \\(h[n] = h_d[n]\\,w[n]\\).\nPor ejemplo, supongamos que queremos un filtro pasa-bajos ideal con frecuencia de corte \\(\\omega_c\\). El impulso ideal es \\(h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}\\) (un sinc) que se extiende infinitamente. Para obtener un FIR causal de longitud \\(M\\), se multiplica \\(h_d[n]\\) por una ventana \\(w[n]\\) de longitud \\(M\\) centrada apropiadamente (y a menudo se aplica un corrimiento para hacer el filtro causal). Las ventanas comúnmente utilizadas incluyen: Rectangular, Bartlett (triangular), Hann (Hanning), Hamming, Blackman, y la Kaiser (que es ajustable). Cada ventana introduce un cierto lóbulo principal en la respuesta en frecuencia (determinando la anchura de la transición) y lóbulos laterales (que determinan el ripple o atenuación en bandas de rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm).\nLas características típicas de ventanas clásicas (según Oppenheim et al. (WindowFIRDesign.fm) (WindowFIRDesign.fm)) son:\n\nRectangular: lóbulo principal más angosto (ancho \\(\\approx 4\\pi/M\\) rad) pero lóbulos laterales más altos (primer sidelobe ~\\(-13\\) dB, atenuación de rechazo $$21 dB) (WindowFIRDesign.fm). Da la transición más abrupta para un orden dado, al costo de peor rechazo de banda.\nBartlett (triangular): lóbulo principal algo más ancho (\\(\\approx 8\\pi/M\\)), sidelobes ~\\(-25\\) dB (WindowFIRDesign.fm).\nHann: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes ~\\(-31\\) dB (WindowFIRDesign.fm) (mejor rechazo que rectangular pero transiciones más suaves).\nHamming: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes \\(\\approx -41\\) dB (mínima atenuación ~53 dB en rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm). Es muy popular por su buen compromiso entre ancho de transición y rechazo en banda eliminada.\nBlackman: lóbulo principal más ancho (\\(\\approx 12\\pi/M\\)) pero sidelobes muy bajos (~\\(-57\\) dB, atenuación ~74 dB) (WindowFIRDesign.fm).\nKaiser: permite escoger un parámetro \\(\\beta\\) para controlar la atenuación de lóbulo lateral, ofreciendo flexibilidad. Aproximadamente, para lograr \\(A\\) dB de atenuación, \\(\\beta \\approx 0.1102(A-8.7)\\) (para \\(A&gt;50\\)), y el ancho de transición normalizado \\(\\Delta\\omega\\) se relaciona con el orden \\(M\\) y \\(\\beta\\) por \\(M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\\) (WindowFIRDesign.fm) (estas fórmulas provienen de aproximaciones de Kaiser y ayudan a dimensionar el filtro).\n\nEl método de ventanas es sencillo pero implica un compromiso fijo entre ancho de transición y ripple: una vez elegida la ventana, la única forma de mejorar la pendiente de corte es aumentar \\(M\\) (orden del filtro). Por ejemplo, la ventana Hamming siempre tendrá ~\\(-53\\) dB de mínimo en rechazo sin importar \\(M\\) (WindowFIRDesign.fm), pero al incrementar \\(M\\) se reducirá la anchura de transición. En contraste, la ventana rectangular logra transiciones muy rápidas con orden modesto, pero su pobre rechazo (~21 dB) la hace inadecuada si necesitamos, digamos, eliminar ruido fuerte. En señales biomédicas, suele preferirse reducir al mínimo distorsiones residuales de ruido, por lo que ventanas con mejor rechazo (Hamming, Blackman o Kaiser ajustada) son comunes.\nCálculo del orden para especificaciones dadas: Dado un requerimiento de diseño (ej. atenuación mínima de 40 dB en banda eliminada y transición de 10 Hz), podemos estimar el orden necesario. Por ejemplo, en el taller se plantea diseñar un pasa-bajos FIR con \\(f_c = 55\\) Hz (definido al nivel de \\(-6\\) dB), que alcance al menos 20 dB de atenuación a 60 Hz y &gt;40 dB más allá de 80 Hz. Esto implica una banda de transición bastante estrecha (de ~55 a 60 Hz) y un rechazo fuerte. Un enfoque sería probar varias ventanas:\n\nRectangular: probablemente no pueda dar 40 dB de rechazo (limita ~21 dB).\nHamming: puede dar ~53 dB de rechazo, suficiente, pero el ancho de transición \\(\\Delta f\\) será ~\\(\\frac{3.3}{M}\\) (en radianes normalizados, equivalente aprox. a \\(\\frac{0.26 f_s}{M}\\) en Hz para banda bilateral). Para \\(\\Delta f \\approx 5\\) Hz con \\(f_s\\) suficientemente grande, requerirá un \\(M\\) elevado.\nBlackman: daría &gt;60 dB de rechazo, pero su transición es más ancha (por ser \\(12\\pi/M\\) rad).\nKaiser: se puede ajustar para 40 dB con quizás menor \\(M\\) que Hamming, porque se elige justo la atenuación requerida y minimiza ancho de transición para ese nivel.\n\nEn el taller, se sugiere calcular el orden mínimo para cada ventana cumpliendo las specs y elegir la de menor orden. Esto implicaría usar fórmulas o tablas estándar (WindowFIRDesign.fm) (WindowFIRDesign.fm). Por ejemplo, para 40 dB de rechazo y \\(\\Delta f = 20\\) Hz (digamos entre 60 y 80 Hz), la Hamming podría necesitar \\(M \\approx \\frac{3.3\\cdot 2\\pi}{(20/f_s)2\\pi} = \\frac{3.3 f_s}{20}\\) (esta es una estimación tosca usando \\(\\Delta\\omega \\approx 8\\pi/M\\)). Si la señal es de voz muestreada a 8 kHz (caso típico, aunque aquí es biomédica a 200 Hz?), podemos obtener números específicos. En general, se podría iterar aumentando \\(M\\) y midiendo la respuesta espectral hasta que los requisitos se satisfagan.\nA modo de ilustración práctica, diseñemos un filtro FIR pasa-bajos con método del ventaneo en Python, usando scipy.signal.firwin. Por simplicidad, tomemos \\(f_s=200\\) Hz, \\(f_c=30\\) Hz, y usemos ventana de Hamming:\nimport numpy as np\nfrom scipy import signal\nfs = 200.0  # Hz\nfc = 30.0   # Hz (deseamos pasa-bajos)\nN = 51      # orden (se puede ajustar)\ntaps = signal.firwin(N, cutoff=fc, window='hamming', fs=fs)\nw, H = signal.freqz(taps, worN=8000, fs=fs)\n# Convertir respuesta a dB:\nH_db = 20*np.log10(np.abs(H))\n# Encontrar atenuación en 60 Hz:\nidx_60 = np.argmin(np.abs(w-60))\nprint(f\"Atenuación a 60Hz: {H_db[idx_60]:.2f} dB\")\n(El código anterior calcula los coeficientes FIR con ventana de Hamming y evalúa la respuesta. Se puede iterar sobre N hasta lograr &gt;40 dB en 80 Hz, etc.)\nEn general, el método de ventanas es rápido y fácil de implementar. Su principal limitación es la falta de control preciso sobre las bandas: el ripple y transición vienen determinados por la elección de ventana, no exactamente por parámetros deseados (excepto en Kaiser donde hay más control). Aún así, es muy útil en procesamiento biomédico cuando queremos filtros lineales en fase y podemos permitir órdenes relativamente altos (el costo computacional suele ser menor preocupación en aplicaciones off-line, pero en tiempo real un FIR muy largo puede introducir latencia).\n\n\n\nLos filtros IIR (Respuesta Infinita al Impulso) se suelen diseñar a partir de filtros analógicos prototipo utilizando transformaciones como la transformación bilineal. Este enfoque aprovecha décadas de diseños analógicos bien estudiados (Butterworth, Chebyshev, Elíptico, etc.) y los lleva al dominio digital asegurando estabilidad y correspondiendo frecuencias de interés.\nTransformación bilineal: Es una transformación conforme que mapea el plano-\\(s\\) (Laplace) en el plano-\\(z\\) (Z) mediante la sustitución:\n\\[ s = \\frac{2}{T}\\,\\frac{z-1}{\\,z+1\\,}, \\]\ndonde \\(T\\) es el periodo de muestreo (usualmente tomamos \\(T=1\\) para frecuencias normalizadas, o usamos \\(2/T\\) para incluir \\(f_s\\) explícitamente) (Transformación bilineal - Wikipedia, la enciclopedia libre) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esta sustitución se adopta universalmente para convertir funciones de transferencia analógicas \\(H_a(s)\\) en funciones \\(H_d(z)\\) digitales (Transformación bilineal - Wikipedia, la enciclopedia libre). La clave es que la transformación bilineal preserva la estabilidad: polos en el semiplano izquierdo (\\(\\Re(s)&lt;0\\)) mapean dentro del círculo unitario (\\(|z|&lt;1\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Así, un filtro analógico estable producirá un filtro digital estable (Transformación bilineal - Wikipedia, la enciclopedia libre). También mapea el eje \\(j\\omega\\) (eje imaginario \\(s = j\\Omega\\)) en la circunferencia unitaria (\\(z = e^{j\\omega T}\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre), aunque no linealmente en frecuencia. De hecho, existe una distorsión de la respuesta frecuencial conocida como warping: la relación entre frecuencia analógica \\(\\Omega\\) y digital \\(\\omega\\) viene dada por \\(\\omega = 2 \\arctan(\\Omega T/2)\\) (y su inversa \\(\\Omega = \\frac{2}{T}\\tan(\\omega/2)\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esto significa que la escala de frecuencias se comprime al mapear al dominio digital, especialmente conforme \\(\\omega\\) se acerca a Nyquist (\\(\\pi\\) rad/s).\nPara lidiar con el warping, en el diseño se realiza una pre-distorsión (pre-warping) de las especificaciones. Si deseamos que una frecuencia analógica \\(\\Omega_p\\) de corte corresponda exactamente a una digital \\(\\omega_p\\), calculamos \\(\\Omega_p = \\frac{2}{T}\\tan(\\omega_p/2)\\). Lo mismo para frecuencias de banda de rechazo, etc., antes de diseñar el filtro analógico. Luego aplicamos la transformación bilineal. En la práctica, las funciones auxiliares de diseño (como scipy.signal.buttord, cheb1ord, etc.) permiten ingresar especificaciones directamente en el dominio digital y hacen el prewarping internamente (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory).\nPrototipos analógicos comunes:\n\nButterworth: Magnitud con máxima planitud en banda de paso (respuesta maximally flat). No presenta ondulaciones en banda de paso ni rechazo, pero la transición es la más lenta de los tipos clásicos (11.3. Common IIR filters — Digital Signals Theory). Su función de magnitud al cuadrado es \\(|H(j\\Omega)|^2 = \\frac{1}{1 + (\\frac{\\Omega}{\\Omega_c})^{2N}}\\). Para un orden \\(N\\), la atenuación en rechazo aumenta gradualmente con la frecuencia. Útil cuando se quiere respuesta suave sin ripple.\nChebyshev Tipo I: Presenta rizado en banda de paso (ε dB de variación) pero ninguna ondulación en banda de rechazo (11.3. Common IIR filters — Digital Signals Theory). A cambio, logra una caída más abrupta que Butterworth para el mismo orden (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). La magnitud cumple \\(|H(j\\Omega)|^2 = \\frac{1}{1 + \\epsilon^2 T_N^2(\\Omega/\\Omega_c)}\\), donde \\(T_N\\) es el polinomio de Chebyshev de primer tipo (oscila entre ±1). Permite especificar ripple tolerado en pasobanda.\nChebyshev Tipo II: Lo opuesto: sin ripple en banda de paso, pero con ondulación controlada en banda de rechazo. También llamados filtros de Chebyshev inversos. Tienen una transición algo más lenta que los tipo I para igual orden, pero fase más lineal en pasobanda (al no tener ripple ahí).\nElíptico (Cauer): Permite rizado tanto en pasobanda como en rechazo (ambos controlables) (11.3. Common IIR filters — Digital Signals Theory), logrando la caída más empinada de todas las aproximaciones para un orden dado (11.3. Common IIR filters — Digital Signals Theory). Son los más eficientes en términos de orden, a costa de ripple en ambas bandas y mayor no linealidad de fase. Incluyen ceros de transmisión en la banda eliminada, lo que les da atenuación muy alta cerca de los bordes.\n\nEn resumen (11.3. Common IIR filters — Digital Signals Theory): Butterworth no tiene ripple en ninguna banda (pero pendiente menor), Chebyshev I tiene ripple en paso (no en rechazo), Chebyshev II ripple en rechazo (no en paso), y Elíptico ripple en ambas, pero transición más rápida. La Figura 1 ilustra las diferencias de respuesta en un ejemplo práctico.\n(image) Figura 1: Comparación de la respuesta en magnitud (en dB) para filtros IIR pasa-bajos diseñados con las mismas especificaciones (pasa-bajos con \\(f_{p}=3.4\\) kHz con 1 dB de ripple en banda de paso, \\(f_{s}=3.8\\) kHz con 30 dB de atenuación). El filtro elíptico (orden 3, línea roja) logra la transición más abrupta (caída más rápida alrededor de 3.4-3.8 kHz) a costa de presentar ondulaciones tanto en la banda de paso como en la de rechazo. El Chebyshev I (orden 3, línea naranja) exhibe ripple en la banda de paso pero no en la de rechazo, con una pendiente intermedia. El Butterworth (orden 4, línea amarilla) no tiene ripple en ninguna banda, pero requiere un orden mayor y su caída es más paulatina (transición más suave) (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). Todos cumplen con los requisitos (–1 dB a 3.4 kHz, –30 dB a 3.8 kHz), pero el orden mínimo necesario varía (Butterworth necesitó \\(N=4\\) mientras Chebyshev I y Elíptico lograron con \\(N=3\\)). Esto ilustra el compromiso entre pendiente de transición y ondulaciones en las distintas aproximaciones.\nEn diseño, elegir el tipo de filtro depende de la aplicación: en bioseñales, a veces se prefiere Butterworth para evitar cualquier ripple (ej. filtrar ECG sin distorsionar amplitud de componentes clínicas), otras veces un Chebyshev o Elíptico puede ser apropiado si se necesita un filtro muy selectivo (ej. aislar una banda muy estrecha de EEG) y se puede tolerar cierta variación en la ganancia de la banda útil. La fase de los IIR no es lineal, pero si la distorsión de fase es un problema (por ejemplo, desplazamiento o deformación de picos en ECG), puede mitigarse aplicando el filtro hacia adelante y hacia atrás (filtrado por procesamiento inverso con filtfilt de SciPy, logrando respuesta cero-fase a costa de procesar offline) (). En muchos casos, se pueden usar filtros IIR en tiempo real y lograr correcciones de fase si es necesario mediante técnicas de compensación o filtrado bidireccional.\nDiseño por especificaciones: Las funciones buttord, cheb1ord, cheb2ord, ellipord de Python/MATLAB calculan el orden mínimo y frecuencia de corte necesaria para cumplir especificaciones dadas (paso, rechazo, ripple). Luego butter, cheby1/2, ellip generan los coeficientes. En el taller, se plantea diseñar un pasa-bajos IIR para voz (ej. telefónica: \\(f_s=8\\) kHz, \\(f_p=3.4\\) kHz, \\(f_s=3.8\\) kHz, ripple 1 dB, atenuación 30 dB). Un proceso típico sería: usar ellipord para obtener el orden mínimo elíptico, cheb1ord para Chebyshev I, etc., comparar órdenes y elegir uno. En nuestro ejemplo de la Figura 1, ya vimos cómo Butterworth requería orden 4 frente a 3 de Chebyshev/Elíptico para la misma tarea, lo cual es común (Butterworth suele necesitar más orden para specs estrictas). Generalmente, Elíptico da el menor orden, seguido por Chebyshev, luego Butterworth (11.3. Common IIR filters — Digital Signals Theory). Sin embargo, a veces se evita Elíptico si un ripple en rechazo muy bajo es crítico (porque incluso la pequeña ondulación en banda eliminada puede ser indeseable para ciertas mediciones sensibles, aunque en la mayoría de casos biomédicos 30 dB de atenuación es suficiente sin importar un leve ripple residual).\nImplementación en Python: A continuación se ilustra cómo diseñar un filtro Chebyshev Tipo I con SciPy para cumplir especificaciones de voz:\nimport numpy as np\nfrom scipy.signal import cheb1ord, cheby1, freqz\nfs = 8000.0  # Hz\nfp = 3400.0  # Hz pasabanda\nfsb = 3800.0 # Hz stopband\nrp = 1.0     # dB ripple paso\nrs = 30.0    # dB atenuacion rechazo\nN, Wn = cheb1ord(fp, fsb, rp, rs, fs=fs)  # orden y frecuencia crítica\nb, a = cheby1(N, rp, Wn, btype='low', fs=fs)\nw, h = freqz(b, a, worN=1024, fs=fs)\n# Verificar desempeño:\nH_db = 20*np.log10(np.abs(h))\nprint(f\"Orden Chebyshev I = {N}\")\nprint(f\"Ganancia a 3.4kHz = {H_db[np.argmin(np.abs(w-3400))]:.2f} dB\")\nprint(f\"Atenuación a 3.8kHz = {H_db[np.argmin(np.abs(w-3800))]:.2f} dB\")\n(Este código calcula el orden mínimo y coeficientes de un Chebyshev I, luego evalúa la ganancia en 3.4 kHz y 3.8 kHz para verificar que esté cerca de –1 dB y –30 dB respectivamente.)\nEl resultado confirmaría el cumplimiento de especificaciones con el filtro diseñado. Del mismo modo podríamos probar ellipord/ellip y buttord/butter. Vale notar que los diseños IIR generalmente no tienen control explícito de fase lineal (la fase es no lineal e importa evaluar el impacto en la señal; a veces, se realizan calibraciones o se aplica filtrado hacia atrás como mencionado para obtener fase cero).\n\n\n\nUna vez diseñado un filtro (FIR o IIR), es crucial validar su respuesta en frecuencia para asegurarse de que cumple con los requisitos. Esto implica computar \\(H(e^{j\\omega})\\) – típicamente mediante freqz – y verificar ganancias en las bandas de paso (p.ej. pérdida de inserción o ripple) y bandas de rechazo (atenuación mínima). También se puede aplicar el filtro a señales de prueba:\n\nImpulso unitario: la salida debe ser \\(h[n]\\) (sirve para obtener la respuesta al impulso directamente).\nEscalón unitario: la salida debe aproximarse a la respuesta al escalón (integral de \\(h[n]\\)), útil para verificar estabilidad (un filtro pasaaltos, por ej., a entrada escalón debería asentarse a un valor constante, indicando que DC fue removido pero no inestabilidad creciente).\nSeñal senoidal a frecuencias críticas: por ejemplo, inyectar una senoide en la frecuencia de corte para ver si sale atenuada a ~-3 dB o -6 dB según definición; inyectar una senoide en banda eliminada para confirmar fuerte atenuación.\n\nEn contexto biomédico, se suele validar con señales reales. Por ejemplo, si diseñamos un filtro para eliminar deriva de línea base en ECG, podemos probarlo con una señal ECG con deriva artificial y comprobar que efectivamente la elimina sin distorsionar el complejo QRS.\n(image) Figura 2: Ejemplo de filtrado de un segmento de señal ECG con un filtro pasoalto para remover la deriva de línea base. En naranja se muestra el ECG original contaminado con una deriva lenta (simulada como una componente de muy baja frecuencia que causa que la línea base oscile). En amarillo se muestra la señal tras aplicar un filtro pasaaltos Butterworth de 4° orden con \\(f_c \\approx 0.5\\) Hz (aplicado con filtrado hacia adelante y atrás para lograr fase cero). Se observa que la señal filtrada se centra alrededor de cero voltios, eliminando las variaciones lentas de la línea base, mientras preserva las características importantes del ECG (picos QRS, ondas P y T) (). Este proceso mejora la calidad de la señal para análisis posterior (por ejemplo, facilitando la detección de eventos cardiacos), sin introducir distorsión apreciable en la forma de onda rápida del ECG.\nOtro ejemplo es la eliminación de interferencia de red: un filtro notch diseñado como en secciones previas se puede aplicar a una señal EEG a la que deliberadamente se le suma un seno de 50 Hz; la validación consistiría en ver el espectro antes y después (verificando que la línea de 50 Hz desaparece tras filtrar) y que la actividad EEG en otras bandas permanece intacta.\nEn el diseño de filtros FIR e IIR para voz o bioseñales, a veces se comparan métodos. Por ejemplo, en el taller se pide diseñar tanto un FIR por ventana como un IIR por transformación bilineal para ciertas especificaciones. Comparar la respuesta espectral es instructivo: un FIR puede requerir mayor orden para lograr la misma nitidez de corte que un IIR, pero tendrá fase lineal; el IIR logrará la especificación con menos coeficientes, pero introducirá dispersión de fase. Dependiendo de la aplicación, uno u otro puede ser preferible. Estudios en filtrado de ECG han encontrado, por ejemplo, que filtros IIR y FIR bien diseñados pueden ambos remover el ruido de línea base efectivamente; los IIR (como filtros Butterworth pasaaltos) pueden ser implementados en tiempo real con pocas operaciones (comp.dsp | How to write a NotchFilter procedure| page 2), mientras que FIR largos podrían introducir retardo si no se aplican con técnicas especiales. Sin embargo, los FIR lineales en fase aseguran que características como la amplitud del ST o la morfología de la onda P no se deformen ni se desplacen temporalmente, lo cual es crítico en ciertos análisis diagnósticos.\nEn resumen, la validación espectral (y temporal) de los filtros diseñados garantiza que el filtro funcione como esperado en las señales biomédicas objetivo. Se recomienda siempre verificar ganancia en banda pasante (por ej., asegurarse de que un filtro pasa-bajos no atenúe significativamente componentes importantes de la señal, salvo el ripple permitido) y atenuación en banda eliminada (asegurarse de que el ruido o interferencia objetivo realmente se reduce a niveles aceptables). Con herramientas como Python/Matlab, esta validación se realiza fácilmente visualizando la respuesta en frecuencia (como en las Figuras 1 y 2) y realizando pruebas con señales sintéticas o reales.\n\n\n\nEste reporte abordó los fundamentos teóricos necesarios para analizar y diseñar sistemas discretos aplicados a señales biomédicas. Se revisó la transformada Z y su papel en caracterizar señales y sistemas LTI, destacando la importancia de la región de convergencia, polos, ceros, causalidad y estabilidad (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). También se discutió cómo interpretar y construir diagramas de bloques a partir de ecuaciones en diferencias, algo útil para implementar filtros digitalmente. En la parte de diseño, se cubrieron dos enfoques contrastantes: filtros FIR por método de ventanas, sencillos y con fase lineal (deseable en biomédica), y filtros IIR por transformación bilineal a partir de prototipos analógicos (eficientes en orden, aunque con fase no lineal). Se compararon los principales tipos de aproximaciones analógicas (Butterworth, Chebyshev I/II, Elíptico) resaltando sus ventajas y compromisos (11.3. Common IIR filters — Digital Signals Theory).\nA lo largo del documento, se enfatizó la aplicación en señales reales: eliminar deriva de línea base con pasaaltos, suprimir interferencia de red con filtros notch, limitar el ancho de banda de voz o EEG con pasabajos, etc., todo soportado por referencias académicas y ejemplos de código. En la práctica, el ingeniero biomédico debe decidir el tipo de filtro según los requisitos clínicos: por ejemplo, ¿es más importante no distorsionar la forma de onda (fase lineal) o tener un filtro muy agudo (menor orden)? Este tipo de decisiones se facilita con la comprensión profunda de los conceptos aquí explicados.\nCon este marco teórico, se está en capacidad de abordar el taller propuesto: calcular transformadas Z y ROC de señales, analizar sistemas LTI (impulso, estabilidad, salida a entradas dadas), dibujar sus polos, ceros y estructuras, así como diseñar filtros FIR e IIR que satisfagan especificaciones dadas, especialmente dentro del contexto de procesamiento de señales biomédicas donde la fidelidad y eficacia del filtrado impactan directamente la calidad de la información diagnóstica obtenida.\nReferencias: Las referencias provistas en el texto (ej.【23】,【17】,【40】) corresponden a fuentes que respaldan y complementan los puntos discutidos, incluyendo textos de procesamiento digital de señales, artículos de investigación en filtrado de ECG/EEG, y documentación de funciones de diseño de filtros. Estas fuentes ofrecen mayor detalle para el lector interesado en profundizar en aspectos específicos. En particular, se destacan obras clásicas como Oppenheim & Schafer en diseño FIR (WindowFIRDesign.fm), y recursos modernos como libros abiertos de señales y sistemas (Transformada Z - Wikipedia, la enciclopedia libre) y tutoriales de SciPy (11.3. Common IIR filters — Digital Signals Theory) que enriquecen la comprensión teórica y práctica del procesamiento de señales biomédicas."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#introducción",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#introducción",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "El procesamiento digital de señales biomédicas (como ECG y EEG) emplea herramientas matemáticas para analizar y mejorar la calidad de estas señales, extrayendo información útil para diagnóstico y monitoreo clínico (Procesamiento de señales biomédicas: EEG & FPGA). En particular, la transformada Z y los filtros digitales (FIR e IIR) son fundamentales para modelar, analizar y modificar señales en tiempo discreto. Por ejemplo, es común eliminar interferencias de línea base o ruido de red eléctrica (50/60 Hz) mediante filtros pasoalto o de rechazo (notch) adecuados (). Este reporte teórico describe los conceptos clave para resolver un taller de análisis de señales biomédicas, cubriendo la transformada Z, la estabilidad y región de convergencia (ROC), la representación de sistemas LTI (Lineales e Invariantes en el Tiempo) mediante polos y ceros, la respuesta al impulso, los diagramas de bloques, y el diseño de filtros digitales FIR e IIR (incluyendo métodos de ventaneo y transformación bilineal). Se incluyen ejemplos prácticos en Python (usando numpy y scipy) para ilustrar implementaciones, con un claro enfoque en aplicaciones biomédicas como el filtrado de señales ECG/EEG. Las explicaciones se apoyan en referencias académicas para asegurar rigor teórico."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#transformada-z-y-sistemas-lti-discretos",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#transformada-z-y-sistemas-lti-discretos",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "La transformada Z convierte una señal \\(x[n]\\) de tiempo discreto en una representación en el dominio complejo. En forma bilateral, se define como:\n\\[X(z) = \\mathcal{Z}\\{x[n]\\} = \\sum_{n=-\\infty}^{\\infty} x[n]\\,z^{-n},\\]\ndonde \\(z\\) es una variable compleja \\(z = A e^{j\\omega}\\) (con \\(A=|z|\\) y \\(\\omega = \\arg(z)\\)) (Transformada Z - Wikipedia, la enciclopedia libre) (Transformada Z - Wikipedia, la enciclopedia libre). En señales causales (\\(x[n]=0\\) para \\(n&lt;0\\)), suele usarse la transformada Z unilateral definida desde \\(n=0\\) hasta \\(\\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). La transformada Z es análoga a la transformada de Laplace en sistemas continuos, y de hecho puede verse como una serie de Laurent (suma infinita de potencias) (Transformada Z - Wikipedia, la enciclopedia libre).\nRegión de Convergencia (ROC): No toda señal tiene transformada Z en forma cerrada; la serie anterior converge únicamente en ciertas regiones del plano \\(z\\). La ROC se define como el conjunto de valores de \\(z\\) para los cuales la serie converge absolutamente (Transformada Z - Wikipedia, la enciclopedia libre). En términos prácticos, la ROC es el rango de \\(z\\) donde \\(\\sum_{n=-\\infty}^{\\infty}|x[n]z^{-n}| &lt; \\infty\\) (Transformada Z - Wikipedia, la enciclopedia libre). Por ejemplo, si \\(x[n] = a^n u[n]\\) (secuencia exponencial causal con \\(u[n]\\) la escalón unidad), su transformada Z es \\(X(z) = \\frac{1}{1 - a\\,z^{-1}}\\), pero esta expresión es válida solo si \\(|z| &gt; |a|\\) (ya que la serie geométrica converge cuando \\(|a/z|&lt;1\\)). Así, la ROC en este caso es \\(|z| &gt; |a|\\). Si la señal fuera anti-causal (\\(x[n]=0\\) para \\(n&gt;0\\)), la ROC sería \\(|z| &lt; |a|\\) (convergencia hacia adentro). Si \\(x[n]\\) tiene duración finita (FIR), su transformada Z existe para todo \\(z\\neq0\\) excepto quizá puntos donde la propia definición tenga singularidades (por lo general ROC = todo el plano \\(z\\), excepto tal vez \\(z=0\\) o \\(z=\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). La ROC nunca incluye polos (donde la función \\(X(z)\\) diverge) (Transformada Z - Wikipedia, la enciclopedia libre), es típicamente un anillo o media-plano en el plano \\(z\\), y su ubicación está ligada a propiedades de la señal como causalidad y estabilidad.\nPolos y ceros: Cualquier función de transferencia discreta o transformada Z de una señal racional puede expresarse en forma de polos y ceros. Los ceros son valores de \\(z\\) que anulan \\(X(z)\\) (raíces del numerador), y los polos donde \\(X(z)\\) diverge (raíces del denominador). Por ejemplo, en \\(X(z) = \\frac{1}{1 - a z^{-1}}\\), hay un polo en \\(z=a\\) y un cero en \\(z=\\infty\\) (o equivalente, un cero de orden 1 en el origen en la función \\(X(z)\\) multiplicada por \\(z^{-1}\\)). La representación gráfica de polos y ceros en el plano \\(z\\) proporciona intuición sobre el comportamiento frecuencial: los ceros en la circunferencia unitaria (\\(|z|=1\\)) cancelan ciertas frecuencias, mientras que los polos cercanos a la circunferencia unitaria amplifican componentes espectrales cercanas a su ángulo.\nCausalidad: Un sistema LTI discreto es causal si \\(h[n]=0\\) para \\(n&lt;0\\) (su respuesta impulso es nula en tiempos negativos). En la transformada Z, esto implica que la ROC es externa, es decir, de la forma \\(|z|&gt;R\\) (convergencia hacia \\(\\infty\\)) (Transformada Z - Wikipedia, la enciclopedia libre). Todos los polos de un sistema causal deben estar dentro de la ROC (que para causal es exterior al polo de mayor radio) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Un detalle importante es que la ubicación de polos por sí sola no determina completamente la causalidad o estabilidad; la ROC es la que define cuál de las posibles señales con esos polos es la realizada (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por ejemplo, una misma función racional puede corresponder a un sistema causal inestable o a un sistema no causal estable, dependiendo de si la ROC se toma fuera o entre polos (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange).\nEstabilidad BIBO: Un sistema es estable (en sentido BIBO: Bounded-Input Bounded-Output) si su respuesta al impulso \\(h[n]\\) es absolutamente sumable, \\(\\sum_{n=-\\infty}^{\\infty}|h[n]| &lt; \\infty\\). Esta condición garantiza que cualquier entrada acotada produce salida acotada (BIBO stability - Wikipedia). En el dominio Z, estabilidad equivale a que la ROC de \\(H(z)\\) contenga al círculo unitario (\\(|z|=1\\)) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Para sistemas causales, esto se traduce en que todos los polos deben estar dentro del círculo unitario (ya que la ROC causal comienza fuera del polo de mayor magnitud) (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). Por tanto, un filtro digital causal será estable si sus polos \\(p_i\\) satisfacen \\(|p_i|&lt;1\\). En sistemas no causales (e.g. acausales diseñados con filtrado hacia atrás y adelante para cancelar fase), la estabilidad puede lograrse con polos fuera del unitario siempre y cuando la ROC (un anillo) incluya el unitario (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange), aunque estos casos son menos comunes en línea real. En general, para diseño de filtros digitales asumiremos causalidad, por lo que chequear estabilidad equivale a verificar polos dentro del unitario.\nEjemplo (ECG y estabilidad): Considere un filtro pasoalto diseñado para remover la línea base de ECG definido por la diferencia \\(y[n] = x[n] - x[n-1]\\). Su función de transferencia es \\(H(z) = 1 - z^{-1}\\), con un cero en \\(z=1\\) (cancela DC) y un polo en \\(z=0\\) (simple, debido al \\(z^{-1}\\)). Este sistema es causal (diferencia causal) y su único polo \\(z=0\\) está dentro del círculo unitario, por lo que es estable. De hecho, su respuesta al impulso \\(h[n]=\\delta[n] - \\delta[n-1]\\) suma 0 en valor absoluto (sumable). Este filtro elimina componentes de muy baja frecuencia, como la deriva de línea base en un ECG (), sin inestabilidad."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#análisis-de-sistemas-lti-en-tiempo-discreto",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#análisis-de-sistemas-lti-en-tiempo-discreto",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Un sistema LTI discreto queda caracterizado completamente por su respuesta al impulso \\(h[n]\\). Dada cualquier entrada \\(x[n]\\), la salida es la convolución discreta \\(y[n] = (x*h)[n] = \\sum_{k=-\\infty}^{\\infty} h[k]\\,x[n-k]\\). En el dominio Z, esta convolución se convierte en multiplicación: \\(Y(z) = H(z)\\,X(z)\\) (dentro de la intersección de ROC de \\(X\\) y \\(H\\)). La función de transferencia \\(H(z)\\) de un sistema LTI causal viene dada por la transformada Z de \\(h[n]\\) (unilateral). En sistemas de coeficientes constantes (difundidos en ingeniería), \\(H(z)\\) suele ser una función racional de \\(z\\):\n\\[H(z) = \\frac{B(z)}{A(z)} = \\frac{b_0 + b_1 z^{-1} + \\cdots + b_M z^{-M}}{1 + a_1 z^{-1} + \\cdots + a_N z^{-N}},\\]\ndonde \\(B(z)\\) y \\(A(z)\\) son polinomios en \\(z^{-1}\\). La razón de escribir en potencias de \\(z^{-1}\\) es para reflejar la causalidad (solo potencias no positivas de \\(z\\)). La ecuación en diferencias asociada es:\n\\[y[n] + a_1 y[n-1] + \\cdots + a_N y[n-N] = b_0 x[n] + b_1 x[n-1] + \\cdots + b_M x[n-M].\\]\nEste es el modelo típico de sistemas LTI discreto. Si \\(N=0\\) (no hay realimentación, solo ceros), el sistema es FIR (Finite Impulse Response), pues \\(h[n]\\) es de duración finita (máximo \\(M\\)). Si \\(N&gt;0\\), hay realimentación y el sistema es IIR (Infinite Impulse Response), con respuesta al impulso teóricamente infinita (aunque decreciente si es estable).\nDiagramas de bloques: Un LTI puede implementarse mediante sumas, retardos (\\(z^{-1}\\) representa un retardo de 1 muestra) y multiplicaciones por constantes. El diagrama de bloques representa visualmente la ecuación en diferencias. Por ejemplo, para un filtro IIR de segundo orden:\n\\[y[n] = -a_1 y[n-1] - a_2 y[n-2] + b_0 x[n] + b_1 x[n-1] + b_2 x[n-2],\\]\nel diagrama en forma Directa II combinaría los términos en una estructura canónica con dos bloques de retardo en la rama de realimentación y avance, sumadores para combinar las ramas, y coeficientes \\(a_i\\), \\(b_i\\). Cada polo corresponde a un lazo de realimentación (coeficientes \\(a_i\\)) y cada cero a una ramificación hacia la entrada (coeficientes \\(b_i\\)). Dibujar estos diagramas ayuda a entender la estructura interna, pero en este reporte nos enfocaremos más en el análisis matemático. Cabe destacar que el tipo de filtro (pasa-bajos, pasa-altos, etc.) puede inferirse de \\(H(z)\\): por ejemplo, si \\(H(e^{j\\omega})\\) (respuesta en frecuencia) atenúa bajas frecuencias y deja pasar altas, es pasa-altos. Un método práctico es evaluar \\(H(z)\\) en \\(z=e^{j0}\\) (DC, \\(\\omega=0\\)) y en \\(z=e^{j\\pi}\\) (Nyquist, \\(\\omega=\\pi\\)): si \\(|H(e^{j0})|=0\\) y \\(|H(e^{j\\pi})|\\approx 1\\), es pasa-altos; al revés sería pasa-bajos. Los ceros en \\(z=1\\) anulan \\(\\omega=0\\) (eliminan DC), típicos en pasa-altos (), mientras ceros en \\(z=-1\\) anulan \\(\\omega=\\pi\\) (eliminan la componente de Nyquist, típicos en pasa-bajos). Por su parte, polos cercanos a \\(z=1\\) refuerzan respuesta en bajas frecuencias; polos cercanos a \\(z=-1\\) refuerzan la alta frecuencia \\(\\pi\\). Así, el diagrama polo-cero brinda intuición: ceros sobre la circunferencia unitaria en cierto ángulo \\(\\theta_0\\) causan una notch (anulación) en la frecuencia \\(\\omega=\\theta_0\\), mientras polos cerca de la unidad en \\(\\theta_0\\) generan picos (potenciales resonancias) alrededor de esa frecuencia.\nEjemplo (Filtro notch 60 Hz): Un problema común en bioseñales es eliminar la interferencia de la red eléctrica (50/60 Hz) sobre, por ejemplo, EEG o ECG. Un filtro digital sencillo para eliminar 60 Hz (asumiendo frecuencia de muestreo \\(f_s=5000\\) Hz) es colocar ceros conjugados en \\(z = e^{\\pm j 2\\pi(60/5000)}\\). La función de transferencia resultante puede ser:\n\\[H(z) = 1 - 2\\cos(2\\pi\\frac{60}{5000})\\,z^{-1} + z^{-2}.\\]\nEste \\(H(z)\\) tiene ceros en \\(e^{\\pm j2\\pi(60/5000)}\\) que anulan exactamente la componente de 60 Hz, implementando un filtro notch. Además, es un filtro FIR (orden 2) con coeficientes simétricos, lo que le da fase lineal (importante para no deformar la forma de onda). ¿Es estable? Sí, al ser FIR no hay polos fuera del origen (solo polos en 0, con módulo 0). ¿Es causal? Sí, depende solo de muestras presentes y pasadas de la señal (\\(x[n]\\), \\(x[n-1]\\), \\(x[n-2]\\)). ¿Qué tipo de filtro es? Es un rechaza-banda estrecho centrado en 60 Hz (deja pasar el resto, pero rechaza esa frecuencia). En aplicaciones, este notch suele atenuar ruido de red sin distorsionar significativamente las señales de interés ()."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-fir-por-el-método-de-ventanas",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-fir-por-el-método-de-ventanas",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Los filtros FIR (Respuesta al Impulso Finita) son ampliamente utilizados en procesamiento biomédico porque pueden diseñarse para tener respuesta en fase lineal, evitando distorsión de fase en la señal filtrada (lo cual es útil para preservar la morfología de ondas ECG, por ejemplo). Una manera conceptualmente sencilla de diseñar un FIR es mediante el método de ventana (WindowFIRDesign.fm). Consiste en: (1) definir la respuesta frecuencial ideal deseada \\(H_d(e^{j\\omega})\\), (2) obtener la respuesta al impulso ideal \\(h_d[n]\\) como la transformada inversa de Fourier de \\(H_d\\), y (3) truncar \\(h_d[n]\\) (que usualmente es infinita o muy larga) mediante una función ventana \\(w[n]\\) para obtener un FIR realizable \\(h[n] = h_d[n]\\,w[n]\\).\nPor ejemplo, supongamos que queremos un filtro pasa-bajos ideal con frecuencia de corte \\(\\omega_c\\). El impulso ideal es \\(h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}\\) (un sinc) que se extiende infinitamente. Para obtener un FIR causal de longitud \\(M\\), se multiplica \\(h_d[n]\\) por una ventana \\(w[n]\\) de longitud \\(M\\) centrada apropiadamente (y a menudo se aplica un corrimiento para hacer el filtro causal). Las ventanas comúnmente utilizadas incluyen: Rectangular, Bartlett (triangular), Hann (Hanning), Hamming, Blackman, y la Kaiser (que es ajustable). Cada ventana introduce un cierto lóbulo principal en la respuesta en frecuencia (determinando la anchura de la transición) y lóbulos laterales (que determinan el ripple o atenuación en bandas de rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm).\nLas características típicas de ventanas clásicas (según Oppenheim et al. (WindowFIRDesign.fm) (WindowFIRDesign.fm)) son:\n\nRectangular: lóbulo principal más angosto (ancho \\(\\approx 4\\pi/M\\) rad) pero lóbulos laterales más altos (primer sidelobe ~\\(-13\\) dB, atenuación de rechazo $$21 dB) (WindowFIRDesign.fm). Da la transición más abrupta para un orden dado, al costo de peor rechazo de banda.\nBartlett (triangular): lóbulo principal algo más ancho (\\(\\approx 8\\pi/M\\)), sidelobes ~\\(-25\\) dB (WindowFIRDesign.fm).\nHann: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes ~\\(-31\\) dB (WindowFIRDesign.fm) (mejor rechazo que rectangular pero transiciones más suaves).\nHamming: lóbulo principal \\(\\approx 8\\pi/M\\), sidelobes \\(\\approx -41\\) dB (mínima atenuación ~53 dB en rechazo) (WindowFIRDesign.fm) (WindowFIRDesign.fm). Es muy popular por su buen compromiso entre ancho de transición y rechazo en banda eliminada.\nBlackman: lóbulo principal más ancho (\\(\\approx 12\\pi/M\\)) pero sidelobes muy bajos (~\\(-57\\) dB, atenuación ~74 dB) (WindowFIRDesign.fm).\nKaiser: permite escoger un parámetro \\(\\beta\\) para controlar la atenuación de lóbulo lateral, ofreciendo flexibilidad. Aproximadamente, para lograr \\(A\\) dB de atenuación, \\(\\beta \\approx 0.1102(A-8.7)\\) (para \\(A&gt;50\\)), y el ancho de transición normalizado \\(\\Delta\\omega\\) se relaciona con el orden \\(M\\) y \\(\\beta\\) por \\(M \\approx \\frac{A - 8}{2.285\\,\\Delta\\omega}\\) (WindowFIRDesign.fm) (estas fórmulas provienen de aproximaciones de Kaiser y ayudan a dimensionar el filtro).\n\nEl método de ventanas es sencillo pero implica un compromiso fijo entre ancho de transición y ripple: una vez elegida la ventana, la única forma de mejorar la pendiente de corte es aumentar \\(M\\) (orden del filtro). Por ejemplo, la ventana Hamming siempre tendrá ~\\(-53\\) dB de mínimo en rechazo sin importar \\(M\\) (WindowFIRDesign.fm), pero al incrementar \\(M\\) se reducirá la anchura de transición. En contraste, la ventana rectangular logra transiciones muy rápidas con orden modesto, pero su pobre rechazo (~21 dB) la hace inadecuada si necesitamos, digamos, eliminar ruido fuerte. En señales biomédicas, suele preferirse reducir al mínimo distorsiones residuales de ruido, por lo que ventanas con mejor rechazo (Hamming, Blackman o Kaiser ajustada) son comunes.\nCálculo del orden para especificaciones dadas: Dado un requerimiento de diseño (ej. atenuación mínima de 40 dB en banda eliminada y transición de 10 Hz), podemos estimar el orden necesario. Por ejemplo, en el taller se plantea diseñar un pasa-bajos FIR con \\(f_c = 55\\) Hz (definido al nivel de \\(-6\\) dB), que alcance al menos 20 dB de atenuación a 60 Hz y &gt;40 dB más allá de 80 Hz. Esto implica una banda de transición bastante estrecha (de ~55 a 60 Hz) y un rechazo fuerte. Un enfoque sería probar varias ventanas:\n\nRectangular: probablemente no pueda dar 40 dB de rechazo (limita ~21 dB).\nHamming: puede dar ~53 dB de rechazo, suficiente, pero el ancho de transición \\(\\Delta f\\) será ~\\(\\frac{3.3}{M}\\) (en radianes normalizados, equivalente aprox. a \\(\\frac{0.26 f_s}{M}\\) en Hz para banda bilateral). Para \\(\\Delta f \\approx 5\\) Hz con \\(f_s\\) suficientemente grande, requerirá un \\(M\\) elevado.\nBlackman: daría &gt;60 dB de rechazo, pero su transición es más ancha (por ser \\(12\\pi/M\\) rad).\nKaiser: se puede ajustar para 40 dB con quizás menor \\(M\\) que Hamming, porque se elige justo la atenuación requerida y minimiza ancho de transición para ese nivel.\n\nEn el taller, se sugiere calcular el orden mínimo para cada ventana cumpliendo las specs y elegir la de menor orden. Esto implicaría usar fórmulas o tablas estándar (WindowFIRDesign.fm) (WindowFIRDesign.fm). Por ejemplo, para 40 dB de rechazo y \\(\\Delta f = 20\\) Hz (digamos entre 60 y 80 Hz), la Hamming podría necesitar \\(M \\approx \\frac{3.3\\cdot 2\\pi}{(20/f_s)2\\pi} = \\frac{3.3 f_s}{20}\\) (esta es una estimación tosca usando \\(\\Delta\\omega \\approx 8\\pi/M\\)). Si la señal es de voz muestreada a 8 kHz (caso típico, aunque aquí es biomédica a 200 Hz?), podemos obtener números específicos. En general, se podría iterar aumentando \\(M\\) y midiendo la respuesta espectral hasta que los requisitos se satisfagan.\nA modo de ilustración práctica, diseñemos un filtro FIR pasa-bajos con método del ventaneo en Python, usando scipy.signal.firwin. Por simplicidad, tomemos \\(f_s=200\\) Hz, \\(f_c=30\\) Hz, y usemos ventana de Hamming:\nimport numpy as np\nfrom scipy import signal\nfs = 200.0  # Hz\nfc = 30.0   # Hz (deseamos pasa-bajos)\nN = 51      # orden (se puede ajustar)\ntaps = signal.firwin(N, cutoff=fc, window='hamming', fs=fs)\nw, H = signal.freqz(taps, worN=8000, fs=fs)\n# Convertir respuesta a dB:\nH_db = 20*np.log10(np.abs(H))\n# Encontrar atenuación en 60 Hz:\nidx_60 = np.argmin(np.abs(w-60))\nprint(f\"Atenuación a 60Hz: {H_db[idx_60]:.2f} dB\")\n(El código anterior calcula los coeficientes FIR con ventana de Hamming y evalúa la respuesta. Se puede iterar sobre N hasta lograr &gt;40 dB en 80 Hz, etc.)\nEn general, el método de ventanas es rápido y fácil de implementar. Su principal limitación es la falta de control preciso sobre las bandas: el ripple y transición vienen determinados por la elección de ventana, no exactamente por parámetros deseados (excepto en Kaiser donde hay más control). Aún así, es muy útil en procesamiento biomédico cuando queremos filtros lineales en fase y podemos permitir órdenes relativamente altos (el costo computacional suele ser menor preocupación en aplicaciones off-line, pero en tiempo real un FIR muy largo puede introducir latencia)."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-iir-por-transformación-bilineal",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#diseño-de-filtros-iir-por-transformación-bilineal",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Los filtros IIR (Respuesta Infinita al Impulso) se suelen diseñar a partir de filtros analógicos prototipo utilizando transformaciones como la transformación bilineal. Este enfoque aprovecha décadas de diseños analógicos bien estudiados (Butterworth, Chebyshev, Elíptico, etc.) y los lleva al dominio digital asegurando estabilidad y correspondiendo frecuencias de interés.\nTransformación bilineal: Es una transformación conforme que mapea el plano-\\(s\\) (Laplace) en el plano-\\(z\\) (Z) mediante la sustitución:\n\\[ s = \\frac{2}{T}\\,\\frac{z-1}{\\,z+1\\,}, \\]\ndonde \\(T\\) es el periodo de muestreo (usualmente tomamos \\(T=1\\) para frecuencias normalizadas, o usamos \\(2/T\\) para incluir \\(f_s\\) explícitamente) (Transformación bilineal - Wikipedia, la enciclopedia libre) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esta sustitución se adopta universalmente para convertir funciones de transferencia analógicas \\(H_a(s)\\) en funciones \\(H_d(z)\\) digitales (Transformación bilineal - Wikipedia, la enciclopedia libre). La clave es que la transformación bilineal preserva la estabilidad: polos en el semiplano izquierdo (\\(\\Re(s)&lt;0\\)) mapean dentro del círculo unitario (\\(|z|&lt;1\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Así, un filtro analógico estable producirá un filtro digital estable (Transformación bilineal - Wikipedia, la enciclopedia libre). También mapea el eje \\(j\\omega\\) (eje imaginario \\(s = j\\Omega\\)) en la circunferencia unitaria (\\(z = e^{j\\omega T}\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre), aunque no linealmente en frecuencia. De hecho, existe una distorsión de la respuesta frecuencial conocida como warping: la relación entre frecuencia analógica \\(\\Omega\\) y digital \\(\\omega\\) viene dada por \\(\\omega = 2 \\arctan(\\Omega T/2)\\) (y su inversa \\(\\Omega = \\frac{2}{T}\\tan(\\omega/2)\\)) (Transformación bilineal - Wikipedia, la enciclopedia libre). Esto significa que la escala de frecuencias se comprime al mapear al dominio digital, especialmente conforme \\(\\omega\\) se acerca a Nyquist (\\(\\pi\\) rad/s).\nPara lidiar con el warping, en el diseño se realiza una pre-distorsión (pre-warping) de las especificaciones. Si deseamos que una frecuencia analógica \\(\\Omega_p\\) de corte corresponda exactamente a una digital \\(\\omega_p\\), calculamos \\(\\Omega_p = \\frac{2}{T}\\tan(\\omega_p/2)\\). Lo mismo para frecuencias de banda de rechazo, etc., antes de diseñar el filtro analógico. Luego aplicamos la transformación bilineal. En la práctica, las funciones auxiliares de diseño (como scipy.signal.buttord, cheb1ord, etc.) permiten ingresar especificaciones directamente en el dominio digital y hacen el prewarping internamente (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory).\nPrototipos analógicos comunes:\n\nButterworth: Magnitud con máxima planitud en banda de paso (respuesta maximally flat). No presenta ondulaciones en banda de paso ni rechazo, pero la transición es la más lenta de los tipos clásicos (11.3. Common IIR filters — Digital Signals Theory). Su función de magnitud al cuadrado es \\(|H(j\\Omega)|^2 = \\frac{1}{1 + (\\frac{\\Omega}{\\Omega_c})^{2N}}\\). Para un orden \\(N\\), la atenuación en rechazo aumenta gradualmente con la frecuencia. Útil cuando se quiere respuesta suave sin ripple.\nChebyshev Tipo I: Presenta rizado en banda de paso (ε dB de variación) pero ninguna ondulación en banda de rechazo (11.3. Common IIR filters — Digital Signals Theory). A cambio, logra una caída más abrupta que Butterworth para el mismo orden (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). La magnitud cumple \\(|H(j\\Omega)|^2 = \\frac{1}{1 + \\epsilon^2 T_N^2(\\Omega/\\Omega_c)}\\), donde \\(T_N\\) es el polinomio de Chebyshev de primer tipo (oscila entre ±1). Permite especificar ripple tolerado en pasobanda.\nChebyshev Tipo II: Lo opuesto: sin ripple en banda de paso, pero con ondulación controlada en banda de rechazo. También llamados filtros de Chebyshev inversos. Tienen una transición algo más lenta que los tipo I para igual orden, pero fase más lineal en pasobanda (al no tener ripple ahí).\nElíptico (Cauer): Permite rizado tanto en pasobanda como en rechazo (ambos controlables) (11.3. Common IIR filters — Digital Signals Theory), logrando la caída más empinada de todas las aproximaciones para un orden dado (11.3. Common IIR filters — Digital Signals Theory). Son los más eficientes en términos de orden, a costa de ripple en ambas bandas y mayor no linealidad de fase. Incluyen ceros de transmisión en la banda eliminada, lo que les da atenuación muy alta cerca de los bordes.\n\nEn resumen (11.3. Common IIR filters — Digital Signals Theory): Butterworth no tiene ripple en ninguna banda (pero pendiente menor), Chebyshev I tiene ripple en paso (no en rechazo), Chebyshev II ripple en rechazo (no en paso), y Elíptico ripple en ambas, pero transición más rápida. La Figura 1 ilustra las diferencias de respuesta en un ejemplo práctico.\n(image) Figura 1: Comparación de la respuesta en magnitud (en dB) para filtros IIR pasa-bajos diseñados con las mismas especificaciones (pasa-bajos con \\(f_{p}=3.4\\) kHz con 1 dB de ripple en banda de paso, \\(f_{s}=3.8\\) kHz con 30 dB de atenuación). El filtro elíptico (orden 3, línea roja) logra la transición más abrupta (caída más rápida alrededor de 3.4-3.8 kHz) a costa de presentar ondulaciones tanto en la banda de paso como en la de rechazo. El Chebyshev I (orden 3, línea naranja) exhibe ripple en la banda de paso pero no en la de rechazo, con una pendiente intermedia. El Butterworth (orden 4, línea amarilla) no tiene ripple en ninguna banda, pero requiere un orden mayor y su caída es más paulatina (transición más suave) (11.3. Common IIR filters — Digital Signals Theory) (11.3. Common IIR filters — Digital Signals Theory). Todos cumplen con los requisitos (–1 dB a 3.4 kHz, –30 dB a 3.8 kHz), pero el orden mínimo necesario varía (Butterworth necesitó \\(N=4\\) mientras Chebyshev I y Elíptico lograron con \\(N=3\\)). Esto ilustra el compromiso entre pendiente de transición y ondulaciones en las distintas aproximaciones.\nEn diseño, elegir el tipo de filtro depende de la aplicación: en bioseñales, a veces se prefiere Butterworth para evitar cualquier ripple (ej. filtrar ECG sin distorsionar amplitud de componentes clínicas), otras veces un Chebyshev o Elíptico puede ser apropiado si se necesita un filtro muy selectivo (ej. aislar una banda muy estrecha de EEG) y se puede tolerar cierta variación en la ganancia de la banda útil. La fase de los IIR no es lineal, pero si la distorsión de fase es un problema (por ejemplo, desplazamiento o deformación de picos en ECG), puede mitigarse aplicando el filtro hacia adelante y hacia atrás (filtrado por procesamiento inverso con filtfilt de SciPy, logrando respuesta cero-fase a costa de procesar offline) (). En muchos casos, se pueden usar filtros IIR en tiempo real y lograr correcciones de fase si es necesario mediante técnicas de compensación o filtrado bidireccional.\nDiseño por especificaciones: Las funciones buttord, cheb1ord, cheb2ord, ellipord de Python/MATLAB calculan el orden mínimo y frecuencia de corte necesaria para cumplir especificaciones dadas (paso, rechazo, ripple). Luego butter, cheby1/2, ellip generan los coeficientes. En el taller, se plantea diseñar un pasa-bajos IIR para voz (ej. telefónica: \\(f_s=8\\) kHz, \\(f_p=3.4\\) kHz, \\(f_s=3.8\\) kHz, ripple 1 dB, atenuación 30 dB). Un proceso típico sería: usar ellipord para obtener el orden mínimo elíptico, cheb1ord para Chebyshev I, etc., comparar órdenes y elegir uno. En nuestro ejemplo de la Figura 1, ya vimos cómo Butterworth requería orden 4 frente a 3 de Chebyshev/Elíptico para la misma tarea, lo cual es común (Butterworth suele necesitar más orden para specs estrictas). Generalmente, Elíptico da el menor orden, seguido por Chebyshev, luego Butterworth (11.3. Common IIR filters — Digital Signals Theory). Sin embargo, a veces se evita Elíptico si un ripple en rechazo muy bajo es crítico (porque incluso la pequeña ondulación en banda eliminada puede ser indeseable para ciertas mediciones sensibles, aunque en la mayoría de casos biomédicos 30 dB de atenuación es suficiente sin importar un leve ripple residual).\nImplementación en Python: A continuación se ilustra cómo diseñar un filtro Chebyshev Tipo I con SciPy para cumplir especificaciones de voz:\nimport numpy as np\nfrom scipy.signal import cheb1ord, cheby1, freqz\nfs = 8000.0  # Hz\nfp = 3400.0  # Hz pasabanda\nfsb = 3800.0 # Hz stopband\nrp = 1.0     # dB ripple paso\nrs = 30.0    # dB atenuacion rechazo\nN, Wn = cheb1ord(fp, fsb, rp, rs, fs=fs)  # orden y frecuencia crítica\nb, a = cheby1(N, rp, Wn, btype='low', fs=fs)\nw, h = freqz(b, a, worN=1024, fs=fs)\n# Verificar desempeño:\nH_db = 20*np.log10(np.abs(h))\nprint(f\"Orden Chebyshev I = {N}\")\nprint(f\"Ganancia a 3.4kHz = {H_db[np.argmin(np.abs(w-3400))]:.2f} dB\")\nprint(f\"Atenuación a 3.8kHz = {H_db[np.argmin(np.abs(w-3800))]:.2f} dB\")\n(Este código calcula el orden mínimo y coeficientes de un Chebyshev I, luego evalúa la ganancia en 3.4 kHz y 3.8 kHz para verificar que esté cerca de –1 dB y –30 dB respectivamente.)\nEl resultado confirmaría el cumplimiento de especificaciones con el filtro diseñado. Del mismo modo podríamos probar ellipord/ellip y buttord/butter. Vale notar que los diseños IIR generalmente no tienen control explícito de fase lineal (la fase es no lineal e importa evaluar el impacto en la señal; a veces, se realizan calibraciones o se aplica filtrado hacia atrás como mencionado para obtener fase cero)."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#validación-espectral-y-aplicaciones-en-señales-biomédicas",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#validación-espectral-y-aplicaciones-en-señales-biomédicas",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Una vez diseñado un filtro (FIR o IIR), es crucial validar su respuesta en frecuencia para asegurarse de que cumple con los requisitos. Esto implica computar \\(H(e^{j\\omega})\\) – típicamente mediante freqz – y verificar ganancias en las bandas de paso (p.ej. pérdida de inserción o ripple) y bandas de rechazo (atenuación mínima). También se puede aplicar el filtro a señales de prueba:\n\nImpulso unitario: la salida debe ser \\(h[n]\\) (sirve para obtener la respuesta al impulso directamente).\nEscalón unitario: la salida debe aproximarse a la respuesta al escalón (integral de \\(h[n]\\)), útil para verificar estabilidad (un filtro pasaaltos, por ej., a entrada escalón debería asentarse a un valor constante, indicando que DC fue removido pero no inestabilidad creciente).\nSeñal senoidal a frecuencias críticas: por ejemplo, inyectar una senoide en la frecuencia de corte para ver si sale atenuada a ~-3 dB o -6 dB según definición; inyectar una senoide en banda eliminada para confirmar fuerte atenuación.\n\nEn contexto biomédico, se suele validar con señales reales. Por ejemplo, si diseñamos un filtro para eliminar deriva de línea base en ECG, podemos probarlo con una señal ECG con deriva artificial y comprobar que efectivamente la elimina sin distorsionar el complejo QRS.\n(image) Figura 2: Ejemplo de filtrado de un segmento de señal ECG con un filtro pasoalto para remover la deriva de línea base. En naranja se muestra el ECG original contaminado con una deriva lenta (simulada como una componente de muy baja frecuencia que causa que la línea base oscile). En amarillo se muestra la señal tras aplicar un filtro pasaaltos Butterworth de 4° orden con \\(f_c \\approx 0.5\\) Hz (aplicado con filtrado hacia adelante y atrás para lograr fase cero). Se observa que la señal filtrada se centra alrededor de cero voltios, eliminando las variaciones lentas de la línea base, mientras preserva las características importantes del ECG (picos QRS, ondas P y T) (). Este proceso mejora la calidad de la señal para análisis posterior (por ejemplo, facilitando la detección de eventos cardiacos), sin introducir distorsión apreciable en la forma de onda rápida del ECG.\nOtro ejemplo es la eliminación de interferencia de red: un filtro notch diseñado como en secciones previas se puede aplicar a una señal EEG a la que deliberadamente se le suma un seno de 50 Hz; la validación consistiría en ver el espectro antes y después (verificando que la línea de 50 Hz desaparece tras filtrar) y que la actividad EEG en otras bandas permanece intacta.\nEn el diseño de filtros FIR e IIR para voz o bioseñales, a veces se comparan métodos. Por ejemplo, en el taller se pide diseñar tanto un FIR por ventana como un IIR por transformación bilineal para ciertas especificaciones. Comparar la respuesta espectral es instructivo: un FIR puede requerir mayor orden para lograr la misma nitidez de corte que un IIR, pero tendrá fase lineal; el IIR logrará la especificación con menos coeficientes, pero introducirá dispersión de fase. Dependiendo de la aplicación, uno u otro puede ser preferible. Estudios en filtrado de ECG han encontrado, por ejemplo, que filtros IIR y FIR bien diseñados pueden ambos remover el ruido de línea base efectivamente; los IIR (como filtros Butterworth pasaaltos) pueden ser implementados en tiempo real con pocas operaciones (comp.dsp | How to write a NotchFilter procedure| page 2), mientras que FIR largos podrían introducir retardo si no se aplican con técnicas especiales. Sin embargo, los FIR lineales en fase aseguran que características como la amplitud del ST o la morfología de la onda P no se deformen ni se desplacen temporalmente, lo cual es crítico en ciertos análisis diagnósticos.\nEn resumen, la validación espectral (y temporal) de los filtros diseñados garantiza que el filtro funcione como esperado en las señales biomédicas objetivo. Se recomienda siempre verificar ganancia en banda pasante (por ej., asegurarse de que un filtro pasa-bajos no atenúe significativamente componentes importantes de la señal, salvo el ripple permitido) y atenuación en banda eliminada (asegurarse de que el ruido o interferencia objetivo realmente se reduce a niveles aceptables). Con herramientas como Python/Matlab, esta validación se realiza fácilmente visualizando la respuesta en frecuencia (como en las Figuras 1 y 2) y realizando pruebas con señales sintéticas o reales."
  },
  {
    "objectID": "recursos/documentos/Teoria_Taller_SYSB.html#conclusiones",
    "href": "recursos/documentos/Teoria_Taller_SYSB.html#conclusiones",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "Este reporte abordó los fundamentos teóricos necesarios para analizar y diseñar sistemas discretos aplicados a señales biomédicas. Se revisó la transformada Z y su papel en caracterizar señales y sistemas LTI, destacando la importancia de la región de convergencia, polos, ceros, causalidad y estabilidad (z transform - BIBO Stability in Z-domain - Signal Processing Stack Exchange). También se discutió cómo interpretar y construir diagramas de bloques a partir de ecuaciones en diferencias, algo útil para implementar filtros digitalmente. En la parte de diseño, se cubrieron dos enfoques contrastantes: filtros FIR por método de ventanas, sencillos y con fase lineal (deseable en biomédica), y filtros IIR por transformación bilineal a partir de prototipos analógicos (eficientes en orden, aunque con fase no lineal). Se compararon los principales tipos de aproximaciones analógicas (Butterworth, Chebyshev I/II, Elíptico) resaltando sus ventajas y compromisos (11.3. Common IIR filters — Digital Signals Theory).\nA lo largo del documento, se enfatizó la aplicación en señales reales: eliminar deriva de línea base con pasaaltos, suprimir interferencia de red con filtros notch, limitar el ancho de banda de voz o EEG con pasabajos, etc., todo soportado por referencias académicas y ejemplos de código. En la práctica, el ingeniero biomédico debe decidir el tipo de filtro según los requisitos clínicos: por ejemplo, ¿es más importante no distorsionar la forma de onda (fase lineal) o tener un filtro muy agudo (menor orden)? Este tipo de decisiones se facilita con la comprensión profunda de los conceptos aquí explicados.\nCon este marco teórico, se está en capacidad de abordar el taller propuesto: calcular transformadas Z y ROC de señales, analizar sistemas LTI (impulso, estabilidad, salida a entradas dadas), dibujar sus polos, ceros y estructuras, así como diseñar filtros FIR e IIR que satisfagan especificaciones dadas, especialmente dentro del contexto de procesamiento de señales biomédicas donde la fidelidad y eficacia del filtrado impactan directamente la calidad de la información diagnóstica obtenida.\nReferencias: Las referencias provistas en el texto (ej.【23】,【17】,【40】) corresponden a fuentes que respaldan y complementan los puntos discutidos, incluyendo textos de procesamiento digital de señales, artículos de investigación en filtrado de ECG/EEG, y documentación de funciones de diseño de filtros. Estas fuentes ofrecen mayor detalle para el lector interesado en profundizar en aspectos específicos. En particular, se destacan obras clásicas como Oppenheim & Schafer en diseño FIR (WindowFIRDesign.fm), y recursos modernos como libros abiertos de señales y sistemas (Transformada Z - Wikipedia, la enciclopedia libre) y tutoriales de SciPy (11.3. Common IIR filters — Digital Signals Theory) que enriquecen la comprensión teórica y práctica del procesamiento de señales biomédicas."
  },
  {
    "objectID": "recursos/documentos/Teoria_SeñalesEnergiaPotencia.html",
    "href": "recursos/documentos/Teoria_SeñalesEnergiaPotencia.html",
    "title": "Taller3: Análisis y diseños de filtros",
    "section": "",
    "text": "¿Por qué distinguir entre señales de energía y señales de potencia en procesamiento de señales?\n\nEl conjunto matemático adecuado.Las señales de energía pertenecen a \\(L^{2}\\) con norma finita \\(\\lVert x\\rVert_{2}=\\sqrt{E}\\), lo que habilita resultados como Parseval/Plancherel (p. ej., \\(\\int_{-\\infty}^{\\infty}\\lvert x(t)\\rvert^{2},dt=\\tfrac{1}{2\\pi}\\int_{-\\infty}^{\\infty}\\lvert X(\\omega)\\rvert^{2},d\\omega\\)). Las señales de potencia suelen requerir promedios temporales y estadísticas de segundo orden en lugar de normas finitas.\nEl análisis espectral difiere. En señales de energía, el objeto natural es la transformada de Fourier \\(X(\\omega)\\) y la energía se concentra en \\(\\lvert X(\\omega)\\rvert^{2}\\). En señales de potencia (p. ej., periódicas o estacionarias), el objeto clave es la densidad espectral de potencia (PSD) \\(S_{X}(\\omega)\\), obtenida a partir de la autocorrelación \\(R_{X}(\\tau)\\) vía Wiener–Khinchin: \\(S_{X}(\\omega)=\\mathcal{F}{R_{X}(\\tau)}\\).\nLas métricas de desempeño dependen de la clase. La relación señal-ruido se formula como SNR de energía \\(\\mathrm{SNR}=E_{s}/E_{n}\\) para pulsos/transitorios y como SNR de potencia \\(\\mathrm{SNR}=P_{s}/P_{n}\\) para procesos de larga duración o estacionarios. Usar la métrica incorrecta sesga el diseño de detectores/estimadores.\nDiseño y evaluación de filtros. Para señales de energía, la detección óptima usa filtros casados que maximizan la energía de salida. Para señales de potencia/estacionarias, se modela el ruido mediante la PSD (p. ej., filtrado de Wiener) y se evalúa la potencia o varianza de salida.\nMuestreo, ventanas y práctica con DFT/FFT. Señales de energía: se integra la energía en el intervalo observado e interprete \\(\\lvert X[k]\\rvert^{2}\\) como distribución de energía por bins de la DFT. Señales de potencia: se estima la PSD con periodogramas/Welch; \\(S_{X}(\\omega)\\) tiene unidades de potencia por Hz y se promedia entre ventanas para reducir varianza.\nModelado de bioseñales reales. Muchos estallidos/transitorios biomédicos (ráfagas de EMG, potenciales evocados) se comportan como señales de energía; componentes cuasi-periódicos o estacionarios de larga duración (fundamental del ECG en reposo, respiración en minutos) se comportan como señales de potencia. Modelarlas correctamente guía la extracción de rasgos (envolventes basadas en energía vs. bandas de PSD).\nArgumentos de convergencia y estabilidad. Demostraciones de convergencia para estimadores y cotas de estabilidad para sistemas suelen asumir energía finita o potencia promedio finita; clasificar mal invalida esas garantías.\nUnidades e interpretación. Los espectros de energía se relacionan con \\(\\lvert X(\\omega)\\rvert^{2}\\) (su integral total da \\(E\\)). La PSD integra a potencia promedio: \\(\\tfrac{1}{2\\pi}\\int_{-\\infty}^{\\infty}S_{X}(\\omega),d\\omega=P\\).\nRegla rápida. Si la señal se extingue o es estrictamente acotada en tiempo y \\(\\int\\lvert x\\rvert^{2}\\) es finita, trátela como energía; si persiste indefinidamente con promedio bien definido, trátela como potencia y use \\(R_{X}(\\tau)\\)/\\(S_{X}(\\omega)\\)."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripción",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#descripción",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "A través de este taller se reforzarán los conocimientos en: señales, transformaciones de la\nvariable independiente, clasificación de señales, ADC y DAC."
  },
  {
    "objectID": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "href": "recursos/talleres/SYSB/SYSB202501_Sol_TallerRepasoIntroSennales.html#procedimiento",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Procedimiento",
    "text": "Procedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\n\n1. Considere la señal\n\\[x(t) = \\begin{cases}\n  t + 1, & -1 \\leq t \\leq 0 \\\\\n  2, & 0 &lt; t \\leq 2 \\\\\n  1, & 2 &lt; t \\leq 3 \\\\\n  0, & \\text{en otro caso}\n\\end{cases}\\]\nDibuje:\n\nSolución\nSe grafican las transformaciones solicitadas en Python con Matplotlib.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef x_t(t):\n    return np.piecewise(t, [(-1 &lt;= t) & (t &lt;= 0), (0 &lt; t) & (t &lt;= 2), (2 &lt; t) & (t &lt;= 3)],\n                         [lambda t: t + 1, 2, 1, 0])\n\nt = np.linspace(-2, 4, 1000)\nplt.plot(t, x_t(t), label='x(t)')\nplt.xlabel('t')\nplt.ylabel('x(t)')\nplt.legend()\nplt.show()\n\n\n\n\n2. Determine si las siguientes señales son periódicas y encuentre su periodo\n\nSolución\nAnalizamos si \\(\\frac{f_0}{f_s}\\) es racional.\n\n\\(x(t) = \\cos(2t) + \\cos(\\pi t)\\)\n\nPeríodos: \\(T_1 = \\frac{2\\pi}{2} = \\pi\\), \\(T_2 = \\frac{2\\pi}{\\pi} = 2\\)\nMínimo común múltiplo: **Período = 2*\n\n\\(x(t) = e^{-j(4\\pi/3)t} + e^{j(2\\pi/5)t}\\)\n\nSe buscan los períodos fundamentales.\nNo es periódica porque las razones de frecuencias son irracionales.\n\n\n…\n\n\n\n\n5. Para una señal análoga \\(x_a(t) = \\sin(600\\pi t) + 3\\sin(480\\pi t)\\), encontrar:\n\nSolución\n\nPeríodo de la señal:\n\nFrecuencias: \\(f_1 = 300Hz\\), \\(f_2 = 240Hz\\)\nMCM de \\(\\frac{1}{300}\\) y \\(\\frac{1}{240}\\) → T = 1/60 s\n\nFrecuencia de muestreo\n\nTeorema de Nyquist: \\(f_s &gt; 2f_{max} = 600Hz\\)\n\nSeñal muestreada:\nfs = 600  # Hz\nn = np.arange(0, 100)\nxa_n = np.sin(600*np.pi*n/fs) + 3*np.sin(480*np.pi*n/fs)\nplt.stem(n, xa_n)\nplt.show()\n\n…\n\n\n\n6. Muestreo y cuantización\n\nSolución\n\nFrecuencia de muestreo:\n\n\\(T_m1 = 12.5ms\\) → \\(f_s = 80Hz\\)\nNo cumple Nyquist → No se puede reconstruir\n\nMuestreo a 8 veces Nyquist:\n\n\\(f_s = 5760Hz\\)\nSe evalúa si \\(\\frac{f_0}{f_s}\\) es racional → Sí es periódica\n\nCuantización (4 bits, rango 0-5):\n\nPaso de cuantización: \\(\\Delta = \\frac{5}{2^4}\\)\nSe discretiza la señal según niveles de cuantización.\n\n\nimport numpy as np\nlevels = np.linspace(0, 5, 16)\nquantized_signal = np.digitize(xa_n, levels) * (5 / 16)\nplt.stem(n, quantized_signal)\nplt.show()\n\nFin del taller."
  },
  {
    "objectID": "recursos/talleres/SYSB/Taller_2025_1.html",
    "href": "recursos/talleres/SYSB/Taller_2025_1.html",
    "title": "Taller 1 - Sistemas y Señales Biomédicos",
    "section": "",
    "text": "Taller 1\nProfesores\nJenny Carolina Castiblanco Sánchez\nPablo Eduardo Caicedo Rodríguez\nDescripción\nA través de este taller se reforzarán los conocimientos en: señales, transformaciones de la variable independiente, clasificación de señales, ADC y DAC.\nProcedimiento\nExplique detalladamente el procedimiento para cada uno de los puntos enunciados a continuación.\nConsidere la señal\nDibuje:\nDetermine si las siguientes señales son periódicas y encuentre su periodo\nPara las siguientes señales encuentre, la potencia instantánea, la energía y la potencia promedio. Indique si la señal se considera de energía o de potencia.\nDemuestre que si y son señales impares, entonces:\n, es una señal par\nes una señal impar.\nSiendo y , grafique en Python y . ¿se cumple lo indicado en el numeral a y b?\nEncuentre la expresión analítica de las señales mostradas a continuación utilizando funciones y (escalón unitario y rampa).\nPara una señal análoga encontrar\nIndique si la señal es una señal periódica, en caso afirmativo, indique el periodo de la señal.\nFrecuencia de muestro que cumpla con el teorema de Nyquist.\nEncontrar con la frecuencia de muestreo encontrada en el punto anterior.\nIndique si la señal es una señal periódica, en caso afirmativo, indique el periodo de la señal.\nConsidere el sistema de procesamiento de señales mostrado en la figura:\nRecuerde que . Si la entrada es , encontrar:\nLa salida si . ¿Con esta frecuencia se puede reconstruir la señal en si ? Justifique su respuesta.\nLa salida si la frecuencia de muestreo del ADC es 8 veces la frecuencia de Nyquist. ¿La señal es periódica en tiempo discreto? Justifique su respuesta.\nPara la señal del punto b, encontrar la señal cuantizada de un ciclo de la señal si el tamaño del registro es de 4bits y el rango de valores que maneja a la entrada es de 0 a 5."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "href": "rubricas/Rubrica_ProyectoFinal_PSIM.html",
    "title": "Proyecto Final: PSIM 2024-1",
    "section": "",
    "text": "Criterio\n5.0  (Excelente)\n4.0  (Bueno)\n3.0  (Aceptable)\n1.0  (Deficiente)\n\n\n\n\n1. Objetivo del Proyecto\nClaramente definido, específico, relevante y alcanzable, alineado con la problemática.\nClaro y relevante, pero carece de precisión o profundidad.\nComprensible, pero general o no bien alineado con la problemática.\nConfuso, irrelevante o ausente.\n\n\n2. Justificación\nSólida, argumenta importancia e impacto con evidencia o literatura relevante.\nAdecuada, pero le falta profundidad o evidencia clara.\nBásica y poco convincente; argumentos débiles o generales.\nInexistente o carente de lógica.\n\n\n3. Metodología\nBien estructurada, clara y adecuada para los objetivos. Técnicas y procedimientos relevantes.\nAdecuada, pero carece de detalle o presenta leves inconsistencias.\nVaga, incompleta o no alineada con los objetivos.\nConfusa, inapropiada o ausente.\n\n\n4. Resultados\nClaros, organizados y rigurosamente analizados. Uso efectivo de herramientas visuales.\nClaros, pero carecen de profundidad en análisis u organización.\nConfusos, incompletos o mal interpretados.\nIrrelevantes, incorrectos o ausentes.\n\n\n5. Discusión\nInterpreta resultados, relaciona con objetivos y literatura, propone mejoras futuras.\nAborda puntos principales, pero falta profundidad o conexión con literatura previa.\nSuperficial, no interpreta correctamente resultados ni plantea ideas futuras.\nAusente o irrelevante.\n\n\n6. Respuesta a Preguntas\nResponde con claridad, precisión y seguridad. Demuestra dominio y análisis crítico del tema.\nResponde adecuadamente, pero muestra inseguridad en algunos aspectos.\nResponde vagamente, con dificultades para argumentar.\nRespuestas incorrectas, confusas o incapacidad para responder."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Preparar una Presentación | 5 PASOS para una CONFERENCIA EXITOSA por Sebastián Lora.\n¿Cómo estructurar una presentación? por Espacio Ñ de la Universidad del Norte\n\n\n\n\n\nCómo Hacer una Buena Presentación de Diapositivas (Tips) por Javier Muñiz.\nConsejos para una buena presentación en POWER POINT por NiboKids en el cole!.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentación\nNo se siguen ninguno de los consejos de los videos adjuntos para la creación de la presentación\nSe siguen algunos de los consejos de los videos adjuntos para la creación  de la presentación\nSe siguen todos los consejos de los videos adjuntos para la creación  de la presentación\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificación de los ejemplos\nNo se describe el código utilizado para los ejemplos\nSe describe parcialmente el código de los ejemplos\nSe describe a cabalidad el código de los ejemplos\n\n\nCalidad del código\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl código utilizado es completamente desarrollado por los estudiantes a excepción del manejo de datos (NUMPY array y las funciones matemáticas elementales) y la graficación (MATPLOTLIB)"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generación-de-presentaciones",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-apoyo-a-la-generación-de-presentaciones",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Preparar una Presentación | 5 PASOS para una CONFERENCIA EXITOSA por Sebastián Lora.\n¿Cómo estructurar una presentación? por Espacio Ñ de la Universidad del Norte"
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generación-de-dipostivas",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#videos-para-la-generación-de-dipostivas",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Cómo Hacer una Buena Presentación de Diapositivas (Tips) por Javier Muñiz.\nConsejos para una buena presentación en POWER POINT por NiboKids en el cole!."
  },
  {
    "objectID": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#rúbrica-de-evaluación",
    "href": "rubricas/Rubrica_ProyectoAnalisisNumerico.html#rúbrica-de-evaluación",
    "title": "Rúbrica: Proyecto Final Análsis Numérico",
    "section": "",
    "text": "Indicador\nInferior0%\nMedio50%\nSuperior100%\n\n\n\n\nCalidad de la presentación\nNo se siguen ninguno de los consejos de los videos adjuntos para la creación de la presentación\nSe siguen algunos de los consejos de los videos adjuntos para la creación  de la presentación\nSe siguen todos los consejos de los videos adjuntos para la creación  de la presentación\n\n\nCalidad de los ejemplos\nNo se describen los ejemplos utilizados en el proyecto\nLos ejemplos utilizados se encuentran descritos parcialmente\nLos ejemplos utilizados dentro del proyecto se encuentran descritos a cabalidad.\n\n\nCodificación de los ejemplos\nNo se describe el código utilizado para los ejemplos\nSe describe parcialmente el código de los ejemplos\nSe describe a cabalidad el código de los ejemplos\n\n\nCalidad del código\nSe utiliza al menos un algoritmo no desarrollado por los integrantes del equipo\n\nEl código utilizado es completamente desarrollado por los estudiantes a excepción del manejo de datos (NUMPY array y las funciones matemáticas elementales) y la graficación (MATPLOTLIB)"
  },
  {
    "objectID": "rubricas/Rubrica_Regression.html",
    "href": "rubricas/Rubrica_Regression.html",
    "title": "Rúbrica: Modelos de regresión",
    "section": "",
    "text": "Equipo 1Equipo 2\n\n\nIntegrantes\n\nLaura Bazante\nNicolás Panesso\nNicoll Arcos\n\nDataset: concreto\n\n\nIntegrantes\n\nKatherin Diaz\nHeidy Fernández\nJuan Muñoz\n\nDataset: Rendimiento\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsuficiente0%\nAceptable50%\nSuperior100%\n\n\n\n\nObjetivo análisis exploratorio de datos\nNo hay un objetivo aparente\nExiste un objetivo de análisis exploratorio de datos planteado pero este no se encuentra alineado con el modelo\nEl objetivo del análisis exploratorio de datos planteado se alinea con la construcción del modelo se encuentra bien descrito\n\n\nContexto del Dataset\nNo es posible establecer el ámbito al cual pertenecen los datos utilizados para desarrollar el trabajo\nSe hace una descripción muy básica de las características del dataset\nSe hace una descripción detallada de las características y las variables que componen el dataset\n\n\nJustificación\nNo existe una justificación aparente\nExiste justificación pero esta se encuentra mal planteda\nLa justificación se encuentra bien planteada\n\n\nPreprocesamiento\nNo se realizó preprocesamiento de los datos.  O no se argumenta de manera clara la razón de los procedimientos realizados\nAl dataset se le aplicaron solo algunas operaciones de preprocesamiento y los datos no tienen la calidad requerida\nAl dataset se le aplicaron las operaciones de preprocesamiento necesarias para mejorar su calidad y poder construir los modelos de clasificación\n\n\nConexión entre el EDA y el modelo final\nMás de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nMenos de dos decisiones del modelo inicial fueron tomadas sin tener en cuenta el EDA\nTodas las decisiones para el modelo inicial fueron tomadas a partir del EDA\n\n\nDuración de la presentación\nLa presentación dura menos de 8 minutos o más de 13 minutos\nLa presentación dura menos de 9 minutos o más de 11 minutos\nLa presentación dura 10 minutos\n\n\nMaterial de clase\nNo usa la plantilla RMARKDOWN\n\nUsa la plantilla  RMARKDOWN\n\n\nUso de gráficos\nNo se usa ESTADÍSTICA para explicar todas las decisiones\n\nSe usa ESTADÍSTICA para explicar todas las decisiones\n\n\nJustificación de las decisiones del modelo final\nMás de dos decisiones del modelo final no están justificadas\nMenos de dos decisiones del modelo final no están justificadas\nLas decisiones del modelo final son justificadas.\n\n\nEvaluación del modelo\nNo hace evaluación del modelo\nUsa el índice de determinación para evaluar el modelo\nUsa el índice de determinación para evaluar el modelo y además hace análisis de residuos sobre la salida del modelo\n\n\nModelo de regresión\nNo se construyó el modelo o el grupo no puede explicar de manera clara la razón de los procedimientos realizados\nSolo construyó un modelo o no hay claridad sobre las características del modelo elegido\nIdentificó el modelo de mayor precisión después de realizar varias pruebas, se exponen las características del modelo elegido.  El modelo se presenta de forma gráfica"
  },
  {
    "objectID": "clases/Class_SYSB.html",
    "href": "clases/Class_SYSB.html",
    "title": "Sistemas y Señales Biomédicos",
    "section": "",
    "text": "El estudio del procesamiento de señales es fundamental en la ingeniería biomédica debido a la amplia variedad de aplicaciones que tiene en el análisis, interpretación y mejora de datos biomédicos. A continuación, se presenta una justificación estructurada de su relevancia:\nNaturaleza de las señales biomédicas\nLas señales biomédicas, como las señales electrocardiográficas (ECG), electromiográficas (EMG), electroencefalográficas (EEG), o incluso imágenes médicas (resonancias magnéticas o tomografías), son complejas y están afectadas por ruido y artefactos.\nEl procesamiento de señales permite extraer información útil, filtrar interferencias y maximizar la calidad de los datos obtenidos.\nDiagnóstico y monitoreo\nLas señales biomédicas son esenciales para el diagnóstico de enfermedades y el monitoreo continuo de pacientes. Por ejemplo, el procesamiento de un ECG ayuda a detectar arritmias, mientras que el análisis de un EEG puede identificar epilepsia o trastornos del sueño.\nEn entornos de cuidado intensivo, el procesamiento en tiempo real de señales vitales garantiza decisiones clínicas rápidas y precisas.\nOptimización de dispositivos biomédicos\nEl diseño de dispositivos biomédicos como marcapasos, desfibriladores implantables y prótesis inteligentes requiere algoritmos avanzados de procesamiento de señales para interpretar datos en tiempo real y responder adecuadamente a las necesidades del paciente.\nAvances en tecnología médica\nTecnologías emergentes como el análisis de datos en telemedicina, dispositivos portátiles (wearables) y sistemas de salud móvil (mHealth) dependen del procesamiento de señales para garantizar la precisión y la utilidad de la información presentada.\nIntegración con otras disciplinas\nEl procesamiento de señales se combina con inteligencia artificial y aprendizaje automático para desarrollar modelos predictivos, clasificar patrones patológicos y personalizar tratamientos.\nInvestigación en fisiología y biomecánica\nEl análisis avanzado de señales contribuye a la comprensión profunda de procesos fisiológicos complejos, como la dinámica del corazón, el cerebro o el sistema musculoesquelético.\nEducación y competencias profesionales\nLa formación en procesamiento de señales biomédicas dota a los futuros ingenieros de herramientas matemáticas y computacionales para enfrentar problemas del mundo real, desarrollar soluciones innovadoras y avanzar en el campo de la ingeniería biomédica.\nEl curso está dividido en 5 partes:\n1. Introducción al procesado de señales.\n2. Conceptos de señales contínuas & discretas.\n3. Muestreo.\n4. Extracción de características de una señal.\n5. Filtraje de señales."
  },
  {
    "objectID": "clases/Class_SYSB.html#presentaciones",
    "href": "clases/Class_SYSB.html#presentaciones",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción\nClasificacion de señales\nSeñales Notables 1/2\nSeñales Notables 2/2\nAdquisición y Muestreo\nFiltros Digitales\nContenido Frecuencial\nTransformada Z"
  },
  {
    "objectID": "clases/Class_SYSB.html#datos",
    "href": "clases/Class_SYSB.html#datos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_SYSB.html#códigos",
    "href": "clases/Class_SYSB.html#códigos",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorios",
    "href": "clases/Class_SYSB.html#laboratorios",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLAB01: Código python, estadística, y números complejos.\nLAB02: El electrocardiograma. Fundamentos Teóricos.\nLAB03: Análisis de información base del dataset (Demografía y estadística inicial)\nLAB04: Convolución\nLab05: Modelo estadístico para la clasificación de arritmias"
  },
  {
    "objectID": "clases/Class_SYSB.html#grupos-2025-1",
    "href": "clases/Class_SYSB.html#grupos-2025-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Grupos 2025-1",
    "text": "Grupos 2025-1\n\n\n\n\n\n\n\n\n\nID Estudiante\nNombre\nCorreo Electrónico\nGrupo\n\n\n\n\n 1000098844\nCRISTIAN STIVEN CAPERA CERQUERA\ncristian.capera-c@mail.escuelaing.edu.co\nA\n\n\n 1000044331\nMARIA ALEJANDRA URIBE RODRIGUEZ\nmaria.uribe-r@mail.escuelaing.edu.co\nA\n\n\n 1000098887\nNICOLE JULIANA AYURE MATAMOROS\nnicole.ayure-m@mail.escuelaing.edu.co\nA\n\n\n 1000097259\nJENNIFER SOFIA SANCHEZ RAMOS\njennifer.sanchez-r@mail.escuelaing.edu.co\nB\n\n\n 1000097273\nMARIA JOSE PIÑEROS ACUÑA\nmaria.pineros-a@mail.escuelaing.edu.co\nB\n\n\n 1000097287\nMARÍA JOSÉ HERNÁNDEZ GUERRA\nmaria.hguerra@mail.escuelaing.edu.co\nB\n\n\n 1000099348\nJAIME LEONARDO CALDERÓN BETANCURT\njaime.calderon-b@mail.escuelaing.edu.co\nC\n\n\n 1000098221\nLAURA CAMILA REYES MUÑOZ\nlaura.reyes-m@mail.escuelaing.edu.co\nC\n\n\n 1000045047\nDANIEL FELIPE BRU MENESES\ndaniel.bru@mail.escuelaing.edu.co\nD\n\n\n 1000053815\nKEVIN DANIEL BEJARANO OSORIO\nkevin.bejarano@mail.escuelaing.edu.co\nD\n\n\n 1000046321\nSANTIAGO ACUÑA MONCADA\nsantiago.acuna@mail.escuelaing.edu.co\nD\n\n\n 1000095641\nANA SOFIA GRANADA LEIVA\nana.granada-l@mail.escuelaing.edu.co\nE\n\n\n 1000092619\nLUISA FERNANDA PEREZ SALGADO\nluisa.perez-s@mail.escuelaing.edu.co\nE\n\n\n 1000094974\nMARIA FERNANDA GOMEZ CUBIDES\nmaria.gcubides@mail.escuelaing.edu.co\nF\n\n\n 1000095693\nMARÍA PAULA CORTES AVILA\nmaria.cortes-a@mail.escuelaing.edu.co\nF\n\n\n 1000053831\nLUISA LORETTA VERGARA ROMERO\nluisa.vergara-r@mail.escuelaing.edu.co\nG\n\n\n 1000095027\nPAULA MELISSA MARTINEZ BARRERA\npaula.martinez-b@mail.escuelaing.edu.co\nG\n\n\n 1000095101\nSANTIAGO PATIÑO MEJIA\nsantiago.pmejia@mail.escuelaing.edu.co\nG\n\n\n 1000098222\nJULIANA MAYORGA AVILA\njuliana.mayorga-a@mail.escuelaing.edu.co\nH\n\n\n 1000099556\nMARIANA FRANCO CARO\nmariana.franco-c@mail.escuelaing.edu.co\nH\n\n\n 1000098162\nMARÍA PAULA GÓMEZ NIÑO\nmaria.gomez-n@mail.escuelaing.edu.co\nI"
  },
  {
    "objectID": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_SYSB.html#talleres-examenes-anteriores",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\nTaller1: Introduccion al procesamiento de señales\nTaller2: Sistemas LTI, Convolución, Series de FOURIER\nTaller3: Análisis y diseños de filtros\nPrimer Parcial 2025-1 A\nPrimer Parcial 2025-1 B"
  },
  {
    "objectID": "clases/Class_SYSB.html#clases",
    "href": "clases/Class_SYSB.html#clases",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Clases",
    "text": "Clases\n\nLunes: 10:00am-11:30am. F204.\n\nJueves: 10:00am-11:30am. F206."
  },
  {
    "objectID": "clases/Class_SYSB.html#laboratorio",
    "href": "clases/Class_SYSB.html#laboratorio",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Laboratorio",
    "text": "Laboratorio\n\nMartes: 10:00am-11:30am. I1-308."
  },
  {
    "objectID": "clases/Class_SYSB.html#atención-a-estudiantes",
    "href": "clases/Class_SYSB.html#atención-a-estudiantes",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Atención a estudiantes",
    "text": "Atención a estudiantes\nGrupo 80:\nGrupo 81:"
  },
  {
    "objectID": "clases/Class_APSB.html",
    "href": "clases/Class_APSB.html",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "",
    "text": "Procesamiento en Tiempo Real\nEn entornos biomédicos, muchas aplicaciones requieren procesamiento en tiempo real, como el monitoreo de pacientes críticos, análisis de imágenes médicas (por ejemplo, ultrasonido, radiografías) y dispositivos portátiles. Edge AI permite procesar datos localmente, reduciendo la latencia en comparación con el envío de datos a servidores remotos. Ejemplo: Un dispositivo portátil para monitoreo continuo de ECG puede detectar arritmias en tiempo real sin depender de una conexión a internet.\nMayor Privacidad y Seguridad\nLos datos médicos son altamente sensibles y están protegidos por regulaciones estrictas (como la HIPAA o el GDPR). Edge AI permite que los datos se procesen y almacenen localmente, minimizando el riesgo de violaciones de seguridad o filtraciones. Ejemplo: Un sensor de glucosa implantable que analiza niveles de glucosa sin enviar los datos a la nube asegura mayor privacidad del paciente.\nReducción de Costos Operativos\nEl procesamiento en el borde elimina la necesidad de transmitir grandes volúmenes de datos a servidores en la nube, lo que reduce costos relacionados con la conectividad y el almacenamiento en línea. Ejemplo: Un sistema de detección de caídas para personas mayores puede analizar los datos del acelerómetro directamente en el dispositivo sin enviar grandes volúmenes de datos a la nube.\nAplicaciones en Zonas Remotas\nEn áreas rurales o zonas con conectividad limitada, Edge AI permite el uso de dispositivos médicos avanzados sin depender de conexiones de internet robustas. Ejemplo: Una máquina portátil de ultrasonido que utiliza Edge AI para interpretar imágenes en tiempo real podría usarse en campañas de salud en comunidades remotas.\nEficiencia Energética\nLos modelos de Edge AI están diseñados para operar en dispositivos de bajo consumo energético, lo que es ideal para dispositivos médicos portátiles y sistemas implantables. Ejemplo: Monitores de salud wearables, como relojes inteligentes o biosensores, que analizan parámetros fisiológicos continuamente.\nPersonalización y Adaptación en el Lugar\nLos modelos de Edge AI pueden adaptarse a los datos del usuario en tiempo real, permitiendo personalización sin enviar datos sensibles a servidores externos. Ejemplo: Un dispositivo de rehabilitación motora que analiza el movimiento del paciente y ajusta los ejercicios en tiempo real según su progreso.\nInterdisciplinariedad y Tendencia Futurista\nLa integración de Edge AI con la ingeniería biomédica fomenta una combinación única de hardware, software y conocimiento médico, lo que te posiciona en el centro de las innovaciones tecnológicas en salud.\nEl curso está dividido en 4 partes:\n1. Introducción a inteligencia artificial en el borde (EDGE AI).\n2. Hardware y software para EDGE AI.\n3. El flujo de trabajo de EDGE AI.\n4. Diseño, desarrollo y evaluación de sistemas EDGE AI."
  },
  {
    "objectID": "clases/Class_APSB.html#presentaciones",
    "href": "clases/Class_APSB.html#presentaciones",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Presentaciones",
    "text": "Presentaciones\n\nPresentación del curso\nIntroducción 1/2\nIntroducción 2/2\nLinux\nMetodología de desarrollo\nIntroducción al machine learning\nFlujo de trabajo para proyectos de machine learning"
  },
  {
    "objectID": "clases/Class_APSB.html#datos",
    "href": "clases/Class_APSB.html#datos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Datos",
    "text": "Datos\n\nData Sources"
  },
  {
    "objectID": "clases/Class_APSB.html#códigos",
    "href": "clases/Class_APSB.html#códigos",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Códigos",
    "text": "Códigos"
  },
  {
    "objectID": "clases/Class_APSB.html#rúbrica",
    "href": "clases/Class_APSB.html#rúbrica",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Rúbrica",
    "text": "Rúbrica\n-Planteamiento del problema"
  },
  {
    "objectID": "clases/Class_APSB.html#laboratorios",
    "href": "clases/Class_APSB.html#laboratorios",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Laboratorios",
    "text": "Laboratorios\n\nLaboratorio001: Conociendo LINUX.\nLaboratorio002: Análisis exploratorio de datos"
  },
  {
    "objectID": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "href": "clases/Class_APSB.html#talleres-examenes-anteriores",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Talleres & Examenes Anteriores",
    "text": "Talleres & Examenes Anteriores\n\n“Necesito un documento PDF descargable con la explicación de los algoritmos de machine learning utilizados en ciencias de la vida. El texto debe contener una relación entre las técnicas de análasis exploratorio y el algoritmo de machine learning, fundamentos teóricos del algoritmo, códigos python para utilizar. Los algoritmos deben ser: KNN, árboles de decisión, máquinas de soporte vectorial, bosques aleatorios y gradient boosting machines. Debes verificar la información para evitar alucinaciones.”\nDocumento 1: machine learning. CHATGPT 4o\nDocumento 2: machine learning. GEMINI 2.0 flash\nJ. D. Kelleher, B. Mac Namee, y A. D’Arcy, Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies, 2nd ed. Cambridge: The MIT press, 2020."
  },
  {
    "objectID": "clases/Class_APSB.html#clases",
    "href": "clases/Class_APSB.html#clases",
    "title": "Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde",
    "section": "Clases",
    "text": "Clases\nMartes 8:30am - 10:00am F-109. Jueves 8:30am - 10:00am F-201."
  },
  {
    "objectID": "proyectos/ComparisonML.html",
    "href": "proyectos/ComparisonML.html",
    "title": "Comparing different Machine Learning architectures for classifying medical terms in Colombian sign language",
    "section": "",
    "text": "Presentación STSIVA2025"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "Se utilizó el sensor XSens MTw Awinda [1].\nSe adquirieron datos de aceleración, giroscopio y magnetómetro.\nSe uso \\(F_s = 100Hz\\).\nLos sensores capturan señales que representan el movimiento en su propio sistema de coordenadas [2].\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatos adquiridos…\n\n\n\n\nProtocolo de adquisición modificado [3]\nActividad con ojos abiertos (eye open), ojos cerrados (eye close) y tarea dual (dual task)\n\n\n\n\n\n\n\n\n\n\n\n\nPrimer paso\n\n\n\n\nEliminación de datos no útiles.\nDatos eliminados: datos na, columnas PacketCounter y SampleTimeFine\nCreación de una columna Time en segundos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSegundo paso\n\n\n\n\nConvertir ejes locales a globales. Utilizando el cuaternio generado por el XSens.\nCalcular la magnitud del vector de aceleración global y la agregar al DataFrame.\nCalcular la magnitud del vector de velocidad angular global y la agregar al DataFrame.\nSeleccionar 20 segundos de información (eliminar información inicial y final)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlgoritmo de Fusión\n\n\n\n\nSe utiliza el algoritmo de la fusión de los datos de aceleración y giroscopio por defecto de XSens.\nSe utiliza el algoritmo de eliminación de distorsión magnética desarrollado por XSens\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMétricas\n\n\n\n\nRaíz cuadrática media (RMS) de la magnitud de la aceleración o de la velocidad angular [4].\nAdaptación de la longitud de la trayectoria [3].\nArea de de la elipse de oscilación (ellipse sway area), típicamente cubriendo el 95% de los datos presentados.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRomberg Ratio\n\n\n\n\nEl test de Romberg es una prueba que se usa frecuentemente en la posturografía.\nSe basa en la evaluación del control postural bajo dos condiciones distintas: con visión (ojos abiertos) y sin visión (ojos cerrados).\nEl índice o ratio de Romberg se calcula dividiendo el balanceo postural (postural sway) en la condición de ojos cerrados entre el balanceo postural en la condición de ojos abiertos.\nTambién se puede calcular dividiendo el balanceo postural (postural sway) en la condición de doble tarea entre el balanceo postural en la condición de ojos abiertos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEyes Open\nEyes Close\nDual Task\nRatio Romberg 1\nRatio Romberg 2\n\n\n\n\nRMS ACC X\n2,83E-03\n2,91E-03\n2,89E-03\n1,03\n1,02\n\n\nRMS ACC Y\n6,82E-04\n6,80E-03\n6,79E-03\n9,98\n9,96\n\n\nRMS ACC Z\n5,74E-04\n5,08E-04\n4,98E-04\n0,89\n0,87\n\n\nRMS GYR X\n4,24E-07\n3,52E-06\n4,24E-07\n8,29\n1,00\n\n\nRMS GYR Y\n1,02E-05\n8,27E-06\n1,16E-05\n0,81\n1,14\n\n\nRMS GYR Z\n8,68E-08\n6,18E-07\n8,52E-07\n7,12\n9,82\n\n\nPATH TRAJ\n0,0025\n0,0025\n0,0031\n1,00\n1,24\n\n\nAREA_ELIPSE_95%\n5,61E-11\n8,30E-11\n6,55E-12\n1,48\n0,12\n\n\n\n\n\n\n\n\n(np.float64(2.7508740895910972), np.float64(3.6048069186140856), np.float64(1.434932874624913), np.float64(2.0295845733092643))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] M. Paulich, M. Schepers, N. Rudigkeit, y G. Bellusci, «Xsens MTw Awinda: Miniature Wireless Inertial-Magnetic Motion Tracker for Highly Accurate 3D Kinematic Applications».\n\n\n[2] D. H. Yoon, J.-H. Kim, K. Lee, J.-S. Cho, S.-H. Jang, y S.-U. Lee, «Inertial measurement unit sensor-based gait analysis in adults and older adults: A cross-sectional study», Gait & Posture, vol. 107, pp. 212-217, ene. 2024, doi: 10.1016/j.gaitpost.2023.10.006.\n\n\n[3] J. Zhou et al., «A novel smartphone App-based assessment of standing postural control: Demonstration of reliability and sensitivity to aging and task constraints», en 2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM), Shenzhen, China: IEEE, mar. 2021, pp. 1-6. doi: 10.1109/HEALTHCOM49281.2021.9398972.\n\n\n[4] M. Calcagni, P. Kosa, y B. Bielekova, «Smartphone postural sway and pronator drift tests as measures of neurological disability», BMC Neurol, vol. 25, n.º 1, p. 50, feb. 2025, doi: 10.1186/s12883-025-04038-2."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "Se utilizó el sensor XSens MTw Awinda [1].\nSe adquirieron datos de aceleración, giroscopio y magnetómetro.\nSe uso \\(F_s = 100Hz\\).\nLos sensores capturan señales que representan el movimiento en su propio sistema de coordenadas [2]."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#adquisición-de-datos-1",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "Datos adquiridos…\n\n\n\n\nProtocolo de adquisición modificado [3]\nActividad con ojos abiertos (eye open), ojos cerrados (eye close) y tarea dual (dual task)"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "Primer paso\n\n\n\n\nEliminación de datos no útiles.\nDatos eliminados: datos na, columnas PacketCounter y SampleTimeFine\nCreación de una columna Time en segundos."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#preprocesamiento-1",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "Segundo paso\n\n\n\n\nConvertir ejes locales a globales. Utilizando el cuaternio generado por el XSens.\nCalcular la magnitud del vector de aceleración global y la agregar al DataFrame.\nCalcular la magnitud del vector de velocidad angular global y la agregar al DataFrame.\nSeleccionar 20 segundos de información (eliminar información inicial y final)"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#fusión-sensorial",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#fusión-sensorial",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "Algoritmo de Fusión\n\n\n\n\nSe utiliza el algoritmo de la fusión de los datos de aceleración y giroscopio por defecto de XSens.\nSe utiliza el algoritmo de eliminación de distorsión magnética desarrollado por XSens"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "Métricas\n\n\n\n\nRaíz cuadrática media (RMS) de la magnitud de la aceleración o de la velocidad angular [4].\nAdaptación de la longitud de la trayectoria [3].\nArea de de la elipse de oscilación (ellipse sway area), típicamente cubriendo el 95% de los datos presentados."
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-1",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-1",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "Romberg Ratio\n\n\n\n\nEl test de Romberg es una prueba que se usa frecuentemente en la posturografía.\nSe basa en la evaluación del control postural bajo dos condiciones distintas: con visión (ojos abiertos) y sin visión (ojos cerrados).\nEl índice o ratio de Romberg se calcula dividiendo el balanceo postural (postural sway) en la condición de ojos cerrados entre el balanceo postural en la condición de ojos abiertos.\nTambién se puede calcular dividiendo el balanceo postural (postural sway) en la condición de doble tarea entre el balanceo postural en la condición de ojos abiertos"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-2",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-2",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "Eyes Open\nEyes Close\nDual Task\nRatio Romberg 1\nRatio Romberg 2\n\n\n\n\nRMS ACC X\n2,83E-03\n2,91E-03\n2,89E-03\n1,03\n1,02\n\n\nRMS ACC Y\n6,82E-04\n6,80E-03\n6,79E-03\n9,98\n9,96\n\n\nRMS ACC Z\n5,74E-04\n5,08E-04\n4,98E-04\n0,89\n0,87\n\n\nRMS GYR X\n4,24E-07\n3,52E-06\n4,24E-07\n8,29\n1,00\n\n\nRMS GYR Y\n1,02E-05\n8,27E-06\n1,16E-05\n0,81\n1,14\n\n\nRMS GYR Z\n8,68E-08\n6,18E-07\n8,52E-07\n7,12\n9,82\n\n\nPATH TRAJ\n0,0025\n0,0025\n0,0031\n1,00\n1,24\n\n\nAREA_ELIPSE_95%\n5,61E-11\n8,30E-11\n6,55E-12\n1,48\n0,12"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-propuesta",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#extracción-de-características-propuesta",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "(np.float64(2.7508740895910972), np.float64(3.6048069186140856), np.float64(1.434932874624913), np.float64(2.0295845733092643))"
  },
  {
    "objectID": "proyectos/Sabana/InertialBalanceAssessment.html#referencias",
    "href": "proyectos/Sabana/InertialBalanceAssessment.html#referencias",
    "title": "Evaluación del equilibrio usando sensores inerciales",
    "section": "",
    "text": "[1] M. Paulich, M. Schepers, N. Rudigkeit, y G. Bellusci, «Xsens MTw Awinda: Miniature Wireless Inertial-Magnetic Motion Tracker for Highly Accurate 3D Kinematic Applications».\n\n\n[2] D. H. Yoon, J.-H. Kim, K. Lee, J.-S. Cho, S.-H. Jang, y S.-U. Lee, «Inertial measurement unit sensor-based gait analysis in adults and older adults: A cross-sectional study», Gait & Posture, vol. 107, pp. 212-217, ene. 2024, doi: 10.1016/j.gaitpost.2023.10.006.\n\n\n[3] J. Zhou et al., «A novel smartphone App-based assessment of standing postural control: Demonstration of reliability and sensitivity to aging and task constraints», en 2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM), Shenzhen, China: IEEE, mar. 2021, pp. 1-6. doi: 10.1109/HEALTHCOM49281.2021.9398972.\n\n\n[4] M. Calcagni, P. Kosa, y B. Bielekova, «Smartphone postural sway and pronator drift tests as measures of neurological disability», BMC Neurol, vol. 25, n.º 1, p. 50, feb. 2025, doi: 10.1186/s12883-025-04038-2."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de Talleres Ingeniería Biomédica en la Escuela Colombiana de Ingeniería\n\n\n\n11 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Sistemas y Señales Biomédicoss en la Escuela Colombiana de Ingeniería\n\n\n\n9 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde en la Escuela Colombiana de Ingeniería\n\n\n\n8 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n8 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n8 sept 2025\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#clases",
    "href": "index.html#clases",
    "title": "PECR Knowledge Hub",
    "section": "",
    "text": "Sitio de Talleres Ingeniería Biomédica en la Escuela Colombiana de Ingeniería\n\n\n\n11 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Sistemas y Señales Biomédicoss en la Escuela Colombiana de Ingeniería\n\n\n\n9 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Adquisición y Procesamiento de Señales Biomédicas en Tecnologías de Borde en la Escuela Colombiana de Ingeniería\n\n\n\n8 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n8 sept 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSitio de la asignatura Procesado de Señales e Imágenes Médicas en la Escuela Colombiana de Ingeniería\n\n\n\n8 sept 2025\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#tutoriales",
    "href": "index.html#tutoriales",
    "title": "PECR Knowledge Hub",
    "section": "Tutoriales",
    "text": "Tutoriales\n\n\n\n\n\n\n\n\n\n\nInstalación de Entorno de trabajo. Ubuntu WSL2\n\n\nTutorial\n\n\n\n8 sept 2025\n\n\n\n\n\n\n\n\n\n\n\nCaso práctico: Análisis de señales EMG en rendimiento deportivo con ML/DL\n\n\nASIM_M\n\n\n\n23 jul 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython programming\n\n\nA small tutorial in python in slides\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\nMicrobit – El minicomputador\n\n\nTutorial: Electrónica Básica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\nMicrobit – El minicomputador\n\n\nTutorial: Electrónica Básica\n\n\n\n12 ago 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial de Python\n\n\nBreve Tutorial de Python\n\n\n\n6 feb 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputación de seno y coseno usando expansión de Taylor\n\n\nUn ejemplo de clase del cálculo de una serie de Taylor sin uso de librerías especiales de Python – En construcción –\n\n\n\n6 feb 2023\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "index.html#proyectos",
    "href": "index.html#proyectos",
    "title": "PECR Knowledge Hub",
    "section": "Proyectos",
    "text": "Proyectos\n\n\n\n\n\n\n\n\n\n\nPredictive modeling for seizure detection in pharmacoresistant epilepsy: a machine learning approach\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparing different Machine Learning architectures for classifying medical terms in Colombian sign language\n\n\nMachine Learning\n\n\n\nInvalid Date\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html",
    "href": "recursos/documentos/SYSB/cuantizacion.html",
    "title": "Quantization",
    "section": "",
    "text": "Quantization maps a continuous-amplitude signal to a finite set of discrete levels so that it can be represented by digits. After anti-alias filtering and sampling, an analog-to-digital converter (ADC) applies quantization. This process introduces an error that acts like noise under standard conditions; understanding its magnitude is essential to sizing bit depth, gain, and dynamic range in biomedical systems (ECG, EEG, EMG, PPG).\n\n\n\nLet the ADC input range be \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\) with \\(b\\) bits and \\(L=2^b\\) levels. The step size (LSB) is\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nTwo common realizations:\n\nMid-tread (rounding): \\(Q(x)=\\Delta,\\mathrm{round}\\left(\\frac{x}{\\Delta}\\right)\\) for \\(x\\in(V\\_{\\min},V\\_{\\max})\\).\nMid-rise (truncate with half-step offset): \\(Q(x)=\\Delta!\\left(\\left\\lfloor\\frac{x}{\\Delta}\\right\\rfloor+\\tfrac12\\right)\\).\n\nOutside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\), overload/clipping occurs: \\(\\tilde{x}=Q(x)=V\\_{\\max}\\) if \\(x&gt;V\\_{\\max}\\) and \\(\\tilde{x}=V\\_{\\min}\\) if \\(x\\&lt;V\\_{\\min}\\).\nCodebook and decision thresholds: Decision thresholds lie at \\(k\\Delta\\) and reconstruction levels at either \\(k\\Delta\\) (mid-tread) or \\((k+\\tfrac12)\\Delta\\) (mid-rise).\n\n\n\nDefine the quantization error \\(e=x-Q(x)\\). Under the high-resolution assumptions (signal varies slowly relative to \\(\\Delta\\), input well distributed within the range, and no overload), the error is modeled as white, signal-independent, and uniformly distributed on \\(\\left[-\\frac{\\Delta}{2},\\frac{\\Delta}{2}\\right]\\):\n\nMean: \\(\\mathbb{E}\\left[e\\right]=0\\).\nVariance (power): \\(\\sigma\\_e^2=\\dfrac{\\Delta^2}{12}\\).\nRMS: \\(\\sigma\\_e=\\dfrac{\\Delta}{\\sqrt{12}}\\).\n\nFor a full-scale sinusoid, the theoretical SNR is\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nIf the signal uses only a fraction \\(\\rho\\) (\\(0&lt;\\rho\\le 1\\)) of full scale (FS) in RMS, then\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]\nEffective Number of Bits (ENOB) from a measured in-band SNR:\n\\[\n\\mathrm{ENOB} \\approx \\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]\n\n\n\nFront-end analog gain \\(G\\) maps a biomedical signal \\(x\\_{\\text{in}}\\) to the ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\). The input-referred LSB is\n\\[\n\\Delta_{\\text{in}}=\\frac{\\Delta}{G}.\n\\]\nChoose \\(G\\) to:\n\navoid overload for rare peaks, and 2) maximize FS utilization to improve SNR. Poor gain wastes bits (small \\(\\rho\\)) or clips clinically relevant transients (e.g., ECG pacer spikes).\n\n\n\n\nSuppose a resting ECG has peak amplitudes around \\(\\pm 5,\\text{mV}\\) at the electrodes. We design the analog front end so that \\(\\pm 5,\\text{mV}\\) maps to \\(\\pm 1,\\text{V}\\) at the ADC, i.e., \\(G=200\\). Use a \\(b=12\\)-bit ADC over \\(\\left[-1,\\text{V},,1,\\text{V}\\right]\\):\n\nADC LSB: \\(\\Delta = \\dfrac{2,\\text{V}}{2^{12}} \\approx 0.488,\\text{mV}\\) (at the ADC input).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\dfrac{0.488,\\text{mV}}{200}\\approx 2.44,\\mu\\text{V}\\).\nInput-referred quantization-noise RMS: \\(\\dfrac{\\Delta\\_{\\text{in}}}{\\sqrt{12}}\\approx 0.704,\\mu\\text{V}\\_{\\mathrm{RMS}}\\).\n\nIf the ECG uses \\(\\rho=0.5\\) of full scale (typical margin against clipping), the quantization-limited SNR is approximately\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\times 12 + 1.76 + 20\\log_{10}(0.5) \\approx 74.0 - 6.0 \\approx 68\\,\\text{dB}.\n\\]\nThis is usually below amplifier and electrode noise constraints, so 12 bits are adequate for diagnostic ECG in this setting. If the chain is quieter (e.g., invasive potentials), higher bit depth or larger \\(G\\) may be justified.\n\n\n\nWhen the amplitude distribution is strongly non-uniform, companding transforms \\(x\\) before uniform quantization to allocate more levels where the signal spends more time. Classical laws:\n\n\\(\\mu\\)-law: \\(y=\\mathrm{sgn}(x),\\dfrac{\\ln(1+\\mu |x|/X\\_{\\max})}{\\ln(1+\\mu)}\\), \\(\\mu\\approx 255\\) (telephony).\n\\(A\\)-law: piecewise logarithmic with parameter \\(A\\) (Europe).\n\nCompanding is common in speech/audio telemetry; in biomedicine it is less standard for primary acquisition, but can help in low-bit-rate wireless monitoring where dynamic range is wide (e.g., PPG with motion).\n\n\n\nAdding small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization decorrelates the error from the signal, eliminating patterning and bias at low amplitudes. This linearizes averages at the cost of a small SNR penalty. Dither can be beneficial for low-level EEG/EMG features and precise baseline estimates.\n\n\n\n\nChoose \\(b\\) so that \\(\\mathrm{SNR}\\_{\\mathrm{dB}}\\) exceeds clinical SNR needs by margin (10–20 dB).\nSet \\(G\\) so typical peaks use \\(50\\)–\\(80%\\) FS; verify pacer spikes and motion spikes do not clip.\nBudget noise: electrode + amplifier + ADC quantization; the largest non-white source often dominates.\nValidate with a calibrated source (sinusoidal and biomedical-like waveforms) and measure in-band SNR/ENOB.\n\n\n\n\n\n\n# Synthetic ECG, uniform quantization at multiple bit depths, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# --- 1) Build a simple ECG template (P-QRS-T) using Gaussians ---\nfs = 360.0                      # sampling rate [Hz]\nT = 5.0                         # duration [s]\nt = np.arange(0, T, 1/fs)\n\nhr = 60.0                       # heart rate [bpm]\nRR = 60.0/hr                    # seconds per beat\n\n# Gaussian helper\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\n# One-beat template (times in seconds relative to beat onset)\ndef ecg_template(t):\n    # amplitudes in mV, widths in s (very simplified)\n    P  = g(t, 0.20, 0.045,  0.10)\n    Q  = g(t, 0.36, 0.010, -0.25)\n    R  = g(t, 0.40, 0.012,  1.00)\n    S  = g(t, 0.44, 0.016, -0.35)\n    T  = g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + T\n\n# Tile the template every RR seconds\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    tau = t - k*RR\n    ecg_mV += ecg_template(tau)\n\n# Optional baseline wander + small EMG-like noise (for realism)\nwander = 0.05*np.sin(2*np.pi*0.3*t)        # 0.05 mV @ 0.3 Hz\nnoise  = 0.02*np.random.randn(len(t))      # 0.02 mV RMS\necg_mV = ecg_mV + wander + noise\n\n# --- 2) Analog front-end gain and ADC setup ---\nG = 200.0                     # gain: mV (input) -&gt; V (ADC input)\nVfs = 1.0                     # full-scale = +/-1 V\nVmin, Vmax = -Vfs, Vfs\n\nx_adc = (ecg_mV/1000.0)*G     # convert mV to V and apply gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    # Saturate to avoid numeric overflow\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)  # ensure within codebook range\n    return y, Delta\n\ndef snr_db(x, y):\n    # SNR over the un-clipped region; compute RMS of signal and error\n    e = x - y\n    # Remove DC for SNR assessment\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\n# --- 3) Quantize at different bit depths ---\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\n# Print a small summary (ADC-domain). Input-referred values via division by G.\nprint(\"Summary (ADC domain):\")\nfor b in bits_list:\n    Delta = results[b][\"Delta\"]\n    snr = results[b][\"snr_db\"]\n    print(f\"{b:2d}-bit -&gt; LSB Δ = {Delta*1e3:.3f} mV, Theoretical/Measured SNR ≈ {snr:5.1f} dB\")\n\n# Input-referred LSB and noise RMS for the 12-bit case\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Δ_in = {Delta_in*1e6:.3f} µV, σ_q ≈ {sigma_q_in*1e6:.3f} µV RMS\")\n\n# --- 4) Plot: original vs quantized (choose 10-bit for visibility) ---\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)  # show about one beat\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- 5) Plot: quantization error histogram (8-bit to exaggerate steps) ---\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()\n\nSummary (ADC domain):\n 8-bit -&gt; LSB Δ = 7.812 mV, Theoretical/Measured SNR ≈  24.1 dB\n10-bit -&gt; LSB Δ = 1.953 mV, Theoretical/Measured SNR ≈  36.0 dB\n12-bit -&gt; LSB Δ = 0.488 mV, Theoretical/Measured SNR ≈  48.1 dB\n\nInput-referred (12-bit): Δ_in = 2.441 µV, σ_q ≈ 0.705 µV RMS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nThe summary reports the measured SNR from the synthetic ECG after quantization for 8/10/12 bits; values will be below the \\(6.02b+1.76\\) bound because the signal does not use full scale constantly and includes non-sinusoidal content.\nThe input-referred \\(\\Delta\\_{\\text{in}}\\) and \\(\\sigma\\_q\\) for 12 bits match the analytical estimates in Section 5 (a few \\(\\mu\\text{V}\\)), consistent with common ECG design targets.\nThe error histogram approaches a uniform distribution as assumptions hold; deviations indicate correlation (e.g., at low amplitudes or with deterministic waveforms)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#purpose-and-big-picture",
    "href": "recursos/documentos/SYSB/cuantizacion.html#purpose-and-big-picture",
    "title": "Quantization",
    "section": "",
    "text": "Quantization maps a continuous-amplitude signal to a finite set of discrete levels so that it can be represented by digits. After anti-alias filtering and sampling, an analog-to-digital converter (ADC) applies quantization. This process introduces an error that acts like noise under standard conditions; understanding its magnitude is essential to sizing bit depth, gain, and dynamic range in biomedical systems (ECG, EEG, EMG, PPG)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#uniform-quantizer-model",
    "href": "recursos/documentos/SYSB/cuantizacion.html#uniform-quantizer-model",
    "title": "Quantization",
    "section": "",
    "text": "Let the ADC input range be \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\) with \\(b\\) bits and \\(L=2^b\\) levels. The step size (LSB) is\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nTwo common realizations:\n\nMid-tread (rounding): \\(Q(x)=\\Delta,\\mathrm{round}\\left(\\frac{x}{\\Delta}\\right)\\) for \\(x\\in(V\\_{\\min},V\\_{\\max})\\).\nMid-rise (truncate with half-step offset): \\(Q(x)=\\Delta!\\left(\\left\\lfloor\\frac{x}{\\Delta}\\right\\rfloor+\\tfrac12\\right)\\).\n\nOutside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\), overload/clipping occurs: \\(\\tilde{x}=Q(x)=V\\_{\\max}\\) if \\(x&gt;V\\_{\\max}\\) and \\(\\tilde{x}=V\\_{\\min}\\) if \\(x\\&lt;V\\_{\\min}\\).\nCodebook and decision thresholds: Decision thresholds lie at \\(k\\Delta\\) and reconstruction levels at either \\(k\\Delta\\) (mid-tread) or \\((k+\\tfrac12)\\Delta\\) (mid-rise)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#quantization-error-and-its-statistics",
    "href": "recursos/documentos/SYSB/cuantizacion.html#quantization-error-and-its-statistics",
    "title": "Quantization",
    "section": "",
    "text": "Define the quantization error \\(e=x-Q(x)\\). Under the high-resolution assumptions (signal varies slowly relative to \\(\\Delta\\), input well distributed within the range, and no overload), the error is modeled as white, signal-independent, and uniformly distributed on \\(\\left[-\\frac{\\Delta}{2},\\frac{\\Delta}{2}\\right]\\):\n\nMean: \\(\\mathbb{E}\\left[e\\right]=0\\).\nVariance (power): \\(\\sigma\\_e^2=\\dfrac{\\Delta^2}{12}\\).\nRMS: \\(\\sigma\\_e=\\dfrac{\\Delta}{\\sqrt{12}}\\).\n\nFor a full-scale sinusoid, the theoretical SNR is\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nIf the signal uses only a fraction \\(\\rho\\) (\\(0&lt;\\rho\\le 1\\)) of full scale (FS) in RMS, then\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]\nEffective Number of Bits (ENOB) from a measured in-band SNR:\n\\[\n\\mathrm{ENOB} \\approx \\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]"
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#input-range-gain-and-clipping",
    "href": "recursos/documentos/SYSB/cuantizacion.html#input-range-gain-and-clipping",
    "title": "Quantization",
    "section": "",
    "text": "Front-end analog gain \\(G\\) maps a biomedical signal \\(x\\_{\\text{in}}\\) to the ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\). The input-referred LSB is\n\\[\n\\Delta_{\\text{in}}=\\frac{\\Delta}{G}.\n\\]\nChoose \\(G\\) to:\n\navoid overload for rare peaks, and 2) maximize FS utilization to improve SNR. Poor gain wastes bits (small \\(\\rho\\)) or clips clinically relevant transients (e.g., ECG pacer spikes)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#biomedical-example-ecg-acquisition",
    "href": "recursos/documentos/SYSB/cuantizacion.html#biomedical-example-ecg-acquisition",
    "title": "Quantization",
    "section": "",
    "text": "Suppose a resting ECG has peak amplitudes around \\(\\pm 5,\\text{mV}\\) at the electrodes. We design the analog front end so that \\(\\pm 5,\\text{mV}\\) maps to \\(\\pm 1,\\text{V}\\) at the ADC, i.e., \\(G=200\\). Use a \\(b=12\\)-bit ADC over \\(\\left[-1,\\text{V},,1,\\text{V}\\right]\\):\n\nADC LSB: \\(\\Delta = \\dfrac{2,\\text{V}}{2^{12}} \\approx 0.488,\\text{mV}\\) (at the ADC input).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\dfrac{0.488,\\text{mV}}{200}\\approx 2.44,\\mu\\text{V}\\).\nInput-referred quantization-noise RMS: \\(\\dfrac{\\Delta\\_{\\text{in}}}{\\sqrt{12}}\\approx 0.704,\\mu\\text{V}\\_{\\mathrm{RMS}}\\).\n\nIf the ECG uses \\(\\rho=0.5\\) of full scale (typical margin against clipping), the quantization-limited SNR is approximately\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}} \\approx 6.02\\times 12 + 1.76 + 20\\log_{10}(0.5) \\approx 74.0 - 6.0 \\approx 68\\,\\text{dB}.\n\\]\nThis is usually below amplifier and electrode noise constraints, so 12 bits are adequate for diagnostic ECG in this setting. If the chain is quieter (e.g., invasive potentials), higher bit depth or larger \\(G\\) may be justified."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#non-uniform-quantization-and-companding-brief",
    "href": "recursos/documentos/SYSB/cuantizacion.html#non-uniform-quantization-and-companding-brief",
    "title": "Quantization",
    "section": "",
    "text": "When the amplitude distribution is strongly non-uniform, companding transforms \\(x\\) before uniform quantization to allocate more levels where the signal spends more time. Classical laws:\n\n\\(\\mu\\)-law: \\(y=\\mathrm{sgn}(x),\\dfrac{\\ln(1+\\mu |x|/X\\_{\\max})}{\\ln(1+\\mu)}\\), \\(\\mu\\approx 255\\) (telephony).\n\\(A\\)-law: piecewise logarithmic with parameter \\(A\\) (Europe).\n\nCompanding is common in speech/audio telemetry; in biomedicine it is less standard for primary acquisition, but can help in low-bit-rate wireless monitoring where dynamic range is wide (e.g., PPG with motion)."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#dither-optional-but-practical",
    "href": "recursos/documentos/SYSB/cuantizacion.html#dither-optional-but-practical",
    "title": "Quantization",
    "section": "",
    "text": "Adding small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization decorrelates the error from the signal, eliminating patterning and bias at low amplitudes. This linearizes averages at the cost of a small SNR penalty. Dither can be beneficial for low-level EEG/EMG features and precise baseline estimates."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#practical-checklist",
    "href": "recursos/documentos/SYSB/cuantizacion.html#practical-checklist",
    "title": "Quantization",
    "section": "",
    "text": "Choose \\(b\\) so that \\(\\mathrm{SNR}\\_{\\mathrm{dB}}\\) exceeds clinical SNR needs by margin (10–20 dB).\nSet \\(G\\) so typical peaks use \\(50\\)–\\(80%\\) FS; verify pacer spikes and motion spikes do not clip.\nBudget noise: electrode + amplifier + ADC quantization; the largest non-white source often dominates.\nValidate with a calibrated source (sinusoidal and biomedical-like waveforms) and measure in-band SNR/ENOB."
  },
  {
    "objectID": "recursos/documentos/SYSB/cuantizacion.html#python-demonstration-ecg-quantization-snr-and-error-statistics",
    "href": "recursos/documentos/SYSB/cuantizacion.html#python-demonstration-ecg-quantization-snr-and-error-statistics",
    "title": "Quantization",
    "section": "",
    "text": "# Synthetic ECG, uniform quantization at multiple bit depths, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n# --- 1) Build a simple ECG template (P-QRS-T) using Gaussians ---\nfs = 360.0                      # sampling rate [Hz]\nT = 5.0                         # duration [s]\nt = np.arange(0, T, 1/fs)\n\nhr = 60.0                       # heart rate [bpm]\nRR = 60.0/hr                    # seconds per beat\n\n# Gaussian helper\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\n# One-beat template (times in seconds relative to beat onset)\ndef ecg_template(t):\n    # amplitudes in mV, widths in s (very simplified)\n    P  = g(t, 0.20, 0.045,  0.10)\n    Q  = g(t, 0.36, 0.010, -0.25)\n    R  = g(t, 0.40, 0.012,  1.00)\n    S  = g(t, 0.44, 0.016, -0.35)\n    T  = g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + T\n\n# Tile the template every RR seconds\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    tau = t - k*RR\n    ecg_mV += ecg_template(tau)\n\n# Optional baseline wander + small EMG-like noise (for realism)\nwander = 0.05*np.sin(2*np.pi*0.3*t)        # 0.05 mV @ 0.3 Hz\nnoise  = 0.02*np.random.randn(len(t))      # 0.02 mV RMS\necg_mV = ecg_mV + wander + noise\n\n# --- 2) Analog front-end gain and ADC setup ---\nG = 200.0                     # gain: mV (input) -&gt; V (ADC input)\nVfs = 1.0                     # full-scale = +/-1 V\nVmin, Vmax = -Vfs, Vfs\n\nx_adc = (ecg_mV/1000.0)*G     # convert mV to V and apply gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    # Saturate to avoid numeric overflow\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)  # ensure within codebook range\n    return y, Delta\n\ndef snr_db(x, y):\n    # SNR over the un-clipped region; compute RMS of signal and error\n    e = x - y\n    # Remove DC for SNR assessment\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\n# --- 3) Quantize at different bit depths ---\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\n# Print a small summary (ADC-domain). Input-referred values via division by G.\nprint(\"Summary (ADC domain):\")\nfor b in bits_list:\n    Delta = results[b][\"Delta\"]\n    snr = results[b][\"snr_db\"]\n    print(f\"{b:2d}-bit -&gt; LSB Δ = {Delta*1e3:.3f} mV, Theoretical/Measured SNR ≈ {snr:5.1f} dB\")\n\n# Input-referred LSB and noise RMS for the 12-bit case\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Δ_in = {Delta_in*1e6:.3f} µV, σ_q ≈ {sigma_q_in*1e6:.3f} µV RMS\")\n\n# --- 4) Plot: original vs quantized (choose 10-bit for visibility) ---\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)  # show about one beat\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- 5) Plot: quantization error histogram (8-bit to exaggerate steps) ---\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()\n\nSummary (ADC domain):\n 8-bit -&gt; LSB Δ = 7.812 mV, Theoretical/Measured SNR ≈  24.1 dB\n10-bit -&gt; LSB Δ = 1.953 mV, Theoretical/Measured SNR ≈  36.0 dB\n12-bit -&gt; LSB Δ = 0.488 mV, Theoretical/Measured SNR ≈  48.1 dB\n\nInput-referred (12-bit): Δ_in = 2.441 µV, σ_q ≈ 0.705 µV RMS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\nThe summary reports the measured SNR from the synthetic ECG after quantization for 8/10/12 bits; values will be below the \\(6.02b+1.76\\) bound because the signal does not use full scale constantly and includes non-sinusoidal content.\nThe input-referred \\(\\Delta\\_{\\text{in}}\\) and \\(\\sigma\\_q\\) for 12 bits match the analytical estimates in Section 5 (a few \\(\\mu\\text{V}\\)), consistent with common ECG design targets.\nThe error histogram approaches a uniform distribution as assumptions hold; deviations indicate correlation (e.g., at low amplitudes or with deterministic waveforms)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition",
    "text": "Introduction to data adquisition\n\n\n\nThere are two main roles in data: capture the information and encode the data in a form tha machine can process.\nData adquisition has three stages:\n\nTransduction\nSignal conditioning\nAnalog-to-digital conversion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---transduction",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Transduction",
    "text": "Introduction to data adquisition - Transduction\n\n\n\nTransduction is the conversion from one form of energy to another.\nThe only energy suitable for computer processing is the electrical\nTherefore signals need to be converted to analog voltages whose waveforms are ideally the same as those of the original signals.\nExist two components a captured signal: one component carries the information (signal), the other one is a probabilistic distorsion of the information(noise)"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nNoise refers to any unwanted or random variations in a signal that interfere with the desired information. It is an unpredictable disturbance that can distort or obscure the actual data, making it harder to interpret or analyze.\n\n\n\n\nTypes of noise\n\nThermal Noise (Random Noise)\nElectromagnetic Interference (EMI)\nMotion Artifacts\nPhysiological Noise\nQuantization Noise"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\n\nModelling the noise\n\nAdditive White Gaussian Noise (AWGN): Modeled as a random process with a normal distribution.\nBand-limited Noise: Affects only specific frequency ranges and can be removed with filters.\nAdditive Noise: Adds directly to the original signal.\nMultiplicative Noise: Multiplies the original signal."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---noise-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - Noise",
    "text": "Introduction to data adquisition - Noise\n\nGraphsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros de la señal\nduration = 2  # Duración en segundos\nfs = 1000  # Frecuencia de muestreo en Hz\nt = np.linspace(0, duration, duration * fs, endpoint=False)  # Vector de tiempo\n\n# Señal senoidal de 10 Hz\nfreq = 10\nsine_wave = np.sin(2 * np.pi * freq * t)\n\n# Señal de ruido aleatorio con distribución normal\nnoise_normal = np.random.normal(0, 1, len(t))\n\n# Señal con ruido aleatorio de 2 a 5 Hz\nlow_freq_noise = np.sin(2 * np.pi * np.random.uniform(2, 5) * t)\nsignal_with_low_freq_noise = sine_wave + low_freq_noise\n\n# Señal con ruido aleatorio uniforme sumado\nuniform_noise = np.random.uniform(-0.5, 0.5, len(t))\nsignal_with_uniform_noise = sine_wave + uniform_noise\n\n# Señal con ruido aleatorio uniforme multiplicado\nmultiplicative_noise = np.random.uniform(0.5, 1.5, len(t))\nsignal_with_mult_noise = sine_wave * multiplicative_noise\n\n# Graficamos las señales\nfig, axes = plt.subplots(5, 1, figsize=(10, 10), sharex=True)\n\naxes[0].plot(t, sine_wave, label=\"Sine wave (10 Hz)\")\naxes[0].set_title(\"Sine Wave (10 Hz)\")\naxes[0].legend()\n\naxes[1].plot(\n    t, noise_normal, label=\"Random Noise (Normal Distribution)\", color=\"orange\"\n)\naxes[1].set_title(\"Random Noise (Normal Distribution)\")\naxes[1].legend()\n\naxes[2].plot(\n    t, signal_with_low_freq_noise, label=\"Sine + Low Freq Noise (2-5 Hz)\", color=\"green\"\n)\naxes[2].set_title(\"Sine + Low Freq Noise (2-5 Hz)\")\naxes[2].legend()\n\naxes[3].plot(t, signal_with_uniform_noise, label=\"Sine + Uniform Noise\", color=\"red\")\naxes[3].set_title(\"Sine + Uniform Noise\")\naxes[3].legend()\n\naxes[4].plot(t, signal_with_mult_noise, label=\"Sine * Uniform Noise\", color=\"purple\")\naxes[4].set_title(\"Sine * Uniform Noise\")\naxes[4].legend()\n\nplt.xlabel(\"Time [s]\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---asp",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - ASP",
    "text": "Introduction to data adquisition - ASP\n\n\n\n\n\n\n\n\n\nDefinition\n\n\nAnalog signal processing (ASP) refers to the manipulation of continuous-time signals after they have been acquired from a transducer but before digital conversion. This type of processing is performed using electronic circuits that modify the signal in the analog domain to enhance its quality, extract useful information, or prepare it for further processing.\n\n\n\n\n\n\n\n\n\n\n\nCommon tasks\n\n\n\nAmplification: Increases the signal strength to match the required voltage levels. Example: ECG signals are weak (~1 mV) and need to be amplified before analysis.\nFiltering: Removes unwanted frequency components such as noise or interference.\nModulation/Demodulation: Used for communication systems where signals are modulated onto a higher-frequency carrier wave. Example: Biomedical telemetry systems use amplitude modulation (AM) or frequency modulation (FM) to transmit patient data wirelessly.\nDifferentiation & Integration: Differentiation: Highlights rapid changes in the signal. Example: Used in QRS detection for ECG signal analysis. Integration: Smooths out signals and accumulates values over time. Example: Used in electromyography (EMG) processing to estimate muscle activation.\nSignal Conditioning: Includes impedance matching, offset correction, and dynamic range adjustments. Example: Removing DC offsets in biosignals before digitization."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#introduction-to-data-adquisition---analog-to-digital-convertion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Introduction to data adquisition - analog-to-digital convertion",
    "text": "Introduction to data adquisition - analog-to-digital convertion\n\n\n\n\n\n\n\nDefinition\n\n\nAn analog-to-digital converter (ADC) is a device that converts a continuous-time signal, obtained through a transducer, into a digital signal that can be processed by a computer. This process consists of two fundamental operations, which occur simultaneously in practical implementations: sampling and quantization.\n\n\n\n\nOperations\n\nSampling involves converting the continuous-time analog signal into a discrete-time signal, where the amplitude remains unrestricted.\nQuantization then maps this continuous-amplitude signal to a finite set of discrete values, making it fully digital."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-in-dsp-purpose-and-context",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-in-dsp-purpose-and-context",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Quantization in DSP: Purpose and Context",
    "text": "Quantization in DSP: Purpose and Context\n\nQuantization maps continuous amplitudes to a finite set of levels to enable digital representation.\nIn acquisition chains: anti-alias filter → sampling → ADC quantization.\nQuantization introduces an error that behaves like noise under standard assumptions.\nBiomedical relevance: ECG, EEG, EMG, and PPG require appropriate bit depth, gain, and dynamic range to preserve diagnostically relevant features."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#uniform-quantizer-definitions",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#uniform-quantizer-definitions",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Uniform Quantizer: Definitions",
    "text": "Uniform Quantizer: Definitions\n\nInput range: \\(\\left[V\\_{\\min},,V\\_{\\max}\\right]\\), bit depth \\(b\\), levels \\(L=2^b\\), step size (LSB)\n\\[\n\\Delta=\\frac{V_{\\max}-V_{\\min}}{L}.\n\\]\nMid-tread (round-to-nearest): \\(Q(x)=\\Delta,\\mathrm{round}!\\big(x/\\Delta\\big)\\).\nMid-rise (truncate + half-step): \\(Q(x)=\\Delta\\big(\\lfloor x/\\Delta\\rfloor+\\tfrac12\\big)\\).\nOverload/clipping outside \\(\\left[V\\_{\\min},V\\_{\\max}\\right]\\): \\(\\tilde{x}=V\\_{\\max}\\) or \\(V\\_{\\min}\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#decision-thresholds-and-codebook",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#decision-thresholds-and-codebook",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Decision Thresholds and Codebook",
    "text": "Decision Thresholds and Codebook\n\nDecision thresholds at \\(k\\Delta\\); reconstruction levels at:\n\n\\(k\\Delta\\) (mid-tread), or\n\\((k+\\tfrac12)\\Delta\\) (mid-rise).\n\nPractical note: choose mid-tread for rounding semantics; mid-rise for deterministic staircase without zero level."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-error-model-and-power",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#quantization-error-model-and-power",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Quantization Error: Model and Power",
    "text": "Quantization Error: Model and Power\n\nError \\(e=x-Q(x)\\). Under high-resolution assumptions (no clipping, sufficiently dense input):\n\n\\(e=x-Q(x)\\sim\\mathcal{U}\\left[-\\tfrac{\\Delta}{2},\\tfrac{\\Delta}{2}\\right]\\), \\(\\mathbb{E}\\left[e\\right]=0\\), \\(\\mathrm{Var}(e)=\\Delta^2/12\\).\n\nFor a full-scale sinusoid:\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76.\n\\]\nWith RMS usage fraction \\(\\rho\\) of full scale (FS):\n\\[\n\\mathrm{SNR}_{\\mathrm{dB}}\\approx 6.02\\,b + 1.76 + 20\\log_{10}(\\rho).\n\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#effective-number-of-bits-enob",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#effective-number-of-bits-enob",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Effective Number of Bits (ENOB)",
    "text": "Effective Number of Bits (ENOB)\n\nFrom a measured in-band SNR (RMS, same bandwidth):\n\\[\n\\mathrm{ENOB}\\approx\\frac{\\mathrm{SNR}_{\\mathrm{dB}}-1.76}{6.02}.\n\\]\nUse ENOB to compare real converters (including clock jitter, distortion) against ideal \\(b\\)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#input-range-analog-gain-and-clipping",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#input-range-analog-gain-and-clipping",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Input Range, Analog Gain, and Clipping",
    "text": "Input Range, Analog Gain, and Clipping\n\nAnalog gain \\(G\\) maps input to ADC: \\(x\\_{\\text{ADC}}=G,x\\_{\\text{in}}\\).\nInput-referred LSB: \\(\\Delta\\_{\\text{in}}=\\Delta/G\\).\nDesign goals:\n\nAvoid overload for rare peaks; 2) Use a large fraction of FS (e.g., \\(50\\)–\\(80%\\)) to improve SNR."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#biomedical-example-ecg-acquisition",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#biomedical-example-ecg-acquisition",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Biomedical Example: ECG Acquisition",
    "text": "Biomedical Example: ECG Acquisition\n\nSuppose electrode-level ECG peaks \\(\\approx \\pm 5,\\mathrm{mV}\\). Choose \\(G=200\\) so \\(\\pm 5,\\mathrm{mV}\\mapsto \\pm 1,\\mathrm{V}\\) at ADC (\\(V\\_{\\min,\\max}=\\pm 1,\\mathrm{V}\\)).\nWith \\(b=12\\):\n\n\\(\\Delta=\\dfrac{2,\\mathrm{V}}{2^{12}}\\approx 0.488,\\mathrm{mV}\\) (ADC domain).\n\\(\\Delta\\_{\\text{in}}=\\Delta/G\\approx 2.44,\\mu\\mathrm{V}\\).\nInput-referred noise RMS \\(\\sigma\\_q=\\Delta\\_{\\text{in}}/\\sqrt{12}\\approx 0.704,\\mu\\mathrm{V}\\_{\\mathrm{RMS}}\\).\n\nIf \\(\\rho\\approx 0.5\\), then \\(\\mathrm{SNR}\\approx 6.02\\cdot 12 + 1.76 - 6 \\approx 68,\\mathrm{dB}\\) → typically adequate for diagnostic ECG."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#non-uniform-quantization-and-companding-brief",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#non-uniform-quantization-and-companding-brief",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Non-Uniform Quantization and Companding (Brief)",
    "text": "Non-Uniform Quantization and Companding (Brief)\n\nFor highly non-uniform amplitude distributions, companding allocates effective resolution to small amplitudes.\n\\(\\mu\\)-law (telephony):\n\\[\ny=\\mathrm{sgn}(x)\\,\\frac{\\ln\\big(1+\\mu |x|/X_{\\max}\\big)}{\\ln(1+\\mu)},\\quad \\mu\\approx 255.\n\\]\nIn biomedicine, primary acquisition usually remains linear; companding is more relevant to low-bit-rate telemetry or storage."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#dither-when-and-why",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#dither-when-and-why",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Dither: When and Why",
    "text": "Dither: When and Why\n\nAdd small white noise (RMS \\(\\approx \\Delta/2\\)) before quantization to decorrelate error, eliminate bias/patterning at low levels, and linearize averages.\nSlight SNR penalty but improved fidelity for low-level features (e.g., EEG baselines)."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#practical-design-checklist",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#practical-design-checklist",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Practical Design Checklist",
    "text": "Practical Design Checklist\n\nChoose \\(b\\) to exceed clinical SNR requirements by \\(10\\)–\\(20,\\mathrm{dB}\\).\nSet \\(G\\) so typical peaks use \\(50\\)–\\(80%\\) FS; verify worst-case spikes do not clip.\nFull noise budget: electrode + amplifier + ADC quantization + clock jitter (for high \\(f\\)).\nValidate with calibrated sources and report ENOB over the intended bandwidth."
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#python-demo-ecg-quantization-at-multiple-bit-depths",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#python-demo-ecg-quantization-at-multiple-bit-depths",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Python Demo: ECG Quantization at Multiple Bit Depths",
    "text": "Python Demo: ECG Quantization at Multiple Bit Depths\n\n# Synthetic ECG, quantization at 8/10/12 bits, SNR and plots\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nfs = 360.0\nT = 5.0\nt = np.arange(0, T, 1/fs)\n\ndef g(t, mu, sigma, A):\n    return A*np.exp(-0.5*((t-mu)/sigma)**2)\n\ndef ecg_template(t):\n    P = g(t, 0.20, 0.045,  0.10)\n    Q = g(t, 0.36, 0.010, -0.25)\n    R = g(t, 0.40, 0.012,  1.00)\n    S = g(t, 0.44, 0.016, -0.35)\n    Tn= g(t, 0.70, 0.080,  0.30)\n    return P + Q + R + S + Tn\n\nhr = 60.0\nRR = 60.0/hr\necg_mV = np.zeros_like(t)\nfor k in range(int(np.ceil(T/RR))):\n    ecg_mV += ecg_template(t - k*RR)\n\nwander = 0.05*np.sin(2*np.pi*0.3*t)\nnoise  = 0.02*np.random.randn(len(t))\necg_mV = ecg_mV + wander + noise\n\nG = 200.0\nVfs = 1.0\nVmin, Vmax = -Vfs, Vfs\nx_adc = (ecg_mV/1000.0)*G  # mV -&gt; V and gain\n\ndef quantize_uniform(x, bits, Vmin, Vmax, mid_tread=True):\n    x_clip = np.clip(x, Vmin, Vmax)\n    L = 2**bits\n    Delta = (Vmax - Vmin)/L\n    if mid_tread:\n        y = Delta*np.round(x_clip/Delta)\n    else:\n        y = Delta*(np.floor(x_clip/Delta) + 0.5)\n    y = np.clip(y, Vmin, Vmax)\n    return y, Delta\n\ndef snr_db(x, y):\n    e = x - y\n    x_ac = x - np.mean(x)\n    e_ac = e - np.mean(e)\n    Px = np.mean(x_ac**2)\n    Pe = np.mean(e_ac**2)\n    return 10*np.log10(Px/Pe), e\n\nbits_list = [8, 10, 12]\nresults = {}\nfor b in bits_list:\n    y_adc, Delta = quantize_uniform(x_adc, b, Vmin, Vmax, mid_tread=True)\n    snr, e = snr_db(x_adc, y_adc)\n    results[b] = dict(y_adc=y_adc, Delta=Delta, snr_db=snr, err=e)\n\nprint(\"Summary (ADC domain):\")\n\nSummary (ADC domain):\n\nfor b in bits_list:\n    print(f\"{b:2d}-bit -&gt; LSB Δ = {results[b]['Delta']*1e3:.3f} mV, Measured SNR ≈ {results[b]['snr_db']:5.1f} dB\")\n\n 8-bit -&gt; LSB Δ = 7.812 mV, Measured SNR ≈  24.1 dB\n10-bit -&gt; LSB Δ = 1.953 mV, Measured SNR ≈  36.0 dB\n12-bit -&gt; LSB Δ = 0.488 mV, Measured SNR ≈  48.1 dB\n\nDelta_in = results[12][\"Delta\"]/G\nsigma_q_in = Delta_in/np.sqrt(12)\nprint(f\"\\nInput-referred (12-bit): Δ_in = {Delta_in*1e6:.3f} µV, σ_q ≈ {sigma_q_in*1e6:.3f} µV RMS\")\n\n\nInput-referred (12-bit): Δ_in = 2.441 µV, σ_q ≈ 0.705 µV RMS\n\n# Plot 1: original vs quantized (10-bit)\nb_plot = 10\nidx = (t &gt;= 1.5) & (t &lt;= 2.7)\nplt.figure()\nplt.title(f\"ECG (ADC input) vs. {b_plot}-bit quantized\")\nplt.plot(t[idx], x_adc[idx], label=\"Original (ADC input)\")\nplt.plot(t[idx], results[b_plot][\"y_adc\"][idx], label=f\"{b_plot}-bit\")\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude [V]\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n# Plot 2: quantization error histogram (8-bit)\nb_err = 8\nplt.figure()\nplt.title(f\"Quantization error histogram ({b_err}-bit)\")\nplt.hist(results[b_err][\"err\"], bins=80, density=True)\nplt.xlabel(\"Error [V]\")\nplt.ylabel(\"PDF estimate\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\nTo explain the analog-to-digital conversion process, we will assume that the input signal is a cosine wave with frequency \\(F\\), angular frequency \\(\\Omega\\) and amplitude \\(a\\).\n\\[x\\left(t\\right) = a \\cos\\left(\\Omega t + \\phi\\right) = a \\cos\\left(2\\pi F t + \\phi\\right)\\]\nObtaining\n\\[x\\left[n\\right] = a \\cos\\left(\\omega n + \\phi\\right) = a \\cos\\left(2\\pi f n + \\phi\\right)\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-1",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#analog-to-digital-convertion-2",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Analog to digital convertion",
    "text": "Analog to digital convertion\n\n\n\n\n\n\n\nWhat?\n\n\nMathematically, the sampling process is:\n\\[x[n] = x(nT_s), \\quad -\\infty &lt; n &lt; \\infty\\]\n\n\n\n\nReplacing in previous equations, we have the expression:\n\\[x[n] = x(nT_s) = a \\cos\\left( 2\\pi F n T_s + \\phi \\right) = a \\cos\\left( 2\\pi n \\frac{F}{F_s} + \\phi \\right)\n\\]\nWhere:\n\\[\\omega = \\Omega T_s, \\quad f = \\frac{F}{F_s}\\]"
  },
  {
    "objectID": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "href": "presentaciones/SYSB/Lect006_SignalAdquisition.html#sample-and-quantization-of-an-ecg-signal",
    "title": "Sistemas y Señales Biomédicos",
    "section": "Sample and quantization of an ECG signal",
    "text": "Sample and quantization of an ECG signal\n\nTaskGraphCode\n\n\n\nGenerate a synthetic ECG-like signal.\nSample it at different rates.\nApply quantization with different bit depths.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import chirp\n\n# Generate a synthetic ECG-like signal (chirp function as approximation)\nfs_original = 10000  # High sampling rate (Hz) - \"continuous\" signal\nt = np.linspace(0, 1, fs_original, endpoint=False)  # 1-second signal\nsignal = np.sin(2 * np.pi * 1.7 * (t**2))  # Simulated chirp (similar to ECG waves)\n\n# Downsample (Sampling Process)\nfs_sampled = 200  # Sampling frequency in Hz (e.g., ECG sampled at 200 Hz)\nt_sampled = np.arange(0, 1, 1/fs_sampled)\nsignal_sampled = np.sin(2 * np.pi * 1.7 * (t_sampled**2))\n\n# Quantization (8-bit and 4-bit)\ndef quantize(signal, bits):\n    levels = 2**bits\n    min_val, max_val = signal.min(), signal.max()\n    step = (max_val - min_val) / levels\n    quantized_signal = np.round((signal - min_val) / step) * step + min_val\n    return quantized_signal\n\nsignal_quantized_8bit = quantize(signal_sampled, 8)\nsignal_quantized_4bit = quantize(signal_sampled, 4)\n\n# Plot Results\nplt.figure(figsize=(12, 6))\n\n# Original vs Sampled Signal\nplt.subplot(2, 1, 1)\nplt.plot(t, signal, 'k', alpha=0.3, label='Original Signal (High Resolution)')\nplt.plot(t_sampled, signal_sampled, 'ro-', label=f'Sampled Signal ({fs_sampled} Hz)')\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Sampling Process\")\n\n# Quantized Signals\nplt.subplot(2, 1, 2)\nplt.plot(t_sampled, signal_sampled, 'bo-', alpha=0.5, label=\"Original Sampled\")\nplt.plot(t_sampled, signal_quantized_8bit, 'go-', label=\"Quantized 8-bit\")\nplt.plot(t_sampled, signal_quantized_4bit, 'ro-', label=\"Quantized 4-bit\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude\")\nplt.legend()\nplt.title(\"Quantization Effect\")\n\nplt.tight_layout()\nplt.show()"
  }
]