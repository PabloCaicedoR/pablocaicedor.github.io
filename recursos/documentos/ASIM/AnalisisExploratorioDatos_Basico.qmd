---
title: "Evaluación de la Calidad de los Datos"
subtitle: "Análisis Exploratorio para Regresión (`knee_flex_deg`) y Clasificación (`Risk_Lesion`)"
description: "ASIM"
lang: es
author: "Ph.D. Pablo Eduardo Caicedo Rodríguez"
date: "`r Sys.Date()`"
format:
  html:
    code-tools: true
    code-overflow: scroll
    code-line-numbers: true
    code-copy: true
    fig-align: center
    self-contained: true
    theme:
      - simple
      - ../../../recursos/estilos/metropolis.scss
    slide-number: true
    preview-links: auto
    logo: ../../../recursos/imagenes/generales/Escuela_Rosario_logo.png
    css: ../../../recursos/estilos/styles_pres.scss
    footer: <https://pablocaicedor.github.io/>
    transition: fade
    progress: true
    scrollable: true

resources:
  - demo.pdf
---

```{r}
#| echo: true
#| eval: true
#| output: false
#| label: Loading R-Libraries
# install.packages(c("DiagrammeR", "reticulate", "kableExtra", "tidyverse", "knitr", "cowplot", "ggfx"))
library("DiagrammeR")
library("reticulate")
library("kableExtra")
library("tidyverse")
library("knitr")
library("cowplot")
library("ggfx")
knitr::opts_chunk$set(echo = FALSE)

def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(options$size != "normalsize", paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize"), x)
})
```

```{python}
#| echo: true
#| eval: true
#| output: false
#| label: Loading Python-Libraries

import numpy as np
import matplotlib.pyplot as plt
path_ecg="../../data"

#https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#write

```

## Introducción

La **evaluación de la calidad de los datos** es una etapa crítica del análisis exploratorio, pues condiciona la validez estadística y la interpretabilidad de los modelos. En este documento se operacionalizan criterios y procedimientos para:

- **Regresión:** `knee_flex_deg` (continua).
- **Clasificación:** `Risk_Lesion` (categórica).

```{python}
# | echo: true
# | output: true
import pandas as pd
import numpy as np
from pathlib import Path

# Ajuste de ruta: si ejecuta desde Quarto/VSCode, use ruta relativa o absoluta
csv_path = Path("Injury_Risk.csv")
if not csv_path.exists():
    # Fallback para entorno de demostración (por ejemplo, ejecución en sandbox)
    csv_path = Path("../../../data/Injury_Risk/Injury_Risk.csv")

df = pd.read_csv(csv_path)
df.info()
```

---

## 1. Identificación de valores faltantes

Se cuantifican porcentajes de celdas vacías y se priorizan acciones: eliminar (>60%), imputar (30–60%), o evaluar impacto (<30%).

```{python}
#| echo: true
#| output: true
missing_tbl = (df.isna().mean().sort_values(ascending=False)*100.0).round(2).to_frame("Porc_Faltantes_%")
missing_tbl.head(20)
```

### Visualización de valores faltantes por variable

```{python}
#| echo: true
#| output: true
import matplotlib.pyplot as plt

plt.figure(figsize=(10, max(3, len(missing_tbl)*0.25)))
vals = missing_tbl["Porc_Faltantes_%"].values
labs = missing_tbl.index.values
ypos = np.arange(len(labs))
plt.barh(ypos, vals)
plt.yticks(ypos, labs)
plt.xlabel("% de celdas faltantes")
plt.title("Porcentaje de valores faltantes por variable")
plt.tight_layout()
plt.show()
```

---

## 2. Detección de cardinalidad irregular

Se inspecciona el número de valores únicos por variable para detectar: cardinalidad 1 (sin información), codificaciones erróneas o cardinalidad excesiva.

```{python}
#| echo: true
#| output: true
card_tbl = df.nunique(dropna=False).sort_values(ascending=True).to_frame("Cardinalidad")
card_tbl.head(20)
```

### Distribución de cardinalidad (todas las columnas)

```{python}
#| echo: true
#| output: true
plt.figure(figsize=(10, max(3, len(card_tbl)*0.25)))
vals = card_tbl["Cardinalidad"].values
labs = card_tbl.index.values
ypos = np.arange(len(labs))
plt.barh(ypos, vals)
plt.yticks(ypos, labs)
plt.xlabel("Número de valores únicos")
plt.title("Cardinalidad por variable")
plt.tight_layout()
plt.show()
```

---

## 3. Detección de valores atípicos (*Outliers*)

Se consideran dos enfoques: **IQR de Tukey** y **z-score**.

```{python}
#| echo: true
#| output: true
from typing import Tuple, Dict

def outlier_bounds_iqr(series: pd.Series, k: float = 1.5) -> Tuple[float, float]:
    s = series.dropna().astype(float)
    q1 = np.percentile(s, 25)
    q3 = np.percentile(s, 75)
    iqr = q3 - q1
    lo = q1 - k*iqr
    hi = q3 + k*iqr
    return lo, hi

def outlier_summary(df_num: pd.DataFrame, method: str = "iqr", k: float = 1.5, z: float = 3.0) -> pd.DataFrame:
    rows = []
    for col in df_num.columns:
        s = df_num[col].dropna().astype(float)
        if s.empty:
            continue
        if method == "iqr":
            lo, hi = outlier_bounds_iqr(s, k=k)
            out = ((df_num[col] < lo) | (df_num[col] > hi)).sum()
            rows.append((col, lo, hi, int(out)))
        else:
            m = s.mean(); sd = s.std(ddof=0)
            if sd == 0:
                rows.append((col, np.nan, np.nan, 0))
            else:
                out = ((np.abs((df_num[col]-m)/sd)) > z).sum()
                rows.append((col, m - z*sd, m + z*sd, int(out)))
    return pd.DataFrame(rows, columns=["Variable", "Límite_inferior", "Límite_superior", "Conteo_outliers"])

df_num = df.select_dtypes(include=[np.number])
iqr_tbl = outlier_summary(df_num, method="iqr", k=1.5).sort_values("Conteo_outliers", ascending=False)
z_tbl   = outlier_summary(df_num, method="z",   z=3.0).sort_values("Conteo_outliers", ascending=False)

iqr_tbl.head(15), z_tbl.head(15)
```

### Boxplots univariados seleccionados (matplotlib)

```{python}
#| echo: true
#| output: true
cols_plot = [c for c in df_num.columns if c.lower() in ["knee_flex_deg", "bodymass", "height"]]
if not cols_plot:
    # Selección automática de hasta 3 numéricas
    cols_plot = df_num.columns.tolist()[:3]

fig, axes = plt.subplots(nrows=len(cols_plot), ncols=1, figsize=(9, 4*len(cols_plot)))
if len(cols_plot) == 1:
    axes = [axes]

for ax, col in zip(axes, cols_plot):
    ax.boxplot(df_num[col].dropna().astype(float), vert=True, showmeans=True)
    ax.set_title(f"Boxplot: {col}")
    ax.set_ylabel(col)

plt.tight_layout()
plt.show()
```

---

## 4. Validez contextual (reglas de plausibilidad)

Se definen reglas de plausibilidad fisiológica/experimental y se generan banderas de validación.

```{python}
#| echo: true
#| output: true
flags = {}
if "knee_flex_deg" in df.columns:
    s = pd.to_numeric(df["knee_flex_deg"], errors="coerce")
    flags["knee_flex_deg_out_of_range"] = ~s.between(0, 180)  # rango articular plausible (ajuste si aplica)

if "bodymass" in df.columns:
    s = pd.to_numeric(df["bodymass"], errors="coerce")
    flags["bodymass_out_of_range"] = ~s.between(30, 300)      # ejemplo amplio; ajuste según protocolo

val_flags = pd.DataFrame(flags) if flags else pd.DataFrame()
val_flags.sum() if not val_flags.empty else "No se definieron reglas de plausibilidad para las variables presentes."
```

---

## 5. Análisis de correlación (soporte a decisiones)

Para orientar transformaciones o selección de variables se explora la correlación entre numéricas.

```{python}
#| echo: true
#| output: true
corr = df_num.corr(numeric_only=True)
corr.round(3).iloc[:8, :8]  # vista parcial
```

### Mapa de calor de correlaciones (matplotlib, sin seaborn)

```{python}
#| echo: true
#| output: true
plt.figure(figsize=(8,6))
im = plt.imshow(corr, interpolation='nearest', aspect='auto')
_ = plt.colorbar(im, fraction=0.046, pad=0.04)
_ = plt.xticks(ticks=np.arange(len(corr.columns)), labels=corr.columns, rotation=90)
_ = plt.yticks(ticks=np.arange(len(corr.index)), labels=corr.index)
_ = plt.title("Matriz de correlación (numéricas)")
_ = plt.tight_layout()
plt.show()
```

---

## 6. Estructura de clases para `Risk_Lesion` (si aplica)

Se inspecciona balance de clases y su impacto potencial en métricas y validación.

```{python}
#| echo: true
#| output: true
if "Risk_Lesion" in df.columns:
    vc = df["Risk_Lesion"].value_counts(dropna=False)
    vcp = df["Risk_Lesion"].value_counts(normalize=True, dropna=False).mul(100).round(2)
    display_tbl = pd.DataFrame({"Conteo": vc, "Porcentaje_%": vcp})
    display_tbl
else:
    "La variable 'Risk_Lesion' no está presente en el dataset."
```

### Barras de distribución de clases (matplotlib)

```{python}
# | echo: false
# | output: true
if "Risk_Lesion" in df.columns:
    counts = df["Risk_Lesion"].value_counts(dropna=False)
    labs = counts.index.astype(str).tolist()
    vals = counts.values.tolist()
    plt.figure(figsize=(6, 4))
    plt.bar(labs, vals)
    plt.xlabel("Clase")
    plt.ylabel("Frecuencia")
    plt.title("Distribución de clases: Risk_Lesion")
    plt.tight_layout()
    plt.show()
```

---

## 7. Plan de Calidad de Datos (plantilla)

Use la siguiente plantilla para documentar problemas detectados y acciones.

| Variable | Problema detectado | Evidencia/Regla | Acción propuesta | Responsable | Fecha |
|----------|--------------------|-----------------|------------------|-------------|-------|
| knee_flex_deg | Outliers (>p99) | IQR/Z-score | Validar en ficha clínica / Winsorizar | Equipo clínico | AAAA-MM-DD |
| Risk_Lesion | Desequilibrio | Conteo de clases | Muestreo estratificado / Umbrales | Equipo DS | AAAA-MM-DD |
| bodymass | Faltantes 8% | % faltantes | Imputación mediana | Equipo DS | AAAA-MM-DD |
| Dominancia | Codificación heterogénea | Cardinalidad/etiquetas | Normalizar etiquetas | Equipo DS | AAAA-MM-DD |

---

## 8. Recomendaciones para el modelado posterior

- **Regresión (`knee_flex_deg`)**: evaluar transformaciones (log/sqrt) si hay asimetría marcada; controlar outliers (winsorización o *RobustScaler*).
- **Clasificación (`Risk_Lesion`)**: balancear clases si hay desproporción; definir métrica principal (AUC/F1) y validación estratificada.
