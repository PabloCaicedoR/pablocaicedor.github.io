---
title: "Aprendizaje automático para señales e imágenes médicas (Documento base)"
author:
    - Pablo Eduardo Caicedo Rodríguez"
date: today
format: html
---

## 0) Propósito del documento

Compilar, con enfoque didáctico y académico, los conceptos y procedimientos mínimos para una asignatura de 24 h sobre aprendizaje automático (AA) aplicado a señales (ECG, EEG, EMG, PPG) e imágenes médicas (RX, RM, US, TC), alineado con los resultados de aprendizaje RA1–RA3 y con una actividad práctica guiada basada en PhysioNet y `scikit-learn`.

---

## 1) Resultados de aprendizaje (RA)

* **RA1.** Diferenciar tareas: **clasificación**, **regresión** y **segmentación** (incluye detección y localización).
* **RA2.** Seleccionar **métricas** apropiadas por tarea:
  Clasificación (Accuracy, AUC-ROC/PR, F1), Regresión (MAE/MSE/$R^2$), Segmentación (Dice/IoU).
* **RA3.** Describir e implementar un **pipeline reproducible** de AA en salud.

---

## 2) Planteamiento del problema y definición de la tarea

1. **Problema clínico** → traducir a una **tarea de AA**:

   * Clasificación: p. ej., “latido normal vs. arrítmico”.
   * Regresión: p. ej., “predecir intervalo QT en ms”.
   * Segmentación: p. ej., “delimitar miocardio en RM”.
2. **Unidad experimental**: típicamente **paciente**. Esto determina cómo se parte el conjunto de datos (evita fugas).
3. **Variables**:

   * **Entrada**: señal (tiempo/espacio), imagen o ambas.
   * **Salida**: etiqueta, valor continuo o máscara binaria/multiclase.
4. **Supuestos** explícitos: estacionariedad aproximada, protocolo de adquisición, etiquetado fiable, criterios de exclusión.

---

## 3) Particionado de datos y validación

### 3.1 Conjuntos estándar

* **Entrenamiento (train)**: ajuste de parámetros.
* **Validación (val)**: selección de hiperparámetros.
* **Prueba (test)**: evaluación final **independiente**.

> Regla: **nunca** usar información de *test* durante diseño o selección de hiperparámetros.

### 3.2 Validación cruzada adecuada a salud

* **Group/Subject-wise k-fold** (recomendado): los **grupos = pacientes**.
  Evita que segmentos del mismo paciente aparezcan en *train* y *val/test*.
* Para series temporales, considerar **TimeSeriesSplit** (sin embarajar en el tiempo).

### 3.3 Estratificación

* **Estratificación por clase y por paciente** cuando aplique: preservar proporciones de clases y garantizar separación por sujeto.

---

## 4) Métricas por tarea (selección y definición breve)

### 4.1 Clasificación

* **Accuracy**: $\text{Acc}=\frac{TP+TN}{TP+TN+FP+FN}$. Sensible a **desbalance**.
* **Precision/Recall**: $\text{Prec}=\frac{TP}{TP+FP}$, $\text{Rec}=\frac{TP}{TP+FN}$.
* **F1**: $\text{F1}=2\frac{\text{Prec}\cdot \text{Rec}}{\text{Prec}+\text{Rec}}$. Usar **macro-F1** en desbalance.
* **AUC-ROC** (área bajo curva ROC): útil con probas bien calibradas; puede ser optimista con clases raras.
* **AUC-PR**: preferible con **clase minoritaria** (p. ej., arritmias poco frecuentes).

### 4.2 Regresión

* **MAE**: $\text{MAE}=\frac{1}{n}\sum|y-\hat y|$ (robusto, interpretable en unidades clínicas).
* **MSE/RMSE**: penaliza más los grandes errores.
* **$R^2$**: proporción de varianza explicada (cuidado con extrapolación).

### 4.3 Segmentación (imágenes o señales con máscaras)

* **Dice**: $\text{Dice}=\frac{2TP}{2TP+FP+FN}$.
* **IoU**: $\text{IoU}=\frac{TP}{TP+FP+FN}$.
* Reportar ambas y **calibrar umbral** si provienen de probabilidades.

> **Buena práctica**: en desbalance, acompañar Acc con **matriz de confusión** y métricas **macro**; incluir **intervalos de confianza** por *bootstrap* por paciente.

---

## 5) Pipeline reproducible en salud (RA3)

**Resumen en 10 pasos (checklist):**

1. **Definición de tarea** y unidad experimental (paciente).
2. **Adquisición & data sheet**: fuente, licencias, versiones, criterios de inclusión/exclusión.
3. **Preprocesamiento**: filtrado artefactos, sincronización, segmentación (p. ej., ventanas centradas en R), remuestreo.
4. **Normalización/estandarización**: definida **solo** con estadísticas de *train* (evita fuga).
5. **Ingeniería de características** (si no es end-to-end):
   temporales, espectrales, morfológicas; para imágenes: texturas, intensidades normalizadas, etc.
6. **Particionado**: *train/val/test* **subject-wise**; *k*-fold con `GroupKFold`.
7. **Modelo baseline**: simple, interpretable (LogReg/SVM) con **pipeline** de `scikit-learn`.
8. **Selección de hiperparámetros**: `GridSearchCV`/`RandomizedSearchCV` **estrictamente dentro de train**, con `GroupKFold`.
9. **Evaluación**: métricas adecuadas + IC (bootstrap por paciente) + análisis de error por subgrupos.
10. **Reproducibilidad**:

    * Fijar semillas; registrar versiones (Python 3.12, `numpy`, `pandas`, `scikit-learn`, `matplotlib`).
    * Guardar **splits por paciente** y configuración en archivos (`.csv`/`.json`).
    * Script único ejecutable de extremo a extremo; reporte con tablas/figuras generadas por código.

---

## 6) Riesgos y *data leakage* (errores típicos)

* **Fuga por paciente**: el mismo sujeto en *train* y *val/test* (p. ej., distintos latidos del mismo ECG). **Solución**: `GroupKFold` con `group = patient_id`.
* **Fuga por normalización**: calcular media/desviación con todo el dataset. **Solución**: `Pipeline([StandardScaler, Modelo])`.
* **Fuga por selección de variables**: usar todo el dataset para *feature selection*. **Solución**: selección **dentro del CV**.
* **Desbalance severo**: optimizar Acc da modelos triviales. **Solución**: usar **macro-F1**, **AUC-PR**, `class_weight="balanced"`, ajuste de umbral.
* **Validación no anidada** con *early peeking*. **Solución**: separar clara y tempranamente *test*; usar CV anidada si se justifica.

---

## 7) Normalización, *feature engineering* y baselines

### 7.1 Normalización típica

* Señales: **estandarización z-score** por segmento ($x'=(x-\mu)/\sigma$) con $\mu,\sigma$ **de *train***, o **robust scaling** (mediana, IQR) si hay artefactos.
* Imágenes: *z-score* por imagen o canal; **reescala de intensidades**; para RM usar normalización por tejido de referencia si procede.

### 7.2 Ejemplos de características (no exhaustivo)

* **ECG**: RR, duración QRS, amplitud R, morfología de ventana centrada en R (vector crudo tras remuestreo), energía en bandas.
* **EEG/EMG**: RMS, varianza, potencia en bandas, *spectral entropy*.
* **Imágenes**: intensidades normalizadas, *first-order stats*, texturas (GLCM), forma (si hay segmentación previa).

### 7.3 Baselines recomendados

* **Regresión logística (L2)** y **SVM lineal** con `class_weight="balanced"`; comparar con **reglas simples** (umbral en una característica) para tener referencia mínima.

---

## 8) Actividad práctica (Mini-Lab 1, 10 %)

**Objetivo**: Clasificar latidos ECG (normal vs. no-normal) con **split estratificado por paciente** y **validación subject-wise k=5**.

### 8.1 Datos

* **Opción A (arrtimias clásicas)**: **MIT-BIH Arrhythmia Database** (PhysioNet). Anotaciones de latidos y etiquetas por clase; fs típica 360 Hz.
* **Opción B (escala clínica)**: **PTB-XL** (PhysioNet). ECG de 12 derivaciones; etiquetas diagnósticas (binaria o multilabel), fs 500 Hz (versión 100 Hz disponible).

> Elegir una sola base. Para latidos con anotaciones explícitas, MIT-BIH simplifica la segmentación centrada en R. Para diagnóstico multi-derivación, PTB-XL es más realista.

### 8.2 Protocolo técnico (stack: Python 3.12, `numpy`, `pandas`, `scikit-learn`, `matplotlib`)

1. **Descarga y organización**: conservar estructura y **ID de paciente**.
2. **Segmentación** (si MIT-BIH): ventana fija centrada en la marca del latido (p. ej., [−100, +200] ms), remuestreo a longitud fija (p. ej., 200 muestras).
3. **Etiquetado**: binario **N vs. no-N** (definir mapeo explícito).
4. **Particionado**: construir `groups = patient_id`; aplicar `GroupKFold(n_splits=5)`.
5. **Pipeline baseline**:

   * `StandardScaler` → (opcional) `PCA(n_components=20)` → `LogisticRegression(penalty="l2", class_weight="balanced", max_iter=200)`
   * Comparar con `LinearSVC(class_weight="balanced")`.
6. **Selección de hiperparámetros**: `GridSearchCV` con `cv=GroupKFold(5)`, `scoring="f1_macro"` y **grupos**.
7. **Reporte**: macro-F1, AUC-PR por *fold*, matriz de confusión agregada por paciente; IC del 95 % por *bootstrap* con remuestreo de pacientes.
8. **Control de fugas**: verificar que ningún `patient_id` aparezca en más de un *fold* simultáneamente.

> **Criterio de éxito del baseline**: superar trivial (clasificador mayoritario) y mostrar **ganancia** consistente en macro-F1; reportar *learning curve* opcional para estimar régimen de datos.

### 8.3 Esqueleto de código (ilustrativo)

```python
import numpy as np, pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.model_selection import GroupKFold, GridSearchCV
from sklearn.metrics import f1_score, average_precision_score

# X: matriz (n_samples, n_features) de latidos remuestreados o features
# y: etiquetas binaras (0/1); groups: patient_id
gkf = GroupKFold(n_splits=5)

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("pca", PCA(n_components=20, random_state=42)),
    ("clf", LogisticRegression(max_iter=200, class_weight="balanced", n_jobs=None))
])

param_grid = {"clf__C": [0.1, 1, 10]}
grid = GridSearchCV(pipe, param_grid, cv=gkf.split(X, y, groups=groups),
                    scoring="f1_macro", n_jobs=-1)
grid.fit(X, y)

# Evaluación interna (val) del mejor modelo por fold ya incluida en GridSearchCV.
# Para test externo, repetir con splits fijos y sin reentrenar sobre test.
```

---

## 9) Selección y justificación de métricas (RA2)

* **Desbalance**: usar **macro-F1** y **AUC-PR** (promedio por clase) además de Acc.
* **Curvas**: ROC y PR; **umbral** optimizado para el criterio clínico (p. ej., maximizar *Recall* en clase patológica).
* **Calibración**: verificar **calibración** de probabilidades (Brier score, reliabilidad); considerar `CalibratedClassifierCV` si se reportan riesgos.

---

## 10) Reporte reproducible y trazabilidad (RA3)

* **Manifiesto de entorno**: versiones exactas (Python 3.12; `numpy`, `pandas`, `scikit-learn`, `matplotlib`), SO, semilla global.
* **Script único** o *Makefile* que recorra todas las etapas.
* **Splits persistidos** por `patient_id` (archivos en `data/splits/`).
* **Resultados** guardados como tablas (`.csv`) y figuras (`.png/.pdf`) generadas automáticamente.
* **Bitácora de decisiones**: justificación de preprocesamiento, features y métricas.
* **Hoja de datos** (*data sheet*): fuente, licencias, versión, criterios de exclusión, porcentaje de desbalance, políticas de anonimización.

---

## 11) Extensiones (según tiempo)

* **Comparación de baselines**: LogReg vs. LinearSVC; análisis de errores por morfología.
* **Imágenes**: mini-experimento de segmentación con máscaras sintéticas para practicar Dice/IoU (sin *deep learning*).
* **Curvas de aprendizaje**: estimar beneficio esperado al aumentar datos.
* **Evaluación por subgrupos**: sexo, edad, dispositivo de adquisición (si está disponible).

---

## 12) Criterios de evaluación (Mini-Lab 1, 10 %)

* **Correctitud técnica (4 %)**: particionado subject-wise, sin fugas, métricas adecuadas.
* **Reproducibilidad (3 %)**: script único, semillas, versiones, splits persistidos.
* **Análisis crítico (2 %)**: interpretación de métricas, limitaciones, propuesta de mejora.
* **Comunicación (1 %)**: claridad del informe, figuras legibles, tablas completas.

---

## 13) Glosario mínimo

* **Subject-wise split**: partición donde cada paciente aparece en un solo conjunto por fold.
* **Fuga de datos (data leakage)**: uso indirecto de información de *val/test* en entrenamiento.
* **Desbalance de clases**: proporción desigual entre clases; requiere métricas/métodos específicos.
* **Baseline**: modelo simple de referencia para establecer un piso de desempeño.
* **Calibración**: coherencia entre probabilidades predichas y frecuencias observadas.

---

## 14) Referencias (verificadas)

* **Bishop, C. M.** *Pattern Recognition and Machine Learning*. Springer, 2006. **ISBN 978-0387310732**.
* **Pedregosa, F.,** Varoquaux, G., Gramfort, A., et al. “Scikit-learn: Machine Learning in Python”. *JMLR* 12:2825–2830, 2011. *(JMLR no asigna DOI; citar con URL oficial del artículo o paquete).*
* **Moody, G. B., Mark, R. G.** “The impact of the MIT-BIH Arrhythmia Database”. *IEEE Eng. Med. Biol. Mag.*, 20(3):45–50, 2001. **doi:10.1109/51.932724**.
* **Wagner, P.,** Strodthoff, N., Bousseljot, R.-D., et al. “PTB-XL, a large publicly available electrocardiography dataset”. *Sci. Data* 7, 154 (2020). **doi:10.1038/s41597-020-0495-6**.
* **Saito, T., Rehmsmeier, M.** “The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Datasets”. *PLOS ONE* 10(3):e0118432, 2015. **doi:10.1371/journal.pone.0118432**.

> Nota: Antes de distribuir materiales, incluir las **URLs oficiales** de PhysioNet de la base elegida y la versión de `scikit-learn` usada (e.g., 1.5.x).

---

## 15) Anexos útiles (plantillas)

### 15.1 Plantilla de *Pipeline* (`scikit-learn`)

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GroupKFold, GridSearchCV

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", LogisticRegression(max_iter=200, class_weight="balanced"))
])

param_grid = {"clf__C": [0.1, 1, 10]}
cv = GroupKFold(n_splits=5)
gscv = GridSearchCV(pipe, param_grid, cv=cv.split(X, y, groups=patient_id),
                    scoring="f1_macro", n_jobs=-1)
gscv.fit(X, y)
```

### 15.2 Checklist de entrega (Mini-Lab 1)

* [ ] Script reproducible de extremo a extremo.
* [ ] Registro de versiones y semillas.
* [ ] Splits por `patient_id` guardados y documentados.
* [ ] Métricas: macro-F1, AUC-PR, matriz de confusión.
* [ ] Análisis de error con ejemplos mal clasificados.
* [ ] Discusión de limitaciones y próximos pasos.

---

### Cierre

El documento cubre RA1–RA3 con foco en métricas adecuadas, control de fuga y un pipeline reproducible compatible con Python 3.12 y `scikit-learn`. La actividad práctica en PhysioNet es coherente con el alcance y permite evaluar de forma objetiva el Mini-Lab 1 (10 %).
