{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Procesamiento de Señales e Imagenes\"\n",
        "description: \"PSIM -- 101849\"\n",
        "subtitle: \"Ingeniería Biomédica\"\n",
        "lang: es\n",
        "author: \"Ph.D. Pablo Eduardo Caicedo Rodríguez\"\n",
        "date: last-modified\n",
        "format:\n",
        "  revealjs: \n",
        "    code-tools: true\n",
        "    code-overflow: wrap\n",
        "    code-line-numbers: true\n",
        "    code-copy: true\n",
        "    fig-align: center\n",
        "    self-contained: true\n",
        "    theme: \n",
        "      - simple\n",
        "      - ../../recursos/estilos/metropolis.scss\n",
        "    slide-number: true\n",
        "    preview-links: auto\n",
        "    logo: ../../recursos/imagenes/generales/Escuela_Rosario_logo.png\n",
        "    css: ../../recursos/estilos/styles_pres.scss\n",
        "    footer: <https://pablocaicedor.github.io/>\n",
        "    transition: fade\n",
        "    progress: true\n",
        "    scrollable: true\n",
        "    mainfont: \"Fira Code\"\n",
        "---\n",
        "\n",
        "# Un recorrido narrado por señales e imágenes\n",
        "\n",
        "Hoy nos reunimos para observar cómo los datos del cuerpo cuentan historias. Pensaremos en una señal como una narración que avanza segundo a segundo —como una línea que respira— y en una imagen como una narración detenida en el espacio, organizada en diminutos cuadros llamados píxeles. No necesitaremos fórmulas: bastará con la curiosidad y con la disposición para experimentar. Al final habrás creado tus propias figuras y podrás explicar, con tus palabras, qué cambió cuando el ruido apareció o cuando un filtro suavizó la escena.\n",
        "\n",
        "---\n",
        "\n",
        "# La primera escena: escuchar el corazón\n",
        "\n",
        "Imagina que acercas un micrófono al pecho. Lo que el sensor “oye” se convierte en una secuencia de números tomada muchas veces por segundo. A ese ritmo de toma lo llamamos *muestreo*, y su papel es parecido al de una cámara lenta: si tomamos muy pocos “fotogramas”, la historia pierde detalle; si tomamos suficientes, podemos seguir el ritmo del latido. Cada número ocupa un espacio en el computador; ese espacio define qué tan finamente distinguimos entre “más fuerte” y “más suave”. Esta finura se asocia con *profundidad de bits*. Sin ecuaciones, basta con la idea: más muestras y pasos más finos suelen permitir descripciones más nítidas, aunque siempre tendremos que escoger con cuidado.\n",
        "\n",
        "---\n",
        "\n",
        "# Una prueba con Python: sonido ideal, ruido y suavizado\n",
        "\n",
        "Enseguida construiremos una señal sencilla que late. Luego le añadiremos ruido —pequeñas sacudidas aleatorias— y por último la suavizaremos con un promedio deslizante. Observa cómo la claridad mejora, pero también cómo algunos detalles se aplanan."
      ],
      "id": "428e5276"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup\n",
        "#| echo: false\n",
        "import numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "rng = np.random.default_rng(42)\n",
        "sns.set()"
      ],
      "id": "setup",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: narrativa-senal\n",
        "#| fig-cap: 'Una historia en el tiempo: señal ideal, señal con ruido y señal suavizada.'\n",
        "fs = 200               # 'muestras por segundo' para narrar con fluidez\n",
        "t  = np.arange(0, 5, 1/fs)\n",
        "x  = 0.8*np.sin(2*np.pi*1.2*t) + 0.3*np.sin(2*np.pi*3.5*t)  # un 'latido' estilizado\n",
        "ruido = 0.4*rng.normal(size=t.size)\n",
        "y  = x + ruido\n",
        "\n",
        "# Suavizado por promedio (ventana impar)\n",
        "k = 9\n",
        "kernel = np.ones(k)/k\n",
        "y_suave = np.convolve(y, kernel, mode='same')\n",
        "\n",
        "plt.figure(figsize=(9,3.2))\n",
        "plt.plot(t, x, lw=1.5, label=\"Relato ideal\")\n",
        "plt.plot(t, y, alpha=.6, label=\"Relato con ruido\")\n",
        "plt.plot(t, y_suave, lw=2, label=\"Relato suavizado\")\n",
        "plt.xlabel(\"Tiempo [s]\"); plt.ylabel(\"Amplitud (adim.)\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()"
      ],
      "id": "narrativa-senal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# La segunda escena: mirar el espacio\n",
        "\n",
        "Una imagen no avanza; se despliega ante nosotros como un mosaico. Cada píxel conserva un valor de brillo o color. Cuantos más píxeles haya en un área dada, más fino será el mosaico y, por tanto, más detalle veremos. Cuando una imagen se vuelve borrosa —por movimiento, por desenfoque o por compresión— las transiciones se suavizan y los bordes pierden definición. Podemos intentar recuperarlos detectando dónde cambian rápido los valores: allí suelen esconderse las líneas y contornos que la mirada reconoce.\n",
        "\n",
        "---\n",
        "\n",
        "# Un experimento visual: del patrón limpio al borde\n",
        "\n",
        "Ahora generaremos una imagen sintética. Primero veremos su versión “limpia”; luego la agitaremos con ruido; después la desenfocaremos con un pequeño promedio; por último buscaremos bordes con un operador sencillo. Observa cómo el desenfoque ayuda a reducir el grano pero, si se exagera, disuelve contornos que tal vez queríamos conservar."
      ],
      "id": "362c1ec5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: narrativa-imagen\n",
        "#| fig-cap: 'Una historia en el espacio: patrón base, ruido, desenfoque y bordes.'\n",
        "def pad_reflect(A, p):\n",
        "    return np.pad(A, ((p,p),(p,p)), mode='reflect')\n",
        "\n",
        "def conv2(A, K):\n",
        "    p = K.shape[0]//2\n",
        "    Ap = pad_reflect(A, p)\n",
        "    out = np.zeros_like(A, dtype=float)\n",
        "    for i in range(out.shape[0]):\n",
        "        for j in range(out.shape[1]):\n",
        "            region = Ap[i:i+K.shape[0], j:j+K.shape[1]]\n",
        "            out[i,j] = np.sum(region * K)\n",
        "    return out\n",
        "\n",
        "# Patrón de prueba: degradé + tableros\n",
        "n = 180\n",
        "x = np.linspace(0,1,n)\n",
        "grad = np.tile(x, (n,1))\n",
        "checker = (((np.indices((n,n)).sum(axis=0))%30) < 15).astype(float)\n",
        "img = 0.6*grad + 0.4*checker\n",
        "\n",
        "# Ruido y desenfoque\n",
        "img_r = img + 0.12*rng.normal(size=img.shape)\n",
        "K = np.ones((5,5))/25\n",
        "img_blur = conv2(img_r, K)\n",
        "\n",
        "# Bordes (Sobel)\n",
        "Sx = np.array([[1,0,-1],[2,0,-2],[1,0,-1]])\n",
        "Sy = Sx.T\n",
        "gx, gy = conv2(img_blur, Sx), conv2(img_blur, Sy)\n",
        "edges = np.hypot(gx, gy)\n",
        "\n",
        "fig, axs = plt.subplots(1,4, figsize=(12,3))\n",
        "for a,im,tit in zip(axs, [img, img_r, img_blur, edges], \n",
        "                    [\"Base\", \"Con ruido\", \"Desenfoque\", \"Bordes\"]):\n",
        "    a.imshow(im, cmap='gray'); a.set_title(tit); a.axis('off')\n",
        "plt.tight_layout(); plt.show()"
      ],
      "id": "narrativa-imagen",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Actividad guiada I: cuenta tu propia señal\n",
        "\n",
        "Te propongo crear tu propia narración en el tiempo. Modifica las frecuencias para imitar un ritmo distinto; aumenta o reduce el ruido para ver en qué momento la historia deja de ser legible; ajusta la ventana del suavizado y describe, con dos o tres frases, el compromiso entre claridad y detalle. No hay respuestas únicas: nos interesa cómo justificas tus decisiones."
      ],
      "id": "667d6d9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: practica-narrativa-senal\n",
        "#| fig-cap: 'Cuenta tu señal: ajusta el ritmo, el ruido y el suavizado y explica tu elección.'\n",
        "fs = 300\n",
        "t  = np.arange(0, 6, 1/fs)\n",
        "\n",
        "f1, f2 = 1.0, 2.2           # experimenta con estos valores\n",
        "x  = 1.0*np.sin(2*np.pi*f1*t) + 0.4*np.sin(2*np.pi*f2*t)\n",
        "ruido = 0.30*rng.normal(size=t.size)   # modifícalo para tensar la historia\n",
        "y  = x + ruido\n",
        "\n",
        "k = 11                       # el tamaño de la 'ventana' moldea el tono\n",
        "kernel = np.ones(k)/k\n",
        "y_suave = np.convolve(y, kernel, mode='same')\n",
        "\n",
        "fig, ax = plt.subplots(2, 1, figsize=(9,6), sharex=True)\n",
        "ax[0].plot(t, x, lw=1.5, label=\"Ideal\"); ax[0].plot(t, y, alpha=.6, label=\"Con ruido\")\n",
        "ax[0].set_title(\"Tu relato con interferencias\")\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(t, y, alpha=.5, label=\"Ruidosa\"); ax[1].plot(t, y_suave, lw=2, label=\"Suavizada\")\n",
        "ax[1].set_title(f\"Tu herramienta de calma (ventana={k})\")\n",
        "ax[1].set_xlabel(\"Tiempo [s]\"); \n",
        "for a in ax: a.set_ylabel(\"Amplitud\")\n",
        "ax[1].legend(); plt.tight_layout(); plt.show()"
      ],
      "id": "practica-narrativa-senal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Actividad guiada II: esculpe tu imagen\n",
        "\n",
        "Ahora construye una escena propia: un degradé, un círculo, un motivo que te guste. Aumenta el ruido hasta que la textura se vuelva áspera y luego atenúala con un desenfoque moderado. Observa cuándo los contornos emergen con el detector de bordes y cuándo, en cambio, se diluyen. Concluye con un pie de foto que explique, sin jerga, qué aprendiste sobre el equilibrio entre nitidez y suavidad."
      ],
      "id": "306e6335"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: practica-narrativa-imagen\n",
        "#| fig-cap: 'Esculpe la escena: patrón, ruido, desenfoque, bordes y tu interpretación final.'\n",
        "n = 200\n",
        "x = np.linspace(0,1,n)\n",
        "grad = np.tile(x**0.6, (n,1))\n",
        "yy, xx = np.indices((n,n))\n",
        "circulo = ((xx-n/2)**2 + (yy-n/2)**2 < (n/4)**2).astype(float)\n",
        "img = 0.7*grad + 0.3*circulo\n",
        "\n",
        "ruido_sigma = 0.18\n",
        "img_r = img + ruido_sigma*rng.normal(size=img.shape)\n",
        "\n",
        "k = 7\n",
        "K = np.ones((k,k))/k**2\n",
        "img_blur = conv2(img_r, K)\n",
        "\n",
        "Sx = np.array([[1,0,-1],[2,0,-2],[1,0,-1]])\n",
        "Sy = Sx.T\n",
        "gx, gy = conv2(img_blur, Sx), conv2(img_blur, Sy)\n",
        "edges = np.hypot(gx, gy)\n",
        "\n",
        "fig, axs = plt.subplots(1,4, figsize=(12,3))\n",
        "for a,im,tit in zip(axs, [img, img_r, img_blur, edges], \n",
        "                    [\"Patrón propio\", f\"Ruido σ={ruido_sigma}\", f\"Desenfoque k={k}\", \"Bordes\"]):\n",
        "    a.imshow(im, cmap='gray'); a.set_title(tit); a.axis('off')\n",
        "plt.tight_layout(); plt.show()"
      ],
      "id": "practica-narrativa-imagen",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Ética y cuidado en cada decisión\n",
        "\n",
        "En esta sesión usamos datos sintéticos, precisamente para practicar sin arriesgar la privacidad de nadie. En proyectos reales, las señales y las imágenes pertenecen a personas, y tratarlas con respeto implica proteger identidades, explicar el propósito de uso y documentar las decisiones de procesamiento. La narrativa técnica siempre convive con una narrativa humana: quiénes participaron, qué beneficios esperan y cómo reducimos riesgos.\n",
        "\n",
        "---\n",
        "\n",
        "# Cierre: lo que la historia nos deja\n",
        "\n",
        "Has visto que una señal puede volverse ruidosa y que un filtro, al calmarla, también puede borrar matices. Has visto que una imagen puede ganar suavidad y perder aristas, o recuperarlas con un detector de bordes. La idea central es sencilla: toda herramienta implica un intercambio. Nuestro trabajo consiste en elegir con sentido, observar con cuidado y explicar con palabras claras cuál fue el camino y por qué.\n",
        "\n",
        "::: notes\n",
        "Para el docente: invita a que cada equipo muestre **un** gráfico y lo resuma en dos frases. Pide que digan explícitamente qué parámetro movieron, qué efecto observaron y qué decisión tomarían si el objetivo fuera ver el latido con nitidez o delinear un borde en una radiografía.\n",
        ":::"
      ],
      "id": "5788e2f3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/sylph/DataCantatio/ai-torch/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}