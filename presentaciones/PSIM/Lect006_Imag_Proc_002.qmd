---
title: "Procesado de Señales e Imágenes Médicas"
description: "ASIM_M -- 104399"
subtitle: "Ingeniería Biomédica"
lang: es
author: "Ph.D. Pablo Eduardo Caicedo Rodríguez"
date: "2024-08-12"
format:
  revealjs: 
    code-tools: true
    code-overflow: wrap
    code-line-numbers: true
    code-copy: true
    fig-align: center
    self-contained: true
    theme: 
      - simple
      - ../../recursos/estilos/metropolis.scss
    slide-number: true
    preview-links: auto
    logo: ../../recursos/imagenes/generales/Escuela_Rosario_logo.png
    css: ../../recursos/estilos/styles_pres.scss
    footer: <https://pablocaicedor.github.io/>
    transition: fade
    progress: true
    scrollable: true
resources:
  - demo.pdf
---

```{r}
#| echo: false
#| eval: true
#| output: false
#| label: Loading R-Libraries

library("DiagrammeR")
library("reticulate")
library("kableExtra")
library("tidyverse")
library("knitr")
library("cowplot")
library("ggfx")


knitr::opts_chunk$set(echo = FALSE)

def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(options$size != "normalsize", paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize"), x)
})


data_path<-"../../data/"

```

```{python}
#| echo: false
#| eval: true
#| output: false
#| label: Loading Python-Libraries

import numpy as np
import scipy.io as sio
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import cv2

data_path="../../data/"

import numpy as np
import cv2
import matplotlib.pyplot as plt

def adjust_gamma(image, gamma=1.0):
   invGamma = 1.0 / gamma
   table = np.array([((i / 255.0) ** invGamma) * 255
      for i in np.arange(0, 256)]).astype("uint8")

   return cv2.LUT(image, table)


# Dibujar un círculo blanco en el centro
image_circle = np.zeros((200, 200), dtype=np.uint8)
cv2.circle(image_circle, (100, 100), 50, (255), -1)


image_gradient = np.linspace(0, 255, 200, dtype=np.uint8)
image_gradient = np.tile(image_gradient, (200, 1))
cv2.circle(image_gradient, (100, 100), 50, (255), -1)

noise = np.random.randint(0, 256, (200, 200), dtype=np.uint8)
noisy_circle = cv2.addWeighted(image_circle, 0.5, noise, 0.5, 0)

```

# Procesamiento de imágenes

## What is Thresholding?

- Definition: A technique to separate objects from the background in images.
- Concept: Converting a grayscale image into a binary image.
- Importance: Simplification for further analysis (e.g., edge detection, segmentation).

---

## Global Thresholding

- Explanation of **Global Thresholding**.
- Example of a fixed threshold \( T \):
  - If \( I(x, y) > T \), the pixel becomes white (1), otherwise black (0).
- Limitations: Sensitivity to uneven lighting.

---

## Adaptive Thresholding

- Definition of **Adaptive Thresholding**.
- Instead of a global threshold, the threshold is calculated for different regions of the image.
- Advantages: Effective in images with varying illumination.
- Algorithm: Example of an adaptive method based on the local mean of neighboring pixels.

---

## Otsu's Algorithm

- Explanation of **Otsu's Algorithm**.
  - Automatic global thresholding that minimizes the within-class variance.
- Steps of the algorithm:
  1. Compute image histograms.
  2. Evaluate the between-class variance function for every possible threshold.
  3. Select the threshold that minimizes the within-class variance.
- Advantages: Automatic and effective in bimodal images.

---

## Justification for Using Thresholding

- When thresholding is useful:
  - Images with a clear contrast between the object and the background.
  - Situations requiring quick segmentation.
- Example applications:
  - Text detection, object recognition, medical images (e.g., X-rays).
- Limitations: Less effective in noisy or low-quality images.

---

## Comparison of Thresholding Algorithms

| Method           | Precision | Processing Speed | Ease of Implementation | Typical Applications  |
|------------------|-----------|------------------|------------------------|-----------------------|
| Global Threshold  | Medium    | Fast             | Simple                 | High-contrast images  |
| Adaptive Threshold| High      | Moderate         | Moderate               | Unevenly lit images   |
| Otsu's Algorithm  | High      | Moderate         | Moderate               | Bimodal distributions |

---

## Practical Examples

- Show examples of original images and the result after applying:
  - Global Thresholding.
  - Adaptive Thresholding.
  - Otsu's Algorithm.
- Visualizations highlighting the differences.

---

## Practical Examples

:::{.panel-tabset}

## Results

```{python}
#| echo: false
#| eval: true
#| output: true
#| label: Image_Thresholding_Creation
#| layout-ncol: 3

plt.imshow(image_circle, cmap="gray");
plt.axis("off");
plt.show()

plt.imshow(image_gradient, cmap="gray");
plt.axis("off");
plt.show()

plt.imshow(noisy_circle, cmap="gray");
plt.axis("off");
plt.show()

_, global_thresh1 = cv2.threshold(image_circle, 127, 255, cv2.THRESH_BINARY)
plt.imshow(global_thresh1, cmap="gray");
plt.axis("off");
plt.show()

_, global_thresh2 = cv2.threshold(image_gradient, 127, 255, cv2.THRESH_BINARY)
plt.imshow(global_thresh2, cmap="gray");
plt.axis("off");
plt.show()

_, global_thresh3 = cv2.threshold(noisy_circle, 127, 255, cv2.THRESH_BINARY)
plt.imshow(global_thresh3, cmap="gray");
plt.axis("off");
plt.show()

adaptive_thresh1 = cv2.adaptiveThreshold(image_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
plt.imshow(adaptive_thresh1, cmap="gray");
plt.axis("off");
plt.show()

adaptive_thresh2 = cv2.adaptiveThreshold(image_gradient, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
plt.imshow(adaptive_thresh2, cmap="gray");
plt.axis("off");
plt.show()

adaptive_thresh3 = cv2.adaptiveThreshold(noisy_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
plt.imshow(adaptive_thresh3, cmap="gray");
plt.axis("off");
plt.show()

_, otsu_thresh1 = cv2.threshold(image_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
plt.imshow(otsu_thresh1, cmap="gray");
plt.axis("off");
plt.show()

_, otsu_thresh2 = cv2.threshold(image_gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
plt.imshow(otsu_thresh2, cmap="gray");
plt.axis("off");
plt.show()

_, otsu_thresh3 = cv2.threshold(noisy_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
plt.imshow(otsu_thresh3, cmap="gray");
plt.axis("off");
plt.show()

```

## Code

```{python}
#| echo: true
#| eval: false
#| output: false
#| label: Image_Thresholding_Creation_Code

plt.imshow(image_circle, cmap="gray")
plt.axis("off")
plt.show()

plt.imshow(image_gradient, cmap="gray")
plt.axis("off")
plt.show()

plt.imshow(noisy_circle, cmap="gray")
plt.axis("off")
plt.show()

_, global_thresh1 = cv2.threshold(image_circle, 127, 255, cv2.THRESH_BINARY)
plt.imshow(global_thresh1, cmap="gray")
plt.axis("off")
plt.show()

_, global_thresh2 = cv2.threshold(image_gradient, 127, 255, cv2.THRESH_BINARY)
plt.imshow(global_thresh2, cmap="gray")
plt.axis("off")
plt.show()

_, global_thresh3 = cv2.threshold(noisy_circle, 127, 255, cv2.THRESH_BINARY)
plt.imshow(global_thresh3, cmap="gray")
plt.axis("off")
plt.show()

adaptive_thresh1 = cv2.adaptiveThreshold(image_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
plt.imshow(adaptive_thresh1, cmap="gray")
plt.axis("off")
plt.show()

adaptive_thresh2 = cv2.adaptiveThreshold(image_gradient, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
plt.imshow(adaptive_thresh2, cmap="gray")
plt.axis("off")
plt.show()

adaptive_thresh3 = cv2.adaptiveThreshold(noisy_circle, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)
plt.imshow(adaptive_thresh3, cmap="gray")
plt.axis("off")
plt.show()

_, otsu_thresh1 = cv2.threshold(image_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
plt.imshow(otsu_thresh1, cmap="gray")
plt.axis("off");
plt.show()

_, otsu_thresh2 = cv2.threshold(image_gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
plt.imshow(otsu_thresh2, cmap="gray")
plt.axis("off")
plt.show()

_, otsu_thresh3 = cv2.threshold(noisy_circle, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
plt.imshow(otsu_thresh3, cmap="gray")
plt.axis("off")
plt.show()

```

:::


---

## Conclusion and Questions

- Summary of key points:
  - Thresholding as a simple yet powerful technique.
  - Importance of choosing the right algorithm depending on the context.
  - Otsu's algorithm as an effective solution for bimodal images.

##  Introduction to Morphological Operations

- Definition: Morphological operations apply a structuring element to an image to alter its structure.
- Focus: Primarily used for binary images.
- Key applications: Noise removal, object extraction, shape analysis.

---

## Structuring Element

- A small matrix used to probe and interact with a given image.
- Common shapes: Rectangular, circular, elliptical.
- Example: A 3x3 square structuring element.

$$\begin{bmatrix}
  1 & 1 & 1 \\
  1 & 1 & 1 \\
  1 & 1 & 1 \\
\end{bmatrix}$$

## Common Morphological Operations

- **Erosion**:
  - Removes pixels on object boundaries.
  - Shrinks the size of objects in the image.
  - Used to eliminate small noise or detach connected objects.

- **Dilation**:
  - Adds pixels to object boundaries.
  - Enlarges the object in an image.
  - Helps fill small holes and gaps within objects.

- **Opening**:
  - Erosion followed by dilation.
  - Used to remove small objects (noise) while maintaining the shape of larger objects.

- **Closing**:
  - Dilation followed by erosion.
  - Fills small holes and gaps in an object’s boundaries.

- **Top-Hat Transformation**:
  - The difference between the original image and its **opening**.
  - Used to highlight **bright regions** on a dark background.
  - Detecting small, bright objects or details in an unevenly illuminated image.
  
- **Black-Hat Transformation**:
  - The difference between the **closing** of an image and the original image.
  - Used to highlight **dark regions** on a bright background.
  - Emphasizing dark objects or shadows in an image.

## Example of Morphological Operations

```{python}

#| echo: false
#| eval: true
#| output: true
#| label: mORPHOLOGICAL_OPERATIONS
#| layout-ncol: 2

# Define a 3x3 structuring element
structuring_element = cv2.getStructuringElement(cv2.MORPH_RECT, (11, 11))


# Erosion example in OpenCV
image = cv2.imread("../../recursos/imagenes/Presentaciones/PSIM/Smiley.png")
binary_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
plt.imshow(binary_image);
plt.title("Binary Image");
plt.axis("off");
plt.show()

eroded_image = cv2.erode(binary_image, structuring_element, iterations=5)
plt.imshow(eroded_image);
plt.title("Eroded Image");
plt.axis("off");
plt.show()

dilated_image = cv2.dilate(binary_image, structuring_element, iterations=5)
plt.imshow(dilated_image);
plt.title("Dilated Image");
plt.axis("off");
plt.show()

opened_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, structuring_element)
plt.imshow(opened_image);
plt.title("Open Image");
plt.axis("off");
plt.show()


closed_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, structuring_element)
plt.imshow(closed_image);
plt.title("Close Image");
plt.axis("off");
plt.show()

gradient_image = cv2.morphologyEx(binary_image, cv2.MORPH_GRADIENT, structuring_element)
plt.imshow(gradient_image);
plt.title("Gradient Image");
plt.axis("off");
plt.show()

top_hat = cv2.morphologyEx(binary_image, cv2.MORPH_TOPHAT, structuring_element)
plt.imshow(top_hat);
plt.title("Top Hat Image");
plt.axis("off");
plt.show()

black_hat = cv2.morphologyEx(binary_image, cv2.MORPH_BLACKHAT, structuring_element)
plt.imshow(black_hat);
plt.title("Black Hat Image");
plt.axis("off");
plt.show()

```

## Introduction to Frequency Response

- **What is Frequency Response?** 
  - The frequency response of an image shows how spatial details in the image are distributed across different frequencies.
  - In image processing, this is typically analyzed using the **Fourier Transform**.
- **Why Frequency Analysis?**
  - Useful for identifying patterns, noise, and image structures not easily observed in the spatial domain.

---

## The Fourier Transform

- **Fourier Transform (FT)**:
  - Converts an image from the **spatial domain** (pixels) to the **frequency domain** (sinusoids).
  - Each point in the frequency domain represents a specific frequency in the image.
- **Mathematical Basis**:
  - \( F(u,v) = \sum_x \sum_y f(x,y) e^{-j 2 \pi (ux/M + vy/N)} \)
  - Where \( F(u,v) \) is the frequency representation of the image.

---

## Low and High Frequencies

- **Low Frequencies**: 
  - Represent **slow variations** or large structures in the image (e.g., background or smooth gradients).
- **High Frequencies**:
  - Represent **rapid variations** or fine details (e.g., edges, noise).
- **Key Insight**: Most of the important structural information in an image is captured in the low-frequency range.

---

## Frequency Domain Representation

- The Fourier Transform of an image produces a **frequency spectrum**.
- **DC Component** (center of the spectrum): Represents the average intensity of the image.
- **Higher frequencies**: Spread out from the center and capture finer details.
  
- **Logarithmic scale**: Often used to visualize the frequency spectrum due to the wide range of values.

---

## The 2D Discrete Fourier Transform (DFT)

- The **2D DFT** is used to convert a 2D image into its frequency components:
  - **Input**: A 2D grayscale image.
  - **Output**: A complex matrix representing amplitude and phase for each frequency.
  
- **Inverse DFT**: Converts the frequency representation back to the spatial domain.

---

## Low-Pass and High-Pass Filtering

- **Low-Pass Filter (LPF)**:
  - Allows **low frequencies** to pass, attenuates high frequencies.
  - Used to **blur** images, removing high-frequency details like noise and edges.
  
- **High-Pass Filter (HPF)**:
  - Allows **high frequencies** to pass, attenuates low frequencies.
  - Used to **sharpen** images by enhancing edges and fine details.

---

## Band-Pass Filtering

- **Band-Pass Filter**:
  - Allows frequencies within a certain range (band) to pass.
  - Useful for **selectively enhancing specific frequency components** while filtering others.
- Applications: Used in image enhancement and texture analysis.

---

## Frequency Response Visualization

- **Magnitude Spectrum**: 
  - Represents the amplitude of each frequency component.
  - Typically visualized using the logarithmic scale to manage the large range of values.

- **Phase Spectrum**: 
  - Represents the phase of each frequency component.
  - Less important for human perception but crucial for reconstructing the image.

---

## Applications of Frequency Domain Processing

- **Noise Removal**: Low-pass filters can smooth out high-frequency noise.
- **Edge Detection**: High-pass filters enhance edges and sharp transitions.
- **Image Compression**: Frequency domain analysis helps identify redundant information.
- **Pattern Recognition**: Useful for detecting repetitive patterns like textures.

---