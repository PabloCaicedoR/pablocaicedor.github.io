% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
  aspectratio=32,
  spanish,
]{beamer}
\newif\ifbibliography
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolshorizontal
% remove section numbering
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{section title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{subsection title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}

\usetheme[]{CambridgeUS}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother



\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}


\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\makeatletter \expandafter\let\csname figure*\endcsname\figure \expandafter\let\csname endfigure*\endcsname\endfigure \expandafter\let\csname table*\endcsname\table \expandafter\let\csname endtable*\endcsname\endtable
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Tabla de contenidos}
\else
  \newcommand\contentsname{Tabla de contenidos}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{Listado de Figuras}
\else
  \newcommand\listfigurename{Listado de Figuras}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{Listado de Tablas}
\else
  \newcommand\listtablename{Listado de Tablas}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figura}
\else
  \newcommand\figurename{Figura}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Tabla}
\else
  \newcommand\tablename{Tabla}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listado}
\newcommand*\listoflistings{\listof{codelisting}{Listado de Listados}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Descenso de Gradiente en Ciencias Biomédicas},
  pdfauthor={PhD. Pablo Eduardo Caicedo Rodríguez},
  pdflang={es},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}


\title{Descenso de Gradiente en Ciencias Biomédicas}
\subtitle{Regresión lineal múltiple y regresión logística}
\author{PhD. Pablo Eduardo Caicedo Rodríguez}
\date{2025-11-01}

\begin{document}
\frame{\titlepage}


\begin{frame}[fragile]{Objetivos de aprendizaje}
\phantomsection\label{objetivos-de-aprendizaje}
\begin{itemize}
\tightlist
\item
  \textbf{Comprender} los fundamentos de la \textbf{Regresión Lineal},
  \textbf{Regresión Logística} y \textbf{Perceptrón Multicapa (MLP)}.
\item
  \textbf{Aplicar} estos modelos al contexto de \textbf{salud fetal} con
  datos de \textbf{cardiotocografía (CTG)}.
\item
  \textbf{Evaluar} el desempeño con métricas adecuadas (MSE,
  AUC/Log-Loss, matriz de confusión, F1).
\end{itemize}

\begin{columns}[T]
\begin{column}{0.45\linewidth}
\begin{enumerate}
\tightlist
\item
  Regresión Lineal
\item
  Regresión Logística
\item
  Perceptrón Multicapa
\item
  Cierre y discusión
\end{enumerate}
\end{column}

\begin{column}{0.45\linewidth}
\textbf{Dataset}: \texttt{fetal\_health.csv} (UCI CTG). \textbf{Contexto
clínico}: interpretación de CTG (\emph{normal}, \emph{sospechoso},
\emph{patológico}).
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Contexto clínico (CTG)}
\phantomsection\label{contexto-cluxednico-ctg}
\begin{tcolorbox}[enhanced jigsaw, breakable, coltitle=black, toptitle=1mm, rightrule=.15mm, leftrule=.75mm, colframe=quarto-callout-important-color-frame, toprule=.15mm, colbacktitle=quarto-callout-important-color!10!white, opacitybacktitle=0.6, titlerule=0mm, colback=white, arc=.35mm, bottomrule=.15mm, opacityback=0, left=2mm, bottomtitle=1mm, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Defición}]

Prueba médica que monitoriza simultáneamente la frecuencia cardíaca del
feto y la actividad contráctil del útero. Se realiza generalmente
durante el tercer trimestre del embarazo y el parto, colocando dos
transductores externos (uno para la frecuencia cardíaca fetal y otro
para las contracciones) sobre el abdomen de la madre

\end{tcolorbox}

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{../../recursos/imagenes/Presentaciones/ASIM/cardiotocografia.png}}

}

\caption{Generada con Gemini}

\end{figure}%
\end{frame}

\begin{frame}{Contexto clínico (CTG)}
\phantomsection\label{contexto-cluxednico-ctg-1}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.1525}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.8475}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Característica (Variable en CSV)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cálculo o Descripción
\end{minipage} \\
\midrule\noalign{}
\endhead
Parámetros Basales & \\
baseline value & Es la frecuencia cardíaca fetal (FCF) media aproximada
en un segmento de 10 minutos, excluyendo aceleraciones, deceleraciones y
períodos de variabilidad marcada (\textgreater25 lpm). Se redondea a
incrementos de 5 latidos por minuto (lpm).{[}4, 5, 6, 7, 8{]} El rango
normal se considera entre 110 y 160 lpm.{[}9, 10{]} \\
fetal\_movement & Número de movimientos fetales detectados por
segundo.{[}1, 11, 12{]} \\
uterine\_contractions & Número de contracciones uterinas por segundo. Se
considera normal tener 5 o menos contracciones en 10 minutos.{[}1, 4,
11, 12{]} \\
Eventos Transitorios (Aceleraciones y Deceleraciones) & \\
accelerations & Número de aceleraciones por segundo. Una aceleración es
un aumento abrupto de la FCF por encima de la línea de base de al menos
15 lpm, que dura 15 segundos o más, pero menos de 2 minutos.{[}5, 9,
10{]} \\
light\_decelerations & Número de deceleraciones leves por segundo. Una
deceleración es una caída de la FCF de más de 15 lpm que dura más de 15
segundos.{[}5{]} La categoría ``leve'' se refiere a su duración,
típicamente menor a 120 segundos.{[}3{]} \\
severe\_decelerations & Número de deceleraciones severas por segundo. Se
refiere a deceleraciones de larga duración, a menudo definidas como
aquellas que superan los 300 segundos.{[}3{]} \\
prolongued\_decelerations & Número de deceleraciones prolongadas por
segundo. Son caídas de la FCF que duran más de 2 o 3 minutos pero menos
de 10 minutos.{[}3, 6, 13{]} \\
Variabilidad de la FCF & \\
abnormal\_short\_term\_variability & Porcentaje de tiempo en que la
variabilidad a corto plazo (latido a latido) es anormal. La variabilidad
se considera anormal si es mínima (≤5 lpm) o marcada (\textgreater25
lpm).{[}6, 8{]} \\
mean\_value\_of\_short\_term\_variability & Valor medio de la
variabilidad a corto plazo (STV), que describe las fluctuaciones de la
FCF latido a latido.{[}3, 6{]} \\
percentage\_of\_time\_with\_abnormal\_long\_term\_variability &
Porcentaje de tiempo en que la variabilidad a largo plazo es anormal. Se
calcula sobre las fluctuaciones de la FCF en un período de un
minuto.{[}5{]} \\
mean\_value\_of\_long\_term\_variability & Valor medio de la
variabilidad a largo plazo (LTV), que mide la amplitud (diferencia entre
el pico y el valle) de las fluctuaciones de la FCF en un minuto.{[}3,
5{]} \\
Características del Histograma de FCF & Estas son propiedades
estadísticas calculadas a partir de la distribución de todos los valores
de FCF registrados durante el período de monitorización.{[}1, 11,
12{]} \\
histogram\_width & El ancho del histograma, calculado como la diferencia
entre el valor máximo (histogram\_max) y el mínimo (histogram\_min) de
la FCF. \\
histogram\_min & El valor mínimo de la FCF registrado en el
histograma. \\
histogram\_max & El valor máximo de la FCF registrado en el
histograma. \\
histogram\_number\_of\_peaks & El número de picos en la distribución del
histograma. \\
histogram\_number\_of\_zeroes & El número de ``ceros'' o bins con
frecuencia cero en el histograma. \\
histogram\_mode & El valor de FCF que aparece con mayor frecuencia (la
moda estadística). \\
histogram\_mean & El valor medio de la FCF en el histograma (la media
estadística). \\
histogram\_median & El valor central de la FCF en el histograma (la
mediana estadística). \\
histogram\_variance & La varianza de los valores de FCF, que mide su
dispersión alrededor de la media. \\
histogram\_tendency & Indica la simetría o sesgo del histograma. Puede
interpretarse como: 1 para tendencia a la derecha (positiva), -1 para
tendencia a la izquierda (negativa) y 0 para una distribución
simétrica. \\
\bottomrule\noalign{}
\end{longtable}
\end{frame}

\begin{frame}{Contexto clínico (CTG)}
\phantomsection\label{contexto-cluxednico-ctg-2}
\begin{itemize}
\tightlist
\item
  CTG registra \textbf{FCF} y \textbf{contracciones uterinas}.
\item
  Clasificación clínica (FIGO): \textbf{normal / sospechoso /
  patológico}.
\item
  Variabilidad, aceleraciones y desaceleraciones son claves.
\end{itemize}
\end{frame}

\begin{frame}{Regresión Lineal}
\phantomsection\label{regresiuxf3n-lineal}
\begin{block}{Idea clave}
\phantomsection\label{idea-clave}
Aproxima una relación \textbf{lineal}
\(\hat{y} = \beta_0 + \sum_j \beta_j x_j\)minimizando \textbf{MSE}.
\end{block}

\begin{block}{Ejemplo didáctico (CTG)}
\phantomsection\label{ejemplo-diduxe1ctico-ctg}
Usamos una \textbf{variable continua} de CTG como respuesta (p.~ej.,
\emph{histogram\_width}) para ilustrar ajuste y residuales.

\pandocbounded{\includegraphics[keepaspectratio]{v2Lect003_ADG_RedesNeuronales_files/figure-beamer/unnamed-chunk-2-1.pdf}}

\textbf{Discusión:} supuestos (linealidad, homocedasticidad,
independencia), diagnóstico con residuales.
\end{block}
\end{frame}

\begin{frame}{Regresión Logística}
\phantomsection\label{regresiuxf3n-loguxedstica}
\begin{block}{Idea clave}
\phantomsection\label{idea-clave-1}
Modela
\(P(Y=1 \mid \mathbf{x}) = \sigma(\beta_0 + \mathbf{x}^\top \beta)\) con
\textbf{sigmoide} \(\sigma(z)=1/(1+e^{-z})\).
\end{block}
\end{frame}

\begin{frame}{1. Definición de Regresión Logística}
\phantomsection\label{definiciuxf3n-de-regresiuxf3n-loguxedstica}
La \textbf{Regresión Logística} es un algoritmo de aprendizaje
automático supervisado utilizado fundamentalmente para problemas de
\textbf{clasificación binaria}.

A pesar de su nombre, su objetivo no es predecir un valor continuo, sino
modelar la \textbf{probabilidad} (\(P\)) de que una observación
pertenezca a una clase específica (usualmente denotada como \(Y=1\)).

El modelo toma variables de entrada (features) \(x_1, \dots, x_n\) y
estima \(P(Y=1 | \mathbf{x})\).
\end{frame}

\begin{frame}{2. El Mecanismo Central del Modelo}
\phantomsection\label{el-mecanismo-central-del-modelo}
El modelo logístico opera en dos pasos cruciales:

\begin{block}{2.1. El Componente Lineal (Logit)}
\phantomsection\label{el-componente-lineal-logit}
Primero, el modelo calcula una suma ponderada de las entradas,
exactamente igual que en una regresión lineal. A este resultado (\(z\))
se le conoce como \textbf{logit} o, más formalmente, \textbf{log-odds}.

\[
z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n
\]

\begin{itemize}
\tightlist
\item
  \(\beta_0\) es el intercepto (sesgo).
\item
  \(\beta_{1 \dots n}\) son los coeficientes (pesos) que el modelo
  aprende.
\item
  El rango de salida de \(z\) es el de todos los números reales:
  \((-\infty, +\infty)\).
\end{itemize}
\end{block}

\begin{block}{2.2. La Función Sigmoide (Logística)}
\phantomsection\label{la-funciuxf3n-sigmoide-loguxedstica}
Dado que una probabilidad debe estar en el rango \([0, 1]\), \(z\) no
puede ser el resultado final. La regresión logística aplica la
\textbf{función sigmoide} (\(\sigma\)) a \(z\) para ``aplastar''
(squash) la salida lineal al rango de probabilidad.

\[
P = \sigma(z) = \frac{1}{1 + e^{-z}}
\]

\begin{itemize}
\tightlist
\item
  Si \(z \to +\infty\), \(e^{-z} \to 0\), y \(P \to 1\).
\item
  Si \(z \to -\infty\), \(e^{-z} \to +\infty\), y \(P \to 0\).
\item
  Si \(z = 0\), \(e^{-0} = 1\), y \(P = 0.5\).
\end{itemize}
\end{block}
\end{frame}

\begin{frame}[fragile]{3. La Relación Clave: Probabilidad y Log-Odds}
\phantomsection\label{la-relaciuxf3n-clave-probabilidad-y-log-odds}
El concepto central que conecta el modelo lineal con la probabilidad es
el \textbf{log-odds}. Esta transformación es necesaria para mapear un
espacio acotado \([0, 1]\) a un espacio no acotado
\([-\infty, +\infty]\).

\begin{block}{3.1. De Probabilidad a Log-Odds}
\phantomsection\label{de-probabilidad-a-log-odds}
La transformación se realiza en dos pasos:

\begin{enumerate}
\tightlist
\item
  \textbf{Probabilidad (\(P\))}: La probabilidad del evento.

  \begin{itemize}
  \tightlist
  \item
    Rango: \([0, 1]\)
  \end{itemize}
\item
  \textbf{Odds (Momios)}: La razón entre la probabilidad de que ocurra
  (\(P\)) y la de que no ocurra (\(1-P\)). \[
  Odds = \frac{P}{1-P}
  \]

  \begin{itemize}
  \tightlist
  \item
    Rango: \([0, +\infty]\)
  \end{itemize}
\item
  \textbf{Log-Odds (Logit)}: El logaritmo natural de los \emph{odds}. \[
  Logit(P) = \ln(Odds) = \ln\left(\frac{P}{1-P}\right)
  \]

  \begin{itemize}
  \tightlist
  \item
    Rango: \([-\infty, +\infty]\)
  \end{itemize}
\end{enumerate}

El modelo de regresión logística es, por tanto, un modelo lineal que
predice el \emph{log-odds}:

\[
z = \ln\left(\frac{P}{1-P}\right) = \beta_0 + \beta_1 x_1 + \dots + \beta_n x_n
\]
\end{block}

\begin{block}{3.2. De Log-Odds a Probabilidad (La Inversa)}
\phantomsection\label{de-log-odds-a-probabilidad-la-inversa}
Para obtener la probabilidad \(P\) a partir del log-odds \(z\),
simplemente revertimos la transformación \texttt{Logit}. Este proceso de
despejar \(P\) de la ecuación del logit \textbf{da origen a la función
sigmoide}:

\begin{enumerate}
\item
  Ecuación base: \[
  z = \ln\left(\frac{P}{1-P}\right)
  \]
\item
  Aplicar exponencial (inversa del logaritmo): \[
  e^z = \frac{P}{1-P}
  \]
\item
  Despejar \(P\): \[
  e^z (1-P) = P
  \] \[
  e^z - e^z P = P
  \] \[
  e^z = P + e^z P
  \] \[
  e^z = P (1 + e^z)
  \]
\item
  Probabilidad \(P\) en función de \(z\): \[
  P = \frac{e^z}{1 + e^z}
  \]
\item
  \emph{Forma sigmoide alternativa (dividiendo numerador y denominador
  por \(e^z\))}: \[
  P = \frac{e^z/e^z}{(1 + e^z)/e^z} = \frac{1}{e^{-z} + 1} = \frac{1}{1 + e^{-z}}
  \]
\end{enumerate}
\end{block}
\end{frame}

\begin{frame}[fragile]{4. Interpretación de Coeficientes}
\phantomsection\label{interpretaciuxf3n-de-coeficientes}
Debido a esta relación, los coeficientes (\(\beta_i\)) del modelo tienen
una interpretación específica:

\begin{itemize}
\tightlist
\item
  \textbf{Coeficiente \(\beta_i\)}: Un incremento de una unidad en la
  variable \(x_i\) (manteniendo las demás constantes) genera un cambio
  de \(\beta_i\) en el \textbf{log-odds} de la predicción.
\item
  \textbf{Odds Ratio (OR)}: Para una interpretación más intuitiva, se
  utiliza \(e^{\beta_i}\). Un incremento de una unidad en \(x_i\)
  \textbf{multiplica} los \emph{odds} por un factor de \(e^{\beta_i}\).
\end{itemize}

\pandocbounded{\includegraphics[keepaspectratio]{v2Lect003_ADG_RedesNeuronales_files/figure-beamer/unnamed-chunk-3-3.pdf}}

\begin{block}{Clasificación binaria (Normal vs No‑Normal)}
\phantomsection\label{clasificaciuxf3n-binaria-normal-vs-nonormal}
\begin{verbatim}
              precision    recall  f1-score   support

           0      0.778     0.745     0.761        94
           1      0.929     0.940     0.934       332

    accuracy                          0.897       426
   macro avg      0.853     0.842     0.848       426
weighted avg      0.895     0.897     0.896       426
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{v2Lect003_ADG_RedesNeuronales_files/figure-beamer/unnamed-chunk-4-5.pdf}}
\end{block}
\end{frame}

\begin{frame}
\end{frame}

\section{Redes Neuronales}\label{redes-neuronales}

\begin{frame}{1. El Punto de Partida: Regresión Lineal}
\phantomsection\label{el-punto-de-partida-regresiuxf3n-lineal}
El problema de regresión estándar busca encontrar una función \(f\) que
mapee entradas \(\mathbf{x}\) a una salida \(y\).

En la \textbf{Regresión Lineal}, asumimos que la relación es
\emph{lineal}:

\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \epsilon
\] O en forma vectorial: \[
y = \mathbf{w}^T \mathbf{x} + b
\]

\begin{itemize}
\tightlist
\item
  \textbf{Objetivo}: Encontrar los parámetros óptimos
  (\(\mathbf{w}, b\)) que minimizan una función de pérdida (ej. Error
  Cuadrático Medio, MSE).
\item
  \textbf{Limitación}: El modelo está restringido a representar
  únicamente relaciones lineales.
\end{itemize}
\end{frame}

\begin{frame}{2. Primera Generalización: El GLM}
\phantomsection\label{primera-generalizaciuxf3n-el-glm}
¿Qué pasa si la salida no es lineal o no sigue una distribución normal?
(Ej. clasificación binaria).

Usamos un \textbf{Modelo Lineal Generalizado (GLM)}, como la
\textbf{Regresión Logística}:

\begin{enumerate}
\item
  \textbf{Predictor Lineal (\(z\))}: Mantenemos el núcleo lineal. \[
  z = \mathbf{w}^T \mathbf{x} + b
  \] El resultado \(z\) (el \emph{logit}) puede ir de
  \((-\infty, +\infty)\).
\item
  \textbf{Función de Enlace (Inversa)}: Aplicamos una transformación
  no-lineal \(g^{-1}\) para mapear \(z\) al rango deseado (ej.
  \([0, 1]\) para probabilidad). \[
  \hat{y} = g^{-1}(z) = \sigma(z) = \frac{1}{1 + e^{-z}}
  \]
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \textbf{Avance}: Hemos \emph{generalizado} la regresión. El modelo
  sigue siendo lineal en sus parámetros \(\mathbf{w}\), pero puede
  modelar fenómenos no lineales mediante una \textbf{función de
  activación} (la sigmoide).
\end{itemize}
\end{frame}

\begin{frame}{3. La Neurona: Una Unidad de Regresión}
\phantomsection\label{la-neurona-una-unidad-de-regresiuxf3n}
Una \textbf{neurona artificial} (o Perceptrón) es conceptualmente
idéntica a un modelo de regresión logística (un GLM).

\begin{enumerate}[<+->]
\item
  \textbf{Agregación Lineal}: Calcula el predictor lineal \(z\) (la
  entrada neta). \[
  z = \sum_{i=1}^n w_i x_i + b
  \]
\item
  \textbf{Función de Activación}: Aplica una transformación no-lineal
  \(a\) (la salida). \[
  a = g(z)
  \]
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(g(z)\) puede ser \(\text{sigmoid}(z)\), \(\tanh(z)\),
  \(\text{ReLU}(z)\), etc.
\item
  \textbf{Concepto Clave}: Una sola neurona es una unidad de regresión
  (lineal o generalizada) que aprende un \emph{único} límite de decisión
  (o una respuesta lineal).
\end{itemize}
\end{frame}

\begin{frame}{4. La Red: Composición de Funciones}
\phantomsection\label{la-red-composiciuxf3n-de-funciones}
¿Cómo modelar relaciones \emph{altamente} complejas que una sola neurona
no puede capturar?

\textbf{Respuesta}: Apilando las neuronas en capas.

La salida de una capa de ``unidades de regresión'' se convierte en la
\emph{entrada} de la siguiente capa.

\[
\text{Capa 1 (Oculta): } \mathbf{a}^{(1)} = g_1(\mathbf{W}^{(1)}\mathbf{x} + \mathbf{b}^{(1)})
\] \[
\text{Capa 2 (Salida): } \hat{y} = g_2(\mathbf{W}^{(2)}\mathbf{a}^{(1)} + \mathbf{b}^{(2)})
\]

Esto es una \textbf{composición de funciones} anidada:

\[
\hat{y} = g_2\left( \mathbf{W}^{(2)} \left( g_1(\mathbf{W}^{(1)}\mathbf{x} + \mathbf{b}^{(1)}) \right) + \mathbf{b}^{(2)} \right)
\]
\end{frame}

\begin{frame}{5. El Teorema de Aproximación Universal}
\phantomsection\label{el-teorema-de-aproximaciuxf3n-universal}
Esta arquitectura de ``regresiones apiladas'' tiene una propiedad
fundamental:

\begin{quote}
\textbf{Teorema de Aproximación Universal}: Una red neuronal
\emph{feedforward} con una sola capa oculta (con una función de
activación no lineal, como ReLU o Sigmoide) puede aproximar cualquier
función continua \(f(\mathbf{x})\) a un grado arbitrario de precisión,
dado un número suficiente de neuronas.
\end{quote}

\begin{itemize}
\tightlist
\item
  Una regresión lineal solo puede encontrar la \emph{mejor línea}.
\item
  Una red neuronal puede encontrar (aprender) la \emph{función}
  \(f(\mathbf{x})\) en sí misma, sin importar su forma.
\end{itemize}

\textbf{La red neuronal es un regresor generalizado en el sentido más
amplio.}
\end{frame}

\begin{frame}{6. Generalización del Aprendizaje (Optimización)}
\phantomsection\label{generalizaciuxf3n-del-aprendizaje-optimizaciuxf3n}
El proceso de ``entrenamiento'' también es una generalización de la
regresión.

\begin{columns}[T]
\begin{column}{0.45\linewidth}
\textbf{Regresión (Lineal/Logística)}

\begin{itemize}
\tightlist
\item
  \textbf{Pérdida}: Se define una función de coste (Loss Function)
  \(L(y, \hat{y})\).

  \begin{itemize}
  \tightlist
  \item
    \emph{Ej. MSE}: \(L = (y - \hat{y})^2\)
  \item
    \emph{Ej. Cross-Entropy}:
    \(L = -[y \log(\hat{y}) + (1-y) \log(1-\hat{y})]\)
  \end{itemize}
\item
  \textbf{Optimización}: Se encuentran los \(\mathbf{w}\) y \(b\) que
  minimizan \(L\) (a menudo usando Descenso de Gradiente).
\end{itemize}
\end{column}

\begin{column}{0.45\linewidth}
\textbf{Red Neuronal}

\begin{itemize}
\tightlist
\item
  \textbf{Pérdida}: Se define la \emph{misma} función de coste
  \(L(y, \hat{y})\) en la salida final.
\item
  \textbf{Optimización}: Se encuentran \emph{todos} los
  \(\mathbf{W}^{(l)}\) y \(\mathbf{b}^{(l)}\) de \emph{todas} las capas
  que minimizan \(L\).
\item
  \textbf{Mecanismo}: \textbf{Descenso de Gradiente} +
  \textbf{Backpropagation} (Retropropagación).

  \begin{itemize}
  \tightlist
  \item
    Backpropagation es simplemente la aplicación sistemática de la
    \textbf{regla de la cadena} del cálculo para encontrar el gradiente
    de \(L\) con respecto a cada peso en la vasta función compuesta.
  \end{itemize}
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{7. Conclusión: La Red como \(f_{\theta}(\mathbf{x})\)}
\phantomsection\label{conclusiuxf3n-la-red-como-f_thetamathbfx}
\begin{enumerate}
\tightlist
\item
  \textbf{Regresión Lineal}:

  \begin{itemize}
  \tightlist
  \item
    Modelo: \(f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b\)
  \item
    Asume una forma funcional \emph{fija} (lineal).
  \end{itemize}
\item
  \textbf{GLM (Logística)}:

  \begin{itemize}
  \tightlist
  \item
    Modelo: \(f(\mathbfx) = g(\mathbf{w}^T \mathbf{x} + b)\)
  \item
    Asume una forma fija (lineal) transformada por una activación fija
    (ej. sigmoide).
  \end{itemize}
\item
  \textbf{Red Neuronal (MLP)}:

  \begin{itemize}
  \tightlist
  \item
    Modelo: \(f(\mathbf{x}) = f_L(\dots f_2(f_1(\mathbf{x}))\dots)\)
  \item
    \textbf{No asume una forma funcional fija}.
  \item
    Es un \textbf{aproximador de funciones universal} cuyos parámetros
    \(\theta\) (todos los \(W\) y \(b\)) se \emph{aprenden} para que
    \(f_{\theta}(\mathbf{x})\) imite la verdadera función subyacente
    \(f(\mathbf{x})\) en los datos.
  \end{itemize}
\end{enumerate}

La red neuronal es la generalización última de la regresión: un sistema
que \textbf{aprende la forma de la función} desde los datos.
\end{frame}

\begin{frame}[fragile]{Perceptrón Multicapa --- MLP}
\phantomsection\label{perceptruxf3n-multicapa-mlp}
\textbf{Arquitectura propuesta:} 21→32→16→3 con \emph{ReLU} y
\textbf{softmax} para 3 clases \((1,2,3)\).

\includegraphics[width=10in,height=7in]{v2Lect003_ADG_RedesNeuronales_files/figure-beamer/dot-figure-1.png}

\begin{block}{Entrenamiento (multiclase)}
\phantomsection\label{entrenamiento-multiclase}
\begin{verbatim}
<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x7df08f74f770>
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{v2Lect003_ADG_RedesNeuronales_files/figure-beamer/unnamed-chunk-6-7.pdf}}

\begin{verbatim}
Macro-F1: 0.8003850715462932
\end{verbatim}

\textbf{Notas didácticas:} desequilibrio de clases (SMOTE), métricas por
clase (F1), validación cruzada, \emph{early stopping}.
\end{block}
\end{frame}

\begin{frame}{Cierre y recomendaciones}
\phantomsection\label{cierre-y-recomendaciones}
\begin{itemize}
\tightlist
\item
  La \textbf{interpretación clínica} sigue siendo esencial; el ML
  complementa, no reemplaza, el juicio médico.
\item
  Validar externamente (dominios LMIC vs HIC), sesgos de muestreo y
  \emph{data shift}.
\item
  Reportar métricas por clase, especialmente la \textbf{clase
  sospechosa}.
\end{itemize}
\end{frame}

\begin{frame}{Referencias (DOI / ISBN)}
\phantomsection\label{referencias-doi-isbn}
\begin{itemize}
\tightlist
\item
  Ayres‑de‑Campos D, \emph{et al.} \textbf{FIGO consensus guidelines on
  intrapartum fetal monitoring: Cardiotocography.} \emph{Int J Gynaecol
  Obstet} 2015;131(1):13--24. DOI: 10.1016/j.ijgo.2015.06.020
\item
  Macones GA, \emph{et al.} \textbf{The 2008 NICHD workshop report on
  electronic fetal monitoring.} \emph{J Obstet Gynecol Neonatal Nurs}
  2008. (see Obstet Gynecol 2008;112:661--6)
\item
  Hoodbhoy Z, \emph{et al.} \textbf{Use of Machine Learning Algorithms
  for Prediction of Fetal Risk using Cardiotocographic Data.} \emph{Int
  J Appl Basic Med Res} 2019;9:226--230. DOI:
  10.4103/ijabmr.IJABMR\_370\_18
\item
  James G, Witten D, Hastie T, Tibshirani R. \textbf{An Introduction to
  Statistical Learning (2nd ed.).} Springer, 2021. DOI:
  10.1007/978-1-0716-1418-1
\item
  Hosmer DW, Lemeshow S, Sturdivant RX. \textbf{Applied Logistic
  Regression (3rd ed.).} Wiley, 2013. DOI: 10.1002/9781118548387
\item
  Rumelhart DE, Hinton GE, Williams RJ. \textbf{Learning representations
  by back‑propagating errors.} \emph{Nature} 1986;323:533--536. DOI:
  10.1038/323533a0
\item
  Goodfellow I, Bengio Y, Courville A. \textbf{Deep Learning.} MIT
  Press, 2016. ISBN: 978‑0262035613
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Apéndice · Carga de datos y EDA mínimo}
\phantomsection\label{apuxe9ndice-carga-de-datos-y-eda-muxednimo}
\begin{verbatim}
fetal_health
1.0    1655
2.0     295
3.0     176
Name: count, dtype: int64
\end{verbatim}

\begin{verbatim}
                                                     count  ...      max
baseline value                                      2126.0  ...  160.000
accelerations                                       2126.0  ...    0.019
fetal_movement                                      2126.0  ...    0.481
uterine_contractions                                2126.0  ...    0.015
light_decelerations                                 2126.0  ...    0.015
severe_decelerations                                2126.0  ...    0.001
prolongued_decelerations                            2126.0  ...    0.005
abnormal_short_term_variability                     2126.0  ...   87.000
mean_value_of_short_term_variability                2126.0  ...    7.000
percentage_of_time_with_abnormal_long_term_vari...  2126.0  ...   91.000
mean_value_of_long_term_variability                 2126.0  ...   50.700
histogram_width                                     2126.0  ...  180.000
histogram_min                                       2126.0  ...  159.000
histogram_max                                       2126.0  ...  238.000
histogram_number_of_peaks                           2126.0  ...   18.000
histogram_number_of_zeroes                          2126.0  ...   10.000
histogram_mode                                      2126.0  ...  187.000
histogram_mean                                      2126.0  ...  182.000
histogram_median                                    2126.0  ...  186.000
histogram_variance                                  2126.0  ...  269.000
histogram_tendency                                  2126.0  ...    1.000
fetal_health                                        2126.0  ...    3.000

[22 rows x 8 columns]
\end{verbatim}
\end{frame}




\end{document}
