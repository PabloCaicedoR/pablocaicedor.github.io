{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be3cdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TextProcessor at 0x7cc2a89f0830>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Configuración del dispositivo (GPU si está disponible, vital para Senior devs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self, text_data):\n",
    "        # Crear vocabulario de caracteres únicos\n",
    "        chars = sorted(list(set(text_data)))\n",
    "        self.vocab_size = len(chars) # +1 para el token EOS (End of Sequence) si es necesario, o manejamos \\n\n",
    "        self.char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
    "        self.ix_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "        self.chars = chars\n",
    "\n",
    "    def str_to_tensor(self, seq):\n",
    "        \"\"\"Convierte string a tensor de índices (LongTensor)\"\"\"\n",
    "        tensor = torch.tensor([self.char_to_ix[ch] for ch in seq], dtype=torch.long).to(device)\n",
    "        return tensor\n",
    "\n",
    "# Datos dummy para probar el código inmediatamente\n",
    "data_raw = \"diplosaurio\\ntiranosaurio\\nvelociraptor\\ntriceratops\\nestegosaurio\\n\"\n",
    "processor = TextProcessor(data_raw)\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f12c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1):\n",
    "        super(DinoRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 1. Capa de Embedding: Representación densa de x_t\n",
    "        # Equivalente eficiente a la entrada one-hot\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "        # 2. Capa RNN: Procesa la secuencia\n",
    "        # batch_first=True espera entrada (batch, seq, features)\n",
    "        self.rnn = nn.RNN(input_size=hidden_size,\n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=num_layers,\n",
    "                          batch_first=True)\n",
    "\n",
    "        # 3. Capa de Salida (Decoder): W_ya * a_t + b_y\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x shape: (batch_size, seq_len)\n",
    "        # hidden shape: (num_layers, batch_size, hidden_size)\n",
    "\n",
    "        # Embed: (batch, seq, hidden)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # RNN Forward: out contiene los estados a_t para cada paso\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "\n",
    "        # Flatten output para la capa lineal\n",
    "        out = out.reshape(-1, self.hidden_size)\n",
    "\n",
    "        # Predicción (Logits no normalizados)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f024d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss inicial: 2.7733\n"
     ]
    }
   ],
   "source": [
    "def train_step(model, optimizer, criterion, input_seq, target_seq):\n",
    "    model.train() # Modo entrenamiento\n",
    "\n",
    "    # Inicializar estado oculto (a_0 = 0)\n",
    "    hidden = model.init_hidden(batch_size=1)\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    # PyTorch permite pasar toda la secuencia a la vez en nn.RNN\n",
    "    # input_seq: (1, seq_len)\n",
    "    input_tensor = input_seq.unsqueeze(0)\n",
    "    target_tensor = target_seq.view(-1)   # Flatten targets\n",
    "\n",
    "    output, _ = model(input_tensor, hidden)\n",
    "\n",
    "    # output: (seq_len, vocab_size), target: (seq_len)\n",
    "    loss = criterion(output, target_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Gradient Clipping: CRUCIAL en RNNs para evitar explosión de gradiente\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "# Configuración\n",
    "hidden_size = 128\n",
    "model = DinoRNN(processor.vocab_size, hidden_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Ejemplo de una iteración (en la práctica, iterarías sobre tu dataset)\n",
    "input_str = \"tiranosaurio\"\n",
    "input_tensor = processor.str_to_tensor(input_str[:-1]) # entrada: \"tiranosauri\"\n",
    "target_tensor = processor.str_to_tensor(input_str[1:]) # target:  \"iranosaurio\"\n",
    "\n",
    "loss = train_step(model, optimizer, criterion, input_tensor, target_tensor)\n",
    "print(f\"Loss inicial: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75615b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generado: aug\n"
     ]
    }
   ],
   "source": [
    "def sample(model, start_char='t', max_length=20, temperature=1.0):\n",
    "    model.eval() # Modo evaluación\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Inicializar entrada\n",
    "        input_tensor = processor.str_to_tensor(start_char).unsqueeze(0) # (1, 1)\n",
    "        hidden = model.init_hidden(1)\n",
    "\n",
    "        generated_name = start_char\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            output, hidden = model(input_tensor, hidden)\n",
    "\n",
    "            # Aplicar temperatura para controlar la aleatoriedad\n",
    "            # Temp alta (>1): más creativo/errores. Temp baja (<1): conservador/repetitivo.\n",
    "            output_dist = output.data.view(-1).div(temperature).exp()\n",
    "            top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "            predicted_char = processor.ix_to_char[top_i.item()]\n",
    "\n",
    "            # Si el modelo predice el fin de línea, terminamos\n",
    "            if predicted_char == '\\n':\n",
    "                break\n",
    "\n",
    "            generated_name += predicted_char\n",
    "            input_tensor = torch.tensor([[top_i]], dtype=torch.long).to(device)\n",
    "\n",
    "        return generated_name\n",
    "\n",
    "# Prueba de generación (sin entrenar saldrá basura, pero el código es funcional)\n",
    "print(f\"Generado: {sample(model, start_char='a', temperature=0.8)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084dfdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de Entrada (X): torch.Size([2, 5, 3])\n",
      "------------------------------\n",
      "Dimensiones de 'output' (Secuencia completa): torch.Size([2, 5, 4])\n",
      "Dimensiones de 'h_n'    (Estado final):       torch.Size([1, 2, 4])\n",
      "\n",
      "--- Verificación de Valores ---\n",
      "El último paso de tiempo de 'output' debe ser igual a 'h_n' (para una sola capa):\n",
      "Output (t=5): [-0.116896   0.3243003 -0.594122  -0.5339937]\n",
      "Hidden (Final): [-0.116896   0.3243003 -0.594122  -0.5339937]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- 1. Definición de Hiperparámetros ---\n",
    "BATCH_SIZE = 2      # Número de muestras procesadas en paralelo\n",
    "SEQ_LEN = 5         # Longitud de la secuencia temporal (T)\n",
    "INPUT_SIZE = 3      # Número de características por paso (ej. [temp, presión, humedad])\n",
    "HIDDEN_SIZE = 4     # Dimensión del espacio latente (memoria de la red)\n",
    "\n",
    "# --- 2. Instancia de la Capa RNN ---\n",
    "# batch_first=True es crucial para usar el formato (N, L, H_in) estándar en ingeniería\n",
    "rnn_layer = nn.RNN(input_size=INPUT_SIZE,\n",
    "                   hidden_size=HIDDEN_SIZE,\n",
    "                   num_layers=1,\n",
    "                   batch_first=True)\n",
    "\n",
    "# --- 3. Generación de Entrada Sintética ---\n",
    "# Tensor X: [Batch Size, Sequence Length, Input Features]\n",
    "inputs = torch.randn(BATCH_SIZE, SEQ_LEN, INPUT_SIZE)\n",
    "\n",
    "print(f\"Dimensiones de Entrada (X): {inputs.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 4. Inicialización del Estado Oculto (Opcional) ---\n",
    "# Si no se provee, PyTorch asume ceros.\n",
    "# Formato h0: [Num Layers, Batch Size, Hidden Size]\n",
    "h0 = torch.zeros(1, BATCH_SIZE, HIDDEN_SIZE)\n",
    "\n",
    "# --- 5. Forward Pass ---\n",
    "# La RNN devuelve dos objetos:\n",
    "#   output: contiene todos los estados ocultos h_1, h_2, ..., h_T\n",
    "#   h_n: contiene solo el último estado oculto h_T (memoria final)\n",
    "output, h_n = rnn_layer(inputs, h0)\n",
    "\n",
    "# --- 6. Análisis de Salidas ---\n",
    "print(f\"Dimensiones de 'output' (Secuencia completa): {output.shape}\")\n",
    "print(f\"Dimensiones de 'h_n'    (Estado final):       {h_n.shape}\")\n",
    "\n",
    "print(\"\\n--- Verificación de Valores ---\")\n",
    "print(\"El último paso de tiempo de 'output' debe ser igual a 'h_n' (para una sola capa):\")\n",
    "# Comparamos el último paso temporal de la primera muestra en el batch\n",
    "print(f\"Output (t=5): {output[0, -1, :].detach().numpy()}\")\n",
    "print(f\"Hidden (Final): {h_n[0, 0, :].detach().numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_causal_env_001 (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
